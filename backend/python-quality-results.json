{
  "Python Compilation Check": {
    "success": false,
    "output": "*** Error compiling 'app/api/v1/endpoints/secure_payments.py'...\nSorry: IndentationError: unexpected indent (secure_payments.py, line 61)\n*** Error compiling 'app/core/security.py'...\nSorry: IndentationError: unexpected indent (security.py, line 486)\n*** Error compiling 'app/core/tenant_security_current.py'...\n  File \"app/core/tenant_security_current.py\", line 237\n    \"\"\"\n    ^\nSyntaxError: unterminated triple-quoted string literal (detected at line 255)\n\n*** Error compiling 'app/schemas/employee_schemas.py'...\nSorry: IndentationError: unexpected indent (employee_schemas.py, line 113)\n*** Error compiling 'app/schemas/search_schemas.py'...\nSorry: IndentationError: unexpected indent (search_schemas.py, line 51)\n*** Error compiling 'app/schemas/subscription.py'...\nSorry: IndentationError: unexpected indent (subscription.py, line 80)\n*** Error compiling 'app/services/activity_logger.py'...\nSorry: IndentationError: unexpected indent (activity_logger.py, line 99)\n",
    "command": "python3 -m compileall -q app/"
  },
  "Ruff Linter Check": {
    "success": false,
    "output": "276\tF821\t[ ] undefined-name\n233\tF401\t[*] unused-import\n152\t    \t[ ] invalid-syntax\n 65\tF841\t[*] unused-variable\n 58\tE712\t[ ] true-false-comparison\n 35\tE402\t[ ] module-import-not-at-top-of-file\n 14\tF541\t[*] f-string-missing-placeholders\n  7\tF811\t[ ] redefined-while-unused\n  6\tE701\t[ ] multiple-statements-on-one-line-colon\nFound 846 errors.\n[*] 299 fixable with the `--fix` option (76 hidden fixes can be enabled with the `--unsafe-fixes` option).\n",
    "command": "ruff check app/ --statistics"
  },
  "Black Code Format Check": {
    "success": false,
    "output": "--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/__init__.py\t2025-08-01 21:42:06.642507+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/__init__.py\t2025-08-02 22:36:02.510394+00:00\n@@ -2,6 +2,6 @@\n Fynlo POS Backend Application\n FastAPI-based Point of Sale system for restaurants\n \"\"\"\n \n __version__ = \"1.0.0\"\n-__author__ = \"Ryan Davidson\"\n\\ No newline at end of file\n+__author__ = \"Ryan Davidson\"\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/__init__.py\t2025-08-01 21:42:06.642625+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/__init__.py\t2025-08-02 22:36:02.517503+00:00\n@@ -1,4 +1,4 @@\n \"\"\"\n API package for Fynlo POS\n Contains all API route definitions and endpoints\n-\"\"\"\n\\ No newline at end of file\n+\"\"\"\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/mobile/__init__.py\t2025-07-03 16:16:48.230130+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/mobile/__init__.py\t2025-08-02 22:36:02.518718+00:00\n@@ -1 +1 @@\n-# Mobile API package\n\\ No newline at end of file\n+# Mobile API package\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/__init__.py\t2025-08-01 21:42:06.642969+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/__init__.py\t2025-08-02 22:36:02.519792+00:00\n@@ -1,4 +1,4 @@\n \"\"\"\n API v1 package\n Version 1 of the Fynlo POS API\n-\"\"\"\n\\ No newline at end of file\n+\"\"\"\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/__init__.py\t2025-08-01 21:42:06.643379+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/__init__.py\t2025-08-02 22:36:02.520804+00:00\n@@ -7,6 +7,6 @@\n - debug_user.py\n - rls_example.py\n - Any other test/mock endpoints\n \n These files are kept for reference but should NEVER be exposed in production.\n-\"\"\"\n\\ No newline at end of file\n+\"\"\"\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/api.py\t2025-08-02 21:56:58.983178+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/api.py\t2025-08-02 22:36:02.544798+00:00\n@@ -4,20 +4,42 @@\n \n from fastapi import APIRouter\n \n \n from app.api.v1.endpoints import (\n-    auth, restaurants, products, orders, payments, customers,\n-    analytics, files, platform, platform_settings, platform_settings_public, payment_configurations,\n-    websocket, sync, notifications, menu, public_menu,\n-    pos, admin, inventory, recipes, employees, # Added inventory, recipes, and employees\n-    exports, dashboard, websocket_portal, storage_health,  # Portal-specific endpoints + storage health\n+    auth,\n+    restaurants,\n+    products,\n+    orders,\n+    payments,\n+    customers,\n+    analytics,\n+    files,\n+    platform,\n+    platform_settings,\n+    platform_settings_public,\n+    payment_configurations,\n+    websocket,\n+    sync,\n+    notifications,\n+    menu,\n+    public_menu,\n+    pos,\n+    admin,\n+    inventory,\n+    recipes,\n+    employees,  # Added inventory, recipes, and employees\n+    exports,\n+    dashboard,\n+    websocket_portal,\n+    storage_health,  # Portal-specific endpoints + storage health\n     platform_settings_optimized,  # Optimized endpoints for mobile app\n     platform_admin,  # Secure platform administration\n     sumup,  # SumUp payment provider initialization\n     restaurant_switch,  # Multi-restaurant management\n-    health, monitoring  # Instance health and monitoring endpoints\n+    health,\n+    monitoring,  # Instance health and monitoring endpoints\n )\n from app.api.v1 import subscriptions\n from app.api.v1.platform import platform_router\n \n # Apply a default rate limit to all routes in this router - TEMPORARILY DISABLED.\n@@ -28,44 +50,66 @@\n \n # Include all endpoint routers\n # Routes that have their own @limiter.limit decorator (e.g., auth, payments)\n # will use their specific limit instead of this default one.\n api_router.include_router(auth.router, prefix=\"/auth\", tags=[\"authentication\"])\n-api_router.include_router(restaurants.router, prefix=\"/restaurants\", tags=[\"restaurants\"])\n+api_router.include_router(\n+    restaurants.router, prefix=\"/restaurants\", tags=[\"restaurants\"]\n+)\n api_router.include_router(products.router, prefix=\"/products\", tags=[\"products\"])\n api_router.include_router(orders.router, prefix=\"/orders\", tags=[\"orders\"])\n api_router.include_router(payments.router, prefix=\"/payments\", tags=[\"payments\"])\n api_router.include_router(customers.router, prefix=\"/customers\", tags=[\"customers\"])\n api_router.include_router(analytics.router, prefix=\"/analytics\", tags=[\"analytics\"])\n api_router.include_router(files.router, prefix=\"/files\", tags=[\"file_upload\"])\n api_router.include_router(platform.router, prefix=\"/platform\", tags=[\"platform\"])\n-api_router.include_router(platform_settings.router, prefix=\"/platform/settings\", tags=[\"platform_settings\"])\n-api_router.include_router(platform_settings_public.router, prefix=\"/platform/public\", tags=[\"platform_public\"])\n-api_router.include_router(payment_configurations.router, prefix=\"/platform\", tags=[\"payment_configurations\"])\n+api_router.include_router(\n+    platform_settings.router, prefix=\"/platform/settings\", tags=[\"platform_settings\"]\n+)\n+api_router.include_router(\n+    platform_settings_public.router, prefix=\"/platform/public\", tags=[\"platform_public\"]\n+)\n+api_router.include_router(\n+    payment_configurations.router, prefix=\"/platform\", tags=[\"payment_configurations\"]\n+)\n api_router.include_router(websocket.router, prefix=\"/websocket\", tags=[\"websocket\"])\n api_router.include_router(sync.router, prefix=\"/sync\", tags=[\"sync\"])\n-api_router.include_router(notifications.router, prefix=\"/notifications\", tags=[\"notifications\"])\n+api_router.include_router(\n+    notifications.router, prefix=\"/notifications\", tags=[\"notifications\"]\n+)\n api_router.include_router(pos.router, prefix=\"/pos\", tags=[\"pos\"])\n api_router.include_router(admin.router, prefix=\"/admin\", tags=[\"admin\"])\n \n # Inventory and Recipe Management\n-api_router.include_router(inventory.router, prefix=\"/inventory\", tags=[\"inventory_management\"])\n+api_router.include_router(\n+    inventory.router, prefix=\"/inventory\", tags=[\"inventory_management\"]\n+)\n api_router.include_router(recipes.router, prefix=\"/recipes\", tags=[\"recipe_management\"])\n \n # Employee Management\n-api_router.include_router(employees.router, prefix=\"/employees\", tags=[\"employee_management\"])\n+api_router.include_router(\n+    employees.router, prefix=\"/employees\", tags=[\"employee_management\"]\n+)\n \n # Restaurant Switching (Multi-restaurant management)\n-api_router.include_router(restaurant_switch.router, prefix=\"/restaurant-switch\", tags=[\"restaurant_management\"])\n+api_router.include_router(\n+    restaurant_switch.router,\n+    prefix=\"/restaurant-switch\",\n+    tags=[\"restaurant_management\"],\n+)\n \n # Menu Management (Frontend compatibility endpoints)\n api_router.include_router(menu.router, prefix=\"/menu\", tags=[\"menu\"])\n # Public menu endpoints (no auth required)\n-api_router.include_router(public_menu.router, prefix=\"/public/menu\", tags=[\"public-menu\"])\n+api_router.include_router(\n+    public_menu.router, prefix=\"/public/menu\", tags=[\"public-menu\"]\n+)\n \n # Subscription Management\n-api_router.include_router(subscriptions.router, prefix=\"/subscriptions\", tags=[\"subscriptions\"])\n+api_router.include_router(\n+    subscriptions.router, prefix=\"/subscriptions\", tags=[\"subscriptions\"]\n+)\n \n # New Platform API for web dashboard (not used by mobile app)\n # This contains comprehensive platform management endpoints\n api_router.include_router(platform_router)\n \n@@ -76,16 +120,22 @@\n \n # Storage management endpoints\n api_router.include_router(storage_health.router, prefix=\"/storage\", tags=[\"storage\"])\n \n # Optimized platform endpoints for mobile app performance\n-api_router.include_router(platform_settings_optimized.router, prefix=\"/platform/optimized\", tags=[\"platform_optimized\"])\n+api_router.include_router(\n+    platform_settings_optimized.router,\n+    prefix=\"/platform/optimized\",\n+    tags=[\"platform_optimized\"],\n+)\n \n # Secure platform administration endpoints\n-api_router.include_router(platform_admin.router, prefix=\"/platform/admin\", tags=[\"platform_admin\"])\n+api_router.include_router(\n+    platform_admin.router, prefix=\"/platform/admin\", tags=[\"platform_admin\"]\n+)\n \n # SumUp payment provider endpoints\n api_router.include_router(sumup.router, prefix=\"/sumup\", tags=[\"sumup\"])\n \n # Health and monitoring endpoints\n api_router.include_router(health.router, prefix=\"/health\", tags=[\"health\"])\n-api_router.include_router(monitoring.router, prefix=\"/monitoring\", tags=[\"monitoring\"])\n\\ No newline at end of file\n+api_router.include_router(monitoring.router, prefix=\"/monitoring\", tags=[\"monitoring\"])\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/exports.py\t2025-08-02 21:56:58.984838+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/exports.py\t2025-08-02 22:36:02.576669+00:00\n@@ -13,52 +13,57 @@\n from app.core.responses import APIResponseHelper\n from app.middleware.rate_limit_middleware import limiter, PORTAL_EXPORT_RATE\n \n router = APIRouter()\n \n+\n @router.get(\"/menu/{restaurant_id}/export\")\n @limiter.limit(PORTAL_EXPORT_RATE)\n async def export_menu_disabled(\n     request: Request,\n     restaurant_id: str,\n     format: str = Query(\"json\", regex=\"^(json|csv|pdf)$\"),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Temporarily disabled endpoint - maintains original signature\"\"\"\n     return APIResponseHelper.error(\n         message=\"Export functionality is temporarily unavailable. Please try again later.\",\n-        status_code=503\n+        status_code=503,\n     )\n+\n \n @router.get(\"/reports/{restaurant_id}/export\")\n @limiter.limit(PORTAL_EXPORT_RATE)\n async def export_report_disabled(\n     request: Request,\n     restaurant_id: str,\n-    report_type: str = Query(..., regex=\"^(sales|inventory|staff|customers|financial)$\"),\n+    report_type: str = Query(\n+        ..., regex=\"^(sales|inventory|staff|customers|financial)$\"\n+    ),\n     format: str = Query(\"json\", regex=\"^(json|csv|pdf)$\"),\n     date_from: date = Query(...),\n     date_to: date = Query(...),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Temporarily disabled endpoint - maintains original signature\"\"\"\n     return APIResponseHelper.error(\n         message=\"Export functionality is temporarily unavailable. Please try again later.\",\n-        status_code=503\n+        status_code=503,\n     )\n+\n \n @router.post(\"/menu/{restaurant_id}/import\")\n @limiter.limit(PORTAL_EXPORT_RATE)\n async def import_menu_disabled(\n     request: Request,\n     restaurant_id: str,\n     file_content: dict,  # JSON content from request body\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Temporarily disabled endpoint - maintains original signature\"\"\"\n     return APIResponseHelper.error(\n         message=\"Import functionality is temporarily unavailable. Please try again later.\",\n-        status_code=503\n-    )\n\\ No newline at end of file\n+        status_code=503,\n+    )\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/auth_backup.py\t2025-08-02 21:56:58.983955+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/auth_backup.py\t2025-08-02 22:36:02.623907+00:00\n@@ -17,43 +17,47 @@\n from app.core.responses import APIResponseHelper, iOSResponseHelper\n from app.core.exceptions import (\n     AuthenticationException,\n     ValidationException,\n     ConflictException,\n-    iOSErrorHelper\n+    iOSErrorHelper,\n )\n from app.middleware.rate_limit_middleware import limiter, AUTH_RATE\n \n \n from app.services.audit_logger import AuditLoggerService\n from app.models.audit_log import AuditEventType, AuditEventStatus\n \n router = APIRouter()\n security = HTTPBearer()\n pwd_context = CryptContext(schemes=[\"bcrypt\"], deprecated=\"auto\")\n+\n \n # Pydantic models\n class UserLogin(BaseModel):\n     email: EmailStr\n     password: str\n+\n \n class UserRegister(BaseModel):\n     email: EmailStr\n     password: str\n     first_name: str\n     last_name: str\n     role: str = \"employee\"\n     restaurant_id: Optional[str] = None\n     platform_id: Optional[str] = None\n \n+\n class Token(BaseModel):\n     access_token: str\n     token_type: str = \"bearer\"\n     user_id: str\n     role: str\n     restaurant_id: Optional[str] = None\n     platform_id: Optional[str] = None\n+\n \n class UserResponse(BaseModel):\n     id: str\n     email: str\n     first_name: str\n@@ -61,231 +65,279 @@\n     role: str\n     restaurant_id: Optional[str] = None\n     platform_id: Optional[str] = None\n     is_active: bool\n \n+\n def verify_password(plain_password: str, hashed_password: str) -> bool:\n     \"\"\"Verify password\"\"\"\n     return pwd_context.verify(plain_password, hashed_password)\n \n+\n def get_password_hash(password: str) -> str:\n     \"\"\"Hash password\"\"\"\n     return pwd_context.hash(password)\n \n+\n def authenticate_user(db: Session, email: str, password: str) -> Optional[User]:\n     \"\"\"Authenticate user with email and password\n-    \n+\n     This function is used by mobile endpoints for authentication.\n     Returns the user if authentication succeeds, None if it fails.\n     \"\"\"\n     user = db.query(User).filter(User.email == email).first()\n-    \n+\n     if not user:\n         return None\n-    \n+\n     if not verify_password(password, user.password_hash):\n         return None\n-    \n+\n     if not user.is_active:\n         return None\n-    \n+\n     return user\n+\n \n def create_access_token(data: dict, expires_delta: Optional[timedelta] = None):\n     \"\"\"Create JWT access token\"\"\"\n     to_encode = data.copy()\n     if expires_delta:\n         expire = datetime.utcnow() + expires_delta\n     else:\n-        expire = datetime.utcnow() + timedelta(minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES)\n-    \n+        expire = datetime.utcnow() + timedelta(\n+            minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES\n+        )\n+\n     to_encode.update({\"exp\": expire})\n-    encoded_jwt = jwt.encode(to_encode, settings.SECRET_KEY, algorithm=settings.ALGORITHM)\n+    encoded_jwt = jwt.encode(\n+        to_encode, settings.SECRET_KEY, algorithm=settings.ALGORITHM\n+    )\n     return encoded_jwt\n \n+\n async def get_current_user(\n-    request: Request, # Added Request\n+    request: Request,  # Added Request\n     credentials: HTTPAuthorizationCredentials = Depends(security),\n     db: Session = Depends(get_db),\n-    redis: RedisClient = Depends(get_redis)\n+    redis: RedisClient = Depends(get_redis),\n ) -> User:\n     \"\"\"Get current authenticated user\"\"\"\n     audit_service = AuditLoggerService(db)\n     ip_address = request.client.host if request.client else \"unknown\"\n     user_agent = request.headers.get(\"user-agent\", \"unknown\")\n     action_prefix = f\"Access to {request.url.path} denied\"\n \n     credentials_exception = AuthenticationException(\n-        message=\"Could not validate credentials\")\n-    \n+        message=\"Could not validate credentials\"\n+    )\n+\n     user_id_from_token: Optional[str] = None\n     try:\n-        payload = jwt.decode(credentials.credentials, settings.SECRET_KEY, algorithms=[settings.ALGORITHM])\n+        payload = jwt.decode(\n+            credentials.credentials,\n+            settings.SECRET_KEY,\n+            algorithms=[settings.ALGORITHM],\n+        )\n         user_id_from_token = payload.get(\"sub\")\n         if user_id_from_token is None:\n             await audit_service.create_audit_log(\n-                event_type=AuditEventType.ACCESS_DENIED, event_status=AuditEventStatus.FAILURE,\n+                event_type=AuditEventType.ACCESS_DENIED,\n+                event_status=AuditEventStatus.FAILURE,\n                 action_performed=f\"{action_prefix}: Invalid token (no sub).\",\n-                ip_address=ip_address, user_agent=user_agent,\n-                details={\"token_prefix\": credentials.credentials[:10]+\"...\", \"reason\": \"Token missing 'sub' field.\"},\n-                commit=True\n+                ip_address=ip_address,\n+                user_agent=user_agent,\n+                details={\n+                    \"token_prefix\": credentials.credentials[:10] + \"...\",\n+                    \"reason\": \"Token missing 'sub' field.\",\n+                },\n+                commit=True,\n             )\n             raise credentials_exception\n     except JWTError as e:\n         await audit_service.create_audit_log(\n-            event_type=AuditEventType.ACCESS_DENIED, event_status=AuditEventStatus.FAILURE,\n+            event_type=AuditEventType.ACCESS_DENIED,\n+            event_status=AuditEventStatus.FAILURE,\n             action_performed=f\"{action_prefix}: JWT decoding error.\",\n-            ip_address=ip_address, user_agent=user_agent,\n-            details={\"token_prefix\": credentials.credentials[:10]+\"...\", \"error\": str(e), \"reason\": \"JWTError\"},\n-            commit=True\n+            ip_address=ip_address,\n+            user_agent=user_agent,\n+            details={\n+                \"token_prefix\": credentials.credentials[:10] + \"...\",\n+                \"error\": str(e),\n+                \"reason\": \"JWTError\",\n+            },\n+            commit=True,\n         )\n         raise credentials_exception\n-    \n+\n     is_blacklisted = await redis.exists(f\"blacklist:{credentials.credentials}\")\n     if is_blacklisted:\n         await audit_service.create_audit_log(\n-            event_type=AuditEventType.ACCESS_DENIED, event_status=AuditEventStatus.FAILURE,\n+            event_type=AuditEventType.ACCESS_DENIED,\n+            event_status=AuditEventStatus.FAILURE,\n             action_performed=f\"{action_prefix}: Token blacklisted.\",\n-            username_or_email=user_id_from_token, # Attempted user from token\n-            ip_address=ip_address, user_agent=user_agent,\n-            details={\"token_prefix\": credentials.credentials[:10]+\"...\", \"reason\": \"Token is blacklisted (logged out).\"},\n-            commit=True\n-        )\n-        raise iOSErrorHelper.token_expired() # This might be better as a generic 401\n-    \n+            username_or_email=user_id_from_token,  # Attempted user from token\n+            ip_address=ip_address,\n+            user_agent=user_agent,\n+            details={\n+                \"token_prefix\": credentials.credentials[:10] + \"...\",\n+                \"reason\": \"Token is blacklisted (logged out).\",\n+            },\n+            commit=True,\n+        )\n+        raise iOSErrorHelper.token_expired()  # This might be better as a generic 401\n+\n     user = db.query(User).filter(User.id == user_id_from_token).first()\n     if user is None:\n         await audit_service.create_audit_log(\n-            event_type=AuditEventType.ACCESS_DENIED, event_status=AuditEventStatus.FAILURE,\n+            event_type=AuditEventType.ACCESS_DENIED,\n+            event_status=AuditEventStatus.FAILURE,\n             action_performed=f\"{action_prefix}: User not found.\",\n-            username_or_email=user_id_from_token, # Attempted user ID from token\n-            ip_address=ip_address, user_agent=user_agent,\n+            username_or_email=user_id_from_token,  # Attempted user ID from token\n+            ip_address=ip_address,\n+            user_agent=user_agent,\n             details={\"reason\": \"User ID from token not found in database.\"},\n-            commit=True\n-        )\n-        raise AuthenticationException(\"User not found\") # This might be better as a generic 401\n-    \n+            commit=True,\n+        )\n+        raise AuthenticationException(\n+            \"User not found\"\n+        )  # This might be better as a generic 401\n+\n     if not user.is_active:\n         await audit_service.create_audit_log(\n-            event_type=AuditEventType.ACCESS_DENIED, event_status=AuditEventStatus.FAILURE,\n+            event_type=AuditEventType.ACCESS_DENIED,\n+            event_status=AuditEventStatus.FAILURE,\n             action_performed=f\"{action_prefix}: Account inactive.\",\n-            user_id=user.id, username_or_email=user.email,\n-            ip_address=ip_address, user_agent=user_agent,\n+            user_id=user.id,\n+            username_or_email=user.email,\n+            ip_address=ip_address,\n+            user_agent=user_agent,\n             details={\"reason\": \"User account is inactive.\"},\n-            commit=True\n-        )\n-        raise AuthenticationException(\"Account is inactive\") # This might be better as a generic 401\n-    \n+            commit=True,\n+        )\n+        raise AuthenticationException(\n+            \"Account is inactive\"\n+        )  # This might be better as a generic 401\n+\n     # If we reach here, access is implicitly granted for this stage.\n     # Explicit ACCESS_GRANTED could be logged in the endpoint itself if needed for specific sensitive operations.\n     return user\n \n+\n async def get_current_user_optional(\n-    request: Request, # Added Request\n+    request: Request,  # Added Request\n     credentials: Optional[HTTPAuthorizationCredentials] = Depends(security),\n     db: Session = Depends(get_db),\n-    redis: RedisClient = Depends(get_redis)\n+    redis: RedisClient = Depends(get_redis),\n ) -> Optional[User]:\n     \"\"\"Get current authenticated user, returns None if not authenticated\"\"\"\n     if not credentials:\n         return None\n-    \n+\n     try:\n-        payload = jwt.decode(credentials.credentials, settings.SECRET_KEY, algorithms=[settings.ALGORITHM])\n+        payload = jwt.decode(\n+            credentials.credentials,\n+            settings.SECRET_KEY,\n+            algorithms=[settings.ALGORITHM],\n+        )\n         user_id: str = payload.get(\"sub\")\n         if user_id is None:\n             return None\n     except JWTError:\n         return None\n-    \n+\n     # Check if token is blacklisted in Redis\n     try:\n         is_blacklisted = await redis.exists(f\"blacklist:{credentials.credentials}\")\n         if is_blacklisted:\n             return None\n     except Exception:\n         # If Redis is unavailable, continue without blacklist check\n         pass\n-    \n+\n     user = db.query(User).filter(User.id == user_id).first()\n     if user is None or not user.is_active:\n         return None\n-    \n+\n     return user\n+\n \n @router.post(\"/login\")\n @limiter.limit(AUTH_RATE)\n async def login(\n-    request: Request, # Added for rate limiter\n+    request: Request,  # Added for rate limiter\n     user_data: UserLogin,\n     db: Session = Depends(get_db),\n-    redis: RedisClient = Depends(get_redis)\n+    redis: RedisClient = Depends(get_redis),\n ):\n     \"\"\"User login with standardized iOS response\"\"\"\n     audit_service = AuditLoggerService(db)\n     ip_address = request.client.host if request.client else \"unknown\"\n     user_agent = request.headers.get(\"user-agent\", \"unknown\")\n \n     user = db.query(User).filter(User.email == user_data.email).first()\n-    \n+\n     if not user or not verify_password(user_data.password, user.password_hash):\n         await audit_service.create_audit_log(\n             event_type=AuditEventType.USER_LOGIN_FAILURE,\n             event_status=AuditEventStatus.FAILURE,\n             action_performed=\"User login attempt failed: Invalid credentials.\",\n             username_or_email=user_data.email,\n             ip_address=ip_address,\n             user_agent=user_agent,\n             details={\"reason\": \"Invalid email or password.\"},\n-            commit=True # Commit immediately as this is a standalone failure event\n+            commit=True,  # Commit immediately as this is a standalone failure event\n         )\n         raise iOSErrorHelper.invalid_credentials()\n-    \n+\n     if not user.is_active:\n         await audit_service.create_audit_log(\n             event_type=AuditEventType.USER_LOGIN_FAILURE,\n             event_status=AuditEventStatus.FAILURE,\n             action_performed=\"User login attempt failed: Account inactive.\",\n             user_id=user.id,\n             username_or_email=user.email,\n             ip_address=ip_address,\n             user_agent=user_agent,\n             details={\"reason\": \"User account is inactive.\"},\n-            commit=True # Commit immediately\n+            commit=True,  # Commit immediately\n         )\n         raise AuthenticationException(\"Account is inactive\")\n-    \n+\n     # Update last login\n     user.last_login = datetime.utcnow()\n     # db.commit() will be called after successful audit logging or by audit_service if commit=True\n \n     # Create access token\n     access_token_expires = timedelta(minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES)\n     access_token = create_access_token(\n         data={\"sub\": str(user.id)}, expires_delta=access_token_expires\n     )\n-    \n+\n     # Store session in Redis\n-    await redis.set_session(str(user.id), {\n-        \"user_id\": str(user.id),\n-        \"email\": user.email,\n-        \"role\": user.role,\n-        \"restaurant_id\": str(user.restaurant_id) if user.restaurant_id else None,\n-        \"platform_id\": str(user.platform_id) if user.platform_id else None,\n-        \"login_time\": datetime.utcnow().isoformat()\n-    })\n-    \n+    await redis.set_session(\n+        str(user.id),\n+        {\n+            \"user_id\": str(user.id),\n+            \"email\": user.email,\n+            \"role\": user.role,\n+            \"restaurant_id\": str(user.restaurant_id) if user.restaurant_id else None,\n+            \"platform_id\": str(user.platform_id) if user.platform_id else None,\n+            \"login_time\": datetime.utcnow().isoformat(),\n+        },\n+    )\n+\n     user_response = {\n         \"id\": str(user.id),\n         \"email\": user.email,\n         \"first_name\": user.first_name,\n         \"last_name\": user.last_name,\n         \"role\": user.role,\n         \"restaurant_id\": str(user.restaurant_id) if user.restaurant_id else None,\n         \"platform_id\": str(user.platform_id) if user.platform_id else None,\n         \"is_active\": user.is_active,\n-        \"last_login\": user.last_login.isoformat() if user.last_login else None\n+        \"last_login\": user.last_login.isoformat() if user.last_login else None,\n     }\n \n     # Log successful login\n     await audit_service.create_audit_log(\n         event_type=AuditEventType.USER_LOGIN_SUCCESS,\n@@ -293,26 +345,26 @@\n         action_performed=\"User logged in successfully.\",\n         user_id=user.id,\n         username_or_email=user.email,\n         ip_address=ip_address,\n         user_agent=user_agent,\n-        commit=False # User last_login update and this log will be committed together\n-    )\n-    db.commit() # Commit user.last_login and audit log\n-    db.refresh(user) # Refresh user to get updated last_login if needed by response\n-    \n+        commit=False,  # User last_login update and this log will be committed together\n+    )\n+    db.commit()  # Commit user.last_login and audit log\n+    db.refresh(user)  # Refresh user to get updated last_login if needed by response\n+\n     return iOSResponseHelper.login_success(\n-        access_token=access_token,\n-        user_data=user_response\n-    )\n+        access_token=access_token, user_data=user_response\n+    )\n+\n \n @router.post(\"/register\")\n @limiter.limit(AUTH_RATE)\n async def register(\n-    request: Request, # Added for rate limiter\n+    request: Request,  # Added for rate limiter\n     user_data: UserRegister,\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"User registration with standardized response\"\"\"\n     audit_service = AuditLoggerService(db)\n     ip_address = request.client.host if request.client else \"unknown\"\n     user_agent = request.headers.get(\"user-agent\", \"unknown\")\n@@ -325,82 +377,90 @@\n             event_status=AuditEventStatus.FAILURE,\n             action_performed=\"User registration failed: Email already registered.\",\n             username_or_email=user_data.email,\n             ip_address=ip_address,\n             user_agent=user_agent,\n-            details={\"reason\": \"Email already registered.\", \"conflicting_field\": \"email\"},\n-            commit=True # Standalone failure event\n+            details={\n+                \"reason\": \"Email already registered.\",\n+                \"conflicting_field\": \"email\",\n+            },\n+            commit=True,  # Standalone failure event\n         )\n         raise ConflictException(\n-            message=\"Email already registered\",\n-            conflicting_field=\"email\"\n-        )\n-    \n+            message=\"Email already registered\", conflicting_field=\"email\"\n+        )\n+\n     # Create new user\n     hashed_password = get_password_hash(user_data.password)\n     new_user = User(\n         email=user_data.email,\n         password_hash=hashed_password,\n         first_name=user_data.first_name,\n         last_name=user_data.last_name,\n         role=user_data.role,\n         restaurant_id=user_data.restaurant_id,\n-        platform_id=user_data.platform_id\n-    )\n-    \n+        platform_id=user_data.platform_id,\n+    )\n+\n     db.add(new_user)\n     # db.commit() will be called after successful audit logging\n \n     await audit_service.create_audit_log(\n         event_type=AuditEventType.USER_REGISTRATION_SUCCESS,\n         event_status=AuditEventStatus.SUCCESS,\n         action_performed=\"User registered successfully.\",\n-        user_id=new_user.id, # Will be available after flush if not committed by audit_service\n+        user_id=new_user.id,  # Will be available after flush if not committed by audit_service\n         username_or_email=new_user.email,\n         ip_address=ip_address,\n         user_agent=user_agent,\n         resource_type=\"User\",\n-        resource_id=str(new_user.id), # Will be available after flush\n-        commit=False # Commit with user creation\n-    )\n-\n-    db.commit() # Commits new_user and audit_log\n+        resource_id=str(new_user.id),  # Will be available after flush\n+        commit=False,  # Commit with user creation\n+    )\n+\n+    db.commit()  # Commits new_user and audit_log\n     db.refresh(new_user)\n-    \n+\n     user_response = {\n         \"id\": str(new_user.id),\n         \"email\": new_user.email,\n         \"first_name\": new_user.first_name,\n         \"last_name\": new_user.last_name,\n         \"role\": new_user.role,\n-        \"restaurant_id\": str(new_user.restaurant_id) if new_user.restaurant_id else None,\n+        \"restaurant_id\": (\n+            str(new_user.restaurant_id) if new_user.restaurant_id else None\n+        ),\n         \"platform_id\": str(new_user.platform_id) if new_user.platform_id else None,\n         \"is_active\": new_user.is_active,\n-        \"created_at\": new_user.created_at.isoformat() if hasattr(new_user, 'created_at') else None\n+        \"created_at\": (\n+            new_user.created_at.isoformat() if hasattr(new_user, \"created_at\") else None\n+        ),\n     }\n-    \n+\n     return APIResponseHelper.created(\n-        data=user_response,\n-        message=\"User registered successfully\"\n-    )\n+        data=user_response, message=\"User registered successfully\"\n+    )\n+\n \n @router.post(\"/logout\")\n async def logout(\n     request: Request,\n     credentials: HTTPAuthorizationCredentials = Depends(security),\n     current_user: User = Depends(get_current_user),\n     redis: RedisClient = Depends(get_redis),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"User logout with standardized response\"\"\"\n     audit_service = AuditLoggerService(db)\n     ip_address = request.client.host if request.client else \"unknown\"\n     user_agent = request.headers.get(\"user-agent\", \"unknown\")\n \n     # Add token to blacklist\n-    await redis.set(f\"blacklist:{credentials.credentials}\", \"1\", expire=86400)  # 24 hours\n-    \n+    await redis.set(\n+        f\"blacklist:{credentials.credentials}\", \"1\", expire=86400\n+    )  # 24 hours\n+\n     # Remove session\n     await redis.delete_session(str(current_user.id))\n \n     await audit_service.create_audit_log(\n         event_type=AuditEventType.USER_LOGOUT,\n@@ -408,11 +468,11 @@\n         action_performed=\"User logged out successfully.\",\n         user_id=current_user.id,\n         username_or_email=current_user.email,\n         ip_address=ip_address,\n         user_agent=user_agent,\n-        commit=True # Standalone action\n+        commit=True,  # Standalone action\n     )\n \n     # Log token blacklisting as a separate event for clarity\n     await audit_service.create_audit_log(\n         event_type=AuditEventType.TOKEN_BLACKLISTED,\n@@ -420,30 +480,38 @@\n         action_performed=\"Access token blacklisted during logout.\",\n         user_id=current_user.id,\n         username_or_email=current_user.email,\n         ip_address=ip_address,\n         user_agent=user_agent,\n-        details={\"token_prefix\": credentials.credentials[:10] + \"...\"}, # Avoid logging full token\n-        commit=True # Standalone action\n-    )\n-    \n+        details={\n+            \"token_prefix\": credentials.credentials[:10] + \"...\"\n+        },  # Avoid logging full token\n+        commit=True,  # Standalone action\n+    )\n+\n     return iOSResponseHelper.logout_success()\n+\n \n @router.get(\"/me\")\n async def get_current_user_info(current_user: User = Depends(get_current_user)):\n     \"\"\"Get current user information with standardized response\"\"\"\n     user_data = {\n         \"id\": str(current_user.id),\n         \"email\": current_user.email,\n         \"first_name\": current_user.first_name,\n         \"last_name\": current_user.last_name,\n         \"role\": current_user.role,\n-        \"restaurant_id\": str(current_user.restaurant_id) if current_user.restaurant_id else None,\n-        \"platform_id\": str(current_user.platform_id) if current_user.platform_id else None,\n+        \"restaurant_id\": (\n+            str(current_user.restaurant_id) if current_user.restaurant_id else None\n+        ),\n+        \"platform_id\": (\n+            str(current_user.platform_id) if current_user.platform_id else None\n+        ),\n         \"is_active\": current_user.is_active,\n-        \"last_login\": current_user.last_login.isoformat() if current_user.last_login else None\n+        \"last_login\": (\n+            current_user.last_login.isoformat() if current_user.last_login else None\n+        ),\n     }\n-    \n+\n     return APIResponseHelper.success(\n-        data=user_data,\n-        message=\"User information retrieved successfully\"\n-    )\n\\ No newline at end of file\n+        data=user_data, message=\"User information retrieved successfully\"\n+    )\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/admin.py\t2025-08-02 21:56:58.983370+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/admin.py\t2025-08-02 22:36:02.626477+00:00\n@@ -7,30 +7,35 @@\n from decimal import Decimal\n from datetime import datetime\n from pydantic import BaseModel\n from sqlalchemy.orm import Session\n from app.services.payment_factory import payment_factory\n-from app.core.exceptions import AuthorizationException, FynloException, ResourceNotFoundException\n+from app.core.exceptions import (\n+    AuthorizationException,\n+    FynloException,\n+    ResourceNotFoundException,\n+)\n from app.services.payment_analytics import PaymentAnalyticsService\n from app.services.smart_routing import RoutingStrategy\n from app.core.database import get_db, User\n-from app.core.auth import get_current_user # get_current_user already has Request\n+from app.core.auth import get_current_user  # get_current_user already has Request\n from app.crud.payments import get_provider_analytics, create_payment_analytics_report\n from app.core.responses import APIResponseHelper\n from app.services.audit_logger import AuditLoggerService\n from app.models.audit_log import AuditEventType, AuditEventStatus\n \n router = APIRouter()\n \n # Define required admin roles (assuming these roles exist or will be created)\n ADMIN_ROLES = [\"admin\", \"platform_owner\"]\n \n+\n @router.get(\"/providers/status\")\n async def get_providers_status(\n     request: Request,\n-    db: Session = Depends(get_db), # Added db for AuditLoggerService\n-    current_user: User = Depends(get_current_user)\n+    db: Session = Depends(get_db),  # Added db for AuditLoggerService\n+    current_user: User = Depends(get_current_user),\n ) -> Dict[str, Any]:\n     \"\"\"Get status of all payment providers\"\"\"\n     audit_service = AuditLoggerService(db)\n     ip_address = request.client.host if request.client else \"unknown\"\n     user_agent = request.headers.get(\"user-agent\", \"unknown\")\n@@ -43,12 +48,15 @@\n             action_performed=action_description,\n             user_id=current_user.id,\n             username_or_email=current_user.email,\n             ip_address=ip_address,\n             user_agent=user_agent,\n-            details={\"required_roles\": ADMIN_ROLES, \"reason\": f\"User role '{current_user.role}' not authorized.\"},\n-            commit=True\n+            details={\n+                \"required_roles\": ADMIN_ROLES,\n+                \"reason\": f\"User role '{current_user.role}' not authorized.\",\n+            },\n+            commit=True,\n         )\n         raise AuthorizationException(message=\"Forbidden: Insufficient privileges.\")\n \n     await audit_service.create_audit_log(\n         event_type=AuditEventType.ACCESS_GRANTED,\n@@ -56,381 +64,443 @@\n         action_performed=action_description,\n         user_id=current_user.id,\n         username_or_email=current_user.email,\n         ip_address=ip_address,\n         user_agent=user_agent,\n-        commit=True\n+        commit=True,\n     )\n     # Proceed with endpoint logic\n     providers = payment_factory.get_available_providers()\n     status = {}\n-    \n+\n     for provider_name in providers:\n         provider = payment_factory.get_provider(provider_name)\n         status[provider_name] = {\n             \"available\": True,\n             \"display_name\": provider_name.title(),\n             \"configuration\": {\n                 \"has_api_key\": bool(\n-                    getattr(provider, 'api_key', None) or \n-                    getattr(provider, 'access_token', None) or\n-                    getattr(provider.config, 'get', lambda x: None)('api_key')\n+                    getattr(provider, \"api_key\", None)\n+                    or getattr(provider, \"access_token\", None)\n+                    or getattr(provider.config, \"get\", lambda x: None)(\"api_key\")\n                 )\n-            }\n+            },\n         }\n-    \n-    return APIResponseHelper.success(\n-        data={\"providers\": status},\n-        message=\"Retrieved provider status\"\n-    )\n+\n+    return APIResponseHelper.success(\n+        data={\"providers\": status}, message=\"Retrieved provider status\"\n+    )\n+\n \n @router.post(\"/providers/test/{provider_name}\")\n async def test_provider(\n     request: Request,\n     provider_name: str,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ) -> Dict[str, Any]:\n     \"\"\"Test a payment provider configuration\"\"\"\n     audit_service = AuditLoggerService(db)\n     ip_address = request.client.host if request.client else \"unknown\"\n     user_agent = request.headers.get(\"user-agent\", \"unknown\")\n     action_description = f\"Test payment provider: {provider_name}\"\n \n     if current_user.role not in ADMIN_ROLES:\n         await audit_service.create_audit_log(\n-            event_type=AuditEventType.ACCESS_DENIED, event_status=AuditEventStatus.FAILURE,\n-            action_performed=action_description, user_id=current_user.id, username_or_email=current_user.email,\n-            ip_address=ip_address, user_agent=user_agent,\n-            details={\"required_roles\": ADMIN_ROLES, \"reason\": f\"User role '{current_user.role}' not authorized.\"}, commit=True\n+            event_type=AuditEventType.ACCESS_DENIED,\n+            event_status=AuditEventStatus.FAILURE,\n+            action_performed=action_description,\n+            user_id=current_user.id,\n+            username_or_email=current_user.email,\n+            ip_address=ip_address,\n+            user_agent=user_agent,\n+            details={\n+                \"required_roles\": ADMIN_ROLES,\n+                \"reason\": f\"User role '{current_user.role}' not authorized.\",\n+            },\n+            commit=True,\n         )\n         raise AuthorizationException(message=\"Forbidden: Insufficient privileges.\")\n \n     await audit_service.create_audit_log(\n-        event_type=AuditEventType.ACCESS_GRANTED, event_status=AuditEventStatus.SUCCESS,\n-        action_performed=action_description, user_id=current_user.id, username_or_email=current_user.email,\n-        ip_address=ip_address, user_agent=user_agent, commit=True\n+        event_type=AuditEventType.ACCESS_GRANTED,\n+        event_status=AuditEventStatus.SUCCESS,\n+        action_performed=action_description,\n+        user_id=current_user.id,\n+        username_or_email=current_user.email,\n+        ip_address=ip_address,\n+        user_agent=user_agent,\n+        commit=True,\n     )\n \n     provider = payment_factory.get_provider(provider_name)\n     if not provider:\n         # Log this attempt to test non-existent provider as a form of admin action failure?\n         # For now, let the HTTP exception suffice.\n         raise ResourceNotFoundException(resource=\"Provider\")\n-    \n+\n     try:\n         # Test with small amount\n         result = await provider.create_checkout(\n             amount=Decimal(\"1.00\"),\n             currency=\"GBP\",\n             return_url=\"https://fynlo.com/test/success\",\n-            cancel_url=\"https://fynlo.com/test/cancel\"\n-        )\n-        \n+            cancel_url=\"https://fynlo.com/test/cancel\",\n+        )\n+\n         return APIResponseHelper.success(\n             data={\n                 \"provider\": provider_name,\n                 \"test_result\": \"Provider configured correctly\",\n-                \"checkout_created\": \"checkout_url\" in result\n-            },\n-            message=f\"{provider_name} test successful\"\n+                \"checkout_created\": \"checkout_url\" in result,\n+            },\n+            message=f\"{provider_name} test successful\",\n         )\n     except Exception as e:\n         return APIResponseHelper.error(\n             message=f\"{provider_name} test failed: {str(e)}\",\n-            error_code=\"PROVIDER_TEST_FAILED\"\n-        )\n+            error_code=\"PROVIDER_TEST_FAILED\",\n+        )\n+\n \n @router.get(\"/providers/analytics\")\n async def get_provider_analytics_endpoint(\n     request: Request,\n     start_date: str,\n     end_date: str,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ) -> Dict[str, Any]:\n     \"\"\"Get payment provider analytics and cost analysis\"\"\"\n     audit_service = AuditLoggerService(db)\n     ip_address = request.client.host if request.client else \"unknown\"\n     user_agent = request.headers.get(\"user-agent\", \"unknown\")\n     action_description = \"Get payment provider analytics\"\n \n     if current_user.role not in ADMIN_ROLES:\n         await audit_service.create_audit_log(\n-            event_type=AuditEventType.ACCESS_DENIED, event_status=AuditEventStatus.FAILURE,\n-            action_performed=action_description, user_id=current_user.id, username_or_email=current_user.email,\n-            ip_address=ip_address, user_agent=user_agent,\n-            details={\"required_roles\": ADMIN_ROLES, \"reason\": f\"User role '{current_user.role}' not authorized.\"}, commit=True\n+            event_type=AuditEventType.ACCESS_DENIED,\n+            event_status=AuditEventStatus.FAILURE,\n+            action_performed=action_description,\n+            user_id=current_user.id,\n+            username_or_email=current_user.email,\n+            ip_address=ip_address,\n+            user_agent=user_agent,\n+            details={\n+                \"required_roles\": ADMIN_ROLES,\n+                \"reason\": f\"User role '{current_user.role}' not authorized.\",\n+            },\n+            commit=True,\n         )\n         raise AuthorizationException(message=\"Forbidden: Insufficient privileges.\")\n \n     await audit_service.create_audit_log(\n-        event_type=AuditEventType.ACCESS_GRANTED, event_status=AuditEventStatus.SUCCESS,\n-        action_performed=action_description, user_id=current_user.id, username_or_email=current_user.email,\n-        ip_address=ip_address, user_agent=user_agent, commit=True\n+        event_type=AuditEventType.ACCESS_GRANTED,\n+        event_status=AuditEventStatus.SUCCESS,\n+        action_performed=action_description,\n+        user_id=current_user.id,\n+        username_or_email=current_user.email,\n+        ip_address=ip_address,\n+        user_agent=user_agent,\n+        commit=True,\n     )\n \n     try:\n         analytics = await get_provider_analytics(start_date, end_date, db)\n-        \n+\n         return APIResponseHelper.success(\n-            data={\n-                \"period\": {\n-                    \"start\": start_date,\n-                    \"end\": end_date\n-                },\n-                **analytics\n-            },\n-            message=\"Retrieved provider analytics\"\n+            data={\"period\": {\"start\": start_date, \"end\": end_date}, **analytics},\n+            message=\"Retrieved provider analytics\",\n         )\n     except Exception as e:\n-        raise FynloException(message=\"Failed to generate 2FA backup codes\", status_code=500)\n+        raise FynloException(\n+            message=\"Failed to generate 2FA backup codes\", status_code=500\n+        )\n+\n \n @router.get(\"/providers/cost-comparison\")\n async def get_cost_comparison(\n     request: Request,\n     amount: float,\n     monthly_volume: float = 5000,\n-    db: Session = Depends(get_db), # Added for audit\n-    current_user: User = Depends(get_current_user)\n+    db: Session = Depends(get_db),  # Added for audit\n+    current_user: User = Depends(get_current_user),\n ) -> Dict[str, Any]:\n     \"\"\"Compare costs across all providers for given amount and volume\"\"\"\n     audit_service = AuditLoggerService(db)\n     ip_address = request.client.host if request.client else \"unknown\"\n     user_agent = request.headers.get(\"user-agent\", \"unknown\")\n     action_description = \"Get provider cost comparison\"\n \n     if current_user.role not in ADMIN_ROLES:\n         await audit_service.create_audit_log(\n-            event_type=AuditEventType.ACCESS_DENIED, event_status=AuditEventStatus.FAILURE,\n-            action_performed=action_description, user_id=current_user.id, username_or_email=current_user.email,\n-            ip_address=ip_address, user_agent=user_agent,\n-            details={\"required_roles\": ADMIN_ROLES, \"reason\": f\"User role '{current_user.role}' not authorized.\"}, commit=True\n+            event_type=AuditEventType.ACCESS_DENIED,\n+            event_status=AuditEventStatus.FAILURE,\n+            action_performed=action_description,\n+            user_id=current_user.id,\n+            username_or_email=current_user.email,\n+            ip_address=ip_address,\n+            user_agent=user_agent,\n+            details={\n+                \"required_roles\": ADMIN_ROLES,\n+                \"reason\": f\"User role '{current_user.role}' not authorized.\",\n+            },\n+            commit=True,\n         )\n         raise AuthorizationException(message=\"Forbidden: Insufficient privileges.\")\n \n     await audit_service.create_audit_log(\n-        event_type=AuditEventType.ACCESS_GRANTED, event_status=AuditEventStatus.SUCCESS,\n-        action_performed=action_description, user_id=current_user.id, username_or_email=current_user.email,\n-        ip_address=ip_address, user_agent=user_agent, commit=True\n+        event_type=AuditEventType.ACCESS_GRANTED,\n+        event_status=AuditEventStatus.SUCCESS,\n+        action_performed=action_description,\n+        user_id=current_user.id,\n+        username_or_email=current_user.email,\n+        ip_address=ip_address,\n+        user_agent=user_agent,\n+        commit=True,\n     )\n \n     amount_decimal = Decimal(str(amount))\n     monthly_volume_decimal = Decimal(str(monthly_volume))\n-    \n+\n     comparison = []\n-    \n+\n     for provider_name in payment_factory.get_available_providers():\n         provider = payment_factory.get_provider(provider_name)\n         fee = provider.calculate_fee(amount_decimal)\n-        \n-        comparison.append({\n-            \"provider\": provider_name,\n-            \"transaction_fee\": float(fee),\n-            \"effective_rate\": float(fee / amount_decimal * 100),\n-            \"monthly_cost\": _calculate_monthly_cost(provider_name, monthly_volume_decimal),\n-            \"annual_savings\": _calculate_annual_savings(\n-                provider_name, \n-                monthly_volume_decimal, \n-                \"stripe\"  # Compare to Stripe as baseline\n-            )\n-        })\n-    \n+\n+        comparison.append(\n+            {\n+                \"provider\": provider_name,\n+                \"transaction_fee\": float(fee),\n+                \"effective_rate\": float(fee / amount_decimal * 100),\n+                \"monthly_cost\": _calculate_monthly_cost(\n+                    provider_name, monthly_volume_decimal\n+                ),\n+                \"annual_savings\": _calculate_annual_savings(\n+                    provider_name,\n+                    monthly_volume_decimal,\n+                    \"stripe\",  # Compare to Stripe as baseline\n+                ),\n+            }\n+        )\n+\n     # Sort by transaction fee\n     comparison.sort(key=lambda x: x[\"transaction_fee\"])\n-    \n+\n     return APIResponseHelper.success(\n         data={\n             \"amount\": amount,\n             \"monthly_volume\": monthly_volume,\n             \"comparison\": comparison,\n-            \"optimal_provider\": comparison[0][\"provider\"] if comparison else None\n+            \"optimal_provider\": comparison[0][\"provider\"] if comparison else None,\n         },\n-        message=\"Generated cost comparison\"\n-    )\n+        message=\"Generated cost comparison\",\n+    )\n+\n \n @router.get(\"/analytics/provider-performance\")\n async def get_provider_performance(\n     request: Request,\n     restaurant_id: Optional[str] = Query(None),\n     start_date: Optional[datetime] = Query(None),\n     end_date: Optional[datetime] = Query(None),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Get comprehensive provider performance analytics\"\"\"\n     audit_service = AuditLoggerService(db)\n     ip_address = request.client.host if request.client else \"unknown\"\n     user_agent = request.headers.get(\"user-agent\", \"unknown\")\n     action_description = \"Get provider performance analytics\"\n \n     if current_user.role not in ADMIN_ROLES:\n         await audit_service.create_audit_log(\n-            event_type=AuditEventType.ACCESS_DENIED, event_status=AuditEventStatus.FAILURE,\n-            action_performed=action_description, user_id=current_user.id, username_or_email=current_user.email,\n-            ip_address=ip_address, user_agent=user_agent,\n-            details={\"required_roles\": ADMIN_ROLES, \"reason\": f\"User role '{current_user.role}' not authorized.\"}, commit=True\n+            event_type=AuditEventType.ACCESS_DENIED,\n+            event_status=AuditEventStatus.FAILURE,\n+            action_performed=action_description,\n+            user_id=current_user.id,\n+            username_or_email=current_user.email,\n+            ip_address=ip_address,\n+            user_agent=user_agent,\n+            details={\n+                \"required_roles\": ADMIN_ROLES,\n+                \"reason\": f\"User role '{current_user.role}' not authorized.\",\n+            },\n+            commit=True,\n         )\n         raise AuthorizationException(message=\"Forbidden: Insufficient privileges.\")\n \n     await audit_service.create_audit_log(\n-        event_type=AuditEventType.ACCESS_GRANTED, event_status=AuditEventStatus.SUCCESS,\n-        action_performed=action_description, user_id=current_user.id, username_or_email=current_user.email,\n-        ip_address=ip_address, user_agent=user_agent, commit=True\n-    )\n-    \n+        event_type=AuditEventType.ACCESS_GRANTED,\n+        event_status=AuditEventStatus.SUCCESS,\n+        action_performed=action_description,\n+        user_id=current_user.id,\n+        username_or_email=current_user.email,\n+        ip_address=ip_address,\n+        user_agent=user_agent,\n+        commit=True,\n+    )\n+\n     analytics_service = PaymentAnalyticsService(db)\n-    \n+\n     performance_data = await analytics_service.get_provider_performance_summary(\n-        restaurant_id=restaurant_id,\n-        start_date=start_date,\n-        end_date=end_date\n-    )\n-    \n+        restaurant_id=restaurant_id, start_date=start_date, end_date=end_date\n+    )\n+\n     return APIResponseHelper.success(\n         data=performance_data,\n-        message=\"Provider performance analytics retrieved successfully\"\n-    )\n+        message=\"Provider performance analytics retrieved successfully\",\n+    )\n+\n \n @router.get(\"/analytics/cost-optimization\")\n async def get_cost_optimization(\n     request: Request,\n     restaurant_id: Optional[str] = Query(None),\n     start_date: Optional[datetime] = Query(None),\n     end_date: Optional[datetime] = Query(None),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Get detailed cost optimization report\"\"\"\n     audit_service = AuditLoggerService(db)\n     ip_address = request.client.host if request.client else \"unknown\"\n     user_agent = request.headers.get(\"user-agent\", \"unknown\")\n     action_description = \"Get cost optimization report\"\n \n     if current_user.role not in ADMIN_ROLES:\n         await audit_service.create_audit_log(\n-            event_type=AuditEventType.ACCESS_DENIED, event_status=AuditEventStatus.FAILURE,\n-            action_performed=action_description, user_id=current_user.id, username_or_email=current_user.email,\n-            ip_address=ip_address, user_agent=user_agent,\n-            details={\"required_roles\": ADMIN_ROLES, \"reason\": f\"User role '{current_user.role}' not authorized.\"}, commit=True\n+            event_type=AuditEventType.ACCESS_DENIED,\n+            event_status=AuditEventStatus.FAILURE,\n+            action_performed=action_description,\n+            user_id=current_user.id,\n+            username_or_email=current_user.email,\n+            ip_address=ip_address,\n+            user_agent=user_agent,\n+            details={\n+                \"required_roles\": ADMIN_ROLES,\n+                \"reason\": f\"User role '{current_user.role}' not authorized.\",\n+            },\n+            commit=True,\n         )\n         raise AuthorizationException(message=\"Forbidden: Insufficient privileges.\")\n \n     await audit_service.create_audit_log(\n-        event_type=AuditEventType.ACCESS_GRANTED, event_status=AuditEventStatus.SUCCESS,\n-        action_performed=action_description, user_id=current_user.id, username_or_email=current_user.email,\n-        ip_address=ip_address, user_agent=user_agent, commit=True\n-    )\n-    \n+        event_type=AuditEventType.ACCESS_GRANTED,\n+        event_status=AuditEventStatus.SUCCESS,\n+        action_performed=action_description,\n+        user_id=current_user.id,\n+        username_or_email=current_user.email,\n+        ip_address=ip_address,\n+        user_agent=user_agent,\n+        commit=True,\n+    )\n+\n     analytics_service = PaymentAnalyticsService(db)\n-    \n+\n     optimization_report = await analytics_service.get_cost_optimization_report(\n-        restaurant_id=restaurant_id,\n-        start_date=start_date,\n-        end_date=end_date\n-    )\n-    \n+        restaurant_id=restaurant_id, start_date=start_date, end_date=end_date\n+    )\n+\n     return APIResponseHelper.success(\n         data=optimization_report,\n-        message=\"Cost optimization report generated successfully\"\n-    )\n+        message=\"Cost optimization report generated successfully\",\n+    )\n+\n \n @router.get(\"/analytics/volume-trends\")\n async def get_volume_trends(\n     restaurant_id: Optional[str] = Query(None),\n     days: int = Query(30, ge=1, le=365),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Get transaction volume trends over time\"\"\"\n-    \n+\n     analytics_service = PaymentAnalyticsService(db)\n-    \n+\n     trends_data = await analytics_service.get_transaction_volume_trends(\n-        restaurant_id=restaurant_id,\n-        days=days\n-    )\n-    \n-    return APIResponseHelper.success(\n-        data=trends_data,\n-        message=\"Volume trends retrieved successfully\"\n-    )\n+        restaurant_id=restaurant_id, days=days\n+    )\n+\n+    return APIResponseHelper.success(\n+        data=trends_data, message=\"Volume trends retrieved successfully\"\n+    )\n+\n \n @router.get(\"/analytics/provider-health\")\n async def get_provider_health(\n     restaurant_id: Optional[str] = Query(None),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Get provider health scores and status\"\"\"\n-    \n+\n     analytics_service = PaymentAnalyticsService(db)\n-    \n+\n     health_scores = await analytics_service.get_provider_health_scores(\n         restaurant_id=restaurant_id\n     )\n-    \n-    return APIResponseHelper.success(\n-        data=health_scores,\n-        message=\"Provider health scores retrieved successfully\"\n-    )\n+\n+    return APIResponseHelper.success(\n+        data=health_scores, message=\"Provider health scores retrieved successfully\"\n+    )\n+\n \n @router.get(\"/routing/recommendations\")\n async def get_routing_recommendations(\n     restaurant_id: str = Query(..., description=\"Restaurant ID\"),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Get smart routing recommendations for a restaurant\"\"\"\n-    \n+\n     recommendations = await payment_factory.get_routing_recommendations(\n-        restaurant_id=restaurant_id,\n-        db_session=db\n-    )\n-    \n-    return APIResponseHelper.success(\n-        data=recommendations,\n-        message=\"Routing recommendations retrieved successfully\"\n-    )\n+        restaurant_id=restaurant_id, db_session=db\n+    )\n+\n+    return APIResponseHelper.success(\n+        data=recommendations, message=\"Routing recommendations retrieved successfully\"\n+    )\n+\n \n @router.post(\"/routing/simulate\")\n async def simulate_routing_strategy(\n     restaurant_id: str,\n     strategy: RoutingStrategy,\n     simulation_days: int = 30,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Simulate the impact of changing routing strategy\"\"\"\n-    \n+\n     simulation_result = await payment_factory.simulate_routing_impact(\n-        restaurant_id=restaurant_id,\n-        strategy=strategy,\n-        db_session=db\n-    )\n-    \n-    return APIResponseHelper.success(\n-        data=simulation_result,\n-        message=\"Routing strategy simulation completed\"\n-    )\n+        restaurant_id=restaurant_id, strategy=strategy, db_session=db\n+    )\n+\n+    return APIResponseHelper.success(\n+        data=simulation_result, message=\"Routing strategy simulation completed\"\n+    )\n+\n \n @router.get(\"/restaurants/{restaurant_id}/analytics\")\n async def get_restaurant_analytics(\n     restaurant_id: str,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ) -> Dict[str, Any]:\n     \"\"\"Get comprehensive payment analytics for a restaurant\"\"\"\n     try:\n         report = await create_payment_analytics_report(restaurant_id, db)\n-        \n+\n         return APIResponseHelper.success(\n-            data=report,\n-            message=\"Generated restaurant payment analytics\"\n+            data=report, message=\"Generated restaurant payment analytics\"\n         )\n     except Exception as e:\n         raise FynloException(message=\"Error processing admin request\", status_code=500)\n+\n \n def _calculate_monthly_cost(provider_name: str, monthly_volume: Decimal) -> float:\n     \"\"\"Calculate total monthly cost for a provider\"\"\"\n     if provider_name == \"sumup\" and monthly_volume >= Decimal(\"2714\"):\n         # 0.69% + \u00a319/month\n@@ -439,32 +509,35 @@\n         # 1.69% for low volume\n         return float(monthly_volume * Decimal(\"0.0169\"))\n     elif provider_name == \"stripe\":\n         # 1.4% + 20p per transaction (assume \u00a350 avg transaction)\n         num_transactions = monthly_volume / Decimal(\"50\")\n-        return float((monthly_volume * Decimal(\"0.014\")) + (num_transactions * Decimal(\"0.20\")))\n+        return float(\n+            (monthly_volume * Decimal(\"0.014\")) + (num_transactions * Decimal(\"0.20\"))\n+        )\n     elif provider_name == \"square\":\n         # 1.75%\n         return float(monthly_volume * Decimal(\"0.0175\"))\n     return 0.0\n \n+\n def _calculate_annual_savings(\n-    provider_name: str, \n-    monthly_volume: Decimal,\n-    baseline_provider: str\n+    provider_name: str, monthly_volume: Decimal, baseline_provider: str\n ) -> float:\n     \"\"\"Calculate annual savings compared to baseline provider\"\"\"\n     provider_cost = _calculate_monthly_cost(provider_name, monthly_volume)\n     baseline_cost = _calculate_monthly_cost(baseline_provider, monthly_volume)\n     monthly_savings = baseline_cost - provider_cost\n     return float(monthly_savings * 12)\n \n+\n class ProviderStatusUpdate(BaseModel):\n     provider: str\n     enabled: bool\n     maintenance_mode: Optional[bool] = False\n     reason: Optional[str] = None\n \n+\n class RoutingStrategyUpdate(BaseModel):\n     restaurant_id: str\n     strategy: RoutingStrategy\n-    auto_switch: bool = True\n\\ No newline at end of file\n+    auto_switch: bool = True\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/fees.py\t2025-08-02 21:56:58.985184+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/fees.py\t2025-08-02 22:36:02.629038+00:00\n@@ -1,45 +1,66 @@\n from fastapi import APIRouter, Depends, Body\n from sqlalchemy.orm import Session\n from typing import Dict, Any, Optional\n \n from app.core.database import get_db\n-from app.core.exceptions import FynloException, ResourceNotFoundException, ValidationException\n+from app.core.exceptions import (\n+    FynloException,\n+    ResourceNotFoundException,\n+    ValidationException,\n+)\n from app.schemas.fee_schemas import (\n     PaymentMethodEnum,\n     CustomerTotalBreakdown,\n-    ServiceChargeBreakdown, # For potential separate return or internal use\n-    PlatformFeeRecordSchema # For response model\n+    ServiceChargeBreakdown,  # For potential separate return or internal use\n+    PlatformFeeRecordSchema,  # For response model\n )\n from app.services.platform_service import PlatformSettingsService\n from app.services.payment_fee_calculator import PaymentFeeCalculator\n from app.services.platform_fee_service import PlatformFeeService\n from app.services.service_charge_calculator import ServiceChargeCalculator\n from app.services.payment_config_service import PaymentConfigService\n-from app.services.financial_records_service import FinancialRecordsService # New service\n+from app.services.financial_records_service import (\n+    FinancialRecordsService,\n+)  # New service\n from pydantic import BaseModel, Field\n \n router = APIRouter()\n+\n \n # --- Request Models ---\n class FeeCalculationRequest(BaseModel):\n-    subtotal: float = Field(..., gt=0, description=\"Order subtotal before VAT and any service charges or fees.\")\n+    subtotal: float = Field(\n+        ...,\n+        gt=0,\n+        description=\"Order subtotal before VAT and any service charges or fees.\",\n+    )\n     vat_amount: float = Field(..., ge=0, description=\"Total VAT amount for the order.\")\n \n     # If service charge is applied, its configured rate (e.g., 0.1 for 10%)\n     # This rate is determined by the client based on restaurant/platform settings for service charge.\n-    service_charge_config_rate: Optional[float] = Field(None, ge=0, le=1, description=\"Configured service charge rate, e.g., 0.1 for 10%. Null if no SC.\")\n+    service_charge_config_rate: Optional[float] = Field(\n+        None,\n+        ge=0,\n+        le=1,\n+        description=\"Configured service charge rate, e.g., 0.1 for 10%. Null if no SC.\",\n+    )\n \n     payment_method: PaymentMethodEnum\n-    restaurant_id: Optional[str] = Field(None, description=\"ID of the restaurant, if applicable.\")\n+    restaurant_id: Optional[str] = Field(\n+        None, description=\"ID of the restaurant, if applicable.\"\n+    )\n \n     # Optional: For payment providers like SumUp that might have volume-based pricing\n-    monthly_volume_for_restaurant: Optional[float] = Field(None, description=\"Estimated monthly transaction volume for the restaurant.\")\n+    monthly_volume_for_restaurant: Optional[float] = Field(\n+        None, description=\"Estimated monthly transaction volume for the restaurant.\"\n+    )\n \n     # Optional: Client can specify if they want to override the default customer_pays_processor_fees setting.\n     # This would only be allowed if `allow_toggle_by_merchant` is true for the payment method.\n     force_customer_pays_processor_fees: Optional[bool] = None\n+\n \n class PlatformFeeRecordInput(BaseModel):\n     order_id: str = Field(..., description=\"Client-generated or Odoo order reference.\")\n     platform_fee_amount: float\n     processor_fee_amount: float\n@@ -50,116 +71,147 @@\n \n # --- Dependency Injection for Services ---\n # These would typically be more sophisticated in a full app, e.g., using a DI container\n # or FastAPI's Depends with classes. For now, direct instantiation in endpoint.\n \n-def get_platform_settings_service(db: Session = Depends(get_db)) -> PlatformSettingsService:\n+\n+def get_platform_settings_service(\n+    db: Session = Depends(get_db),\n+) -> PlatformSettingsService:\n     \"\"\"Execute get_platform_settings_service operation.\"\"\"\n     return PlatformSettingsService(db=db)\n+\n \n def get_payment_config_service(db: Session = Depends(get_db)) -> PaymentConfigService:\n     \"\"\"Execute get_payment_config_service operation.\"\"\"\n     return PaymentConfigService(db=db)\n \n+\n def get_payment_fee_calculator(\n-    pss: PlatformSettingsService = Depends(get_platform_settings_service)\n+    pss: PlatformSettingsService = Depends(get_platform_settings_service),\n ) -> PaymentFeeCalculator:\n     return PaymentFeeCalculator(platform_settings_service=pss)\n \n+\n def get_service_charge_calculator(\n     pss: PlatformSettingsService = Depends(get_platform_settings_service),\n-    pfc: PaymentFeeCalculator = Depends(get_payment_fee_calculator)\n+    pfc: PaymentFeeCalculator = Depends(get_payment_fee_calculator),\n ) -> ServiceChargeCalculator:\n-    return ServiceChargeCalculator(payment_fee_calculator=pfc, platform_settings_service=pss)\n+    return ServiceChargeCalculator(\n+        payment_fee_calculator=pfc, platform_settings_service=pss\n+    )\n+\n \n def get_platform_fee_service(\n     pss: PlatformSettingsService = Depends(get_platform_settings_service),\n-    pfc: PaymentFeeCalculator = Depends(get_payment_fee_calculator)\n+    pfc: PaymentFeeCalculator = Depends(get_payment_fee_calculator),\n ) -> PlatformFeeService:\n     return PlatformFeeService(payment_fee_calculator=pfc, platform_settings_service=pss)\n \n-def get_financial_records_service(db: Session = Depends(get_db)) -> FinancialRecordsService:\n+\n+def get_financial_records_service(\n+    db: Session = Depends(get_db),\n+) -> FinancialRecordsService:\n     \"\"\"Execute get_financial_records_service operation.\"\"\"\n     return FinancialRecordsService(db=db)\n \n \n @router.post(\"/calculate-fees\", response_model=CustomerTotalBreakdown)\n async def calculate_fees_for_order(\n     request: FeeCalculationRequest,\n-    db: Session = Depends(get_db), # get_db for direct session if needed by services not using DI functions above\n+    db: Session = Depends(\n+        get_db\n+    ),  # get_db for direct session if needed by services not using DI functions above\n     payment_config_service: PaymentConfigService = Depends(get_payment_config_service),\n-    service_charge_calc: ServiceChargeCalculator = Depends(get_service_charge_calculator),\n-    platform_fee_service: PlatformFeeService = Depends(get_platform_fee_service)\n+    service_charge_calc: ServiceChargeCalculator = Depends(\n+        get_service_charge_calculator\n+    ),\n+    platform_fee_service: PlatformFeeService = Depends(get_platform_fee_service),\n ):\n     \"\"\"\n     Calculates the detailed fee breakdown for a given order's subtotal and payment method.\n     This endpoint determines processor fees, platform fees, and service charges.\n     \"\"\"\n \n     # 1. Determine fee payment rules (who pays processor fee, is it part of SC)\n     payment_method_setting = payment_config_service.get_payment_method_setting(\n-        payment_method=request.payment_method,\n-        restaurant_id=request.restaurant_id\n+        payment_method=request.payment_method, restaurant_id=request.restaurant_id\n     )\n \n     if not payment_method_setting:\n         # This should ideally not happen if defaults are seeded for all PaymentMethodEnums\n-        raise ResourceNotFoundException(resource=\"Resource\", message=f\"Fee configuration not found for payment method {request.payment_method.value} for restaurant {request.restaurant_id or 'unknown'}\")\n+        raise ResourceNotFoundException(\n+            resource=\"Resource\",\n+            message=f\"Fee configuration not found for payment method {request.payment_method.value} for restaurant {request.restaurant_id or 'unknown'}\",\n+        )\n \n     # Determine who pays processor fees\n     customer_pays_processor_fees = payment_method_setting.customer_pays_default\n     if request.force_customer_pays_processor_fees is not None:\n         if payment_method_setting.allow_toggle_by_merchant:\n             customer_pays_processor_fees = request.force_customer_pays_processor_fees\n         else:\n             # Client tried to override but not allowed\n-            raise ValidationException(message=f\"Toggling who pays processor fee is not allowed for payment method {request.payment_method.value}.\")\n-\n-    include_processor_fee_in_sc = payment_method_setting.include_processor_fee_in_service_charge\n+            raise ValidationException(\n+                message=f\"Toggling who pays processor fee is not allowed for payment method {request.payment_method.value}.\"\n+            )\n+\n+    include_processor_fee_in_sc = (\n+        payment_method_setting.include_processor_fee_in_service_charge\n+    )\n \n     # 2. Calculate final Service Charge\n     final_service_charge_amount = 0.0\n     service_charge_breakdown_details: Optional[ServiceChargeBreakdown] = None\n \n-    if request.service_charge_config_rate is not None and request.service_charge_config_rate > 0:\n+    if (\n+        request.service_charge_config_rate is not None\n+        and request.service_charge_config_rate > 0\n+    ):\n         try:\n             service_charge_breakdown_details = await service_charge_calc.calculate_service_charge_with_fees(\n                 order_subtotal=request.subtotal,\n                 service_charge_config_rate=request.service_charge_config_rate,\n                 payment_method=request.payment_method,\n-                customer_pays_processor_fees=customer_pays_processor_fees, # Crucial: SC structure depends on this\n+                customer_pays_processor_fees=customer_pays_processor_fees,  # Crucial: SC structure depends on this\n                 include_processor_fee_in_service_charge=include_processor_fee_in_sc,\n                 restaurant_id=request.restaurant_id,\n-                monthly_volume_for_restaurant=request.monthly_volume_for_restaurant\n+                monthly_volume_for_restaurant=request.monthly_volume_for_restaurant,\n             )\n-            final_service_charge_amount = service_charge_breakdown_details['final_service_charge_amount']\n+            final_service_charge_amount = service_charge_breakdown_details[\n+                \"final_service_charge_amount\"\n+            ]\n         except Exception as e:\n             # Log the exception details\n             # logger.error(f\"Error in ServiceChargeCalculator: {e}\", exc_info=True)\n-            raise FynloException(message=\"An error occurred processing the request\", status_code=500)\n-\n+            raise FynloException(\n+                message=\"An error occurred processing the request\", status_code=500\n+            )\n \n     # 3. Calculate final Customer Total Breakdown using PlatformFeeService\n     try:\n         customer_total_breakdown = await platform_fee_service.calculate_customer_total(\n             subtotal=request.subtotal,\n             vat_amount=request.vat_amount,\n             service_charge_final_amount=final_service_charge_amount,\n             payment_method=request.payment_method,\n-            customer_pays_processor_fees=customer_pays_processor_fees, # This is the effective decision\n+            customer_pays_processor_fees=customer_pays_processor_fees,  # This is the effective decision\n             restaurant_id=request.restaurant_id,\n-            monthly_volume_for_restaurant=request.monthly_volume_for_restaurant\n+            monthly_volume_for_restaurant=request.monthly_volume_for_restaurant,\n         )\n         # Could augment with more details if needed\n         # customer_total_breakdown['service_charge_details'] = service_charge_breakdown_details\n         return customer_total_breakdown\n \n-    except ValueError as ve: # From underlying services if config is missing etc.\n+    except ValueError as ve:  # From underlying services if config is missing etc.\n         raise ValidationException(message=\"An error occurred processing the request\")\n     except Exception as e:\n         # logger.error(f\"Error in PlatformFeeService's calculate_customer_total: {e}\", exc_info=True)\n-        raise FynloException(message=\"An error occurred processing the request\", status_code=500)\n+        raise FynloException(\n+            message=\"An error occurred processing the request\", status_code=500\n+        )\n+\n \n # To include this router in the main application:\n # In backend/app/api/v1/api.py (or equivalent main router aggregation file):\n # from .endpoints import fees\n # api_router.include_router(fees.router, prefix=\"/fees\", tags=[\"Fees & Calculations\"])\n@@ -170,14 +222,18 @@\n #\n # And schemas in backend/app/schemas/__init__.py\n # e.g. from .fee_schemas import *\n \n \n-@router.post(\"/platform-fees/record\", response_model=PlatformFeeRecordSchema, status_code=201)\n+@router.post(\n+    \"/platform-fees/record\", response_model=PlatformFeeRecordSchema, status_code=201\n+)\n async def record_platform_fee(\n-    fee_data_input: PlatformFeeRecordInput, # Using the Pydantic model for input\n-    financial_records_service: FinancialRecordsService = Depends(get_financial_records_service)\n+    fee_data_input: PlatformFeeRecordInput,  # Using the Pydantic model for input\n+    financial_records_service: FinancialRecordsService = Depends(\n+        get_financial_records_service\n+    ),\n ):\n     \"\"\"\n     Records a platform fee transaction.\n     The fee calculation should have been done prior to calling this.\n     \"\"\"\n@@ -194,24 +250,30 @@\n             customer_paid_processor=fee_data_input.customer_paid_processor,\n             payment_method=fee_data_input.payment_method,\n             # transaction_timestamp is not in input, will be set by server_default or None\n         )\n \n-        db_record = financial_records_service.create_platform_fee_record(fee_data_schema)\n+        db_record = financial_records_service.create_platform_fee_record(\n+            fee_data_schema\n+        )\n \n         # Convert SQLAlchemy model back to Pydantic schema for response\n         # (FastAPI does this automatically if response_model is a Pydantic model and ORM mode is enabled)\n         # To be absolutely explicit or if ORM mode isn't perfect:\n         return PlatformFeeRecordSchema(\n             id=db_record.id,\n             order_id=db_record.order_reference,\n             platform_fee_amount=float(db_record.platform_fee_amount),\n             processor_fee_amount=float(db_record.processor_fee_amount),\n             customer_paid_processor=db_record.customer_paid_processor_fee,\n-            payment_method=PaymentMethodEnum(db_record.payment_method), # Ensure enum conversion\n-            transaction_timestamp=db_record.transaction_timestamp.isoformat()\n-        )\n-    except ValueError as ve: # Catch specific errors if service raises them\n+            payment_method=PaymentMethodEnum(\n+                db_record.payment_method\n+            ),  # Ensure enum conversion\n+            transaction_timestamp=db_record.transaction_timestamp.isoformat(),\n+        )\n+    except ValueError as ve:  # Catch specific errors if service raises them\n         raise ValidationException(message=\"An error occurred processing the request\")\n     except Exception as e:\n         # logger.error(f\"Error recording platform fee for order {fee_data_input.order_id}: {e}\", exc_info=True)\n-        raise FynloException(message=\"An error occurred processing the request\", status_code=500)\n+        raise FynloException(\n+            message=\"An error occurred processing the request\", status_code=500\n+        )\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/mobile/endpoints.py\t2025-08-02 19:23:36.804508+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/mobile/endpoints.py\t2025-08-02 22:36:02.630147+00:00\n@@ -16,425 +16,446 @@\n from app.core.mobile_id_mapping import get_mobile_id_service\n from app.core.redis_client import get_redis, RedisClient\n \n router = APIRouter()\n \n+\n # Mobile-optimized response models\n class MobileProductResponse(BaseModel):\n     \"\"\"Lightweight product response for mobile\"\"\"\n+\n     id: int  # Mobile-friendly integer ID\n     uuid_id: str  # Original UUID for reference\n     name: str\n     price: float\n     image_url: Optional[str] = None\n     category_id: int  # Mobile-friendly integer ID\n     category_uuid_id: str  # Original category UUID\n     is_available: bool = True\n     prep_time: int = 0\n \n+\n class MobileCategoryResponse(BaseModel):\n     \"\"\"Lightweight category response for mobile\"\"\"\n+\n     id: int  # Mobile-friendly integer ID\n     uuid_id: str  # Original UUID for reference\n     name: str\n     color: str = \"#00A651\"\n     icon: Optional[str] = None\n     product_count: int = 0\n \n+\n class MobileMenuResponse(BaseModel):\n     \"\"\"Mobile-optimized complete menu\"\"\"\n+\n     categories: List[MobileCategoryResponse]\n     products: List[MobileProductResponse]\n     restaurant_info: Dict[str, Any]\n     last_updated: str\n \n+\n class MobileOrderSummary(BaseModel):\n     \"\"\"Lightweight order summary for mobile\"\"\"\n+\n     id: str\n     order_number: str\n     status: str\n     total: float\n     items_count: int\n     table_number: Optional[str] = None\n     created_at: str\n \n+\n # Odoo-style Authentication Endpoint\n @router.post(\"/web/session/authenticate\")\n-async def odoo_style_authenticate(\n-    request: Request,\n-    db: Session = Depends(get_db)\n-):\n+async def odoo_style_authenticate(request: Request, db: Session = Depends(get_db)):\n     \"\"\"\n     Odoo-compatible authentication endpoint\n     Expected by iOS app for backwards compatibility\n     \"\"\"\n     try:\n         # Parse request body\n         body = await request.body()\n         data = json.loads(body) if body else {}\n-        \n+\n         params = data.get(\"params\", {})\n         login = params.get(\"login\")\n         password = params.get(\"password\")\n-        \n+\n         if not login or not password:\n             raise FynloException(\n                 message=\"Login and password are required\",\n                 error_code=ErrorCodes.VALIDATION_ERROR,\n-                status_code=400\n-            )\n-        \n+                status_code=400,\n+            )\n+\n         # Since we're using Supabase auth, we need to authenticate through Supabase\n         # For backwards compatibility with mobile app expecting username/password auth,\n         # we'll need to handle this differently. For now, return an error message\n         # indicating that Supabase authentication should be used\n         raise FynloException(\n             message=\"Please use Supabase authentication. Legacy username/password authentication is not supported.\",\n             error_code=ErrorCodes.AUTHENTICATION_ERROR,\n-            status_code=401\n-        )\n-        \n-        \n+            status_code=401,\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Authentication failed: {str(e)}\",\n             error_code=ErrorCodes.AUTHENTICATION_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n # Mobile-optimized menu endpoint\n @router.get(\"/api/v1/products/mobile\")\n async def get_mobile_menu(\n     restaurant_id: Optional[str] = Query(None),\n     include_unavailable: bool = Query(False),\n     db: Session = Depends(get_db),\n     current_user: User = Depends(get_current_user),\n-    redis: RedisClient = Depends(get_redis)\n+    redis: RedisClient = Depends(get_redis),\n ):\n     \"\"\"\n     Mobile-optimized menu endpoint with reduced payload\n     \"\"\"\n     try:\n         # Use user's restaurant if not specified\n         if not restaurant_id:\n             restaurant_id = str(current_user.restaurant_id)\n-        \n+\n         # Get restaurant info\n         restaurant = db.query(Restaurant).filter(Restaurant.id == restaurant_id).first()\n         if not restaurant:\n             raise FynloException(\n                 message=\"Restaurant not found\",\n                 error_code=ErrorCodes.NOT_FOUND,\n-                status_code=404\n-            )\n-        \n+                status_code=404,\n+            )\n+\n         # Get categories with product counts\n-        categories = db.query(Category).filter(\n-            Category.restaurant_id == restaurant_id,\n-            Category.is_active == True\n-        ).all()\n-        \n+        categories = (\n+            db.query(Category)\n+            .filter(Category.restaurant_id == restaurant_id, Category.is_active == True)\n+            .all()\n+        )\n+\n         # Get products\n         products_query = db.query(Product).filter(\n-            Product.restaurant_id == restaurant_id,\n-            Product.is_active == True\n-        )\n-        \n+            Product.restaurant_id == restaurant_id, Product.is_active == True\n+        )\n+\n         if not include_unavailable:\n             # Only include available products\n             products_query = products_query.filter(Product.is_active == True)\n-        \n+\n         products = products_query.all()\n-        \n+\n         # Initialize mobile ID service\n         mobile_id_service = get_mobile_id_service(db, redis)\n-        \n+\n         # Get mobile IDs for all categories and products\n         category_uuids = [str(cat.id) for cat in categories]\n         product_uuids = [str(prod.id) for prod in products]\n-        \n-        category_mobile_ids = mobile_id_service.get_batch_mappings(category_uuids, \"category\")\n-        product_mobile_ids = mobile_id_service.get_batch_mappings(product_uuids, \"product\")\n-        \n+\n+        category_mobile_ids = mobile_id_service.get_batch_mappings(\n+            category_uuids, \"category\"\n+        )\n+        product_mobile_ids = mobile_id_service.get_batch_mappings(\n+            product_uuids, \"product\"\n+        )\n+\n         # Count products per category\n         category_product_counts = {}\n         for product in products:\n             cat_id = str(product.category_id)\n             category_product_counts[cat_id] = category_product_counts.get(cat_id, 0) + 1\n-        \n+\n         # Build mobile-optimized response with safe integer IDs\n         mobile_categories = [\n             MobileCategoryResponse(\n                 id=category_mobile_ids[str(cat.id)],\n                 uuid_id=str(cat.id),\n                 name=cat.name,\n                 color=cat.color,\n                 icon=cat.icon,\n-                product_count=category_product_counts.get(str(cat.id), 0)\n+                product_count=category_product_counts.get(str(cat.id), 0),\n             )\n             for cat in categories\n         ]\n-        \n+\n         mobile_products = [\n             MobileProductResponse(\n                 id=product_mobile_ids[str(prod.id)],\n                 uuid_id=str(prod.id),\n                 name=prod.name,\n                 price=float(prod.price),\n                 image_url=prod.image_url,\n                 category_id=category_mobile_ids[str(prod.category_id)],\n                 category_uuid_id=str(prod.category_id),\n-                is_available=prod.is_active and (\n-                    not prod.stock_tracking or prod.stock_quantity > 0\n-                ),\n-                prep_time=prod.prep_time or 0\n+                is_available=prod.is_active\n+                and (not prod.stock_tracking or prod.stock_quantity > 0),\n+                prep_time=prod.prep_time or 0,\n             )\n             for prod in products\n         ]\n-        \n+\n         restaurant_info = {\n             \"id\": str(restaurant.id),\n             \"name\": restaurant.name,\n-            \"logo_url\": restaurant.settings.get(\"logo_url\") if restaurant.settings else None,\n+            \"logo_url\": (\n+                restaurant.settings.get(\"logo_url\") if restaurant.settings else None\n+            ),\n             \"business_hours\": restaurant.business_hours,\n-            \"timezone\": restaurant.timezone\n+            \"timezone\": restaurant.timezone,\n         }\n-        \n+\n         menu_response = MobileMenuResponse(\n             categories=mobile_categories,\n             products=mobile_products,\n             restaurant_info=restaurant_info,\n-            last_updated=max(\n-                prod.updated_at or prod.created_at for prod in products\n-            ).isoformat() if products else restaurant.updated_at.isoformat()\n-        )\n-        \n+            last_updated=(\n+                max(prod.updated_at or prod.created_at for prod in products).isoformat()\n+                if products\n+                else restaurant.updated_at.isoformat()\n+            ),\n+        )\n+\n         return APIResponseHelper.success(\n             data=menu_response.dict(),\n             message=f\"Mobile menu retrieved with {len(mobile_products)} products\",\n             meta={\n                 \"categories_count\": len(mobile_categories),\n                 \"products_count\": len(mobile_products),\n                 \"restaurant_id\": restaurant_id,\n-                \"optimized_for\": \"mobile\"\n-            }\n-        )\n-        \n+                \"optimized_for\": \"mobile\",\n+            },\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to retrieve mobile menu: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n # Daily sales report endpoint (Odoo-style)\n @router.get(\"/pos/reports/daily_sales\")\n async def get_daily_sales_report(\n     date: Optional[str] = Query(None, description=\"Date in YYYY-MM-DD format\"),\n     restaurant_id: Optional[str] = Query(None),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"\n     Daily sales report endpoint (Odoo-compatible)\n     \"\"\"\n     try:\n         from datetime import datetime, timedelta\n         from sqlalchemy import and_\n-        \n+\n         # Use user's restaurant if not specified\n         if not restaurant_id:\n             restaurant_id = str(current_user.restaurant_id)\n-        \n+\n         # Parse date or use today\n         if date:\n             report_date = datetime.strptime(date, \"%Y-%m-%d\").date()\n         else:\n             report_date = datetime.now().date()\n-        \n+\n         # Date range for the day\n         start_date = datetime.combine(report_date, datetime.min.time())\n         end_date = start_date + timedelta(days=1)\n-        \n+\n         # Get orders for the day\n-        orders = db.query(Order).filter(\n-            and_(\n-                Order.restaurant_id == restaurant_id,\n-                Order.created_at >= start_date,\n-                Order.created_at < end_date,\n-                Order.status == \"completed\"\n-            )\n-        ).all()\n-        \n+        orders = (\n+            db.query(Order)\n+            .filter(\n+                and_(\n+                    Order.restaurant_id == restaurant_id,\n+                    Order.created_at >= start_date,\n+                    Order.created_at < end_date,\n+                    Order.status == \"completed\",\n+                )\n+            )\n+            .all()\n+        )\n+\n         # Calculate metrics\n         total_sales = sum(order.total_amount for order in orders)\n         total_orders = len(orders)\n         average_order_value = total_sales / total_orders if total_orders > 0 else 0\n-        \n+\n         # Payment method breakdown\n         payment_methods = {}\n         for order in orders:\n             # Simplified - in real implementation, would join with payments table\n             method = \"qr_code\"  # Default\n-            payment_methods[method] = payment_methods.get(method, 0) + order.total_amount\n-        \n+            payment_methods[method] = (\n+                payment_methods.get(method, 0) + order.total_amount\n+            )\n+\n         # Top selling items\n         item_sales = {}\n         for order in orders:\n             for item in order.items:\n                 product_name = item.get(\"product_name\", \"Unknown\")\n                 quantity = item.get(\"quantity\", 0)\n                 item_sales[product_name] = item_sales.get(product_name, 0) + quantity\n-        \n+\n         top_items = sorted(item_sales.items(), key=lambda x: x[1], reverse=True)[:5]\n-        \n+\n         report_data = {\n             \"date\": report_date.isoformat(),\n             \"restaurant_id\": restaurant_id,\n             \"summary\": {\n                 \"total_sales\": round(total_sales, 2),\n                 \"total_orders\": total_orders,\n                 \"average_order_value\": round(average_order_value, 2),\n-                \"currency\": \"GBP\"\n+                \"currency\": \"GBP\",\n             },\n             \"payment_methods\": {\n-                method: round(amount, 2) \n-                for method, amount in payment_methods.items()\n+                method: round(amount, 2) for method, amount in payment_methods.items()\n             },\n             \"top_selling_items\": [\n-                {\"name\": name, \"quantity\": qty} \n-                for name, qty in top_items\n+                {\"name\": name, \"quantity\": qty} for name, qty in top_items\n             ],\n             \"hourly_breakdown\": [],  # Could be implemented for detailed analysis\n-            \"generated_at\": datetime.now().isoformat()\n+            \"generated_at\": datetime.now().isoformat(),\n         }\n-        \n+\n         return APIResponseHelper.success(\n             data=report_data,\n             message=f\"Daily sales report for {report_date}\",\n-            meta={\"report_type\": \"daily_sales\", \"format\": \"mobile_optimized\"}\n-        )\n-        \n+            meta={\"report_type\": \"daily_sales\", \"format\": \"mobile_optimized\"},\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to generate daily sales report: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n # Mobile orders endpoint\n @router.get(\"/api/v1/orders/mobile\")\n async def get_mobile_orders(\n     status: Optional[str] = Query(None),\n     limit: int = Query(20, le=50),\n     restaurant_id: Optional[str] = Query(None),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"\n     Mobile-optimized orders endpoint with lightweight responses\n     \"\"\"\n     try:\n         # Use user's restaurant if not specified\n         if not restaurant_id:\n             restaurant_id = str(current_user.restaurant_id)\n-        \n+\n         # Build query\n         query = db.query(Order).filter(Order.restaurant_id == restaurant_id)\n-        \n+\n         if status:\n             query = query.filter(Order.status == status)\n-        \n+\n         # Get recent orders\n         orders = query.order_by(Order.created_at.desc()).limit(limit).all()\n-        \n+\n         # Build mobile response\n         mobile_orders = [\n             MobileOrderSummary(\n                 id=str(order.id),\n                 order_number=order.order_number,\n                 status=order.status,\n                 total=float(order.total_amount),\n                 items_count=len(order.items),\n                 table_number=order.table_number,\n-                created_at=order.created_at.isoformat()\n+                created_at=order.created_at.isoformat(),\n             )\n             for order in orders\n         ]\n-        \n+\n         return APIResponseHelper.success(\n             data=mobile_orders,\n             message=f\"Retrieved {len(mobile_orders)} orders\",\n             meta={\n                 \"total_count\": len(mobile_orders),\n                 \"status_filter\": status,\n                 \"limit\": limit,\n-                \"optimized_for\": \"mobile\"\n-            }\n-        )\n-        \n+                \"optimized_for\": \"mobile\",\n+            },\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to retrieve mobile orders: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n # Base URL configuration endpoint\n @router.get(\"/api/config/base_url\")\n async def get_base_url_config():\n     \"\"\"\n     Configuration endpoint for mobile app base URL setup\n     Supports both port 8000 and 8069 for compatibility\n     \"\"\"\n     try:\n         from app.core.config import settings\n-        \n+\n         # Get the actual host from request or settings\n-        base_url = getattr(settings, 'BASE_URL', 'https://fynlopos-9eg2c.ondigitalocean.app')\n-        ws_protocol = 'wss' if base_url.startswith('https') else 'ws'\n-        \n+        base_url = getattr(\n+            settings, \"BASE_URL\", \"https://fynlopos-9eg2c.ondigitalocean.app\"\n+        )\n+        ws_protocol = \"wss\" if base_url.startswith(\"https\") else \"ws\"\n+\n         config_data = {\n             \"api_base_url\": base_url,  # Use production URL from settings\n             \"odoo_compatible_url\": base_url,  # Legacy compatibility - consider removal\n             \"websocket_url\": f\"{ws_protocol}://{base_url.replace('https://', '').replace('http://', '')}/ws\",\n             \"supported_versions\": [\"v1\"],\n             \"mobile_optimized\": True,\n             \"features\": {\n                 \"file_upload\": True,\n                 \"real_time\": True,\n                 \"offline_sync\": True,\n-                \"push_notifications\": True\n-            }\n+                \"push_notifications\": True,\n+            },\n         }\n-        \n+\n         return APIResponseHelper.success(\n             data=config_data,\n             message=\"Mobile configuration retrieved\",\n-            meta={\"environment\": \"development\"}  # Would be dynamic\n-        )\n-        \n+            meta={\"environment\": \"development\"},  # Would be dynamic\n+        )\n+\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to retrieve configuration: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n # Feature flags endpoint for mobile\n @router.get(\"/api/features\")\n-async def get_feature_flags(\n-    current_user: User = Depends(get_current_user)\n-):\n+async def get_feature_flags(current_user: User = Depends(get_current_user)):\n     \"\"\"\n     Feature flags endpoint for mobile app feature toggles\n     \"\"\"\n     try:\n         # Feature flags based on user role and restaurant settings\n@@ -442,73 +463,74 @@\n             \"new_ui\": True,\n             \"qr_payments\": True,\n             \"offline_mode\": True,\n             \"real_time_updates\": True,\n             \"multi_restaurant\": current_user.role == \"platform_owner\",\n-            \"advanced_analytics\": current_user.role in [\"platform_owner\", \"restaurant_owner\"],\n+            \"advanced_analytics\": current_user.role\n+            in [\"platform_owner\", \"restaurant_owner\"],\n             \"hardware_integration\": True,\n             \"table_management\": True,\n             \"inventory_tracking\": True,\n-            \"customer_loyalty\": True\n+            \"customer_loyalty\": True,\n         }\n-        \n+\n         return APIResponseHelper.success(\n             data=features,\n             message=\"Feature flags retrieved\",\n-            meta={\n-                \"user_role\": current_user.role,\n-                \"features_count\": len(features)\n-            }\n-        )\n-        \n+            meta={\"user_role\": current_user.role, \"features_count\": len(features)},\n+        )\n+\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to retrieve feature flags: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n # Session validation endpoint (Odoo-style)\n @router.post(\"/web/session/get_session_info\")\n async def get_session_info(\n-    current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    current_user: User = Depends(get_current_user), db: Session = Depends(get_db)\n ):\n     \"\"\"\n     Odoo-compatible session information endpoint\n     \"\"\"\n     try:\n         # Get restaurant info\n         restaurant = None\n         if current_user.restaurant_id:\n-            restaurant = db.query(Restaurant).filter(\n-                Restaurant.id == current_user.restaurant_id\n-            ).first()\n-        \n+            restaurant = (\n+                db.query(Restaurant)\n+                .filter(Restaurant.id == current_user.restaurant_id)\n+                .first()\n+            )\n+\n         session_info = {\n             \"uid\": str(current_user.id),\n             \"username\": current_user.username,\n-            \"user_context\": {\n-                \"lang\": \"en_US\",\n-                \"tz\": \"UTC\",\n-                \"uid\": str(current_user.id)\n-            },\n+            \"user_context\": {\"lang\": \"en_US\", \"tz\": \"UTC\", \"uid\": str(current_user.id)},\n             \"is_admin\": current_user.role in [\"platform_owner\", \"restaurant_owner\"],\n-            \"company_id\": str(current_user.restaurant_id) if current_user.restaurant_id else None,\n+            \"company_id\": (\n+                str(current_user.restaurant_id) if current_user.restaurant_id else None\n+            ),\n             \"company_name\": restaurant.name if restaurant else None,\n             \"session_id\": \"active\",  # Simplified\n             \"user_companies\": {\n-                \"current_company\": str(current_user.restaurant_id) if current_user.restaurant_id else None\n-            }\n+                \"current_company\": (\n+                    str(current_user.restaurant_id)\n+                    if current_user.restaurant_id\n+                    else None\n+                )\n+            },\n         }\n-        \n+\n         return APIResponseHelper.success(\n-            data=session_info,\n-            message=\"Session information retrieved\"\n-        )\n-        \n+            data=session_info, message=\"Session information retrieved\"\n+        )\n+\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to retrieve session info: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n\\ No newline at end of file\n+            status_code=500,\n+        )\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/config.py\t2025-08-02 22:03:30.949358+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/config.py\t2025-08-02 22:36:02.631815+00:00\n@@ -7,478 +7,494 @@\n from fastapi import APIRouter, Depends, status\n from sqlalchemy.orm import Session\n from pydantic import BaseModel\n \n from app.core.database import get_db, User\n-from app.core.exceptions import FynloException, ResourceNotFoundException, ValidationException, AuthenticationException, ConflictException\n+from app.core.exceptions import (\n+    FynloException,\n+    ResourceNotFoundException,\n+    ValidationException,\n+    AuthenticationException,\n+    ConflictException,\n+)\n from app.core.auth import get_current_user\n from app.core.responses import APIResponseHelper\n-from app.services.config_manager import config_manager, ProviderConfig, RoutingConfig, FeatureFlags\n+from app.services.config_manager import (\n+    config_manager,\n+    ProviderConfig,\n+    RoutingConfig,\n+    FeatureFlags,\n+)\n from app.services.payment_factory import payment_factory\n from app.services.smart_routing import RoutingStrategy\n from app.services.monitoring import get_monitoring_service\n \n router = APIRouter()\n+\n \n # Pydantic models for requests/responses\n class ProviderConfigRequest(BaseModel):\n     enabled: Optional[bool] = None\n     environment: Optional[str] = None\n     webhook_url: Optional[str] = None\n     timeout_seconds: Optional[int] = None\n     retry_attempts: Optional[int] = None\n     custom_settings: Optional[Dict[str, Any]] = None\n \n+\n class RoutingConfigRequest(BaseModel):\n     enabled: Optional[bool] = None\n     default_strategy: Optional[str] = None\n     fallback_provider: Optional[str] = None\n \n+\n class FeatureFlagRequest(BaseModel):\n     feature_name: str\n     enabled: bool\n \n+\n class ThresholdUpdateRequest(BaseModel):\n     thresholds: Dict[str, float]\n \n+\n @router.get(\"/summary\")\n-async def get_configuration_summary(\n-    current_user: User = Depends(get_current_user)\n-):\n+async def get_configuration_summary(current_user: User = Depends(get_current_user)):\n     \"\"\"Get comprehensive configuration summary\"\"\"\n     try:\n         summary = config_manager.get_configuration_summary()\n-        \n+\n         # Add runtime information\n         available_providers = payment_factory.get_available_providers()\n-        \n-        summary['runtime'] = {\n-            'available_providers': available_providers,\n-            'total_providers_configured': len(config_manager.providers),\n-            'enabled_providers': len(config_manager.get_enabled_providers())\n+\n+        summary[\"runtime\"] = {\n+            \"available_providers\": available_providers,\n+            \"total_providers_configured\": len(config_manager.providers),\n+            \"enabled_providers\": len(config_manager.get_enabled_providers()),\n         }\n-        \n-        return APIResponseHelper.success(\n-            data=summary,\n-            message=\"Configuration summary retrieved successfully\"\n-        )\n-        \n-    except Exception as e:\n-        raise FynloException(message=str(e))\n+\n+        return APIResponseHelper.success(\n+            data=summary, message=\"Configuration summary retrieved successfully\"\n+        )\n+\n+    except Exception as e:\n+        raise FynloException(message=str(e))\n+\n \n @router.get(\"/providers\")\n-async def get_provider_configurations(\n-    current_user: User = Depends(get_current_user)\n-):\n+async def get_provider_configurations(current_user: User = Depends(get_current_user)):\n     \"\"\"Get all provider configurations\"\"\"\n     try:\n         providers_config = {}\n-        \n+\n         for name, config in config_manager.providers.items():\n             providers_config[name] = {\n-                'name': config.name,\n-                'enabled': config.enabled,\n-                'environment': config.environment,\n-                'webhook_url': config.webhook_url,\n-                'timeout_seconds': config.timeout_seconds,\n-                'retry_attempts': config.retry_attempts,\n-                'custom_settings': config.custom_settings,\n-                'has_api_key': bool(config.api_key),\n-                'has_secret_key': bool(config.secret_key)\n+                \"name\": config.name,\n+                \"enabled\": config.enabled,\n+                \"environment\": config.environment,\n+                \"webhook_url\": config.webhook_url,\n+                \"timeout_seconds\": config.timeout_seconds,\n+                \"retry_attempts\": config.retry_attempts,\n+                \"custom_settings\": config.custom_settings,\n+                \"has_api_key\": bool(config.api_key),\n+                \"has_secret_key\": bool(config.secret_key),\n             }\n-        \n+\n         return APIResponseHelper.success(\n             data=providers_config,\n-            message=f\"Retrieved configuration for {len(providers_config)} providers\"\n-        )\n-        \n-    except Exception as e:\n-        raise FynloException(message=str(e))\n+            message=f\"Retrieved configuration for {len(providers_config)} providers\",\n+        )\n+\n+    except Exception as e:\n+        raise FynloException(message=str(e))\n+\n \n @router.get(\"/providers/{provider_name}\")\n async def get_provider_configuration(\n-    provider_name: str,\n-    current_user: User = Depends(get_current_user)\n+    provider_name: str, current_user: User = Depends(get_current_user)\n ):\n     \"\"\"Get configuration for a specific provider\"\"\"\n     try:\n         config = config_manager.get_provider_config(provider_name)\n-        \n+\n         if not config:\n-            raise ResourceNotFoundException(resource=\"Provider\", resource_id=provider_name)\n-        \n+            raise ResourceNotFoundException(\n+                resource=\"Provider\", resource_id=provider_name\n+            )\n+\n         # Don't expose sensitive information\n         provider_config = {\n-            'name': config.name,\n-            'enabled': config.enabled,\n-            'environment': config.environment,\n-            'webhook_url': config.webhook_url,\n-            'timeout_seconds': config.timeout_seconds,\n-            'retry_attempts': config.retry_attempts,\n-            'custom_settings': config.custom_settings,\n-            'has_api_key': bool(config.api_key),\n-            'has_secret_key': bool(config.secret_key)\n+            \"name\": config.name,\n+            \"enabled\": config.enabled,\n+            \"environment\": config.environment,\n+            \"webhook_url\": config.webhook_url,\n+            \"timeout_seconds\": config.timeout_seconds,\n+            \"retry_attempts\": config.retry_attempts,\n+            \"custom_settings\": config.custom_settings,\n+            \"has_api_key\": bool(config.api_key),\n+            \"has_secret_key\": bool(config.secret_key),\n         }\n-        \n+\n         return APIResponseHelper.success(\n             data=provider_config,\n-            message=f\"Configuration for {provider_name} retrieved successfully\"\n-        )\n-        \n+            message=f\"Configuration for {provider_name} retrieved successfully\",\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(message=str(e))\n+\n \n @router.put(\"/providers/{provider_name}\")\n async def update_provider_configuration(\n     provider_name: str,\n     config_update: ProviderConfigRequest,\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Update configuration for a specific provider\"\"\"\n     try:\n         # Get current configuration\n         current_config = config_manager.get_provider_config(provider_name)\n-        \n+\n         # Prepare update data (exclude None values)\n-        update_data = {\n-            k: v for k, v in config_update.dict().items() \n-            if v is not None\n-        }\n-        \n+        update_data = {k: v for k, v in config_update.dict().items() if v is not None}\n+\n         if not update_data:\n             raise ValidationException(message=\"No configuration changes provided\")\n-        \n+\n         # Update configuration\n         config_manager.update_provider_config(provider_name, **update_data)\n-        \n+\n         # Save to file\n         config_manager.save_configuration(\"providers\")\n-        \n+\n         # Get updated configuration\n         updated_config = config_manager.get_provider_config(provider_name)\n-        \n+\n         return APIResponseHelper.success(\n             data={\n-                'name': updated_config.name,\n-                'enabled': updated_config.enabled,\n-                'environment': updated_config.environment,\n-                'webhook_url': updated_config.webhook_url,\n-                'timeout_seconds': updated_config.timeout_seconds,\n-                'retry_attempts': updated_config.retry_attempts,\n-                'custom_settings': updated_config.custom_settings\n+                \"name\": updated_config.name,\n+                \"enabled\": updated_config.enabled,\n+                \"environment\": updated_config.environment,\n+                \"webhook_url\": updated_config.webhook_url,\n+                \"timeout_seconds\": updated_config.timeout_seconds,\n+                \"retry_attempts\": updated_config.retry_attempts,\n+                \"custom_settings\": updated_config.custom_settings,\n             },\n-            message=f\"Configuration for {provider_name} updated successfully\"\n-        )\n-        \n+            message=f\"Configuration for {provider_name} updated successfully\",\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(message=str(e))\n \n+\n @router.get(\"/routing\")\n-async def get_routing_configuration(\n-    current_user: User = Depends(get_current_user)\n-):\n+async def get_routing_configuration(current_user: User = Depends(get_current_user)):\n     \"\"\"Get smart routing configuration\"\"\"\n     try:\n         routing_config = config_manager.get_routing_config()\n-        \n+\n         config_data = {\n-            'enabled': routing_config.enabled,\n-            'default_strategy': routing_config.default_strategy,\n-            'volume_thresholds': {k: float(v) for k, v in routing_config.volume_thresholds.items()},\n-            'provider_weights': routing_config.provider_weights,\n-            'fallback_provider': routing_config.fallback_provider,\n-            'available_strategies': [strategy.value for strategy in RoutingStrategy]\n+            \"enabled\": routing_config.enabled,\n+            \"default_strategy\": routing_config.default_strategy,\n+            \"volume_thresholds\": {\n+                k: float(v) for k, v in routing_config.volume_thresholds.items()\n+            },\n+            \"provider_weights\": routing_config.provider_weights,\n+            \"fallback_provider\": routing_config.fallback_provider,\n+            \"available_strategies\": [strategy.value for strategy in RoutingStrategy],\n         }\n-        \n-        return APIResponseHelper.success(\n-            data=config_data,\n-            message=\"Routing configuration retrieved successfully\"\n-        )\n-        \n-    except Exception as e:\n-        raise FynloException(message=str(e))\n+\n+        return APIResponseHelper.success(\n+            data=config_data, message=\"Routing configuration retrieved successfully\"\n+        )\n+\n+    except Exception as e:\n+        raise FynloException(message=str(e))\n+\n \n @router.put(\"/routing\")\n async def update_routing_configuration(\n-    config_update: RoutingConfigRequest,\n-    current_user: User = Depends(get_current_user)\n+    config_update: RoutingConfigRequest, current_user: User = Depends(get_current_user)\n ):\n     \"\"\"Update smart routing configuration\"\"\"\n     try:\n         routing_config = config_manager.routing\n-        \n+\n         # Update provided fields\n         if config_update.enabled is not None:\n             routing_config.enabled = config_update.enabled\n-        \n+\n         if config_update.default_strategy is not None:\n             # Validate strategy\n             try:\n                 RoutingStrategy(config_update.default_strategy)\n                 routing_config.default_strategy = config_update.default_strategy\n             except ValueError:\n-                raise ValidationException(message=f\"Invalid routing strategy: {config_update.default_strategy}\")\n-        \n+                raise ValidationException(\n+                    message=f\"Invalid routing strategy: {config_update.default_strategy}\"\n+                )\n+\n         if config_update.fallback_provider is not None:\n             # Validate provider exists\n             if config_update.fallback_provider not in config_manager.providers:\n                 raise ValidationException(\n                     message=f\"Fallback provider '{config_update.fallback_provider}' not configured\"\n                 )\n             routing_config.fallback_provider = config_update.fallback_provider\n-        \n+\n         # Save configuration\n         config_manager.save_configuration(\"routing\")\n-        \n+\n         return APIResponseHelper.success(\n             data={\n-                'enabled': routing_config.enabled,\n-                'default_strategy': routing_config.default_strategy,\n-                'fallback_provider': routing_config.fallback_provider\n+                \"enabled\": routing_config.enabled,\n+                \"default_strategy\": routing_config.default_strategy,\n+                \"fallback_provider\": routing_config.fallback_provider,\n             },\n-            message=\"Routing configuration updated successfully\"\n-        )\n-        \n+            message=\"Routing configuration updated successfully\",\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(message=str(e))\n \n+\n @router.get(\"/features\")\n-async def get_feature_flags(\n-    current_user: User = Depends(get_current_user)\n-):\n+async def get_feature_flags(current_user: User = Depends(get_current_user)):\n     \"\"\"Get all feature flags\"\"\"\n     try:\n         features = config_manager.features\n-        \n+\n         feature_flags = {\n-            'smart_routing_enabled': features.smart_routing_enabled,\n-            'analytics_enabled': features.analytics_enabled,\n-            'volume_tracking_enabled': features.volume_tracking_enabled,\n-            'qr_payments_enabled': features.qr_payments_enabled,\n-            'cash_payments_enabled': features.cash_payments_enabled,\n-            'auto_refunds_enabled': features.auto_refunds_enabled,\n-            'webhook_retries_enabled': features.webhook_retries_enabled,\n-            'cost_optimization_alerts': features.cost_optimization_alerts\n+            \"smart_routing_enabled\": features.smart_routing_enabled,\n+            \"analytics_enabled\": features.analytics_enabled,\n+            \"volume_tracking_enabled\": features.volume_tracking_enabled,\n+            \"qr_payments_enabled\": features.qr_payments_enabled,\n+            \"cash_payments_enabled\": features.cash_payments_enabled,\n+            \"auto_refunds_enabled\": features.auto_refunds_enabled,\n+            \"webhook_retries_enabled\": features.webhook_retries_enabled,\n+            \"cost_optimization_alerts\": features.cost_optimization_alerts,\n         }\n-        \n-        return APIResponseHelper.success(\n-            data=feature_flags,\n-            message=\"Feature flags retrieved successfully\"\n-        )\n-        \n-    except Exception as e:\n-        raise FynloException(message=str(e))\n+\n+        return APIResponseHelper.success(\n+            data=feature_flags, message=\"Feature flags retrieved successfully\"\n+        )\n+\n+    except Exception as e:\n+        raise FynloException(message=str(e))\n+\n \n @router.put(\"/features\")\n async def update_feature_flag(\n-    feature_update: FeatureFlagRequest,\n-    current_user: User = Depends(get_current_user)\n+    feature_update: FeatureFlagRequest, current_user: User = Depends(get_current_user)\n ):\n     \"\"\"Update a feature flag\"\"\"\n     try:\n-        config_manager.update_feature_flag(feature_update.feature_name, feature_update.enabled)\n-        \n+        config_manager.update_feature_flag(\n+            feature_update.feature_name, feature_update.enabled\n+        )\n+\n         # Save configuration\n         config_manager.save_configuration(\"features\")\n-        \n+\n         return APIResponseHelper.success(\n             data={\n-                'feature_name': feature_update.feature_name,\n-                'enabled': feature_update.enabled\n+                \"feature_name\": feature_update.feature_name,\n+                \"enabled\": feature_update.enabled,\n             },\n-            message=f\"Feature flag '{feature_update.feature_name}' updated successfully\"\n-        )\n-        \n-    except Exception as e:\n-        raise FynloException(message=str(e))\n+            message=f\"Feature flag '{feature_update.feature_name}' updated successfully\",\n+        )\n+\n+    except Exception as e:\n+        raise FynloException(message=str(e))\n+\n \n @router.get(\"/security\")\n-async def get_security_configuration(\n-    current_user: User = Depends(get_current_user)\n-):\n+async def get_security_configuration(current_user: User = Depends(get_current_user)):\n     \"\"\"Get security configuration\"\"\"\n     try:\n         security_config = config_manager.get_security_config()\n-        \n+\n         config_data = {\n-            'encrypt_api_keys': security_config.encrypt_api_keys,\n-            'webhook_signature_validation': security_config.webhook_signature_validation,\n-            'rate_limiting_enabled': security_config.rate_limiting_enabled,\n-            'max_requests_per_minute': security_config.max_requests_per_minute,\n-            'allowed_origins': security_config.allowed_origins,\n-            'ssl_required': security_config.ssl_required\n+            \"encrypt_api_keys\": security_config.encrypt_api_keys,\n+            \"webhook_signature_validation\": security_config.webhook_signature_validation,\n+            \"rate_limiting_enabled\": security_config.rate_limiting_enabled,\n+            \"max_requests_per_minute\": security_config.max_requests_per_minute,\n+            \"allowed_origins\": security_config.allowed_origins,\n+            \"ssl_required\": security_config.ssl_required,\n         }\n-        \n-        return APIResponseHelper.success(\n-            data=config_data,\n-            message=\"Security configuration retrieved successfully\"\n-        )\n-        \n-    except Exception as e:\n-        raise FynloException(message=str(e))\n+\n+        return APIResponseHelper.success(\n+            data=config_data, message=\"Security configuration retrieved successfully\"\n+        )\n+\n+    except Exception as e:\n+        raise FynloException(message=str(e))\n+\n \n @router.post(\"/validate\")\n-async def validate_configuration(\n-    current_user: User = Depends(get_current_user)\n-):\n+async def validate_configuration(current_user: User = Depends(get_current_user)):\n     \"\"\"Validate current configuration\"\"\"\n     try:\n         # Re-run validation\n         config_manager._validate_configurations()\n-        \n+\n         # Get validation results\n         issues = []\n-        \n+\n         # Check provider configurations\n         enabled_providers = config_manager.get_enabled_providers()\n         if not enabled_providers:\n             issues.append(\"No payment providers are enabled\")\n-        \n+\n         # Check routing configuration\n-        if config_manager.routing.enabled and config_manager.routing.fallback_provider not in enabled_providers:\n-            issues.append(f\"Fallback provider '{config_manager.routing.fallback_provider}' is not enabled\")\n-        \n+        if (\n+            config_manager.routing.enabled\n+            and config_manager.routing.fallback_provider not in enabled_providers\n+        ):\n+            issues.append(\n+                f\"Fallback provider '{config_manager.routing.fallback_provider}' is not enabled\"\n+            )\n+\n         # Check feature dependencies\n-        if config_manager.features.smart_routing_enabled and not config_manager.routing.enabled:\n+        if (\n+            config_manager.features.smart_routing_enabled\n+            and not config_manager.routing.enabled\n+        ):\n             issues.append(\"Smart routing feature is enabled but routing is disabled\")\n-        \n+\n         validation_result = {\n-            'valid': len(issues) == 0,\n-            'issues': issues,\n-            'enabled_providers': enabled_providers,\n-            'routing_enabled': config_manager.routing.enabled,\n-            'features_enabled': {\n+            \"valid\": len(issues) == 0,\n+            \"issues\": issues,\n+            \"enabled_providers\": enabled_providers,\n+            \"routing_enabled\": config_manager.routing.enabled,\n+            \"features_enabled\": {\n                 name: getattr(config_manager.features, name)\n                 for name in dir(config_manager.features)\n-                if not name.startswith('_')\n-            }\n+                if not name.startswith(\"_\")\n+            },\n         }\n-        \n-        return APIResponseHelper.success(\n-            data=validation_result,\n-            message=\"Configuration validation completed\"\n-        )\n-        \n-    except Exception as e:\n-        raise FynloException(message=str(e))\n+\n+        return APIResponseHelper.success(\n+            data=validation_result, message=\"Configuration validation completed\"\n+        )\n+\n+    except Exception as e:\n+        raise FynloException(message=str(e))\n+\n \n @router.get(\"/monitoring/health\")\n async def get_system_health(\n-    db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    db: Session = Depends(get_db), current_user: User = Depends(get_current_user)\n ):\n     \"\"\"Get system health status\"\"\"\n     try:\n         monitoring_service = get_monitoring_service(db)\n         health_status = await monitoring_service.check_system_health()\n-        \n-        return APIResponseHelper.success(\n-            data=health_status,\n-            message=\"System health status retrieved successfully\"\n-        )\n-        \n-    except Exception as e:\n-        raise FynloException(message=str(e))\n+\n+        return APIResponseHelper.success(\n+            data=health_status, message=\"System health status retrieved successfully\"\n+        )\n+\n+    except Exception as e:\n+        raise FynloException(message=str(e))\n+\n \n @router.get(\"/monitoring/metrics\")\n async def get_system_metrics(\n     hours: int = 24,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Get system metrics for specified time period\"\"\"\n     try:\n         if hours < 1 or hours > 168:  # Max 1 week\n             raise ValidationException(message=\"Hours must be between 1 and 168\")\n-        \n+\n         monitoring_service = get_monitoring_service(db)\n         metrics = await monitoring_service.get_system_metrics(hours)\n-        \n+\n         return APIResponseHelper.success(\n             data=metrics,\n-            message=f\"System metrics for last {hours} hours retrieved successfully\"\n-        )\n-        \n+            message=f\"System metrics for last {hours} hours retrieved successfully\",\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(message=str(e))\n+\n \n @router.put(\"/monitoring/thresholds\")\n async def update_monitoring_thresholds(\n     threshold_update: ThresholdUpdateRequest,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Update monitoring alert thresholds\"\"\"\n     try:\n         monitoring_service = get_monitoring_service(db)\n         await monitoring_service.update_thresholds(threshold_update.thresholds)\n-        \n+\n         return APIResponseHelper.success(\n             data=threshold_update.thresholds,\n-            message=\"Monitoring thresholds updated successfully\"\n-        )\n-        \n-    except Exception as e:\n-        raise FynloException(message=str(e))\n+            message=\"Monitoring thresholds updated successfully\",\n+        )\n+\n+    except Exception as e:\n+        raise FynloException(message=str(e))\n+\n \n @router.post(\"/test/routing\")\n async def test_routing_simulation(\n     restaurant_id: str,\n     strategy: str,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Test routing strategy simulation\"\"\"\n     try:\n         # Validate strategy\n         try:\n             routing_strategy = RoutingStrategy(strategy)\n         except ValueError:\n             raise ValidationException(message=f\"Invalid routing strategy: {strategy}\")\n-        \n+\n         # Run simulation\n         simulation_result = await payment_factory.simulate_routing_impact(\n-            restaurant_id=restaurant_id,\n-            strategy=routing_strategy,\n-            db_session=db\n-        )\n-        \n-        return APIResponseHelper.success(\n-            data=simulation_result,\n-            message=\"Routing simulation completed successfully\"\n-        )\n-        \n+            restaurant_id=restaurant_id, strategy=routing_strategy, db_session=db\n+        )\n+\n+        return APIResponseHelper.success(\n+            data=simulation_result, message=\"Routing simulation completed successfully\"\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(message=str(e))\n \n+\n @router.post(\"/backup\")\n-async def backup_configuration(\n-    current_user: User = Depends(get_current_user)\n-):\n+async def backup_configuration(current_user: User = Depends(get_current_user)):\n     \"\"\"Create a backup of current configuration\"\"\"\n     try:\n         # Save all configurations\n         config_manager.save_configuration(\"all\")\n-        \n+\n         # Get configuration summary for backup verification\n         summary = config_manager.get_configuration_summary()\n-        \n+\n         return APIResponseHelper.success(\n             data={\n-                'backup_timestamp': summary,\n-                'backup_location': f\"config/payment_config_{config_manager.environment.value}.json\"\n+                \"backup_timestamp\": summary,\n+                \"backup_location\": f\"config/payment_config_{config_manager.environment.value}.json\",\n             },\n-            message=\"Configuration backup created successfully\"\n-        )\n-        \n-    except Exception as e:\n-        raise FynloException(message=str(e))\n\\ No newline at end of file\n+            message=\"Configuration backup created successfully\",\n+        )\n+\n+    except Exception as e:\n+        raise FynloException(message=str(e))\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/employees.py\t2025-08-02 21:56:58.984663+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/employees.py\t2025-08-02 22:36:02.634823+00:00\n@@ -12,458 +12,414 @@\n from app.core.responses import APIResponseHelper\n from app.core.auth import get_current_user\n from app.core.onboarding_helper import OnboardingHelper\n from app.models.employee import Employee\n from app.schemas.employee_schemas import (\n-    EmployeeCreateRequest, EmployeeUpdateRequest, EmployeeResponse,\n-    ScheduleCreateRequest, ScheduleUpdateRequest, ScheduleResponse,\n-    ShiftResponse, TimeEntryResponse, PerformanceMetricResponse\n+    EmployeeCreateRequest,\n+    EmployeeUpdateRequest,\n+    EmployeeResponse,\n+    ScheduleCreateRequest,\n+    ScheduleUpdateRequest,\n+    ScheduleResponse,\n+    ShiftResponse,\n+    TimeEntryResponse,\n+    PerformanceMetricResponse,\n )\n from app.services.employee_service import EmployeeService\n from app.middleware.rate_limit_middleware import limiter\n \n router = APIRouter()\n \n # Initialize employee service\n employee_service = EmployeeService()\n+\n \n @router.get(\"/\", response_model=List[EmployeeResponse])\n async def get_employees(\n     restaurant_id: Optional[int] = Query(None, description=\"Filter by restaurant ID\"),\n     role: Optional[str] = Query(None, description=\"Filter by employee role\"),\n     active: Optional[bool] = Query(True, description=\"Filter by active status\"),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Get all employees with optional filtering\"\"\"\n-    \n+\n     # Check if user needs onboarding (no restaurant)\n     onboarding_response = OnboardingHelper.handle_onboarding_response(\n-        user=current_user,\n-        resource_type=\"employees\",\n-        endpoint_requires_restaurant=True\n+        user=current_user, resource_type=\"employees\", endpoint_requires_restaurant=True\n     )\n     if onboarding_response:\n         return onboarding_response\n-    \n+\n     try:\n         employees = await employee_service.get_employees(\n             db=db,\n             restaurant_id=restaurant_id,\n             role=role,\n             active=active,\n-            current_user=current_user\n-        )\n-        return APIResponseHelper.success(\n-            data=employees,\n-            message=f\"Retrieved {len(employees)} employees\"\n-        )\n-    except Exception as e:\n-        return APIResponseHelper.error(\n-            message=f\"Failed to retrieve employees: {str(e)}\",\n-            status_code=500\n-        )\n+            current_user=current_user,\n+        )\n+        return APIResponseHelper.success(\n+            data=employees, message=f\"Retrieved {len(employees)} employees\"\n+        )\n+    except Exception as e:\n+        return APIResponseHelper.error(\n+            message=f\"Failed to retrieve employees: {str(e)}\", status_code=500\n+        )\n+\n \n @router.get(\"/{employee_id}\", response_model=EmployeeResponse)\n async def get_employee(\n     employee_id: int,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Get specific employee by ID\"\"\"\n     try:\n         employee = await employee_service.get_employee_by_id(\n-            db=db,\n-            employee_id=employee_id,\n-            current_user=current_user\n+            db=db, employee_id=employee_id, current_user=current_user\n         )\n         if not employee:\n             return APIResponseHelper.error(\n-                message=\"Employee not found\",\n-                status_code=404\n+                message=\"Employee not found\", status_code=404\n             )\n         return APIResponseHelper.success(\n-            data=employee,\n-            message=\"Employee retrieved successfully\"\n-        )\n-    except Exception as e:\n-        return APIResponseHelper.error(\n-            message=f\"Failed to retrieve employee: {str(e)}\",\n-            status_code=500\n-        )\n+            data=employee, message=\"Employee retrieved successfully\"\n+        )\n+    except Exception as e:\n+        return APIResponseHelper.error(\n+            message=f\"Failed to retrieve employee: {str(e)}\", status_code=500\n+        )\n+\n \n @router.post(\"/\", response_model=EmployeeResponse)\n async def create_employee(\n     employee_data: EmployeeCreateRequest,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Create new employee\"\"\"\n     try:\n         employee = employee_service.create_employee(\n-            db=db,\n-            employee_data=employee_data,\n-            current_user=current_user\n-        )\n-        return APIResponseHelper.success(\n-            data=employee,\n-            message=\"Employee created successfully\",\n-            status_code=201\n-        )\n-    except ValueError as e:\n-        return APIResponseHelper.error(\n-            message=str(e),\n-            status_code=400\n-        )\n-    except Exception as e:\n-        return APIResponseHelper.error(\n-            message=f\"Failed to create employee: {str(e)}\",\n-            status_code=500\n-        )\n+            db=db, employee_data=employee_data, current_user=current_user\n+        )\n+        return APIResponseHelper.success(\n+            data=employee, message=\"Employee created successfully\", status_code=201\n+        )\n+    except ValueError as e:\n+        return APIResponseHelper.error(message=str(e), status_code=400)\n+    except Exception as e:\n+        return APIResponseHelper.error(\n+            message=f\"Failed to create employee: {str(e)}\", status_code=500\n+        )\n+\n \n @router.put(\"/{employee_id}\", response_model=EmployeeResponse)\n async def update_employee(\n     employee_id: int,\n     employee_data: EmployeeUpdateRequest,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Update employee information\"\"\"\n     try:\n         employee = employee_service.update_employee(\n             db=db,\n             employee_id=employee_id,\n             employee_data=employee_data,\n-            current_user=current_user\n+            current_user=current_user,\n         )\n         if not employee:\n             return APIResponseHelper.error(\n-                message=\"Employee not found\",\n-                status_code=404\n+                message=\"Employee not found\", status_code=404\n             )\n         return APIResponseHelper.success(\n-            data=employee,\n-            message=\"Employee updated successfully\"\n-        )\n-    except ValueError as e:\n-        return APIResponseHelper.error(\n-            message=str(e),\n-            status_code=400\n-        )\n-    except Exception as e:\n-        return APIResponseHelper.error(\n-            message=f\"Failed to update employee: {str(e)}\",\n-            status_code=500\n-        )\n+            data=employee, message=\"Employee updated successfully\"\n+        )\n+    except ValueError as e:\n+        return APIResponseHelper.error(message=str(e), status_code=400)\n+    except Exception as e:\n+        return APIResponseHelper.error(\n+            message=f\"Failed to update employee: {str(e)}\", status_code=500\n+        )\n+\n \n @router.delete(\"/{employee_id}\")\n async def delete_employee(\n     employee_id: int,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Delete employee (soft delete - marks as inactive)\"\"\"\n     try:\n         success = employee_service.delete_employee(\n-            db=db,\n-            employee_id=employee_id,\n-            current_user=current_user\n+            db=db, employee_id=employee_id, current_user=current_user\n         )\n         if not success:\n             return APIResponseHelper.error(\n-                message=\"Employee not found\",\n-                status_code=404\n+                message=\"Employee not found\", status_code=404\n             )\n-        return APIResponseHelper.success(\n-            message=\"Employee deactivated successfully\"\n-        )\n-    except Exception as e:\n-        return APIResponseHelper.error(\n-            message=f\"Failed to delete employee: {str(e)}\",\n-            status_code=500\n-        )\n+        return APIResponseHelper.success(message=\"Employee deactivated successfully\")\n+    except Exception as e:\n+        return APIResponseHelper.error(\n+            message=f\"Failed to delete employee: {str(e)}\", status_code=500\n+        )\n+\n \n # Schedule Management Endpoints\n+\n \n @router.get(\"/{employee_id}/schedules\", response_model=List[ScheduleResponse])\n async def get_employee_schedules(\n     employee_id: int,\n-    start_date: Optional[date] = Query(None, description=\"Filter schedules from this date\"),\n+    start_date: Optional[date] = Query(\n+        None, description=\"Filter schedules from this date\"\n+    ),\n     end_date: Optional[date] = Query(None, description=\"Filter schedules to this date\"),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Get employee schedules with optional date filtering\"\"\"\n     try:\n         schedules = employee_service.get_employee_schedules(\n             db=db,\n             employee_id=employee_id,\n             start_date=start_date,\n             end_date=end_date,\n-            current_user=current_user\n-        )\n-        return APIResponseHelper.success(\n-            data=schedules,\n-            message=f\"Retrieved {len(schedules)} schedules\"\n-        )\n-    except Exception as e:\n-        return APIResponseHelper.error(\n-            message=f\"Failed to retrieve schedules: {str(e)}\",\n-            status_code=500\n-        )\n+            current_user=current_user,\n+        )\n+        return APIResponseHelper.success(\n+            data=schedules, message=f\"Retrieved {len(schedules)} schedules\"\n+        )\n+    except Exception as e:\n+        return APIResponseHelper.error(\n+            message=f\"Failed to retrieve schedules: {str(e)}\", status_code=500\n+        )\n+\n \n @router.post(\"/{employee_id}/schedules\", response_model=ScheduleResponse)\n async def create_employee_schedule(\n     employee_id: int,\n     schedule_data: ScheduleCreateRequest,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Create new schedule for employee\"\"\"\n     try:\n         schedule = employee_service.create_schedule(\n             db=db,\n             employee_id=employee_id,\n             schedule_data=schedule_data,\n-            current_user=current_user\n-        )\n-        return APIResponseHelper.success(\n-            data=schedule,\n-            message=\"Schedule created successfully\",\n-            status_code=201\n-        )\n-    except ValueError as e:\n-        return APIResponseHelper.error(\n-            message=str(e),\n-            status_code=400\n-        )\n-    except Exception as e:\n-        return APIResponseHelper.error(\n-            message=f\"Failed to create schedule: {str(e)}\",\n-            status_code=500\n-        )\n+            current_user=current_user,\n+        )\n+        return APIResponseHelper.success(\n+            data=schedule, message=\"Schedule created successfully\", status_code=201\n+        )\n+    except ValueError as e:\n+        return APIResponseHelper.error(message=str(e), status_code=400)\n+    except Exception as e:\n+        return APIResponseHelper.error(\n+            message=f\"Failed to create schedule: {str(e)}\", status_code=500\n+        )\n+\n \n @router.put(\"/schedules/{schedule_id}\", response_model=ScheduleResponse)\n async def update_schedule(\n     schedule_id: int,\n     schedule_data: ScheduleUpdateRequest,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Update existing schedule\"\"\"\n     try:\n         schedule = employee_service.update_schedule(\n             db=db,\n             schedule_id=schedule_id,\n             schedule_data=schedule_data,\n-            current_user=current_user\n+            current_user=current_user,\n         )\n         if not schedule:\n             return APIResponseHelper.error(\n-                message=\"Schedule not found\",\n-                status_code=404\n+                message=\"Schedule not found\", status_code=404\n             )\n         return APIResponseHelper.success(\n-            data=schedule,\n-            message=\"Schedule updated successfully\"\n-        )\n-    except ValueError as e:\n-        return APIResponseHelper.error(\n-            message=str(e),\n-            status_code=400\n-        )\n-    except Exception as e:\n-        return APIResponseHelper.error(\n-            message=f\"Failed to update schedule: {str(e)}\",\n-            status_code=500\n-        )\n+            data=schedule, message=\"Schedule updated successfully\"\n+        )\n+    except ValueError as e:\n+        return APIResponseHelper.error(message=str(e), status_code=400)\n+    except Exception as e:\n+        return APIResponseHelper.error(\n+            message=f\"Failed to update schedule: {str(e)}\", status_code=500\n+        )\n+\n \n @router.delete(\"/schedules/{schedule_id}\")\n async def delete_schedule(\n     schedule_id: int,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Delete schedule\"\"\"\n     try:\n         success = employee_service.delete_schedule(\n-            db=db,\n-            schedule_id=schedule_id,\n-            current_user=current_user\n+            db=db, schedule_id=schedule_id, current_user=current_user\n         )\n         if not success:\n             return APIResponseHelper.error(\n-                message=\"Schedule not found\",\n-                status_code=404\n+                message=\"Schedule not found\", status_code=404\n             )\n-        return APIResponseHelper.success(\n-            message=\"Schedule deleted successfully\"\n-        )\n-    except Exception as e:\n-        return APIResponseHelper.error(\n-            message=f\"Failed to delete schedule: {str(e)}\",\n-            status_code=500\n-        )\n+        return APIResponseHelper.success(message=\"Schedule deleted successfully\")\n+    except Exception as e:\n+        return APIResponseHelper.error(\n+            message=f\"Failed to delete schedule: {str(e)}\", status_code=500\n+        )\n+\n \n # Time Tracking Endpoints\n+\n \n @router.post(\"/{employee_id}/clock-in\")\n async def clock_in(\n     employee_id: int,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Clock in employee for their shift\"\"\"\n     try:\n         shift = employee_service.clock_in(\n-            db=db,\n-            employee_id=employee_id,\n-            current_user=current_user\n-        )\n-        return APIResponseHelper.success(\n-            data=shift,\n-            message=\"Clocked in successfully\"\n-        )\n-    except ValueError as e:\n-        return APIResponseHelper.error(\n-            message=str(e),\n-            status_code=400\n-        )\n-    except Exception as e:\n-        return APIResponseHelper.error(\n-            message=f\"Failed to clock in: {str(e)}\",\n-            status_code=500\n-        )\n+            db=db, employee_id=employee_id, current_user=current_user\n+        )\n+        return APIResponseHelper.success(data=shift, message=\"Clocked in successfully\")\n+    except ValueError as e:\n+        return APIResponseHelper.error(message=str(e), status_code=400)\n+    except Exception as e:\n+        return APIResponseHelper.error(\n+            message=f\"Failed to clock in: {str(e)}\", status_code=500\n+        )\n+\n \n @router.post(\"/{employee_id}/clock-out\")\n async def clock_out(\n     employee_id: int,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Clock out employee from their shift\"\"\"\n     try:\n         shift = employee_service.clock_out(\n-            db=db,\n-            employee_id=employee_id,\n-            current_user=current_user\n-        )\n-        return APIResponseHelper.success(\n-            data=shift,\n-            message=\"Clocked out successfully\"\n-        )\n-    except ValueError as e:\n-        return APIResponseHelper.error(\n-            message=str(e),\n-            status_code=400\n-        )\n-    except Exception as e:\n-        return APIResponseHelper.error(\n-            message=f\"Failed to clock out: {str(e)}\",\n-            status_code=500\n-        )\n+            db=db, employee_id=employee_id, current_user=current_user\n+        )\n+        return APIResponseHelper.success(data=shift, message=\"Clocked out successfully\")\n+    except ValueError as e:\n+        return APIResponseHelper.error(message=str(e), status_code=400)\n+    except Exception as e:\n+        return APIResponseHelper.error(\n+            message=f\"Failed to clock out: {str(e)}\", status_code=500\n+        )\n+\n \n @router.get(\"/{employee_id}/shifts\", response_model=List[ShiftResponse])\n async def get_employee_shifts(\n     employee_id: int,\n-    start_date: Optional[date] = Query(None, description=\"Filter shifts from this date\"),\n+    start_date: Optional[date] = Query(\n+        None, description=\"Filter shifts from this date\"\n+    ),\n     end_date: Optional[date] = Query(None, description=\"Filter shifts to this date\"),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Get employee work shifts with optional date filtering\"\"\"\n     try:\n         shifts = employee_service.get_employee_shifts(\n             db=db,\n             employee_id=employee_id,\n             start_date=start_date,\n             end_date=end_date,\n-            current_user=current_user\n-        )\n-        return APIResponseHelper.success(\n-            data=shifts,\n-            message=f\"Retrieved {len(shifts)} shifts\"\n-        )\n-    except Exception as e:\n-        return APIResponseHelper.error(\n-            message=f\"Failed to retrieve shifts: {str(e)}\",\n-            status_code=500\n-        )\n+            current_user=current_user,\n+        )\n+        return APIResponseHelper.success(\n+            data=shifts, message=f\"Retrieved {len(shifts)} shifts\"\n+        )\n+    except Exception as e:\n+        return APIResponseHelper.error(\n+            message=f\"Failed to retrieve shifts: {str(e)}\", status_code=500\n+        )\n+\n \n # Performance Metrics Endpoints\n \n-@router.get(\"/{employee_id}/performance\", response_model=List[PerformanceMetricResponse])\n+\n+@router.get(\n+    \"/{employee_id}/performance\", response_model=List[PerformanceMetricResponse]\n+)\n async def get_employee_performance(\n     employee_id: int,\n-    start_date: Optional[date] = Query(None, description=\"Filter metrics from this date\"),\n+    start_date: Optional[date] = Query(\n+        None, description=\"Filter metrics from this date\"\n+    ),\n     end_date: Optional[date] = Query(None, description=\"Filter metrics to this date\"),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Get employee performance metrics\"\"\"\n     try:\n         metrics = employee_service.get_performance_metrics(\n             db=db,\n             employee_id=employee_id,\n             start_date=start_date,\n             end_date=end_date,\n-            current_user=current_user\n-        )\n-        return APIResponseHelper.success(\n-            data=metrics,\n-            message=f\"Retrieved {len(metrics)} performance metrics\"\n-        )\n-    except Exception as e:\n-        return APIResponseHelper.error(\n-            message=f\"Failed to retrieve performance metrics: {str(e)}\",\n-            status_code=500\n-        )\n+            current_user=current_user,\n+        )\n+        return APIResponseHelper.success(\n+            data=metrics, message=f\"Retrieved {len(metrics)} performance metrics\"\n+        )\n+    except Exception as e:\n+        return APIResponseHelper.error(\n+            message=f\"Failed to retrieve performance metrics: {str(e)}\", status_code=500\n+        )\n+\n \n # Bulk Operations for Restaurant Dashboard\n+\n \n @router.get(\"/restaurant/{restaurant_id}/summary\")\n async def get_restaurant_employee_summary(\n     restaurant_id: int,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Get employee summary for restaurant dashboard\"\"\"\n     try:\n         summary = employee_service.get_restaurant_employee_summary(\n-            db=db,\n-            restaurant_id=restaurant_id,\n-            current_user=current_user\n-        )\n-        return APIResponseHelper.success(\n-            data=summary,\n-            message=\"Employee summary retrieved successfully\"\n-        )\n-    except Exception as e:\n-        return APIResponseHelper.error(\n-            message=f\"Failed to retrieve employee summary: {str(e)}\",\n-            status_code=500\n-        )\n+            db=db, restaurant_id=restaurant_id, current_user=current_user\n+        )\n+        return APIResponseHelper.success(\n+            data=summary, message=\"Employee summary retrieved successfully\"\n+        )\n+    except Exception as e:\n+        return APIResponseHelper.error(\n+            message=f\"Failed to retrieve employee summary: {str(e)}\", status_code=500\n+        )\n+\n \n @router.get(\"/restaurant/{restaurant_id}/schedules/week\")\n async def get_weekly_schedule(\n     restaurant_id: int,\n     week_start: Optional[date] = Query(None, description=\"Start date of the week\"),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Get weekly schedule for all restaurant employees\"\"\"\n     try:\n         schedule = employee_service.get_weekly_schedule(\n             db=db,\n             restaurant_id=restaurant_id,\n             week_start=week_start,\n-            current_user=current_user\n-        )\n-        return APIResponseHelper.success(\n-            data=schedule,\n-            message=\"Weekly schedule retrieved successfully\"\n-        )\n-    except Exception as e:\n-        return APIResponseHelper.error(\n-            message=f\"Failed to retrieve weekly schedule: {str(e)}\",\n-            status_code=500\n-        )\n\\ No newline at end of file\n+            current_user=current_user,\n+        )\n+        return APIResponseHelper.success(\n+            data=schedule, message=\"Weekly schedule retrieved successfully\"\n+        )\n+    except Exception as e:\n+        return APIResponseHelper.error(\n+            message=f\"Failed to retrieve weekly schedule: {str(e)}\", status_code=500\n+        )\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/dashboard.py\t2025-08-02 21:56:58.984467+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/dashboard.py\t2025-08-02 22:36:02.637272+00:00\n@@ -9,45 +9,55 @@\n from sqlalchemy.orm import Session\n from sqlalchemy import and_, func, case\n from collections import defaultdict\n import json\n \n-from app.core.database import get_db, Restaurant, Order, Product, User, Customer, InventoryItem\n+from app.core.database import (\n+    get_db,\n+    Restaurant,\n+    Order,\n+    Product,\n+    User,\n+    Customer,\n+    InventoryItem,\n+)\n from app.core.exceptions import ValidationException\n from app.core.auth import get_current_user\n from app.core.redis_client import get_redis, RedisClient\n from app.core.responses import APIResponseHelper\n from app.services.activity_logger import ActivityLogger\n from app.middleware.rate_limit_middleware import limiter, PORTAL_DASHBOARD_RATE\n \n router = APIRouter()\n+\n \n @router.get(\"/analytics/dashboard/{restaurant_id}\")\n @limiter.limit(PORTAL_DASHBOARD_RATE)\n async def get_dashboard_metrics(\n     request: Request,\n     restaurant_id: str,\n     period: str = Query(\"today\", regex=\"^(today|week|month|year)$\"),\n     db: Session = Depends(get_db),\n     current_user: User = Depends(get_current_user),\n-    redis: RedisClient = Depends(get_redis)\n+    redis: RedisClient = Depends(get_redis),\n ):\n     \"\"\"Get aggregated dashboard metrics for a restaurant\"\"\"\n-    \n+\n     # Check permissions\n-    if current_user.role != 'platform_owner':\n+    if current_user.role != \"platform_owner\":\n         # Validate that user has access to the requested restaurant\n         from app.core.tenant_security import TenantSecurity\n+\n         await TenantSecurity.validate_restaurant_access(\n             user=current_user,\n             restaurant_id=restaurant_id,\n             operation=\"access\",\n             resource_type=\"dashboard\",\n             resource_id=None,\n-            db=db\n-        )\n-    \n+            db=db,\n+        )\n+\n     # Check cache\n     cache_key = f\"dashboard:{restaurant_id}:{period}\"\n     cached_data = await redis.get(cache_key)\n     if cached_data:\n         # Deserialize the cached JSON string\n@@ -56,44 +66,50 @@\n                 cached_data = json.loads(cached_data)\n             return APIResponseHelper.success(data=cached_data)\n         except json.JSONDecodeError:\n             # If cached data is invalid, continue to generate fresh data\n             await redis.delete(cache_key)\n-    \n+\n     # Log dashboard view\n     ActivityLogger.log_dashboard_view(\n         db=db,\n         user_id=str(current_user.id),\n         restaurant_id=restaurant_id,\n         dashboard_type=\"restaurant\",\n-        period=period\n-    )\n-    \n+        period=period,\n+    )\n+\n     # Calculate date range\n     end_date = datetime.utcnow()\n     if period == \"today\":\n-        start_date = datetime.utcnow().replace(hour=0, minute=0, second=0, microsecond=0)\n+        start_date = datetime.utcnow().replace(\n+            hour=0, minute=0, second=0, microsecond=0\n+        )\n     elif period == \"week\":\n         start_date = end_date - timedelta(days=7)\n     elif period == \"month\":\n         start_date = end_date - timedelta(days=30)\n     else:  # year\n         start_date = end_date - timedelta(days=365)\n-    \n+\n     # Get orders for period\n-    orders = db.query(Order).filter(\n-        Order.restaurant_id == restaurant_id,\n-        Order.created_at >= start_date,\n-        Order.created_at <= end_date,\n-        Order.status.in_(['completed', 'paid'])\n-    ).all()\n-    \n+    orders = (\n+        db.query(Order)\n+        .filter(\n+            Order.restaurant_id == restaurant_id,\n+            Order.created_at >= start_date,\n+            Order.created_at <= end_date,\n+            Order.status.in_([\"completed\", \"paid\"]),\n+        )\n+        .all()\n+    )\n+\n     # Calculate revenue metrics\n     total_revenue = sum(order.total_amount for order in orders)\n     total_orders = len(orders)\n     avg_order_value = total_revenue / total_orders if total_orders > 0 else 0\n-    \n+\n     # Get top products - TEMPORARILY DISABLED (OrderItem model not available)\n     top_products_query = []\n     # top_products_query = db.query(\n     #     Product.name,\n     #     func.sum(OrderItem.quantity).label('total_quantity'),\n@@ -108,115 +124,114 @@\n     #     Order.created_at <= end_date,\n     #     Order.status.in_(['completed', 'paid'])\n     # ).group_by(Product.id, Product.name).order_by(\n     #     func.sum(OrderItem.quantity).desc()\n     # ).limit(5).all()\n-    \n+\n     # Get staff metrics - using User model for employees\n-    active_staff = db.query(func.count(User.id)).filter(\n-        User.restaurant_id == restaurant_id,\n-        User.is_active == True,\n-        User.role.in_(['employee', 'manager', 'cashier', 'server'])  # Filter for staff roles\n-    ).scalar()\n-    \n+    active_staff = (\n+        db.query(func.count(User.id))\n+        .filter(\n+            User.restaurant_id == restaurant_id,\n+            User.is_active == True,\n+            User.role.in_(\n+                [\"employee\", \"manager\", \"cashier\", \"server\"]\n+            ),  # Filter for staff roles\n+        )\n+        .scalar()\n+    )\n+\n     # Get customer metrics\n-    unique_customers = db.query(func.count(func.distinct(Order.customer_id))).filter(\n-        Order.restaurant_id == restaurant_id,\n-        Order.created_at >= start_date,\n-        Order.created_at <= end_date\n-    ).scalar()\n-    \n+    unique_customers = (\n+        db.query(func.count(func.distinct(Order.customer_id)))\n+        .filter(\n+            Order.restaurant_id == restaurant_id,\n+            Order.created_at >= start_date,\n+            Order.created_at <= end_date,\n+        )\n+        .scalar()\n+    )\n+\n     # Get inventory alerts - using InventoryItem model\n-    low_stock_items = db.query(func.count(InventoryItem.id)).filter(\n-        InventoryItem.restaurant_id == restaurant_id,\n-        InventoryItem.current_quantity <= InventoryItem.reorder_level\n-    ).scalar()\n-    \n+    low_stock_items = (\n+        db.query(func.count(InventoryItem.id))\n+        .filter(\n+            InventoryItem.restaurant_id == restaurant_id,\n+            InventoryItem.current_quantity <= InventoryItem.reorder_level,\n+        )\n+        .scalar()\n+    )\n+\n     # Calculate hourly distribution for today\n     hourly_sales = {}\n     if period == \"today\":\n         for order in orders:\n             hour = order.created_at.hour\n             if hour not in hourly_sales:\n                 hourly_sales[hour] = {\"count\": 0, \"revenue\": 0}\n             hourly_sales[hour][\"count\"] += 1\n             hourly_sales[hour][\"revenue\"] += float(order.total_amount)\n-    \n+\n     # Build response\n     dashboard_data = {\n         \"period\": period,\n         \"start_date\": start_date.isoformat(),\n         \"end_date\": end_date.isoformat(),\n         \"revenue\": {\n             \"total\": float(total_revenue),\n             \"orders\": total_orders,\n             \"average_order\": float(avg_order_value),\n-            \"currency\": \"GBP\"\n+            \"currency\": \"GBP\",\n         },\n         \"orders\": {\n             \"total\": total_orders,\n-            \"completed\": sum(1 for o in orders if o.status == 'completed'),\n-            \"pending\": db.query(func.count(Order.id)).filter(\n-                Order.restaurant_id == restaurant_id,\n-                Order.status == 'pending'\n-            ).scalar()\n+            \"completed\": sum(1 for o in orders if o.status == \"completed\"),\n+            \"pending\": db.query(func.count(Order.id))\n+            .filter(Order.restaurant_id == restaurant_id, Order.status == \"pending\")\n+            .scalar(),\n         },\n         \"products\": {\n             \"top_selling\": [\n-                {\n-                    \"name\": prod[0],\n-                    \"quantity\": int(prod[1]),\n-                    \"revenue\": float(prod[2])\n-                }\n+                {\"name\": prod[0], \"quantity\": int(prod[1]), \"revenue\": float(prod[2])}\n                 for prod in top_products_query\n             ]\n         },\n         \"customers\": {\n             \"unique\": unique_customers,\n-            \"new\": unique_customers  # Simplified for now\n-        },\n-        \"staff\": {\n-            \"active\": active_staff,\n-            \"on_duty\": 0  # Would need shift data\n-        },\n-        \"inventory\": {\n-            \"low_stock_alerts\": low_stock_items\n-        }\n+            \"new\": unique_customers,  # Simplified for now\n+        },\n+        \"staff\": {\"active\": active_staff, \"on_duty\": 0},  # Would need shift data\n+        \"inventory\": {\"low_stock_alerts\": low_stock_items},\n     }\n-    \n+\n     if hourly_sales:\n         dashboard_data[\"hourly_distribution\"] = [\n-            {\n-                \"hour\": hour,\n-                \"orders\": data[\"count\"],\n-                \"revenue\": data[\"revenue\"]\n-            }\n+            {\"hour\": hour, \"orders\": data[\"count\"], \"revenue\": data[\"revenue\"]}\n             for hour, data in sorted(hourly_sales.items())\n         ]\n-    \n+\n     # Cache for 5 minutes\n     await redis.set(cache_key, dashboard_data, expire=300)\n-    \n+\n     return APIResponseHelper.success(\n-        data=dashboard_data,\n-        message=\"Dashboard metrics retrieved successfully\"\n+        data=dashboard_data, message=\"Dashboard metrics retrieved successfully\"\n     )\n \n \n @router.get(\"/analytics/platform-dashboard\")\n async def get_platform_dashboard(\n     period: str = Query(\"today\", regex=\"^(today|week|month|year)$\"),\n     db: Session = Depends(get_db),\n     current_user: User = Depends(get_current_user),\n-    redis: RedisClient = Depends(get_redis)\n+    redis: RedisClient = Depends(get_redis),\n ):\n     \"\"\"Get aggregated metrics for all restaurants (platform owner only)\"\"\"\n-    \n+\n     # Check if user is platform owner\n-    if current_user.role != 'platform_owner':\n+    if current_user.role != \"platform_owner\":\n         raise ValidationException(message=\"Platform owner access required\")\n-    \n+\n     # Check cache\n     cache_key = f\"platform_dashboard:{period}\"\n     cached_data = await redis.get(cache_key)\n     if cached_data:\n         # Deserialize the cached JSON string\n@@ -225,93 +240,97 @@\n                 cached_data = json.loads(cached_data)\n             return APIResponseHelper.success(data=cached_data)\n         except json.JSONDecodeError:\n             # If cached data is invalid, continue to generate fresh data\n             await redis.delete(cache_key)\n-    \n+\n     # Calculate date range\n     end_date = datetime.utcnow()\n     if period == \"today\":\n-        start_date = datetime.utcnow().replace(hour=0, minute=0, second=0, microsecond=0)\n+        start_date = datetime.utcnow().replace(\n+            hour=0, minute=0, second=0, microsecond=0\n+        )\n     elif period == \"week\":\n         start_date = end_date - timedelta(days=7)\n     elif period == \"month\":\n         start_date = end_date - timedelta(days=30)\n     else:  # year\n         start_date = end_date - timedelta(days=365)\n-    \n+\n     # Get all active restaurants - platform owners can see all\n-    if current_user.role == 'platform_owner':\n-        restaurants = db.query(Restaurant).filter(\n-            Restaurant.is_active == True\n-        ).all()\n+    if current_user.role == \"platform_owner\":\n+        restaurants = db.query(Restaurant).filter(Restaurant.is_active == True).all()\n     else:\n         # Non-platform owners shouldn't access this endpoint\n         raise ValidationException(message=\"Platform owner access required\")\n-    \n+\n     # Aggregate metrics across all restaurants\n     total_revenue = 0\n     total_orders = 0\n     total_transactions = 0\n     restaurant_metrics = []\n-    \n+\n     for restaurant in restaurants:\n         # Get orders for this restaurant\n-        restaurant_orders = db.query(Order).filter(\n-            Order.restaurant_id == restaurant.id,\n-            Order.created_at >= start_date,\n-            Order.created_at <= end_date,\n-            Order.status.in_(['completed', 'paid'])\n-        ).all()\n-        \n+        restaurant_orders = (\n+            db.query(Order)\n+            .filter(\n+                Order.restaurant_id == restaurant.id,\n+                Order.created_at >= start_date,\n+                Order.created_at <= end_date,\n+                Order.status.in_([\"completed\", \"paid\"]),\n+            )\n+            .all()\n+        )\n+\n         restaurant_revenue = sum(order.total_amount for order in restaurant_orders)\n         restaurant_order_count = len(restaurant_orders)\n-        \n+\n         total_revenue += restaurant_revenue\n         total_orders += restaurant_order_count\n-        \n+\n         # Calculate platform fees (1% transaction fee)\n         platform_fee = restaurant_revenue * 0.01\n-        \n-        restaurant_metrics.append({\n-            \"id\": str(restaurant.id),\n-            \"name\": restaurant.name,\n-            \"revenue\": float(restaurant_revenue),\n-            \"orders\": restaurant_order_count,\n-            \"platform_fee\": float(platform_fee),\n-            \"subscription_plan\": getattr(restaurant, 'subscription_plan', 'alpha'),\n-            \"status\": \"active\" if restaurant.is_active else \"inactive\"\n-        })\n-    \n+\n+        restaurant_metrics.append(\n+            {\n+                \"id\": str(restaurant.id),\n+                \"name\": restaurant.name,\n+                \"revenue\": float(restaurant_revenue),\n+                \"orders\": restaurant_order_count,\n+                \"platform_fee\": float(platform_fee),\n+                \"subscription_plan\": getattr(restaurant, \"subscription_plan\", \"alpha\"),\n+                \"status\": \"active\" if restaurant.is_active else \"inactive\",\n+            }\n+        )\n+\n     # Get subscription distribution\n-    subscription_counts = db.query(\n-        Restaurant.subscription_plan,\n-        func.count(Restaurant.id).label('count')\n-    ).filter(\n-        Restaurant.is_active == True\n-    ).group_by(Restaurant.subscription_plan).all()\n-    \n-    subscription_distribution = {\n-        plan: count for plan, count in subscription_counts\n-    }\n-    \n+    subscription_counts = (\n+        db.query(Restaurant.subscription_plan, func.count(Restaurant.id).label(\"count\"))\n+        .filter(Restaurant.is_active == True)\n+        .group_by(Restaurant.subscription_plan)\n+        .all()\n+    )\n+\n+    subscription_distribution = {plan: count for plan, count in subscription_counts}\n+\n     # Calculate platform revenue\n     # Subscription fees (monthly) in GBP\n     subscription_revenue = {\n-        'alpha': 0,  # \u00a30/month + 1% transaction fee\n-        'beta': 49,  # \u00a349/month + 1% transaction fee\n-        'omega': 119  # \u00a3119/month + 1% transaction fee\n+        \"alpha\": 0,  # \u00a30/month + 1% transaction fee\n+        \"beta\": 49,  # \u00a349/month + 1% transaction fee\n+        \"omega\": 119,  # \u00a3119/month + 1% transaction fee\n     }\n-    \n+\n     monthly_subscription_revenue = sum(\n         subscription_revenue.get(plan, 0) * count\n         for plan, count in subscription_distribution.items()\n     )\n-    \n+\n     # Transaction fees (1% of all transactions)\n     transaction_fee_revenue = total_revenue * 0.01\n-    \n+\n     # Build response\n     platform_data = {\n         \"period\": period,\n         \"start_date\": start_date.isoformat(),\n         \"end_date\": end_date.isoformat(),\n@@ -321,122 +340,130 @@\n             \"total_revenue\": float(total_revenue),\n             \"total_orders\": total_orders,\n             \"platform_revenue\": {\n                 \"transaction_fees\": float(transaction_fee_revenue),\n                 \"subscription_fees\": float(monthly_subscription_revenue),\n-                \"total\": float(transaction_fee_revenue + monthly_subscription_revenue)\n-            }\n+                \"total\": float(transaction_fee_revenue + monthly_subscription_revenue),\n+            },\n         },\n         \"subscriptions\": {\n             \"distribution\": subscription_distribution,\n-            \"monthly_revenue\": float(monthly_subscription_revenue)\n+            \"monthly_revenue\": float(monthly_subscription_revenue),\n         },\n         \"top_restaurants\": sorted(\n-            restaurant_metrics,\n-            key=lambda x: x[\"revenue\"],\n-            reverse=True\n+            restaurant_metrics, key=lambda x: x[\"revenue\"], reverse=True\n         )[:10],\n         \"growth_metrics\": {\n-            \"new_restaurants\": db.query(func.count(Restaurant.id)).filter(\n-                Restaurant.created_at >= start_date,\n-                Restaurant.created_at <= end_date\n-            ).scalar(),\n-            \"churned_restaurants\": 0  # Would need historical data\n-        }\n+            \"new_restaurants\": db.query(func.count(Restaurant.id))\n+            .filter(\n+                Restaurant.created_at >= start_date, Restaurant.created_at <= end_date\n+            )\n+            .scalar(),\n+            \"churned_restaurants\": 0,  # Would need historical data\n+        },\n     }\n-    \n+\n     # Cache for 10 minutes\n     await redis.set(cache_key, platform_data, expire=600)\n-    \n+\n     return APIResponseHelper.success(\n-        data=platform_data,\n-        message=\"Platform dashboard metrics retrieved successfully\"\n+        data=platform_data, message=\"Platform dashboard metrics retrieved successfully\"\n     )\n \n \n @router.get(\"/analytics/restaurant-comparison\")\n async def get_restaurant_comparison(\n     period: str = Query(\"month\", regex=\"^(week|month|year)$\"),\n     metric: str = Query(\"revenue\", regex=\"^(revenue|orders|customers)$\"),\n     limit: int = Query(10, ge=1, le=50),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Compare restaurants by various metrics (platform owner only)\"\"\"\n-    \n+\n     # Check if user is platform owner\n-    if current_user.role != 'platform_owner':\n+    if current_user.role != \"platform_owner\":\n         raise ValidationException(message=\"Platform owner access required\")\n-    \n+\n     # Calculate date range\n     end_date = datetime.utcnow()\n     if period == \"week\":\n         start_date = end_date - timedelta(days=7)\n     elif period == \"month\":\n         start_date = end_date - timedelta(days=30)\n     else:  # year\n         start_date = end_date - timedelta(days=365)\n-    \n+\n     # Build query based on metric\n     if metric == \"revenue\":\n-        results = db.query(\n-            Restaurant.id,\n-            Restaurant.name,\n-            func.sum(Order.total_amount).label('value')\n-        ).join(\n-            Order, Restaurant.id == Order.restaurant_id\n-        ).filter(\n-            Order.created_at >= start_date,\n-            Order.created_at <= end_date,\n-            Order.status.in_(['completed', 'paid'])\n-        ).group_by(Restaurant.id, Restaurant.name).order_by(\n-            func.sum(Order.total_amount).desc()\n-        ).limit(limit).all()\n-        \n+        results = (\n+            db.query(\n+                Restaurant.id,\n+                Restaurant.name,\n+                func.sum(Order.total_amount).label(\"value\"),\n+            )\n+            .join(Order, Restaurant.id == Order.restaurant_id)\n+            .filter(\n+                Order.created_at >= start_date,\n+                Order.created_at <= end_date,\n+                Order.status.in_([\"completed\", \"paid\"]),\n+            )\n+            .group_by(Restaurant.id, Restaurant.name)\n+            .order_by(func.sum(Order.total_amount).desc())\n+            .limit(limit)\n+            .all()\n+        )\n+\n     elif metric == \"orders\":\n-        results = db.query(\n-            Restaurant.id,\n-            Restaurant.name,\n-            func.count(Order.id).label('value')\n-        ).join(\n-            Order, Restaurant.id == Order.restaurant_id\n-        ).filter(\n-            Order.created_at >= start_date,\n-            Order.created_at <= end_date,\n-            Order.status.in_(['completed', 'paid'])\n-        ).group_by(Restaurant.id, Restaurant.name).order_by(\n-            func.count(Order.id).desc()\n-        ).limit(limit).all()\n-        \n+        results = (\n+            db.query(\n+                Restaurant.id, Restaurant.name, func.count(Order.id).label(\"value\")\n+            )\n+            .join(Order, Restaurant.id == Order.restaurant_id)\n+            .filter(\n+                Order.created_at >= start_date,\n+                Order.created_at <= end_date,\n+                Order.status.in_([\"completed\", \"paid\"]),\n+            )\n+            .group_by(Restaurant.id, Restaurant.name)\n+            .order_by(func.count(Order.id).desc())\n+            .limit(limit)\n+            .all()\n+        )\n+\n     else:  # customers\n-        results = db.query(\n-            Restaurant.id,\n-            Restaurant.name,\n-            func.count(func.distinct(Order.customer_id)).label('value')\n-        ).join(\n-            Order, Restaurant.id == Order.restaurant_id\n-        ).filter(\n-            Order.created_at >= start_date,\n-            Order.created_at <= end_date,\n-            Order.customer_id.isnot(None)\n-        ).group_by(Restaurant.id, Restaurant.name).order_by(\n-            func.count(func.distinct(Order.customer_id)).desc()\n-        ).limit(limit).all()\n-    \n+        results = (\n+            db.query(\n+                Restaurant.id,\n+                Restaurant.name,\n+                func.count(func.distinct(Order.customer_id)).label(\"value\"),\n+            )\n+            .join(Order, Restaurant.id == Order.restaurant_id)\n+            .filter(\n+                Order.created_at >= start_date,\n+                Order.created_at <= end_date,\n+                Order.customer_id.isnot(None),\n+            )\n+            .group_by(Restaurant.id, Restaurant.name)\n+            .order_by(func.count(func.distinct(Order.customer_id)).desc())\n+            .limit(limit)\n+            .all()\n+        )\n+\n     # Format results\n     comparison_data = {\n         \"period\": period,\n         \"metric\": metric,\n         \"data\": [\n             {\n                 \"restaurant_id\": str(r[0]),\n                 \"restaurant_name\": r[1],\n-                \"value\": float(r[2]) if metric == \"revenue\" else int(r[2])\n+                \"value\": float(r[2]) if metric == \"revenue\" else int(r[2]),\n             }\n             for r in results\n-        ]\n+        ],\n     }\n-    \n+\n     return APIResponseHelper.success(\n         data=comparison_data,\n-        message=f\"Restaurant comparison by {metric} retrieved successfully\"\n-    )\n\\ No newline at end of file\n+        message=f\"Restaurant comparison by {metric} retrieved successfully\",\n+    )\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/customers.py\t2025-08-02 21:56:58.984288+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/customers.py\t2025-08-02 22:36:02.665747+00:00\n@@ -11,30 +11,38 @@\n \n from app.core.database import get_db, Customer, Order, User\n from app.core.auth import get_current_user\n from app.core.redis_client import get_redis, RedisClient\n from app.core.responses import APIResponseHelper\n-from app.core.exceptions import ConflictException, InventoryException, ResourceNotFoundException, ValidationException\n+from app.core.exceptions import (\n+    ConflictException,\n+    InventoryException,\n+    ResourceNotFoundException,\n+    ValidationException,\n+)\n from app.core.security_utils import sanitize_sql_like_pattern, sanitize_search_term\n from app.schemas.search_schemas import CustomerSearchRequest\n \n router = APIRouter()\n+\n \n # Pydantic models\n class CustomerCreate(BaseModel):\n     email: Optional[EmailStr] = None\n     phone: Optional[str] = None\n     first_name: str\n     last_name: str\n     preferences: dict = {}\n \n+\n class CustomerUpdate(BaseModel):\n     email: Optional[EmailStr] = None\n     phone: Optional[str] = None\n     first_name: Optional[str] = None\n     last_name: Optional[str] = None\n     preferences: Optional[dict] = None\n+\n \n class CustomerResponse(BaseModel):\n     id: str\n     email: Optional[str]\n     phone: Optional[str]\n@@ -46,87 +54,99 @@\n     preferences: dict\n     created_at: datetime\n     updated_at: Optional[datetime]\n     last_visit: Optional[datetime]\n \n+\n class CustomerBasicInfo(BaseModel):\n     id: str\n     name: str\n     email: Optional[EmailStr] = None\n+\n \n class CustomerStats(BaseModel):\n     total_customers: int\n     new_this_month: int\n     average_spend: float\n     top_customers: List[CustomerResponse]\n+\n \n class LoyaltyTransaction(BaseModel):\n     customer_id: str\n     points: int\n     transaction_type: str  # earned, redeemed, adjusted\n     description: str\n     order_id: Optional[str] = None\n \n+\n @router.get(\"/\", response_model=List[CustomerResponse])\n async def get_customers(\n     restaurant_id: Optional[str] = Query(None),\n     search: Optional[str] = Query(None),\n     limit: int = Query(50, le=100),\n     offset: int = Query(0),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Get customers with search and pagination\"\"\"\n-    \n+\n     # Use current user's restaurant context\n-    user_restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n+    user_restaurant_id = (\n+        current_user.current_restaurant_id or current_user.restaurant_id\n+    )\n     if not user_restaurant_id:\n-        raise ValidationException(message=\"User must be assigned to a restaurant\", field=\"user\")\n-    \n+        raise ValidationException(\n+            message=\"User must be assigned to a restaurant\", field=\"user\"\n+        )\n+\n     # Use provided restaurant_id or fallback to user's current restaurant\n     if not restaurant_id:\n         restaurant_id = str(user_restaurant_id)\n     else:\n         # Validate that user has access to the requested restaurant\n         from app.core.tenant_security import TenantSecurity\n+\n         await TenantSecurity.validate_restaurant_access(\n             user=current_user,\n             restaurant_id=restaurant_id,\n             operation=\"access\",\n             resource_type=\"customers\",\n             resource_id=None,\n-            db=db\n-        )\n-    \n+            db=db,\n+        )\n+\n     query = db.query(Customer).filter(Customer.restaurant_id == restaurant_id)\n-    \n+\n     if search:\n         search_pattern = f\"%{search}%\"\n         query = query.filter(\n             or_(\n                 Customer.first_name.ilike(search_pattern),\n                 Customer.last_name.ilike(search_pattern),\n                 Customer.email.ilike(search_pattern),\n-                Customer.phone.ilike(search_pattern)\n+                Customer.phone.ilike(search_pattern),\n             )\n         )\n-    \n-    customers = query.order_by(desc(Customer.total_spent)).offset(offset).limit(limit).all()\n-    \n+\n+    customers = (\n+        query.order_by(desc(Customer.total_spent)).offset(offset).limit(limit).all()\n+    )\n+\n     # Get last visit dates\n     customer_ids = [customer.id for customer in customers]\n     last_visits = {}\n     if customer_ids:\n-        last_visit_query = db.query(\n-            Customer.id,\n-            func.max(Order.created_at).label('last_visit')\n-        ).join(Order, Customer.id == Order.customer_id).filter(\n-            Customer.id.in_(customer_ids)\n-        ).group_by(Customer.id).all()\n-        \n+        last_visit_query = (\n+            db.query(Customer.id, func.max(Order.created_at).label(\"last_visit\"))\n+            .join(Order, Customer.id == Order.customer_id)\n+            .filter(Customer.id.in_(customer_ids))\n+            .group_by(Customer.id)\n+            .all()\n+        )\n+\n         last_visits = {str(cv.id): cv.last_visit for cv in last_visit_query}\n-    \n+\n     return [\n         CustomerResponse(\n             id=str(customer.id),\n             email=customer.email,\n             phone=customer.phone,\n@@ -136,73 +156,93 @@\n             total_spent=customer.total_spent,\n             visit_count=customer.visit_count,\n             preferences=customer.preferences,\n             created_at=customer.created_at,\n             updated_at=customer.updated_at,\n-            last_visit=last_visits.get(str(customer.id))\n+            last_visit=last_visits.get(str(customer.id)),\n         )\n         for customer in customers\n     ]\n+\n \n @router.get(\"/stats\", response_model=CustomerStats)\n async def get_customer_stats(\n     restaurant_id: Optional[str] = Query(None),\n     db: Session = Depends(get_db),\n     current_user: User = Depends(get_current_user),\n-    redis: RedisClient = Depends(get_redis)\n+    redis: RedisClient = Depends(get_redis),\n ):\n     \"\"\"Get customer statistics\"\"\"\n-    \n+\n     # Use current user's restaurant context\n-    user_restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n+    user_restaurant_id = (\n+        current_user.current_restaurant_id or current_user.restaurant_id\n+    )\n     if not user_restaurant_id:\n-        raise ValidationException(message=\"User must be assigned to a restaurant\", field=\"user\")\n-    \n+        raise ValidationException(\n+            message=\"User must be assigned to a restaurant\", field=\"user\"\n+        )\n+\n     # Use provided restaurant_id or fallback to user's current restaurant\n     if not restaurant_id:\n         restaurant_id = str(user_restaurant_id)\n     else:\n         # Validate that user has access to the requested restaurant\n         from app.core.tenant_security import TenantSecurity\n+\n         await TenantSecurity.validate_restaurant_access(\n             user=current_user,\n             restaurant_id=restaurant_id,\n             operation=\"access\",\n             resource_type=\"customers\",\n             resource_id=None,\n-            db=db\n-        )\n-    \n+            db=db,\n+        )\n+\n     # Check cache first\n     cache_key = f\"customer_stats:{restaurant_id}\"\n     cached_stats = await redis.get(cache_key)\n     if cached_stats:\n         return cached_stats\n-    \n+\n     # Total customers\n-    total_customers = db.query(Customer).filter(Customer.restaurant_id == restaurant_id).count()\n-    \n+    total_customers = (\n+        db.query(Customer).filter(Customer.restaurant_id == restaurant_id).count()\n+    )\n+\n     # New customers this month\n-    month_start = datetime.now().replace(day=1, hour=0, minute=0, second=0, microsecond=0)\n-    new_this_month = db.query(Customer).filter(\n-        and_(\n-            Customer.restaurant_id == restaurant_id,\n-            Customer.created_at >= month_start\n-        )\n-    ).count()\n-    \n+    month_start = datetime.now().replace(\n+        day=1, hour=0, minute=0, second=0, microsecond=0\n+    )\n+    new_this_month = (\n+        db.query(Customer)\n+        .filter(\n+            and_(\n+                Customer.restaurant_id == restaurant_id,\n+                Customer.created_at >= month_start,\n+            )\n+        )\n+        .count()\n+    )\n+\n     # Average spend\n-    avg_spend_result = db.query(func.avg(Customer.total_spent)).filter(\n-        Customer.restaurant_id == restaurant_id\n-    ).scalar()\n+    avg_spend_result = (\n+        db.query(func.avg(Customer.total_spent))\n+        .filter(Customer.restaurant_id == restaurant_id)\n+        .scalar()\n+    )\n     average_spend = float(avg_spend_result or 0)\n-    \n+\n     # Top 5 customers\n-    top_customers = db.query(Customer).filter(\n-        Customer.restaurant_id == restaurant_id\n-    ).order_by(desc(Customer.total_spent)).limit(5).all()\n-    \n+    top_customers = (\n+        db.query(Customer)\n+        .filter(Customer.restaurant_id == restaurant_id)\n+        .order_by(desc(Customer.total_spent))\n+        .limit(5)\n+        .all()\n+    )\n+\n     result = CustomerStats(\n         total_customers=total_customers,\n         new_this_month=new_this_month,\n         average_spend=round(average_spend, 2),\n         top_customers=[\n@@ -216,88 +256,102 @@\n                 total_spent=customer.total_spent,\n                 visit_count=customer.visit_count,\n                 preferences=customer.preferences,\n                 created_at=customer.created_at,\n                 updated_at=customer.updated_at,\n-                last_visit=None  # Not needed for stats\n+                last_visit=None,  # Not needed for stats\n             )\n             for customer in top_customers\n-        ]\n-    )\n-    \n+        ],\n+    )\n+\n     # Cache for 5 minutes\n     await redis.set(cache_key, result.dict(), expire=300)\n-    \n+\n     return result\n+\n \n @router.post(\"/\", response_model=CustomerResponse)\n async def create_customer(\n     customer_data: CustomerCreate,\n     restaurant_id: Optional[str] = Query(None),\n     db: Session = Depends(get_db),\n     current_user: User = Depends(get_current_user),\n-    redis: RedisClient = Depends(get_redis)\n+    redis: RedisClient = Depends(get_redis),\n ):\n     \"\"\"Create a new customer\"\"\"\n-    \n+\n     # Use current user's restaurant context\n-    user_restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n+    user_restaurant_id = (\n+        current_user.current_restaurant_id or current_user.restaurant_id\n+    )\n     if not user_restaurant_id:\n-        raise ValidationException(message=\"User must be assigned to a restaurant\", field=\"user\")\n-    \n+        raise ValidationException(\n+            message=\"User must be assigned to a restaurant\", field=\"user\"\n+        )\n+\n     # Use provided restaurant_id or fallback to user's current restaurant\n     if not restaurant_id:\n         restaurant_id = str(user_restaurant_id)\n     else:\n         # Validate that user has access to the requested restaurant\n         from app.core.tenant_security import TenantSecurity\n+\n         await TenantSecurity.validate_restaurant_access(\n             user=current_user,\n             restaurant_id=restaurant_id,\n             operation=\"create\",\n             resource_type=\"customers\",\n             resource_id=None,\n-            db=db\n-        )\n-    \n+            db=db,\n+        )\n+\n     # Check if customer already exists (by email or phone)\n     existing_customer = None\n     if customer_data.email:\n-        existing_customer = db.query(Customer).filter(\n-            and_(\n-                Customer.restaurant_id == restaurant_id,\n-                Customer.email == customer_data.email\n+        existing_customer = (\n+            db.query(Customer)\n+            .filter(\n+                and_(\n+                    Customer.restaurant_id == restaurant_id,\n+                    Customer.email == customer_data.email,\n+                )\n             )\n-        ).first()\n-    \n+            .first()\n+        )\n+\n     if not existing_customer and customer_data.phone:\n-        existing_customer = db.query(Customer).filter(\n-            and_(\n-                Customer.restaurant_id == restaurant_id,\n-                Customer.phone == customer_data.phone\n+        existing_customer = (\n+            db.query(Customer)\n+            .filter(\n+                and_(\n+                    Customer.restaurant_id == restaurant_id,\n+                    Customer.phone == customer_data.phone,\n+                )\n             )\n-        ).first()\n-    \n+            .first()\n+        )\n+\n     if existing_customer:\n         raise ConflictException(message=\"Customer already exists\")\n-    \n+\n     new_customer = Customer(\n         restaurant_id=restaurant_id,\n         email=customer_data.email,\n         phone=customer_data.phone,\n         first_name=customer_data.first_name,\n         last_name=customer_data.last_name,\n-        preferences=customer_data.preferences\n-    )\n-    \n+        preferences=customer_data.preferences,\n+    )\n+\n     db.add(new_customer)\n     db.commit()\n     db.refresh(new_customer)\n-    \n+\n     # Clear customer stats cache\n     await redis.delete(f\"customer_stats:{restaurant_id}\")\n-    \n+\n     return CustomerResponse(\n         id=str(new_customer.id),\n         email=new_customer.email,\n         phone=new_customer.phone,\n         first_name=new_customer.first_name,\n@@ -306,41 +360,46 @@\n         total_spent=new_customer.total_spent,\n         visit_count=new_customer.visit_count,\n         preferences=new_customer.preferences,\n         created_at=new_customer.created_at,\n         updated_at=new_customer.updated_at,\n-        last_visit=None\n-    )\n+        last_visit=None,\n+    )\n+\n \n @router.get(\"/{customer_id}\", response_model=CustomerResponse)\n async def get_customer(\n     customer_id: str,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Get a specific customer\"\"\"\n-    \n+\n     customer = db.query(Customer).filter(Customer.id == customer_id).first()\n     if not customer:\n         raise ResourceNotFoundException(resource=\"Customer\")\n-    \n+\n     # Verify tenant access\n     from app.core.tenant_security import TenantSecurity\n+\n     await TenantSecurity.validate_restaurant_access(\n         user=current_user,\n         restaurant_id=str(customer.restaurant_id),\n         operation=\"access\",\n         resource_type=\"customers\",\n         resource_id=customer_id,\n-        db=db\n-    )\n-    \n+        db=db,\n+    )\n+\n     # Get last visit\n-    last_order = db.query(Order).filter(\n-        Order.customer_id == customer_id\n-    ).order_by(desc(Order.created_at)).first()\n-    \n+    last_order = (\n+        db.query(Order)\n+        .filter(Order.customer_id == customer_id)\n+        .order_by(desc(Order.created_at))\n+        .first()\n+    )\n+\n     return CustomerResponse(\n         id=str(customer.id),\n         email=customer.email,\n         phone=customer.phone,\n         first_name=customer.first_name,\n@@ -349,53 +408,55 @@\n         total_spent=customer.total_spent,\n         visit_count=customer.visit_count,\n         preferences=customer.preferences,\n         created_at=customer.created_at,\n         updated_at=customer.updated_at,\n-        last_visit=last_order.created_at if last_order else None\n-    )\n+        last_visit=last_order.created_at if last_order else None,\n+    )\n+\n \n @router.put(\"/{customer_id}\", response_model=CustomerResponse)\n async def update_customer(\n     customer_id: str,\n     customer_data: CustomerUpdate,\n     db: Session = Depends(get_db),\n     current_user: User = Depends(get_current_user),\n-    redis: RedisClient = Depends(get_redis)\n+    redis: RedisClient = Depends(get_redis),\n ):\n     \"\"\"Update customer information\"\"\"\n-    \n+\n     customer = db.query(Customer).filter(Customer.id == customer_id).first()\n     if not customer:\n         raise ResourceNotFoundException(resource=\"Customer\")\n-    \n+\n     # Verify tenant access\n     from app.core.tenant_security import TenantSecurity\n+\n     await TenantSecurity.validate_restaurant_access(\n         user=current_user,\n         restaurant_id=str(customer.restaurant_id),\n         operation=\"modify\",\n         resource_type=\"customers\",\n         resource_id=customer_id,\n-        db=db\n-    )\n-    \n+        db=db,\n+    )\n+\n     # Update fields if provided - whitelist allowed fields for security\n-    ALLOWED_UPDATE_FIELDS = {'email', 'phone', 'first_name', 'last_name', 'preferences'}\n+    ALLOWED_UPDATE_FIELDS = {\"email\", \"phone\", \"first_name\", \"last_name\", \"preferences\"}\n     update_data = customer_data.dict(exclude_unset=True)\n     for field, value in update_data.items():\n         if field in ALLOWED_UPDATE_FIELDS and hasattr(customer, field):\n             setattr(customer, field, value)\n-    \n+\n     customer.updated_at = datetime.utcnow()\n     db.commit()\n     db.refresh(customer)\n-    \n+\n     # Clear customer stats cache\n     restaurant_id = str(customer.restaurant_id)\n     await redis.delete(f\"customer_stats:{restaurant_id}\")\n-    \n+\n     return CustomerResponse(\n         id=str(customer.id),\n         email=customer.email,\n         phone=customer.phone,\n         first_name=customer.first_name,\n@@ -404,180 +465,197 @@\n         total_spent=customer.total_spent,\n         visit_count=customer.visit_count,\n         preferences=customer.preferences,\n         created_at=customer.created_at,\n         updated_at=customer.updated_at,\n-        last_visit=None\n-    )\n+        last_visit=None,\n+    )\n+\n \n @router.post(\"/{customer_id}/loyalty\", response_model=dict)\n async def update_loyalty_points(\n     customer_id: str,\n     loyalty_data: LoyaltyTransaction,\n     db: Session = Depends(get_db),\n     current_user: User = Depends(get_current_user),\n-    redis: RedisClient = Depends(get_redis)\n+    redis: RedisClient = Depends(get_redis),\n ):\n     \"\"\"Update customer loyalty points\"\"\"\n-    \n+\n     customer = db.query(Customer).filter(Customer.id == customer_id).first()\n     if not customer:\n         raise ResourceNotFoundException(resource=\"Customer\")\n-    \n+\n     # Verify tenant access\n     from app.core.tenant_security import TenantSecurity\n+\n     await TenantSecurity.validate_restaurant_access(\n         user=current_user,\n         restaurant_id=str(customer.restaurant_id),\n         operation=\"modify\",\n         resource_type=\"customers\",\n         resource_id=customer_id,\n-        db=db\n-    )\n-    \n+        db=db,\n+    )\n+\n     # Validate transaction\n-    if loyalty_data.transaction_type == \"redeemed\" and customer.loyalty_points < abs(loyalty_data.points):\n+    if loyalty_data.transaction_type == \"redeemed\" and customer.loyalty_points < abs(\n+        loyalty_data.points\n+    ):\n         raise InventoryException(message=\"Insufficient loyalty points\")\n-    \n+\n     # Update points\n     if loyalty_data.transaction_type == \"earned\":\n         customer.loyalty_points += abs(loyalty_data.points)\n     elif loyalty_data.transaction_type == \"redeemed\":\n         customer.loyalty_points -= abs(loyalty_data.points)\n     elif loyalty_data.transaction_type == \"adjusted\":\n         customer.loyalty_points = abs(loyalty_data.points)\n-    \n+\n     customer.updated_at = datetime.utcnow()\n     db.commit()\n-    \n+\n     # Clear customer stats cache\n     restaurant_id = str(customer.restaurant_id)\n     await redis.delete(f\"customer_stats:{restaurant_id}\")\n-    \n+\n     return {\n         \"message\": f\"Loyalty points {loyalty_data.transaction_type}\",\n         \"new_balance\": customer.loyalty_points,\n         \"transaction\": {\n             \"type\": loyalty_data.transaction_type,\n             \"points\": loyalty_data.points,\n-            \"description\": loyalty_data.description\n-        }\n+            \"description\": loyalty_data.description,\n+        },\n     }\n+\n \n @router.get(\"/{customer_id}/orders\")\n async def get_customer_orders(\n     customer_id: str,\n     limit: int = Query(20, le=50),\n     offset: int = Query(0),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Get customer's order history\"\"\"\n-    \n+\n     customer = db.query(Customer).filter(Customer.id == customer_id).first()\n     if not customer:\n         raise ResourceNotFoundException(resource=\"Customer\")\n-    \n+\n     # Verify tenant access\n     from app.core.tenant_security import TenantSecurity\n+\n     await TenantSecurity.validate_restaurant_access(\n         user=current_user,\n         restaurant_id=str(customer.restaurant_id),\n         operation=\"access\",\n         resource_type=\"customers\",\n         resource_id=customer_id,\n-        db=db\n-    )\n-    \n-    orders = db.query(Order).filter(\n-        Order.customer_id == customer_id\n-    ).order_by(desc(Order.created_at)).offset(offset).limit(limit).all()\n-    \n+        db=db,\n+    )\n+\n+    orders = (\n+        db.query(Order)\n+        .filter(Order.customer_id == customer_id)\n+        .order_by(desc(Order.created_at))\n+        .offset(offset)\n+        .limit(limit)\n+        .all()\n+    )\n+\n     return [\n         {\n             \"id\": str(order.id),\n             \"order_number\": order.order_number,\n             \"status\": order.status,\n             \"total_amount\": order.total_amount,\n             \"payment_status\": order.payment_status,\n-            \"created_at\": order.created_at\n+            \"created_at\": order.created_at,\n         }\n         for order in orders\n     ]\n \n+\n @router.post(\"/search\")\n async def search_customers(\n     search_data: CustomerSearchRequest,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Advanced customer search with enhanced validation\"\"\"\n-    \n+\n     # Use current user's restaurant context\n-    user_restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n+    user_restaurant_id = (\n+        current_user.current_restaurant_id or current_user.restaurant_id\n+    )\n     if not user_restaurant_id:\n-        raise ValidationException(message=\"User must be assigned to a restaurant\", field=\"user\")\n-    \n+        raise ValidationException(\n+            message=\"User must be assigned to a restaurant\", field=\"user\"\n+        )\n+\n     # Use provided restaurant_id from search_data or fallback to user's current restaurant\n     if not search_data.restaurant_id:\n         restaurant_id = str(user_restaurant_id)\n     else:\n         restaurant_id = search_data.restaurant_id\n         # Validate that user has access to the requested restaurant\n         from app.core.tenant_security import TenantSecurity\n+\n         await TenantSecurity.validate_restaurant_access(\n             user=current_user,\n             restaurant_id=restaurant_id,\n             operation=\"access\",\n             resource_type=\"customers\",\n             resource_id=None,\n-            db=db\n-        )\n-    \n+            db=db,\n+        )\n+\n     query = db.query(Customer).filter(Customer.restaurant_id == restaurant_id)\n-    \n+\n     # All search inputs are already validated and sanitized by Pydantic schema\n     if search_data.email:\n         # Email already sanitized by CustomerSearchRequest validator\n         query = query.filter(Customer.email.ilike(f\"%{search_data.email}%\"))\n-    \n+\n     if search_data.phone:\n         # Phone already sanitized by CustomerSearchRequest validator\n         query = query.filter(Customer.phone.ilike(f\"%{search_data.phone}%\"))\n-    \n+\n     if search_data.name:\n         # Name already sanitized by CustomerSearchRequest validator\n         name_pattern = f\"%{search_data.name}%\"\n         query = query.filter(\n             or_(\n                 Customer.first_name.ilike(name_pattern),\n-                Customer.last_name.ilike(name_pattern)\n+                Customer.last_name.ilike(name_pattern),\n             )\n         )\n-    \n+\n     if search_data.min_spent is not None:\n         query = query.filter(Customer.total_spent >= search_data.min_spent)\n-    \n+\n     # Apply sorting - sort_by is already validated against whitelist\n     if search_data.sort_by:\n         order_func = desc if search_data.sort_order == \"desc\" else lambda x: x\n         sort_column = getattr(Customer, search_data.sort_by)\n         query = query.order_by(order_func(sort_column))\n     else:\n         query = query.order_by(desc(Customer.total_spent))\n-    \n+\n     # Apply pagination\n     offset = (search_data.page - 1) * search_data.limit\n     customers = query.offset(offset).limit(search_data.limit).all()\n-    \n+\n     return [\n         {\n             \"id\": str(customer.id),\n             \"name\": f\"{customer.first_name} {customer.last_name}\",\n             \"email\": customer.email,\n             \"phone\": customer.phone,\n             \"loyalty_points\": customer.loyalty_points,\n             \"total_spent\": customer.total_spent,\n-            \"visit_count\": customer.visit_count\n+            \"visit_count\": customer.visit_count,\n         }\n         for customer in customers\n-    ]\n\\ No newline at end of file\n+    ]\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/menu.py\t2025-08-02 21:56:58.985906+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/menu.py\t2025-08-02 22:36:02.704584+00:00\n@@ -19,232 +19,255 @@\n from app.core.cache_service import cached\n \n router = APIRouter()\n logger = logging.getLogger(__name__)\n \n+\n def format_menu_item(product, category_name=None):\n     \"\"\"Format product as menu item with required fields\"\"\"\n     # Map category names to professional icons (Material Design Icons)\n     icon_map = {\n-        'Tacos': 'restaurant',\n-        'Special Tacos': 'star',\n-        'Appetizers': 'restaurant-menu',\n-        'Snacks': 'restaurant-menu',\n-        'Beverages': 'local-drink', \n-        'Drinks': 'local-drink',\n-        'Desserts': 'cake',\n-        'Main Courses': 'restaurant',\n-        'Sides': 'restaurant-menu',\n-        'Breakfast': 'restaurant',\n-        'Salads': 'eco',\n-        'Soups': 'soup',\n-        'Burritos': 'restaurant-menu',\n-        'Alcohol': 'local-bar',\n-        'Coffee': 'local-cafe',\n-        'Tea': 'local-cafe',\n+        \"Tacos\": \"restaurant\",\n+        \"Special Tacos\": \"star\",\n+        \"Appetizers\": \"restaurant-menu\",\n+        \"Snacks\": \"restaurant-menu\",\n+        \"Beverages\": \"local-drink\",\n+        \"Drinks\": \"local-drink\",\n+        \"Desserts\": \"cake\",\n+        \"Main Courses\": \"restaurant\",\n+        \"Sides\": \"restaurant-menu\",\n+        \"Breakfast\": \"restaurant\",\n+        \"Salads\": \"eco\",\n+        \"Soups\": \"soup\",\n+        \"Burritos\": \"restaurant-menu\",\n+        \"Alcohol\": \"local-bar\",\n+        \"Coffee\": \"local-cafe\",\n+        \"Tea\": \"local-cafe\",\n     }\n-    \n+\n     # Legacy emoji mapping for backward compatibility (will be phased out)\n     emoji_map = {\n-        'Tacos': '\ud83c\udf2e',\n-        'Special Tacos': '\u2b50',\n-        'Appetizers': '\ud83e\udd57',\n-        'Snacks': '\ud83c\udf7f',\n-        'Beverages': '\ud83e\udd64',\n-        'Drinks': '\ud83e\udd64',\n-        'Desserts': '\ud83c\udf70',\n-        'Main Courses': '\ud83c\udf7d\ufe0f',\n-        'Sides': '\ud83c\udf5f',\n-        'Breakfast': '\ud83c\udf73',\n-        'Salads': '\ud83e\udd57',\n-        'Soups': '\ud83c\udf72',\n-        'Burritos': '\ud83c\udf2f',\n-        'Alcohol': '\ud83c\udf7a',\n-        'Coffee': '\u2615',\n-        'Tea': '\ud83c\udf75',\n+        \"Tacos\": \"\ud83c\udf2e\",\n+        \"Special Tacos\": \"\u2b50\",\n+        \"Appetizers\": \"\ud83e\udd57\",\n+        \"Snacks\": \"\ud83c\udf7f\",\n+        \"Beverages\": \"\ud83e\udd64\",\n+        \"Drinks\": \"\ud83e\udd64\",\n+        \"Desserts\": \"\ud83c\udf70\",\n+        \"Main Courses\": \"\ud83c\udf7d\ufe0f\",\n+        \"Sides\": \"\ud83c\udf5f\",\n+        \"Breakfast\": \"\ud83c\udf73\",\n+        \"Salads\": \"\ud83e\udd57\",\n+        \"Soups\": \"\ud83c\udf72\",\n+        \"Burritos\": \"\ud83c\udf2f\",\n+        \"Alcohol\": \"\ud83c\udf7a\",\n+        \"Coffee\": \"\u2615\",\n+        \"Tea\": \"\ud83c\udf75\",\n     }\n-    \n+\n     # Get icon and emoji based on category or use defaults\n-    icon = icon_map.get(category_name, 'restaurant')\n-    emoji = emoji_map.get(category_name, '\ud83c\udf7d\ufe0f')\n-    \n+    icon = icon_map.get(category_name, \"restaurant\")\n+    emoji = emoji_map.get(category_name, \"\ud83c\udf7d\ufe0f\")\n+\n     return {\n-        'id': str(product.id),\n-        'name': product.name,\n-        'price': float(product.price),\n-        'icon': icon,  # Professional icon for UI\n-        'emoji': emoji,  # Legacy support (will be removed later)\n-        'available': product.is_active if hasattr(product, 'is_active') else True,\n-        'category': category_name or 'Uncategorized',\n-        'description': product.description or ''\n+        \"id\": str(product.id),\n+        \"name\": product.name,\n+        \"price\": float(product.price),\n+        \"icon\": icon,  # Professional icon for UI\n+        \"emoji\": emoji,  # Legacy support (will be removed later)\n+        \"available\": product.is_active if hasattr(product, \"is_active\") else True,\n+        \"category\": category_name or \"Uncategorized\",\n+        \"description\": product.description or \"\",\n     }\n+\n \n @cached(ttl=300, prefix=\"menu_items\", key_params=[\"restaurant_id\", \"category\"])\n async def _get_menu_items_cached(\n-    restaurant_id: str,\n-    category: Optional[str],\n-    db: Session\n+    restaurant_id: str, category: Optional[str], db: Session\n ):\n     \"\"\"Internal cached function for getting menu items\"\"\"\n     start_time = time.time()\n-    \n-    logger.info(f\"Menu items request started - Restaurant: {restaurant_id}, Category: {category}\")\n-    \n+\n+    logger.info(\n+        f\"Menu items request started - Restaurant: {restaurant_id}, Category: {category}\"\n+    )\n+\n     # Build query\n     query = db.query(Product).filter(\n         and_(Product.restaurant_id == restaurant_id, Product.is_active == True)\n     )\n-    \n+\n     # Optimize category handling\n     categories_dict = {}\n     category_filter_applied = False\n-    \n+\n     # Filter by category if specified\n-    if category and category != 'All':\n-        category_obj = db.query(Category).filter(\n-            and_(Category.restaurant_id == restaurant_id, Category.name == category)\n-        ).first()\n+    if category and category != \"All\":\n+        category_obj = (\n+            db.query(Category)\n+            .filter(\n+                and_(Category.restaurant_id == restaurant_id, Category.name == category)\n+            )\n+            .first()\n+        )\n         if category_obj:\n             query = query.filter(Product.category_id == category_obj.id)\n             # Only fetch the specific category for optimization\n             categories_dict = {category_obj.id: category_obj.name}\n             category_filter_applied = True\n-    \n+\n     # Join with categories to avoid N+1 queries\n-    products = query.join(Category, Product.category_id == Category.id, isouter=True).order_by(Product.name).all()\n-    \n+    products = (\n+        query.join(Category, Product.category_id == Category.id, isouter=True)\n+        .order_by(Product.name)\n+        .all()\n+    )\n+\n     # Only fetch all categories if we haven't filtered by a specific one\n     if not category_filter_applied:\n         categories_dict = {\n-            cat.id: cat.name \n-            for cat in db.query(Category).filter(Category.restaurant_id == restaurant_id).all()\n+            cat.id: cat.name\n+            for cat in db.query(Category)\n+            .filter(Category.restaurant_id == restaurant_id)\n+            .all()\n         }\n-    \n+\n     # Transform to match frontend expectations\n     menu_items = []\n     for product in products:\n         # Use pre-fetched category name\n-        category_name = categories_dict.get(product.category_id, 'Uncategorized')\n+        category_name = categories_dict.get(product.category_id, \"Uncategorized\")\n         menu_items.append(format_menu_item(product, category_name))\n-    \n+\n     # Log execution time and performance warnings\n     execution_time = time.time() - start_time\n-    logger.info(f\"Menu items request completed in {execution_time:.3f}s - Items: {len(menu_items)}\")\n-    \n+    logger.info(\n+        f\"Menu items request completed in {execution_time:.3f}s - Items: {len(menu_items)}\"\n+    )\n+\n     if execution_time > 5:\n-        logger.warning(f\"SLOW QUERY WARNING: Menu items took {execution_time:.3f}s for restaurant {restaurant_id} with {len(menu_items)} items\")\n+        logger.warning(\n+            f\"SLOW QUERY WARNING: Menu items took {execution_time:.3f}s for restaurant {restaurant_id} with {len(menu_items)} items\"\n+        )\n     elif execution_time > 2:\n-        logger.warning(f\"Performance Alert: Menu query took {execution_time:.3f}s - consider optimization\")\n-    \n+        logger.warning(\n+            f\"Performance Alert: Menu query took {execution_time:.3f}s - consider optimization\"\n+        )\n+\n     return APIResponseHelper.success(\n         data=menu_items,\n         message=f\"Retrieved {len(menu_items)} menu items\",\n         meta={\n             \"restaurant_id\": restaurant_id,\n             \"category_filter\": category,\n             \"total_count\": len(menu_items),\n-            \"execution_time_ms\": int(execution_time * 1000)\n-        }\n+            \"execution_time_ms\": int(execution_time * 1000),\n+        },\n     )\n \n \n @router.get(\"/items\")\n async def get_menu_items(\n     restaurant_id: Optional[str] = Query(None),\n     category: Optional[str] = Query(None),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Get menu items (products) for frontend compatibility\"\"\"\n     # Use current user's restaurant context\n-    user_restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n+    user_restaurant_id = (\n+        current_user.current_restaurant_id or current_user.restaurant_id\n+    )\n     if not user_restaurant_id:\n         return APIResponseHelper.error(\n-            message=\"User must be assigned to a restaurant\",\n-            status_code=400\n-        )\n-    \n+            message=\"User must be assigned to a restaurant\", status_code=400\n+        )\n+\n     # Use provided restaurant_id or fallback to user's current restaurant\n     if not restaurant_id:\n         restaurant_id = str(user_restaurant_id)\n     else:\n         # Validate that user has access to the requested restaurant\n         from app.core.tenant_security import TenantSecurity\n+\n         await TenantSecurity.validate_restaurant_access(\n             user=current_user,\n             restaurant_id=restaurant_id,\n             operation=\"access\",\n             resource_type=\"menu\",\n             resource_id=None,\n-            db=db\n-        )\n-    \n+            db=db,\n+        )\n+\n     # Call the cached function with resolved restaurant_id\n     return await _get_menu_items_cached(restaurant_id, category, db)\n \n+\n @cached(ttl=300, prefix=\"menu_categories\", key_params=[\"restaurant_id\"])\n-async def _get_menu_categories_cached(\n-    restaurant_id: str,\n-    db: Session\n-):\n+async def _get_menu_categories_cached(restaurant_id: str, db: Session):\n     \"\"\"Internal cached function for getting menu categories\"\"\"\n     # Get categories\n-    categories = db.query(Category).filter(\n-        and_(Category.restaurant_id == restaurant_id, Category.is_active == True)\n-    ).order_by(Category.sort_order, Category.name).all()\n-    \n+    categories = (\n+        db.query(Category)\n+        .filter(\n+            and_(Category.restaurant_id == restaurant_id, Category.is_active == True)\n+        )\n+        .order_by(Category.sort_order, Category.name)\n+        .all()\n+    )\n+\n     # Transform to match frontend expectations\n     menu_categories = [\n         {\n-            'id': int(str(cat.id).replace('-', '')[:8], 16) % 100000,  # Convert UUID to int for frontend compatibility\n-            'name': cat.name,\n-            'active': cat.is_active\n+            \"id\": int(str(cat.id).replace(\"-\", \"\")[:8], 16)\n+            % 100000,  # Convert UUID to int for frontend compatibility\n+            \"name\": cat.name,\n+            \"active\": cat.is_active,\n         }\n         for cat in categories\n     ]\n-    \n+\n     # Always include 'All' category at the beginning\n-    if not any(cat['name'] == 'All' for cat in menu_categories):\n-        menu_categories.insert(0, {'id': 1, 'name': 'All', 'active': True})\n-    \n+    if not any(cat[\"name\"] == \"All\" for cat in menu_categories):\n+        menu_categories.insert(0, {\"id\": 1, \"name\": \"All\", \"active\": True})\n+\n     return APIResponseHelper.success(\n         data=menu_categories,\n         message=f\"Retrieved {len(menu_categories)} menu categories\",\n-        meta={\n-            \"restaurant_id\": restaurant_id,\n-            \"total_count\": len(menu_categories)\n-        }\n+        meta={\"restaurant_id\": restaurant_id, \"total_count\": len(menu_categories)},\n     )\n \n \n @router.get(\"/categories\")\n async def get_menu_categories(\n     restaurant_id: Optional[str] = Query(None),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Get menu categories for frontend compatibility\"\"\"\n     # Use current user's restaurant context\n-    user_restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n+    user_restaurant_id = (\n+        current_user.current_restaurant_id or current_user.restaurant_id\n+    )\n     if not user_restaurant_id:\n         return APIResponseHelper.error(\n-            message=\"User must be assigned to a restaurant\",\n-            status_code=400\n-        )\n-    \n+            message=\"User must be assigned to a restaurant\", status_code=400\n+        )\n+\n     # Use provided restaurant_id or fallback to user's current restaurant\n     if not restaurant_id:\n         restaurant_id = str(user_restaurant_id)\n     else:\n         # Validate that user has access to the requested restaurant\n         from app.core.tenant_security import TenantSecurity\n+\n         await TenantSecurity.validate_restaurant_access(\n             user=current_user,\n             restaurant_id=restaurant_id,\n             operation=\"access\",\n             resource_type=\"menu\",\n             resource_id=None,\n-            db=db\n-        )\n-    \n+            db=db,\n+        )\n+\n     # Call the cached function with resolved restaurant_id\n-    return await _get_menu_categories_cached(restaurant_id, db)\n\\ No newline at end of file\n+    return await _get_menu_categories_cached(restaurant_id, db)\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/auth.py\t2025-08-02 21:56:58.983793+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/auth.py\t2025-08-02 22:36:02.709516+00:00\n@@ -16,11 +16,11 @@\n from app.core.database import get_db\n from app.core.exceptions import (\n     AuthenticationException,\n     FynloException,\n     ResourceNotFoundException,\n-    ValidationException\n+    ValidationException,\n )\n from app.core.supabase import supabase_admin, get_admin_client\n from app.core.config import settings\n from app.core.database import User, Restaurant\n from app.schemas.auth import AuthVerifyResponse, RegisterRestaurantRequest\n@@ -47,278 +47,331 @@\n     except (ValueError, TypeError) as e:\n         logger.error(f\"Invalid UUID format: {value}\")\n         raise ValueError(f\"Invalid UUID format: {value}\")\n \n \n-\n-\n # Rate limited: 5 requests per minute per IP\n @router.post(\"/verify\", response_model=AuthVerifyResponse)\n @limiter.limit(AUTH_RATE)\n async def verify_supabase_user(\n     request: Request,\n     authorization: Optional[str] = Header(None),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Verify Supabase token and return user info with subscription details\"\"\"\n-    \n+\n     if not authorization:\n         raise AuthenticationException(message=\"No authorization header provided\")\n-    \n+\n     # Extract token from \"Bearer <token>\" format\n     token = authorization.replace(\"Bearer \", \"\")\n-    \n+\n     if not token or token == authorization:\n-        raise ValidationException(message=\"Invalid authorization format. Expected: Bearer <token>\", field=\"authorization\")\n-    \n+        raise ValidationException(\n+            message=\"Invalid authorization format. Expected: Bearer <token>\",\n+            field=\"authorization\",\n+        )\n+\n     # Get Supabase client (will initialize if needed)\n     client = supabase_admin or get_admin_client()\n     if not client:\n         logger.error(\"Supabase admin client not available\")\n         logger.error(f\"SUPABASE_URL set: {bool(settings.SUPABASE_URL)}\")\n-        logger.error(f\"SUPABASE_SERVICE_ROLE_KEY set: {bool(settings.SUPABASE_SERVICE_ROLE_KEY)}\")\n-        raise AuthenticationException(message=\"Authentication service temporarily unavailable. Please check backend configuration.\")\n-    \n+        logger.error(\n+            f\"SUPABASE_SERVICE_ROLE_KEY set: {bool(settings.SUPABASE_SERVICE_ROLE_KEY)}\"\n+        )\n+        raise AuthenticationException(\n+            message=\"Authentication service temporarily unavailable. Please check backend configuration.\"\n+        )\n+\n     try:\n         # Verify token with Supabase Admin API\n         logger.info(f\"Verifying token with Supabase (token length: {len(token)})\")\n         # Never log token content for security reasons\n-        \n+\n         # Log Supabase client state\n         logger.info(f\"Supabase client URL: {client.supabase_url}\")\n-        \n+\n         user_response = client.auth.get_user(token)\n-        \n+\n         # Check if we got a valid response\n         if not user_response:\n             logger.error(\"Supabase returned None response for get_user\")\n-            raise AuthenticationException(message=\"Authentication service returned invalid response\")\n-        \n+            raise AuthenticationException(\n+                message=\"Authentication service returned invalid response\"\n+            )\n+\n         supabase_user = user_response.user\n-        \n+\n         if not supabase_user:\n             logger.warning(\"Supabase returned no user for the provided token\")\n             raise ValidationException(message=\"Invalid or expired token\", field=\"or\")\n-        \n+\n         logger.info(f\"Successfully verified Supabase user: {supabase_user.email}\")\n-        \n+\n         # Find or create user in our database with proper error handling\n         db_user = None\n         try:\n             # Use supabase_id for secure lookup\n-            db_user = db.query(User).filter(\n-                User.supabase_id == supabase_user.id\n-            ).first()\n-            \n+            db_user = (\n+                db.query(User).filter(User.supabase_id == supabase_user.id).first()\n+            )\n+\n             if not db_user:\n                 # Check if user exists by email (for backward compatibility)\n-                db_user = db.query(User).filter(\n-                    User.email == supabase_user.email\n-                ).first()\n-                \n+                db_user = (\n+                    db.query(User).filter(User.email == supabase_user.email).first()\n+                )\n+\n                 # If found by email but missing supabase_id, update it\n                 if db_user and not db_user.supabase_id:\n-                    db_user.supabase_id = supabase_user.id  # Use UUID object, not string\n+                    db_user.supabase_id = (\n+                        supabase_user.id\n+                    )  # Use UUID object, not string\n                     db.commit()\n-                    logger.info(f\"Updated user {db_user.id} with Supabase ID: {supabase_user.id}\")\n+                    logger.info(\n+                        f\"Updated user {db_user.id} with Supabase ID: {supabase_user.id}\"\n+                    )\n         except SQLAlchemyError as e:\n             logger.error(f\"Database query error when finding user: {str(e)}\")\n             db.rollback()\n-            raise FynloException(message=\"Database error while retrieving user information\", status_code=500)\n-        \n+            raise FynloException(\n+                message=\"Database error while retrieving user information\",\n+                status_code=500,\n+            )\n+\n         if not db_user:\n             # First time login - create user with proper transaction handling\n             logger.info(f\"First time login for user: {supabase_user.email}\")\n-            \n+\n             try:\n                 # Create new user with proper defaults\n                 # Safely access user_metadata with null check\n                 user_metadata = supabase_user.user_metadata or {}\n-                \n+\n                 db_user = User(\n                     id=uuid.uuid4(),\n                     email=supabase_user.email,\n                     username=supabase_user.email,  # Use email as username\n                     supabase_id=supabase_user.id,  # Store the Supabase ID for secure lookups\n-                    first_name=user_metadata.get('first_name', ''),\n-                    last_name=user_metadata.get('last_name', ''),\n-                    role='restaurant_owner',  # Default role for new users\n-                    auth_provider='supabase',\n+                    first_name=user_metadata.get(\"first_name\", \"\"),\n+                    last_name=user_metadata.get(\"last_name\", \"\"),\n+                    role=\"restaurant_owner\",  # Default role for new users\n+                    auth_provider=\"supabase\",\n                     is_active=True,\n-                    last_login=datetime.utcnow()\n+                    last_login=datetime.utcnow(),\n                 )\n                 db.add(db_user)\n                 db.commit()\n                 db.refresh(db_user)\n-                logger.info(f\"Successfully created new user with ID: {db_user.id} and Supabase ID: {supabase_user.id}\")\n+                logger.info(\n+                    f\"Successfully created new user with ID: {db_user.id} and Supabase ID: {supabase_user.id}\"\n+                )\n             except IntegrityError as e:\n                 logger.error(f\"Integrity error creating user: {str(e)}\")\n                 db.rollback()\n                 # Try to fetch the user again in case of race condition\n                 try:\n-                    db_user = db.query(User).filter(\n-                        User.supabase_id == supabase_user.id\n-                    ).first()\n+                    db_user = (\n+                        db.query(User)\n+                        .filter(User.supabase_id == supabase_user.id)\n+                        .first()\n+                    )\n                     if not db_user:\n                         # Also check by email\n-                        db_user = db.query(User).filter(\n-                            User.email == supabase_user.email\n-                        ).first()\n+                        db_user = (\n+                            db.query(User)\n+                            .filter(User.email == supabase_user.email)\n+                            .first()\n+                        )\n                         if db_user and not db_user.supabase_id:\n                             # Update the supabase_id if missing\n                             try:\n-                                db_user.supabase_id = supabase_user.id  # Use UUID object, not string\n+                                db_user.supabase_id = (\n+                                    supabase_user.id\n+                                )  # Use UUID object, not string\n                                 db.commit()\n-                                logger.info(f\"Updated user {db_user.id} with Supabase ID in retry path\")\n+                                logger.info(\n+                                    f\"Updated user {db_user.id} with Supabase ID in retry path\"\n+                                )\n                             except SQLAlchemyError as update_error:\n-                                logger.error(f\"Failed to update supabase_id in retry path: {str(update_error)}\")\n+                                logger.error(\n+                                    f\"Failed to update supabase_id in retry path: {str(update_error)}\"\n+                                )\n                                 db.rollback()\n                                 # Continue with the user even if update fails\n                     if not db_user:\n-                        raise FynloException(message=\"Failed to create user account. Please try again.\", status_code=500)\n+                        raise FynloException(\n+                            message=\"Failed to create user account. Please try again.\",\n+                            status_code=500,\n+                        )\n                 except SQLAlchemyError as retry_error:\n-                    logger.error(f\"Failed to fetch user after IntegrityError: {str(retry_error)}\")\n+                    logger.error(\n+                        f\"Failed to fetch user after IntegrityError: {str(retry_error)}\"\n+                    )\n                     db.rollback()\n-                    raise FynloException(message=\"Database error while creating user account\", status_code=500)\n+                    raise FynloException(\n+                        message=\"Database error while creating user account\",\n+                        status_code=500,\n+                    )\n             except SQLAlchemyError as e:\n                 logger.error(f\"Database error creating user: {str(e)}\")\n                 db.rollback()\n-                raise FynloException(message=\"Database error while creating user account\", status_code=500)\n+                raise FynloException(\n+                    message=\"Database error while creating user account\",\n+                    status_code=500,\n+                )\n         else:\n             # Update last login\n             try:\n                 db_user.last_login = datetime.utcnow()\n                 db.commit()\n             except SQLAlchemyError as e:\n                 logger.error(f\"Error updating last login: {str(e)}\")\n                 db.rollback()\n                 # Non-critical error, continue\n-        \n+\n         # Build response with proper UUID to string conversion\n         response_data = {\n             \"user\": {\n                 \"id\": str(db_user.id),\n                 \"email\": db_user.email,\n-                \"name\": f\"{db_user.first_name} {db_user.last_name}\".strip() or db_user.email,\n-                \"is_platform_owner\": db_user.role == 'platform_owner',\n-                \"role\": db_user.role\n+                \"name\": f\"{db_user.first_name} {db_user.last_name}\".strip()\n+                or db_user.email,\n+                \"is_platform_owner\": db_user.role == \"platform_owner\",\n+                \"role\": db_user.role,\n             }\n         }\n-        \n+\n         # Add restaurant info if user has one\n         if db_user.restaurant_id:\n             try:\n-                restaurant = db.query(Restaurant).filter(\n-                    Restaurant.id == db_user.restaurant_id\n-                ).first()\n-                \n+                restaurant = (\n+                    db.query(Restaurant)\n+                    .filter(Restaurant.id == db_user.restaurant_id)\n+                    .first()\n+                )\n+\n                 if restaurant:\n                     # Sync subscription data from Supabase if available\n                     # Safely access user_metadata with null check\n                     user_metadata = supabase_user.user_metadata or {}\n-                    supabase_plan = user_metadata.get('subscription_plan')\n-                    supabase_status = user_metadata.get('subscription_status')\n-                    \n+                    supabase_plan = user_metadata.get(\"subscription_plan\")\n+                    supabase_status = user_metadata.get(\"subscription_status\")\n+\n                     # Update restaurant subscription info if needed\n                     update_needed = False\n-                    \n+\n                     if supabase_plan and restaurant.subscription_plan != supabase_plan:\n                         restaurant.subscription_plan = supabase_plan\n                         update_needed = True\n                     elif not restaurant.subscription_plan:\n-                        restaurant.subscription_plan = 'alpha'\n+                        restaurant.subscription_plan = \"alpha\"\n                         update_needed = True\n-                    \n-                    if supabase_status and restaurant.subscription_status != supabase_status:\n+\n+                    if (\n+                        supabase_status\n+                        and restaurant.subscription_status != supabase_status\n+                    ):\n                         restaurant.subscription_status = supabase_status\n                         update_needed = True\n                     elif not restaurant.subscription_status:\n-                        restaurant.subscription_status = 'trial'\n+                        restaurant.subscription_status = \"trial\"\n                         update_needed = True\n-                    \n+\n                     if update_needed:\n                         try:\n                             db.commit()\n                         except SQLAlchemyError as e:\n-                            logger.error(f\"Error updating restaurant subscription: {str(e)}\")\n+                            logger.error(\n+                                f\"Error updating restaurant subscription: {str(e)}\"\n+                            )\n                             db.rollback()\n-                    \n+\n                     # Add restaurant info to response with proper string conversion\n                     response_data[\"user\"][\"restaurant_id\"] = str(restaurant.id)\n                     response_data[\"user\"][\"restaurant_name\"] = restaurant.name\n-                    response_data[\"user\"][\"subscription_plan\"] = restaurant.subscription_plan or 'alpha'\n-                    response_data[\"user\"][\"subscription_status\"] = restaurant.subscription_status or 'trial'\n+                    response_data[\"user\"][\"subscription_plan\"] = (\n+                        restaurant.subscription_plan or \"alpha\"\n+                    )\n+                    response_data[\"user\"][\"subscription_status\"] = (\n+                        restaurant.subscription_status or \"trial\"\n+                    )\n                     response_data[\"user\"][\"enabled_features\"] = get_plan_features(\n-                        restaurant.subscription_plan or 'alpha'\n+                        restaurant.subscription_plan or \"alpha\"\n                     )\n             except SQLAlchemyError as e:\n                 logger.error(f\"Error retrieving restaurant info: {str(e)}\")\n                 db.rollback()\n                 # Continue without restaurant info rather than failing\n         else:\n             # User has no restaurant yet - they need to complete onboarding\n             logger.info(f\"User {db_user.id} has no restaurant - needs onboarding\")\n-            \n+\n             # Get subscription plan from Supabase user metadata\n             # Safely access user_metadata with null check\n             user_metadata = supabase_user.user_metadata or {}\n-            subscription_plan = user_metadata.get('subscription_plan', 'alpha')\n-            subscription_status = user_metadata.get('subscription_status', 'trial')\n-            \n-            logger.info(f\"User {db_user.id} has subscription plan: {subscription_plan} (status: {subscription_status})\")\n-            \n+            subscription_plan = user_metadata.get(\"subscription_plan\", \"alpha\")\n+            subscription_status = user_metadata.get(\"subscription_status\", \"trial\")\n+\n+            logger.info(\n+                f\"User {db_user.id} has subscription plan: {subscription_plan} (status: {subscription_status})\"\n+            )\n+\n             # Return subscription info and features based on plan even without restaurant\n             response_data[\"user\"][\"needs_onboarding\"] = True\n             response_data[\"user\"][\"subscription_plan\"] = subscription_plan\n             response_data[\"user\"][\"subscription_status\"] = subscription_status\n-            response_data[\"user\"][\"enabled_features\"] = get_plan_features(subscription_plan)\n-            \n+            response_data[\"user\"][\"enabled_features\"] = get_plan_features(\n+                subscription_plan\n+            )\n+\n             # Add onboarding progress tracking\n             response_data[\"user\"][\"onboarding_progress\"] = {\n                 \"current_step\": 0,\n                 \"completed_steps\": [],\n                 \"total_steps\": 9,\n-                \"resume_at_step\": 1\n+                \"resume_at_step\": 1,\n             }\n-        \n+\n         return response_data\n-        \n+\n     except FynloException:\n         # Re-raise HTTP exceptions without modification\n         raise\n     except (AuthApiError, PostgrestAPIError) as e:\n         # Handle Supabase authentication errors\n         error_msg = str(e)\n         logger.warning(f\"Supabase AuthApiError: {error_msg}\")\n         logger.warning(f\"Error type: {type(e).__name__}\")\n-        \n+\n         # Create audit logger\n         audit_logger = AuditLoggerService(db)\n-        \n+\n         # Get client info for audit\n         client_ip = request.client.host if request.client else \"unknown\"\n         user_agent = request.headers.get(\"user-agent\", \"unknown\")\n-        \n+\n         # Try to get more details from the error\n-        if hasattr(e, 'code'):\n+        if hasattr(e, \"code\"):\n             logger.warning(f\"Error code: {e.code}\")\n-        if hasattr(e, 'message'):\n+        if hasattr(e, \"message\"):\n             logger.warning(f\"Error message: {e.message}\")\n-        if hasattr(e, 'response'):\n+        if hasattr(e, \"response\"):\n             logger.warning(f\"Error response: {e.response}\")\n-        \n+\n         error_msg_lower = error_msg.lower()\n         if \"invalid jwt\" in error_msg_lower or \"malformed\" in error_msg_lower:\n             # Log failed authentication attempt\n             await audit_logger.create_audit_log(\n                 event_type=AuditEventType.AUTHENTICATION,\n                 event_status=AuditEventStatus.FAILURE,\n                 action_performed=\"Invalid JWT token presented\",\n                 ip_address=client_ip,\n                 user_agent=user_agent,\n                 details={\"error\": \"invalid_jwt\", \"token_provided\": bool(authorization)},\n-                risk_score=70  # High risk - invalid token\n+                risk_score=70,  # High risk - invalid token\n             )\n             raise AuthenticationException(message=\"Invalid authentication token\")\n         elif \"expired\" in error_msg_lower:\n             # Log expired token attempt\n             await audit_logger.create_audit_log(\n@@ -326,216 +379,271 @@\n                 event_status=AuditEventStatus.FAILURE,\n                 action_performed=\"Expired JWT token presented\",\n                 ip_address=client_ip,\n                 user_agent=user_agent,\n                 details={\"error\": \"expired_token\"},\n-                risk_score=30  # Low risk - just expired\n-            )\n-            raise AuthenticationException(message=\"Token has expired. Please sign in again.\")\n+                risk_score=30,  # Low risk - just expired\n+            )\n+            raise AuthenticationException(\n+                message=\"Token has expired. Please sign in again.\"\n+            )\n         elif \"not found\" in error_msg_lower:\n             # Log user not found attempt\n             await audit_logger.create_audit_log(\n                 event_type=AuditEventType.AUTHENTICATION,\n                 event_status=AuditEventStatus.FAILURE,\n                 action_performed=\"Authentication attempt for non-existent user\",\n                 ip_address=client_ip,\n                 user_agent=user_agent,\n                 details={\"error\": \"user_not_found\"},\n-                risk_score=50  # Medium risk\n-            )\n-            raise ResourceNotFoundException(resource=\"User\", message=\"User not found. Please sign up first.\")\n+                risk_score=50,  # Medium risk\n+            )\n+            raise ResourceNotFoundException(\n+                resource=\"User\", message=\"User not found. Please sign up first.\"\n+            )\n         else:\n             # Log unexpected auth errors with full details\n-            logger.error(f\"Unexpected Supabase auth error: {type(e).__name__}: {str(e)}\")\n+            logger.error(\n+                f\"Unexpected Supabase auth error: {type(e).__name__}: {str(e)}\"\n+            )\n             await audit_logger.create_audit_log(\n                 event_type=AuditEventType.AUTHENTICATION,\n                 event_status=AuditEventStatus.FAILURE,\n                 action_performed=\"Authentication failed with unexpected error\",\n                 ip_address=client_ip,\n                 user_agent=user_agent,\n-                details={\"error\": \"unexpected_auth_error\", \"error_type\": type(e).__name__},\n-                risk_score=80  # High risk - unexpected error\n-            )\n-            raise AuthenticationException(message=\"Authentication failed. Please sign in again.\")\n+                details={\n+                    \"error\": \"unexpected_auth_error\",\n+                    \"error_type\": type(e).__name__,\n+                },\n+                risk_score=80,  # High risk - unexpected error\n+            )\n+            raise AuthenticationException(\n+                message=\"Authentication failed. Please sign in again.\"\n+            )\n     except Exception as e:\n         # Check if this is actually an AuthApiError wrapped in another exception\n         error_str = str(e)\n-        logger.error(f\"Auth verification error - Type: {type(e).__name__}, Message: {error_str}\")\n-        \n+        logger.error(\n+            f\"Auth verification error - Type: {type(e).__name__}, Message: {error_str}\"\n+        )\n+\n         # Create audit logger for generic exceptions\n         audit_logger = AuditLoggerService(db)\n         client_ip = request.client.host if request.client else \"unknown\"\n         user_agent = request.headers.get(\"user-agent\", \"unknown\")\n-        \n+\n         # Check for common Supabase error patterns in the exception message\n         if \"invalid jwt\" in error_str.lower() or \"jwt\" in error_str.lower():\n-            logger.warning(\"Detected JWT error in generic exception, treating as auth error\")\n+            logger.warning(\n+                \"Detected JWT error in generic exception, treating as auth error\"\n+            )\n             await audit_logger.create_audit_log(\n                 event_type=AuditEventType.AUTHENTICATION,\n                 event_status=AuditEventStatus.FAILURE,\n                 action_performed=\"JWT error detected in generic exception\",\n                 ip_address=client_ip,\n                 user_agent=user_agent,\n-                details={\"error\": \"jwt_error_wrapped\", \"exception_type\": type(e).__name__},\n-                risk_score=70\n+                details={\n+                    \"error\": \"jwt_error_wrapped\",\n+                    \"exception_type\": type(e).__name__,\n+                },\n+                risk_score=70,\n             )\n             raise AuthenticationException(message=\"Invalid authentication token\")\n         elif \"user not found\" in error_str.lower():\n             logger.warning(\"Detected user not found error in generic exception\")\n             await audit_logger.create_audit_log(\n                 event_type=AuditEventType.AUTHENTICATION,\n                 event_status=AuditEventStatus.FAILURE,\n                 action_performed=\"User not found error in generic exception\",\n                 ip_address=client_ip,\n                 user_agent=user_agent,\n-                details={\"error\": \"user_not_found_wrapped\", \"exception_type\": type(e).__name__},\n-                risk_score=50\n-            )\n-            raise ResourceNotFoundException(resource=\"User\", message=\"User not found. Please sign up first.\")\n-        \n+                details={\n+                    \"error\": \"user_not_found_wrapped\",\n+                    \"exception_type\": type(e).__name__,\n+                },\n+                risk_score=50,\n+            )\n+            raise ResourceNotFoundException(\n+                resource=\"User\", message=\"User not found. Please sign up first.\"\n+            )\n+\n         # Log the full exception type chain for debugging\n         import traceback\n+\n         logger.error(f\"Full exception details: {traceback.format_exc()}\")\n-        \n+\n         # Check if it's a Supabase initialization error\n-        if \"supabase\" in error_str.lower() and (\"missing\" in error_str.lower() or \"environment\" in error_str.lower()):\n+        if \"supabase\" in error_str.lower() and (\n+            \"missing\" in error_str.lower() or \"environment\" in error_str.lower()\n+        ):\n             await audit_logger.create_audit_log(\n                 event_type=AuditEventType.SYSTEM_EVENT,\n                 event_status=AuditEventStatus.FAILURE,\n                 action_performed=\"Authentication service configuration error\",\n                 ip_address=client_ip,\n                 user_agent=user_agent,\n-                details={\"error\": \"service_config_error\", \"exception_type\": type(e).__name__},\n-                risk_score=90  # Very high risk - config error\n-            )\n-            raise AuthenticationException(message=\"Authentication service configuration error. Please contact support.\")\n-        \n+                details={\n+                    \"error\": \"service_config_error\",\n+                    \"exception_type\": type(e).__name__,\n+                },\n+                risk_score=90,  # Very high risk - config error\n+            )\n+            raise AuthenticationException(\n+                message=\"Authentication service configuration error. Please contact support.\"\n+            )\n+\n         # Log generic authentication service error\n         await audit_logger.create_audit_log(\n             event_type=AuditEventType.AUTHENTICATION,\n             event_status=AuditEventStatus.FAILURE,\n             action_performed=\"Authentication service error\",\n             ip_address=client_ip,\n             user_agent=user_agent,\n-            details={\"error\": \"service_error\", \"exception_type\": type(e).__name__, \"message\": error_str[:200]},\n-            risk_score=60\n+            details={\n+                \"error\": \"service_error\",\n+                \"exception_type\": type(e).__name__,\n+                \"message\": error_str[:200],\n+            },\n+            risk_score=60,\n         )\n-        \n-        raise AuthenticationException(message=\"Authentication service error. Please try again later.\")\n+\n+        raise AuthenticationException(\n+            message=\"Authentication service error. Please try again later.\"\n+        )\n \n \n @router.post(\"/register-restaurant\")\n @limiter.limit(AUTH_RATE)\n async def register_restaurant(\n     request: Request,\n     data: RegisterRestaurantRequest,\n     authorization: Optional[str] = Header(None),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Register a new restaurant after Supabase signup\"\"\"\n-    \n+\n     if not authorization:\n         raise AuthenticationException(message=\"No authorization header\")\n-    \n+\n     token = authorization.replace(\"Bearer \", \"\")\n-    \n+\n     # Get Supabase client (will initialize if needed)\n     client = supabase_admin or get_admin_client()\n     if not client:\n         logger.error(\"Supabase admin client not available\")\n         logger.error(f\"SUPABASE_URL set: {bool(settings.SUPABASE_URL)}\")\n-        logger.error(f\"SUPABASE_SERVICE_ROLE_KEY set: {bool(settings.SUPABASE_SERVICE_ROLE_KEY)}\")\n-        raise AuthenticationException(message=\"Authentication service temporarily unavailable. Please check backend configuration.\")\n-    \n+        logger.error(\n+            f\"SUPABASE_SERVICE_ROLE_KEY set: {bool(settings.SUPABASE_SERVICE_ROLE_KEY)}\"\n+        )\n+        raise AuthenticationException(\n+            message=\"Authentication service temporarily unavailable. Please check backend configuration.\"\n+        )\n+\n     try:\n         # Verify token\n         user_response = client.auth.get_user(token)\n         supabase_user = user_response.user\n-        \n+\n         if not supabase_user:\n             raise AuthenticationException(message=\"Invalid token\")\n-        \n+\n         # Get user from database by Supabase ID\n-        db_user = db.query(User).filter(\n-            User.supabase_id == supabase_user.id\n-        ).first()\n-        \n+        db_user = db.query(User).filter(User.supabase_id == supabase_user.id).first()\n+\n         if not db_user:\n             # Check by email for backward compatibility\n-            db_user = db.query(User).filter(\n-                User.email == supabase_user.email\n-            ).first()\n+            db_user = db.query(User).filter(User.email == supabase_user.email).first()\n             if db_user and not db_user.supabase_id:\n                 # Update the supabase_id if missing\n                 try:\n-                    db_user.supabase_id = supabase_user.id  # Use UUID object, not string\n+                    db_user.supabase_id = (\n+                        supabase_user.id\n+                    )  # Use UUID object, not string\n                     db.commit()\n-                    logger.info(f\"Updated user {db_user.id} with Supabase ID during registration\")\n+                    logger.info(\n+                        f\"Updated user {db_user.id} with Supabase ID during registration\"\n+                    )\n                 except SQLAlchemyError as e:\n-                    logger.error(f\"Failed to update user supabase_id during registration: {str(e)}\")\n+                    logger.error(\n+                        f\"Failed to update user supabase_id during registration: {str(e)}\"\n+                    )\n                     db.rollback()\n                     # Continue with registration even if update fails\n-        \n+\n         if not db_user:\n             raise ResourceNotFoundException(resource=\"User\")\n-        \n+\n         # Check if user already has a restaurant\n         if db_user.restaurant_id:\n             raise ValidationException(message=\"User already has a restaurant\")\n-        \n+\n         # Get subscription info from Supabase user metadata or default to alpha\n         # Safely access user_metadata with null check\n         user_metadata = supabase_user.user_metadata or {}\n-        subscription_plan = user_metadata.get('subscription_plan', 'alpha')\n-        subscription_status = user_metadata.get('subscription_status', 'trial')\n-        \n+        subscription_plan = user_metadata.get(\"subscription_plan\", \"alpha\")\n+        subscription_status = user_metadata.get(\"subscription_status\", \"trial\")\n+\n         # Create restaurant with proper error handling\n         try:\n             # Get default platform if user doesn't have one\n             platform_id = str(db_user.platform_id) if db_user.platform_id else None\n             if not platform_id:\n                 from app.core.database import Platform\n-                default_platform = db.query(Platform).filter(Platform.name == \"Fynlo\").first()\n+\n+                default_platform = (\n+                    db.query(Platform).filter(Platform.name == \"Fynlo\").first()\n+                )\n                 if default_platform:\n                     platform_id = str(default_platform.id)\n                 else:\n                     # No platform found - this is a critical error\n-                    raise FynloException(message=\"No platform found. Please contact support.\", status_code=500)\n-            \n+                    raise FynloException(\n+                        message=\"No platform found. Please contact support.\",\n+                        status_code=500,\n+                    )\n+\n             # Create properly structured address\n             address_data = {\n                 \"street\": data.address or \"\",\n                 \"city\": \"\",\n                 \"state\": \"\",\n                 \"zipCode\": \"\",\n-                \"country\": \"UK\"  # Default to UK\n+                \"country\": \"UK\",  # Default to UK\n             }\n-            \n+\n             # Validate inputs\n             from app.core.validation import (\n                 validate_model_jsonb_fields,\n                 validate_email,\n                 validate_phone,\n                 sanitize_string,\n-                ValidationError as ValidationErr\n-            )\n-            \n+                ValidationError as ValidationErr,\n+            )\n+\n             # Sanitize restaurant name\n             sanitized_name = sanitize_string(data.restaurant_name, 255)\n             if not sanitized_name:\n-                raise ValidationException(message=\"Restaurant name cannot be empty\", field=\"name\")\n-            \n+                raise ValidationException(\n+                    message=\"Restaurant name cannot be empty\", field=\"name\"\n+                )\n+\n             # Validate phone if provided\n             if data.phone and not validate_phone(data.phone):\n-                raise ValidationException(message=\"Invalid phone number format\", field=\"phone\")\n-            \n+                raise ValidationException(\n+                    message=\"Invalid phone number format\", field=\"phone\"\n+                )\n+\n             # Validate address structure\n             try:\n-                validated_address = validate_model_jsonb_fields('restaurant', 'address', address_data)\n+                validated_address = validate_model_jsonb_fields(\n+                    \"restaurant\", \"address\", address_data\n+                )\n             except ValidationErr as e:\n                 raise ValidationException(message=f\"Invalid address format: {str(e)}\")\n-            \n+\n             restaurant = Restaurant(\n                 id=uuid.uuid4(),\n                 platform_id=platform_id,\n                 name=sanitized_name,\n                 email=supabase_user.email,\n@@ -547,71 +655,74 @@\n                     \"tuesday\": {\"open\": \"09:00\", \"close\": \"22:00\"},\n                     \"wednesday\": {\"open\": \"09:00\", \"close\": \"22:00\"},\n                     \"thursday\": {\"open\": \"09:00\", \"close\": \"22:00\"},\n                     \"friday\": {\"open\": \"09:00\", \"close\": \"23:00\"},\n                     \"saturday\": {\"open\": \"09:00\", \"close\": \"23:00\"},\n-                    \"sunday\": {\"open\": \"10:00\", \"close\": \"21:00\"}\n+                    \"sunday\": {\"open\": \"10:00\", \"close\": \"21:00\"},\n                 },\n                 settings={\n                     \"currency\": \"GBP\",\n                     \"date_format\": \"DD/MM/YYYY\",\n                     \"time_format\": \"24h\",\n                     \"allow_tips\": True,\n                     \"auto_gratuity_percentage\": 12.5,\n-                    \"print_receipt_default\": True\n+                    \"print_receipt_default\": True,\n                 },\n                 subscription_plan=subscription_plan,\n                 subscription_status=subscription_status,\n                 subscription_started_at=datetime.utcnow(),\n                 # Set default configurations\n                 tax_configuration={\n                     \"vat_rate\": 0.20,\n                     \"included_in_price\": True,\n-                    \"tax_number\": \"\"\n+                    \"tax_number\": \"\",\n                 },\n                 payment_methods={\n                     \"cash\": True,\n                     \"card\": True,\n                     \"qr_code\": True,\n                     \"apple_pay\": True,\n-                    \"google_pay\": True\n+                    \"google_pay\": True,\n                 },\n-                is_active=True\n+                is_active=True,\n             )\n             db.add(restaurant)\n-            \n+\n             # Link user to restaurant and update user state\n             db_user.restaurant_id = restaurant.id\n             db_user.needs_onboarding = False  # Mark onboarding as complete\n             db_user.updated_at = datetime.utcnow()\n-            \n-            if db_user.role not in ['platform_owner', 'restaurant_owner']:\n-                db_user.role = 'restaurant_owner'\n-            \n+\n+            if db_user.role not in [\"platform_owner\", \"restaurant_owner\"]:\n+                db_user.role = \"restaurant_owner\"\n+\n             db.commit()\n             db.refresh(restaurant)\n             db.refresh(db_user)\n-            \n+\n             # Import feature gates\n             from app.core.feature_gate import get_plan_features\n-            \n+\n             return {\n                 \"success\": True,\n                 \"restaurant_id\": str(restaurant.id),\n                 \"restaurant_name\": restaurant.name,\n                 \"subscription_plan\": subscription_plan,\n                 \"subscription_status\": subscription_status,\n                 \"enabled_features\": get_plan_features(subscription_plan),\n                 \"needs_onboarding\": False,\n-                \"message\": \"Restaurant registered successfully\"\n+                \"message\": \"Restaurant registered successfully\",\n             }\n         except SQLAlchemyError as e:\n             logger.error(f\"Database error creating restaurant: {str(e)}\")\n             db.rollback()\n-            raise FynloException(message=\"Failed to register restaurant. Please try again.\", status_code=500)\n-        \n+            raise FynloException(\n+                message=\"Failed to register restaurant. Please try again.\",\n+                status_code=500,\n+            )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         logger.error(f\"Restaurant registration error: {str(e)}\")\n         db.rollback()\n-        raise FynloException(message=\"Failed to register restaurant\", status_code=500)\n\\ No newline at end of file\n+        raise FynloException(message=\"Failed to register restaurant\", status_code=500)\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/inventory.py\t2025-08-02 21:56:58.985565+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/inventory.py\t2025-08-02 22:36:02.722626+00:00\n@@ -1,303 +1,378 @@\n \"\"\"\n API Endpoints for Inventory Management\n \"\"\"\n+\n from fastapi import APIRouter, Depends, Query, Body\n from pydantic import BaseModel\n from sqlalchemy.orm import Session\n from typing import List, Optional\n from datetime import datetime\n-import base64 # Added for base64 decoding\n+import base64  # Added for base64 decoding\n from uuid import UUID\n \n from app.core.database import get_db\n from app.core.exceptions import ResourceNotFoundException, ValidationException\n-from app.core.database import User # Assuming User model for authentication/authorization\n+from app.core.database import (\n+    User,\n+)  # Assuming User model for authentication/authorization\n from app.crud import inventory as crud_inventory\n from app.schemas import inventory_schemas as schemas\n from app.core.dependencies import get_current_user\n from app.core.tenant_security import TenantSecurity\n from app.core.response_helper import APIResponseHelper\n \n router = APIRouter()\n \n # --- Inventory Item Endpoints ---\n \n+\n @router.post(\"/items/\", response_model=schemas.InventoryItem, status_code=201)\n async def create_inventory_item_api(\n     item: schemas.InventoryItemCreate,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n-):\n-    # Use current user's restaurant\n-    restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n-    if not restaurant_id:\n-        raise ValidationException(message=\"User must be assigned to a restaurant\", field=\"user\")\n-    \n+    current_user: User = Depends(get_current_user),\n+):\n+    # Use current user's restaurant\n+    restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n+    if not restaurant_id:\n+        raise ValidationException(\n+            message=\"User must be assigned to a restaurant\", field=\"user\"\n+        )\n+\n     # Check if SKU already exists for this restaurant\n-    db_item = crud_inventory.get_inventory_item(db, sku=item.sku, restaurant_id=restaurant_id)\n+    db_item = crud_inventory.get_inventory_item(\n+        db, sku=item.sku, restaurant_id=restaurant_id\n+    )\n     if db_item:\n-        raise ValidationException(message=f\"Inventory item with SKU {item.sku} already exists.\")\n-    \n-    return crud_inventory.create_inventory_item(db=db, item=item, restaurant_id=restaurant_id)\n+        raise ValidationException(\n+            message=f\"Inventory item with SKU {item.sku} already exists.\"\n+        )\n+\n+    return crud_inventory.create_inventory_item(\n+        db=db, item=item, restaurant_id=restaurant_id\n+    )\n+\n \n @router.get(\"/items/{sku}\", response_model=schemas.InventoryItem)\n async def read_inventory_item_api(\n     sku: str,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n-):\n-    # Use current user's restaurant\n-    restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n-    if not restaurant_id:\n-        raise ValidationException(message=\"User must be assigned to a restaurant\", field=\"user\")\n-    \n-    db_item = crud_inventory.get_inventory_item(db, sku=sku, restaurant_id=restaurant_id)\n+    current_user: User = Depends(get_current_user),\n+):\n+    # Use current user's restaurant\n+    restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n+    if not restaurant_id:\n+        raise ValidationException(\n+            message=\"User must be assigned to a restaurant\", field=\"user\"\n+        )\n+\n+    db_item = crud_inventory.get_inventory_item(\n+        db, sku=sku, restaurant_id=restaurant_id\n+    )\n     if db_item is None:\n-        raise ResourceNotFoundException(resource=\"Item\", message=\"Inventory item not found\")\n-    \n+        raise ResourceNotFoundException(\n+            resource=\"Item\", message=\"Inventory item not found\"\n+        )\n+\n     # Verify tenant access\n     await TenantSecurity.validate_restaurant_access(\n         user=current_user,\n         restaurant_id=str(db_item.restaurant_id),\n         operation=\"access\",\n         resource_type=\"inventory\",\n         resource_id=sku,\n-        db=db\n-    )\n-    \n+        db=db,\n+    )\n+\n     return db_item\n+\n \n @router.get(\"/items/\", response_model=List[schemas.InventoryItem])\n async def read_inventory_items_api(\n     skip: int = 0,\n     limit: int = Query(default=100, le=200),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n-):\n-    # Use current user's restaurant\n-    restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n-    if not restaurant_id:\n-        raise ValidationException(message=\"User must be assigned to a restaurant\", field=\"user\")\n-    \n-    items = crud_inventory.get_inventory_items(db, restaurant_id=restaurant_id, skip=skip, limit=limit)\n+    current_user: User = Depends(get_current_user),\n+):\n+    # Use current user's restaurant\n+    restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n+    if not restaurant_id:\n+        raise ValidationException(\n+            message=\"User must be assigned to a restaurant\", field=\"user\"\n+        )\n+\n+    items = crud_inventory.get_inventory_items(\n+        db, restaurant_id=restaurant_id, skip=skip, limit=limit\n+    )\n     return items\n+\n \n @router.put(\"/items/{sku}\", response_model=schemas.InventoryItem)\n async def update_inventory_item_api(\n     sku: str,\n     item_update: schemas.InventoryItemUpdate,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n-):\n-    # Use current user's restaurant\n-    restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n-    if not restaurant_id:\n-        raise ValidationException(message=\"User must be assigned to a restaurant\", field=\"user\")\n-    \n+    current_user: User = Depends(get_current_user),\n+):\n+    # Use current user's restaurant\n+    restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n+    if not restaurant_id:\n+        raise ValidationException(\n+            message=\"User must be assigned to a restaurant\", field=\"user\"\n+        )\n+\n     # Check if item exists and user has access\n-    db_item = crud_inventory.get_inventory_item(db, sku=sku, restaurant_id=restaurant_id)\n+    db_item = crud_inventory.get_inventory_item(\n+        db, sku=sku, restaurant_id=restaurant_id\n+    )\n     if not db_item:\n-        raise ResourceNotFoundException(resource=\"Item\", message=\"Inventory item not found\")\n-    \n+        raise ResourceNotFoundException(\n+            resource=\"Item\", message=\"Inventory item not found\"\n+        )\n+\n     # Verify tenant access\n     await TenantSecurity.validate_restaurant_access(\n         user=current_user,\n         restaurant_id=str(db_item.restaurant_id),\n         operation=\"modify\",\n         resource_type=\"inventory\",\n         resource_id=sku,\n-        db=db\n-    )\n-    \n-    updated_item = crud_inventory.update_inventory_item(db, sku=sku, item_update=item_update, restaurant_id=restaurant_id)\n+        db=db,\n+    )\n+\n+    updated_item = crud_inventory.update_inventory_item(\n+        db, sku=sku, item_update=item_update, restaurant_id=restaurant_id\n+    )\n     return updated_item\n+\n \n @router.delete(\"/items/{sku}\", response_model=schemas.InventoryItem)\n async def delete_inventory_item_api(\n     sku: str,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n-):\n-    # Use current user's restaurant\n-    restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n-    if not restaurant_id:\n-        raise ValidationException(message=\"User must be assigned to a restaurant\", field=\"user\")\n-    \n+    current_user: User = Depends(get_current_user),\n+):\n+    # Use current user's restaurant\n+    restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n+    if not restaurant_id:\n+        raise ValidationException(\n+            message=\"User must be assigned to a restaurant\", field=\"user\"\n+        )\n+\n     # Check if item exists and user has access\n-    db_item = crud_inventory.get_inventory_item(db, sku=sku, restaurant_id=restaurant_id)\n+    db_item = crud_inventory.get_inventory_item(\n+        db, sku=sku, restaurant_id=restaurant_id\n+    )\n     if not db_item:\n-        raise ResourceNotFoundException(resource=\"Item\", message=\"Inventory item not found\")\n-    \n+        raise ResourceNotFoundException(\n+            resource=\"Item\", message=\"Inventory item not found\"\n+        )\n+\n     # Verify tenant access - require owner/manager role for deletion\n     await TenantSecurity.validate_restaurant_access(\n         user=current_user,\n         restaurant_id=str(db_item.restaurant_id),\n         operation=\"delete\",\n         resource_type=\"inventory\",\n         resource_id=sku,\n-        db=db\n-    )\n-    \n+        db=db,\n+    )\n+\n     # Check if item is used in recipes\n     from app.models import Recipe\n+\n     recipes_using_item = db.query(Recipe).filter(Recipe.ingredient_sku == sku).first()\n     if recipes_using_item:\n-        raise ValidationException(message=\"Cannot delete item, it is used in existing recipes.\")\n-\n-    deleted_item = crud_inventory.delete_inventory_item(db, sku=sku, restaurant_id=restaurant_id)\n+        raise ValidationException(\n+            message=\"Cannot delete item, it is used in existing recipes.\"\n+        )\n+\n+    deleted_item = crud_inventory.delete_inventory_item(\n+        db, sku=sku, restaurant_id=restaurant_id\n+    )\n     return deleted_item\n+\n \n @router.post(\"/items/{sku}/adjust-stock\", response_model=schemas.StockAdjustmentResult)\n async def adjust_stock_api(\n     sku: str,\n     adjustment: schemas.StockAdjustment = Body(...),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n-):\n-    # Use current user's restaurant\n-    restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n-    if not restaurant_id:\n-        raise ValidationException(message=\"User must be assigned to a restaurant\", field=\"user\")\n-    \n+    current_user: User = Depends(get_current_user),\n+):\n+    # Use current user's restaurant\n+    restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n+    if not restaurant_id:\n+        raise ValidationException(\n+            message=\"User must be assigned to a restaurant\", field=\"user\"\n+        )\n+\n     if adjustment.sku != sku:\n         raise ValidationException(message=\"SKU in path and body do not match.\")\n-    \n+\n     # Check if item exists and user has access\n-    db_item = crud_inventory.get_inventory_item(db, sku=sku, restaurant_id=restaurant_id)\n+    db_item = crud_inventory.get_inventory_item(\n+        db, sku=sku, restaurant_id=restaurant_id\n+    )\n     if not db_item:\n-        raise ResourceNotFoundException(resource=\"Item\", message=\"Inventory item not found\")\n-    \n+        raise ResourceNotFoundException(\n+            resource=\"Item\", message=\"Inventory item not found\"\n+        )\n+\n     # Verify tenant access\n     await TenantSecurity.validate_restaurant_access(\n         user=current_user,\n         restaurant_id=str(db_item.restaurant_id),\n         operation=\"modify\",\n         resource_type=\"inventory\",\n         resource_id=sku,\n-        db=db\n+        db=db,\n     )\n \n     updated_item, ledger_entry = crud_inventory.adjust_inventory_item_quantity(\n         db,\n         sku=adjustment.sku,\n         change_qty_g=adjustment.change_qty_g,\n         source=adjustment.reason or \"manual_adjustment\",\n         restaurant_id=restaurant_id,\n-        source_id=str(current_user.id)\n+        source_id=str(current_user.id),\n     )\n     if not updated_item:\n-        raise ResourceNotFoundException(resource=\"Resource\", message=f\"Inventory item with SKU {sku} not found.\")\n+        raise ResourceNotFoundException(\n+            resource=\"Resource\", message=f\"Inventory item with SKU {sku} not found.\"\n+        )\n \n     return schemas.StockAdjustmentResult(\n         sku=updated_item.sku,\n         new_qty_g=updated_item.qty_g,\n-        message=f\"Stock for {sku} adjusted by {ledger_entry.delta_g}. New quantity: {updated_item.qty_g}.\"\n-    )\n+        message=f\"Stock for {sku} adjusted by {ledger_entry.delta_g}. New quantity: {updated_item.qty_g}.\",\n+    )\n+\n \n # --- Inventory Ledger Endpoints ---\n+\n \n @router.get(\"/ledger/\", response_model=List[schemas.InventoryLedgerEntry])\n async def read_all_ledger_entries_api(\n     skip: int = 0,\n     limit: int = Query(default=100, le=500),\n     start_date: Optional[datetime] = None,\n     end_date: Optional[datetime] = None,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n-):\n-    # Use current user's restaurant\n-    restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n-    if not restaurant_id:\n-        raise ValidationException(message=\"User must be assigned to a restaurant\", field=\"user\")\n-    \n+    current_user: User = Depends(get_current_user),\n+):\n+    # Use current user's restaurant\n+    restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n+    if not restaurant_id:\n+        raise ValidationException(\n+            message=\"User must be assigned to a restaurant\", field=\"user\"\n+        )\n+\n     entries = crud_inventory.get_all_ledger_entries(\n-        db, \n+        db,\n         restaurant_id=restaurant_id,\n-        skip=skip, \n-        limit=limit, \n-        start_date=start_date, \n-        end_date=end_date\n+        skip=skip,\n+        limit=limit,\n+        start_date=start_date,\n+        end_date=end_date,\n     )\n     return entries\n+\n \n @router.get(\"/ledger/{sku}\", response_model=List[schemas.InventoryLedgerEntry])\n async def read_ledger_entries_for_sku_api(\n     sku: str,\n     skip: int = 0,\n     limit: int = Query(default=100, le=500),\n     start_date: Optional[datetime] = None,\n     end_date: Optional[datetime] = None,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n-):\n-    # Use current user's restaurant\n-    restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n-    if not restaurant_id:\n-        raise ValidationException(message=\"User must be assigned to a restaurant\", field=\"user\")\n-    \n+    current_user: User = Depends(get_current_user),\n+):\n+    # Use current user's restaurant\n+    restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n+    if not restaurant_id:\n+        raise ValidationException(\n+            message=\"User must be assigned to a restaurant\", field=\"user\"\n+        )\n+\n     # Check if SKU exists and user has access\n     item = crud_inventory.get_inventory_item(db, sku, restaurant_id=restaurant_id)\n     if not item:\n-        raise ResourceNotFoundException(resource=\"Resource\", message=f\"Inventory item with SKU {sku} not found.\")\n-    \n+        raise ResourceNotFoundException(\n+            resource=\"Resource\", message=f\"Inventory item with SKU {sku} not found.\"\n+        )\n+\n     # Verify tenant access\n     await TenantSecurity.validate_restaurant_access(\n         user=current_user,\n         restaurant_id=str(item.restaurant_id),\n         operation=\"access\",\n         resource_type=\"inventory_ledger\",\n         resource_id=sku,\n-        db=db\n+        db=db,\n     )\n \n     entries = crud_inventory.get_ledger_entries_for_sku(\n-        db, \n-        sku=sku, \n+        db,\n+        sku=sku,\n         restaurant_id=restaurant_id,\n-        skip=skip, \n-        limit=limit, \n-        start_date=start_date, \n-        end_date=end_date\n+        skip=skip,\n+        limit=limit,\n+        start_date=start_date,\n+        end_date=end_date,\n     )\n     return entries\n \n+\n # --- Inventory Status/Reporting Endpoints ---\n+\n \n @router.get(\"/status/summary\", response_model=List[schemas.InventoryStatusResponse])\n async def get_inventory_status_summary_api(\n-    db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n-):\n-    # Use current user's restaurant\n-    restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n-    if not restaurant_id:\n-        raise ValidationException(message=\"User must be assigned to a restaurant\", field=\"user\")\n-    \n-    summary = crud_inventory.get_inventory_status_summary(db, restaurant_id=restaurant_id)\n+    db: Session = Depends(get_db), current_user: User = Depends(get_current_user)\n+):\n+    # Use current user's restaurant\n+    restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n+    if not restaurant_id:\n+        raise ValidationException(\n+            message=\"User must be assigned to a restaurant\", field=\"user\"\n+        )\n+\n+    summary = crud_inventory.get_inventory_status_summary(\n+        db, restaurant_id=restaurant_id\n+    )\n     return summary\n+\n \n @router.get(\"/status/low-stock\", response_model=List[schemas.LowStockItem])\n async def get_low_stock_items_api(\n-    threshold_percentage: float = Query(default=0.1, ge=0.01, le=1.0, description=\"Threshold percentage for low stock (e.g., 0.1 for 10%)\"),\n-    db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n-):\n-    # Use current user's restaurant\n-    restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n-    if not restaurant_id:\n-        raise ValidationException(message=\"User must be assigned to a restaurant\", field=\"user\")\n-    \n+    threshold_percentage: float = Query(\n+        default=0.1,\n+        ge=0.01,\n+        le=1.0,\n+        description=\"Threshold percentage for low stock (e.g., 0.1 for 10%)\",\n+    ),\n+    db: Session = Depends(get_db),\n+    current_user: User = Depends(get_current_user),\n+):\n+    # Use current user's restaurant\n+    restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n+    if not restaurant_id:\n+        raise ValidationException(\n+            message=\"User must be assigned to a restaurant\", field=\"user\"\n+        )\n+\n     try:\n         low_stock_items = crud_inventory.get_low_stock_items(\n-            db, \n-            restaurant_id=restaurant_id,\n-            threshold_percentage=threshold_percentage\n+            db, restaurant_id=restaurant_id, threshold_percentage=threshold_percentage\n         )\n         return low_stock_items\n     except ValueError as e:\n         raise ValidationException(message=\"Invalid inventory update request\")\n+\n \n # Placeholder for authentication dependency - replace with actual implementation\n # async def get_current_active_user_with_permissions(required_permissions: List[str]):\n #     # This is a placeholder. Implement actual user authentication and permission checking.\n #     # For example, using OAuth2PasswordBearer and a User model.\n@@ -309,50 +384,57 @@\n \n #     pass # Allow all for now for easier testing without setting up full auth\n \n # --- Receipt Scanning Endpoint ---\n \n-class ScanReceiptRequest(schemas.BaseModel): # Use a base model from schemas if available, or pydantic.BaseModel\n+\n+class ScanReceiptRequest(\n+    schemas.BaseModel\n+):  # Use a base model from schemas if available, or pydantic.BaseModel\n     image_base64: str\n \n-class ScannedItemResponse(schemas.BaseModel): # Use a base model from schemas\n+\n+class ScannedItemResponse(schemas.BaseModel):  # Use a base model from schemas\n     name: str\n     quantity: float\n     price: float\n     sku_match: Optional[str] = None\n-    raw_text_name: Optional[str] = None # To show what was parsed vs matched\n+    raw_text_name: Optional[str] = None  # To show what was parsed vs matched\n     raw_text_quantity: Optional[str] = None\n     raw_text_price: Optional[str] = None\n \n \n @router.post(\"/scan\", response_model=List[ScannedItemResponse], status_code=200)\n async def scan_receipt_api(\n     scan_request: ScanReceiptRequest,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"\n     Accepts a base64 encoded image of a receipt, processes it (simulated for now),\n     and returns a list of parsed items.\n     \"\"\"\n     # Use current user's restaurant\n     restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n     if not restaurant_id:\n-        raise ValidationException(message=\"User must be assigned to a restaurant\", field=\"user\")\n-    \n+        raise ValidationException(\n+            message=\"User must be assigned to a restaurant\", field=\"user\"\n+        )\n+\n     # Verify user has permission to scan inventory\n     await TenantSecurity.validate_restaurant_access(\n         user=current_user,\n         restaurant_id=str(restaurant_id),\n         operation=\"create\",\n         resource_type=\"inventory_scan\",\n         resource_id=None,\n-        db=db\n-    )\n-    \n+        db=db,\n+    )\n+\n     # Integration with OCRService\n     from app.services.ocr_service import OCRService\n+\n     ocr_service = OCRService()\n \n     try:\n         image_bytes = base64.b64decode(scan_request.image_base64)\n         # Parse items from OCR service\n@@ -365,24 +447,32 @@\n     # This is where fuzzy matching against DB products would also happen.\n     response_items: List[ScannedItemResponse] = []\n     for ocr_item in parsed_ocr_items:\n         # Simulate fuzzy matching or direct use if OCR provides SKU\n         # sku_match_result = await fuzzy_match_item_name_to_sku(ocr_item.get(\"raw_text_name\"), db)\n-        sku_match_result = f\"SKU_FOR_{ocr_item.get('raw_text_name', '').split(' ')[0]}\" if ocr_item.get('raw_text_name') else None\n+        sku_match_result = (\n+            f\"SKU_FOR_{ocr_item.get('raw_text_name', '').split(' ')[0]}\"\n+            if ocr_item.get(\"raw_text_name\")\n+            else None\n+        )\n \n         response_items.append(\n             ScannedItemResponse(\n-                name=ocr_item.get(\"raw_text_name\", \"Unknown Item\"), # Prefer matched name if available later\n+                name=ocr_item.get(\n+                    \"raw_text_name\", \"Unknown Item\"\n+                ),  # Prefer matched name if available later\n                 quantity=ocr_item.get(\"parsed_quantity\", 0.0) or 0.0,\n                 price=ocr_item.get(\"parsed_price\", 0.0) or 0.0,\n-                sku_match=sku_match_result, # Placeholder\n+                sku_match=sku_match_result,  # Placeholder\n                 raw_text_name=ocr_item.get(\"raw_text_name\"),\n                 raw_text_quantity=ocr_item.get(\"raw_text_quantity\"),\n-                raw_text_price=ocr_item.get(\"raw_text_price\")\n+                raw_text_price=ocr_item.get(\"raw_text_price\"),\n             )\n         )\n \n     # Return empty list if no items were parsed\n     if not response_items:\n-        raise ValidationException(message=\"No items could be parsed from the receipt image. Please ensure the image is clear and contains readable text.\")\n+        raise ValidationException(\n+            message=\"No items could be parsed from the receipt image. Please ensure the image is clear and contains readable text.\"\n+        )\n \n     return response_items\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/monitoring.py\t2025-08-02 21:56:58.986321+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/monitoring.py\t2025-08-02 22:36:02.724544+00:00\n@@ -20,11 +20,11 @@\n from app.core.security import (\n     ReplicaQueryParams,\n     DeploymentQueryParams,\n     DeploymentTriggerRequest,\n     MetricsQueryParams,\n-    RefreshReplicasRequest\n+    RefreshReplicasRequest,\n )\n from app.middleware.rate_limit_middleware import limiter, DEFAULT_RATE\n \n logger = logging.getLogger(__name__)\n \n@@ -36,282 +36,309 @@\n async def get_replica_status(\n     request: Request,\n     query_params: ReplicaQueryParams = Depends(),\n     current_user: User = Depends(get_current_user),\n     redis: RedisClient = Depends(get_redis),\n-    do_monitor: DigitalOceanMonitor = Depends(get_do_monitor)\n+    do_monitor: DigitalOceanMonitor = Depends(get_do_monitor),\n ) -> Dict[str, Any]:\n     \"\"\"\n     Get comprehensive replica status comparing multiple data sources.\n-    \n+\n     This endpoint provides:\n     - Configured replica count from DigitalOcean\n     - Active instances tracked via heartbeat\n     - Discrepancy analysis\n     - Actionable recommendations\n-    \n+\n     Requires authentication - platform owners get full details.\n     \"\"\"\n     # Check if user is platform owner for full access\n     is_platform_owner = current_user.role == \"platform_owner\"\n-    \n+\n     # Get active instances from tracker\n     active_instances = []\n     instance_counts = {\"active\": 0, \"stale\": 0, \"total\": 0}\n-    \n+\n     if instance_tracker:\n         active_instances = await instance_tracker.get_active_instances()\n         instance_counts = await instance_tracker.get_instance_count()\n-    \n+\n     # Get DigitalOcean status if requested\n     do_status = None\n     do_configured = False\n     if query_params.include_do_status:\n         do_status = await do_monitor.get_actual_replicas()\n         do_configured = \"error\" not in do_status\n-    \n+\n     # Calculate discrepancies\n     configured_replicas = do_status.get(\"desired_replicas\", 2) if do_configured else 2\n     active_count = instance_counts[\"active\"]\n     discrepancy = active_count != configured_replicas\n-    \n+\n     # Generate recommendations\n     recommendations = _generate_recommendations(\n         active_count=active_count,\n         configured_count=configured_replicas,\n         stale_count=instance_counts[\"stale\"],\n-        do_configured=do_configured\n-    )\n-    \n+        do_configured=do_configured,\n+    )\n+\n     # Build response\n     response_data = {\n         \"summary\": {\n             \"configured_replicas\": configured_replicas,\n             \"active_instances\": active_count,\n             \"stale_instances\": instance_counts[\"stale\"],\n             \"total_registered\": instance_counts[\"total\"],\n             \"discrepancy\": discrepancy,\n-            \"status\": _get_overall_status(active_count, configured_replicas)\n+            \"status\": _get_overall_status(active_count, configured_replicas),\n         },\n         \"instances\": {\n             \"active\": [\n-                _sanitize_instance_data(inst, is_platform_owner) \n-                for inst in active_instances \n+                _sanitize_instance_data(inst, is_platform_owner)\n+                for inst in active_instances\n                 if _is_instance_active(inst)\n             ],\n-            \"stale\": [\n-                _sanitize_instance_data(inst, is_platform_owner) \n-                for inst in active_instances \n-                if not _is_instance_active(inst)\n-            ] if query_params.include_stale else []\n+            \"stale\": (\n+                [\n+                    _sanitize_instance_data(inst, is_platform_owner)\n+                    for inst in active_instances\n+                    if not _is_instance_active(inst)\n+                ]\n+                if query_params.include_stale\n+                else []\n+            ),\n         },\n-        \"digitalocean\": do_status if is_platform_owner else {\n-            \"configured\": do_configured,\n-            \"desired_replicas\": configured_replicas\n-        },\n+        \"digitalocean\": (\n+            do_status\n+            if is_platform_owner\n+            else {\"configured\": do_configured, \"desired_replicas\": configured_replicas}\n+        ),\n         \"recommendations\": recommendations,\n-        \"last_check\": datetime.now(timezone.utc).isoformat()\n+        \"last_check\": datetime.now(timezone.utc).isoformat(),\n     }\n-    \n+\n     # Add warnings if needed\n     warnings = []\n     if discrepancy:\n         if active_count > configured_replicas:\n-            warnings.append(f\"{active_count - configured_replicas} extra instances detected\")\n+            warnings.append(\n+                f\"{active_count - configured_replicas} extra instances detected\"\n+            )\n         elif active_count < configured_replicas:\n             warnings.append(f\"{configured_replicas - active_count} instances missing\")\n-    \n+\n     if instance_counts[\"stale\"] > 0:\n         warnings.append(f\"{instance_counts['stale']} stale instances detected\")\n-    \n+\n     if warnings:\n         response_data[\"warnings\"] = warnings\n-    \n-    return APIResponseHelper.success(\n-        data=response_data,\n-        message=\"Replica status retrieved successfully\"\n+\n+    return APIResponseHelper.success(\n+        data=response_data, message=\"Replica status retrieved successfully\"\n     )\n \n \n @router.get(\"/metrics\")\n @limiter.limit(DEFAULT_RATE)\n async def get_monitoring_metrics(\n     request: Request,\n     query_params: MetricsQueryParams = Depends(),\n     current_user: User = Depends(get_current_user),\n-    do_monitor: DigitalOceanMonitor = Depends(get_do_monitor)\n+    do_monitor: DigitalOceanMonitor = Depends(get_do_monitor),\n ) -> Dict[str, Any]:\n     \"\"\"\n     Get comprehensive monitoring metrics from DigitalOcean.\n-    \n+\n     Requires platform owner role.\n     \"\"\"\n     if current_user.role != \"platform_owner\":\n-        raise AuthorizationException(message=\"Only platform owners can access detailed metrics\")\n-    \n+        raise AuthorizationException(\n+            message=\"Only platform owners can access detailed metrics\"\n+        )\n+\n     metrics = await do_monitor.get_metrics_summary()\n-    \n-    return APIResponseHelper.success(\n-        data=metrics,\n-        message=\"Monitoring metrics retrieved\"\n+\n+    return APIResponseHelper.success(\n+        data=metrics, message=\"Monitoring metrics retrieved\"\n     )\n \n \n @router.post(\"/replicas/refresh\")\n @limiter.limit(\"10/minute\")  # Stricter limit for refresh operations\n async def refresh_replica_count(\n     request: Request,\n     background_tasks: BackgroundTasks,\n     request_body: RefreshReplicasRequest = Body(...),\n     current_user: User = Depends(get_current_user),\n-    do_monitor: DigitalOceanMonitor = Depends(get_do_monitor)\n+    do_monitor: DigitalOceanMonitor = Depends(get_do_monitor),\n ) -> Dict[str, Any]:\n     \"\"\"\n     Force refresh of replica count by clearing caches.\n-    \n+\n     This endpoint:\n     - Clears DigitalOcean API cache\n     - Triggers stale instance cleanup\n     - Returns fresh status\n-    \n+\n     Requires platform owner role.\n     \"\"\"\n     if current_user.role != \"platform_owner\":\n-        raise AuthorizationException(message=\"Only platform owners can refresh replica status\")\n-    \n+        raise AuthorizationException(\n+            message=\"Only platform owners can refresh replica status\"\n+        )\n+\n     # Clear DO cache and get fresh data if requested\n     if request_body.clear_cache:\n         fresh_status = await do_monitor.get_app_info(force_refresh=True)\n-    \n+\n     # Schedule stale instance cleanup in background if requested\n     if request_body.force_cleanup and instance_tracker:\n         background_tasks.add_task(instance_tracker.cleanup_stale_instances)\n-    \n+\n     # Get updated replica status\n     replica_status = await get_replica_status(current_user)\n-    \n+\n     return APIResponseHelper.success(\n         data={\n             \"refreshed\": True,\n             \"timestamp\": datetime.now(timezone.utc).isoformat(),\n-            \"current_status\": replica_status[\"data\"][\"summary\"]\n+            \"current_status\": replica_status[\"data\"][\"summary\"],\n         },\n-        message=\"Replica status refreshed\"\n+        message=\"Replica status refreshed\",\n     )\n \n \n @router.get(\"/deployments\")\n @limiter.limit(DEFAULT_RATE)\n async def get_recent_deployments(\n     request: Request,\n     query_params: DeploymentQueryParams = Depends(),\n     current_user: User = Depends(get_current_user),\n-    do_monitor: DigitalOceanMonitor = Depends(get_do_monitor)\n+    do_monitor: DigitalOceanMonitor = Depends(get_do_monitor),\n ) -> Dict[str, Any]:\n     \"\"\"\n     Get recent deployment history from DigitalOcean.\n-    \n+\n     Shows deployment phases and causes to help diagnose replica issues.\n     Requires platform owner role.\n     \"\"\"\n     if current_user.role != \"platform_owner\":\n-        raise AuthorizationException(message=\"Only platform owners can view deployment history\")\n-    \n+        raise AuthorizationException(\n+            message=\"Only platform owners can view deployment history\"\n+        )\n+\n     deployments = await do_monitor.get_deployments(limit=query_params.limit)\n-    \n+\n     # Process deployment data\n     processed_deployments = []\n     for deployment in deployments:\n-        processed_deployments.append({\n-            \"id\": deployment.get(\"id\"),\n-            \"phase\": deployment.get(\"phase\"),\n-            \"created_at\": deployment.get(\"created_at\"),\n-            \"updated_at\": deployment.get(\"updated_at\"),\n-            \"cause\": deployment.get(\"cause\"),\n-            \"progress\": deployment.get(\"progress\", {})\n-        })\n-    \n+        processed_deployments.append(\n+            {\n+                \"id\": deployment.get(\"id\"),\n+                \"phase\": deployment.get(\"phase\"),\n+                \"created_at\": deployment.get(\"created_at\"),\n+                \"updated_at\": deployment.get(\"updated_at\"),\n+                \"cause\": deployment.get(\"cause\"),\n+                \"progress\": deployment.get(\"progress\", {}),\n+            }\n+        )\n+\n     return APIResponseHelper.success(\n         data={\n             \"deployments\": processed_deployments,\n             \"total\": len(processed_deployments),\n-            \"app_id\": do_monitor.app_id\n+            \"app_id\": do_monitor.app_id,\n         },\n-        message=\"Deployment history retrieved\"\n+        message=\"Deployment history retrieved\",\n     )\n \n \n @router.post(\"/deployments/trigger\")\n @limiter.limit(\"2/hour\")  # Very strict limit for deployment triggers\n async def trigger_deployment(\n     request: Request,\n     request_body: DeploymentTriggerRequest = Body(...),\n     current_user: User = Depends(get_current_user),\n-    do_monitor: DigitalOceanMonitor = Depends(get_do_monitor)\n+    do_monitor: DigitalOceanMonitor = Depends(get_do_monitor),\n ) -> Dict[str, Any]:\n     \"\"\"\n     Trigger a new deployment to refresh instance metrics.\n-    \n+\n     WARNING: This will cause a brief service interruption.\n     Use only as a last resort to fix replica count issues.\n-    \n+\n     Requires platform owner role and explicit confirmation.\n     \"\"\"\n     if current_user.role != \"platform_owner\":\n-        raise AuthorizationException(message=\"Only platform owners can trigger deployments\")\n-    \n+        raise AuthorizationException(\n+            message=\"Only platform owners can trigger deployments\"\n+        )\n+\n     # Log deployment trigger with reason\n-    logger.warning(f\"Deployment triggered by {current_user.email}. Reason: {request_body.reason}\")\n-    \n+    logger.warning(\n+        f\"Deployment triggered by {current_user.email}. Reason: {request_body.reason}\"\n+    )\n+\n     # Pass force_rebuild parameter to the monitor\n-    result = await do_monitor.force_deployment_refresh(force_rebuild=request_body.force_rebuild)\n-    \n+    result = await do_monitor.force_deployment_refresh(\n+        force_rebuild=request_body.force_rebuild\n+    )\n+\n     if \"error\" in result:\n         return APIResponseHelper.error(\n-            message=\"Failed to trigger deployment\",\n-            errors=result\n-        )\n-    \n-    return APIResponseHelper.success(\n-        data=result,\n-        message=\"Deployment triggered successfully\"\n+            message=\"Failed to trigger deployment\", errors=result\n+        )\n+\n+    return APIResponseHelper.success(\n+        data=result, message=\"Deployment triggered successfully\"\n     )\n \n \n # Helper functions\n \n+\n def _generate_recommendations(\n-    active_count: int, \n-    configured_count: int, \n-    stale_count: int,\n-    do_configured: bool\n+    active_count: int, configured_count: int, stale_count: int, do_configured: bool\n ) -> List[str]:\n     \"\"\"Generate actionable recommendations based on current state.\"\"\"\n     recommendations = []\n-    \n+\n     if not do_configured:\n-        recommendations.append(\"Configure DO_API_TOKEN and DO_APP_ID environment variables for full monitoring\")\n-    \n+        recommendations.append(\n+            \"Configure DO_API_TOKEN and DO_APP_ID environment variables for full monitoring\"\n+        )\n+\n     if active_count > configured_count:\n         diff = active_count - configured_count\n-        recommendations.append(f\"ACTION: {diff} extra instances detected. Check for stuck deployments.\")\n+        recommendations.append(\n+            f\"ACTION: {diff} extra instances detected. Check for stuck deployments.\"\n+        )\n         recommendations.append(\"TRY: Use 'doctl apps update' to force scale reset\")\n-        recommendations.append(\"TRY: Trigger a new deployment to refresh instance count\")\n-    \n+        recommendations.append(\n+            \"TRY: Trigger a new deployment to refresh instance count\"\n+        )\n+\n     elif active_count < configured_count:\n         diff = configured_count - active_count\n-        recommendations.append(f\"ACTION: {diff} instances missing. Check deployment logs for failures.\")\n+        recommendations.append(\n+            f\"ACTION: {diff} instances missing. Check deployment logs for failures.\"\n+        )\n         recommendations.append(\"TRY: Review recent deployments for errors\")\n         recommendations.append(\"TRY: Ensure health checks are passing\")\n-    \n+\n     if stale_count > 0:\n-        recommendations.append(f\"WARNING: {stale_count} stale instances should be cleaned up automatically\")\n+        recommendations.append(\n+            f\"WARNING: {stale_count} stale instances should be cleaned up automatically\"\n+        )\n         recommendations.append(\"TRY: Use the refresh endpoint to force cleanup\")\n-    \n+\n     if active_count == configured_count and stale_count == 0:\n-        recommendations.append(\"\u2713 Instance count matches configuration - no action needed\")\n-    \n+        recommendations.append(\n+            \"\u2713 Instance count matches configuration - no action needed\"\n+        )\n+\n     return recommendations\n \n \n def _get_overall_status(active: int, configured: int) -> str:\n     \"\"\"Determine overall system status.\"\"\"\n@@ -325,29 +352,31 @@\n         return \"under_provisioned\"\n \n \n def _is_instance_active(instance: Dict[str, Any]) -> bool:\n     \"\"\"Check if an instance is considered active based on heartbeat.\"\"\"\n-    last_heartbeat_str = instance.get('last_heartbeat')\n+    last_heartbeat_str = instance.get(\"last_heartbeat\")\n     if not last_heartbeat_str:\n         return False\n-    \n+\n     try:\n         last_heartbeat = datetime.fromisoformat(last_heartbeat_str)\n         age_seconds = (datetime.now(timezone.utc) - last_heartbeat).total_seconds()\n         return age_seconds <= 60  # Active if heartbeat within 60 seconds\n     except Exception as e:\n         return False\n \n \n-def _sanitize_instance_data(instance: Dict[str, Any], full_access: bool) -> Dict[str, Any]:\n+def _sanitize_instance_data(\n+    instance: Dict[str, Any], full_access: bool\n+) -> Dict[str, Any]:\n     \"\"\"Sanitize instance data based on user access level.\"\"\"\n     if full_access:\n         return instance\n-    \n+\n     # Limited data for non-platform owners\n     return {\n         \"instance_id\": instance.get(\"instance_id\"),\n         \"status\": instance.get(\"status\"),\n         \"last_heartbeat\": instance.get(\"last_heartbeat\"),\n-        \"environment\": instance.get(\"environment\")\n-    }\n\\ No newline at end of file\n+        \"environment\": instance.get(\"environment\"),\n+    }\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/menu_optimized.py\t2025-08-02 21:56:58.986138+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/menu_optimized.py\t2025-08-02 22:36:02.722010+00:00\n@@ -20,34 +20,37 @@\n router = APIRouter()\n \n \n class MenuItemResponse:\n     \"\"\"Response model for menu items\"\"\"\n+\n     def __init__(self, product, category_name=None):\n         self.id = str(product.id)\n         self.name = product.name\n         self.description = product.description\n         self.price = float(product.price)\n         self.category_id = str(product.category_id)\n-        self.category_name = category_name or (product.category.name if product.category else None)\n+        self.category_name = category_name or (\n+            product.category.name if product.category else None\n+        )\n         self.is_active = product.is_active\n         self.sort_order = product.sort_order\n         self.image_url = product.image_url\n         self.modifiers = product.modifiers or []\n         self.variants = []\n-        if hasattr(product, 'variants') and product.variants:\n+        if hasattr(product, \"variants\") and product.variants:\n             self.variants = [\n-                {\n-                    \"id\": str(v.id),\n-                    \"name\": v.name,\n-                    \"price\": float(v.price),\n-                    \"sku\": v.sku\n-                } for v in product.variants\n+                {\"id\": str(v.id), \"name\": v.name, \"price\": float(v.price), \"sku\": v.sku}\n+                for v in product.variants\n             ]\n-        self.allergens = product.dietary_info if hasattr(product, 'dietary_info') else []\n+        self.allergens = (\n+            product.dietary_info if hasattr(product, \"dietary_info\") else []\n+        )\n         self.nutritional_info = {}\n-        self.preparation_time = product.prep_time if hasattr(product, 'prep_time') else 0\n+        self.preparation_time = (\n+            product.prep_time if hasattr(product, \"prep_time\") else 0\n+        )\n         self.created_at = product.created_at.isoformat()\n         self.updated_at = product.updated_at.isoformat()\n         return {\n             \"id\": self.id,\n             \"name\": self.name,\n@@ -62,34 +65,43 @@\n             \"variants\": self.variants,\n             \"allergens\": self.allergens,\n             \"nutritional_info\": self.nutritional_info,\n             \"preparation_time\": self.preparation_time,\n             \"created_at\": self.created_at,\n-            \"updated_at\": self.updated_at\n+            \"updated_at\": self.updated_at,\n         }\n \n \n class CategoryResponse:\n     \"\"\"Response model for categories\"\"\"\n+\n     def __init__(self, category, product_count=0):\n         self.id = str(category.id)\n         self.name = category.name\n         self.description = category.description\n         self.sort_order = category.sort_order\n         self.icon = category.icon\n         self.product_count = product_count\n-        self.created_at = category.created_at.isoformat() if hasattr(category, 'created_at') else datetime.now().isoformat()\n-        self.updated_at = category.updated_at.isoformat() if hasattr(category, 'updated_at') else datetime.now().isoformat()\n+        self.created_at = (\n+            category.created_at.isoformat()\n+            if hasattr(category, \"created_at\")\n+            else datetime.now().isoformat()\n+        )\n+        self.updated_at = (\n+            category.updated_at.isoformat()\n+            if hasattr(category, \"updated_at\")\n+            else datetime.now().isoformat()\n+        )\n         return {\n             \"id\": self.id,\n             \"name\": self.name,\n             \"description\": self.description,\n             \"sort_order\": self.sort_order,\n             \"icon\": self.icon,\n             \"product_count\": self.product_count,\n             \"created_at\": self.created_at,\n-            \"updated_at\": self.updated_at\n+            \"updated_at\": self.updated_at,\n         }\n \n \n @router.get(\"/menu\", response_model=List[dict])\n async def get_menu_items_optimized(\n@@ -98,280 +110,268 @@\n     page: int = Query(1, ge=1),\n     limit: int = Query(50, ge=1, le=100),\n     include_inactive: bool = Query(False),\n     db: Session = Depends(get_db),\n     redis_client: RedisClient = Depends(get_redis),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"\n     Get menu items with optimized performance\n     - Eager loading to prevent N+1 queries\n     - Redis caching with smart invalidation\n     - Pagination for large menus\n     - Query timeout protection\n     \"\"\"\n     try:\n         # Use current user's restaurant context\n-        user_restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n+        user_restaurant_id = (\n+            current_user.current_restaurant_id or current_user.restaurant_id\n+        )\n         if not user_restaurant_id:\n             raise FynloException(\n                 message=\"User must be assigned to a restaurant\",\n                 error_code=ErrorCodes.VALIDATION_ERROR,\n-                status_code=400\n-            )\n-        \n+                status_code=400,\n+            )\n+\n         # Use provided restaurant_id or fallback to user's current restaurant\n         if not restaurant_id:\n             restaurant_id = str(user_restaurant_id)\n         else:\n             # Validate that user has access to the requested restaurant\n             from app.core.tenant_security import TenantSecurity\n+\n             await TenantSecurity.validate_restaurant_access(\n                 user=current_user,\n                 restaurant_id=restaurant_id,\n                 operation=\"access\",\n                 resource_type=\"menu\",\n                 resource_id=None,\n-                db=db\n+                db=db,\n             )\n         # Build cache key\n         cache_key = f\"menu:v3:{restaurant_id}:{category or 'all'}:{page}:{limit}:{include_inactive}\"\n-        \n+\n         # Try cache first\n         if redis_client:\n             try:\n                 cached_data = redis_client.get(cache_key)\n                 if cached_data:\n                     logger.info(f\"Menu cache hit for restaurant {restaurant_id}\")\n                     return APIResponseHelper.success(\n                         data=json.loads(cached_data),\n-                        message=\"Menu retrieved from cache\"\n+                        message=\"Menu retrieved from cache\",\n                     )\n             except Exception as e:\n                 logger.warning(f\"Redis cache error: {e}\")\n-        \n+\n         # Build optimized query with eager loading\n-        query = db.query(Product).options(\n-            selectinload(Product.category),\n-            selectinload(Product.modifiers),\n-            selectinload(Product.variants),\n-            selectinload(Product.images)\n-        ).filter(Product.restaurant_id == restaurant_id)\n-        \n+        query = (\n+            db.query(Product)\n+            .options(\n+                selectinload(Product.category),\n+                selectinload(Product.modifiers),\n+                selectinload(Product.variants),\n+                selectinload(Product.images),\n+            )\n+            .filter(Product.restaurant_id == restaurant_id)\n+        )\n+\n         # Apply filters\n         if not include_inactive:\n             query = query.filter(Product.is_active == True)\n-        \n+\n         if category:\n             query = query.filter(Product.category_id == category)\n-        \n+\n         # Add consistent ordering\n-        query = query.order_by(\n-            Product.sort_order.asc(),\n-            Product.name.asc()\n-        )\n-        \n+        query = query.order_by(Product.sort_order.asc(), Product.name.asc())\n+\n         # Apply pagination\n         offset = (page - 1) * limit\n         query = query.offset(offset).limit(limit)\n-        \n+\n         # Execute query\n         products = query.all()\n-        \n+\n         # Transform to response format\n-        response_data = [\n-            MenuItemResponse(product).dict()\n-            for product in products\n-        ]\n-        \n+        response_data = [MenuItemResponse(product).dict() for product in products]\n+\n         # Cache for 5 minutes\n         if redis_client and response_data:\n             try:\n                 redis_client.setex(\n-                    cache_key,\n-                    300,  # 5 minutes TTL\n-                    json.dumps(response_data)\n+                    cache_key, 300, json.dumps(response_data)  # 5 minutes TTL\n                 )\n             except Exception as e:\n                 logger.warning(f\"Failed to cache menu: {e}\")\n-        \n+\n         return APIResponseHelper.success(\n             data=response_data,\n             message=\"Menu retrieved successfully\",\n-            meta={\n-                \"page\": page,\n-                \"limit\": limit,\n-                \"has_more\": len(products) == limit\n-            }\n-        )\n-        \n+            meta={\"page\": page, \"limit\": limit, \"has_more\": len(products) == limit},\n+        )\n+\n     except Exception as e:\n         logger.error(f\"Menu query error for restaurant {restaurant_id}: {str(e)}\")\n         raise FynloException(\n             message=\"Failed to retrieve menu items\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n+            status_code=500,\n         )\n \n \n @router.get(\"/menu/categories\", response_model=List[dict])\n async def get_menu_categories(\n     restaurant_id: Optional[str] = Query(None),\n     db: Session = Depends(get_db),\n     redis_client: RedisClient = Depends(get_redis),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Get menu categories with product counts\"\"\"\n     try:\n         # Use current user's restaurant context\n-        user_restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n+        user_restaurant_id = (\n+            current_user.current_restaurant_id or current_user.restaurant_id\n+        )\n         if not user_restaurant_id:\n             raise FynloException(\n                 message=\"User must be assigned to a restaurant\",\n                 error_code=ErrorCodes.VALIDATION_ERROR,\n-                status_code=400\n-            )\n-        \n+                status_code=400,\n+            )\n+\n         # Use provided restaurant_id or fallback to user's current restaurant\n         if not restaurant_id:\n             restaurant_id = str(user_restaurant_id)\n         else:\n             # Validate that user has access to the requested restaurant\n             from app.core.tenant_security import TenantSecurity\n+\n             await TenantSecurity.validate_restaurant_access(\n                 user=current_user,\n                 restaurant_id=restaurant_id,\n                 operation=\"access\",\n                 resource_type=\"menu\",\n                 resource_id=None,\n-                db=db\n+                db=db,\n             )\n         cache_key = f\"menu_categories:v2:{restaurant_id}\"\n-        \n+\n         # Try cache\n         if redis_client:\n             try:\n                 cached_data = redis_client.get(cache_key)\n                 if cached_data:\n                     return APIResponseHelper.success(\n                         data=json.loads(cached_data),\n-                        message=\"Categories retrieved from cache\"\n+                        message=\"Categories retrieved from cache\",\n                     )\n             except Exception as e:\n                 logger.warning(f\"Redis cache error: {e}\")\n-        \n+\n         # Query with product counts using subquery for performance\n-        categories_query = db.query(\n-            Category,\n-            func.count(Product.id).label('product_count')\n-        ).outerjoin(\n-            Product,\n-            and_(\n-                Product.category_id == Category.id,\n-                Product.is_active == True\n-            )\n-        ).filter(\n-            Category.restaurant_id == restaurant_id,\n-            Category.is_active == True\n-        ).group_by(\n-            Category.id\n-        ).order_by(Category.sort_order.asc())\n-        \n+        categories_query = (\n+            db.query(Category, func.count(Product.id).label(\"product_count\"))\n+            .outerjoin(\n+                Product,\n+                and_(Product.category_id == Category.id, Product.is_active == True),\n+            )\n+            .filter(Category.restaurant_id == restaurant_id, Category.is_active == True)\n+            .group_by(Category.id)\n+            .order_by(Category.sort_order.asc())\n+        )\n+\n         categories_data = categories_query.all()\n-        \n+\n         response_data = [\n             CategoryResponse(cat, product_count).dict()\n             for cat, product_count in categories_data\n         ]\n-        \n+\n         # Cache for 10 minutes\n         if redis_client and response_data:\n             try:\n                 redis_client.setex(\n-                    cache_key,\n-                    600,  # 10 minutes TTL\n-                    json.dumps(response_data)\n+                    cache_key, 600, json.dumps(response_data)  # 10 minutes TTL\n                 )\n             except Exception as e:\n                 logger.warning(f\"Failed to cache categories: {e}\")\n-        \n+\n         return APIResponseHelper.success(\n-            data=response_data,\n-            message=\"Categories retrieved successfully\"\n-        )\n-        \n+            data=response_data, message=\"Categories retrieved successfully\"\n+        )\n+\n     except Exception as e:\n         logger.error(f\"Category query error for restaurant {restaurant_id}: {str(e)}\")\n         raise FynloException(\n             message=\"Failed to retrieve categories\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n+            status_code=500,\n         )\n \n \n @router.post(\"/menu/cache/invalidate\")\n async def invalidate_menu_cache(\n     restaurant_id: Optional[str] = Query(None),\n     current_user: User = Depends(get_current_user),\n     redis_client: RedisClient = Depends(get_redis),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Invalidate menu cache for a restaurant\"\"\"\n     try:\n         # Use current user's restaurant context\n-        user_restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n+        user_restaurant_id = (\n+            current_user.current_restaurant_id or current_user.restaurant_id\n+        )\n         if not user_restaurant_id:\n             raise FynloException(\n                 message=\"User must be assigned to a restaurant\",\n                 error_code=ErrorCodes.VALIDATION_ERROR,\n-                status_code=400\n-            )\n-        \n+                status_code=400,\n+            )\n+\n         # Use provided restaurant_id or fallback to user's current restaurant\n         if not restaurant_id:\n             restaurant_id = str(user_restaurant_id)\n         else:\n             # Validate that user has access to the requested restaurant\n             from app.core.tenant_security import TenantSecurity\n+\n             await TenantSecurity.validate_restaurant_access(\n                 user=current_user,\n                 restaurant_id=restaurant_id,\n                 operation=\"modify\",\n                 resource_type=\"menu_cache\",\n                 resource_id=None,\n-                db=db\n-            )\n-        \n+                db=db,\n+            )\n+\n         if not redis_client:\n-            return APIResponseHelper.success(\n-                message=\"Cache not available\"\n-            )\n-        \n+            return APIResponseHelper.success(message=\"Cache not available\")\n+\n         # Invalidate all menu caches for restaurant\n-        patterns = [\n-            f\"menu:*:{restaurant_id}:*\",\n-            f\"menu_categories:*:{restaurant_id}\"\n-        ]\n-        \n+        patterns = [f\"menu:*:{restaurant_id}:*\", f\"menu_categories:*:{restaurant_id}\"]\n+\n         deleted_count = 0\n         for pattern in patterns:\n             try:\n                 keys = redis_client.keys(pattern)\n                 if keys:\n                     deleted_count += redis_client.delete(*keys)\n             except Exception as e:\n                 logger.error(f\"Cache invalidation error: {e}\")\n-        \n+\n         return APIResponseHelper.success(\n             message=f\"Menu cache invalidated ({deleted_count} keys cleared)\",\n-            meta={\"deleted_keys\": deleted_count}\n-        )\n-        \n+            meta={\"deleted_keys\": deleted_count},\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         logger.error(f\"Cache invalidation error: {str(e)}\")\n         raise FynloException(\n             message=\"Failed to invalidate cache\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n\\ No newline at end of file\n+            status_code=500,\n+        )\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/files.py\t2025-08-02 19:23:36.807763+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/files.py\t2025-08-02 22:36:02.737445+00:00\n@@ -16,102 +16,110 @@\n from app.core.responses import APIResponseHelper\n from app.core.exceptions import FynloException, ErrorCodes\n \n router = APIRouter()\n \n+\n # Product Image Upload Models\n class ProductImageUpload(BaseModel):\n     \"\"\"Product image upload request\"\"\"\n+\n     image_data: str  # Base64 encoded image\n     alt_text: Optional[str] = None\n     filename: Optional[str] = None\n \n+\n class RestaurantLogoUpload(BaseModel):\n     \"\"\"Restaurant logo upload request\"\"\"\n+\n     image_data: str  # Base64 encoded image\n     alt_text: Optional[str] = None\n     filename: Optional[str] = None\n \n+\n class FileUploadResponse(BaseModel):\n     \"\"\"Standardized file upload response\"\"\"\n+\n     file_id: str\n     original_url: str\n     thumbnail_url: Optional[str]\n     variants: dict\n     metadata: dict\n \n+\n # Product Image Endpoints\n @router.post(\"/products/{product_id}/image\")\n async def upload_product_image(\n     product_id: str = Path(..., description=\"Product ID\"),\n     upload_data: ProductImageUpload = ...,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"\n     Upload base64 image for a product (iOS optimized)\n-    \n+\n     This endpoint accepts base64 encoded images from mobile devices\n     and generates multiple size variants for optimal mobile performance.\n     \"\"\"\n     try:\n         # Verify product exists and user has access\n         product = db.query(Product).filter(Product.id == product_id).first()\n         if not product:\n             raise FynloException(\n                 message=\"Product not found\",\n                 error_code=ErrorCodes.NOT_FOUND,\n-                status_code=404\n-            )\n-        \n+                status_code=404,\n+            )\n+\n         # Check permissions\n         if str(product.restaurant_id) != str(current_user.restaurant_id):\n             if current_user.role != \"platform_owner\":\n                 raise FynloException(\n                     message=\"Access denied - not your restaurant's product\",\n                     error_code=ErrorCodes.FORBIDDEN,\n-                    status_code=403\n-                )\n-        \n+                    status_code=403,\n+                )\n+\n         # Upload image\n         upload_result = await file_upload_service.upload_base64_image(\n             base64_data=upload_data.image_data,\n             upload_type=\"product\",\n             filename=upload_data.filename or f\"product_{product.name}\",\n-            generate_variants=True\n-        )\n-        \n+            generate_variants=True,\n+        )\n+\n         # Update product with image URL\n         product.image_url = upload_result.original_url\n         db.commit()\n-        \n+\n         return APIResponseHelper.success(\n             data=FileUploadResponse(\n                 file_id=upload_result.file_id,\n                 original_url=upload_result.original_url,\n                 thumbnail_url=upload_result.thumbnail_url,\n                 variants=upload_result.variants,\n-                metadata=upload_result.metadata\n+                metadata=upload_result.metadata,\n             ).dict(),\n-            message=\"Product image uploaded successfully\"\n-        )\n-        \n+            message=\"Product image uploaded successfully\",\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Product image upload failed: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n @router.get(\"/products/{product_id}/image\")\n async def get_product_image(\n     product_id: str = Path(..., description=\"Product ID\"),\n     size: Optional[str] = Query(\"original\", description=\"Image size variant\"),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"\n     Get product image URL with size variants\n     \"\"\"\n     try:\n@@ -119,47 +127,47 @@\n         product = db.query(Product).filter(Product.id == product_id).first()\n         if not product:\n             raise FynloException(\n                 message=\"Product not found\",\n                 error_code=ErrorCodes.NOT_FOUND,\n-                status_code=404\n-            )\n-        \n+                status_code=404,\n+            )\n+\n         if not product.image_url:\n             raise FynloException(\n                 message=\"Product has no image\",\n                 error_code=ErrorCodes.NOT_FOUND,\n-                status_code=404\n-            )\n-        \n+                status_code=404,\n+            )\n+\n         # For size variants, we'd need to store metadata in database\n         # For now, return the original URL\n         image_data = {\n             \"original_url\": product.image_url,\n             \"product_id\": str(product.id),\n-            \"product_name\": product.name\n+            \"product_name\": product.name,\n         }\n-        \n+\n         return APIResponseHelper.success(\n-            data=image_data,\n-            message=\"Product image retrieved successfully\"\n-        )\n-        \n+            data=image_data, message=\"Product image retrieved successfully\"\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to retrieve product image: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n @router.delete(\"/products/{product_id}/image\")\n async def delete_product_image(\n     product_id: str = Path(..., description=\"Product ID\"),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"\n     Delete product image\n     \"\"\"\n     try:\n@@ -167,54 +175,53 @@\n         product = db.query(Product).filter(Product.id == product_id).first()\n         if not product:\n             raise FynloException(\n                 message=\"Product not found\",\n                 error_code=ErrorCodes.NOT_FOUND,\n-                status_code=404\n-            )\n-        \n+                status_code=404,\n+            )\n+\n         # Check permissions\n         if str(product.restaurant_id) != str(current_user.restaurant_id):\n             if current_user.role != \"platform_owner\":\n                 raise FynloException(\n                     message=\"Access denied\",\n                     error_code=ErrorCodes.FORBIDDEN,\n-                    status_code=403\n-                )\n-        \n+                    status_code=403,\n+                )\n+\n         if not product.image_url:\n             raise FynloException(\n                 message=\"Product has no image to delete\",\n                 error_code=ErrorCodes.NOT_FOUND,\n-                status_code=404\n-            )\n-        \n+                status_code=404,\n+            )\n+\n         # Extract file_id from URL (simplified - in production you'd store this)\n         # For now, just clear the URL\n         product.image_url = None\n         db.commit()\n-        \n-        return APIResponseHelper.success(\n-            message=\"Product image deleted successfully\"\n-        )\n-        \n+\n+        return APIResponseHelper.success(message=\"Product image deleted successfully\")\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to delete product image: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n # Restaurant Logo Endpoints\n @router.post(\"/restaurants/{restaurant_id}/logo\")\n async def upload_restaurant_logo(\n     restaurant_id: str = Path(..., description=\"Restaurant ID\"),\n     upload_data: RestaurantLogoUpload = ...,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"\n     Upload base64 logo for a restaurant (iOS optimized)\n     \"\"\"\n     try:\n@@ -222,73 +229,74 @@\n         restaurant = db.query(Restaurant).filter(Restaurant.id == restaurant_id).first()\n         if not restaurant:\n             raise FynloException(\n                 message=\"Restaurant not found\",\n                 error_code=ErrorCodes.NOT_FOUND,\n-                status_code=404\n-            )\n-        \n+                status_code=404,\n+            )\n+\n         # Check permissions\n         if current_user.role == \"platform_owner\":\n             # Platform owners can update any restaurant in their platform\n             if str(restaurant.platform_id) != str(current_user.platform_id):\n                 raise FynloException(\n                     message=\"Access denied - not your platform's restaurant\",\n                     error_code=ErrorCodes.FORBIDDEN,\n-                    status_code=403\n+                    status_code=403,\n                 )\n         else:\n             # Restaurant users can only update their own restaurant\n             if str(restaurant.id) != str(current_user.restaurant_id):\n                 raise FynloException(\n                     message=\"Access denied - not your restaurant\",\n                     error_code=ErrorCodes.FORBIDDEN,\n-                    status_code=403\n-                )\n-        \n+                    status_code=403,\n+                )\n+\n         # Upload logo\n         upload_result = await file_upload_service.upload_base64_image(\n             base64_data=upload_data.image_data,\n             upload_type=\"restaurant\",\n             filename=upload_data.filename or f\"logo_{restaurant.name}\",\n-            generate_variants=True\n-        )\n-        \n+            generate_variants=True,\n+        )\n+\n         # Update restaurant settings with logo URL\n         if not restaurant.settings:\n             restaurant.settings = {}\n-        \n+\n         restaurant.settings[\"logo_url\"] = upload_result.original_url\n         restaurant.settings[\"logo_variants\"] = upload_result.variants\n         db.commit()\n-        \n+\n         return APIResponseHelper.success(\n             data=FileUploadResponse(\n                 file_id=upload_result.file_id,\n                 original_url=upload_result.original_url,\n                 thumbnail_url=upload_result.thumbnail_url,\n                 variants=upload_result.variants,\n-                metadata=upload_result.metadata\n+                metadata=upload_result.metadata,\n             ).dict(),\n-            message=\"Restaurant logo uploaded successfully\"\n-        )\n-        \n+            message=\"Restaurant logo uploaded successfully\",\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Restaurant logo upload failed: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n @router.get(\"/restaurants/{restaurant_id}/logo\")\n async def get_restaurant_logo(\n     restaurant_id: str = Path(..., description=\"Restaurant ID\"),\n     size: Optional[str] = Query(\"original\", description=\"Logo size variant\"),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"\n     Get restaurant logo URL with size variants\n     \"\"\"\n     try:\n@@ -296,155 +304,158 @@\n         restaurant = db.query(Restaurant).filter(Restaurant.id == restaurant_id).first()\n         if not restaurant:\n             raise FynloException(\n                 message=\"Restaurant not found\",\n                 error_code=ErrorCodes.NOT_FOUND,\n-                status_code=404\n-            )\n-        \n+                status_code=404,\n+            )\n+\n         logo_url = restaurant.settings.get(\"logo_url\") if restaurant.settings else None\n         if not logo_url:\n             raise FynloException(\n                 message=\"Restaurant has no logo\",\n                 error_code=ErrorCodes.NOT_FOUND,\n-                status_code=404\n-            )\n-        \n-        logo_variants = restaurant.settings.get(\"logo_variants\", {}) if restaurant.settings else {}\n-        \n+                status_code=404,\n+            )\n+\n+        logo_variants = (\n+            restaurant.settings.get(\"logo_variants\", {}) if restaurant.settings else {}\n+        )\n+\n         logo_data = {\n             \"original_url\": logo_url,\n             \"variants\": logo_variants,\n             \"restaurant_id\": str(restaurant.id),\n-            \"restaurant_name\": restaurant.name\n+            \"restaurant_name\": restaurant.name,\n         }\n-        \n+\n         return APIResponseHelper.success(\n-            data=logo_data,\n-            message=\"Restaurant logo retrieved successfully\"\n-        )\n-        \n+            data=logo_data, message=\"Restaurant logo retrieved successfully\"\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to retrieve restaurant logo: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n # File Serving Endpoint\n @router.get(\"/files/{file_type}/{filename}\")\n async def serve_file(\n     file_type: str = Path(..., description=\"File type (products, restaurants, etc.)\"),\n-    filename: str = Path(..., description=\"Filename\")\n+    filename: str = Path(..., description=\"Filename\"),\n ):\n     \"\"\"\n     Serve uploaded files with proper caching headers\n     \"\"\"\n     try:\n         # Map file types to directories\n         type_dirs = {\n-            'products': 'products',\n-            'restaurants': 'restaurants', \n-            'receipts': 'receipts',\n-            'profiles': 'profiles'\n+            \"products\": \"products\",\n+            \"restaurants\": \"restaurants\",\n+            \"receipts\": \"receipts\",\n+            \"profiles\": \"profiles\",\n         }\n-        \n+\n         if file_type not in type_dirs:\n             raise FynloException(\n                 message=\"Invalid file type\",\n                 error_code=ErrorCodes.NOT_FOUND,\n-                status_code=404\n-            )\n-        \n+                status_code=404,\n+            )\n+\n         # Construct file path\n         file_path = os.path.join(\"uploads\", type_dirs[file_type], filename)\n-        \n+\n         if not os.path.exists(file_path):\n             raise FynloException(\n                 message=\"File not found\",\n                 error_code=ErrorCodes.NOT_FOUND,\n-                status_code=404\n-            )\n-        \n+                status_code=404,\n+            )\n+\n         # Serve file with caching headers\n         return FileResponse(\n             path=file_path,\n             headers={\n                 \"Cache-Control\": \"max-age=3600\",  # Cache for 1 hour\n-                \"ETag\": f'\"{os.path.getmtime(file_path)}\"'\n-            }\n-        )\n-        \n+                \"ETag\": f'\"{os.path.getmtime(file_path)}\"',\n+            },\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to serve file: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n # Batch Upload Endpoint (for multiple images)\n @router.post(\"/batch-upload\")\n async def batch_upload_images(\n     upload_requests: list[ImageUploadRequest],\n-    upload_type: str = Query(\"product\", description=\"Upload type (product, restaurant, etc.)\"),\n-    db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    upload_type: str = Query(\n+        \"product\", description=\"Upload type (product, restaurant, etc.)\"\n+    ),\n+    db: Session = Depends(get_db),\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"\n     Batch upload multiple images (iOS optimized)\n     \"\"\"\n     try:\n         if len(upload_requests) > 10:\n             raise FynloException(\n                 message=\"Maximum 10 images per batch upload\",\n                 error_code=ErrorCodes.VALIDATION_ERROR,\n-                status_code=400\n-            )\n-        \n+                status_code=400,\n+            )\n+\n         results = []\n         for i, upload_request in enumerate(upload_requests):\n             try:\n                 upload_result = await file_upload_service.upload_base64_image(\n                     base64_data=upload_request.image_data,\n                     upload_type=upload_type,\n                     filename=upload_request.filename or f\"batch_{i}\",\n-                    generate_variants=upload_request.generate_thumbnails\n-                )\n-                \n-                results.append({\n-                    \"success\": True,\n-                    \"index\": i,\n-                    \"file_id\": upload_result.file_id,\n-                    \"original_url\": upload_result.original_url,\n-                    \"thumbnail_url\": upload_result.thumbnail_url,\n-                    \"variants\": upload_result.variants\n-                })\n-                \n+                    generate_variants=upload_request.generate_thumbnails,\n+                )\n+\n+                results.append(\n+                    {\n+                        \"success\": True,\n+                        \"index\": i,\n+                        \"file_id\": upload_result.file_id,\n+                        \"original_url\": upload_result.original_url,\n+                        \"thumbnail_url\": upload_result.thumbnail_url,\n+                        \"variants\": upload_result.variants,\n+                    }\n+                )\n+\n             except Exception as e:\n-                results.append({\n-                    \"success\": False,\n-                    \"index\": i,\n-                    \"error\": str(e)\n-                })\n-        \n+                results.append({\"success\": False, \"index\": i, \"error\": str(e)})\n+\n         return APIResponseHelper.success(\n             data={\n                 \"results\": results,\n                 \"total\": len(upload_requests),\n                 \"successful\": sum(1 for r in results if r[\"success\"]),\n-                \"failed\": sum(1 for r in results if not r[\"success\"])\n+                \"failed\": sum(1 for r in results if not r[\"success\"]),\n             },\n-            message=\"Batch upload completed\"\n-        )\n-        \n+            message=\"Batch upload completed\",\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Batch upload failed: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n\\ No newline at end of file\n+            status_code=500,\n+        )\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/analytics.py\t2025-08-02 21:56:58.983595+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/analytics.py\t2025-08-02 22:36:02.756871+00:00\n@@ -15,58 +15,70 @@\n from app.core.responses import APIResponseHelper\n from app.core.exceptions import FynloException, ErrorCodes\n from app.core.analytics_engine import get_analytics_engine, AnalyticsTimeframe\n \n router = APIRouter()\n+\n \n # Pydantic models for analytics responses\n class RevenueMetrics(BaseModel):\n     total_revenue: float\n     daily_revenue: float\n     weekly_revenue: float\n     monthly_revenue: float\n     revenue_growth: float\n \n+\n class OrderMetrics(BaseModel):\n     total_orders: int\n     daily_orders: int\n     weekly_orders: int\n     monthly_orders: int\n     average_order_value: float\n     order_growth: float\n \n+\n class CustomerMetrics(BaseModel):\n     total_customers: int\n     new_customers_today: int\n     new_customers_week: int\n     new_customers_month: int\n     returning_customers: int\n     customer_retention_rate: float\n \n+\n class PaymentMethodBreakdown(BaseModel):\n     qr_payments: float\n     card_payments: float\n     cash_payments: float\n     apple_pay: float\n     other_payments: float\n+\n \n class AnalyticsDashboard(BaseModel):\n     revenue_metrics: RevenueMetrics\n     order_metrics: OrderMetrics\n     customer_metrics: CustomerMetrics\n     payment_breakdown: PaymentMethodBreakdown\n     peak_hours: List[dict]\n     top_products: List[dict]\n \n+\n @router.get(\"/dashboard/overview\")\n async def get_enhanced_dashboard_overview(\n-    timeframe: str = Query(\"day\", description=\"Timeframe: hour, day, week, month, quarter, year\"),\n-    start_date: Optional[str] = Query(None, description=\"Custom start date (ISO format)\"),\n+    timeframe: str = Query(\n+        \"day\", description=\"Timeframe: hour, day, week, month, quarter, year\"\n+    ),\n+    start_date: Optional[str] = Query(\n+        None, description=\"Custom start date (ISO format)\"\n+    ),\n     end_date: Optional[str] = Query(None, description=\"Custom end date (ISO format)\"),\n-    restaurant_id: Optional[str] = Query(None, description=\"Specific restaurant ID (platform owners)\"),\n+    restaurant_id: Optional[str] = Query(\n+        None, description=\"Specific restaurant ID (platform owners)\"\n+    ),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"\n     Get enhanced dashboard overview with real-time metrics\n     Optimized for mobile consumption with comprehensive analytics\n     \"\"\"\n@@ -74,85 +86,92 @@\n         # Determine restaurant scope\n         if current_user.role == \"platform_owner\":\n             target_restaurant_id = restaurant_id or str(current_user.restaurant_id)\n         else:\n             target_restaurant_id = str(current_user.restaurant_id)\n-        \n+\n         if not target_restaurant_id:\n             raise FynloException(\n                 message=\"Restaurant context required\",\n                 error_code=ErrorCodes.VALIDATION_ERROR,\n-                status_code=400\n-            )\n-        \n+                status_code=400,\n+            )\n+\n         # Parse dates if provided\n         parsed_start_date = None\n         parsed_end_date = None\n-        \n+\n         if start_date:\n             try:\n-                parsed_start_date = datetime.fromisoformat(start_date.replace(\"Z\", \"+00:00\"))\n+                parsed_start_date = datetime.fromisoformat(\n+                    start_date.replace(\"Z\", \"+00:00\")\n+                )\n             except ValueError:\n                 raise FynloException(\n                     message=\"Invalid start_date format\",\n                     error_code=ErrorCodes.VALIDATION_ERROR,\n-                    status_code=400\n-                )\n-        \n+                    status_code=400,\n+                )\n+\n         if end_date:\n             try:\n-                parsed_end_date = datetime.fromisoformat(end_date.replace(\"Z\", \"+00:00\"))\n+                parsed_end_date = datetime.fromisoformat(\n+                    end_date.replace(\"Z\", \"+00:00\")\n+                )\n             except ValueError:\n                 raise FynloException(\n                     message=\"Invalid end_date format\",\n                     error_code=ErrorCodes.VALIDATION_ERROR,\n-                    status_code=400\n-                )\n-        \n+                    status_code=400,\n+                )\n+\n         # Validate timeframe\n         try:\n             analytics_timeframe = AnalyticsTimeframe(timeframe)\n         except ValueError:\n             raise FynloException(\n                 message=f\"Invalid timeframe: {timeframe}\",\n                 error_code=ErrorCodes.VALIDATION_ERROR,\n-                status_code=400\n-            )\n-        \n+                status_code=400,\n+            )\n+\n         # Get analytics engine and generate dashboard\n         analytics_engine = get_analytics_engine(db)\n         dashboard_data = analytics_engine.get_dashboard_overview(\n             restaurant_id=target_restaurant_id,\n             timeframe=analytics_timeframe,\n             start_date=parsed_start_date,\n-            end_date=parsed_end_date\n-        )\n-        \n+            end_date=parsed_end_date,\n+        )\n+\n         return APIResponseHelper.success(\n             data=dashboard_data,\n             message=\"Dashboard overview retrieved successfully\",\n             meta={\n                 \"restaurant_id\": target_restaurant_id,\n                 \"timeframe\": timeframe,\n-                \"mobile_optimized\": True\n-            }\n-        )\n-        \n+                \"mobile_optimized\": True,\n+            },\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to get dashboard overview: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n @router.get(\"/dashboard/mobile\")\n async def get_mobile_reports_dashboard(\n-    restaurant_id: Optional[str] = Query(None, description=\"Specific restaurant ID (platform owners)\"),\n+    restaurant_id: Optional[str] = Query(\n+        None, description=\"Specific restaurant ID (platform owners)\"\n+    ),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"\n     Get mobile-optimized reports dashboard data\n     Matches exactly the data structure expected by ReportsScreenSimple.tsx\n     \"\"\"\n@@ -167,29 +186,33 @@\n         today_start = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)\n         today_end = today_start + timedelta(days=1)\n         week_start = today_start - timedelta(days=7)\n \n         # Today's Summary\n-        today_orders = db.query(Order).filter(\n-            and_(\n-                Order.restaurant_id == target_restaurant_id,\n-                Order.status == \"completed\",\n-                Order.created_at >= today_start,\n-                Order.created_at < today_end\n-            )\n-        ).all()\n+        today_orders = (\n+            db.query(Order)\n+            .filter(\n+                and_(\n+                    Order.restaurant_id == target_restaurant_id,\n+                    Order.status == \"completed\",\n+                    Order.created_at >= today_start,\n+                    Order.created_at < today_end,\n+                )\n+            )\n+            .all()\n+        )\n \n         total_sales = sum(order.total_amount for order in today_orders)\n         total_transactions = len(today_orders)\n         avg_order = total_sales / total_transactions if total_transactions > 0 else 0\n \n         # Weekly Labor - Feature not yet implemented\n         weekly_labor = {\n             \"totalActualHours\": 0,\n             \"totalLaborCost\": 0.00,\n             \"efficiency\": 0.0,\n-            \"message\": \"Labor tracking feature coming soon\"\n+            \"message\": \"Labor tracking feature coming soon\",\n         }\n \n         # Top Items Today (from order items)\n         item_sales = {}\n         for order in today_orders:\n@@ -199,187 +222,231 @@\n                     item_sales[item.product_name][\"revenue\"] += item.subtotal\n                 else:\n                     item_sales[item.product_name] = {\n                         \"name\": item.product_name,\n                         \"quantity\": item.quantity,\n-                        \"revenue\": item.subtotal\n+                        \"revenue\": item.subtotal,\n                     }\n \n-        top_items = sorted(item_sales.values(), key=lambda x: x[\"revenue\"], reverse=True)[:5]\n+        top_items = sorted(\n+            item_sales.values(), key=lambda x: x[\"revenue\"], reverse=True\n+        )[:5]\n \n         # Top Performers - Feature not yet implemented\n         top_performers = []  # Will be populated when employee tracking is implemented\n \n         # Sales Trend (last 7 days)\n         sales_trend = []\n         for i in range(7):\n             day_start = today_start - timedelta(days=i)\n             day_end = day_start + timedelta(days=1)\n-            day_orders = db.query(func.sum(Order.total_amount)).filter(\n-                and_(\n-                    Order.restaurant_id == target_restaurant_id,\n-                    Order.status == \"completed\",\n-                    Order.created_at >= day_start,\n-                    Order.created_at < day_end\n-                )\n-            ).scalar() or 0\n-\n-            sales_trend.append({\n-                \"period\": day_start.strftime(\"%a\"),\n-                \"sales\": float(day_orders)\n-            })\n+            day_orders = (\n+                db.query(func.sum(Order.total_amount))\n+                .filter(\n+                    and_(\n+                        Order.restaurant_id == target_restaurant_id,\n+                        Order.status == \"completed\",\n+                        Order.created_at >= day_start,\n+                        Order.created_at < day_end,\n+                    )\n+                )\n+                .scalar()\n+                or 0\n+            )\n+\n+            sales_trend.append(\n+                {\"period\": day_start.strftime(\"%a\"), \"sales\": float(day_orders)}\n+            )\n \n         # Structure response to match frontend expectations\n         response_data = {\n             \"todaySummary\": {\n                 \"totalSales\": float(total_sales),\n                 \"transactions\": total_transactions,\n                 \"averageOrder\": float(avg_order),\n                 \"totalRevenue\": float(total_sales),\n                 \"totalOrders\": total_transactions,\n-                \"averageOrderValue\": float(avg_order)\n+                \"averageOrderValue\": float(avg_order),\n             },\n             \"weeklyLabor\": weekly_labor,\n             \"topItemsToday\": top_items,\n             \"topPerformersToday\": top_performers,\n-            \"salesTrend\": list(reversed(sales_trend))  # Reverse to show oldest first\n+            \"salesTrend\": list(reversed(sales_trend)),  # Reverse to show oldest first\n         }\n \n         return APIResponseHelper.success(\n-            data=response_data,\n-            message=\"Mobile dashboard data retrieved successfully\"\n+            data=response_data, message=\"Mobile dashboard data retrieved successfully\"\n         )\n \n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to get mobile dashboard data: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n @router.get(\"/dashboard\", response_model=AnalyticsDashboard)\n async def get_legacy_analytics_dashboard(\n     restaurant_id: Optional[str] = Query(None),\n     days: int = Query(30, le=365),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Get legacy analytics dashboard (maintained for backward compatibility)\"\"\"\n-    \n+\n     # Determine restaurant scope\n     if current_user.role == \"platform_owner\":\n         # Platform owners can see specific restaurant or all\n         if restaurant_id:\n             restaurants = [restaurant_id]\n         else:\n             # Get all restaurants in platform\n-            platform_restaurants = db.query(Restaurant).filter(\n-                Restaurant.platform_id == current_user.platform_id\n-            ).all()\n+            platform_restaurants = (\n+                db.query(Restaurant)\n+                .filter(Restaurant.platform_id == current_user.platform_id)\n+                .all()\n+            )\n             restaurants = [str(r.id) for r in platform_restaurants]\n     else:\n         # Restaurant users see only their own data\n         restaurants = [str(current_user.restaurant_id)]\n-    \n+\n     # Date ranges\n     today_start = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)\n     week_start = today_start - timedelta(days=7)\n     month_start = today_start - timedelta(days=30)\n     period_start = today_start - timedelta(days=days)\n-    \n+\n     # Revenue Metrics\n-    total_revenue = db.query(func.sum(Order.total_amount)).filter(\n-        and_(\n-            Order.restaurant_id.in_(restaurants),\n-            Order.status == \"completed\",\n-            Order.created_at >= period_start\n-        )\n-    ).scalar() or 0\n-    \n-    daily_revenue = db.query(func.sum(Order.total_amount)).filter(\n-        and_(\n-            Order.restaurant_id.in_(restaurants),\n-            Order.status == \"completed\",\n-            Order.created_at >= today_start\n-        )\n-    ).scalar() or 0\n-    \n-    weekly_revenue = db.query(func.sum(Order.total_amount)).filter(\n-        and_(\n-            Order.restaurant_id.in_(restaurants),\n-            Order.status == \"completed\",\n-            Order.created_at >= week_start\n-        )\n-    ).scalar() or 0\n-    \n-    monthly_revenue = db.query(func.sum(Order.total_amount)).filter(\n-        and_(\n-            Order.restaurant_id.in_(restaurants),\n-            Order.status == \"completed\",\n-            Order.created_at >= month_start\n-        )\n-    ).scalar() or 0\n-    \n+    total_revenue = (\n+        db.query(func.sum(Order.total_amount))\n+        .filter(\n+            and_(\n+                Order.restaurant_id.in_(restaurants),\n+                Order.status == \"completed\",\n+                Order.created_at >= period_start,\n+            )\n+        )\n+        .scalar()\n+        or 0\n+    )\n+\n+    daily_revenue = (\n+        db.query(func.sum(Order.total_amount))\n+        .filter(\n+            and_(\n+                Order.restaurant_id.in_(restaurants),\n+                Order.status == \"completed\",\n+                Order.created_at >= today_start,\n+            )\n+        )\n+        .scalar()\n+        or 0\n+    )\n+\n+    weekly_revenue = (\n+        db.query(func.sum(Order.total_amount))\n+        .filter(\n+            and_(\n+                Order.restaurant_id.in_(restaurants),\n+                Order.status == \"completed\",\n+                Order.created_at >= week_start,\n+            )\n+        )\n+        .scalar()\n+        or 0\n+    )\n+\n+    monthly_revenue = (\n+        db.query(func.sum(Order.total_amount))\n+        .filter(\n+            and_(\n+                Order.restaurant_id.in_(restaurants),\n+                Order.status == \"completed\",\n+                Order.created_at >= month_start,\n+            )\n+        )\n+        .scalar()\n+        or 0\n+    )\n+\n     # Order Metrics\n-    total_orders = db.query(Order).filter(\n-        and_(\n-            Order.restaurant_id.in_(restaurants),\n-            Order.created_at >= period_start\n-        )\n-    ).count()\n-    \n-    daily_orders = db.query(Order).filter(\n-        and_(\n-            Order.restaurant_id.in_(restaurants),\n-            Order.created_at >= today_start\n-        )\n-    ).count()\n-    \n-    weekly_orders = db.query(Order).filter(\n-        and_(\n-            Order.restaurant_id.in_(restaurants),\n-            Order.created_at >= week_start\n-        )\n-    ).count()\n-    \n-    monthly_orders = db.query(Order).filter(\n-        and_(\n-            Order.restaurant_id.in_(restaurants),\n-            Order.created_at >= month_start\n-        )\n-    ).count()\n-    \n+    total_orders = (\n+        db.query(Order)\n+        .filter(\n+            and_(Order.restaurant_id.in_(restaurants), Order.created_at >= period_start)\n+        )\n+        .count()\n+    )\n+\n+    daily_orders = (\n+        db.query(Order)\n+        .filter(\n+            and_(Order.restaurant_id.in_(restaurants), Order.created_at >= today_start)\n+        )\n+        .count()\n+    )\n+\n+    weekly_orders = (\n+        db.query(Order)\n+        .filter(\n+            and_(Order.restaurant_id.in_(restaurants), Order.created_at >= week_start)\n+        )\n+        .count()\n+    )\n+\n+    monthly_orders = (\n+        db.query(Order)\n+        .filter(\n+            and_(Order.restaurant_id.in_(restaurants), Order.created_at >= month_start)\n+        )\n+        .count()\n+    )\n+\n     avg_order_value = (total_revenue / total_orders) if total_orders > 0 else 0\n-    \n+\n     # Customer Metrics\n-    total_customers = db.query(Customer).filter(\n-        Customer.restaurant_id.in_(restaurants)\n-    ).count()\n-    \n-    new_customers_today = db.query(Customer).filter(\n-        and_(\n-            Customer.restaurant_id.in_(restaurants),\n-            Customer.created_at >= today_start\n-        )\n-    ).count()\n-    \n-    new_customers_week = db.query(Customer).filter(\n-        and_(\n-            Customer.restaurant_id.in_(restaurants),\n-            Customer.created_at >= week_start\n-        )\n-    ).count()\n-    \n-    new_customers_month = db.query(Customer).filter(\n-        and_(\n-            Customer.restaurant_id.in_(restaurants),\n-            Customer.created_at >= month_start\n-        )\n-    ).count()\n-    \n+    total_customers = (\n+        db.query(Customer).filter(Customer.restaurant_id.in_(restaurants)).count()\n+    )\n+\n+    new_customers_today = (\n+        db.query(Customer)\n+        .filter(\n+            and_(\n+                Customer.restaurant_id.in_(restaurants),\n+                Customer.created_at >= today_start,\n+            )\n+        )\n+        .count()\n+    )\n+\n+    new_customers_week = (\n+        db.query(Customer)\n+        .filter(\n+            and_(\n+                Customer.restaurant_id.in_(restaurants),\n+                Customer.created_at >= week_start,\n+            )\n+        )\n+        .count()\n+    )\n+\n+    new_customers_month = (\n+        db.query(Customer)\n+        .filter(\n+            and_(\n+                Customer.restaurant_id.in_(restaurants),\n+                Customer.created_at >= month_start,\n+            )\n+        )\n+        .count()\n+    )\n+\n     # Calculate growth metrics - proper implementation needed\n     revenue_growth = 0.0\n     order_growth = 0.0\n     customer_retention_rate = 0.0\n     returning_customers = 0\n@@ -387,56 +454,63 @@\n     payment_breakdown = PaymentMethodBreakdown(\n         qr_payments=0.0,\n         card_payments=0.0,\n         cash_payments=0.0,\n         apple_pay=0.0,\n-        other_payments=0.0\n-    )\n-    \n+        other_payments=0.0,\n+    )\n+\n     # Peak hours - Feature not yet implemented\n     peak_hours = []  # Will be populated with real hourly analytics\n-    \n+\n     # Top products - Feature not yet implemented\n     top_products = []  # Will be populated with real product analytics\n-    \n+\n     return AnalyticsDashboard(\n         revenue_metrics=RevenueMetrics(\n             total_revenue=float(total_revenue),\n             daily_revenue=float(daily_revenue),\n             weekly_revenue=float(weekly_revenue),\n             monthly_revenue=float(monthly_revenue),\n-            revenue_growth=revenue_growth\n+            revenue_growth=revenue_growth,\n         ),\n         order_metrics=OrderMetrics(\n             total_orders=total_orders,\n             daily_orders=daily_orders,\n             weekly_orders=weekly_orders,\n             monthly_orders=monthly_orders,\n             average_order_value=round(avg_order_value, 2),\n-            order_growth=order_growth\n+            order_growth=order_growth,\n         ),\n         customer_metrics=CustomerMetrics(\n             total_customers=total_customers,\n             new_customers_today=new_customers_today,\n             new_customers_week=new_customers_week,\n             new_customers_month=new_customers_month,\n             returning_customers=returning_customers,\n-            customer_retention_rate=customer_retention_rate\n+            customer_retention_rate=customer_retention_rate,\n         ),\n         payment_breakdown=payment_breakdown,\n         peak_hours=peak_hours,\n-        top_products=top_products\n-    )\n+        top_products=top_products,\n+    )\n+\n \n @router.get(\"/sales\")\n async def get_enhanced_sales_analytics(\n-    timeframe: str = Query(\"day\", description=\"Timeframe: hour, day, week, month, quarter, year\"),\n-    start_date: Optional[str] = Query(None, description=\"Custom start date (ISO format)\"),\n+    timeframe: str = Query(\n+        \"day\", description=\"Timeframe: hour, day, week, month, quarter, year\"\n+    ),\n+    start_date: Optional[str] = Query(\n+        None, description=\"Custom start date (ISO format)\"\n+    ),\n     end_date: Optional[str] = Query(None, description=\"Custom end date (ISO format)\"),\n-    restaurant_id: Optional[str] = Query(None, description=\"Specific restaurant ID (platform owners)\"),\n+    restaurant_id: Optional[str] = Query(\n+        None, description=\"Specific restaurant ID (platform owners)\"\n+    ),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"\n     Get enhanced sales analytics with comprehensive reporting\n     Optimized for mobile consumption with detailed sales insights\n     \"\"\"\n@@ -444,88 +518,99 @@\n         # Determine restaurant scope\n         if current_user.role == \"platform_owner\":\n             target_restaurant_id = restaurant_id or str(current_user.restaurant_id)\n         else:\n             target_restaurant_id = str(current_user.restaurant_id)\n-        \n+\n         if not target_restaurant_id:\n             raise FynloException(\n                 message=\"Restaurant context required\",\n                 error_code=ErrorCodes.VALIDATION_ERROR,\n-                status_code=400\n-            )\n-        \n+                status_code=400,\n+            )\n+\n         # Parse dates if provided\n         parsed_start_date = None\n         parsed_end_date = None\n-        \n+\n         if start_date:\n             try:\n-                parsed_start_date = datetime.fromisoformat(start_date.replace(\"Z\", \"+00:00\"))\n+                parsed_start_date = datetime.fromisoformat(\n+                    start_date.replace(\"Z\", \"+00:00\")\n+                )\n             except ValueError:\n                 raise FynloException(\n                     message=\"Invalid start_date format\",\n                     error_code=ErrorCodes.VALIDATION_ERROR,\n-                    status_code=400\n-                )\n-        \n+                    status_code=400,\n+                )\n+\n         if end_date:\n             try:\n-                parsed_end_date = datetime.fromisoformat(end_date.replace(\"Z\", \"+00:00\"))\n+                parsed_end_date = datetime.fromisoformat(\n+                    end_date.replace(\"Z\", \"+00:00\")\n+                )\n             except ValueError:\n                 raise FynloException(\n                     message=\"Invalid end_date format\",\n                     error_code=ErrorCodes.VALIDATION_ERROR,\n-                    status_code=400\n-                )\n-        \n+                    status_code=400,\n+                )\n+\n         # Validate timeframe\n         try:\n             analytics_timeframe = AnalyticsTimeframe(timeframe)\n         except ValueError:\n             raise FynloException(\n                 message=f\"Invalid timeframe: {timeframe}\",\n                 error_code=ErrorCodes.VALIDATION_ERROR,\n-                status_code=400\n-            )\n-        \n+                status_code=400,\n+            )\n+\n         # Get analytics engine and generate sales data\n         analytics_engine = get_analytics_engine(db)\n         sales_data = analytics_engine.get_sales_analytics(\n             restaurant_id=target_restaurant_id,\n             timeframe=analytics_timeframe,\n             start_date=parsed_start_date,\n-            end_date=parsed_end_date\n-        )\n-        \n+            end_date=parsed_end_date,\n+        )\n+\n         return APIResponseHelper.success(\n             data=sales_data,\n             message=\"Sales analytics retrieved successfully\",\n             meta={\n                 \"restaurant_id\": target_restaurant_id,\n                 \"timeframe\": timeframe,\n-                \"mobile_optimized\": True\n-            }\n-        )\n-        \n+                \"mobile_optimized\": True,\n+            },\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to get sales analytics: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n @router.get(\"/employees\")\n async def get_enhanced_employee_performance(\n-    timeframe: str = Query(\"day\", description=\"Timeframe: hour, day, week, month, quarter, year\"),\n-    start_date: Optional[str] = Query(None, description=\"Custom start date (ISO format)\"),\n+    timeframe: str = Query(\n+        \"day\", description=\"Timeframe: hour, day, week, month, quarter, year\"\n+    ),\n+    start_date: Optional[str] = Query(\n+        None, description=\"Custom start date (ISO format)\"\n+    ),\n     end_date: Optional[str] = Query(None, description=\"Custom end date (ISO format)\"),\n-    restaurant_id: Optional[str] = Query(None, description=\"Specific restaurant ID (platform owners)\"),\n+    restaurant_id: Optional[str] = Query(\n+        None, description=\"Specific restaurant ID (platform owners)\"\n+    ),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"\n     Get enhanced employee performance analytics\n     Optimized for mobile consumption with staff productivity insights\n     \"\"\"\n@@ -533,88 +618,99 @@\n         # Determine restaurant scope\n         if current_user.role == \"platform_owner\":\n             target_restaurant_id = restaurant_id or str(current_user.restaurant_id)\n         else:\n             target_restaurant_id = str(current_user.restaurant_id)\n-        \n+\n         if not target_restaurant_id:\n             raise FynloException(\n                 message=\"Restaurant context required\",\n                 error_code=ErrorCodes.VALIDATION_ERROR,\n-                status_code=400\n-            )\n-        \n+                status_code=400,\n+            )\n+\n         # Parse dates if provided\n         parsed_start_date = None\n         parsed_end_date = None\n-        \n+\n         if start_date:\n             try:\n-                parsed_start_date = datetime.fromisoformat(start_date.replace(\"Z\", \"+00:00\"))\n+                parsed_start_date = datetime.fromisoformat(\n+                    start_date.replace(\"Z\", \"+00:00\")\n+                )\n             except ValueError:\n                 raise FynloException(\n                     message=\"Invalid start_date format\",\n                     error_code=ErrorCodes.VALIDATION_ERROR,\n-                    status_code=400\n-                )\n-        \n+                    status_code=400,\n+                )\n+\n         if end_date:\n             try:\n-                parsed_end_date = datetime.fromisoformat(end_date.replace(\"Z\", \"+00:00\"))\n+                parsed_end_date = datetime.fromisoformat(\n+                    end_date.replace(\"Z\", \"+00:00\")\n+                )\n             except ValueError:\n                 raise FynloException(\n                     message=\"Invalid end_date format\",\n                     error_code=ErrorCodes.VALIDATION_ERROR,\n-                    status_code=400\n-                )\n-        \n+                    status_code=400,\n+                )\n+\n         # Validate timeframe\n         try:\n             analytics_timeframe = AnalyticsTimeframe(timeframe)\n         except ValueError:\n             raise FynloException(\n                 message=f\"Invalid timeframe: {timeframe}\",\n                 error_code=ErrorCodes.VALIDATION_ERROR,\n-                status_code=400\n-            )\n-        \n+                status_code=400,\n+            )\n+\n         # Get analytics engine and generate employee performance data\n         analytics_engine = get_analytics_engine(db)\n         employee_data = analytics_engine.get_employee_performance(\n             restaurant_id=target_restaurant_id,\n             timeframe=analytics_timeframe,\n             start_date=parsed_start_date,\n-            end_date=parsed_end_date\n-        )\n-        \n+            end_date=parsed_end_date,\n+        )\n+\n         return APIResponseHelper.success(\n             data=employee_data,\n             message=\"Employee performance analytics retrieved successfully\",\n             meta={\n                 \"restaurant_id\": target_restaurant_id,\n                 \"timeframe\": timeframe,\n-                \"mobile_optimized\": True\n-            }\n-        )\n-        \n+                \"mobile_optimized\": True,\n+            },\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to get employee performance analytics: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n @router.get(\"/customers\")\n async def get_enhanced_customer_analytics(\n-    timeframe: str = Query(\"day\", description=\"Timeframe: hour, day, week, month, quarter, year\"),\n-    start_date: Optional[str] = Query(None, description=\"Custom start date (ISO format)\"),\n+    timeframe: str = Query(\n+        \"day\", description=\"Timeframe: hour, day, week, month, quarter, year\"\n+    ),\n+    start_date: Optional[str] = Query(\n+        None, description=\"Custom start date (ISO format)\"\n+    ),\n     end_date: Optional[str] = Query(None, description=\"Custom end date (ISO format)\"),\n-    restaurant_id: Optional[str] = Query(None, description=\"Specific restaurant ID (platform owners)\"),\n+    restaurant_id: Optional[str] = Query(\n+        None, description=\"Specific restaurant ID (platform owners)\"\n+    ),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"\n     Get enhanced customer behavior analytics and insights\n     Optimized for mobile consumption with customer lifecycle data\n     \"\"\"\n@@ -622,88 +718,99 @@\n         # Determine restaurant scope\n         if current_user.role == \"platform_owner\":\n             target_restaurant_id = restaurant_id or str(current_user.restaurant_id)\n         else:\n             target_restaurant_id = str(current_user.restaurant_id)\n-        \n+\n         if not target_restaurant_id:\n             raise FynloException(\n                 message=\"Restaurant context required\",\n                 error_code=ErrorCodes.VALIDATION_ERROR,\n-                status_code=400\n-            )\n-        \n+                status_code=400,\n+            )\n+\n         # Parse dates if provided\n         parsed_start_date = None\n         parsed_end_date = None\n-        \n+\n         if start_date:\n             try:\n-                parsed_start_date = datetime.fromisoformat(start_date.replace(\"Z\", \"+00:00\"))\n+                parsed_start_date = datetime.fromisoformat(\n+                    start_date.replace(\"Z\", \"+00:00\")\n+                )\n             except ValueError:\n                 raise FynloException(\n                     message=\"Invalid start_date format\",\n                     error_code=ErrorCodes.VALIDATION_ERROR,\n-                    status_code=400\n-                )\n-        \n+                    status_code=400,\n+                )\n+\n         if end_date:\n             try:\n-                parsed_end_date = datetime.fromisoformat(end_date.replace(\"Z\", \"+00:00\"))\n+                parsed_end_date = datetime.fromisoformat(\n+                    end_date.replace(\"Z\", \"+00:00\")\n+                )\n             except ValueError:\n                 raise FynloException(\n                     message=\"Invalid end_date format\",\n                     error_code=ErrorCodes.VALIDATION_ERROR,\n-                    status_code=400\n-                )\n-        \n+                    status_code=400,\n+                )\n+\n         # Validate timeframe\n         try:\n             analytics_timeframe = AnalyticsTimeframe(timeframe)\n         except ValueError:\n             raise FynloException(\n                 message=f\"Invalid timeframe: {timeframe}\",\n                 error_code=ErrorCodes.VALIDATION_ERROR,\n-                status_code=400\n-            )\n-        \n+                status_code=400,\n+            )\n+\n         # Get analytics engine and generate customer analytics\n         analytics_engine = get_analytics_engine(db)\n         customer_data = analytics_engine.get_customer_analytics(\n             restaurant_id=target_restaurant_id,\n             timeframe=analytics_timeframe,\n             start_date=parsed_start_date,\n-            end_date=parsed_end_date\n-        )\n-        \n+            end_date=parsed_end_date,\n+        )\n+\n         return APIResponseHelper.success(\n             data=customer_data,\n             message=\"Customer analytics retrieved successfully\",\n             meta={\n                 \"restaurant_id\": target_restaurant_id,\n                 \"timeframe\": timeframe,\n-                \"mobile_optimized\": True\n-            }\n-        )\n-        \n+                \"mobile_optimized\": True,\n+            },\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to get customer analytics: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n @router.get(\"/inventory\")\n async def get_enhanced_inventory_analytics(\n-    timeframe: str = Query(\"day\", description=\"Timeframe: hour, day, week, month, quarter, year\"),\n-    start_date: Optional[str] = Query(None, description=\"Custom start date (ISO format)\"),\n+    timeframe: str = Query(\n+        \"day\", description=\"Timeframe: hour, day, week, month, quarter, year\"\n+    ),\n+    start_date: Optional[str] = Query(\n+        None, description=\"Custom start date (ISO format)\"\n+    ),\n     end_date: Optional[str] = Query(None, description=\"Custom end date (ISO format)\"),\n-    restaurant_id: Optional[str] = Query(None, description=\"Specific restaurant ID (platform owners)\"),\n+    restaurant_id: Optional[str] = Query(\n+        None, description=\"Specific restaurant ID (platform owners)\"\n+    ),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"\n     Get enhanced inventory analytics and stock insights\n     Optimized for mobile consumption with product performance data\n     \"\"\"\n@@ -711,85 +818,92 @@\n         # Determine restaurant scope\n         if current_user.role == \"platform_owner\":\n             target_restaurant_id = restaurant_id or str(current_user.restaurant_id)\n         else:\n             target_restaurant_id = str(current_user.restaurant_id)\n-        \n+\n         if not target_restaurant_id:\n             raise FynloException(\n                 message=\"Restaurant context required\",\n                 error_code=ErrorCodes.VALIDATION_ERROR,\n-                status_code=400\n-            )\n-        \n+                status_code=400,\n+            )\n+\n         # Parse dates if provided\n         parsed_start_date = None\n         parsed_end_date = None\n-        \n+\n         if start_date:\n             try:\n-                parsed_start_date = datetime.fromisoformat(start_date.replace(\"Z\", \"+00:00\"))\n+                parsed_start_date = datetime.fromisoformat(\n+                    start_date.replace(\"Z\", \"+00:00\")\n+                )\n             except ValueError:\n                 raise FynloException(\n                     message=\"Invalid start_date format\",\n                     error_code=ErrorCodes.VALIDATION_ERROR,\n-                    status_code=400\n-                )\n-        \n+                    status_code=400,\n+                )\n+\n         if end_date:\n             try:\n-                parsed_end_date = datetime.fromisoformat(end_date.replace(\"Z\", \"+00:00\"))\n+                parsed_end_date = datetime.fromisoformat(\n+                    end_date.replace(\"Z\", \"+00:00\")\n+                )\n             except ValueError:\n                 raise FynloException(\n                     message=\"Invalid end_date format\",\n                     error_code=ErrorCodes.VALIDATION_ERROR,\n-                    status_code=400\n-                )\n-        \n+                    status_code=400,\n+                )\n+\n         # Validate timeframe\n         try:\n             analytics_timeframe = AnalyticsTimeframe(timeframe)\n         except ValueError:\n             raise FynloException(\n                 message=f\"Invalid timeframe: {timeframe}\",\n                 error_code=ErrorCodes.VALIDATION_ERROR,\n-                status_code=400\n-            )\n-        \n+                status_code=400,\n+            )\n+\n         # Get analytics engine and generate inventory analytics\n         analytics_engine = get_analytics_engine(db)\n         inventory_data = analytics_engine.get_inventory_analytics(\n             restaurant_id=target_restaurant_id,\n             timeframe=analytics_timeframe,\n             start_date=parsed_start_date,\n-            end_date=parsed_end_date\n-        )\n-        \n+            end_date=parsed_end_date,\n+        )\n+\n         return APIResponseHelper.success(\n             data=inventory_data,\n             message=\"Inventory analytics retrieved successfully\",\n             meta={\n                 \"restaurant_id\": target_restaurant_id,\n                 \"timeframe\": timeframe,\n-                \"mobile_optimized\": True\n-            }\n-        )\n-        \n+                \"mobile_optimized\": True,\n+            },\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to get inventory analytics: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n @router.get(\"/real-time\")\n async def get_real_time_metrics(\n-    restaurant_id: Optional[str] = Query(None, description=\"Specific restaurant ID (platform owners)\"),\n+    restaurant_id: Optional[str] = Query(\n+        None, description=\"Specific restaurant ID (platform owners)\"\n+    ),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"\n     Get real-time metrics for live dashboard updates\n     Optimized for mobile consumption with current operational data\n     \"\"\"\n@@ -797,49 +911,54 @@\n         # Determine restaurant scope\n         if current_user.role == \"platform_owner\":\n             target_restaurant_id = restaurant_id or str(current_user.restaurant_id)\n         else:\n             target_restaurant_id = str(current_user.restaurant_id)\n-        \n+\n         if not target_restaurant_id:\n             raise FynloException(\n                 message=\"Restaurant context required\",\n                 error_code=ErrorCodes.VALIDATION_ERROR,\n-                status_code=400\n-            )\n-        \n+                status_code=400,\n+            )\n+\n         # Get analytics engine and generate real-time metrics\n         analytics_engine = get_analytics_engine(db)\n         real_time_data = analytics_engine.get_real_time_metrics(\n             restaurant_id=target_restaurant_id\n         )\n-        \n+\n         return APIResponseHelper.success(\n             data=real_time_data,\n             message=\"Real-time metrics retrieved successfully\",\n             meta={\n                 \"restaurant_id\": target_restaurant_id,\n                 \"mobile_optimized\": True,\n-                \"refresh_interval\": 30  # Seconds\n-            }\n-        )\n-        \n+                \"refresh_interval\": 30,  # Seconds\n+            },\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to get real-time metrics: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n @router.get(\"/financial\")\n async def get_financial_analytics(\n-    period: str = Query(\"today\", description=\"Period: today, week, month, quarter, year\"),\n-    restaurant_id: Optional[str] = Query(None, description=\"Specific restaurant ID (platform owners)\"),\n+    period: str = Query(\n+        \"today\", description=\"Period: today, week, month, quarter, year\"\n+    ),\n+    restaurant_id: Optional[str] = Query(\n+        None, description=\"Specific restaurant ID (platform owners)\"\n+    ),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"\n     Get comprehensive financial analytics including P&L, revenue breakdowns, and cost analysis\n     Optimized for mobile financial reporting and decision making\n     \"\"\"\n@@ -850,76 +969,78 @@\n         else:\n             target_restaurant_id = str(current_user.restaurant_id)\n \n         # Get analytics engine\n         analytics_engine = get_analytics_engine()\n-        \n+\n         # Map period to timeframe\n         timeframe_map = {\n             \"today\": AnalyticsTimeframe.TODAY,\n             \"week\": AnalyticsTimeframe.WEEK,\n             \"month\": AnalyticsTimeframe.MONTH,\n             \"quarter\": AnalyticsTimeframe.QUARTER,\n-            \"year\": AnalyticsTimeframe.YEAR\n+            \"year\": AnalyticsTimeframe.YEAR,\n         }\n-        \n+\n         timeframe = timeframe_map.get(period, AnalyticsTimeframe.TODAY)\n-        \n+\n         # Get financial analytics from the engine\n         financial_data = analytics_engine.get_financial_analytics(\n-            restaurant_id=target_restaurant_id,\n-            timeframe=timeframe,\n-            db=db\n-        )\n-        \n+            restaurant_id=target_restaurant_id, timeframe=timeframe, db=db\n+        )\n+\n         # Structure response for mobile consumption\n         response_data = {\n             \"period\": period,\n             \"restaurant_id\": target_restaurant_id,\n             \"summary\": {\n                 \"total_revenue\": float(financial_data.get(\"total_revenue\", 0)),\n                 \"total_costs\": float(financial_data.get(\"total_costs\", 0)),\n                 \"gross_profit\": float(financial_data.get(\"gross_profit\", 0)),\n                 \"net_profit\": float(financial_data.get(\"net_profit\", 0)),\n-                \"profit_margin\": float(financial_data.get(\"profit_margin\", 0))\n+                \"profit_margin\": float(financial_data.get(\"profit_margin\", 0)),\n             },\n             \"revenue\": {\n                 \"food_sales\": float(financial_data.get(\"food_sales\", 0)),\n                 \"beverage_sales\": float(financial_data.get(\"beverage_sales\", 0)),\n                 \"service_fees\": float(financial_data.get(\"service_fees\", 0)),\n-                \"total_revenue\": float(financial_data.get(\"total_revenue\", 0))\n+                \"total_revenue\": float(financial_data.get(\"total_revenue\", 0)),\n             },\n             \"costs\": {\n                 \"cost_of_goods_sold\": float(financial_data.get(\"cogs\", 0)),\n                 \"labor_costs\": float(financial_data.get(\"labor_costs\", 0)),\n-                \"operating_expenses\": float(financial_data.get(\"operating_expenses\", 0)),\n-                \"total_costs\": float(financial_data.get(\"total_costs\", 0))\n+                \"operating_expenses\": float(\n+                    financial_data.get(\"operating_expenses\", 0)\n+                ),\n+                \"total_costs\": float(financial_data.get(\"total_costs\", 0)),\n             },\n             \"payment_breakdown\": {\n                 \"cash_payments\": float(financial_data.get(\"cash_payments\", 0)),\n                 \"card_payments\": float(financial_data.get(\"card_payments\", 0)),\n                 \"qr_payments\": float(financial_data.get(\"qr_payments\", 0)),\n-                \"total_payments\": float(financial_data.get(\"total_payments\", 0))\n+                \"total_payments\": float(financial_data.get(\"total_payments\", 0)),\n             },\n             \"taxes\": {\n                 \"vat_collected\": float(financial_data.get(\"vat_collected\", 0)),\n-                \"service_charge_collected\": float(financial_data.get(\"service_charge_collected\", 0)),\n-                \"total_taxes\": float(financial_data.get(\"total_taxes\", 0))\n+                \"service_charge_collected\": float(\n+                    financial_data.get(\"service_charge_collected\", 0)\n+                ),\n+                \"total_taxes\": float(financial_data.get(\"total_taxes\", 0)),\n             },\n             \"trends\": financial_data.get(\"trends\", []),\n             \"generated_at\": datetime.now().isoformat(),\n-            \"currency\": \"GBP\"\n+            \"currency\": \"GBP\",\n         }\n \n         return APIResponseHelper.success(\n             data=response_data,\n-            message=f\"Financial analytics retrieved successfully for {period}\"\n-        )\n-        \n+            message=f\"Financial analytics retrieved successfully for {period}\",\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to get financial analytics: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n\\ No newline at end of file\n+            status_code=500,\n+        )\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/health.py\t2025-08-02 21:56:58.985372+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/health.py\t2025-08-02 22:36:02.762413+00:00\n@@ -14,14 +14,14 @@\n import logging\n \n from app.core.response_helper import APIResponseHelper\n from app.core.redis_client import get_redis, RedisClient, get_redis_health\n from app.core.security import (\n-    SafeEnvironmentFilter, \n-    SecurityLevel, \n+    SafeEnvironmentFilter,\n+    SecurityLevel,\n     InputValidator,\n-    HealthDetailedQueryParams\n+    HealthDetailedQueryParams,\n )\n from app.core.database import get_db\n from app.middleware.rate_limit_middleware import limiter, DEFAULT_RATE\n from app.core.auth import get_current_user\n from app.core.database import User\n@@ -42,29 +42,33 @@\n     hostname = socket.gethostname()\n     # In container environments, hostname might be the container ID\n     # Also check for DigitalOcean specific environment variables\n     pod_name = os.environ.get(\"POD_NAME\", \"\")\n     do_app_id = os.environ.get(\"DO_APP_ID\", \"\")\n-    \n+\n     # Generate 8-character random suffix for security\n     random_suffix = secrets.token_hex(4)\n-    \n+\n     if pod_name:\n         # Validate pod name with random suffix\n         instance_id = f\"{pod_name}-{random_suffix}\"\n         try:\n             return InputValidator.validate_instance_id(instance_id)\n         except ValueError:\n-            logger.warning(f\"Invalid pod name format: {pod_name}, falling back to hostname\")\n-    \n+            logger.warning(\n+                f\"Invalid pod name format: {pod_name}, falling back to hostname\"\n+            )\n+\n     if do_app_id and hostname:\n         instance_id = f\"{do_app_id}-{hostname}-{random_suffix}\"\n         try:\n             return InputValidator.validate_instance_id(instance_id)\n         except ValueError:\n-            logger.warning(f\"Invalid instance ID format: {instance_id}, using hostname only\")\n-    \n+            logger.warning(\n+                f\"Invalid instance ID format: {instance_id}, using hostname only\"\n+            )\n+\n     # Validate hostname with random suffix\n     instance_id = f\"{hostname}-{random_suffix}\"\n     try:\n         return InputValidator.validate_instance_id(instance_id)\n     except ValueError:\n@@ -76,57 +80,57 @@\n @limiter.limit(\"1000/minute\")  # Very high limit for load balancer health checks\n async def health_basic(request: Request):\n     \"\"\"\n     Basic health check endpoint - no authentication required.\n     Returns minimal information for load balancer health checks.\n-    \n+\n     This endpoint is designed to be extremely fast and lightweight.\n     \"\"\"\n     return APIResponseHelper.success(\n         data={\n             \"status\": \"healthy\",\n             \"timestamp\": datetime.now(timezone.utc).isoformat(),\n-            \"service\": \"fynlo-backend\"\n-        },\n-        message=\"Service is healthy\"\n+            \"service\": \"fynlo-backend\",\n+        },\n+        message=\"Service is healthy\",\n     )\n \n \n @router.get(\"/detailed\")\n @limiter.limit(DEFAULT_RATE)\n async def health_detailed(\n     request: Request,\n     query_params: HealthDetailedQueryParams = Depends(),\n     db: Session = Depends(get_db),\n     redis: RedisClient = Depends(get_redis),\n-    current_user: User = Depends(get_current_user)  # Now requires authentication\n+    current_user: User = Depends(get_current_user),  # Now requires authentication\n ) -> Dict[str, Any]:\n     \"\"\"\n     Detailed health check with comprehensive instance and system information.\n-    \n+\n     Requires authentication to prevent information disclosure.\n-    \n+\n     Returns:\n         - Instance identification details\n         - Filtered environment configuration\n         - System resource usage (if requested)\n         - Connection statistics\n         - Service health status\n     \"\"\"\n     current_time = datetime.now(timezone.utc)\n     uptime_seconds = (current_time - INSTANCE_START_TIME).total_seconds()\n-    \n+\n     # Determine security level based on user role\n     security_level = SecurityLevel.AUTHENTICATED\n     if current_user.role == \"platform_owner\":\n         security_level = SecurityLevel.PLATFORM_OWNER\n     elif current_user.role in [\"admin\", \"manager\"]:\n         security_level = SecurityLevel.ADMIN\n-    \n+\n     # Get filtered environment variables based on security level\n     safe_environment = SafeEnvironmentFilter.get_safe_environment(security_level)\n-    \n+\n     # Check database health\n     db_healthy = False\n     db_latency_ms = None\n     db_error = None\n     try:\n@@ -139,33 +143,33 @@\n         logger.error(f\"Database health check failed: {type(e).__name__}\")\n         db_error = type(e).__name__  # Don't expose full error details\n     except Exception as e:\n         logger.error(f\"Unexpected database error: {type(e).__name__}\")\n         db_error = \"UnexpectedError\"\n-    \n+\n     # Check Redis health with enhanced monitoring\n     redis_healthy = False\n     redis_latency_ms = None\n     redis_error = None\n     redis_health_details = await get_redis_health()\n-    \n+\n     try:\n         start = datetime.now()\n         test_key = f\"health_check_{get_instance_id()}\"\n         await redis.set(test_key, \"healthy\", expire=10)\n         value = await redis.get(test_key)\n         redis_healthy = value == \"healthy\"\n         redis_latency_ms = (datetime.now() - start).total_seconds() * 1000\n     except Exception as e:\n         logger.error(f\"Redis health check failed: {type(e).__name__}\")\n         redis_error = type(e).__name__\n-    \n+\n     # Get active connections count (if available from app state)\n     active_connections = 0\n-    if hasattr(request.app.state, 'connections'):\n+    if hasattr(request.app.state, \"connections\"):\n         active_connections = len(request.app.state.connections)\n-    \n+\n     # Build health response\n     health_data = {\n         \"status\": \"healthy\" if db_healthy and redis_healthy else \"degraded\",\n         \"timestamp\": current_time.isoformat(),\n         \"instance\": {\n@@ -178,284 +182,296 @@\n         \"connections\": {\n             \"active_websocket_connections\": active_connections,\n             \"database\": {\n                 \"healthy\": db_healthy,\n                 \"latency_ms\": db_latency_ms,\n-                \"error\": db_error\n+                \"error\": db_error,\n             },\n             \"redis\": {\n                 \"healthy\": redis_healthy,\n                 \"latency_ms\": redis_latency_ms,\n                 \"error\": redis_error,\n                 \"circuit_state\": redis_health_details.get(\"circuit_state\"),\n                 \"failure_count\": redis_health_details.get(\"failure_count\"),\n-                \"is_mock\": redis_health_details.get(\"is_mock\", False)\n-            }\n+                \"is_mock\": redis_health_details.get(\"is_mock\", False),\n+            },\n         },\n         \"services\": {\n             \"database\": \"healthy\" if db_healthy else \"unhealthy\",\n             \"redis\": redis_health_details.get(\"status\", \"unknown\"),\n-            \"storage\": await _check_storage_health()\n-        }\n+            \"storage\": await _check_storage_health(),\n+        },\n     }\n-    \n+\n     # Only include system metrics if requested and user has sufficient privileges\n     if query_params.include_system and current_user.role in [\"platform_owner\", \"admin\"]:\n         try:\n             memory = psutil.virtual_memory()\n-            disk = psutil.disk_usage('/')\n-            \n+            disk = psutil.disk_usage(\"/\")\n+\n             health_data[\"system\"] = {\n                 \"platform\": platform.platform(),\n                 \"python_version\": platform.python_version(),\n                 \"cpu_count\": psutil.cpu_count(),\n                 \"cpu_percent\": psutil.cpu_percent(interval=0.1),\n                 \"memory\": {\n                     \"total_mb\": memory.total // (1024 * 1024),\n                     \"available_mb\": memory.available // (1024 * 1024),\n                     \"used_mb\": memory.used // (1024 * 1024),\n-                    \"percent\": memory.percent\n+                    \"percent\": memory.percent,\n                 },\n                 \"disk\": {\n                     \"total_gb\": disk.total // (1024 * 1024 * 1024),\n                     \"used_gb\": disk.used // (1024 * 1024 * 1024),\n                     \"free_gb\": disk.free // (1024 * 1024 * 1024),\n-                    \"percent\": disk.percent\n-                }\n+                    \"percent\": disk.percent,\n+                },\n             }\n         except Exception as e:\n             logger.error(f\"Failed to collect system metrics: {type(e).__name__}\")\n             health_data[\"system\"] = {\"error\": \"Failed to collect metrics\"}\n-    \n+\n     return APIResponseHelper.success(\n-        data=health_data,\n-        message=\"Detailed health information retrieved\"\n+        data=health_data, message=\"Detailed health information retrieved\"\n     )\n \n \n @router.get(\"/instances\")\n @limiter.limit(DEFAULT_RATE)\n async def health_instances(\n     request: Request,\n     redis: RedisClient = Depends(get_redis),\n-    current_user: User = Depends(get_current_user)  # Now requires authentication\n+    current_user: User = Depends(get_current_user),  # Now requires authentication\n ) -> Dict[str, Any]:\n     \"\"\"\n     List all active instances registered in the system.\n-    \n+\n     This endpoint shows:\n     - Desired replica count (from environment)\n     - Currently registered instances\n     - Instance details and last heartbeat\n-    \n+\n     Note: Sensitive instance details are filtered for non-authenticated users.\n     \"\"\"\n     desired_replicas = int(os.environ.get(\"DESIRED_REPLICAS\", \"2\"))\n-    \n+\n     # Get all registered instances from Redis\n     registered_instances = []\n     instance_pattern = \"fynlo:instances:*\"\n-    \n+\n     # Validate Redis pattern\n     try:\n         instance_pattern = InputValidator.validate_redis_pattern(instance_pattern)\n     except ValueError as e:\n         logger.error(f\"Invalid Redis pattern: {e}\")\n         return APIResponseHelper.error(\n-            message=\"Invalid instance pattern\",\n-            errors={\"pattern\": str(e)}\n+            message=\"Invalid instance pattern\", errors={\"pattern\": str(e)}\n         )\n-    \n+\n     try:\n         # Scan for all instance keys with pagination\n         if redis.redis:  # Real Redis\n             cursor = 0\n             while True:\n                 cursor, keys = await redis.redis.scan(\n                     cursor=cursor,\n                     match=instance_pattern,\n-                    count=100  # Process in batches\n+                    count=100,  # Process in batches\n                 )\n-                \n+\n                 for key in keys:\n                     instance_data = await redis.redis.hgetall(key)\n                     if instance_data:\n                         # Convert bytes to strings if needed\n                         instance_info = {\n-                            k.decode() if isinstance(k, bytes) else k: \n-                            v.decode() if isinstance(v, bytes) else v \n+                            k.decode() if isinstance(k, bytes) else k: (\n+                                v.decode() if isinstance(v, bytes) else v\n+                            )\n                             for k, v in instance_data.items()\n                         }\n-                        \n+\n                         # Calculate time since last heartbeat\n-                        if 'last_heartbeat' in instance_info:\n+                        if \"last_heartbeat\" in instance_info:\n                             try:\n-                                last_heartbeat = datetime.fromisoformat(instance_info['last_heartbeat'])\n-                                time_since_heartbeat = (datetime.now(timezone.utc) - last_heartbeat).total_seconds()\n-                                instance_info['seconds_since_heartbeat'] = int(time_since_heartbeat)\n-                                instance_info['is_stale'] = time_since_heartbeat > 60  # Consider stale after 60s\n+                                last_heartbeat = datetime.fromisoformat(\n+                                    instance_info[\"last_heartbeat\"]\n+                                )\n+                                time_since_heartbeat = (\n+                                    datetime.now(timezone.utc) - last_heartbeat\n+                                ).total_seconds()\n+                                instance_info[\"seconds_since_heartbeat\"] = int(\n+                                    time_since_heartbeat\n+                                )\n+                                instance_info[\"is_stale\"] = (\n+                                    time_since_heartbeat > 60\n+                                )  # Consider stale after 60s\n                             except (ValueError, TypeError):\n-                                instance_info['is_stale'] = True\n-                        \n+                                instance_info[\"is_stale\"] = True\n+\n                         registered_instances.append(instance_info)\n-                \n+\n                 if cursor == 0:\n                     break\n         else:\n             # Mock Redis fallback\n             logger.warning(\"Using mock Redis, instance tracking not available\")\n     except Exception as e:\n         logger.error(f\"Error fetching instances: {type(e).__name__}: {e}\")\n         return APIResponseHelper.error(\n-            message=\"Failed to fetch instance data\",\n-            errors={\"error\": type(e).__name__}\n+            message=\"Failed to fetch instance data\", errors={\"error\": type(e).__name__}\n         )\n-    \n+\n     # Sort instances by last heartbeat (most recent first)\n-    registered_instances.sort(\n-        key=lambda x: x.get('last_heartbeat', ''), \n-        reverse=True\n-    )\n-    \n+    registered_instances.sort(key=lambda x: x.get(\"last_heartbeat\", \"\"), reverse=True)\n+\n     # Since authentication is now required, we can show full instance details\n     # No need to filter sensitive data anymore\n-    \n+\n     # Analyze discrepancies\n-    active_count = len([i for i in registered_instances if not i.get('is_stale', False)])\n+    active_count = len(\n+        [i for i in registered_instances if not i.get(\"is_stale\", False)]\n+    )\n     discrepancy = active_count != desired_replicas\n-    \n+\n     instance_data = {\n         \"desired_replicas\": desired_replicas,\n         \"registered_instances\": registered_instances,\n         \"active_instances\": active_count,\n         \"total_registered\": len(registered_instances),\n         \"discrepancy\": discrepancy,\n         \"last_check\": datetime.now(timezone.utc).isoformat(),\n         \"current_instance\": {\n             \"id\": get_instance_id(),\n             \"is_registered\": any(\n-                i.get('instance_id') == get_instance_id() \n-                for i in registered_instances\n-            )\n-        }\n+                i.get(\"instance_id\") == get_instance_id() for i in registered_instances\n+            ),\n+        },\n     }\n-    \n+\n     # Add warnings if there are issues\n     warnings = []\n     if discrepancy:\n         if active_count > desired_replicas:\n-            warnings.append(f\"WARNING: {active_count - desired_replicas} extra instances detected\")\n+            warnings.append(\n+                f\"WARNING: {active_count - desired_replicas} extra instances detected\"\n+            )\n         elif active_count < desired_replicas:\n-            warnings.append(f\"WARNING: {desired_replicas - active_count} instances missing\")\n-    \n-    stale_count = len([i for i in registered_instances if i.get('is_stale', False)])\n+            warnings.append(\n+                f\"WARNING: {desired_replicas - active_count} instances missing\"\n+            )\n+\n+    stale_count = len([i for i in registered_instances if i.get(\"is_stale\", False)])\n     if stale_count > 0:\n-        warnings.append(f\"WARNING: {stale_count} stale instances detected (no heartbeat in 60s)\")\n-    \n+        warnings.append(\n+            f\"WARNING: {stale_count} stale instances detected (no heartbeat in 60s)\"\n+        )\n+\n     if warnings:\n-        instance_data['warnings'] = warnings\n-    \n+        instance_data[\"warnings\"] = warnings\n+\n     return APIResponseHelper.success(\n-        data=instance_data,\n-        message=\"Instance information retrieved\"\n+        data=instance_data, message=\"Instance information retrieved\"\n     )\n \n \n @router.get(\"/ready\")\n @limiter.limit(\"1000/minute\")  # High limit for k8s readiness probes\n async def health_ready(\n     request: Request,\n     db: Session = Depends(get_db),\n-    redis: RedisClient = Depends(get_redis)\n+    redis: RedisClient = Depends(get_redis),\n ) -> Dict[str, Any]:\n     \"\"\"\n     Kubernetes/container readiness probe endpoint.\n-    \n+\n     Returns 200 if the instance is ready to serve traffic.\n     Returns 503 if any critical service is unavailable.\n-    \n+\n     No authentication required for container orchestration compatibility.\n     \"\"\"\n     # Check database\n     db_ready = False\n     try:\n         result = db.execute(text(\"SELECT 1\"))\n         db.commit()\n         db_ready = result.scalar() == 1\n     except Exception as e:\n         logger.error(f\"Database readiness check failed: {type(e).__name__}\")\n-    \n+\n     # Check Redis\n     redis_ready = False\n     try:\n         await redis.set(\"readiness_check\", \"1\", expire=5)\n         redis_ready = await redis.get(\"readiness_check\") == \"1\"\n     except Exception as e:\n         logger.error(f\"Redis readiness check failed: {type(e).__name__}\")\n-    \n+\n     if db_ready and redis_ready:\n         return APIResponseHelper.success(\n             data={\"ready\": True, \"services\": {\"database\": \"ready\", \"redis\": \"ready\"}},\n-            message=\"Instance is ready\"\n+            message=\"Instance is ready\",\n         )\n     else:\n         return APIResponseHelper.error(\n             message=\"Instance not ready\",\n             status_code=503,\n             errors={\n                 \"database\": \"ready\" if db_ready else \"not ready\",\n-                \"redis\": \"ready\" if redis_ready else \"not ready\"\n-            }\n+                \"redis\": \"ready\" if redis_ready else \"not ready\",\n+            },\n         )\n \n \n @router.get(\"/live\")\n @limiter.limit(\"1000/minute\")  # High limit for k8s liveness probes\n async def health_live(request: Request) -> Dict[str, Any]:\n     \"\"\"\n     Kubernetes/container liveness probe endpoint.\n-    \n+\n     Simple check that the application is running.\n     Returns 200 if the application is alive.\n-    \n+\n     No authentication required for container orchestration compatibility.\n     \"\"\"\n     return APIResponseHelper.success(\n         data={\n             \"alive\": True,\n             \"instance_id\": get_instance_id(),\n-            \"timestamp\": datetime.now(timezone.utc).isoformat()\n-        },\n-        message=\"Instance is alive\"\n+            \"timestamp\": datetime.now(timezone.utc).isoformat(),\n+        },\n+        message=\"Instance is alive\",\n     )\n \n \n # Helper functions\n+\n \n def _format_uptime(seconds: int) -> str:\n     \"\"\"Format uptime seconds into human-readable string.\"\"\"\n     days = seconds // 86400\n     hours = (seconds % 86400) // 3600\n     minutes = (seconds % 3600) // 60\n     seconds = seconds % 60\n-    \n+\n     parts = []\n     if days > 0:\n         parts.append(f\"{days}d\")\n     if hours > 0:\n         parts.append(f\"{hours}h\")\n     if minutes > 0:\n         parts.append(f\"{minutes}m\")\n     if seconds > 0 or not parts:\n         parts.append(f\"{seconds}s\")\n-    \n+\n     return \" \".join(parts)\n \n \n async def _check_storage_health() -> str:\n     \"\"\"Check if storage service (DigitalOcean Spaces) is healthy.\"\"\"\n     # This is a placeholder - implement actual storage health check if needed\n     # For now, we'll assume it's healthy if the environment variables are set\n     # Don't expose the actual values\n-    if os.environ.get(\"SPACES_ACCESS_KEY_ID\") and os.environ.get(\"SPACES_SECRET_ACCESS_KEY\"):\n+    if os.environ.get(\"SPACES_ACCESS_KEY_ID\") and os.environ.get(\n+        \"SPACES_SECRET_ACCESS_KEY\"\n+    ):\n         return \"healthy\"\n-    return \"not_configured\"\n\\ No newline at end of file\n+    return \"not_configured\"\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/platform_admin.py\t2025-08-02 21:56:58.987618+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/platform_admin.py\t2025-08-02 22:36:02.771451+00:00\n@@ -10,11 +10,15 @@\n import logging\n import hmac\n import hashlib\n \n from app.core.database import get_db, User\n-from app.core.exceptions import AuthorizationException, ResourceNotFoundException, ValidationException\n+from app.core.exceptions import (\n+    AuthorizationException,\n+    ResourceNotFoundException,\n+    ValidationException,\n+)\n from app.core.auth import get_current_user\n from app.core.config import settings\n from app.core.responses import APIResponseHelper\n from pydantic import BaseModel, EmailStr\n \n@@ -22,149 +26,171 @@\n router = APIRouter()\n \n \n class GrantPlatformOwnerRequest(BaseModel):\n     \"\"\"Request to grant platform owner role\"\"\"\n+\n     user_email: EmailStr\n     verification_code: str  # Secret code sent out-of-band to admin\n \n \n class RevokePlatformOwnerRequest(BaseModel):\n     \"\"\"Request to revoke platform owner role\"\"\"\n+\n     user_email: EmailStr\n     reason: str\n \n \n-def verify_platform_owner_access(current_user: User, verification_token: Optional[str] = Header(None)):\n+def verify_platform_owner_access(\n+    current_user: User, verification_token: Optional[str] = Header(None)\n+):\n     \"\"\"\n     Verify that the current user is a platform owner with proper authentication\n     \"\"\"\n-    if current_user.role != 'platform_owner':\n-        raise AuthorizationException(message=\"Access denied: Platform owner role required\")\n-    \n+    if current_user.role != \"platform_owner\":\n+        raise AuthorizationException(\n+            message=\"Access denied: Platform owner role required\"\n+        )\n+\n     # Additional verification for sensitive operations\n     if settings.PLATFORM_OWNER_SECRET_KEY and verification_token:\n         # Verify the token matches expected format\n         expected_token = hmac.new(\n             settings.PLATFORM_OWNER_SECRET_KEY.encode(),\n             f\"{current_user.id}:{datetime.utcnow().strftime('%Y-%m-%d')}\".encode(),\n-            hashlib.sha256\n+            hashlib.sha256,\n         ).hexdigest()\n-        \n+\n         if not hmac.compare_digest(verification_token, expected_token):\n-            logger.warning(f\"Invalid platform owner verification token for user {current_user.id}\")\n-            raise ValidationException(message=\"Invalid verification token\", field=\"verification\")\n+            logger.warning(\n+                f\"Invalid platform owner verification token for user {current_user.id}\"\n+            )\n+            raise ValidationException(\n+                message=\"Invalid verification token\", field=\"verification\"\n+            )\n \n \n @router.post(\"/grant-platform-owner\")\n async def grant_platform_owner_role(\n     request: GrantPlatformOwnerRequest,\n     db: Session = Depends(get_db),\n     current_user: User = Depends(get_current_user),\n-    verification_token: Optional[str] = Header(None)\n+    verification_token: Optional[str] = Header(None),\n ):\n     \"\"\"\n     Grant platform owner role to a user\n     Requires: Current user must be platform owner with verification\n     \"\"\"\n     verify_platform_owner_access(current_user, verification_token)\n-    \n+\n     # Verify the verification code (this should be sent via secure channel)\n     # In production, this would check against a time-limited code sent via SMS/email\n     if not request.verification_code or len(request.verification_code) < 6:\n-        raise ValidationException(message=\"Invalid verification code\", field=\"verification\")\n-    \n+        raise ValidationException(\n+            message=\"Invalid verification code\", field=\"verification\"\n+        )\n+\n     # Find the target user\n     target_user = db.query(User).filter(User.email == request.user_email).first()\n     if not target_user:\n         raise ResourceNotFoundException(resource=\"User\")\n-    \n-    if target_user.role == 'platform_owner':\n-        return APIResponseHelper.success(\n-            message=\"User already has platform owner role\"\n-        )\n-    \n+\n+    if target_user.role == \"platform_owner\":\n+        return APIResponseHelper.success(message=\"User already has platform owner role\")\n+\n     # Update user role\n-    target_user.role = 'platform_owner'\n+    target_user.role = \"platform_owner\"\n     target_user.updated_at = datetime.utcnow()\n-    \n+\n     # Log this sensitive operation\n-    logger.info(f\"Platform owner role granted to {target_user.email} by {current_user.email}\")\n-    \n+    logger.info(\n+        f\"Platform owner role granted to {target_user.email} by {current_user.email}\"\n+    )\n+\n     db.commit()\n-    \n+\n     return APIResponseHelper.success(\n         data={\"user_id\": str(target_user.id), \"email\": target_user.email},\n-        message=\"Platform owner role granted successfully\"\n+        message=\"Platform owner role granted successfully\",\n     )\n \n \n @router.post(\"/revoke-platform-owner\")\n async def revoke_platform_owner_role(\n     request: RevokePlatformOwnerRequest,\n     db: Session = Depends(get_db),\n     current_user: User = Depends(get_current_user),\n-    verification_token: Optional[str] = Header(None)\n+    verification_token: Optional[str] = Header(None),\n ):\n     \"\"\"\n     Revoke platform owner role from a user\n     Requires: Current user must be platform owner with verification\n     \"\"\"\n     verify_platform_owner_access(current_user, verification_token)\n-    \n+\n     # Prevent self-revocation\n     if request.user_email == current_user.email:\n         raise ValidationException(message=\"Cannot revoke your own platform owner role\")\n-    \n+\n     # Find the target user\n     target_user = db.query(User).filter(User.email == request.user_email).first()\n     if not target_user:\n         raise ResourceNotFoundException(resource=\"User\")\n-    \n-    if target_user.role != 'platform_owner':\n+\n+    if target_user.role != \"platform_owner\":\n         return APIResponseHelper.success(\n             message=\"User does not have platform owner role\"\n         )\n-    \n+\n     # Check if this would leave no platform owners\n-    platform_owner_count = db.query(User).filter(User.role == 'platform_owner').count()\n+    platform_owner_count = db.query(User).filter(User.role == \"platform_owner\").count()\n     if platform_owner_count <= 1:\n-        raise ValidationException(message=\"Cannot revoke: This would leave no platform owners in the system\")\n-    \n+        raise ValidationException(\n+            message=\"Cannot revoke: This would leave no platform owners in the system\"\n+        )\n+\n     # Update user role to restaurant_owner\n-    target_user.role = 'restaurant_owner'\n+    target_user.role = \"restaurant_owner\"\n     target_user.updated_at = datetime.utcnow()\n-    \n+\n     # Log this sensitive operation\n-    logger.info(f\"Platform owner role revoked from {target_user.email} by {current_user.email}. Reason: {request.reason}\")\n-    \n+    logger.info(\n+        f\"Platform owner role revoked from {target_user.email} by {current_user.email}. Reason: {request.reason}\"\n+    )\n+\n     db.commit()\n-    \n+\n     return APIResponseHelper.success(\n         data={\"user_id\": str(target_user.id), \"email\": target_user.email},\n-        message=\"Platform owner role revoked successfully\"\n+        message=\"Platform owner role revoked successfully\",\n     )\n \n \n @router.get(\"/platform-owners\")\n async def list_platform_owners(\n-    db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    db: Session = Depends(get_db), current_user: User = Depends(get_current_user)\n ):\n     \"\"\"\n     List all platform owners\n     Requires: Current user must be platform owner\n     \"\"\"\n-    if current_user.role != 'platform_owner':\n-        raise AuthorizationException(message=\"Access denied: Platform owner role required\")\n-    \n-    platform_owners = db.query(User).filter(User.role == 'platform_owner').all()\n-    \n+    if current_user.role != \"platform_owner\":\n+        raise AuthorizationException(\n+            message=\"Access denied: Platform owner role required\"\n+        )\n+\n+    platform_owners = db.query(User).filter(User.role == \"platform_owner\").all()\n+\n     return APIResponseHelper.success(\n-        data=[{\n-            \"id\": str(owner.id),\n-            \"email\": owner.email,\n-            \"name\": f\"{owner.first_name} {owner.last_name}\".strip() or owner.email,\n-            \"created_at\": owner.created_at.isoformat() if owner.created_at else None\n-        } for owner in platform_owners],\n-        message=f\"Found {len(platform_owners)} platform owners\"\n-    )\n\\ No newline at end of file\n+        data=[\n+            {\n+                \"id\": str(owner.id),\n+                \"email\": owner.email,\n+                \"name\": f\"{owner.first_name} {owner.last_name}\".strip() or owner.email,\n+                \"created_at\": (\n+                    owner.created_at.isoformat() if owner.created_at else None\n+                ),\n+            }\n+            for owner in platform_owners\n+        ],\n+        message=f\"Found {len(platform_owners)} platform owners\",\n+    )\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/payment_configurations.py\t2025-08-02 22:07:19.187986+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/payment_configurations.py\t2025-08-02 22:36:02.776241+00:00\n@@ -7,78 +7,101 @@\n from app.core.exceptions import (\n     AuthorizationException,\n     ConflictException,\n     FynloException,\n     ResourceNotFoundException,\n-    ValidationException\n+    ValidationException,\n )\n from app.core.auth import get_current_user\n from app.schemas.fee_schemas import PaymentMethodEnum, PaymentMethodFeeSettingSchema\n from app.services.payment_config_service import PaymentConfigService\n-from app.models.payment_config import PaymentMethodSetting # For ORM response\n+from app.models.payment_config import PaymentMethodSetting  # For ORM response\n from app.core.tenant_security import TenantSecurity\n \n router = APIRouter()\n \n+\n # --- Dependency for Service ---\n-def get_payment_config_service_dep(db: Session = Depends(get_db)) -> PaymentConfigService:\n+def get_payment_config_service_dep(\n+    db: Session = Depends(get_db),\n+) -> PaymentConfigService:\n     \"\"\"Execute get_payment_config_service_dep operation.\"\"\"\n     return PaymentConfigService(db=db)\n+\n \n # --- Pydantic Models for Input/Output ---\n # Using PaymentMethodFeeSettingSchema from fee_schemas.py for both input and output.\n # For input, we might want a slightly different model if `id` is not allowed.\n class PaymentMethodSettingCreateInput(BaseModel):\n     payment_method: PaymentMethodEnum\n     customer_pays_default: bool = True\n     allow_toggle_by_merchant: bool = True\n     include_processor_fee_in_service_charge: bool = True\n-    restaurant_id: Optional[str] = None # Null for platform default\n+    restaurant_id: Optional[str] = None  # Null for platform default\n+\n \n class PaymentMethodSettingUpdateInput(BaseModel):\n     customer_pays_default: Optional[bool] = None\n     allow_toggle_by_merchant: Optional[bool] = None\n     include_processor_fee_in_service_charge: Optional[bool] = None\n \n+\n # Helper to convert SQLAlchemy model to Pydantic schema for response\n-def convert_db_model_to_schema(db_setting: PaymentMethodSetting) -> PaymentMethodFeeSettingSchema:\n+def convert_db_model_to_schema(\n+    db_setting: PaymentMethodSetting,\n+) -> PaymentMethodFeeSettingSchema:\n     \"\"\"Execute convert_db_model_to_schema operation.\"\"\"\n     return PaymentMethodFeeSettingSchema(\n         id=db_setting.id,\n         restaurant_id=db_setting.restaurant_id,\n-        payment_method=PaymentMethodEnum(db_setting.payment_method), # Ensure enum conversion\n+        payment_method=PaymentMethodEnum(\n+            db_setting.payment_method\n+        ),  # Ensure enum conversion\n         customer_pays_default=db_setting.customer_pays_default,\n         allow_toggle_by_merchant=db_setting.allow_toggle_by_merchant,\n-        include_processor_fee_in_service_charge=db_setting.include_processor_fee_in_service_charge\n-    )\n+        include_processor_fee_in_service_charge=db_setting.include_processor_fee_in_service_charge,\n+    )\n+\n \n # --- API Endpoints ---\n \n-@router.get(\"/settings/platform-defaults\", response_model=List[PaymentMethodFeeSettingSchema])\n+\n+@router.get(\n+    \"/settings/platform-defaults\", response_model=List[PaymentMethodFeeSettingSchema]\n+)\n def list_platform_default_settings(\n     service: PaymentConfigService = Depends(get_payment_config_service_dep),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Execute list_platform_default_settings operation.\"\"\"\n     \"\"\"Lists all platform default payment method settings.\"\"\"\n     db_settings = service.get_all_platform_default_settings()\n     return [convert_db_model_to_schema(s) for s in db_settings]\n \n-@router.post(\"/settings/platform-defaults\", response_model=PaymentMethodFeeSettingSchema, status_code=201)\n+\n+@router.post(\n+    \"/settings/platform-defaults\",\n+    response_model=PaymentMethodFeeSettingSchema,\n+    status_code=201,\n+)\n def create_platform_default_setting(\n     setting_data: PaymentMethodSettingCreateInput,\n     service: PaymentConfigService = Depends(get_payment_config_service_dep),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Execute create_platform_default_setting operation.\"\"\"\n     \"\"\"Creates a new platform default payment method setting.\"\"\"\n     # Only platform owners can create platform defaults\n-    if current_user.role != 'platform_owner':\n-        raise AuthorizationException(message=\"Only platform owners can create platform default settings\")\n-    \n+    if current_user.role != \"platform_owner\":\n+        raise AuthorizationException(\n+            message=\"Only platform owners can create platform default settings\"\n+        )\n+\n     if setting_data.restaurant_id is not None:\n-        raise ValidationException(message=\"Platform default settings cannot have a restaurant_id.\")\n+        raise ValidationException(\n+            message=\"Platform default settings cannot have a restaurant_id.\"\n+        )\n \n     # Convert Pydantic input to the TypedDict schema service might expect\n     # (If service directly uses Pydantic, this conversion might be simpler)\n     typed_dict_data = PaymentMethodFeeSettingSchema(\n         payment_method=setting_data.payment_method,\n@@ -87,45 +110,62 @@\n         include_processor_fee_in_service_charge=setting_data.include_processor_fee_in_service_charge,\n         # id and restaurant_id are not part of create for platform default via this input model\n     )\n     try:\n         created_setting = service.create_platform_default_setting(typed_dict_data)\n-        if not created_setting: # Should not happen if service raises error on failure\n-            raise FynloException(message=\"Failed to create platform default setting.\", status_code=500)\n+        if not created_setting:  # Should not happen if service raises error on failure\n+            raise FynloException(\n+                message=\"Failed to create platform default setting.\", status_code=500\n+            )\n         return convert_db_model_to_schema(created_setting)\n     except ValueError as ve:\n         raise ValidationException(message=\"Invalid payment configuration data\")\n-    except Exception as e: # Catches IntegrityError from service if duplicate\n+    except Exception as e:  # Catches IntegrityError from service if duplicate\n         raise ConflictException(message=\"Payment configuration already exists\")\n \n \n-@router.put(\"/settings/platform-defaults/{payment_method}\", response_model=PaymentMethodFeeSettingSchema)\n+@router.put(\n+    \"/settings/platform-defaults/{payment_method}\",\n+    response_model=PaymentMethodFeeSettingSchema,\n+)\n def update_platform_default_setting(\n     payment_method: PaymentMethodEnum = Path(...),\n     updates: PaymentMethodSettingUpdateInput = Body(...),\n     service: PaymentConfigService = Depends(get_payment_config_service_dep),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Execute update_platform_default_setting operation.\"\"\"\n     \"\"\"Updates an existing platform default payment method setting.\"\"\"\n     # Only platform owners can update platform defaults\n-    if current_user.role != 'platform_owner':\n-        raise AuthorizationException(message=\"Only platform owners can update platform default settings\")\n-    \n-    updated_setting = service.update_platform_default_setting(payment_method, updates.dict(exclude_unset=True))\n+    if current_user.role != \"platform_owner\":\n+        raise AuthorizationException(\n+            message=\"Only platform owners can update platform default settings\"\n+        )\n+\n+    updated_setting = service.update_platform_default_setting(\n+        payment_method, updates.dict(exclude_unset=True)\n+    )\n     if not updated_setting:\n-        raise ResourceNotFoundException(resource=\"Resource\", message=f\"Platform default setting for {payment_method.value} not found.\")\n+        raise ResourceNotFoundException(\n+            resource=\"Resource\",\n+            message=f\"Platform default setting for {payment_method.value} not found.\",\n+        )\n     return convert_db_model_to_schema(updated_setting)\n \n \n-@router.get(\"/settings/restaurants/{restaurant_id}\", response_model=List[PaymentMethodFeeSettingSchema])\n+@router.get(\n+    \"/settings/restaurants/{restaurant_id}\",\n+    response_model=List[PaymentMethodFeeSettingSchema],\n+)\n async def list_restaurant_settings(\n     restaurant_id: str = Path(...),\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Restaurant ID for multi-location owners\"),\n-    service: PaymentConfigService = Depends(get_payment_config_service_dep),\n-    current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Restaurant ID for multi-location owners\"\n+    ),\n+    service: PaymentConfigService = Depends(get_payment_config_service_dep),\n+    current_user: User = Depends(get_current_user),\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"\n     Lists all payment method settings for a specific restaurant.\n     This will include specific overrides for the restaurant.\n     To get effective settings (override + fallback to default), client would call this\n@@ -135,90 +175,115 @@\n     \"\"\"\n     # Validate access - if accessing a specific restaurant, validate tenant access\n     if restaurant_id:\n         # If current_restaurant_id is provided, validate it matches\n         if current_restaurant_id and current_restaurant_id != restaurant_id:\n-            raise AuthorizationException(message=\"Cannot access settings for a different restaurant\")\n-        \n+            raise AuthorizationException(\n+                message=\"Cannot access settings for a different restaurant\"\n+            )\n+\n         # Validate the user has access to this restaurant\n         await TenantSecurity.validate_restaurant_access(\n             current_user, restaurant_id, db=db\n         )\n-    \n+\n     db_settings = service.get_all_settings_for_restaurant(restaurant_id)\n     return [convert_db_model_to_schema(s) for s in db_settings]\n \n \n-@router.post(\"/settings/restaurants/{restaurant_id}\", response_model=PaymentMethodFeeSettingSchema, status_code=201)\n+@router.post(\n+    \"/settings/restaurants/{restaurant_id}\",\n+    response_model=PaymentMethodFeeSettingSchema,\n+    status_code=201,\n+)\n async def create_or_update_restaurant_setting(\n     restaurant_id: str = Path(...),\n-    setting_data: PaymentMethodSettingCreateInput = Body(...), # Uses same create input, restaurant_id from path\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Restaurant ID for multi-location owners\"),\n-    service: PaymentConfigService = Depends(get_payment_config_service_dep),\n-    current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    setting_data: PaymentMethodSettingCreateInput = Body(\n+        ...\n+    ),  # Uses same create input, restaurant_id from path\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Restaurant ID for multi-location owners\"\n+    ),\n+    service: PaymentConfigService = Depends(get_payment_config_service_dep),\n+    current_user: User = Depends(get_current_user),\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Creates or updates a restaurant-specific payment method setting (override).\"\"\"\n     # Validate access\n     if current_restaurant_id and current_restaurant_id != restaurant_id:\n-        raise AuthorizationException(message=\"Cannot modify settings for a different restaurant\")\n-    \n+        raise AuthorizationException(\n+            message=\"Cannot modify settings for a different restaurant\"\n+        )\n+\n     # Validate the user has access to this restaurant\n-    await TenantSecurity.validate_restaurant_access(\n-        current_user, restaurant_id, db=db\n-    )\n-    \n+    await TenantSecurity.validate_restaurant_access(current_user, restaurant_id, db=db)\n+\n     # Check permissions - only owners and managers can modify settings\n-    if current_user.role not in ['platform_owner', 'restaurant_owner', 'manager']:\n-        raise AuthorizationException(message=\"Insufficient permissions to modify payment settings\")\n+    if current_user.role not in [\"platform_owner\", \"restaurant_owner\", \"manager\"]:\n+        raise AuthorizationException(\n+            message=\"Insufficient permissions to modify payment settings\"\n+        )\n \n     # Use the restaurant_id from the path\n     typed_dict_data = PaymentMethodFeeSettingSchema(\n-        restaurant_id=restaurant_id, # Set from path\n+        restaurant_id=restaurant_id,  # Set from path\n         payment_method=setting_data.payment_method,\n         customer_pays_default=setting_data.customer_pays_default,\n         allow_toggle_by_merchant=setting_data.allow_toggle_by_merchant,\n-        include_processor_fee_in_service_charge=setting_data.include_processor_fee_in_service_charge\n+        include_processor_fee_in_service_charge=setting_data.include_processor_fee_in_service_charge,\n     )\n     try:\n-        saved_setting = service.create_or_update_restaurant_setting(restaurant_id, typed_dict_data)\n-        if not saved_setting: # Should not happen if service raises specific errors\n-            raise FynloException(message=\"Failed to save restaurant setting.\", status_code=500)\n+        saved_setting = service.create_or_update_restaurant_setting(\n+            restaurant_id, typed_dict_data\n+        )\n+        if not saved_setting:  # Should not happen if service raises specific errors\n+            raise FynloException(\n+                message=\"Failed to save restaurant setting.\", status_code=500\n+            )\n         return convert_db_model_to_schema(saved_setting)\n     except ValueError as ve:\n         raise ValidationException(message=\"Invalid payment provider settings\")\n-    except Exception as e: # Catches IntegrityError from service\n+    except Exception as e:  # Catches IntegrityError from service\n         raise ConflictException(message=\"Payment provider already configured\")\n \n \n-@router.delete(\"/settings/restaurants/{restaurant_id}/{payment_method}\", status_code=204)\n+@router.delete(\n+    \"/settings/restaurants/{restaurant_id}/{payment_method}\", status_code=204\n+)\n async def delete_restaurant_setting(\n     restaurant_id: str = Path(...),\n     payment_method: PaymentMethodEnum = Path(...),\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Restaurant ID for multi-location owners\"),\n-    service: PaymentConfigService = Depends(get_payment_config_service_dep),\n-    current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Restaurant ID for multi-location owners\"\n+    ),\n+    service: PaymentConfigService = Depends(get_payment_config_service_dep),\n+    current_user: User = Depends(get_current_user),\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Deletes a restaurant-specific payment method setting (override).\"\"\"\n     # Validate access\n     if current_restaurant_id and current_restaurant_id != restaurant_id:\n-        raise AuthorizationException(message=\"Cannot delete settings for a different restaurant\")\n-    \n+        raise AuthorizationException(\n+            message=\"Cannot delete settings for a different restaurant\"\n+        )\n+\n     # Validate the user has access to this restaurant\n-    await TenantSecurity.validate_restaurant_access(\n-        current_user, restaurant_id, db=db\n-    )\n-    \n+    await TenantSecurity.validate_restaurant_access(current_user, restaurant_id, db=db)\n+\n     # Check permissions - only owners and managers can delete settings\n-    if current_user.role not in ['platform_owner', 'restaurant_owner', 'manager']:\n-        raise AuthorizationException(message=\"Insufficient permissions to delete payment settings\")\n-    \n+    if current_user.role not in [\"platform_owner\", \"restaurant_owner\", \"manager\"]:\n+        raise AuthorizationException(\n+            message=\"Insufficient permissions to delete payment settings\"\n+        )\n+\n     deleted = service.delete_restaurant_setting(restaurant_id, payment_method)\n     if not deleted:\n-        raise ResourceNotFoundException(resource=\"Resource\", message=f\"Setting for restaurant {restaurant_id}, method {payment_method.value} not found.\")\n-    return None # No content for 204\n+        raise ResourceNotFoundException(\n+            resource=\"Resource\",\n+            message=f\"Setting for restaurant {restaurant_id}, method {payment_method.value} not found.\",\n+        )\n+    return None  # No content for 204\n \n \n # To include this router in the main application:\n # In backend/app/api/v1/api.py (or equivalent):\n # from .endpoints import payment_configurations\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/notifications.py\t2025-08-02 19:23:36.808937+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/notifications.py\t2025-08-02 22:36:02.789897+00:00\n@@ -16,53 +16,78 @@\n from app.core.push_notifications import (\n     get_push_service,\n     NotificationType,\n     NotificationPriority,\n     NotificationPayload,\n-    NotificationPreferences\n+    NotificationPreferences,\n )\n \n router = APIRouter()\n+\n \n # Notification Models\n class DeviceRegistrationRequest(BaseModel):\n     \"\"\"Device registration request\"\"\"\n-    device_token: str = Field(..., description=\"APNs device token (64-character hex string)\")\n+\n+    device_token: str = Field(\n+        ..., description=\"APNs device token (64-character hex string)\"\n+    )\n     device_type: str = Field(default=\"ios\", description=\"Device type\")\n-    device_name: Optional[str] = Field(None, description=\"Device name for identification\")\n+    device_name: Optional[str] = Field(\n+        None, description=\"Device name for identification\"\n+    )\n+\n \n class NotificationSendRequest(BaseModel):\n     \"\"\"Manual notification send request\"\"\"\n+\n     title: str = Field(..., description=\"Notification title\")\n     body: str = Field(..., description=\"Notification body\")\n     notification_type: str = Field(..., description=\"Notification type\")\n     priority: str = Field(default=\"normal\", description=\"Notification priority\")\n     target_users: Optional[List[str]] = Field(None, description=\"Target user IDs\")\n-    target_restaurants: Optional[List[str]] = Field(None, description=\"Target restaurant IDs\")\n+    target_restaurants: Optional[List[str]] = Field(\n+        None, description=\"Target restaurant IDs\"\n+    )\n     sound: str = Field(default=\"default\", description=\"Notification sound\")\n-    custom_data: Optional[Dict[str, Any]] = Field(None, description=\"Custom data payload\")\n+    custom_data: Optional[Dict[str, Any]] = Field(\n+        None, description=\"Custom data payload\"\n+    )\n+\n \n class TemplatedNotificationRequest(BaseModel):\n     \"\"\"Templated notification request\"\"\"\n+\n     notification_type: str = Field(..., description=\"Notification template type\")\n-    template_data: Dict[str, Any] = Field(..., description=\"Data for template formatting\")\n+    template_data: Dict[str, Any] = Field(\n+        ..., description=\"Data for template formatting\"\n+    )\n     target_users: Optional[List[str]] = Field(None, description=\"Target user IDs\")\n-    target_restaurants: Optional[List[str]] = Field(None, description=\"Target restaurant IDs\")\n+    target_restaurants: Optional[List[str]] = Field(\n+        None, description=\"Target restaurant IDs\"\n+    )\n+\n \n class NotificationPreferencesRequest(BaseModel):\n     \"\"\"Notification preferences update request\"\"\"\n+\n     enabled_types: List[str] = Field(..., description=\"Enabled notification types\")\n-    quiet_hours_start: Optional[str] = Field(None, description=\"Quiet hours start time (HH:MM)\")\n-    quiet_hours_end: Optional[str] = Field(None, description=\"Quiet hours end time (HH:MM)\")\n+    quiet_hours_start: Optional[str] = Field(\n+        None, description=\"Quiet hours start time (HH:MM)\"\n+    )\n+    quiet_hours_end: Optional[str] = Field(\n+        None, description=\"Quiet hours end time (HH:MM)\"\n+    )\n     sound_enabled: bool = Field(default=True, description=\"Sound enabled\")\n     badge_enabled: bool = Field(default=True, description=\"Badge enabled\")\n+\n \n @router.post(\"/register-device\")\n async def register_device_token(\n     request: DeviceRegistrationRequest,\n     current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"\n     Register device token for push notifications\n     \"\"\"\n     try:\n@@ -70,93 +95,92 @@\n         restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n         if not restaurant_id:\n             raise FynloException(\n                 message=\"User must be associated with a restaurant\",\n                 error_code=ErrorCodes.VALIDATION_ERROR,\n-                status_code=400\n+                status_code=400,\n             )\n         restaurant_id = str(restaurant_id)\n-        \n+\n         push_service = get_push_service()\n         success = await push_service.register_device_token(\n             token=request.device_token,\n             user_id=str(current_user.id),\n             restaurant_id=restaurant_id,\n-            device_type=request.device_type\n-        )\n-        \n+            device_type=request.device_type,\n+        )\n+\n         if not success:\n             raise FynloException(\n                 message=\"Failed to register device token\",\n                 error_code=ErrorCodes.INTERNAL_ERROR,\n-                status_code=500\n-            )\n-        \n+                status_code=500,\n+            )\n+\n         return APIResponseHelper.success(\n             data={\n                 \"device_token\": request.device_token[:8] + \"...\",  # Masked for security\n                 \"device_type\": request.device_type,\n-                \"registered_at\": datetime.now().isoformat()\n+                \"registered_at\": datetime.now().isoformat(),\n             },\n             message=\"Device token registered successfully\",\n-            meta={\n-                \"user_id\": str(current_user.id),\n-                \"restaurant_id\": restaurant_id\n-            }\n-        )\n-        \n+            meta={\"user_id\": str(current_user.id), \"restaurant_id\": restaurant_id},\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to register device: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n @router.delete(\"/unregister-device\")\n async def unregister_device_token(\n     device_token: str = Query(..., description=\"Device token to unregister\"),\n     current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"\n     Unregister device token\n     \"\"\"\n     try:\n         push_service = get_push_service()\n         success = await push_service.unregister_device_token(device_token)\n-        \n+\n         if not success:\n             raise FynloException(\n                 message=\"Device token not found or already inactive\",\n                 error_code=ErrorCodes.NOT_FOUND,\n-                status_code=404\n-            )\n-        \n+                status_code=404,\n+            )\n+\n         return APIResponseHelper.success(\n             message=\"Device token unregistered successfully\",\n             meta={\n                 \"device_token\": device_token[:8] + \"...\",\n-                \"unregistered_by\": current_user.username\n-            }\n-        )\n-        \n+                \"unregistered_by\": current_user.username,\n+            },\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to unregister device: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n @router.post(\"/send\")\n async def send_notification(\n     request: NotificationSendRequest,\n     current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"\n     Send push notification manually\n     Requires management permissions\n     \"\"\"\n@@ -164,137 +188,141 @@\n         # Only managers and owners can send manual notifications\n         if current_user.role not in [\"restaurant_owner\", \"platform_owner\", \"manager\"]:\n             raise FynloException(\n                 message=\"Access denied - management permissions required\",\n                 error_code=ErrorCodes.FORBIDDEN,\n-                status_code=403\n-            )\n-        \n+                status_code=403,\n+            )\n+\n         # Validate target restaurants if specified\n         if request.target_restaurants:\n             from app.core.tenant_security import TenantSecurity\n+\n             for restaurant_id in request.target_restaurants:\n                 await TenantSecurity.validate_restaurant_access(\n                     user=current_user,\n                     restaurant_id=restaurant_id,\n                     operation=\"access\",\n                     resource_type=\"notifications\",\n-                    db=db\n+                    db=db,\n                 )\n-        \n+\n         # Validate notification type and priority\n         try:\n             notification_type = NotificationType(request.notification_type)\n             priority = NotificationPriority(request.priority)\n         except ValueError as e:\n             raise FynloException(\n                 message=f\"Invalid notification type or priority: {str(e)}\",\n                 error_code=ErrorCodes.VALIDATION_ERROR,\n-                status_code=400\n-            )\n-        \n+                status_code=400,\n+            )\n+\n         # Create notification payload\n         payload = NotificationPayload(\n             title=request.title,\n             body=request.body,\n             notification_type=notification_type,\n             priority=priority,\n             sound=request.sound,\n-            custom_data=request.custom_data or {}\n-        )\n-        \n+            custom_data=request.custom_data or {},\n+        )\n+\n         # Send notification\n         push_service = get_push_service()\n         result = await push_service.send_notification(\n             payload=payload,\n             target_users=request.target_users,\n-            target_restaurants=request.target_restaurants\n-        )\n-        \n+            target_restaurants=request.target_restaurants,\n+        )\n+\n         return APIResponseHelper.success(\n             data=result,\n             message=f\"Notification sent to {result['total_sent']} devices\",\n             meta={\n                 \"sent_by\": current_user.username,\n                 \"notification_type\": request.notification_type,\n-                \"priority\": request.priority\n-            }\n-        )\n-        \n+                \"priority\": request.priority,\n+            },\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to send notification: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n @router.post(\"/send-templated\")\n async def send_templated_notification(\n     request: TemplatedNotificationRequest,\n     current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"\n     Send notification using predefined template\n     \"\"\"\n     try:\n         # Validate target restaurants if specified\n         if request.target_restaurants:\n             from app.core.tenant_security import TenantSecurity\n+\n             for restaurant_id in request.target_restaurants:\n                 await TenantSecurity.validate_restaurant_access(\n                     user=current_user,\n                     restaurant_id=restaurant_id,\n                     operation=\"access\",\n                     resource_type=\"notifications\",\n-                    db=db\n+                    db=db,\n                 )\n-        \n+\n         # Validate notification type\n         try:\n             notification_type = NotificationType(request.notification_type)\n         except ValueError:\n             raise FynloException(\n                 message=f\"Invalid notification type: {request.notification_type}\",\n                 error_code=ErrorCodes.VALIDATION_ERROR,\n-                status_code=400\n-            )\n-        \n+                status_code=400,\n+            )\n+\n         # Send templated notification\n         push_service = get_push_service()\n         result = await push_service.send_templated_notification(\n             notification_type=notification_type,\n             template_data=request.template_data,\n             target_users=request.target_users,\n-            target_restaurants=request.target_restaurants\n-        )\n-        \n+            target_restaurants=request.target_restaurants,\n+        )\n+\n         return APIResponseHelper.success(\n             data=result,\n             message=f\"Templated notification sent to {result['total_sent']} devices\",\n             meta={\n                 \"sent_by\": current_user.username,\n-                \"template_type\": request.notification_type\n-            }\n-        )\n-        \n+                \"template_type\": request.notification_type,\n+            },\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to send templated notification: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n @router.post(\"/preferences\")\n async def update_notification_preferences(\n     request: NotificationPreferencesRequest,\n     current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"\n     Update user notification preferences\n     \"\"\"\n     try:\n@@ -305,199 +333,198 @@\n                 enabled_types.append(NotificationType(type_str))\n             except ValueError:\n                 raise FynloException(\n                     message=f\"Invalid notification type: {type_str}\",\n                     error_code=ErrorCodes.VALIDATION_ERROR,\n-                    status_code=400\n+                    status_code=400,\n                 )\n-        \n+\n         # Create preferences object\n         preferences = NotificationPreferences(\n             user_id=str(current_user.id),\n             enabled_types=enabled_types,\n             quiet_hours_start=request.quiet_hours_start,\n             quiet_hours_end=request.quiet_hours_end,\n             sound_enabled=request.sound_enabled,\n-            badge_enabled=request.badge_enabled\n-        )\n-        \n+            badge_enabled=request.badge_enabled,\n+        )\n+\n         # Update preferences\n         push_service = get_push_service()\n         success = push_service.update_user_preferences(\n-            user_id=str(current_user.id),\n-            preferences=preferences\n-        )\n-        \n+            user_id=str(current_user.id), preferences=preferences\n+        )\n+\n         if not success:\n             raise FynloException(\n                 message=\"Failed to update notification preferences\",\n                 error_code=ErrorCodes.INTERNAL_ERROR,\n-                status_code=500\n-            )\n-        \n+                status_code=500,\n+            )\n+\n         return APIResponseHelper.success(\n             data={\n                 \"enabled_types\": [t.value for t in enabled_types],\n                 \"quiet_hours_start\": request.quiet_hours_start,\n                 \"quiet_hours_end\": request.quiet_hours_end,\n                 \"sound_enabled\": request.sound_enabled,\n                 \"badge_enabled\": request.badge_enabled,\n-                \"updated_at\": datetime.now().isoformat()\n+                \"updated_at\": datetime.now().isoformat(),\n             },\n             message=\"Notification preferences updated successfully\",\n-            meta={\"user_id\": str(current_user.id)}\n-        )\n-        \n+            meta={\"user_id\": str(current_user.id)},\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to update preferences: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n @router.get(\"/preferences\")\n async def get_notification_preferences(\n-    current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    current_user: User = Depends(get_current_user), db: Session = Depends(get_db)\n ):\n     \"\"\"\n     Get user notification preferences\n     \"\"\"\n     try:\n         push_service = get_push_service()\n         preferences = push_service.get_user_preferences(str(current_user.id))\n-        \n+\n         if not preferences:\n             # Return default preferences\n             return APIResponseHelper.success(\n                 data={\n                     \"enabled_types\": [t.value for t in NotificationType],\n                     \"quiet_hours_start\": None,\n                     \"quiet_hours_end\": None,\n                     \"sound_enabled\": True,\n                     \"badge_enabled\": True,\n-                    \"is_default\": True\n+                    \"is_default\": True,\n                 },\n                 message=\"Default notification preferences (not customized)\",\n-                meta={\"user_id\": str(current_user.id)}\n-            )\n-        \n+                meta={\"user_id\": str(current_user.id)},\n+            )\n+\n         return APIResponseHelper.success(\n             data={\n                 \"enabled_types\": [t.value for t in preferences.enabled_types],\n                 \"quiet_hours_start\": preferences.quiet_hours_start,\n                 \"quiet_hours_end\": preferences.quiet_hours_end,\n                 \"sound_enabled\": preferences.sound_enabled,\n                 \"badge_enabled\": preferences.badge_enabled,\n                 \"updated_at\": preferences.updated_at.isoformat(),\n-                \"is_default\": False\n+                \"is_default\": False,\n             },\n             message=\"Notification preferences retrieved successfully\",\n-            meta={\"user_id\": str(current_user.id)}\n-        )\n-        \n+            meta={\"user_id\": str(current_user.id)},\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to get preferences: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n @router.get(\"/history\")\n async def get_notification_history(\n     limit: int = Query(50, le=200, description=\"Maximum notifications to return\"),\n     current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"\n     Get notification history for current user\n     \"\"\"\n     try:\n         push_service = get_push_service()\n         history = push_service.get_notification_history(\n-            user_id=str(current_user.id),\n-            limit=limit\n-        )\n-        \n+            user_id=str(current_user.id), limit=limit\n+        )\n+\n         # Convert to response format\n         history_data = [\n             {\n                 \"device_token\": result.device_token[:8] + \"...\",  # Masked\n                 \"success\": result.success,\n                 \"message_id\": result.message_id,\n                 \"error_code\": result.error_code,\n                 \"error_message\": result.error_message,\n-                \"sent_at\": result.sent_at.isoformat()\n+                \"sent_at\": result.sent_at.isoformat(),\n             }\n             for result in history\n         ]\n-        \n+\n         return APIResponseHelper.success(\n             data=history_data,\n             message=f\"Retrieved {len(history_data)} notification records\",\n             meta={\n                 \"user_id\": str(current_user.id),\n                 \"limit\": limit,\n-                \"total_records\": len(history_data)\n-            }\n-        )\n-        \n+                \"total_records\": len(history_data),\n+            },\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to get notification history: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n @router.get(\"/templates\")\n async def get_notification_templates(\n-    current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    current_user: User = Depends(get_current_user), db: Session = Depends(get_db)\n ):\n     \"\"\"\n     Get available notification templates\n     \"\"\"\n     try:\n         push_service = get_push_service()\n         templates = push_service.templates\n-        \n+\n         # Convert templates to response format\n         templates_data = {}\n         for notification_type, template in templates.items():\n             templates_data[notification_type.value] = {\n                 \"title_template\": template.title_template,\n                 \"body_template\": template.body_template,\n                 \"priority\": template.priority.value,\n                 \"sound\": template.sound,\n-                \"custom_data_template\": template.custom_data_template\n+                \"custom_data_template\": template.custom_data_template,\n             }\n-        \n+\n         return APIResponseHelper.success(\n             data=templates_data,\n             message=f\"Retrieved {len(templates_data)} notification templates\",\n-            meta={\"template_count\": len(templates_data)}\n-        )\n-        \n+            meta={\"template_count\": len(templates_data)},\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to get templates: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n @router.get(\"/stats\")\n async def get_notification_statistics(\n-    current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    current_user: User = Depends(get_current_user), db: Session = Depends(get_db)\n ):\n     \"\"\"\n     Get push notification service statistics\n     Requires management permissions\n     \"\"\"\n@@ -505,36 +532,39 @@\n         # Only managers and owners can view statistics\n         if current_user.role not in [\"restaurant_owner\", \"platform_owner\", \"manager\"]:\n             raise FynloException(\n                 message=\"Access denied - management permissions required\",\n                 error_code=ErrorCodes.FORBIDDEN,\n-                status_code=403\n-            )\n-        \n+                status_code=403,\n+            )\n+\n         push_service = get_push_service()\n         stats = push_service.get_service_statistics()\n-        \n+\n         return APIResponseHelper.success(\n             data=stats,\n             message=\"Push notification statistics retrieved successfully\",\n-            meta={\"requested_by\": current_user.username}\n-        )\n-        \n+            meta={\"requested_by\": current_user.username},\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to get statistics: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n @router.post(\"/test\")\n async def send_test_notification(\n-    device_token: Optional[str] = Body(None, description=\"Specific device token to test\"),\n+    device_token: Optional[str] = Body(\n+        None, description=\"Specific device token to test\"\n+    ),\n     current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"\n     Send test notification for debugging\n     Requires management permissions\n     \"\"\"\n@@ -542,55 +572,53 @@\n         # Only managers and owners can send test notifications\n         if current_user.role not in [\"restaurant_owner\", \"platform_owner\", \"manager\"]:\n             raise FynloException(\n                 message=\"Access denied - management permissions required\",\n                 error_code=ErrorCodes.FORBIDDEN,\n-                status_code=403\n-            )\n-        \n+                status_code=403,\n+            )\n+\n         # Create test payload\n         payload = NotificationPayload(\n             title=\"Test Notification\",\n             body=f\"Test notification sent by {current_user.username} at {datetime.now().strftime('%H:%M:%S')}\",\n             notification_type=NotificationType.SYSTEM_MAINTENANCE,\n             priority=NotificationPriority.NORMAL,\n             sound=\"default\",\n             custom_data={\n                 \"test\": True,\n                 \"sent_by\": current_user.username,\n-                \"timestamp\": datetime.now().isoformat()\n-            }\n-        )\n-        \n+                \"timestamp\": datetime.now().isoformat(),\n+            },\n+        )\n+\n         # Send notification\n         push_service = get_push_service()\n-        \n+\n         if device_token:\n             # Send to specific device\n             result = await push_service.send_notification(\n-                payload=payload,\n-                target_tokens=[device_token]\n+                payload=payload, target_tokens=[device_token]\n             )\n         else:\n             # Send to current user's devices\n             result = await push_service.send_notification(\n-                payload=payload,\n-                target_users=[str(current_user.id)]\n-            )\n-        \n+                payload=payload, target_users=[str(current_user.id)]\n+            )\n+\n         return APIResponseHelper.success(\n             data=result,\n             message=f\"Test notification sent to {result['total_sent']} devices\",\n             meta={\n                 \"test_type\": \"specific_device\" if device_token else \"user_devices\",\n-                \"sent_by\": current_user.username\n-            }\n-        )\n-        \n+                \"sent_by\": current_user.username,\n+            },\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to send test notification: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n\\ No newline at end of file\n+            status_code=500,\n+        )\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/platform_settings_optimized.py\t2025-08-02 21:56:58.988113+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/platform_settings_optimized.py\t2025-08-02 22:36:02.806038+00:00\n@@ -1,9 +1,10 @@\n \"\"\"\n Optimized Platform Settings Endpoints\n Performance improvements for mobile app connectivity\n \"\"\"\n+\n from typing import Dict, Any, Optional\n from pydantic import BaseModel\n from fastapi import APIRouter, Response\n from sqlalchemy.orm import Session\n import asyncio\n@@ -26,39 +27,35 @@\n # Default configurations\n DEFAULT_SERVICE_CHARGE = {\n     \"enabled\": True,\n     \"rate\": 12.5,\n     \"description\": \"Platform service charge\",\n-    \"currency\": \"GBP\"\n+    \"currency\": \"GBP\",\n }\n \n DEFAULT_PAYMENT_METHODS = {\n     \"qr_code\": {\n         \"enabled\": True,\n         \"fee_percentage\": 1.2,\n         \"name\": \"QR Code Payment\",\n-        \"icon\": \"qrcode\"\n+        \"icon\": \"qrcode\",\n     },\n     \"card\": {\n         \"enabled\": True,\n         \"fee_percentage\": 2.9,\n         \"name\": \"Card Payment\",\n-        \"icon\": \"credit-card\"\n+        \"icon\": \"credit-card\",\n     },\n-    \"cash\": {\n-        \"enabled\": True,\n-        \"fee_percentage\": 0.0,\n-        \"name\": \"Cash\",\n-        \"icon\": \"cash\"\n-    },\n+    \"cash\": {\"enabled\": True, \"fee_percentage\": 0.0, \"name\": \"Cash\", \"icon\": \"cash\"},\n     \"apple_pay\": {\n         \"enabled\": True,\n         \"fee_percentage\": 2.9,\n         \"name\": \"Apple Pay\",\n-        \"icon\": \"apple\"\n-    }\n+        \"icon\": \"apple\",\n+    },\n }\n+\n \n async def get_from_memory_cache(key: str) -> Optional[Dict[str, Any]]:\n     \"\"\"Get value from memory cache if not expired (thread-safe)\"\"\"\n     async with _cache_lock:\n         if key in _memory_cache:\n@@ -68,17 +65,19 @@\n             else:\n                 # Clean up expired entry\n                 _memory_cache.pop(key, None)\n     return None\n \n+\n async def set_memory_cache(key: str, data: Dict[str, Any]):\n     \"\"\"Set value in memory cache with TTL (thread-safe)\"\"\"\n     async with _cache_lock:\n         _memory_cache[key] = {\n             \"data\": data,\n-            \"expires_at\": datetime.utcnow() + _cache_ttl\n+            \"expires_at\": datetime.utcnow() + _cache_ttl,\n         }\n+\n \n @router.get(\"/service-charge/fast\")\n async def get_service_charge_fast(response: Response):\n     \"\"\"\n     Ultra-fast service charge endpoint with aggressive caching\n@@ -89,33 +88,34 @@\n         cached = await get_from_memory_cache(\"service_charge\")\n         if cached:\n             response.headers[\"X-Cache\"] = \"HIT\"\n             return APIResponseHelper.success(\n                 data={\"service_charge\": cached},\n-                message=\"Service charge configuration (cached)\"\n+                message=\"Service charge configuration (cached)\",\n             )\n-        \n+\n         # Return defaults immediately, update cache in background\n         response.headers[\"X-Cache\"] = \"MISS\"\n-        \n+\n         # Set memory cache\n         await set_memory_cache(\"service_charge\", DEFAULT_SERVICE_CHARGE)\n-        \n+\n         # Schedule background cache update\n         asyncio.create_task(update_service_charge_cache())\n-        \n+\n         return APIResponseHelper.success(\n             data={\"service_charge\": DEFAULT_SERVICE_CHARGE},\n-            message=\"Service charge configuration\"\n-        )\n-        \n+            message=\"Service charge configuration\",\n+        )\n+\n     except Exception as e:\n         logger.error(f\"Error in get_service_charge_fast: {e}\")\n         return APIResponseHelper.success(\n             data={\"service_charge\": DEFAULT_SERVICE_CHARGE},\n-            message=\"Service charge configuration (fallback)\"\n-        )\n+            message=\"Service charge configuration (fallback)\",\n+        )\n+\n \n @router.get(\"/payment-methods/fast\")\n async def get_payment_methods_fast(response: Response):\n     \"\"\"\n     Ultra-fast payment methods endpoint with aggressive caching\n@@ -124,34 +124,33 @@\n         # Check memory cache first\n         cached = await get_from_memory_cache(\"payment_methods\")\n         if cached:\n             response.headers[\"X-Cache\"] = \"HIT\"\n             return APIResponseHelper.success(\n-                data={\"payment_methods\": cached},\n-                message=\"Payment methods (cached)\"\n+                data={\"payment_methods\": cached}, message=\"Payment methods (cached)\"\n             )\n-        \n+\n         # Return defaults immediately, update cache in background\n         response.headers[\"X-Cache\"] = \"MISS\"\n-        \n+\n         # Set memory cache\n         await set_memory_cache(\"payment_methods\", DEFAULT_PAYMENT_METHODS)\n-        \n+\n         # Schedule background cache update (same as service charge)\n         asyncio.create_task(update_payment_methods_cache())\n-        \n+\n+        return APIResponseHelper.success(\n+            data={\"payment_methods\": DEFAULT_PAYMENT_METHODS}, message=\"Payment methods\"\n+        )\n+\n+    except Exception as e:\n+        logger.error(f\"Error in get_payment_methods_fast: {e}\")\n         return APIResponseHelper.success(\n             data={\"payment_methods\": DEFAULT_PAYMENT_METHODS},\n-            message=\"Payment methods\"\n-        )\n-        \n-    except Exception as e:\n-        logger.error(f\"Error in get_payment_methods_fast: {e}\")\n-        return APIResponseHelper.success(\n-            data={\"payment_methods\": DEFAULT_PAYMENT_METHODS},\n-            message=\"Payment methods (fallback)\"\n-        )\n+            message=\"Payment methods (fallback)\",\n+        )\n+\n \n @router.get(\"/all-settings/fast\")\n async def get_all_settings_fast(response: Response):\n     \"\"\"\n     Combined endpoint to reduce number of API calls\n@@ -159,91 +158,92 @@\n     \"\"\"\n     try:\n         # Check if we have all settings cached\n         service_charge_cached = await get_from_memory_cache(\"service_charge\")\n         payment_methods_cached = await get_from_memory_cache(\"payment_methods\")\n-        \n+\n         # Track original cache state for header\n         service_charge_was_cached = service_charge_cached is not None\n         payment_methods_was_cached = payment_methods_cached is not None\n-        \n+\n         # Populate cache for any missing values\n         if not service_charge_cached:\n             await set_memory_cache(\"service_charge\", DEFAULT_SERVICE_CHARGE)\n             asyncio.create_task(update_service_charge_cache())\n             service_charge_cached = DEFAULT_SERVICE_CHARGE\n-            \n+\n         if not payment_methods_cached:\n             await set_memory_cache(\"payment_methods\", DEFAULT_PAYMENT_METHODS)\n             asyncio.create_task(update_payment_methods_cache())\n             payment_methods_cached = DEFAULT_PAYMENT_METHODS\n-        \n+\n         all_settings = {\n             \"service_charge\": service_charge_cached,\n             \"payment_methods\": payment_methods_cached,\n             \"platform_info\": {\n                 \"name\": \"Fynlo POS\",\n                 \"version\": \"1.0.0\",\n-                \"support_email\": \"support@fynlo.com\"\n-            }\n+                \"support_email\": \"support@fynlo.com\",\n+            },\n         }\n-        \n+\n         # Set cache header based on original cache state\n         if service_charge_was_cached and payment_methods_was_cached:\n             response.headers[\"X-Cache\"] = \"HIT\"\n         elif service_charge_was_cached or payment_methods_was_cached:\n             response.headers[\"X-Cache\"] = \"PARTIAL\"\n         else:\n             response.headers[\"X-Cache\"] = \"MISS\"\n-        \n-        return APIResponseHelper.success(\n-            data=all_settings,\n-            message=\"All platform settings\"\n-        )\n-        \n+\n+        return APIResponseHelper.success(\n+            data=all_settings, message=\"All platform settings\"\n+        )\n+\n     except Exception as e:\n         logger.error(f\"Error in get_all_settings_fast: {e}\")\n         return APIResponseHelper.success(\n             data={\n                 \"service_charge\": DEFAULT_SERVICE_CHARGE,\n                 \"payment_methods\": DEFAULT_PAYMENT_METHODS,\n                 \"platform_info\": {\n                     \"name\": \"Fynlo POS\",\n                     \"version\": \"1.0.0\",\n-                    \"support_email\": \"support@fynlo.com\"\n-                }\n+                    \"support_email\": \"support@fynlo.com\",\n+                },\n             },\n-            message=\"All platform settings (fallback)\"\n-        )\n+            message=\"All platform settings (fallback)\",\n+        )\n+\n \n async def update_service_charge_cache():\n     \"\"\"Background task to update service charge cache from database\"\"\"\n     try:\n         # Try to get from Redis first\n         cached_config = await PlatformCacheService.get_service_charge_config()\n         if cached_config:\n             await set_memory_cache(\"service_charge\", cached_config)\n             return\n-        \n+\n         # If not in Redis, we'll just keep using defaults\n         # Database queries can be added here if needed in future\n-        \n+\n     except Exception as e:\n         logger.warning(f\"Background service charge cache update failed: {e}\")\n+\n \n async def update_payment_methods_cache():\n     \"\"\"Background task to update payment methods cache from database\"\"\"\n     try:\n         # For now, payment methods are static configuration\n         # In future, this could fetch from database or Redis\n         # This ensures consistency with service charge pattern\n-        \n+\n         # Could add database query here when payment methods become configurable\n         # Example:\n         # payment_config = await fetch_payment_methods_from_db()\n         # if payment_config:\n         #     await set_memory_cache(\"payment_methods\", payment_config)\n-        \n+\n         logger.debug(\"Payment methods cache update completed (using defaults)\")\n-        \n-    except Exception as e:\n-        logger.warning(f\"Background payment methods cache update failed: {e}\")\n\\ No newline at end of file\n+\n+    except Exception as e:\n+        logger.warning(f\"Background payment methods cache update failed: {e}\")\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/platform_settings_public.py\t2025-08-02 21:56:58.988331+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/platform_settings_public.py\t2025-08-02 22:36:02.812106+00:00\n@@ -1,9 +1,10 @@\n \"\"\"\n Public Platform Settings Endpoints\n Non-admin endpoints for reading platform configurations\n \"\"\"\n+\n from typing import Optional\n from pydantic import BaseModel\n from fastapi import APIRouter, Depends\n from sqlalchemy.orm import Session\n from concurrent.futures import TimeoutError as FuturesTimeoutError\n@@ -20,17 +21,16 @@\n # Default service charge configuration\n DEFAULT_SERVICE_CHARGE = {\n     \"enabled\": True,\n     \"rate\": 12.5,\n     \"description\": \"Platform service charge\",\n-    \"currency\": \"GBP\"\n+    \"currency\": \"GBP\",\n }\n \n+\n @router.get(\"/service-charge\")\n-async def get_service_charge_public(\n-    db: Session = Depends(get_db)\n-):\n+async def get_service_charge_public(db: Session = Depends(get_db)):\n     \"\"\"\n     Get service charge configuration (public endpoint)\n     This endpoint doesn't require admin authentication\n     \"\"\"\n     try:\n@@ -38,73 +38,81 @@\n         cached_config = await PlatformCacheService.get_service_charge_config()\n         if cached_config:\n             logger.info(\"Returning cached service charge configuration\")\n             return APIResponseHelper.success(\n                 data={\"service_charge\": cached_config},\n-                message=\"Service charge configuration retrieved (cached)\"\n+                message=\"Service charge configuration retrieved (cached)\",\n             )\n-        \n+\n         logger.info(\"Cache miss - querying database\")\n-        \n+\n         # Use defaults as starting point\n         result = DEFAULT_SERVICE_CHARGE.copy()\n-        \n+\n         # Try a quick database query with statement timeout\n         db_success = False\n         try:\n             # Set a statement timeout at the database level\n             db.execute(\"SET LOCAL statement_timeout = '500ms'\")\n-            \n+\n             from app.models.platform_config import PlatformConfiguration\n-            \n-            configs = db.query(PlatformConfiguration).filter(\n-                PlatformConfiguration.category == \"service_charge\",\n-                PlatformConfiguration.is_active == True\n-            ).limit(4).all()\n-            \n+\n+            configs = (\n+                db.query(PlatformConfiguration)\n+                .filter(\n+                    PlatformConfiguration.category == \"service_charge\",\n+                    PlatformConfiguration.is_active == True,\n+                )\n+                .limit(4)\n+                .all()\n+            )\n+\n             # Parse configurations if query succeeds\n             for config in configs:\n                 if config.config_key == \"platform.service_charge.enabled\":\n                     result[\"enabled\"] = config.config_value.get(\"value\", True)\n                 elif config.config_key == \"platform.service_charge.rate\":\n                     result[\"rate\"] = config.config_value.get(\"value\", 12.5)\n                 elif config.config_key == \"platform.service_charge.description\":\n-                    result[\"description\"] = config.config_value.get(\"value\", \"Platform service charge\")\n+                    result[\"description\"] = config.config_value.get(\n+                        \"value\", \"Platform service charge\"\n+                    )\n                 elif config.config_key == \"platform.service_charge.currency\":\n                     result[\"currency\"] = config.config_value.get(\"value\", \"GBP\")\n-            \n+\n             db_success = True\n-                    \n+\n         except Exception as e:\n             # If database query fails or times out, use defaults\n             logger.warning(f\"Database query failed, using defaults: {e}\")\n         finally:\n             # Always reset the timeout for the connection\n             try:\n                 db.execute(\"RESET statement_timeout\")\n             except Exception as reset_error:\n                 logger.warning(f\"Failed to reset statement timeout: {reset_error}\")\n-        \n+\n         # Cache the result if database query was successful\n         if db_success:\n             try:\n                 await PlatformCacheService.set_service_charge_config(result)\n             except Exception as cache_error:\n                 logger.warning(f\"Failed to cache configuration: {cache_error}\")\n-        \n+\n         return APIResponseHelper.success(\n             data={\"service_charge\": result},\n-            message=\"Service charge configuration retrieved\"\n+            message=\"Service charge configuration retrieved\",\n         )\n-        \n+\n     except Exception as e:\n         logger.error(f\"Error in get_service_charge_public: {e}\")\n         # Always return a valid response instead of timing out\n         return APIResponseHelper.success(\n             data={\"service_charge\": DEFAULT_SERVICE_CHARGE},\n-            message=\"Service charge configuration (default)\"\n+            message=\"Service charge configuration (default)\",\n         )\n+\n \n @router.get(\"/payment-methods\")\n async def get_payment_methods_public():\n     \"\"\"\n     Get available payment methods (public endpoint)\n@@ -113,35 +121,37 @@\n         payment_methods = {\n             \"qr_code\": {\n                 \"enabled\": True,\n                 \"fee_percentage\": 1.2,\n                 \"name\": \"QR Code Payment\",\n-                \"icon\": \"qrcode\"\n+                \"icon\": \"qrcode\",\n             },\n             \"card\": {\n                 \"enabled\": True,\n                 \"fee_percentage\": 2.9,\n                 \"name\": \"Card Payment\",\n-                \"icon\": \"credit-card\"\n+                \"icon\": \"credit-card\",\n             },\n             \"cash\": {\n                 \"enabled\": True,\n                 \"fee_percentage\": 0.0,\n                 \"name\": \"Cash\",\n-                \"icon\": \"cash\"\n+                \"icon\": \"cash\",\n             },\n             \"apple_pay\": {\n                 \"enabled\": True,\n                 \"fee_percentage\": 2.9,\n                 \"name\": \"Apple Pay\",\n-                \"icon\": \"apple\"\n-            }\n+                \"icon\": \"apple\",\n+            },\n         }\n-        \n+\n         return APIResponseHelper.success(\n             data={\"payment_methods\": payment_methods},\n-            message=\"Payment methods retrieved\"\n+            message=\"Payment methods retrieved\",\n         )\n-        \n+\n     except Exception as e:\n         logger.error(f\"Error in get_payment_methods_public: {e}\")\n-        raise FynloException(message=\"Failed to retrieve public settings\", status_code=500)\n\\ No newline at end of file\n+        raise FynloException(\n+            message=\"Failed to retrieve public settings\", status_code=500\n+        )\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/products_secure.py\t2025-08-02 21:56:58.988520+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/products_secure.py\t2025-08-02 22:36:02.828294+00:00\n@@ -20,187 +20,190 @@\n @router.put(\"/{product_id}\")\n async def update_product_secure(\n     product_id: str,\n     product_data: dict,  # ProductUpdate schema\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"\n     Secure version of update_product that validates restaurant access\n     \"\"\"\n     # First, get the product to check its restaurant\n     product = db.query(Product).filter(Product.id == product_id).first()\n-    \n+\n     if not product:\n         raise ResourceNotFoundException(resource=\"Product\")\n-    \n+\n     # CRITICAL SECURITY CHECK: Validate user can access this product's restaurant\n     await TenantSecurity.validate_restaurant_access(\n         user=current_user,\n         restaurant_id=str(product.restaurant_id),\n         operation=\"modify\",\n-        db=db\n+        db=db,\n     )\n-    \n+\n     # If we get here, user has access (either platform owner or same restaurant)\n     # Proceed with update...\n-    \n+\n     # Additional security: If user tries to change restaurant_id, validate that too\n-    if \"restaurant_id\" in product_data and product_data[\"restaurant_id\"] != str(product.restaurant_id):\n+    if \"restaurant_id\" in product_data and product_data[\"restaurant_id\"] != str(\n+        product.restaurant_id\n+    ):\n         # Only platform owners can move products between restaurants\n         if not TenantSecurity.is_platform_owner(current_user):\n-            raise AuthorizationException(message=\"Only platform owners can move products between restaurants\")\n+            raise AuthorizationException(\n+                message=\"Only platform owners can move products between restaurants\"\n+            )\n         # Validate access to target restaurant\n         await TenantSecurity.validate_restaurant_access(\n             user=current_user,\n             restaurant_id=product_data[\"restaurant_id\"],\n             operation=\"create\",\n-            db=db\n+            db=db,\n         )\n-    \n+\n     # Update the product...\n     return {\"message\": \"Product updated securely\"}\n \n \n @router.delete(\"/{product_id}\")\n async def delete_product_secure(\n     product_id: str,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"\n     Secure version of delete_product that validates restaurant access\n     \"\"\"\n     product = db.query(Product).filter(Product.id == product_id).first()\n-    \n+\n     if not product:\n         raise ResourceNotFoundException(resource=\"Product\")\n-    \n+\n     # CRITICAL: Validate access before deletion\n     await TenantSecurity.validate_restaurant_access(\n         user=current_user,\n         restaurant_id=str(product.restaurant_id),\n         operation=\"delete\",\n-        db=db\n+        db=db,\n     )\n-    \n+\n     # Proceed with soft delete\n     product.is_active = False\n     db.commit()\n-    \n+\n     return {\"message\": \"Product deleted securely\"}\n \n \n @router.get(\"/\")\n async def get_products_secure(\n     restaurant_id: Optional[str] = Query(None),\n     category_id: Optional[str] = Query(None),\n     is_active: Optional[bool] = Query(True),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"\n     Secure version of get_products with proper tenant filtering\n     \"\"\"\n     # Start with base query\n     query = db.query(Product)\n-    \n+\n     # Apply tenant filtering\n     query = TenantSecurity.apply_tenant_filter(\n-        query=query,\n-        user=current_user,\n-        model_class=Product,\n-        db=db\n+        query=query, user=current_user, model_class=Product, db=db\n     )\n-    \n+\n     # If restaurant_id specified, validate access\n     if restaurant_id:\n         await TenantSecurity.validate_restaurant_access(\n-            user=current_user,\n-            restaurant_id=restaurant_id,\n-            operation=\"view\",\n-            db=db\n+            user=current_user, restaurant_id=restaurant_id, operation=\"view\", db=db\n         )\n         query = query.filter(Product.restaurant_id == restaurant_id)\n-    \n+\n     # Apply other filters\n     if category_id:\n         query = query.filter(Product.category_id == category_id)\n-    \n+\n     if is_active is not None:\n         query = query.filter(Product.is_active == is_active)\n-    \n+\n     products = query.all()\n-    \n+\n     # Additional security: Sanitize response based on user level\n     results = []\n     for product in products:\n         product_dict = {\n             \"id\": str(product.id),\n             \"name\": product.name,\n             \"price\": float(product.price),\n             \"category_id\": str(product.category_id),\n-            \"restaurant_id\": str(product.restaurant_id)\n+            \"restaurant_id\": str(product.restaurant_id),\n         }\n-        \n+\n         # Platform owners see cost/profit data\n         if TenantSecurity.is_platform_owner(current_user):\n             product_dict[\"cost\"] = float(product.cost) if product.cost else None\n             product_dict[\"profit_margin\"] = (\n-                ((float(product.price) - float(product.cost)) / float(product.price) * 100)\n-                if product.cost else None\n+                (\n+                    (float(product.price) - float(product.cost))\n+                    / float(product.price)\n+                    * 100\n+                )\n+                if product.cost\n+                else None\n             )\n-        \n+\n         results.append(product_dict)\n-    \n+\n     return {\n         \"items\": results,\n         \"total\": len(results),\n-        \"restaurant_filter\": restaurant_id or current_user.restaurant_id\n+        \"restaurant_filter\": restaurant_id or current_user.restaurant_id,\n     }\n \n \n @router.post(\"/bulk-update\")\n async def bulk_update_products_secure(\n     updates: List[dict],  # List of product updates\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"\n     Secure bulk update that validates each product's restaurant\n     \"\"\"\n     results = []\n     errors = []\n-    \n+\n     for update in updates:\n         product_id = update.get(\"id\")\n         if not product_id:\n             errors.append({\"error\": \"Missing product ID in update\"})\n             continue\n-        \n+\n         product = db.query(Product).filter(Product.id == product_id).first()\n         if not product:\n             errors.append({\"id\": product_id, \"error\": \"Product not found\"})\n             continue\n-        \n+\n         # Validate access for each product\n         try:\n             await TenantSecurity.validate_restaurant_access(\n                 user=current_user,\n                 restaurant_id=str(product.restaurant_id),\n                 operation=\"modify\",\n-                db=db\n+                db=db,\n             )\n-            \n+\n             # Update product...\n             results.append({\"id\": product_id, \"status\": \"updated\"})\n-            \n+\n         except FynloException as e:\n             errors.append({\"id\": product_id, \"error\": str(e.detail)})\n-    \n+\n     db.commit()\n-    \n+\n     return {\n         \"successful\": results,\n         \"errors\": errors,\n-        \"summary\": f\"{len(results)} updated, {len(errors)} failed\"\n-    }\n\\ No newline at end of file\n+        \"summary\": f\"{len(results)} updated, {len(errors)} failed\",\n+    }\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/pos.py\t2025-08-02 19:52:26.967038+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/pos.py\t2025-08-02 22:36:02.832881+00:00\n@@ -15,14 +15,16 @@\n from app.core.exceptions import FynloException, ErrorCodes\n from app.core.tenant_security import TenantSecurity\n \n router = APIRouter()\n \n+\n # Pydantic models for POS Session\n class PosSessionCreate(BaseModel):\n     config_id: int\n     name: Optional[str] = None\n+\n \n class PosSessionResponse(BaseModel):\n     id: str\n     name: str\n     state: str  # 'opening_control' | 'opened' | 'closing_control' | 'closed'\n@@ -31,235 +33,249 @@\n     config_id: int\n     config_name: str\n     user_id: str\n     user_name: str\n \n+\n @router.get(\"/sessions/current\")\n async def get_current_session(\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Specific restaurant ID for multi-restaurant users\"),\n-    current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Specific restaurant ID for multi-restaurant users\"\n+    ),\n+    current_user: User = Depends(get_current_user),\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Get the current active POS session\"\"\"\n-    \n-    # Validate restaurant access\n-    await TenantSecurity.validate_restaurant_access(\n-        current_user, \n-        current_restaurant_id or current_user.restaurant_id, \n-        db=db\n+\n+    # Validate restaurant access\n+    await TenantSecurity.validate_restaurant_access(\n+        current_user, current_restaurant_id or current_user.restaurant_id, db=db\n     )\n     # Use the provided restaurant_id or fall back to user's default\n     restaurant_id = current_restaurant_id or current_user.restaurant_id\n-    \n+\n     # Find the active session for this user\n-    active_session = db.query(PosSession).filter(\n-        and_(\n-            PosSession.user_id == current_user.id,\n-            PosSession.restaurant_id == restaurant_id,\n-            PosSession.state.in_([\"opening_control\", \"opened\"]),\n-            PosSession.is_active == True\n-        )\n-    ).first()\n-    \n+    active_session = (\n+        db.query(PosSession)\n+        .filter(\n+            and_(\n+                PosSession.user_id == current_user.id,\n+                PosSession.restaurant_id == restaurant_id,\n+                PosSession.state.in_([\"opening_control\", \"opened\"]),\n+                PosSession.is_active == True,\n+            )\n+        )\n+        .first()\n+    )\n+\n     if not active_session:\n         return APIResponseHelper.success(\n-            data=None,\n-            message=\"No active POS session found\"\n-        )\n-    \n+            data=None, message=\"No active POS session found\"\n+        )\n+\n     session_data = {\n         \"id\": str(active_session.id),\n         \"name\": active_session.name,\n         \"state\": active_session.state,\n         \"start_at\": active_session.start_at.isoformat(),\n-        \"stop_at\": active_session.stop_at.isoformat() if active_session.stop_at else None,\n+        \"stop_at\": (\n+            active_session.stop_at.isoformat() if active_session.stop_at else None\n+        ),\n         \"config_id\": active_session.config_id,\n         \"config_name\": active_session.config_name,\n         \"user_id\": str(active_session.user_id),\n-        \"user_name\": f\"{current_user.first_name} {current_user.last_name}\"\n+        \"user_name\": f\"{current_user.first_name} {current_user.last_name}\",\n     }\n-    \n-    return APIResponseHelper.success(\n-        data=session_data,\n-        message=\"Current POS session retrieved successfully\"\n-    )\n+\n+    return APIResponseHelper.success(\n+        data=session_data, message=\"Current POS session retrieved successfully\"\n+    )\n+\n \n @router.post(\"/sessions\")\n async def create_session(\n     session_data: PosSessionCreate,\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Specific restaurant ID for multi-restaurant users\"),\n-    current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Specific restaurant ID for multi-restaurant users\"\n+    ),\n+    current_user: User = Depends(get_current_user),\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Create a new POS session\"\"\"\n-    \n-    # Validate restaurant access\n-    await TenantSecurity.validate_restaurant_access(\n-        current_user, \n-        current_restaurant_id or current_user.restaurant_id, \n-        db=db\n+\n+    # Validate restaurant access\n+    await TenantSecurity.validate_restaurant_access(\n+        current_user, current_restaurant_id or current_user.restaurant_id, db=db\n     )\n     # Use the provided restaurant_id or fall back to user's default\n     restaurant_id = current_restaurant_id or current_user.restaurant_id\n-    \n+\n     # Check if user already has an active session\n-    existing_session = db.query(PosSession).filter(\n-        and_(\n-            PosSession.user_id == current_user.id,\n-            PosSession.restaurant_id == restaurant_id,\n-            PosSession.state.in_([\"opening_control\", \"opened\"]),\n-            PosSession.is_active == True\n-        )\n-    ).first()\n-    \n+    existing_session = (\n+        db.query(PosSession)\n+        .filter(\n+            and_(\n+                PosSession.user_id == current_user.id,\n+                PosSession.restaurant_id == restaurant_id,\n+                PosSession.state.in_([\"opening_control\", \"opened\"]),\n+                PosSession.is_active == True,\n+            )\n+        )\n+        .first()\n+    )\n+\n     if existing_session:\n         raise FynloException(\n             error_code=ErrorCodes.BUSINESS_LOGIC_ERROR,\n-            detail=\"User already has an active POS session\"\n-        )\n-    \n+            detail=\"User already has an active POS session\",\n+        )\n+\n     # Create new session\n     new_session = PosSession(\n         restaurant_id=restaurant_id,\n         user_id=current_user.id,\n         name=session_data.name or f\"POS Session {datetime.utcnow().strftime('%H:%M')}\",\n         state=\"opening_control\",\n         config_id=session_data.config_id,\n         config_name=f\"POS Config {session_data.config_id}\",\n-        session_data={}\n-    )\n-    \n+        session_data={},\n+    )\n+\n     db.add(new_session)\n     db.commit()\n     db.refresh(new_session)\n-    \n+\n     response_data = {\n         \"id\": str(new_session.id),\n         \"name\": new_session.name,\n         \"state\": new_session.state,\n         \"start_at\": new_session.start_at.isoformat(),\n         \"stop_at\": None,\n         \"config_id\": new_session.config_id,\n         \"config_name\": new_session.config_name,\n         \"user_id\": str(new_session.user_id),\n-        \"user_name\": f\"{current_user.first_name} {current_user.last_name}\"\n+        \"user_name\": f\"{current_user.first_name} {current_user.last_name}\",\n     }\n-    \n-    return APIResponseHelper.success(\n-        data=response_data,\n-        message=\"POS session created successfully\"\n-    )\n+\n+    return APIResponseHelper.success(\n+        data=response_data, message=\"POS session created successfully\"\n+    )\n+\n \n @router.put(\"/sessions/{session_id}/state\")\n async def update_session_state(\n     session_id: str,\n     state: str,\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Specific restaurant ID for multi-restaurant users\"),\n-    current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Specific restaurant ID for multi-restaurant users\"\n+    ),\n+    current_user: User = Depends(get_current_user),\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Update POS session state\"\"\"\n-    \n+\n     session = db.query(PosSession).filter(PosSession.id == session_id).first()\n-    \n+\n     if not session:\n         raise FynloException(\n-            error_code=ErrorCodes.RESOURCE_NOT_FOUND,\n-            detail=\"POS session not found\"\n-        )\n-    \n-    # Validate restaurant access\n-    await TenantSecurity.validate_restaurant_access(\n-        current_user, \n-        str(session.restaurant_id), \n-        db=db\n-    )\n-    \n+            error_code=ErrorCodes.RESOURCE_NOT_FOUND, detail=\"POS session not found\"\n+        )\n+\n+    # Validate restaurant access\n+    await TenantSecurity.validate_restaurant_access(\n+        current_user, str(session.restaurant_id), db=db\n+    )\n+\n     # Check if user owns this session\n     if session.user_id != current_user.id:\n         raise FynloException(\n             error_code=ErrorCodes.FORBIDDEN,\n-            detail=\"Not authorized to modify this session\"\n-        )\n-    \n+            detail=\"Not authorized to modify this session\",\n+        )\n+\n     # Validate state transition\n     valid_states = [\"opening_control\", \"opened\", \"closing_control\", \"closed\"]\n     if state not in valid_states:\n         raise FynloException(\n             error_code=ErrorCodes.VALIDATION_ERROR,\n-            detail=f\"Invalid state. Must be one of: {valid_states}\"\n-        )\n-    \n+            detail=f\"Invalid state. Must be one of: {valid_states}\",\n+        )\n+\n     session.state = state\n     session.updated_at = datetime.utcnow()\n-    \n+\n     if state == \"closed\":\n         session.stop_at = datetime.utcnow()\n         session.is_active = False\n-    \n+\n     db.commit()\n     db.refresh(session)\n-    \n+\n     response_data = {\n         \"id\": str(session.id),\n         \"name\": session.name,\n         \"state\": session.state,\n         \"start_at\": session.start_at.isoformat(),\n         \"stop_at\": session.stop_at.isoformat() if session.stop_at else None,\n         \"config_id\": session.config_id,\n         \"config_name\": session.config_name,\n         \"user_id\": str(session.user_id),\n-        \"user_name\": f\"{current_user.first_name} {current_user.last_name}\"\n+        \"user_name\": f\"{current_user.first_name} {current_user.last_name}\",\n     }\n-    \n-    return APIResponseHelper.success(\n-        data=response_data,\n-        message=f\"POS session state updated to {state}\"\n-    )\n+\n+    return APIResponseHelper.success(\n+        data=response_data, message=f\"POS session state updated to {state}\"\n+    )\n+\n \n @router.get(\"/sessions\")\n async def get_sessions(\n     limit: int = 10,\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Specific restaurant ID for multi-restaurant users\"),\n-    current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Specific restaurant ID for multi-restaurant users\"\n+    ),\n+    current_user: User = Depends(get_current_user),\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Get POS sessions for the current user\"\"\"\n-    \n-    # Validate restaurant access\n-    await TenantSecurity.validate_restaurant_access(\n-        current_user, \n-        current_restaurant_id or current_user.restaurant_id, \n-        db=db\n+\n+    # Validate restaurant access\n+    await TenantSecurity.validate_restaurant_access(\n+        current_user, current_restaurant_id or current_user.restaurant_id, db=db\n     )\n     # Use the provided restaurant_id or fall back to user's default\n     restaurant_id = current_restaurant_id or current_user.restaurant_id\n-    \n-    sessions = db.query(PosSession).filter(\n-        and_(\n-            PosSession.user_id == current_user.id,\n-            PosSession.restaurant_id == restaurant_id\n-        )\n-    ).order_by(PosSession.start_at.desc()).limit(limit).all()\n-    \n+\n+    sessions = (\n+        db.query(PosSession)\n+        .filter(\n+            and_(\n+                PosSession.user_id == current_user.id,\n+                PosSession.restaurant_id == restaurant_id,\n+            )\n+        )\n+        .order_by(PosSession.start_at.desc())\n+        .limit(limit)\n+        .all()\n+    )\n+\n     sessions_data = []\n     for session in sessions:\n-        sessions_data.append({\n-            \"id\": str(session.id),\n-            \"name\": session.name,\n-            \"state\": session.state,\n-            \"start_at\": session.start_at.isoformat(),\n-            \"stop_at\": session.stop_at.isoformat() if session.stop_at else None,\n-            \"config_id\": session.config_id,\n-            \"config_name\": session.config_name,\n-            \"user_id\": str(session.user_id),\n-            \"user_name\": f\"{current_user.first_name} {current_user.last_name}\"\n-        })\n-    \n+        sessions_data.append(\n+            {\n+                \"id\": str(session.id),\n+                \"name\": session.name,\n+                \"state\": session.state,\n+                \"start_at\": session.start_at.isoformat(),\n+                \"stop_at\": session.stop_at.isoformat() if session.stop_at else None,\n+                \"config_id\": session.config_id,\n+                \"config_name\": session.config_name,\n+                \"user_id\": str(session.user_id),\n+                \"user_name\": f\"{current_user.first_name} {current_user.last_name}\",\n+            }\n+        )\n+\n     return APIResponseHelper.success(\n         data=sessions_data,\n         message=f\"Retrieved {len(sessions_data)} POS sessions\",\n-        meta={\n-            \"total\": len(sessions_data),\n-            \"limit\": limit\n-        }\n-    )\n\\ No newline at end of file\n+        meta={\"total\": len(sessions_data), \"limit\": limit},\n+    )\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/public_menu.py\t2025-08-02 21:56:58.988704+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/public_menu.py\t2025-08-02 22:36:02.850282+00:00\n@@ -3,11 +3,11 @@\n These endpoints don't require authentication to allow menu loading before login\n \"\"\"\n \n from typing import Optional\n from pydantic import BaseModel\n-from fastapi import APIRouter, Depends, Query \n+from fastapi import APIRouter, Depends, Query\n from sqlalchemy.orm import Session\n from sqlalchemy import and_\n import time\n import logging\n \n@@ -16,189 +16,213 @@\n from app.core.responses import APIResponseHelper\n \n router = APIRouter()\n logger = logging.getLogger(__name__)\n \n+\n def format_menu_item(product, category_name=None):\n     \"\"\"Format product as menu item with required fields\"\"\"\n     # Map category names to emojis\n     emoji_map = {\n-        'Tacos': '\ud83c\udf2e',\n-        'Snacks': '\ud83c\udf2e',\n-        'Appetizers': '\ud83e\udd57',\n-        'Beverages': '\ud83e\udd64',\n-        'Desserts': '\ud83c\udf70',\n-        'Main Courses': '\ud83c\udf7d\ufe0f',\n-        'Sides': '\ud83c\udf5f',\n-        'Breakfast': '\ud83c\udf73',\n-        'Salads': '\ud83e\udd57',\n-        'Soups': '\ud83c\udf72',\n-        'Drinks': '\ud83e\udd64',\n-        'Alcohol': '\ud83c\udf7a',\n-        'Coffee': '\u2615',\n-        'Tea': '\ud83c\udf75',\n+        \"Tacos\": \"\ud83c\udf2e\",\n+        \"Snacks\": \"\ud83c\udf2e\",\n+        \"Appetizers\": \"\ud83e\udd57\",\n+        \"Beverages\": \"\ud83e\udd64\",\n+        \"Desserts\": \"\ud83c\udf70\",\n+        \"Main Courses\": \"\ud83c\udf7d\ufe0f\",\n+        \"Sides\": \"\ud83c\udf5f\",\n+        \"Breakfast\": \"\ud83c\udf73\",\n+        \"Salads\": \"\ud83e\udd57\",\n+        \"Soups\": \"\ud83c\udf72\",\n+        \"Drinks\": \"\ud83e\udd64\",\n+        \"Alcohol\": \"\ud83c\udf7a\",\n+        \"Coffee\": \"\u2615\",\n+        \"Tea\": \"\ud83c\udf75\",\n     }\n-    \n+\n     # Get emoji based on category or use default\n-    emoji = emoji_map.get(category_name, '\ud83c\udf7d\ufe0f')\n-    \n+    emoji = emoji_map.get(category_name, \"\ud83c\udf7d\ufe0f\")\n+\n     return {\n-        'id': str(product.id),  # Convert UUID to string\n-        'name': product.name,\n-        'price': str(product.price),  # Convert to string for precision\n-        'emoji': emoji,\n-        'available': product.is_active if hasattr(product, 'is_active') else True,\n-        'category': category_name or 'Uncategorized',\n-        'description': product.description or '',\n-        'icon': 'restaurant',  # Default icon for compatibility\n-        'category_id': str(product.category_id) if hasattr(product, 'category_id') and product.category_id else None  # Convert UUID to string\n+        \"id\": str(product.id),  # Convert UUID to string\n+        \"name\": product.name,\n+        \"price\": str(product.price),  # Convert to string for precision\n+        \"emoji\": emoji,\n+        \"available\": product.is_active if hasattr(product, \"is_active\") else True,\n+        \"category\": category_name or \"Uncategorized\",\n+        \"description\": product.description or \"\",\n+        \"icon\": \"restaurant\",  # Default icon for compatibility\n+        \"category_id\": (\n+            str(product.category_id)\n+            if hasattr(product, \"category_id\") and product.category_id\n+            else None\n+        ),  # Convert UUID to string\n     }\n+\n \n @router.get(\"/items\")\n async def get_public_menu_items(\n-    restaurant_id: Optional[str] = Query(None, description=\"Restaurant ID (optional for multi-tenant)\"),\n+    restaurant_id: Optional[str] = Query(\n+        None, description=\"Restaurant ID (optional for multi-tenant)\"\n+    ),\n     category: Optional[str] = Query(None, description=\"Filter by category name\"),\n     db: Session = Depends(get_db),\n-    redis: RedisClient = Depends(get_redis)\n+    redis: RedisClient = Depends(get_redis),\n ):\n     \"\"\"\n     Get menu items without authentication requirement.\n     This allows menu to be loaded on POS screen before login.\n     \"\"\"\n     start_time = time.time()\n-    \n+\n     try:\n         # Try to get from cache first\n-        cache_key = f\"public_menu:items:{restaurant_id or 'default'}:{category or 'all'}\"\n-        \n+        cache_key = (\n+            f\"public_menu:items:{restaurant_id or 'default'}:{category or 'all'}\"\n+        )\n+\n         if redis:\n             try:\n                 cached_data = await redis.get(cache_key)\n                 if cached_data:\n-                    logger.info(f\"Returning cached public menu items for key: {cache_key}\")\n+                    logger.info(\n+                        f\"Returning cached public menu items for key: {cache_key}\"\n+                    )\n                     return APIResponseHelper.success(\n-                        data=cached_data,\n-                        message=\"Menu items retrieved from cache\"\n+                        data=cached_data, message=\"Menu items retrieved from cache\"\n                     )\n             except Exception as e:\n                 logger.warning(f\"Redis cache error: {e}\")\n-        \n+\n         # Build query\n         query = db.query(Product).filter(Product.is_active == True)\n-        \n+\n         # Filter by category if provided\n         if category:\n-            category_obj = db.query(Category).filter(\n-                Category.name == category,\n-                Category.is_active == True\n-            ).first()\n-            \n+            category_obj = (\n+                db.query(Category)\n+                .filter(Category.name == category, Category.is_active == True)\n+                .first()\n+            )\n+\n             if category_obj:\n                 query = query.filter(Product.category_id == category_obj.id)\n-        \n+\n         # Get all products\n         products = query.order_by(Product.category_id, Product.name).all()\n-        \n+\n         # Format menu items with category names\n         menu_items = []\n         for product in products:\n             category_name = None\n             if product.category_id:\n-                category_obj = db.query(Category).filter(Category.id == product.category_id).first()\n+                category_obj = (\n+                    db.query(Category)\n+                    .filter(Category.id == product.category_id)\n+                    .first()\n+                )\n                 if category_obj:\n                     category_name = category_obj.name\n-            \n+\n             menu_items.append(format_menu_item(product, category_name))\n-        \n+\n         # Cache the result\n         if redis and menu_items:\n             try:\n                 await redis.set(cache_key, menu_items, expire=300)  # 5 minute cache\n             except Exception as e:\n                 logger.warning(f\"Failed to cache public menu items: {e}\")\n-        \n+\n         elapsed_time = time.time() - start_time\n-        logger.info(f\"Public menu items retrieved in {elapsed_time:.3f}s - {len(menu_items)} items\")\n-        \n+        logger.info(\n+            f\"Public menu items retrieved in {elapsed_time:.3f}s - {len(menu_items)} items\"\n+        )\n+\n         return APIResponseHelper.success(\n             data=menu_items,\n-            message=f\"Successfully retrieved {len(menu_items)} menu items\"\n-        )\n-        \n+            message=f\"Successfully retrieved {len(menu_items)} menu items\",\n+        )\n+\n     except Exception as e:\n         logger.error(f\"Error retrieving public menu items: {str(e)}\")\n         return APIResponseHelper.error(\n-            message=\"Failed to retrieve menu items\",\n-            status_code=500\n-        )\n+            message=\"Failed to retrieve menu items\", status_code=500\n+        )\n+\n \n @router.get(\"/categories\")\n async def get_public_menu_categories(\n     restaurant_id: Optional[str] = Query(None),\n     db: Session = Depends(get_db),\n-    redis: RedisClient = Depends(get_redis)\n+    redis: RedisClient = Depends(get_redis),\n ):\n     \"\"\"\n     Get menu categories without authentication requirement.\n     This allows menu categories to be loaded on POS screen before login.\n     \"\"\"\n     start_time = time.time()\n-    \n+\n     try:\n         # Try to get from cache first\n         cache_key = f\"public_menu:categories:{restaurant_id or 'default'}\"\n-        \n+\n         if redis:\n             try:\n                 cached_data = await redis.get(cache_key)\n                 if cached_data:\n                     logger.info(f\"Returning cached public menu categories\")\n                     return APIResponseHelper.success(\n-                        data=cached_data,\n-                        message=\"Menu categories retrieved from cache\"\n+                        data=cached_data, message=\"Menu categories retrieved from cache\"\n                     )\n             except Exception as e:\n                 logger.warning(f\"Redis cache error: {e}\")\n-        \n+\n         # Get all active categories\n-        categories = db.query(Category).filter(\n-            Category.is_active == True\n-        ).order_by(Category.sort_order, Category.name).all()\n-        \n+        categories = (\n+            db.query(Category)\n+            .filter(Category.is_active == True)\n+            .order_by(Category.sort_order, Category.name)\n+            .all()\n+        )\n+\n         # Format categories\n         category_list = []\n         for cat in categories:\n             # Count products in category\n-            product_count = db.query(Product).filter(\n-                Product.category_id == cat.id,\n-                Product.is_active == True\n-            ).count()\n-            \n-            category_list.append({\n-                'id': str(cat.id),  # Convert UUID to string\n-                'name': cat.name,\n-                'description': cat.description,\n-                'active': cat.is_active,\n-                'product_count': product_count\n-            })\n-        \n+            product_count = (\n+                db.query(Product)\n+                .filter(Product.category_id == cat.id, Product.is_active == True)\n+                .count()\n+            )\n+\n+            category_list.append(\n+                {\n+                    \"id\": str(cat.id),  # Convert UUID to string\n+                    \"name\": cat.name,\n+                    \"description\": cat.description,\n+                    \"active\": cat.is_active,\n+                    \"product_count\": product_count,\n+                }\n+            )\n+\n         # Cache the result\n         if redis and category_list:\n             try:\n                 await redis.set(cache_key, category_list, expire=300)  # 5 minute cache\n             except Exception as e:\n                 logger.warning(f\"Failed to cache public menu categories: {e}\")\n-        \n+\n         elapsed_time = time.time() - start_time\n-        logger.info(f\"Public menu categories retrieved in {elapsed_time:.3f}s - {len(category_list)} categories\")\n-        \n+        logger.info(\n+            f\"Public menu categories retrieved in {elapsed_time:.3f}s - {len(category_list)} categories\"\n+        )\n+\n         return APIResponseHelper.success(\n             data=category_list,\n-            message=f\"Successfully retrieved {len(category_list)} menu categories\"\n-        )\n-        \n+            message=f\"Successfully retrieved {len(category_list)} menu categories\",\n+        )\n+\n     except Exception as e:\n         logger.error(f\"Error retrieving public menu categories: {str(e)}\")\n         return APIResponseHelper.error(\n-            message=\"Failed to retrieve menu categories\",\n-            status_code=500\n-        )\n\\ No newline at end of file\n+            message=\"Failed to retrieve menu categories\", status_code=500\n+        )\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/recipes.py\t2025-08-02 21:56:58.988879+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/recipes.py\t2025-08-02 22:36:02.854051+00:00\n@@ -1,75 +1,91 @@\n \"\"\"\n API Endpoints for Recipe Management\n \"\"\"\n+\n from fastapi import APIRouter, Depends, Query\n from pydantic import BaseModel\n from sqlalchemy.orm import Session\n from typing import List\n from uuid import UUID\n \n-from app.core.database import get_db, Product # Import Product model\n+from app.core.database import get_db, Product  # Import Product model\n from app.core.exceptions import ResourceNotFoundException, ValidationException\n-from app.core.database import User # Assuming User model for authentication/authorization\n-from app.crud import inventory as crud_inventory # Using the same CRUD module\n-from app.schemas import inventory_schemas as schemas # Using the same schemas module\n+from app.core.database import (\n+    User,\n+)  # Assuming User model for authentication/authorization\n+from app.crud import inventory as crud_inventory  # Using the same CRUD module\n+from app.schemas import inventory_schemas as schemas  # Using the same schemas module\n from app.core.dependencies import get_current_user\n from app.core.tenant_security import TenantSecurity\n \n router = APIRouter()\n \n # --- Recipe Endpoints ---\n \n-@router.post(\"/\", response_model=List[schemas.Recipe], status_code=201) # Returns list of created recipe ingredients\n+\n+@router.post(\n+    \"/\", response_model=List[schemas.Recipe], status_code=201\n+)  # Returns list of created recipe ingredients\n async def create_or_update_recipe_for_item_api(\n     recipe_in: schemas.RecipeCreate,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"\n     Create or update the full recipe for a specific menu item (Product).\n     - If the item has no recipe, it's created.\n     - If the item has an existing recipe, it's entirely replaced by the ingredients provided.\n     - If an empty list of ingredients is provided for an existing recipe, it effectively deletes the recipe.\n     \"\"\"\n     # Use current user's restaurant\n     restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n     if not restaurant_id:\n-        raise ValidationException(message=\"User must be assigned to a restaurant\", field=\"user\")\n-    \n+        raise ValidationException(\n+            message=\"User must be assigned to a restaurant\", field=\"user\"\n+        )\n+\n     # Check if product (item_id) exists for this restaurant\n-    product = db.query(Product).filter(\n-        Product.id == recipe_in.item_id,\n-        Product.restaurant_id == restaurant_id\n-    ).first()\n+    product = (\n+        db.query(Product)\n+        .filter(Product.id == recipe_in.item_id, Product.restaurant_id == restaurant_id)\n+        .first()\n+    )\n     if not product:\n-        raise ResourceNotFoundException(resource=\"Resource\", message=f\"Product with ID {recipe_in.item_id} not found.\")\n-    \n+        raise ResourceNotFoundException(\n+            resource=\"Resource\",\n+            message=f\"Product with ID {recipe_in.item_id} not found.\",\n+        )\n+\n     # Verify tenant access\n     await TenantSecurity.validate_restaurant_access(\n         user=current_user,\n         restaurant_id=str(restaurant_id),\n         operation=\"modify\",\n         resource_type=\"recipe\",\n         resource_id=str(recipe_in.item_id),\n-        db=db\n+        db=db,\n     )\n \n     # Validate that all ingredient SKUs exist in inventory for this restaurant\n     for ingredient in recipe_in.ingredients:\n-        inv_item = crud_inventory.get_inventory_item(db, sku=ingredient.ingredient_sku, restaurant_id=restaurant_id)\n+        inv_item = crud_inventory.get_inventory_item(\n+            db, sku=ingredient.ingredient_sku, restaurant_id=restaurant_id\n+        )\n         if not inv_item:\n-            raise ValidationException(message=f\"Ingredient with SKU {ingredient.ingredient_sku} not found in inventory.\")\n+            raise ValidationException(\n+                message=f\"Ingredient with SKU {ingredient.ingredient_sku} not found in inventory.\"\n+            )\n         # qty_g validation (gt=0, le=1000) is handled by Pydantic schema (RecipeIngredientCreate)\n \n     # The CRUD function `create_or_update_recipe_ingredients` handles upsert logic\n     # and deletion of ingredients not present in the new list.\n     db_recipe_ingredients = crud_inventory.create_or_update_recipe_ingredients(\n         db=db,\n         item_id=recipe_in.item_id,\n         ingredients_data=recipe_in.ingredients,\n-        restaurant_id=restaurant_id\n+        restaurant_id=restaurant_id,\n     )\n \n     if not recipe_in.ingredients and db_recipe_ingredients:\n         # This case should ideally be handled by the CRUD to ensure consistency\n         # For now, if input is empty and output is not, it implies something went wrong or was not fully cleared.\n@@ -77,112 +93,130 @@\n         pass\n \n     return db_recipe_ingredients\n \n \n-@router.get(\"/{item_id}\", response_model=schemas.RecipeResponse) # Using the RecipeResponse model\n+@router.get(\n+    \"/{item_id}\", response_model=schemas.RecipeResponse\n+)  # Using the RecipeResponse model\n async def read_recipe_for_item_api(\n     item_id: UUID,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"\n     Retrieve the recipe for a specific menu item, including ingredient details.\n     \"\"\"\n     # Use current user's restaurant\n     restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n     if not restaurant_id:\n-        raise ValidationException(message=\"User must be assigned to a restaurant\", field=\"user\")\n-    \n-    recipe_details = crud_inventory.get_product_details_with_recipe(db, item_id=item_id, restaurant_id=restaurant_id)\n+        raise ValidationException(\n+            message=\"User must be assigned to a restaurant\", field=\"user\"\n+        )\n+\n+    recipe_details = crud_inventory.get_product_details_with_recipe(\n+        db, item_id=item_id, restaurant_id=restaurant_id\n+    )\n     if not recipe_details:\n         # Check if product exists but has no recipe vs product does not exist\n-        product = db.query(Product).filter(\n-            Product.id == item_id,\n-            Product.restaurant_id == restaurant_id\n-        ).first()\n+        product = (\n+            db.query(Product)\n+            .filter(Product.id == item_id, Product.restaurant_id == restaurant_id)\n+            .first()\n+        )\n         if not product:\n-            raise ResourceNotFoundException(resource=\"Resource\", message=f\"Product with ID {item_id} not found.\")\n-        \n+            raise ResourceNotFoundException(\n+                resource=\"Resource\", message=f\"Product with ID {item_id} not found.\"\n+            )\n+\n         # Verify tenant access\n         await TenantSecurity.validate_restaurant_access(\n             user=current_user,\n             restaurant_id=str(restaurant_id),\n             operation=\"access\",\n             resource_type=\"recipe\",\n             resource_id=str(item_id),\n-            db=db\n-        )\n-        \n+            db=db,\n+        )\n+\n         # Product exists but has no recipe, return empty list of ingredients\n-        return schemas.RecipeResponse(item_id=item_id, item_name=product.name, ingredients=[])\n+        return schemas.RecipeResponse(\n+            item_id=item_id, item_name=product.name, ingredients=[]\n+        )\n \n     return schemas.RecipeResponse(**recipe_details)\n \n \n @router.get(\"/\", response_model=List[schemas.RecipeResponse])\n async def read_all_recipes_api(\n     skip: int = 0,\n     limit: int = Query(default=100, le=200),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"\n     Retrieve all products that have recipes, along with their recipe details.\n     \"\"\"\n     # Use current user's restaurant\n     restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n     if not restaurant_id:\n-        raise ValidationException(message=\"User must be assigned to a restaurant\", field=\"user\")\n-    \n+        raise ValidationException(\n+            message=\"User must be assigned to a restaurant\", field=\"user\"\n+        )\n+\n     all_recipes_details = crud_inventory.get_all_products_with_recipes(\n-        db,\n-        restaurant_id=restaurant_id,\n-        skip=skip,\n-        limit=limit\n+        db, restaurant_id=restaurant_id, skip=skip, limit=limit\n     )\n     return [schemas.RecipeResponse(**details) for details in all_recipes_details]\n \n \n-@router.delete(\"/{item_id}\", status_code=204) # No content to return\n+@router.delete(\"/{item_id}\", status_code=204)  # No content to return\n async def delete_recipe_for_item_api(\n     item_id: UUID,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"\n     Delete the entire recipe for a specific menu item.\n     \"\"\"\n     # Use current user's restaurant\n     restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n     if not restaurant_id:\n-        raise ValidationException(message=\"User must be assigned to a restaurant\", field=\"user\")\n-    \n+        raise ValidationException(\n+            message=\"User must be assigned to a restaurant\", field=\"user\"\n+        )\n+\n     # Check if product exists first\n-    product = db.query(Product).filter(\n-        Product.id == item_id,\n-        Product.restaurant_id == restaurant_id\n-    ).first()\n+    product = (\n+        db.query(Product)\n+        .filter(Product.id == item_id, Product.restaurant_id == restaurant_id)\n+        .first()\n+    )\n     if not product:\n-        raise ResourceNotFoundException(resource=\"Resource\", message=f\"Product with ID {item_id} not found, cannot delete its recipe.\")\n-    \n+        raise ResourceNotFoundException(\n+            resource=\"Resource\",\n+            message=f\"Product with ID {item_id} not found, cannot delete its recipe.\",\n+        )\n+\n     # Verify tenant access - require owner/manager role for deletion\n     await TenantSecurity.validate_restaurant_access(\n         user=current_user,\n         restaurant_id=str(restaurant_id),\n         operation=\"delete\",\n         resource_type=\"recipe\",\n         resource_id=str(item_id),\n-        db=db\n-    )\n-\n-    deleted_count = crud_inventory.delete_recipe_for_item(db, item_id=item_id, restaurant_id=restaurant_id)\n+        db=db,\n+    )\n+\n+    deleted_count = crud_inventory.delete_recipe_for_item(\n+        db, item_id=item_id, restaurant_id=restaurant_id\n+    )\n     if deleted_count == 0:\n         # Product exists, but had no recipe to delete. Not an error, but could be a specific response.\n         # For 204, no response body is sent, so client just knows it's gone or was never there.\n         pass\n-    return None # FastAPI will return 204 No Content\n+    return None  # FastAPI will return 204 No Content\n \n \n # Placeholder for role-based authentication dependency\n # async def get_current_active_user_with_role(required_role: str):\n #     # from app.api.v1.dependencies import get_current_active_user\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/platform_settings.py\t2025-08-02 21:56:58.987777+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/platform_settings.py\t2025-08-02 22:36:02.862709+00:00\n@@ -1,527 +1,591 @@\n \"\"\"\n Platform Settings API Endpoints\n Admin-only endpoints for managing platform-wide configurations\n \"\"\"\n-from datetime import datetime # Added missing import\n+\n+from datetime import datetime  # Added missing import\n from typing import Dict, Any, Optional, List\n from fastapi import APIRouter, Depends, Query, Request\n-import logging # Added for logging in new endpoints\n+import logging  # Added for logging in new endpoints\n from sqlalchemy.orm import Session\n from pydantic import BaseModel, Field\n \n from app.core.database import get_db, User\n from app.core.exceptions import (\n     FynloException,\n     PaymentException,\n     ResourceNotFoundException,\n-    ValidationException\n+    ValidationException,\n )\n from app.core.auth import get_current_user\n from app.core.responses import APIResponseHelper\n from app.services.platform_service import PlatformSettingsService\n \n router = APIRouter()\n \n+\n # Pydantic models for requests/responses\n class PlatformSettingRequest(BaseModel):\n     config_value: Any\n     change_reason: Optional[str] = None\n \n+\n class RestaurantOverrideRequest(BaseModel):\n     override_value: Any\n     requires_approval: bool = False\n+\n \n class FeatureFlagRequest(BaseModel):\n     is_enabled: bool\n     rollout_percentage: Optional[float] = Field(None, ge=0.0, le=100.0)\n     target_restaurants: Optional[List[str]] = None\n \n+\n class BulkUpdateRequest(BaseModel):\n     updates: Dict[str, Any]\n     change_reason: Optional[str] = None\n+\n \n class ServiceChargeConfigRequest(BaseModel):\n     enabled: bool\n     rate: float = Field(..., ge=0, le=100)\n     description: str = Field(..., max_length=255)\n-    currency: str # Should ideally be an Enum, e.g., Literal['GBP', 'USD', 'EUR']\n+    currency: str  # Should ideally be an Enum, e.g., Literal['GBP', 'USD', 'EUR']\n+\n \n class ServiceChargeConfigResponse(BaseModel):\n     service_charge: ServiceChargeConfigRequest\n \n+\n def require_admin_user(current_user: User = Depends(get_current_user)) -> User:\n     \"\"\"Ensure user has admin privileges for platform settings\"\"\"\n-        # For now, check if user has admin role or specific permissions\n-    if not hasattr(current_user, 'is_admin') or not current_user.is_admin:\n+    # For now, check if user has admin role or specific permissions\n+    if not hasattr(current_user, \"is_admin\") or not current_user.is_admin:\n         raise FynloException(message=\"Admin privileges required for platform settings\")\n     return current_user\n+\n \n @router.get(\"/settings\")\n async def get_platform_settings(\n     category: Optional[str] = Query(None, description=\"Filter by category\"),\n     include_sensitive: bool = Query(False, description=\"Include sensitive settings\"),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(require_admin_user)\n+    current_user: User = Depends(require_admin_user),\n ):\n     \"\"\"Get all platform settings (admin only)\"\"\"\n     try:\n         service = PlatformSettingsService(db)\n         settings = await service.get_platform_settings(\n-            category=category,\n-            include_sensitive=include_sensitive\n-        )\n-        \n-        return APIResponseHelper.success(\n-            data=settings,\n-            message=f\"Retrieved {len(settings)} platform settings\"\n-        )\n-        \n-    except Exception as e:\n-        raise FynloException(message=\"An error occurred processing the request\", status_code=500)\n+            category=category, include_sensitive=include_sensitive\n+        )\n+\n+        return APIResponseHelper.success(\n+            data=settings, message=f\"Retrieved {len(settings)} platform settings\"\n+        )\n+\n+    except Exception as e:\n+        raise FynloException(\n+            message=\"An error occurred processing the request\", status_code=500\n+        )\n+\n \n # Service Charge Specific Endpoints\n @router.get(\n     \"/service-charge\",\n     response_model=ServiceChargeConfigResponse,\n     summary=\"Get service charge configuration\",\n-    tags=[\"Platform Settings\", \"Service Charge\"]\n+    tags=[\"Platform Settings\", \"Service Charge\"],\n )\n async def get_service_charge_configuration(\n-    db: Session = Depends(get_db),\n-    current_user: User = Depends(require_admin_user)\n+    db: Session = Depends(get_db), current_user: User = Depends(require_admin_user)\n ):\n     \"\"\"Retrieve the current platform service charge configuration.\"\"\"\n     try:\n         service = PlatformSettingsService(db)\n         config = await service.get_service_charge_config()\n-        return config # FastAPI will wrap this in the response_model\n-    except Exception as e:\n-        logging.error(f\"Error retrieving service charge configuration: {e}\", exc_info=True)\n-        raise PaymentException(message=\"Failed to retrieve service charge configuration\")\n+        return config  # FastAPI will wrap this in the response_model\n+    except Exception as e:\n+        logging.error(\n+            f\"Error retrieving service charge configuration: {e}\", exc_info=True\n+        )\n+        raise PaymentException(\n+            message=\"Failed to retrieve service charge configuration\"\n+        )\n+\n \n @router.put(\n     \"/service-charge\",\n     response_model=ServiceChargeConfigResponse,\n     summary=\"Update service charge configuration\",\n-    tags=[\"Platform Settings\", \"Service Charge\"]\n+    tags=[\"Platform Settings\", \"Service Charge\"],\n )\n async def update_service_charge_configuration(\n     request: ServiceChargeConfigRequest,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(require_admin_user)\n+    current_user: User = Depends(require_admin_user),\n ):\n     \"\"\"Update the platform service charge configuration.\"\"\"\n     try:\n         service = PlatformSettingsService(db)\n         # The service method expects a dictionary, so we convert the Pydantic model\n         success = await service.update_service_charge_config(\n             config_data=request.dict(),\n-            updated_by=str(current_user.id) # Assuming user ID is a UUID or string\n+            updated_by=str(current_user.id),  # Assuming user ID is a UUID or string\n         )\n         if not success:\n             # This case might be tricky if partial updates occurred.\n             # The service method tries to update all and returns True if all succeed.\n             # If it returns False, it implies one or more updates failed but didn't raise an exception (e.g. key not found).\n-            raise PaymentException(message=\"Failed to update some service charge settings\")\n+            raise PaymentException(\n+                message=\"Failed to update some service charge settings\"\n+            )\n \n         # Fetch the updated configuration to return\n         updated_config = await service.get_service_charge_config()\n         return updated_config\n-    except ValueError as e: # Catch validation errors from the service layer\n+    except ValueError as e:  # Catch validation errors from the service layer\n         raise ValidationException(message=\"An error occurred processing the request\")\n     except Exception as e:\n-        logging.error(f\"Error updating service charge configuration: {e}\", exc_info=True)\n+        logging.error(\n+            f\"Error updating service charge configuration: {e}\", exc_info=True\n+        )\n         raise PaymentException(message=\"Failed to update service charge configuration\")\n+\n \n @router.get(\"/settings/{config_key}\")\n async def get_platform_setting(\n     config_key: str,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(require_admin_user)\n+    current_user: User = Depends(require_admin_user),\n ):\n     \"\"\"Get a specific platform setting by key\"\"\"\n     try:\n         service = PlatformSettingsService(db)\n         setting = await service.get_platform_setting(config_key)\n-        \n+\n         if not setting:\n-            raise ResourceNotFoundException(resource=\"Resource\", message=f\"Platform setting \")\n-        \n-        return APIResponseHelper.success(\n-            data=setting,\n-            message=f\"Retrieved platform setting '{config_key}'\"\n-        )\n-        \n+            raise ResourceNotFoundException(\n+                resource=\"Resource\", message=f\"Platform setting \"\n+            )\n+\n+        return APIResponseHelper.success(\n+            data=setting, message=f\"Retrieved platform setting '{config_key}'\"\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n-        raise FynloException(message=\"An error occurred processing the request\", status_code=500)\n+        raise FynloException(\n+            message=\"An error occurred processing the request\", status_code=500\n+        )\n+\n \n @router.put(\"/settings/{config_key}\")\n async def update_platform_setting(\n     config_key: str,\n     request: PlatformSettingRequest,\n     db: Session = Depends(get_db),\n     current_user: User = Depends(require_admin_user),\n-    http_request: Request = None\n+    http_request: Request = None,\n ):\n     \"\"\"Update a platform setting (admin only)\"\"\"\n     try:\n         service = PlatformSettingsService(db)\n-        \n+\n         success = await service.update_platform_setting(\n             config_key=config_key,\n             config_value=request.config_value,\n             updated_by=str(current_user.id),\n             change_reason=request.change_reason,\n-            change_source=\"admin_api\"\n-        )\n-        \n+            change_source=\"admin_api\",\n+        )\n+\n         if not success:\n-            raise ResourceNotFoundException(resource=\"Resource\", message=f\"Platform setting \")\n-        \n+            raise ResourceNotFoundException(\n+                resource=\"Resource\", message=f\"Platform setting \"\n+            )\n+\n         # Log the change for audit\n         if http_request:\n             # Create audit record with IP and user agent\n             pass  # Already handled in service\n-        \n-        return APIResponseHelper.success(\n-            data={'config_key': config_key, 'updated': True},\n-            message=f\"Platform setting '{config_key}' updated successfully\"\n-        )\n-        \n+\n+        return APIResponseHelper.success(\n+            data={\"config_key\": config_key, \"updated\": True},\n+            message=f\"Platform setting '{config_key}' updated successfully\",\n+        )\n+\n     except ValueError as e:\n         raise ValidationException(message=\"An error occurred processing the request\")\n     except FynloException:\n         raise\n     except Exception as e:\n-        raise FynloException(message=\"An error occurred processing the request\", status_code=500)\n+        raise FynloException(\n+            message=\"An error occurred processing the request\", status_code=500\n+        )\n+\n \n @router.post(\"/settings/bulk-update\")\n async def bulk_update_platform_settings(\n     request: BulkUpdateRequest,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(require_admin_user)\n+    current_user: User = Depends(require_admin_user),\n ):\n     \"\"\"Bulk update multiple platform settings\"\"\"\n     try:\n         service = PlatformSettingsService(db)\n-        \n+\n         results = {}\n         errors = {}\n-        \n+\n         for config_key, config_value in request.updates.items():\n             try:\n                 success = await service.update_platform_setting(\n                     config_key=config_key,\n                     config_value=config_value,\n                     updated_by=str(current_user.id),\n                     change_reason=request.change_reason,\n-                    change_source=\"admin_bulk_api\"\n+                    change_source=\"admin_bulk_api\",\n                 )\n                 results[config_key] = success\n             except Exception as e:\n                 errors[config_key] = str(e)\n-        \n+\n         response_data = {\n-            'successful_updates': len([k for k, v in results.items() if v]),\n-            'failed_updates': len(errors),\n-            'results': results,\n-            'errors': errors\n+            \"successful_updates\": len([k for k, v in results.items() if v]),\n+            \"failed_updates\": len(errors),\n+            \"results\": results,\n+            \"errors\": errors,\n         }\n-        \n+\n         if errors:\n             return APIResponseHelper.success(\n                 data=response_data,\n-                message=f\"Bulk update completed with {len(errors)} errors\"\n+                message=f\"Bulk update completed with {len(errors)} errors\",\n             )\n         else:\n             return APIResponseHelper.success(\n                 data=response_data,\n-                message=f\"Successfully updated {len(results)} platform settings\"\n-            )\n-        \n-    except Exception as e:\n-        raise FynloException(message=\"An error occurred processing the request\", status_code=500)\n+                message=f\"Successfully updated {len(results)} platform settings\",\n+            )\n+\n+    except Exception as e:\n+        raise FynloException(\n+            message=\"An error occurred processing the request\", status_code=500\n+        )\n+\n \n @router.get(\"/payment-fees\")\n async def get_payment_fees(\n-    db: Session = Depends(get_db),\n-    current_user: User = Depends(require_admin_user)\n+    db: Session = Depends(get_db), current_user: User = Depends(require_admin_user)\n ):\n     \"\"\"Get all payment processing fees\"\"\"\n     try:\n         service = PlatformSettingsService(db)\n         fees = await service.get_payment_fees()\n-        \n-        return APIResponseHelper.success(\n-            data=fees,\n-            message=\"Retrieved payment processing fees\"\n-        )\n-        \n-    except Exception as e:\n-        raise FynloException(message=\"An error occurred processing the request\", status_code=500)\n+\n+        return APIResponseHelper.success(\n+            data=fees, message=\"Retrieved payment processing fees\"\n+        )\n+\n+    except Exception as e:\n+        raise FynloException(\n+            message=\"An error occurred processing the request\", status_code=500\n+        )\n+\n \n @router.post(\"/payment-fees/calculate\")\n async def calculate_payment_fee(\n     payment_method: str,\n     amount: float = Query(..., description=\"Transaction amount\"),\n-    restaurant_id: Optional[str] = Query(None, description=\"Restaurant ID for overrides\"),\n-    monthly_volume: Optional[float] = Query(None, description=\"Monthly volume for volume-based pricing\"),\n-    db: Session = Depends(get_db),\n-    current_user: User = Depends(require_admin_user)\n+    restaurant_id: Optional[str] = Query(\n+        None, description=\"Restaurant ID for overrides\"\n+    ),\n+    monthly_volume: Optional[float] = Query(\n+        None, description=\"Monthly volume for volume-based pricing\"\n+    ),\n+    db: Session = Depends(get_db),\n+    current_user: User = Depends(require_admin_user),\n ):\n     \"\"\"Calculate effective payment fee for given parameters\"\"\"\n     try:\n         if amount <= 0:\n             raise ValidationException(message=\"Amount must be positive\", field=\"amount\")\n-        \n+\n         service = PlatformSettingsService(db)\n         fee_calculation = await service.calculate_effective_fee(\n             payment_method=payment_method,\n             amount=amount,\n             restaurant_id=restaurant_id,\n-            monthly_volume=monthly_volume\n-        )\n-        \n-        return APIResponseHelper.success(\n-            data=fee_calculation,\n-            message=f\"Calculated fee for {payment_method} payment\"\n-        )\n-        \n+            monthly_volume=monthly_volume,\n+        )\n+\n+        return APIResponseHelper.success(\n+            data=fee_calculation, message=f\"Calculated fee for {payment_method} payment\"\n+        )\n+\n     except ValueError as e:\n         raise ValidationException(message=\"An error occurred processing the request\")\n     except Exception as e:\n-        raise FynloException(message=\"An error occurred processing the request\", status_code=500)\n+        raise FynloException(\n+            message=\"An error occurred processing the request\", status_code=500\n+        )\n+\n \n @router.get(\"/feature-flags\")\n async def get_feature_flags(\n-    restaurant_id: Optional[str] = Query(None, description=\"Filter for specific restaurant\"),\n-    db: Session = Depends(get_db),\n-    current_user: User = Depends(require_admin_user)\n+    restaurant_id: Optional[str] = Query(\n+        None, description=\"Filter for specific restaurant\"\n+    ),\n+    db: Session = Depends(get_db),\n+    current_user: User = Depends(require_admin_user),\n ):\n     \"\"\"Get all feature flags\"\"\"\n     try:\n         service = PlatformSettingsService(db)\n         flags = await service.get_feature_flags(restaurant_id=restaurant_id)\n-        \n-        return APIResponseHelper.success(\n-            data=flags,\n-            message=\"Retrieved feature flags\"\n-        )\n-        \n-    except Exception as e:\n-        raise FynloException(message=\"An error occurred processing the request\", status_code=500)\n+\n+        return APIResponseHelper.success(data=flags, message=\"Retrieved feature flags\")\n+\n+    except Exception as e:\n+        raise FynloException(\n+            message=\"An error occurred processing the request\", status_code=500\n+        )\n+\n \n @router.put(\"/feature-flags/{feature_key}\")\n async def update_feature_flag(\n     feature_key: str,\n     request: FeatureFlagRequest,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(require_admin_user)\n+    current_user: User = Depends(require_admin_user),\n ):\n     \"\"\"Update a feature flag\"\"\"\n     try:\n         service = PlatformSettingsService(db)\n-        \n+\n         success = await service.update_feature_flag(\n             feature_key=feature_key,\n             is_enabled=request.is_enabled,\n             rollout_percentage=request.rollout_percentage,\n             target_restaurants=request.target_restaurants,\n-            updated_by=str(current_user.id)\n-        )\n-        \n+            updated_by=str(current_user.id),\n+        )\n+\n         if not success:\n-            raise ResourceNotFoundException(resource=\"Resource\", message=f\"Feature flag \")\n-        \n-        return APIResponseHelper.success(\n-            data={'feature_key': feature_key, 'is_enabled': request.is_enabled},\n-            message=f\"Feature flag '{feature_key}' updated successfully\"\n-        )\n-        \n+            raise ResourceNotFoundException(\n+                resource=\"Resource\", message=f\"Feature flag \"\n+            )\n+\n+        return APIResponseHelper.success(\n+            data={\"feature_key\": feature_key, \"is_enabled\": request.is_enabled},\n+            message=f\"Feature flag '{feature_key}' updated successfully\",\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n-        raise FynloException(message=\"An error occurred processing the request\", status_code=500)\n+        raise FynloException(\n+            message=\"An error occurred processing the request\", status_code=500\n+        )\n+\n \n @router.get(\"/audit-trail\")\n async def get_configuration_audit_trail(\n     config_key: Optional[str] = Query(None, description=\"Filter by configuration key\"),\n     entity_id: Optional[str] = Query(None, description=\"Filter by entity ID\"),\n     limit: int = Query(100, description=\"Maximum number of records\", le=1000),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(require_admin_user)\n+    current_user: User = Depends(require_admin_user),\n ):\n     \"\"\"Get configuration change audit trail\"\"\"\n     try:\n         service = PlatformSettingsService(db)\n         audit_trail = await service.get_audit_trail(\n-            config_key=config_key,\n-            entity_id=entity_id,\n-            limit=limit\n-        )\n-        \n-        return APIResponseHelper.success(\n-            data={\n-                'audit_records': audit_trail,\n-                'total_records': len(audit_trail)\n-            },\n-            message=f\"Retrieved {len(audit_trail)} audit records\"\n-        )\n-        \n-    except Exception as e:\n-        raise FynloException(message=\"An error occurred processing the request\", status_code=500)\n+            config_key=config_key, entity_id=entity_id, limit=limit\n+        )\n+\n+        return APIResponseHelper.success(\n+            data={\"audit_records\": audit_trail, \"total_records\": len(audit_trail)},\n+            message=f\"Retrieved {len(audit_trail)} audit records\",\n+        )\n+\n+    except Exception as e:\n+        raise FynloException(\n+            message=\"An error occurred processing the request\", status_code=500\n+        )\n+\n \n @router.post(\"/initialize-defaults\")\n async def initialize_default_settings(\n-    db: Session = Depends(get_db),\n-    current_user: User = Depends(require_admin_user)\n+    db: Session = Depends(get_db), current_user: User = Depends(require_admin_user)\n ):\n     \"\"\"Initialize platform with default configurations\"\"\"\n     try:\n         service = PlatformSettingsService(db)\n         success = await service.initialize_default_settings()\n-        \n+\n         if success:\n             return APIResponseHelper.success(\n-                data={'initialized': True},\n-                message=\"Default platform settings initialized successfully\"\n+                data={\"initialized\": True},\n+                message=\"Default platform settings initialized successfully\",\n             )\n         else:\n-            raise FynloException(message=\"Failed to initialize default settings\", status_code=500)\n-        \n-    except Exception as e:\n-        raise FynloException(message=\"An error occurred processing the request\", status_code=500)\n+            raise FynloException(\n+                message=\"Failed to initialize default settings\", status_code=500\n+            )\n+\n+    except Exception as e:\n+        raise FynloException(\n+            message=\"An error occurred processing the request\", status_code=500\n+        )\n+\n \n # Restaurant override endpoints (for restaurant users)\n @router.get(\"/restaurants/{restaurant_id}/effective-settings\")\n async def get_restaurant_effective_settings(\n     restaurant_id: str,\n     category: Optional[str] = Query(None, description=\"Filter by category\"),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Get effective settings for a restaurant (platform + overrides)\"\"\"\n     try:\n-                \n+\n         service = PlatformSettingsService(db)\n         settings = await service.get_restaurant_effective_settings(\n-            restaurant_id=restaurant_id,\n-            category=category\n-        )\n-        \n+            restaurant_id=restaurant_id, category=category\n+        )\n+\n         return APIResponseHelper.success(\n             data=settings,\n-            message=f\"Retrieved effective settings for restaurant {restaurant_id}\"\n-        )\n-        \n-    except Exception as e:\n-        raise FynloException(message=\"An error occurred processing the request\", status_code=500)\n+            message=f\"Retrieved effective settings for restaurant {restaurant_id}\",\n+        )\n+\n+    except Exception as e:\n+        raise FynloException(\n+            message=\"An error occurred processing the request\", status_code=500\n+        )\n+\n \n @router.put(\"/restaurants/{restaurant_id}/overrides/{config_key}\")\n async def set_restaurant_override(\n     restaurant_id: str,\n     config_key: str,\n     request: RestaurantOverrideRequest,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Set a restaurant override for a platform setting\"\"\"\n     try:\n-                \n-        service = PlatformSettingsService(db)\n-        \n+\n+        service = PlatformSettingsService(db)\n+\n         success = await service.set_restaurant_override(\n             restaurant_id=restaurant_id,\n             config_key=config_key,\n             override_value=request.override_value,\n             created_by=str(current_user.id),\n-            requires_approval=request.requires_approval\n-        )\n-        \n+            requires_approval=request.requires_approval,\n+        )\n+\n         if success:\n             status_msg = \"pending approval\" if request.requires_approval else \"active\"\n             return APIResponseHelper.success(\n                 data={\n-                    'restaurant_id': restaurant_id,\n-                    'config_key': config_key,\n-                    'status': status_msg\n+                    \"restaurant_id\": restaurant_id,\n+                    \"config_key\": config_key,\n+                    \"status\": status_msg,\n                 },\n-                message=f\"Restaurant override set successfully ({status_msg})\"\n+                message=f\"Restaurant override set successfully ({status_msg})\",\n             )\n         else:\n-            raise FynloException(message=\"Failed to set restaurant override\", status_code=500)\n-        \n+            raise FynloException(\n+                message=\"Failed to set restaurant override\", status_code=500\n+            )\n+\n     except ValueError as e:\n         raise ValidationException(message=\"An error occurred processing the request\")\n     except Exception as e:\n-        raise FynloException(message=\"An error occurred processing the request\", status_code=500)\n+        raise FynloException(\n+            message=\"An error occurred processing the request\", status_code=500\n+        )\n+\n \n # Public sync endpoint for mobile apps\n @router.get(\"/sync/platform-config\")\n async def sync_platform_config(\n-    restaurant_id: Optional[str] = Query(None, description=\"Restaurant ID for targeted settings\"),\n+    restaurant_id: Optional[str] = Query(\n+        None, description=\"Restaurant ID for targeted settings\"\n+    ),\n     categories: Optional[str] = Query(None, description=\"Comma-separated categories\"),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Sync platform configuration for mobile apps (public endpoint with rate limiting)\"\"\"\n     try:\n         service = PlatformSettingsService(db)\n-        \n+\n         # Parse categories\n-        category_list = categories.split(',') if categories else None\n-        \n+        category_list = categories.split(\",\") if categories else None\n+\n         # Get platform settings and feature flags\n         all_settings = {}\n-        \n+\n         if category_list:\n             for category in category_list:\n-                settings = await service.get_platform_settings(category=category.strip())\n+                settings = await service.get_platform_settings(\n+                    category=category.strip()\n+                )\n                 all_settings.update(settings)\n         else:\n             all_settings = await service.get_platform_settings()\n-        \n+\n         # Get feature flags\n         feature_flags = await service.get_feature_flags(restaurant_id=restaurant_id)\n-        \n+\n         # Get restaurant-specific effective settings if restaurant_id provided\n         effective_settings = {}\n         if restaurant_id:\n-            effective_settings = await service.get_restaurant_effective_settings(restaurant_id)\n-        \n+            effective_settings = await service.get_restaurant_effective_settings(\n+                restaurant_id\n+            )\n+\n         return APIResponseHelper.success(\n             data={\n-                'platform_settings': all_settings,\n-                'feature_flags': feature_flags,\n-                'effective_settings': effective_settings,\n-                'sync_timestamp': datetime.utcnow().isoformat(),\n-                'restaurant_id': restaurant_id\n+                \"platform_settings\": all_settings,\n+                \"feature_flags\": feature_flags,\n+                \"effective_settings\": effective_settings,\n+                \"sync_timestamp\": datetime.utcnow().isoformat(),\n+                \"restaurant_id\": restaurant_id,\n             },\n-            message=\"Platform configuration synchronized\"\n-        )\n-        \n-    except Exception as e:\n-        raise FynloException(message=\"An error occurred processing the request\", status_code=500)\n+            message=\"Platform configuration synchronized\",\n+        )\n+\n+    except Exception as e:\n+        raise FynloException(\n+            message=\"An error occurred processing the request\", status_code=500\n+        )\n+\n \n @router.get(\"/categories\")\n async def get_setting_categories(\n-    db: Session = Depends(get_db),\n-    current_user: User = Depends(require_admin_user)\n+    db: Session = Depends(get_db), current_user: User = Depends(require_admin_user)\n ):\n     \"\"\"Get all available setting categories\"\"\"\n     try:\n         service = PlatformSettingsService(db)\n         settings = await service.get_platform_settings()\n-        \n+\n         categories = set()\n         for setting_data in settings.values():\n-            categories.add(setting_data['category'])\n-        \n+            categories.add(setting_data[\"category\"])\n+\n         return APIResponseHelper.success(\n             data=sorted(list(categories)),\n-            message=f\"Retrieved {len(categories)} setting categories\"\n-        )\n-        \n-    except Exception as e:\n-        raise FynloException(message=\"An error occurred processing the request\", status_code=500)\n\\ No newline at end of file\n+            message=f\"Retrieved {len(categories)} setting categories\",\n+        )\n+\n+    except Exception as e:\n+        raise FynloException(\n+            message=\"An error occurred processing the request\", status_code=500\n+        )\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/restaurant_deletion.py\t2025-08-02 21:56:58.989179+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/restaurant_deletion.py\t2025-08-02 22:36:02.893291+00:00\n@@ -8,11 +8,19 @@\n from sqlalchemy.orm import Session\n from sqlalchemy import and_, func\n from datetime import datetime, timedelta\n from typing import Optional, List, Dict\n \n-from app.core.database import get_db, Restaurant, User, Order, Payment, InventoryItem, UserRestaurant\n+from app.core.database import (\n+    get_db,\n+    Restaurant,\n+    User,\n+    Order,\n+    Payment,\n+    InventoryItem,\n+    UserRestaurant,\n+)\n from app.core.auth import get_current_user\n from app.core.tenant_security import TenantSecurity\n from app.core.response_helper import APIResponseHelper\n from app.core.security_monitor import security_monitor, SecurityEventType\n from app.core.validators import validate_uuid_format\n@@ -20,10 +28,11 @@\n router = APIRouter()\n \n \n class DeletionCheckResult:\n     \"\"\"Result of deletion safety check\"\"\"\n+\n     def __init__(self):\n         self.can_delete = True\n         self.warnings = []\n         self.blockers = []\n         self.stats = {}\n@@ -32,42 +41,42 @@\n @router.delete(\"/{restaurant_id}\")\n async def delete_restaurant(\n     restaurant_id: str,\n     force: bool = False,\n     current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"\n     Safely delete a restaurant with dependency checks\n-    \n+\n     Args:\n         restaurant_id: Restaurant to delete\n         force: Force deletion even with warnings (requires platform owner)\n         current_user: Current authenticated user\n         db: Database session\n-    \n+\n     Returns:\n         Success response or error with dependency information\n     \"\"\"\n     # Validate restaurant_id format\n     try:\n         validate_uuid_format(restaurant_id)\n     except ValueError:\n         raise ValidationException(message=\"Invalid restaurant ID format\")\n-    \n+\n     # Only platform owners can delete restaurants\n     if not TenantSecurity.is_platform_owner(current_user):\n         raise FynloException(message=\"Only platform owners can delete restaurants\")\n-    \n+\n     # Get restaurant\n     restaurant = db.query(Restaurant).filter(Restaurant.id == restaurant_id).first()\n     if not restaurant:\n         raise NotFoundException(message=\"Restaurant not found\")\n-    \n+\n     # Perform deletion safety checks\n     check_result = await check_deletion_safety(restaurant_id, db)\n-    \n+\n     # Log the deletion attempt\n     await security_monitor.log_event(\n         user=current_user,\n         event_type=SecurityEventType.ADMIN_ACTION,\n         details={\n@@ -75,275 +84,305 @@\n             \"restaurant_id\": restaurant_id,\n             \"restaurant_name\": restaurant.name,\n             \"can_delete\": check_result.can_delete,\n             \"blockers\": check_result.blockers,\n             \"warnings\": check_result.warnings,\n-            \"force\": force\n-        }\n-    )\n-    \n+            \"force\": force,\n+        },\n+    )\n+\n     # If there are blockers, deletion is not allowed\n     if check_result.blockers:\n         return APIResponseHelper.error(\n             message=\"Restaurant deletion blocked due to critical dependencies\",\n             status_code=status.HTTP_409_CONFLICT,\n             data={\n                 \"blockers\": check_result.blockers,\n                 \"warnings\": check_result.warnings,\n-                \"stats\": check_result.stats\n-            }\n-        )\n-    \n+                \"stats\": check_result.stats,\n+            },\n+        )\n+\n     # If there are warnings but no blockers\n     if check_result.warnings and not force:\n         return APIResponseHelper.error(\n             message=\"Restaurant has dependencies. Use force=true to delete anyway (platform owner only)\",\n             status_code=status.HTTP_409_CONFLICT,\n             data={\n                 \"warnings\": check_result.warnings,\n                 \"stats\": check_result.stats,\n-                \"can_force_delete\": TenantSecurity.is_platform_owner(current_user)\n-            }\n-        )\n-    \n+                \"can_force_delete\": TenantSecurity.is_platform_owner(current_user),\n+            },\n+        )\n+\n     # Proceed with deletion\n     try:\n         # Soft delete - mark as inactive first\n         restaurant.is_active = False\n         restaurant.deleted_at = datetime.utcnow()\n         restaurant.deleted_by = current_user.id\n         db.commit()\n-        \n+\n         # Log successful deletion\n         await security_monitor.log_event(\n             user=current_user,\n             event_type=SecurityEventType.ADMIN_ACTION,\n             details={\n                 \"action\": \"restaurant_deleted\",\n                 \"restaurant_id\": restaurant_id,\n                 \"restaurant_name\": restaurant.name,\n                 \"deletion_type\": \"soft_delete\",\n-                \"forced\": force\n-            }\n-        )\n-        \n+                \"forced\": force,\n+            },\n+        )\n+\n         return APIResponseHelper.success(\n             message=f\"Restaurant '{restaurant.name}' has been deactivated\",\n             data={\n                 \"restaurant_id\": restaurant_id,\n                 \"deletion_type\": \"soft_delete\",\n                 \"warnings_overridden\": check_result.warnings if force else [],\n-                \"stats\": check_result.stats\n-            }\n-        )\n-        \n+                \"stats\": check_result.stats,\n+            },\n+        )\n+\n     except Exception as e:\n         db.rollback()\n         await security_monitor.log_event(\n             user=current_user,\n             event_type=SecurityEventType.ERROR,\n             details={\n                 \"action\": \"restaurant_deletion_failed\",\n                 \"restaurant_id\": restaurant_id,\n-                \"error\": str(e)\n-            }\n+                \"error\": str(e),\n+            },\n         )\n         raise FynloException(message=\"Failed to delete restaurant\")\n \n \n async def check_deletion_safety(restaurant_id: str, db: Session) -> DeletionCheckResult:\n     \"\"\"\n     Check if a restaurant can be safely deleted\n-    \n+\n     Returns DeletionCheckResult with:\n     - blockers: Critical issues that prevent deletion\n     - warnings: Non-critical issues that should be reviewed\n     - stats: Statistics about the restaurant's data\n     \"\"\"\n     result = DeletionCheckResult()\n-    \n+\n     # Check for active orders in the last 24 hours\n     recent_cutoff = datetime.utcnow() - timedelta(hours=24)\n-    active_orders = db.query(Order).filter(\n-        and_(\n-            Order.restaurant_id == restaurant_id,\n-            Order.created_at >= recent_cutoff,\n-            Order.status.in_([\"pending\", \"preparing\", \"ready\"])\n-        )\n-    ).count()\n-    \n+    active_orders = (\n+        db.query(Order)\n+        .filter(\n+            and_(\n+                Order.restaurant_id == restaurant_id,\n+                Order.created_at >= recent_cutoff,\n+                Order.status.in_([\"pending\", \"preparing\", \"ready\"]),\n+            )\n+        )\n+        .count()\n+    )\n+\n     if active_orders > 0:\n-        result.blockers.append(f\"Restaurant has {active_orders} active orders in the last 24 hours\")\n+        result.blockers.append(\n+            f\"Restaurant has {active_orders} active orders in the last 24 hours\"\n+        )\n         result.can_delete = False\n-    \n+\n     result.stats[\"active_orders\"] = active_orders\n-    \n+\n     # Check for pending payments\n-    pending_payments = db.query(Payment).filter(\n-        and_(\n-            Payment.restaurant_id == restaurant_id,\n-            Payment.status == \"pending\"\n-        )\n-    ).count()\n-    \n+    pending_payments = (\n+        db.query(Payment)\n+        .filter(\n+            and_(Payment.restaurant_id == restaurant_id, Payment.status == \"pending\")\n+        )\n+        .count()\n+    )\n+\n     if pending_payments > 0:\n         result.blockers.append(f\"Restaurant has {pending_payments} pending payments\")\n         result.can_delete = False\n-    \n+\n     result.stats[\"pending_payments\"] = pending_payments\n-    \n+\n     # Check for active employees\n-    active_employees = db.query(User).filter(\n-        and_(\n-            User.restaurant_id == restaurant_id,\n-            User.is_active == True,\n-            User.role.in_([\"manager\", \"employee\"])\n-        )\n-    ).count()\n-    \n+    active_employees = (\n+        db.query(User)\n+        .filter(\n+            and_(\n+                User.restaurant_id == restaurant_id,\n+                User.is_active == True,\n+                User.role.in_([\"manager\", \"employee\"]),\n+            )\n+        )\n+        .count()\n+    )\n+\n     if active_employees > 0:\n-        result.warnings.append(f\"Restaurant has {active_employees} active employees who will lose access\")\n-    \n+        result.warnings.append(\n+            f\"Restaurant has {active_employees} active employees who will lose access\"\n+        )\n+\n     result.stats[\"active_employees\"] = active_employees\n-    \n+\n     # Check for inventory with value\n-    inventory_value = db.query(func.sum(InventoryItem.quantity * InventoryItem.unit_cost)).filter(\n-        and_(\n-            InventoryItem.restaurant_id == restaurant_id,\n-            InventoryItem.quantity > 0\n-        )\n-    ).scalar() or 0\n-    \n+    inventory_value = (\n+        db.query(func.sum(InventoryItem.quantity * InventoryItem.unit_cost))\n+        .filter(\n+            and_(\n+                InventoryItem.restaurant_id == restaurant_id, InventoryItem.quantity > 0\n+            )\n+        )\n+        .scalar()\n+        or 0\n+    )\n+\n     if inventory_value > 100:  # Threshold for significant inventory\n         result.warnings.append(f\"Restaurant has inventory worth \u00a3{inventory_value:.2f}\")\n-    \n+\n     result.stats[\"inventory_value\"] = float(inventory_value)\n-    \n+\n     # Check for recent revenue\n     week_ago = datetime.utcnow() - timedelta(days=7)\n-    recent_revenue = db.query(func.sum(Order.total_amount)).filter(\n-        and_(\n-            Order.restaurant_id == restaurant_id,\n-            Order.created_at >= week_ago,\n-            Order.status == \"completed\"\n-        )\n-    ).scalar() or 0\n-    \n+    recent_revenue = (\n+        db.query(func.sum(Order.total_amount))\n+        .filter(\n+            and_(\n+                Order.restaurant_id == restaurant_id,\n+                Order.created_at >= week_ago,\n+                Order.status == \"completed\",\n+            )\n+        )\n+        .scalar()\n+        or 0\n+    )\n+\n     if recent_revenue > 0:\n-        result.warnings.append(f\"Restaurant had \u00a3{recent_revenue:.2f} in revenue in the last 7 days\")\n-    \n+        result.warnings.append(\n+            f\"Restaurant had \u00a3{recent_revenue:.2f} in revenue in the last 7 days\"\n+        )\n+\n     result.stats[\"recent_revenue\"] = float(recent_revenue)\n-    \n+\n     # Check for total historical data\n     total_orders = db.query(Order).filter(Order.restaurant_id == restaurant_id).count()\n-    total_customers = db.query(func.count(func.distinct(Order.customer_id))).filter(\n-        Order.restaurant_id == restaurant_id\n-    ).scalar() or 0\n-    \n+    total_customers = (\n+        db.query(func.count(func.distinct(Order.customer_id)))\n+        .filter(Order.restaurant_id == restaurant_id)\n+        .scalar()\n+        or 0\n+    )\n+\n     if total_orders > 1000:\n         result.warnings.append(f\"Restaurant has {total_orders} historical orders\")\n-    \n+\n     result.stats[\"total_orders\"] = total_orders\n     result.stats[\"total_customers\"] = total_customers\n-    \n+\n     # Check if this is the user's only restaurant\n     # Get all users associated with this restaurant\n-    restaurant_users = db.query(User).filter(\n-        User.restaurant_id == restaurant_id\n-    ).all()\n-    \n+    restaurant_users = db.query(User).filter(User.restaurant_id == restaurant_id).all()\n+\n     for user in restaurant_users:\n         # Check if user has access to other restaurants\n-        other_restaurants = db.query(UserRestaurant).filter(\n-            and_(\n-                UserRestaurant.user_id == user.id,\n-                UserRestaurant.restaurant_id != restaurant_id\n-            )\n-        ).count()\n-        \n+        other_restaurants = (\n+            db.query(UserRestaurant)\n+            .filter(\n+                and_(\n+                    UserRestaurant.user_id == user.id,\n+                    UserRestaurant.restaurant_id != restaurant_id,\n+                )\n+            )\n+            .count()\n+        )\n+\n         if other_restaurants == 0 and user.role == \"restaurant_owner\":\n-            result.warnings.append(f\"User {user.email} will have no restaurants after deletion\")\n-    \n+            result.warnings.append(\n+                f\"User {user.email} will have no restaurants after deletion\"\n+            )\n+\n     return result\n \n \n @router.post(\"/{restaurant_id}/archive\")\n async def archive_restaurant(\n     restaurant_id: str,\n     current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"\n     Archive a restaurant (soft delete with data retention)\n     This is safer than deletion as it preserves all data\n     \"\"\"\n     # Validate restaurant_id format\n     try:\n         validate_uuid_format(restaurant_id)\n     except ValueError:\n         raise ValidationException(message=\"Invalid restaurant ID format\")\n-    \n+\n     # Check permissions\n     if not TenantSecurity.is_platform_owner(current_user):\n         # Restaurant owners can archive their own restaurants\n         await TenantSecurity.validate_restaurant_access(\n-            current_user,\n-            restaurant_id,\n-            \"archive\",\n-            db=db\n-        )\n-        \n+            current_user, restaurant_id, \"archive\", db=db\n+        )\n+\n         # Additional check: restaurant owners can only archive if they own it\n         if current_user.role != \"restaurant_owner\":\n-            raise FynloException(message=\"Only restaurant owners or platform owners can archive restaurants\")\n-    \n+            raise FynloException(\n+                message=\"Only restaurant owners or platform owners can archive restaurants\"\n+            )\n+\n     # Get restaurant\n     restaurant = db.query(Restaurant).filter(Restaurant.id == restaurant_id).first()\n     if not restaurant:\n         raise NotFoundException(message=\"Restaurant not found\")\n-    \n+\n     if not restaurant.is_active:\n         return APIResponseHelper.error(\n             message=\"Restaurant is already archived\",\n-            status_code=status.HTTP_400_BAD_REQUEST\n-        )\n-    \n+            status_code=status.HTTP_400_BAD_REQUEST,\n+        )\n+\n     try:\n         # Archive the restaurant\n         restaurant.is_active = False\n         restaurant.archived_at = datetime.utcnow()\n         restaurant.archived_by = current_user.id\n         restaurant.archive_reason = \"User requested archive\"\n-        \n+\n         # Deactivate all employees\n         db.query(User).filter(\n             and_(\n                 User.restaurant_id == restaurant_id,\n-                User.role.in_([\"manager\", \"employee\"])\n+                User.role.in_([\"manager\", \"employee\"]),\n             )\n         ).update({\"is_active\": False})\n-        \n+\n         db.commit()\n-        \n+\n         # Log the archive action\n         await security_monitor.log_event(\n             user=current_user,\n             event_type=SecurityEventType.ADMIN_ACTION,\n             details={\n                 \"action\": \"restaurant_archived\",\n                 \"restaurant_id\": restaurant_id,\n-                \"restaurant_name\": restaurant.name\n-            }\n-        )\n-        \n+                \"restaurant_name\": restaurant.name,\n+            },\n+        )\n+\n         return APIResponseHelper.success(\n             message=f\"Restaurant '{restaurant.name}' has been archived\",\n             data={\n                 \"restaurant_id\": restaurant_id,\n                 \"archived_at\": restaurant.archived_at.isoformat(),\n-                \"archive_type\": \"soft_archive\"\n-            }\n-        )\n-        \n+                \"archive_type\": \"soft_archive\",\n+            },\n+        )\n+\n     except Exception as e:\n         db.rollback()\n-        raise FynloException(message=\"Failed to archive restaurant\")\n\\ No newline at end of file\n+        raise FynloException(message=\"Failed to archive restaurant\")\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/platform.py\t2025-08-02 21:56:58.987402+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/platform.py\t2025-08-02 22:36:02.895683+00:00\n@@ -18,33 +18,41 @@\n from app.api.v1.endpoints import platform_settings\n \n router = APIRouter()\n \n # Include platform settings router\n-router.include_router(platform_settings.router, prefix=\"/settings\", tags=[\"platform-settings\"])\n+router.include_router(\n+    platform_settings.router, prefix=\"/settings\", tags=[\"platform-settings\"]\n+)\n+\n \n # Platform Management Models\n class PlatformCreateRequest(BaseModel):\n     \"\"\"Create new platform request\"\"\"\n+\n     name: str\n     description: Optional[str] = None\n     settings: Dict[str, Any] = {}\n \n+\n class PlatformResponse(BaseModel):\n     \"\"\"Platform information response\"\"\"\n+\n     id: str\n     name: str\n     description: Optional[str]\n     owner_id: str\n     total_restaurants: int\n     active_restaurants: int\n     settings: Dict[str, Any]\n     created_at: datetime\n     updated_at: Optional[datetime]\n \n+\n class RestaurantSummary(BaseModel):\n     \"\"\"Restaurant summary for platform dashboard\"\"\"\n+\n     id: str\n     name: str\n     address: Dict[str, Any]\n     is_active: bool\n     total_revenue: float\n@@ -52,124 +60,143 @@\n     total_orders: int\n     monthly_orders: int\n     last_order_at: Optional[datetime]\n     created_at: datetime\n \n+\n class PlatformDashboardResponse(BaseModel):\n     \"\"\"Platform dashboard overview\"\"\"\n+\n     platform_info: PlatformResponse\n     restaurants: List[RestaurantSummary]\n     aggregated_metrics: Dict[str, Any]\n     recent_activity: List[Dict[str, Any]]\n \n+\n class RestaurantSwitchRequest(BaseModel):\n     \"\"\"Restaurant switching request\"\"\"\n+\n     restaurant_id: str\n+\n \n class CommissionReport(BaseModel):\n     \"\"\"Commission tracking report\"\"\"\n+\n     restaurant_id: str\n     restaurant_name: str\n     period_start: datetime\n     period_end: datetime\n     gross_revenue: float\n     commission_rate: float\n     commission_amount: float\n     net_revenue: float\n \n+\n # Platform Dashboard Endpoints\n @router.get(\"/dashboard\")\n async def get_platform_dashboard(\n-    current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    current_user: User = Depends(get_current_user), db: Session = Depends(get_db)\n ):\n     \"\"\"\n     Get comprehensive platform dashboard for platform owners\n     \"\"\"\n     try:\n         # Verify platform owner permissions\n         if current_user.role != \"platform_owner\":\n             raise FynloException(\n                 message=\"Access denied - platform owners only\",\n                 error_code=ErrorCodes.FORBIDDEN,\n-                status_code=403\n-            )\n-        \n+                status_code=403,\n+            )\n+\n         platform_id = str(current_user.platform_id)\n-        \n+\n         # Get platform information\n         platform = db.query(Platform).filter(Platform.id == platform_id).first()\n         if not platform:\n             raise FynloException(\n                 message=\"Platform not found\",\n                 error_code=ErrorCodes.NOT_FOUND,\n-                status_code=404\n-            )\n-        \n+                status_code=404,\n+            )\n+\n         # Get all restaurants in platform\n-        restaurants = db.query(Restaurant).filter(\n-            Restaurant.platform_id == platform_id\n-        ).all()\n-        \n+        restaurants = (\n+            db.query(Restaurant).filter(Restaurant.platform_id == platform_id).all()\n+        )\n+\n         restaurant_ids = [str(r.id) for r in restaurants]\n-        \n+\n         # Calculate period (last 30 days)\n         end_date = datetime.now()\n         start_date = end_date - timedelta(days=30)\n-        \n+\n         # Get restaurant summaries with metrics\n         restaurant_summaries = []\n         total_platform_revenue = 0\n         total_platform_orders = 0\n-        \n+\n         for restaurant in restaurants:\n             # Calculate restaurant metrics\n-            restaurant_orders = db.query(Order).filter(\n-                and_(\n-                    Order.restaurant_id == restaurant.id,\n-                    Order.status == \"completed\"\n-                )\n-            ).all()\n-            \n-            monthly_orders = db.query(Order).filter(\n-                and_(\n-                    Order.restaurant_id == restaurant.id,\n-                    Order.created_at >= start_date,\n-                    Order.status == \"completed\"\n-                )\n-            ).all()\n-            \n+            restaurant_orders = (\n+                db.query(Order)\n+                .filter(\n+                    and_(\n+                        Order.restaurant_id == restaurant.id,\n+                        Order.status == \"completed\",\n+                    )\n+                )\n+                .all()\n+            )\n+\n+            monthly_orders = (\n+                db.query(Order)\n+                .filter(\n+                    and_(\n+                        Order.restaurant_id == restaurant.id,\n+                        Order.created_at >= start_date,\n+                        Order.status == \"completed\",\n+                    )\n+                )\n+                .all()\n+            )\n+\n             total_revenue = sum(order.total_amount for order in restaurant_orders)\n             monthly_revenue = sum(order.total_amount for order in monthly_orders)\n-            \n+\n             # Get last order\n-            last_order = db.query(Order).filter(\n-                Order.restaurant_id == restaurant.id\n-            ).order_by(desc(Order.created_at)).first()\n-            \n-            restaurant_summaries.append(RestaurantSummary(\n-                id=str(restaurant.id),\n-                name=restaurant.name,\n-                address=restaurant.address,\n-                is_active=restaurant.is_active,\n-                total_revenue=float(total_revenue),\n-                monthly_revenue=float(monthly_revenue),\n-                total_orders=len(restaurant_orders),\n-                monthly_orders=len(monthly_orders),\n-                last_order_at=last_order.created_at if last_order else None,\n-                created_at=restaurant.created_at\n-            ))\n-            \n+            last_order = (\n+                db.query(Order)\n+                .filter(Order.restaurant_id == restaurant.id)\n+                .order_by(desc(Order.created_at))\n+                .first()\n+            )\n+\n+            restaurant_summaries.append(\n+                RestaurantSummary(\n+                    id=str(restaurant.id),\n+                    name=restaurant.name,\n+                    address=restaurant.address,\n+                    is_active=restaurant.is_active,\n+                    total_revenue=float(total_revenue),\n+                    monthly_revenue=float(monthly_revenue),\n+                    total_orders=len(restaurant_orders),\n+                    monthly_orders=len(monthly_orders),\n+                    last_order_at=last_order.created_at if last_order else None,\n+                    created_at=restaurant.created_at,\n+                )\n+            )\n+\n             total_platform_revenue += total_revenue\n             total_platform_orders += len(restaurant_orders)\n-        \n+\n         # Calculate aggregated metrics\n         active_restaurants = sum(1 for r in restaurants if r.is_active)\n         average_revenue_per_restaurant = (\n             total_platform_revenue / len(restaurants) if restaurants else 0\n         )\n-        \n+\n         aggregated_metrics = {\n             \"total_revenue\": round(total_platform_revenue, 2),\n             \"monthly_revenue\": round(\n                 sum(r.monthly_revenue for r in restaurant_summaries), 2\n             ),\n@@ -178,451 +205,529 @@\n             \"total_orders\": total_platform_orders,\n             \"monthly_orders\": sum(r.monthly_orders for r in restaurant_summaries),\n             \"average_revenue_per_restaurant\": round(average_revenue_per_restaurant, 2),\n             \"platform_growth_rate\": 0.0,  # Would calculate based on historical data\n         }\n-        \n+\n         # Get recent activity (last 10 orders across all restaurants)\n-        recent_orders = db.query(Order).filter(\n-            Order.restaurant_id.in_(restaurant_ids)\n-        ).order_by(desc(Order.created_at)).limit(10).all()\n-        \n+        recent_orders = (\n+            db.query(Order)\n+            .filter(Order.restaurant_id.in_(restaurant_ids))\n+            .order_by(desc(Order.created_at))\n+            .limit(10)\n+            .all()\n+        )\n+\n         recent_activity = []\n         for order in recent_orders:\n-            restaurant = next((r for r in restaurants if str(r.id) == str(order.restaurant_id)), None)\n-            recent_activity.append({\n-                \"id\": str(order.id),\n-                \"type\": \"order\",\n-                \"restaurant_name\": restaurant.name if restaurant else \"Unknown\",\n-                \"restaurant_id\": str(order.restaurant_id),\n-                \"order_number\": order.order_number,\n-                \"amount\": float(order.total_amount),\n-                \"status\": order.status,\n-                \"created_at\": order.created_at.isoformat()\n-            })\n-        \n+            restaurant = next(\n+                (r for r in restaurants if str(r.id) == str(order.restaurant_id)), None\n+            )\n+            recent_activity.append(\n+                {\n+                    \"id\": str(order.id),\n+                    \"type\": \"order\",\n+                    \"restaurant_name\": restaurant.name if restaurant else \"Unknown\",\n+                    \"restaurant_id\": str(order.restaurant_id),\n+                    \"order_number\": order.order_number,\n+                    \"amount\": float(order.total_amount),\n+                    \"status\": order.status,\n+                    \"created_at\": order.created_at.isoformat(),\n+                }\n+            )\n+\n         # Build platform response\n         platform_response = PlatformResponse(\n             id=str(platform.id),\n             name=platform.name,\n             description=platform.description,\n             owner_id=str(platform.owner_id),\n             total_restaurants=len(restaurants),\n             active_restaurants=active_restaurants,\n             settings=platform.settings or {},\n             created_at=platform.created_at,\n-            updated_at=platform.updated_at\n-        )\n-        \n+            updated_at=platform.updated_at,\n+        )\n+\n         dashboard_data = PlatformDashboardResponse(\n             platform_info=platform_response,\n             restaurants=restaurant_summaries,\n             aggregated_metrics=aggregated_metrics,\n-            recent_activity=recent_activity\n-        )\n-        \n+            recent_activity=recent_activity,\n+        )\n+\n         return APIResponseHelper.success(\n             data=dashboard_data.dict(),\n             message=\"Platform dashboard retrieved successfully\",\n             meta={\n                 \"restaurants_count\": len(restaurants),\n                 \"total_revenue\": aggregated_metrics[\"total_revenue\"],\n-                \"period\": \"last_30_days\"\n-            }\n-        )\n-        \n+                \"period\": \"last_30_days\",\n+            },\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to retrieve platform dashboard: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n @router.post(\"/restaurants/{restaurant_id}/switch\")\n async def switch_restaurant_context(\n     restaurant_id: str = Path(..., description=\"Restaurant ID to switch to\"),\n     current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"\n     Switch restaurant context for platform owners\n     \"\"\"\n     try:\n         # Verify platform owner permissions\n         if current_user.role != \"platform_owner\":\n             raise FynloException(\n                 message=\"Access denied - platform owners only\",\n                 error_code=ErrorCodes.FORBIDDEN,\n-                status_code=403\n-            )\n-        \n+                status_code=403,\n+            )\n+\n         # Verify restaurant exists and belongs to platform\n-        restaurant = db.query(Restaurant).filter(\n-            and_(\n-                Restaurant.id == restaurant_id,\n-                Restaurant.platform_id == current_user.platform_id\n-            )\n-        ).first()\n-        \n+        restaurant = (\n+            db.query(Restaurant)\n+            .filter(\n+                and_(\n+                    Restaurant.id == restaurant_id,\n+                    Restaurant.platform_id == current_user.platform_id,\n+                )\n+            )\n+            .first()\n+        )\n+\n         if not restaurant:\n             raise FynloException(\n                 message=\"Restaurant not found or access denied\",\n                 error_code=ErrorCodes.NOT_FOUND,\n-                status_code=404\n-            )\n-        \n+                status_code=404,\n+            )\n+\n         # Update user's current restaurant context (in session/JWT claims)\n         # This would be handled by updating JWT claims or session data\n         restaurant_context = {\n             \"restaurant_id\": str(restaurant.id),\n             \"restaurant_name\": restaurant.name,\n             \"switched_at\": datetime.now().isoformat(),\n-            \"previous_context\": str(current_user.restaurant_id) if current_user.restaurant_id else None\n+            \"previous_context\": (\n+                str(current_user.restaurant_id) if current_user.restaurant_id else None\n+            ),\n         }\n-        \n+\n         return APIResponseHelper.success(\n             data=restaurant_context,\n             message=f\"Switched to restaurant: {restaurant.name}\",\n             meta={\n                 \"restaurant_id\": str(restaurant.id),\n-                \"platform_id\": str(current_user.platform_id)\n-            }\n-        )\n-        \n+                \"platform_id\": str(current_user.platform_id),\n+            },\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to switch restaurant context: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n @router.get(\"/restaurants\")\n async def get_platform_restaurants(\n     status: Optional[str] = Query(None, description=\"Filter by restaurant status\"),\n     limit: int = Query(50, le=100),\n     offset: int = Query(0),\n     current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"\n     Get all restaurants for platform owner\n     \"\"\"\n     try:\n         # Verify platform owner permissions\n         if current_user.role != \"platform_owner\":\n             raise FynloException(\n                 message=\"Access denied - platform owners only\",\n                 error_code=ErrorCodes.FORBIDDEN,\n-                status_code=403\n-            )\n-        \n+                status_code=403,\n+            )\n+\n         platform_id = str(current_user.platform_id)\n-        \n+\n         # Build query\n         query = db.query(Restaurant).filter(Restaurant.platform_id == platform_id)\n-        \n+\n         if status:\n             if status == \"active\":\n                 query = query.filter(Restaurant.is_active == True)\n             elif status == \"inactive\":\n                 query = query.filter(Restaurant.is_active == False)\n-        \n+\n         # Get total count for pagination\n         total_count = query.count()\n-        \n+\n         # Apply pagination\n         restaurants = query.order_by(Restaurant.name).offset(offset).limit(limit).all()\n-        \n+\n         # Build restaurant summaries\n         restaurant_data = []\n         for restaurant in restaurants:\n             # Get basic metrics\n-            total_orders = db.query(Order).filter(\n-                Order.restaurant_id == restaurant.id\n-            ).count()\n-            \n-            total_revenue = db.query(func.sum(Order.total_amount)).filter(\n-                and_(\n-                    Order.restaurant_id == restaurant.id,\n-                    Order.status == \"completed\"\n-                )\n-            ).scalar() or 0\n-            \n-            restaurant_data.append({\n-                \"id\": str(restaurant.id),\n-                \"name\": restaurant.name,\n-                \"address\": restaurant.address,\n-                \"phone\": restaurant.phone,\n-                \"email\": restaurant.email,\n-                \"is_active\": restaurant.is_active,\n-                \"total_orders\": total_orders,\n-                \"total_revenue\": float(total_revenue),\n-                \"timezone\": restaurant.timezone,\n-                \"created_at\": restaurant.created_at.isoformat(),\n-                \"updated_at\": restaurant.updated_at.isoformat() if restaurant.updated_at else None\n-            })\n-        \n+            total_orders = (\n+                db.query(Order).filter(Order.restaurant_id == restaurant.id).count()\n+            )\n+\n+            total_revenue = (\n+                db.query(func.sum(Order.total_amount))\n+                .filter(\n+                    and_(\n+                        Order.restaurant_id == restaurant.id,\n+                        Order.status == \"completed\",\n+                    )\n+                )\n+                .scalar()\n+                or 0\n+            )\n+\n+            restaurant_data.append(\n+                {\n+                    \"id\": str(restaurant.id),\n+                    \"name\": restaurant.name,\n+                    \"address\": restaurant.address,\n+                    \"phone\": restaurant.phone,\n+                    \"email\": restaurant.email,\n+                    \"is_active\": restaurant.is_active,\n+                    \"total_orders\": total_orders,\n+                    \"total_revenue\": float(total_revenue),\n+                    \"timezone\": restaurant.timezone,\n+                    \"created_at\": restaurant.created_at.isoformat(),\n+                    \"updated_at\": (\n+                        restaurant.updated_at.isoformat()\n+                        if restaurant.updated_at\n+                        else None\n+                    ),\n+                }\n+            )\n+\n         return APIResponseHelper.success(\n             data=restaurant_data,\n             message=f\"Retrieved {len(restaurant_data)} restaurants\",\n             meta={\n                 \"total_count\": total_count,\n                 \"limit\": limit,\n                 \"offset\": offset,\n                 \"platform_id\": platform_id,\n-                \"status_filter\": status\n-            }\n-        )\n-        \n+                \"status_filter\": status,\n+            },\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to retrieve platform restaurants: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n @router.get(\"/analytics/commission\")\n async def get_commission_report(\n     period_days: int = Query(30, description=\"Report period in days\"),\n     restaurant_id: Optional[str] = Query(None, description=\"Specific restaurant ID\"),\n     current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"\n     Get commission tracking report for platform\n     \"\"\"\n     try:\n         # Verify platform owner permissions\n         if current_user.role != \"platform_owner\":\n             raise FynloException(\n                 message=\"Access denied - platform owners only\",\n                 error_code=ErrorCodes.FORBIDDEN,\n-                status_code=403\n-            )\n-        \n+                status_code=403,\n+            )\n+\n         platform_id = str(current_user.platform_id)\n-        \n+\n         # Calculate date range\n         end_date = datetime.now()\n         start_date = end_date - timedelta(days=period_days)\n-        \n+\n         # Get restaurants to report on\n-        restaurants_query = db.query(Restaurant).filter(Restaurant.platform_id == platform_id)\n+        restaurants_query = db.query(Restaurant).filter(\n+            Restaurant.platform_id == platform_id\n+        )\n         if restaurant_id:\n             restaurants_query = restaurants_query.filter(Restaurant.id == restaurant_id)\n-        \n+\n         restaurants = restaurants_query.all()\n-        \n+\n         commission_reports = []\n         total_commission = 0\n-        \n+\n         for restaurant in restaurants:\n             # Get completed orders for the period\n-            orders = db.query(Order).filter(\n-                and_(\n-                    Order.restaurant_id == restaurant.id,\n-                    Order.created_at >= start_date,\n-                    Order.created_at <= end_date,\n-                    Order.status == \"completed\"\n-                )\n-            ).all()\n-            \n+            orders = (\n+                db.query(Order)\n+                .filter(\n+                    and_(\n+                        Order.restaurant_id == restaurant.id,\n+                        Order.created_at >= start_date,\n+                        Order.created_at <= end_date,\n+                        Order.status == \"completed\",\n+                    )\n+                )\n+                .all()\n+            )\n+\n             gross_revenue = sum(order.total_amount for order in orders)\n-            \n+\n             # Commission rate (could be stored in restaurant settings)\n-            commission_rate = restaurant.settings.get(\"commission_rate\", 0.05) if restaurant.settings else 0.05  # 5% default\n+            commission_rate = (\n+                restaurant.settings.get(\"commission_rate\", 0.05)\n+                if restaurant.settings\n+                else 0.05\n+            )  # 5% default\n             commission_amount = gross_revenue * commission_rate\n             net_revenue = gross_revenue - commission_amount\n-            \n-            commission_reports.append(CommissionReport(\n-                restaurant_id=str(restaurant.id),\n-                restaurant_name=restaurant.name,\n-                period_start=start_date,\n-                period_end=end_date,\n-                gross_revenue=float(gross_revenue),\n-                commission_rate=float(commission_rate),\n-                commission_amount=float(commission_amount),\n-                net_revenue=float(net_revenue)\n-            ))\n-            \n+\n+            commission_reports.append(\n+                CommissionReport(\n+                    restaurant_id=str(restaurant.id),\n+                    restaurant_name=restaurant.name,\n+                    period_start=start_date,\n+                    period_end=end_date,\n+                    gross_revenue=float(gross_revenue),\n+                    commission_rate=float(commission_rate),\n+                    commission_amount=float(commission_amount),\n+                    net_revenue=float(net_revenue),\n+                )\n+            )\n+\n             total_commission += commission_amount\n-        \n+\n         # Calculate summary\n         total_gross_revenue = sum(r.gross_revenue for r in commission_reports)\n         average_commission_rate = (\n             sum(r.commission_rate for r in commission_reports) / len(commission_reports)\n-            if commission_reports else 0\n-        )\n-        \n+            if commission_reports\n+            else 0\n+        )\n+\n         summary = {\n             \"period_days\": period_days,\n             \"period_start\": start_date.isoformat(),\n             \"period_end\": end_date.isoformat(),\n             \"total_restaurants\": len(commission_reports),\n             \"total_gross_revenue\": round(total_gross_revenue, 2),\n             \"total_commission\": round(total_commission, 2),\n             \"average_commission_rate\": round(average_commission_rate, 4),\n-            \"platform_earnings\": round(total_commission, 2)\n+            \"platform_earnings\": round(total_commission, 2),\n         }\n-        \n+\n         return APIResponseHelper.success(\n             data={\n                 \"summary\": summary,\n-                \"restaurant_reports\": [report.dict() for report in commission_reports]\n+                \"restaurant_reports\": [report.dict() for report in commission_reports],\n             },\n             message=f\"Commission report generated for {len(commission_reports)} restaurants\",\n             meta={\n                 \"period_days\": period_days,\n                 \"platform_id\": platform_id,\n-                \"total_commission\": total_commission\n-            }\n-        )\n-        \n+                \"total_commission\": total_commission,\n+            },\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to generate commission report: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n @router.get(\"/analytics/performance\")\n async def get_platform_performance_analytics(\n     period_days: int = Query(30, description=\"Analysis period in days\"),\n     current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"\n     Get platform-wide performance analytics\n     \"\"\"\n     try:\n         # Verify platform owner permissions\n         if current_user.role != \"platform_owner\":\n             raise FynloException(\n                 message=\"Access denied - platform owners only\",\n                 error_code=ErrorCodes.FORBIDDEN,\n-                status_code=403\n-            )\n-        \n+                status_code=403,\n+            )\n+\n         platform_id = str(current_user.platform_id)\n-        \n+\n         # Calculate date range\n         end_date = datetime.now()\n         start_date = end_date - timedelta(days=period_days)\n-        \n+\n         # Get all restaurants\n-        restaurants = db.query(Restaurant).filter(Restaurant.platform_id == platform_id).all()\n+        restaurants = (\n+            db.query(Restaurant).filter(Restaurant.platform_id == platform_id).all()\n+        )\n         restaurant_ids = [str(r.id) for r in restaurants]\n-        \n+\n         # Performance metrics\n-        total_orders = db.query(Order).filter(\n-            and_(\n-                Order.restaurant_id.in_(restaurant_ids),\n-                Order.created_at >= start_date\n-            )\n-        ).count()\n-        \n-        completed_orders = db.query(Order).filter(\n-            and_(\n-                Order.restaurant_id.in_(restaurant_ids),\n-                Order.created_at >= start_date,\n-                Order.status == \"completed\"\n-            )\n-        ).count()\n-        \n-        total_revenue = db.query(func.sum(Order.total_amount)).filter(\n-            and_(\n-                Order.restaurant_id.in_(restaurant_ids),\n-                Order.created_at >= start_date,\n-                Order.status == \"completed\"\n-            )\n-        ).scalar() or 0\n-        \n+        total_orders = (\n+            db.query(Order)\n+            .filter(\n+                and_(\n+                    Order.restaurant_id.in_(restaurant_ids),\n+                    Order.created_at >= start_date,\n+                )\n+            )\n+            .count()\n+        )\n+\n+        completed_orders = (\n+            db.query(Order)\n+            .filter(\n+                and_(\n+                    Order.restaurant_id.in_(restaurant_ids),\n+                    Order.created_at >= start_date,\n+                    Order.status == \"completed\",\n+                )\n+            )\n+            .count()\n+        )\n+\n+        total_revenue = (\n+            db.query(func.sum(Order.total_amount))\n+            .filter(\n+                and_(\n+                    Order.restaurant_id.in_(restaurant_ids),\n+                    Order.created_at >= start_date,\n+                    Order.status == \"completed\",\n+                )\n+            )\n+            .scalar()\n+            or 0\n+        )\n+\n         # Customer metrics\n-        total_customers = db.query(Customer).filter(\n-            Customer.restaurant_id.in_(restaurant_ids)\n-        ).count()\n-        \n+        total_customers = (\n+            db.query(Customer)\n+            .filter(Customer.restaurant_id.in_(restaurant_ids))\n+            .count()\n+        )\n+\n         # Calculate performance metrics\n-        order_completion_rate = (completed_orders / total_orders * 100) if total_orders > 0 else 0\n-        average_order_value = (total_revenue / completed_orders) if completed_orders > 0 else 0\n+        order_completion_rate = (\n+            (completed_orders / total_orders * 100) if total_orders > 0 else 0\n+        )\n+        average_order_value = (\n+            (total_revenue / completed_orders) if completed_orders > 0 else 0\n+        )\n         daily_average_revenue = total_revenue / period_days\n-        \n+\n         # Top performing restaurants\n         top_restaurants = []\n         for restaurant in restaurants:\n-            restaurant_revenue = db.query(func.sum(Order.total_amount)).filter(\n-                and_(\n-                    Order.restaurant_id == restaurant.id,\n-                    Order.created_at >= start_date,\n-                    Order.status == \"completed\"\n-                )\n-            ).scalar() or 0\n-            \n-            restaurant_orders = db.query(Order).filter(\n-                and_(\n-                    Order.restaurant_id == restaurant.id,\n-                    Order.created_at >= start_date\n-                )\n-            ).count()\n-            \n-            top_restaurants.append({\n-                \"restaurant_id\": str(restaurant.id),\n-                \"restaurant_name\": restaurant.name,\n-                \"revenue\": float(restaurant_revenue),\n-                \"orders\": restaurant_orders,\n-                \"avg_order_value\": float(restaurant_revenue / restaurant_orders) if restaurant_orders > 0 else 0\n-            })\n-        \n+            restaurant_revenue = (\n+                db.query(func.sum(Order.total_amount))\n+                .filter(\n+                    and_(\n+                        Order.restaurant_id == restaurant.id,\n+                        Order.created_at >= start_date,\n+                        Order.status == \"completed\",\n+                    )\n+                )\n+                .scalar()\n+                or 0\n+            )\n+\n+            restaurant_orders = (\n+                db.query(Order)\n+                .filter(\n+                    and_(\n+                        Order.restaurant_id == restaurant.id,\n+                        Order.created_at >= start_date,\n+                    )\n+                )\n+                .count()\n+            )\n+\n+            top_restaurants.append(\n+                {\n+                    \"restaurant_id\": str(restaurant.id),\n+                    \"restaurant_name\": restaurant.name,\n+                    \"revenue\": float(restaurant_revenue),\n+                    \"orders\": restaurant_orders,\n+                    \"avg_order_value\": (\n+                        float(restaurant_revenue / restaurant_orders)\n+                        if restaurant_orders > 0\n+                        else 0\n+                    ),\n+                }\n+            )\n+\n         # Sort by revenue\n         top_restaurants.sort(key=lambda x: x[\"revenue\"], reverse=True)\n-        \n+\n         performance_data = {\n             \"period_summary\": {\n                 \"period_days\": period_days,\n                 \"start_date\": start_date.isoformat(),\n-                \"end_date\": end_date.isoformat()\n+                \"end_date\": end_date.isoformat(),\n             },\n             \"key_metrics\": {\n                 \"total_revenue\": round(float(total_revenue), 2),\n                 \"total_orders\": total_orders,\n                 \"completed_orders\": completed_orders,\n                 \"order_completion_rate\": round(order_completion_rate, 2),\n                 \"average_order_value\": round(float(average_order_value), 2),\n                 \"daily_average_revenue\": round(float(daily_average_revenue), 2),\n                 \"total_customers\": total_customers,\n-                \"active_restaurants\": len([r for r in restaurants if r.is_active])\n+                \"active_restaurants\": len([r for r in restaurants if r.is_active]),\n             },\n             \"top_performing_restaurants\": top_restaurants[:5],\n             \"growth_indicators\": {\n                 \"revenue_growth\": 0.0,  # Would calculate vs previous period\n                 \"order_growth\": 0.0,\n                 \"customer_growth\": 0.0,\n-                \"restaurant_growth\": 0.0\n-            }\n+                \"restaurant_growth\": 0.0,\n+            },\n         }\n-        \n+\n         return APIResponseHelper.success(\n             data=performance_data,\n             message=\"Platform performance analytics retrieved\",\n             meta={\n                 \"platform_id\": platform_id,\n                 \"restaurants_analyzed\": len(restaurants),\n-                \"period_days\": period_days\n-            }\n-        )\n-        \n+                \"period_days\": period_days,\n+            },\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to retrieve platform analytics: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n\\ No newline at end of file\n+            status_code=500,\n+        )\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/storage_health.py\t2025-08-02 19:23:36.813658+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/storage_health.py\t2025-08-02 22:36:02.902693+00:00\n@@ -11,89 +11,79 @@\n from app.services.storage_service import storage_service\n from app.core.config import settings\n \n router = APIRouter()\n \n+\n @router.get(\"/health\")\n async def storage_health_check(current_user: User = Depends(get_current_user)):\n     \"\"\"\n     Check storage service health and configuration\n     Requires authentication to prevent information disclosure\n     \"\"\"\n-    \n+\n     # Only allow platform owners to check health\n     if current_user.role != \"platform_owner\":\n-        return APIResponseHelper.error(\n-            message=\"Access denied\",\n-            status_code=403\n-        )\n-    \n+        return APIResponseHelper.error(message=\"Access denied\", status_code=403)\n+\n     # Get health status\n     health_status = await storage_service.check_health()\n-    \n+\n     # Add configuration info (without sensitive data)\n     config_info = {\n-        'spaces_enabled': settings.ENABLE_SPACES_STORAGE,\n-        'bucket_name': settings.SPACES_BUCKET if storage_service.enabled else None,\n-        'region': settings.SPACES_REGION if storage_service.enabled else None,\n-        'cdn_configured': bool(settings.CDN_ENDPOINT),\n-        'max_file_size': f\"{settings.MAX_FILE_SIZE / (1024*1024):.1f} MB\",\n-        'allowed_file_types': settings.ALLOWED_FILE_TYPES.split(',')\n+        \"spaces_enabled\": settings.ENABLE_SPACES_STORAGE,\n+        \"bucket_name\": settings.SPACES_BUCKET if storage_service.enabled else None,\n+        \"region\": settings.SPACES_REGION if storage_service.enabled else None,\n+        \"cdn_configured\": bool(settings.CDN_ENDPOINT),\n+        \"max_file_size\": f\"{settings.MAX_FILE_SIZE / (1024*1024):.1f} MB\",\n+        \"allowed_file_types\": settings.ALLOWED_FILE_TYPES.split(\",\"),\n     }\n-    \n+\n     return APIResponseHelper.success(\n-        data={\n-            'storage_health': health_status,\n-            'configuration': config_info\n-        },\n-        message=\"Storage health check completed\"\n+        data={\"storage_health\": health_status, \"configuration\": config_info},\n+        message=\"Storage health check completed\",\n     )\n+\n \n @router.get(\"/files/count\")\n async def get_file_count(\n-    prefix: str = \"\",\n-    current_user: User = Depends(get_current_user)\n+    prefix: str = \"\", current_user: User = Depends(get_current_user)\n ):\n     \"\"\"\n     Get count of files in Spaces storage\n     \"\"\"\n-    \n+\n     # Only allow platform owners or restaurant owners\n     if current_user.role not in [\"platform_owner\", \"restaurant_owner\"]:\n-        return APIResponseHelper.error(\n-            message=\"Access denied\",\n-            status_code=403\n-        )\n-    \n+        return APIResponseHelper.error(message=\"Access denied\", status_code=403)\n+\n     if not storage_service.enabled:\n         return APIResponseHelper.error(\n-            message=\"Spaces storage not enabled\",\n-            status_code=503\n+            message=\"Spaces storage not enabled\", status_code=503\n         )\n-    \n+\n     try:\n         # Restrict prefix for non-platform owners\n         if current_user.role != \"platform_owner\":\n-            if hasattr(current_user, 'restaurant_id') and current_user.restaurant_id:\n+            if hasattr(current_user, \"restaurant_id\") and current_user.restaurant_id:\n                 # Restaurant owners see their restaurant's files\n                 prefix = f\"uploads/restaurant_{current_user.restaurant_id}/\"\n             else:\n                 # Other users see only their own files\n                 prefix = f\"uploads/user_{current_user.id}/\"\n-        \n+\n         # List files with limit to get count\n         files = await storage_service.list_files(prefix=prefix, limit=1000)\n-        \n+\n         return APIResponseHelper.success(\n             data={\n-                'file_count': len(files),\n-                'prefix': prefix,\n-                'storage_type': 'spaces' if storage_service.enabled else 'local'\n+                \"file_count\": len(files),\n+                \"prefix\": prefix,\n+                \"storage_type\": \"spaces\" if storage_service.enabled else \"local\",\n             },\n-            message=\"File count retrieved successfully\"\n+            message=\"File count retrieved successfully\",\n         )\n-        \n+\n     except Exception as e:\n         return APIResponseHelper.error(\n-            message=f\"Failed to get file count: {str(e)}\",\n-            status_code=500\n-        )\n\\ No newline at end of file\n+            message=f\"Failed to get file count: {str(e)}\", status_code=500\n+        )\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/rls_example.py\t2025-08-02 21:56:58.989734+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/rls_example.py\t2025-08-02 22:36:02.903097+00:00\n@@ -20,119 +20,140 @@\n \n @router.get(\"/orders/with-rls\")\n async def get_orders_with_rls(\n     db: Session = Depends(get_db),\n     _rls: None = Depends(set_rls_context),  # This sets RLS context automatically\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"\n     Example endpoint that uses RLS to filter orders by restaurant.\n     The RLS context is automatically set based on the current user.\n     \"\"\"\n     try:\n         # Debug: Show current RLS context\n         context = get_rls_context()\n-        \n+\n         # These queries will be automatically filtered by restaurant_id\n         # if RLS policies are enabled in PostgreSQL\n-        orders = db.query(Order).filter(Order.restaurant_id == current_user.restaurant_id).all()\n-        \n+        orders = (\n+            db.query(Order)\n+            .filter(Order.restaurant_id == current_user.restaurant_id)\n+            .all()\n+        )\n+\n         # You can also check the session variables directly\n-        current_user_id = db.execute(text(\"SELECT current_setting('app.user_id', true)\")).scalar()\n-        current_restaurant_id = db.execute(text(\"SELECT current_setting('app.restaurant_id', true)\")).scalar()\n-        \n+        current_user_id = db.execute(\n+            text(\"SELECT current_setting('app.user_id', true)\")\n+        ).scalar()\n+        current_restaurant_id = db.execute(\n+            text(\"SELECT current_setting('app.restaurant_id', true)\")\n+        ).scalar()\n+\n         return APIResponseHelper.success(\n             data={\n-                \"orders\": [{\"id\": str(o.id), \"total\": float(o.total_amount)} for o in orders],\n+                \"orders\": [\n+                    {\"id\": str(o.id), \"total\": float(o.total_amount)} for o in orders\n+                ],\n                 \"rls_context\": {\n-                    \"user_id\": context.get('user_id'),\n-                    \"restaurant_id\": context.get('restaurant_id'),\n-                    \"role\": context.get('role')\n+                    \"user_id\": context.get(\"user_id\"),\n+                    \"restaurant_id\": context.get(\"restaurant_id\"),\n+                    \"role\": context.get(\"role\"),\n                 },\n                 \"session_variables\": {\n                     \"app.user_id\": current_user_id,\n-                    \"app.restaurant_id\": current_restaurant_id\n-                }\n+                    \"app.restaurant_id\": current_restaurant_id,\n+                },\n             }\n         )\n     except Exception as e:\n         return APIResponseHelper.error(f\"Error fetching orders: {str(e)}\")\n \n \n @router.get(\"/products/count-by-restaurant\")\n async def count_products_by_restaurant(\n     db: Session = Depends(get_db),\n     _rls: None = Depends(set_rls_context),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"\n     Example showing how RLS ensures data isolation.\n     Each user only sees their restaurant's product count.\n     \"\"\"\n     # This query is automatically filtered by RLS\n-    product_count = db.query(Product).filter(\n-        Product.restaurant_id == current_user.restaurant_id\n-    ).count()\n-    \n+    product_count = (\n+        db.query(Product)\n+        .filter(Product.restaurant_id == current_user.restaurant_id)\n+        .count()\n+    )\n+\n     return APIResponseHelper.success(\n         data={\n             \"restaurant_id\": str(current_user.restaurant_id),\n             \"product_count\": product_count,\n-            \"user_role\": current_user.role\n+            \"user_role\": current_user.role,\n         }\n     )\n \n \n @router.post(\"/test-rls-isolation\")\n async def test_rls_isolation(\n     db: Session = Depends(get_db),\n     _rls: None = Depends(set_rls_context),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"\n     Test endpoint to verify RLS isolation is working correctly.\n     This creates a test query and verifies session variables.\n     \"\"\"\n     try:\n         # Get current session variables\n-        session_info = db.execute(text(\"\"\"\n+        session_info = db.execute(\n+            text(\n+                \"\"\"\n             SELECT \n                 current_setting('app.user_id', true) as user_id,\n                 current_setting('app.restaurant_id', true) as restaurant_id,\n                 current_setting('app.user_role', true) as user_role,\n                 pg_backend_pid() as connection_pid\n-        \"\"\")).first()\n-        \n+        \"\"\"\n+            )\n+        ).first()\n+\n         # Verify they match the current user\n         assert session_info.user_id == str(current_user.id), \"User ID mismatch\"\n-        assert session_info.restaurant_id == str(current_user.restaurant_id), \"Restaurant ID mismatch\"\n+        assert session_info.restaurant_id == str(\n+            current_user.restaurant_id\n+        ), \"Restaurant ID mismatch\"\n         assert session_info.user_role == current_user.role, \"Role mismatch\"\n-        \n+\n         return APIResponseHelper.success(\n             data={\n                 \"status\": \"RLS isolation verified\",\n                 \"session_variables\": {\n                     \"user_id\": session_info.user_id,\n                     \"restaurant_id\": session_info.restaurant_id,\n                     \"role\": session_info.user_role,\n-                    \"connection_pid\": session_info.connection_pid\n+                    \"connection_pid\": session_info.connection_pid,\n                 },\n                 \"expected_values\": {\n                     \"user_id\": str(current_user.id),\n                     \"restaurant_id\": str(current_user.restaurant_id),\n-                    \"role\": current_user.role\n-                }\n+                    \"role\": current_user.role,\n+                },\n             }\n         )\n     except AssertionError as e:\n-        return APIResponseHelper.error(f\"RLS isolation check failed: {str(e)}\", status_code=500)\n+        return APIResponseHelper.error(\n+            f\"RLS isolation check failed: {str(e)}\", status_code=500\n+        )\n     except Exception as e:\n         return APIResponseHelper.error(f\"Error testing RLS: {str(e)}\", status_code=500)\n \n \n # Example of using RLS in a background task\n from app.middleware.rls_middleware import with_rls_context\n+\n \n @with_rls_context(restaurant_id=\"specific-restaurant-id\")\n async def process_restaurant_orders():\n     \"\"\"\n     Background task that processes orders for a specific restaurant.\n@@ -142,6 +163,6 @@\n     try:\n         orders = db.query(Order).filter(Order.status == \"pending\").all()\n         # Process orders...\n         return len(orders)\n     finally:\n-        db.close()\n\\ No newline at end of file\n+        db.close()\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/restaurant_switch.py\t2025-08-02 21:56:58.989325+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/restaurant_switch.py\t2025-08-02 22:36:02.902314+00:00\n@@ -21,123 +21,132 @@\n router = APIRouter()\n \n \n @router.get(\"/my-restaurants\")\n async def get_my_restaurants(\n-    current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    current_user: User = Depends(get_current_user), db: Session = Depends(get_db)\n ):\n     \"\"\"\n     Get all restaurants accessible by the current user\n     Only restaurant owners see multiple restaurants\n     \"\"\"\n     # Platform owners don't need this endpoint\n     if TenantSecurity.is_platform_owner(current_user):\n         return APIResponseHelper.error(\n             message=\"Platform owners should use the platform dashboard\",\n-            status_code=status.HTTP_400_BAD_REQUEST\n-        )\n-    \n+            status_code=status.HTTP_400_BAD_REQUEST,\n+        )\n+\n     # Only restaurant owners can have multiple restaurants\n     if current_user.role != \"restaurant_owner\":\n         # Employees/managers only see their assigned restaurant\n         if current_user.restaurant_id:\n-            restaurant = db.query(Restaurant).filter(\n-                Restaurant.id == current_user.restaurant_id\n-            ).first()\n-            \n+            restaurant = (\n+                db.query(Restaurant)\n+                .filter(Restaurant.id == current_user.restaurant_id)\n+                .first()\n+            )\n+\n             if restaurant:\n                 return APIResponseHelper.success(\n                     data={\n-                        \"restaurants\": [{\n-                            \"id\": str(restaurant.id),\n-                            \"name\": restaurant.name,\n-                            \"is_current\": True,\n-                            \"is_primary\": True,\n-                            \"subscription_plan\": restaurant.subscription_plan,\n-                            \"subscription_status\": restaurant.subscription_status\n-                        }],\n+                        \"restaurants\": [\n+                            {\n+                                \"id\": str(restaurant.id),\n+                                \"name\": restaurant.name,\n+                                \"is_current\": True,\n+                                \"is_primary\": True,\n+                                \"subscription_plan\": restaurant.subscription_plan,\n+                                \"subscription_status\": restaurant.subscription_status,\n+                            }\n+                        ],\n                         \"can_switch\": False,\n-                        \"total\": 1\n+                        \"total\": 1,\n                     }\n                 )\n-        \n+\n         return APIResponseHelper.success(\n-            data={\n-                \"restaurants\": [],\n-                \"can_switch\": False,\n-                \"total\": 0\n-            }\n-        )\n-    \n+            data={\"restaurants\": [], \"can_switch\": False, \"total\": 0}\n+        )\n+\n     # Get all restaurants for this owner\n-    user_restaurants = db.query(UserRestaurant).filter(\n-        UserRestaurant.user_id == current_user.id\n-    ).all()\n-    \n+    user_restaurants = (\n+        db.query(UserRestaurant).filter(UserRestaurant.user_id == current_user.id).all()\n+    )\n+\n     restaurants = []\n-    current_restaurant_id = str(current_user.current_restaurant_id) if current_user.current_restaurant_id else None\n-    \n+    current_restaurant_id = (\n+        str(current_user.current_restaurant_id)\n+        if current_user.current_restaurant_id\n+        else None\n+    )\n+\n     # Add restaurants from user_restaurants table\n     for ur in user_restaurants:\n-        restaurant = db.query(Restaurant).filter(\n-            Restaurant.id == ur.restaurant_id\n-        ).first()\n-        \n+        restaurant = (\n+            db.query(Restaurant).filter(Restaurant.id == ur.restaurant_id).first()\n+        )\n+\n         if restaurant:\n-            restaurants.append({\n-                \"id\": str(restaurant.id),\n-                \"name\": restaurant.name,\n-                \"is_current\": str(restaurant.id) == current_restaurant_id,\n-                \"is_primary\": ur.is_primary,\n-                \"role\": ur.role,\n-                \"subscription_plan\": restaurant.subscription_plan,\n-                \"subscription_status\": restaurant.subscription_status,\n-                \"address\": restaurant.address,\n-                \"phone\": restaurant.phone\n-            })\n-    \n+            restaurants.append(\n+                {\n+                    \"id\": str(restaurant.id),\n+                    \"name\": restaurant.name,\n+                    \"is_current\": str(restaurant.id) == current_restaurant_id,\n+                    \"is_primary\": ur.is_primary,\n+                    \"role\": ur.role,\n+                    \"subscription_plan\": restaurant.subscription_plan,\n+                    \"subscription_status\": restaurant.subscription_status,\n+                    \"address\": restaurant.address,\n+                    \"phone\": restaurant.phone,\n+                }\n+            )\n+\n     # Also check legacy restaurant_id field\n     if current_user.restaurant_id:\n         # Check if this restaurant is already in the list\n         legacy_id = str(current_user.restaurant_id)\n         if not any(r[\"id\"] == legacy_id for r in restaurants):\n-            restaurant = db.query(Restaurant).filter(\n-                Restaurant.id == current_user.restaurant_id\n-            ).first()\n-            \n+            restaurant = (\n+                db.query(Restaurant)\n+                .filter(Restaurant.id == current_user.restaurant_id)\n+                .first()\n+            )\n+\n             if restaurant:\n-                restaurants.append({\n-                    \"id\": str(restaurant.id),\n-                    \"name\": restaurant.name,\n-                    \"is_current\": str(restaurant.id) == current_restaurant_id,\n-                    \"is_primary\": True,  # Legacy assignment is primary\n-                    \"role\": \"owner\",\n-                    \"subscription_plan\": restaurant.subscription_plan,\n-                    \"subscription_status\": restaurant.subscription_status,\n-                    \"address\": restaurant.address,\n-                    \"phone\": restaurant.phone\n-                })\n-    \n+                restaurants.append(\n+                    {\n+                        \"id\": str(restaurant.id),\n+                        \"name\": restaurant.name,\n+                        \"is_current\": str(restaurant.id) == current_restaurant_id,\n+                        \"is_primary\": True,  # Legacy assignment is primary\n+                        \"role\": \"owner\",\n+                        \"subscription_plan\": restaurant.subscription_plan,\n+                        \"subscription_status\": restaurant.subscription_status,\n+                        \"address\": restaurant.address,\n+                        \"phone\": restaurant.phone,\n+                    }\n+                )\n+\n     # Only show switching option if user has multiple restaurants\n     can_switch = len(restaurants) > 1\n-    \n+\n     return APIResponseHelper.success(\n         data={\n             \"restaurants\": restaurants,\n             \"can_switch\": can_switch,\n             \"total\": len(restaurants),\n-            \"current_restaurant_id\": current_restaurant_id\n+            \"current_restaurant_id\": current_restaurant_id,\n         }\n     )\n \n \n @router.post(\"/switch/{restaurant_id}\")\n async def switch_restaurant(\n     restaurant_id: str,\n     current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"\n     Switch to a different restaurant\n     Only restaurant owners with multiple restaurants can switch\n     \"\"\"\n@@ -145,219 +154,234 @@\n     try:\n         validate_uuid_format(restaurant_id)\n     except ValueError:\n         return APIResponseHelper.error(\n             message=\"Invalid restaurant ID format\",\n-            status_code=status.HTTP_400_BAD_REQUEST\n-        )\n-    \n+            status_code=status.HTTP_400_BAD_REQUEST,\n+        )\n+\n     # Only restaurant owners can switch\n     if current_user.role != \"restaurant_owner\":\n         return APIResponseHelper.error(\n             message=\"Only restaurant owners can switch between restaurants\",\n-            status_code=status.HTTP_403_FORBIDDEN\n-        )\n-    \n+            status_code=status.HTTP_403_FORBIDDEN,\n+        )\n+\n     # Verify user has access to the target restaurant\n     has_access = False\n-    \n+\n     # Check user_restaurants table\n-    user_restaurant = db.query(UserRestaurant).filter(\n-        UserRestaurant.user_id == current_user.id,\n-        UserRestaurant.restaurant_id == restaurant_id\n-    ).first()\n-    \n+    user_restaurant = (\n+        db.query(UserRestaurant)\n+        .filter(\n+            UserRestaurant.user_id == current_user.id,\n+            UserRestaurant.restaurant_id == restaurant_id,\n+        )\n+        .first()\n+    )\n+\n     if user_restaurant:\n         has_access = True\n-    \n+\n     # Check legacy restaurant_id\n-    elif current_user.restaurant_id and str(current_user.restaurant_id) == restaurant_id:\n+    elif (\n+        current_user.restaurant_id and str(current_user.restaurant_id) == restaurant_id\n+    ):\n         has_access = True\n-    \n+\n     if not has_access:\n         # Log unauthorized switch attempt\n         await security_monitor.log_access_attempt(\n             user=current_user,\n             resource_type=\"restaurant_switch\",\n             resource_id=restaurant_id,\n             action=\"switch\",\n             granted=False,\n             ip_address=\"api\",\n-            reason=\"User does not have access to target restaurant\"\n-        )\n-        \n+            reason=\"User does not have access to target restaurant\",\n+        )\n+\n         return APIResponseHelper.error(\n             message=\"You don't have access to this restaurant\",\n-            status_code=status.HTTP_403_FORBIDDEN\n-        )\n-    \n+            status_code=status.HTTP_403_FORBIDDEN,\n+        )\n+\n     # Get restaurant details\n-    restaurant = db.query(Restaurant).filter(\n-        Restaurant.id == restaurant_id\n-    ).first()\n-    \n+    restaurant = db.query(Restaurant).filter(Restaurant.id == restaurant_id).first()\n+\n     if not restaurant:\n         return APIResponseHelper.error(\n-            message=\"Restaurant not found\",\n-            status_code=status.HTTP_404_NOT_FOUND\n-        )\n-    \n+            message=\"Restaurant not found\", status_code=status.HTTP_404_NOT_FOUND\n+        )\n+\n     # Update current restaurant with proper locking\n     old_restaurant_id = current_user.current_restaurant_id\n-    \n+\n     try:\n         # Use with_for_update() for row-level locking to prevent race conditions\n-        locked_user = db.query(User).filter(\n-            User.id == current_user.id\n-        ).with_for_update().first()\n-        \n+        locked_user = (\n+            db.query(User).filter(User.id == current_user.id).with_for_update().first()\n+        )\n+\n         if not locked_user:\n             return APIResponseHelper.error(\n-                message=\"User not found\",\n-                status_code=status.HTTP_404_NOT_FOUND\n-            )\n-        \n+                message=\"User not found\", status_code=status.HTTP_404_NOT_FOUND\n+            )\n+\n         locked_user.current_restaurant_id = restaurant_id\n         locked_user.last_restaurant_switch = datetime.utcnow()\n-        \n+\n         db.commit()\n-        \n+\n         # Log successful switch\n         await security_monitor.log_event(\n             user=current_user,\n             event_type=\"restaurant_switch\",\n             details={\n-                \"from_restaurant_id\": str(old_restaurant_id) if old_restaurant_id else None,\n+                \"from_restaurant_id\": (\n+                    str(old_restaurant_id) if old_restaurant_id else None\n+                ),\n                 \"to_restaurant_id\": restaurant_id,\n-                \"restaurant_name\": restaurant.name\n-            }\n-        )\n-        \n+                \"restaurant_name\": restaurant.name,\n+            },\n+        )\n+\n         return APIResponseHelper.success(\n             data={\n                 \"message\": f\"Successfully switched to {restaurant.name}\",\n                 \"restaurant\": {\n                     \"id\": str(restaurant.id),\n                     \"name\": restaurant.name,\n                     \"subscription_plan\": restaurant.subscription_plan,\n-                    \"subscription_status\": restaurant.subscription_status\n-                }\n+                    \"subscription_status\": restaurant.subscription_status,\n+                },\n             }\n         )\n-        \n+\n     except Exception as e:\n         db.rollback()\n         await security_monitor.log_event(\n             user=current_user,\n             event_type=SecurityEventType.ERROR,\n             details={\n                 \"error\": \"Failed to switch restaurant\",\n                 \"restaurant_id\": restaurant_id,\n-                \"exception\": str(e)\n-            }\n+                \"exception\": str(e),\n+            },\n         )\n         return APIResponseHelper.error(\n             message=\"Failed to switch restaurant\",\n-            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR\n+            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n         )\n \n \n @router.post(\"/assign-restaurant\")\n async def assign_restaurant_to_user(\n     user_id: str,\n     restaurant_id: str,\n     role: str = \"employee\",\n     current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"\n     Assign a restaurant to a user (multi-restaurant support)\n     Only restaurant owners can assign their restaurants to other users\n     \"\"\"\n     # Validate role\n     valid_roles = [\"owner\", \"manager\", \"employee\"]\n     if role not in valid_roles:\n         return APIResponseHelper.error(\n             message=f\"Invalid role. Must be one of: {', '.join(valid_roles)}\",\n-            status_code=status.HTTP_400_BAD_REQUEST\n-        )\n-    \n+            status_code=status.HTTP_400_BAD_REQUEST,\n+        )\n+\n     # Only restaurant owners and platform owners can assign restaurants\n     if current_user.role not in [\"restaurant_owner\", \"platform_owner\"]:\n         return APIResponseHelper.error(\n             message=\"Only restaurant owners can assign restaurants to users\",\n-            status_code=status.HTTP_403_FORBIDDEN\n-        )\n-    \n+            status_code=status.HTTP_403_FORBIDDEN,\n+        )\n+\n     # Verify current user has access to this restaurant\n     if not TenantSecurity.is_platform_owner(current_user):\n         has_access = False\n-        \n+\n         # Check if user owns this restaurant\n-        owner_restaurant = db.query(UserRestaurant).filter(\n-            UserRestaurant.user_id == current_user.id,\n-            UserRestaurant.restaurant_id == restaurant_id,\n-            UserRestaurant.role == \"owner\"\n-        ).first()\n-        \n-        if owner_restaurant or (current_user.restaurant_id and str(current_user.restaurant_id) == restaurant_id):\n+        owner_restaurant = (\n+            db.query(UserRestaurant)\n+            .filter(\n+                UserRestaurant.user_id == current_user.id,\n+                UserRestaurant.restaurant_id == restaurant_id,\n+                UserRestaurant.role == \"owner\",\n+            )\n+            .first()\n+        )\n+\n+        if owner_restaurant or (\n+            current_user.restaurant_id\n+            and str(current_user.restaurant_id) == restaurant_id\n+        ):\n             has_access = True\n-        \n+\n         if not has_access:\n             return APIResponseHelper.error(\n                 message=\"You can only assign users to restaurants you own\",\n-                status_code=status.HTTP_403_FORBIDDEN\n-            )\n-    \n+                status_code=status.HTTP_403_FORBIDDEN,\n+            )\n+\n     # Check if assignment already exists\n-    existing = db.query(UserRestaurant).filter(\n-        UserRestaurant.user_id == user_id,\n-        UserRestaurant.restaurant_id == restaurant_id\n-    ).first()\n-    \n+    existing = (\n+        db.query(UserRestaurant)\n+        .filter(\n+            UserRestaurant.user_id == user_id,\n+            UserRestaurant.restaurant_id == restaurant_id,\n+        )\n+        .first()\n+    )\n+\n     if existing:\n         return APIResponseHelper.error(\n             message=\"User is already assigned to this restaurant\",\n-            status_code=status.HTTP_400_BAD_REQUEST\n-        )\n-    \n+            status_code=status.HTTP_400_BAD_REQUEST,\n+        )\n+\n     # Create new assignment\n     new_assignment = UserRestaurant(\n         user_id=user_id,\n         restaurant_id=restaurant_id,\n         role=role,\n         assigned_by=current_user.id,\n-        is_primary=False  # New assignments are not primary by default\n-    )\n-    \n+        is_primary=False,  # New assignments are not primary by default\n+    )\n+\n     try:\n         db.add(new_assignment)\n         db.commit()\n-        \n+\n         # Log assignment\n         await security_monitor.log_event(\n             user=current_user,\n             event_type=\"restaurant_assignment\",\n             details={\n                 \"assigned_user_id\": user_id,\n                 \"restaurant_id\": restaurant_id,\n-                \"role\": role\n-            }\n-        )\n-        \n+                \"role\": role,\n+            },\n+        )\n+\n         return APIResponseHelper.success(\n             data={\n                 \"message\": \"User successfully assigned to restaurant\",\n                 \"assignment\": {\n                     \"user_id\": user_id,\n                     \"restaurant_id\": restaurant_id,\n-                    \"role\": role\n-                }\n+                    \"role\": role,\n+                },\n             }\n         )\n-        \n+\n     except Exception as e:\n         db.rollback()\n         return APIResponseHelper.error(\n             message=\"Failed to assign user to restaurant\",\n-            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR\n-        )\n\\ No newline at end of file\n+            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n+        )\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/secure_payment_provider_management.py\t2025-08-02 19:23:36.813010+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/secure_payment_provider_management.py\t2025-08-02 22:36:02.921212+00:00\n@@ -23,17 +23,19 @@\n @router.post(\"/payment-providers/configure\")\n async def configure_payment_provider(\n     provider: str,\n     credentials: Dict[str, Any],\n     mode: str = \"sandbox\",\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Restaurant ID for multi-location owners\"),\n-    current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Restaurant ID for multi-location owners\"\n+    ),\n+    current_user: User = Depends(get_current_user),\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"\n     Configure a payment provider for the restaurant\n-    \n+\n     Args:\n         provider: Provider name (stripe, square, sumup)\n         credentials: Provider-specific credentials\n         mode: sandbox or production\n     \"\"\"\n@@ -41,272 +43,285 @@\n         # Validate restaurant access for multi-tenant\n         await TenantSecurity.validate_restaurant_access(\n             current_user, current_restaurant_id or current_user.restaurant_id, db=db\n         )\n         restaurant_id = current_restaurant_id or current_user.restaurant_id\n-        \n+\n         # Check user permissions\n-        if current_user.role not in ['platform_owner', 'restaurant_owner']:\n-            raise AuthorizationException(message=\"Only owners can configure payment providers\")\n-        \n+        if current_user.role not in [\"platform_owner\", \"restaurant_owner\"]:\n+            raise AuthorizationException(\n+                message=\"Only owners can configure payment providers\"\n+            )\n+\n         # Initialize config service\n         config_service = SecurePaymentConfigService(db)\n-        \n+\n         # Store provider configuration\n         config_id = config_service.store_provider_config(\n             provider=provider,\n             restaurant_id=restaurant_id,\n             credentials=credentials,\n-            mode=mode\n-        )\n-        \n+            mode=mode,\n+        )\n+\n         return APIResponseHelper.success(\n             data={\n-                'config_id': config_id,\n-                'provider': provider,\n-                'mode': mode,\n-                'message': f'{provider.capitalize()} configuration stored securely'\n+                \"config_id\": config_id,\n+                \"provider\": provider,\n+                \"mode\": mode,\n+                \"message\": f\"{provider.capitalize()} configuration stored securely\",\n             },\n-            message=\"Payment provider configured successfully\"\n-        )\n-        \n+            message=\"Payment provider configured successfully\",\n+        )\n+\n     except Exception as e:\n         return APIResponseHelper.error(\n             message=f\"Failed to configure payment provider: {str(e)}\",\n-            status_code=status.HTTP_400_BAD_REQUEST\n+            status_code=status.HTTP_400_BAD_REQUEST,\n         )\n \n \n @router.get(\"/payment-providers\")\n async def list_payment_providers(\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Restaurant ID for multi-location owners\"),\n-    current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Restaurant ID for multi-location owners\"\n+    ),\n+    current_user: User = Depends(get_current_user),\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Get all configured payment providers for the restaurant\"\"\"\n     try:\n         # Validate restaurant access for multi-tenant\n         await TenantSecurity.validate_restaurant_access(\n             current_user, current_restaurant_id or current_user.restaurant_id, db=db\n         )\n         restaurant_id = current_restaurant_id or current_user.restaurant_id\n-        \n+\n         config_service = SecurePaymentConfigService(db)\n-        \n+\n         # Get provider configurations\n         configs = config_service.list_provider_configs(restaurant_id)\n-        \n+\n         # Initialize provider factory\n         factory = PaymentProviderFactory()\n         await factory.initialize(restaurant_id)\n-        \n+\n         # Get provider info\n         provider_info = factory.get_provider_info()\n-        \n+\n         # Combine configuration and runtime info\n         providers = []\n         for config in configs:\n-            info = provider_info.get(config['provider'], {})\n-            providers.append({\n-                'provider': config['provider'],\n-                'enabled': config['enabled'],\n-                'mode': config['mode'],\n-                'configured_at': config['configured_at'],\n-                'available': info.get('available', False),\n-                'supported_currencies': info.get('supported_currencies', []),\n-                'supported_methods': info.get('supported_methods', []),\n-                'fee_structure': _get_fee_structure(config['provider'])\n-            })\n-        \n-        return APIResponseHelper.success(\n-            data={'providers': providers},\n-            message=\"Payment providers retrieved successfully\"\n-        )\n-        \n+            info = provider_info.get(config[\"provider\"], {})\n+            providers.append(\n+                {\n+                    \"provider\": config[\"provider\"],\n+                    \"enabled\": config[\"enabled\"],\n+                    \"mode\": config[\"mode\"],\n+                    \"configured_at\": config[\"configured_at\"],\n+                    \"available\": info.get(\"available\", False),\n+                    \"supported_currencies\": info.get(\"supported_currencies\", []),\n+                    \"supported_methods\": info.get(\"supported_methods\", []),\n+                    \"fee_structure\": _get_fee_structure(config[\"provider\"]),\n+                }\n+            )\n+\n+        return APIResponseHelper.success(\n+            data={\"providers\": providers},\n+            message=\"Payment providers retrieved successfully\",\n+        )\n+\n     except Exception as e:\n         return APIResponseHelper.error(\n             message=f\"Failed to retrieve payment providers: {str(e)}\",\n-            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR\n+            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n         )\n \n \n @router.post(\"/payment-providers/{provider}/test\")\n async def test_payment_provider(\n     provider: str,\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Restaurant ID for multi-location owners\"),\n-    current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Restaurant ID for multi-location owners\"\n+    ),\n+    current_user: User = Depends(get_current_user),\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Test a payment provider connection\"\"\"\n     try:\n         # Validate restaurant access for multi-tenant\n         await TenantSecurity.validate_restaurant_access(\n             current_user, current_restaurant_id or current_user.restaurant_id, db=db\n         )\n         restaurant_id = current_restaurant_id or current_user.restaurant_id\n-        \n+\n         # Check permissions\n-        if current_user.role not in ['platform_owner', 'restaurant_owner', 'manager']:\n+        if current_user.role not in [\"platform_owner\", \"restaurant_owner\", \"manager\"]:\n             raise AuthorizationException(message=\"Insufficient permissions\")\n-        \n+\n         # Initialize provider factory\n         factory = PaymentProviderFactory()\n         await factory.initialize(restaurant_id)\n-        \n+\n         # Get the specific provider\n         provider_instance = await factory.get_provider(provider)\n-        \n+\n         if not provider_instance:\n             return APIResponseHelper.error(\n                 message=f\"Provider {provider} not configured\",\n-                status_code=status.HTTP_404_NOT_FOUND\n-            )\n-        \n+                status_code=status.HTTP_404_NOT_FOUND,\n+            )\n+\n         # Test the connection\n         test_result = await provider_instance.test_connection()\n-        \n-        return APIResponseHelper.success(\n-            data=test_result,\n-            message=f\"Provider {provider} test completed\"\n-        )\n-        \n+\n+        return APIResponseHelper.success(\n+            data=test_result, message=f\"Provider {provider} test completed\"\n+        )\n+\n     except Exception as e:\n         return APIResponseHelper.error(\n             message=f\"Provider test failed: {str(e)}\",\n-            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR\n+            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n         )\n \n \n @router.post(\"/payment-providers/{provider}/calculate-fee\")\n async def calculate_provider_fee(\n     provider: str,\n     amount: Decimal,\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Restaurant ID for multi-location owners\"),\n-    current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Restaurant ID for multi-location owners\"\n+    ),\n+    current_user: User = Depends(get_current_user),\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Calculate fees for a specific provider and amount\"\"\"\n     try:\n         # Validate restaurant access for multi-tenant\n         await TenantSecurity.validate_restaurant_access(\n             current_user, current_restaurant_id or current_user.restaurant_id, db=db\n         )\n         restaurant_id = current_restaurant_id or current_user.restaurant_id\n-        \n+\n         # Initialize provider factory\n         factory = PaymentProviderFactory()\n         await factory.initialize(restaurant_id)\n-        \n+\n         # Get the specific provider\n         provider_instance = await factory.get_provider(provider)\n-        \n+\n         if not provider_instance:\n             return APIResponseHelper.error(\n                 message=f\"Provider {provider} not configured\",\n-                status_code=status.HTTP_404_NOT_FOUND\n-            )\n-        \n+                status_code=status.HTTP_404_NOT_FOUND,\n+            )\n+\n         # Calculate fee\n         fee = provider_instance.calculate_fee(amount)\n         net_amount = amount - fee\n-        \n+\n         return APIResponseHelper.success(\n             data={\n-                'provider': provider,\n-                'amount': float(amount),\n-                'fee': float(fee),\n-                'net_amount': float(net_amount),\n-                'fee_percentage': float(fee / amount * 100) if amount > 0 else 0\n+                \"provider\": provider,\n+                \"amount\": float(amount),\n+                \"fee\": float(fee),\n+                \"net_amount\": float(net_amount),\n+                \"fee_percentage\": float(fee / amount * 100) if amount > 0 else 0,\n             },\n-            message=\"Fee calculated successfully\"\n-        )\n-        \n+            message=\"Fee calculated successfully\",\n+        )\n+\n     except Exception as e:\n         return APIResponseHelper.error(\n             message=f\"Failed to calculate fee: {str(e)}\",\n-            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR\n+            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n         )\n \n \n @router.get(\"/payment-providers/best-provider\")\n async def get_best_provider(\n     amount: Decimal,\n     payment_method: str = \"card\",\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Restaurant ID for multi-location owners\"),\n-    current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Restaurant ID for multi-location owners\"\n+    ),\n+    current_user: User = Depends(get_current_user),\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Get the best provider for a transaction based on fees and performance\"\"\"\n     try:\n         # Validate restaurant access for multi-tenant\n         await TenantSecurity.validate_restaurant_access(\n             current_user, current_restaurant_id or current_user.restaurant_id, db=db\n         )\n         restaurant_id = current_restaurant_id or current_user.restaurant_id\n-        \n+\n         # Initialize provider factory\n         factory = PaymentProviderFactory()\n         await factory.initialize(restaurant_id)\n-        \n+\n         # Get best provider\n         best_provider = await factory.get_best_provider(\n-            amount=amount,\n-            payment_method=payment_method\n-        )\n-        \n+            amount=amount, payment_method=payment_method\n+        )\n+\n         if not best_provider:\n             return APIResponseHelper.error(\n                 message=\"No suitable payment provider found\",\n-                status_code=status.HTTP_404_NOT_FOUND\n-            )\n-        \n+                status_code=status.HTTP_404_NOT_FOUND,\n+            )\n+\n         # Calculate fee for best provider\n         fee = best_provider.calculate_fee(amount)\n-        \n+\n         return APIResponseHelper.success(\n             data={\n-                'provider': best_provider.provider_name,\n-                'amount': float(amount),\n-                'fee': float(fee),\n-                'net_amount': float(amount - fee),\n-                'fee_percentage': float(fee / amount * 100) if amount > 0 else 0,\n-                'reason': 'Lowest fees with best performance'\n+                \"provider\": best_provider.provider_name,\n+                \"amount\": float(amount),\n+                \"fee\": float(fee),\n+                \"net_amount\": float(amount - fee),\n+                \"fee_percentage\": float(fee / amount * 100) if amount > 0 else 0,\n+                \"reason\": \"Lowest fees with best performance\",\n             },\n-            message=\"Best provider determined successfully\"\n-        )\n-        \n+            message=\"Best provider determined successfully\",\n+        )\n+\n     except Exception as e:\n         return APIResponseHelper.error(\n             message=f\"Failed to determine best provider: {str(e)}\",\n-            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR\n+            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n         )\n \n \n def _get_fee_structure(provider: str) -> Dict[str, Any]:\n     \"\"\"Get fee structure for a provider\"\"\"\n     fee_structures = {\n-        'stripe': {\n-            'percentage': 1.4,\n-            'fixed_fee': 0.20,\n-            'currency': 'GBP',\n-            'description': '1.4% + \u00a30.20 per transaction'\n+        \"stripe\": {\n+            \"percentage\": 1.4,\n+            \"fixed_fee\": 0.20,\n+            \"currency\": \"GBP\",\n+            \"description\": \"1.4% + \u00a30.20 per transaction\",\n         },\n-        'square': {\n-            'percentage': 1.75,\n-            'fixed_fee': 0,\n-            'currency': 'GBP',\n-            'description': '1.75% per transaction'\n+        \"square\": {\n+            \"percentage\": 1.75,\n+            \"fixed_fee\": 0,\n+            \"currency\": \"GBP\",\n+            \"description\": \"1.75% per transaction\",\n         },\n-        'sumup': {\n-            'percentage': 1.69,\n-            'fixed_fee': 0,\n-            'currency': 'GBP',\n-            'description': '1.69% per transaction (online)'\n-        }\n+        \"sumup\": {\n+            \"percentage\": 1.69,\n+            \"fixed_fee\": 0,\n+            \"currency\": \"GBP\",\n+            \"description\": \"1.69% per transaction (online)\",\n+        },\n     }\n-    \n-    return fee_structures.get(provider, {\n-        'percentage': 2.9,\n-        'fixed_fee': 0,\n-        'currency': 'GBP',\n-        'description': 'Standard rate'\n-    })\n\\ No newline at end of file\n+\n+    return fee_structures.get(\n+        provider,\n+        {\n+            \"percentage\": 2.9,\n+            \"fixed_fee\": 0,\n+            \"currency\": \"GBP\",\n+            \"description\": \"Standard rate\",\n+        },\n+    )\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/tips.py\t2025-08-02 22:07:19.188234+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/tips.py\t2025-08-02 22:36:02.935379+00:00\n@@ -2,68 +2,89 @@\n from sqlalchemy.orm import Session\n from typing import List, Optional\n \n from app.core.database import get_db\n from app.core.exceptions import FynloException, ValidationException\n-from app.schemas.fee_schemas import StaffMember, StaffTipDistribution, StaffTipDistributionRecordSchema\n+from app.schemas.fee_schemas import (\n+    StaffMember,\n+    StaffTipDistribution,\n+    StaffTipDistributionRecordSchema,\n+)\n from app.services.staff_tip_service import StaffTipService\n-from app.models.financial_records import StaffTipDistributionRecord # For ORM response conversion\n+from app.models.financial_records import (\n+    StaffTipDistributionRecord,\n+)  # For ORM response conversion\n from pydantic import BaseModel, Field\n \n router = APIRouter()\n+\n \n # --- Dependency for Service ---\n def get_staff_tip_service_dep(db: Session = Depends(get_db)) -> StaffTipService:\n     \"\"\"Execute get_staff_tip_service_dep operation.\"\"\"\n     return StaffTipService(db=db)\n \n+\n # --- Pydantic Models for Input/Output ---\n class TipDistributionRequestInput(BaseModel):\n     total_tips_collected: float = Field(..., ge=0)\n     service_charge_amount_on_order: float = Field(..., ge=0)\n     processor_fee_covered_by_service_charge: float = Field(..., ge=0)\n-    assigned_staff: List[StaffMember] # List of {'id': str, 'name': str}\n+    assigned_staff: List[StaffMember]  # List of {'id': str, 'name': str}\n     tip_distribution_strategy: Optional[str] = \"equal_split\"\n \n+\n # Helper to convert DB model to response schema\n-def convert_db_tip_dist_to_schema(record: StaffTipDistributionRecord) -> StaffTipDistributionRecordSchema:\n+def convert_db_tip_dist_to_schema(\n+    record: StaffTipDistributionRecord,\n+) -> StaffTipDistributionRecordSchema:\n     \"\"\"Execute convert_db_tip_dist_to_schema operation.\"\"\"\n     return StaffTipDistributionRecordSchema(\n         id=record.id,\n-        order_id=record.order_reference, # Maps from order_reference\n+        order_id=record.order_reference,  # Maps from order_reference\n         staff_id=record.staff_id,\n         tip_amount_gross=float(record.tip_amount_gross),\n         service_charge_deduction=float(record.service_charge_deduction),\n         transaction_fee_impact_on_tip=float(record.transaction_fee_impact_on_tip),\n         tip_amount_net=float(record.tip_amount_net),\n-        distribution_timestamp=record.distribution_timestamp.isoformat()\n+        distribution_timestamp=record.distribution_timestamp.isoformat(),\n     )\n \n \n # --- API Endpoints ---\n \n-@router.post(\"/orders/{order_reference}/distribute-tips\", response_model=List[StaffTipDistribution])\n+\n+@router.post(\n+    \"/orders/{order_reference}/distribute-tips\",\n+    response_model=List[StaffTipDistribution],\n+)\n def trigger_tip_distribution(\n-    order_reference: str = Path(..., description=\"The reference ID of the order for which tips are being distributed.\"),\n+    order_reference: str = Path(\n+        ...,\n+        description=\"The reference ID of the order for which tips are being distributed.\",\n+    ),\n     request_data: TipDistributionRequestInput = Body(...),\n-    service: StaffTipService = Depends(get_staff_tip_service_dep)\n+    service: StaffTipService = Depends(get_staff_tip_service_dep),\n ):\n     \"\"\"\n     Distributes tips for a given order to the assigned staff members and records the distribution.\n     Returns the breakdown of how tips were allocated per staff member.\n     \"\"\"\n     if not request_data.assigned_staff and request_data.total_tips_collected > 0:\n-        raise ValidationException(message=\"Cannot distribute tips: No staff members assigned to the order.\")\n+        raise ValidationException(\n+            message=\"Cannot distribute tips: No staff members assigned to the order.\"\n+        )\n \n     try:\n         distributions = service.distribute_order_tips(\n             order_reference=order_reference,\n             total_tips_collected=request_data.total_tips_collected,\n             service_charge_amount_on_order=request_data.service_charge_amount_on_order,\n             processor_fee_covered_by_service_charge=request_data.processor_fee_covered_by_service_charge,\n             assigned_staff=request_data.assigned_staff,\n-            tip_distribution_strategy=request_data.tip_distribution_strategy or \"equal_split\"\n+            tip_distribution_strategy=request_data.tip_distribution_strategy\n+            or \"equal_split\",\n         )\n         # The service's distribute_order_tips already returns List[StaffTipDistribution]\n         # which matches the response_model.\n         return distributions\n     except ValueError as ve:\n@@ -71,37 +92,43 @@\n     except Exception as e:\n         # logger.error(f\"Error distributing tips for order {order_reference}: {e}\", exc_info=True)\n         raise FynloException(message=\"Failed to update tip settings\", status_code=500)\n \n \n-@router.get(\"/orders/{order_reference}/tip-distributions\", response_model=List[StaffTipDistributionRecordSchema])\n+@router.get(\n+    \"/orders/{order_reference}/tip-distributions\",\n+    response_model=List[StaffTipDistributionRecordSchema],\n+)\n def get_tip_distributions_for_order_api(\n     order_reference: str = Path(..., description=\"The reference ID of the order.\"),\n-    service: StaffTipService = Depends(get_staff_tip_service_dep)\n+    service: StaffTipService = Depends(get_staff_tip_service_dep),\n ):\n     \"\"\"\n     Retrieves all recorded tip distributions for a specific order.\n     \"\"\"\n-    db_records = service.get_tip_distributions_for_order(order_reference=order_reference)\n+    db_records = service.get_tip_distributions_for_order(\n+        order_reference=order_reference\n+    )\n     return [convert_db_tip_dist_to_schema(rec) for rec in db_records]\n \n \n-@router.get(\"/staff/{staff_id}/tip-distributions\", response_model=List[StaffTipDistributionRecordSchema])\n+@router.get(\n+    \"/staff/{staff_id}/tip-distributions\",\n+    response_model=List[StaffTipDistributionRecordSchema],\n+)\n def get_tip_distributions_for_staff_api(\n     staff_id: str = Path(..., description=\"The ID of the staff member.\"),\n-    start_date: Optional[str] = None, # Query param, e.g., YYYY-MM-DD\n-    end_date: Optional[str] = None,   # Query param, e.g., YYYY-MM-DD\n-    service: StaffTipService = Depends(get_staff_tip_service_dep)\n+    start_date: Optional[str] = None,  # Query param, e.g., YYYY-MM-DD\n+    end_date: Optional[str] = None,  # Query param, e.g., YYYY-MM-DD\n+    service: StaffTipService = Depends(get_staff_tip_service_dep),\n ):\n     \"\"\"\n     Retrieves all recorded tip distributions for a specific staff member,\n     optionally filtered by a date range (ISO format dates expected).\n     \"\"\"\n     db_records = service.get_tip_distributions_for_staff(\n-        staff_id=staff_id,\n-        start_date=start_date,\n-        end_date=end_date\n+        staff_id=staff_id, start_date=start_date, end_date=end_date\n     )\n     return [convert_db_tip_dist_to_schema(rec) for rec in db_records]\n \n \n # To include this router in the main application:\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/sumup.py\t2025-08-02 21:56:58.990329+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/sumup.py\t2025-08-02 22:36:02.956000+00:00\n@@ -24,68 +24,71 @@\n router = APIRouter()\n \n \n class SumUpInitRequest(BaseModel):\n     \"\"\"Request model for SumUp initialization\"\"\"\n+\n     mode: str = Field(default=\"production\", description=\"Mode: sandbox or production\")\n-    \n+\n     class Config:\n-        schema_extra = {\n-            \"example\": {\n-                \"mode\": \"production\"\n-            }\n-        }\n+        schema_extra = {\"example\": {\"mode\": \"production\"}}\n \n \n class SumUpConfigData(BaseModel):\n     \"\"\"SumUp SDK configuration data\"\"\"\n+\n     appId: str = Field(..., description=\"SumUp app ID for mobile SDK\")\n     environment: str = Field(..., description=\"Environment: sandbox or production\")\n-    merchantCode: Optional[str] = Field(None, description=\"SumUp merchant code if available\")\n+    merchantCode: Optional[str] = Field(\n+        None, description=\"SumUp merchant code if available\"\n+    )\n     currency: str = Field(default=\"GBP\", description=\"Currency code\")\n+\n \n class SumUpConfigResponse(BaseModel):\n     \"\"\"Response model for SumUp configuration matching frontend expectations\"\"\"\n+\n     config: SumUpConfigData = Field(..., description=\"SumUp SDK configuration\")\n     sdkInitialized: bool = Field(..., description=\"Whether SDK is initialized\")\n-    enabled: bool = Field(..., description=\"Whether SumUp is enabled for this restaurant\")\n+    enabled: bool = Field(\n+        ..., description=\"Whether SumUp is enabled for this restaurant\"\n+    )\n     features: Dict[str, bool] = Field(..., description=\"Enabled SumUp features\")\n \n \n class MerchantValidationRequest(BaseModel):\n     \"\"\"Request model for merchant code validation\"\"\"\n+\n     merchant_code: str = Field(..., description=\"SumUp merchant code to validate\")\n-    \n+\n     class Config:\n-        schema_extra = {\n-            \"example\": {\n-                \"merchant_code\": \"MC123456\"\n-            }\n-        }\n+        schema_extra = {\"example\": {\"merchant_code\": \"MC123456\"}}\n \n \n @router.post(\"/initialize\", response_model=SumUpConfigResponse)\n @limiter.limit(\"10/minute\")\n async def initialize_sumup(\n     request: Request,\n     init_request: SumUpInitRequest,\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Restaurant ID for multi-location owners\"),\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Restaurant ID for multi-location owners\"\n+    ),\n     current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"\n     Initialize SumUp configuration for mobile app\n-    \n+\n     This endpoint provides the necessary configuration for the mobile app\n     to initialize the SumUp SDK without exposing sensitive API keys.\n-    \n+\n     Returns:\n         - Merchant code (if configured)\n         - Environment setting\n         - App ID for SDK initialization\n         - Feature flags\n-    \n+\n     Security:\n         - Requires authenticated user\n         - Restaurant must have active subscription\n         - Rate limited to prevent abuse\n     \"\"\"\n@@ -94,97 +97,96 @@\n         await TenantSecurity.validate_restaurant_access(\n             current_user, current_restaurant_id or current_user.restaurant_id, db=db\n         )\n         # Use the provided restaurant_id or fall back to user's default\n         restaurant_id = current_restaurant_id or current_user.restaurant_id\n-        \n+\n         # Check if restaurant has active subscription\n-                \n+\n         # Get SumUp configuration from environment\n         sumup_environment = os.getenv(\"SUMUP_ENVIRONMENT\", \"production\")\n         sumup_app_id = os.getenv(\"SUMUP_APP_ID\", \"com.fynlo.pos\")\n-        \n+\n         # Check if SumUp is properly configured\n         sumup_api_key = os.getenv(\"SUMUP_API_KEY\")\n         if not sumup_api_key:\n-            logger.warning(f\"SumUp API key not configured for restaurant {restaurant_id}\")\n+            logger.warning(\n+                f\"SumUp API key not configured for restaurant {restaurant_id}\"\n+            )\n             return APIResponseHelper.success(\n                 data={\n                     \"merchant_code\": None,\n                     \"environment\": sumup_environment,\n                     \"app_id\": sumup_app_id,\n                     \"enabled\": False,\n                     \"features\": {\n                         \"card_reader\": False,\n                         \"tap_to_pay\": False,\n-                        \"refunds\": False\n-                    }\n+                        \"refunds\": False,\n+                    },\n                 },\n-                message=\"SumUp is not configured for this restaurant\"\n-            )\n-        \n+                message=\"SumUp is not configured for this restaurant\",\n+            )\n+\n         # For now, use a placeholder or environment variable\n         merchant_code = os.getenv(\"SUMUP_MERCHANT_CODE\")\n-        \n+\n         # Determine feature availability based on subscription plan\n         features = {\n             \"card_reader\": True,  # Physical card reader support\n-            \"tap_to_pay\": True,   # Tap to pay on phone\n-            \"refunds\": True       # Refund capabilities\n+            \"tap_to_pay\": True,  # Tap to pay on phone\n+            \"refunds\": True,  # Refund capabilities\n         }\n-        \n+\n         # Override with requested mode if valid\n         if init_request.mode in [\"sandbox\", \"production\"]:\n             environment = init_request.mode\n         else:\n             environment = sumup_environment\n-        \n+\n         # Log initialization request for audit\n         logger.info(\n             f\"SumUp initialization requested by user {current_user.id} \"\n             f\"for restaurant {restaurant_id} in {environment} mode\"\n         )\n-        \n+\n         # Build response using the proper model\n         config_data = SumUpConfigData(\n             appId=sumup_app_id,\n             environment=environment,\n             merchantCode=merchant_code,\n-            currency=\"GBP\"  # Using GBP to match application standard\n-        )\n-        \n+            currency=\"GBP\",  # Using GBP to match application standard\n+        )\n+\n         response = SumUpConfigResponse(\n-            config=config_data,\n-            sdkInitialized=True,\n-            enabled=True,\n-            features=features\n-        )\n-        \n+            config=config_data, sdkInitialized=True, enabled=True, features=features\n+        )\n+\n         return APIResponseHelper.success(\n-            data=response.dict(),\n-            message=\"SumUp configuration retrieved successfully\"\n-        )\n-        \n+            data=response.dict(), message=\"SumUp configuration retrieved successfully\"\n+        )\n+\n     except Exception as e:\n         logger.error(f\"Error initializing SumUp: {str(e)}\")\n         return APIResponseHelper.internal_error(\n-            message=\"Failed to initialize SumUp configuration\",\n-            error_id=str(e)\n+            message=\"Failed to initialize SumUp configuration\", error_id=str(e)\n         )\n \n \n @router.get(\"/status\")\n @limiter.limit(\"30/minute\")\n async def get_sumup_status(\n     request: Request,\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Restaurant ID for multi-location owners\"),\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Restaurant ID for multi-location owners\"\n+    ),\n     current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"\n     Get current SumUp integration status\n-    \n+\n     Returns the current status of SumUp integration including:\n     - Configuration status\n     - Last successful transaction (if any)\n     - Current mode (sandbox/production)\n     - Feature availability\n@@ -194,91 +196,97 @@\n         await TenantSecurity.validate_restaurant_access(\n             current_user, current_restaurant_id or current_user.restaurant_id, db=db\n         )\n         # Use the provided restaurant_id or fall back to user's default\n         restaurant_id = current_restaurant_id or current_user.restaurant_id\n-        \n+\n         # Check SumUp configuration\n         sumup_api_key = os.getenv(\"SUMUP_API_KEY\")\n         sumup_environment = os.getenv(\"SUMUP_ENVIRONMENT\", \"production\")\n-        \n+\n         status_data = {\n             \"configured\": bool(sumup_api_key),\n             \"environment\": sumup_environment,\n-            \"last_transaction\": None,              \"total_transactions\": 0,               \"features\": {\n+            \"last_transaction\": None,\n+            \"total_transactions\": 0,\n+            \"features\": {\n                 \"card_reader\": bool(sumup_api_key),\n                 \"tap_to_pay\": bool(sumup_api_key),\n-                \"refunds\": bool(sumup_api_key)\n-            }\n+                \"refunds\": bool(sumup_api_key),\n+            },\n         }\n-        \n+\n         return APIResponseHelper.success(\n-            data=status_data,\n-            message=\"SumUp status retrieved successfully\"\n-        )\n-        \n+            data=status_data, message=\"SumUp status retrieved successfully\"\n+        )\n+\n     except Exception as e:\n         logger.error(f\"Error getting SumUp status: {str(e)}\")\n         return APIResponseHelper.internal_error(\n-            message=\"Failed to retrieve SumUp status\",\n-            error_id=str(e)\n+            message=\"Failed to retrieve SumUp status\", error_id=str(e)\n         )\n \n \n @router.post(\"/validate-merchant\")\n @limiter.limit(\"5/minute\")\n async def validate_merchant_code(\n     request: Request,\n     validation_request: MerchantValidationRequest,\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Restaurant ID for multi-location owners\"),\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Restaurant ID for multi-location owners\"\n+    ),\n     current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"\n     Validate a SumUp merchant code\n-    \n+\n     This endpoint can be used to validate a merchant code\n     before storing it in the configuration.\n-    \n+\n     Note: Actual validation would require calling SumUp API\n     \"\"\"\n     try:\n         # Validate restaurant access for multi-tenant\n         await TenantSecurity.validate_restaurant_access(\n             current_user, current_restaurant_id or current_user.restaurant_id, db=db\n         )\n         # Use the provided restaurant_id or fall back to user's default\n         restaurant_id = current_restaurant_id or current_user.restaurant_id\n-        \n+\n         # Check permissions\n-        if current_user.role not in ['platform_owner', 'restaurant_owner', 'manager']:\n+        if current_user.role not in [\"platform_owner\", \"restaurant_owner\", \"manager\"]:\n             return APIResponseHelper.forbidden(\n                 message=\"Insufficient permissions to validate merchant code\"\n             )\n-        \n+\n         # Basic validation\n-        if not validation_request.merchant_code or len(validation_request.merchant_code) < 6:\n+        if (\n+            not validation_request.merchant_code\n+            or len(validation_request.merchant_code) < 6\n+        ):\n             return APIResponseHelper.validation_error(\n                 message=\"Invalid merchant code format\",\n-                errors=[{\n-                    \"field\": \"merchant_code\",\n-                    \"message\": \"Merchant code must be at least 6 characters\"\n-                }]\n-            )\n-        \n-                # For now, just return success\n-        \n+                errors=[\n+                    {\n+                        \"field\": \"merchant_code\",\n+                        \"message\": \"Merchant code must be at least 6 characters\",\n+                    }\n+                ],\n+            )\n+\n+            # For now, just return success\n+\n         return APIResponseHelper.success(\n             data={\n                 \"merchantCode\": validation_request.merchant_code,\n                 \"valid\": True,\n-                \"message\": \"Merchant code format is valid\"\n+                \"message\": \"Merchant code format is valid\",\n             },\n-            message=\"Merchant code validated successfully\"\n-        )\n-        \n+            message=\"Merchant code validated successfully\",\n+        )\n+\n     except Exception as e:\n         logger.error(f\"Error validating merchant code: {str(e)}\")\n         return APIResponseHelper.internal_error(\n-            message=\"Failed to validate merchant code\",\n-            error_id=str(e)\n-        )\n\\ No newline at end of file\n+            message=\"Failed to validate merchant code\", error_id=str(e)\n+        )\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/websocket_secure.py\t2025-08-02 21:56:58.991684+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/websocket_secure.py\t2025-08-02 22:36:02.999887+00:00\n@@ -14,76 +14,71 @@\n \n logger = logging.getLogger(__name__)\n \n \n async def verify_websocket_access_secure(\n-    restaurant_id: str,\n-    user: User,\n-    connection_type: str = \"pos\"\n+    restaurant_id: str, user: User, connection_type: str = \"pos\"\n ) -> bool:\n     \"\"\"\n     Enhanced WebSocket access verification using TenantSecurity\n-    \n+\n     Args:\n         restaurant_id: Restaurant to connect to\n         user: Authenticated user\n         connection_type: Type of connection (pos, kitchen, management)\n-        \n+\n     Returns:\n         bool: Whether access is granted\n     \"\"\"\n     # Special handling for onboarding\n     if restaurant_id == \"onboarding\":\n         # Users without a restaurant can connect to onboarding\n         return user.restaurant_id is None\n-    \n+\n     # Platform owners (Ryan & Arnaud) can connect to any restaurant\n     if TenantSecurity.is_platform_owner(user):\n         logger.info(\n             f\"Platform owner {user.email} connecting to restaurant {restaurant_id}\"\n         )\n         return True\n-    \n+\n     # Regular users can only connect to their own restaurant\n     if not user.restaurant_id:\n         logger.warning(\n             f\"User {user.email} has no restaurant assigned, denying WebSocket\"\n         )\n         return False\n-    \n+\n     if str(user.restaurant_id) != str(restaurant_id):\n         logger.warning(\n             f\"User {user.email} from restaurant {user.restaurant_id} \"\n             f\"attempted to connect to restaurant {restaurant_id}\"\n         )\n         return False\n-    \n+\n     # User has access to their own restaurant\n     return True\n \n \n async def handle_websocket_message_secure(\n-    message: dict,\n-    user: User,\n-    restaurant_id: str,\n-    connection_id: str\n+    message: dict, user: User, restaurant_id: str, connection_id: str\n ):\n     \"\"\"\n     Handle incoming WebSocket messages with tenant security\n-    \n+\n     Args:\n         message: Incoming message data\n         user: Authenticated user\n         restaurant_id: Restaurant context\n         connection_id: WebSocket connection ID\n     \"\"\"\n     message_type = message.get(\"type\")\n-    \n+\n     # Validate any restaurant_id in the message\n     if \"restaurant_id\" in message:\n         msg_restaurant_id = message[\"restaurant_id\"]\n-        \n+\n         # Platform owners can send messages to any restaurant\n         if TenantSecurity.is_platform_owner(user):\n             # Allow cross-restaurant operations for platform owners\n             pass\n         elif str(msg_restaurant_id) != str(restaurant_id):\n@@ -91,93 +86,91 @@\n             logger.error(\n                 f\"Tenant violation: User {user.email} tried to send message \"\n                 f\"to restaurant {msg_restaurant_id} while connected to {restaurant_id}\"\n             )\n             return  # Silently drop the message\n-    \n+\n     # Process the message based on type\n     if message_type == \"order_update\":\n         # Ensure order belongs to the correct restaurant\n         order_id = message.get(\"order_id\")\n         if order_id:\n             # In production, verify the order belongs to restaurant_id\n             # This prevents users from updating other restaurants' orders\n             pass\n-    \n+\n     elif message_type == \"broadcast\":\n         # Only platform owners can broadcast to multiple restaurants\n         if not TenantSecurity.is_platform_owner(user):\n-            logger.warning(\n-                f\"Non-platform owner {user.email} attempted broadcast\"\n-            )\n+            logger.warning(f\"Non-platform owner {user.email} attempted broadcast\")\n             return\n-    \n+\n     # Forward the message through normal channels\n     await websocket_manager.process_message(\n-        connection_id=connection_id,\n-        message=message,\n-        restaurant_id=restaurant_id\n+        connection_id=connection_id, message=message, restaurant_id=restaurant_id\n     )\n \n \n class SecureWebSocketManager:\n     \"\"\"\n     Enhanced WebSocket manager with tenant isolation\n     \"\"\"\n-    \n+\n     @staticmethod\n     async def broadcast_to_restaurant_secure(\n         restaurant_id: str,\n         message: dict,\n         exclude_connection: Optional[str] = None,\n-        sender_user: Optional[User] = None\n+        sender_user: Optional[User] = None,\n     ):\n         \"\"\"\n         Broadcast message to all connections in a restaurant with security checks\n-        \n+\n         Args:\n             restaurant_id: Target restaurant\n             message: Message to broadcast\n             exclude_connection: Connection to exclude from broadcast\n             sender_user: User sending the message\n         \"\"\"\n         # Platform owners can broadcast to any restaurant\n         if sender_user and not TenantSecurity.is_platform_owner(sender_user):\n             # Verify sender belongs to the restaurant they're broadcasting to\n-            if not sender_user.restaurant_id or str(sender_user.restaurant_id) != str(restaurant_id):\n+            if not sender_user.restaurant_id or str(sender_user.restaurant_id) != str(\n+                restaurant_id\n+            ):\n                 logger.error(\n                     f\"Broadcast denied: User {sender_user.email} cannot broadcast \"\n                     f\"to restaurant {restaurant_id}\"\n                 )\n                 return\n-        \n+\n         # Use the existing broadcast mechanism\n         await websocket_manager.broadcast_to_restaurant(\n             restaurant_id=restaurant_id,\n             message=message,\n-            exclude_user_id=str(sender_user.id) if sender_user else None\n+            exclude_user_id=str(sender_user.id) if sender_user else None,\n         )\n-    \n+\n     @staticmethod\n     async def notify_platform_owners(message: dict):\n         \"\"\"\n         Send notifications to all connected platform owners (Ryan & Arnaud)\n-        \n+\n         Args:\n             message: Notification message\n         \"\"\"\n         # This is a special broadcast only for platform owners\n         platform_owner_connections = []\n-        \n+\n         # Find all platform owner connections\n         for conn_id, conn_info in websocket_manager.connections.items():\n             user = conn_info.get(\"user\")\n             if user and TenantSecurity.is_platform_owner(user):\n                 platform_owner_connections.append(conn_id)\n-        \n+\n         # Send to all platform owners\n         for conn_id in platform_owner_connections:\n             await websocket_manager.send_to_connection(conn_id, message)\n-        \n+\n         logger.info(\n             f\"Notified {len(platform_owner_connections)} platform owner connections\"\n-        )\n\\ No newline at end of file\n+        )\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/orders.py\t2025-08-02 21:56:58.986542+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/orders.py\t2025-08-02 22:36:03.003587+00:00\n@@ -13,67 +13,79 @@\n \n logger = logging.getLogger(__name__)\n \n from app.core.database import get_db, Order, Product, Customer, User\n from app.core.auth import get_current_user\n-from app.api.v1.endpoints.customers import CustomerCreate as CustomerCreateSchema # Renamed to avoid conflict\n+from app.api.v1.endpoints.customers import (\n+    CustomerCreate as CustomerCreateSchema,\n+)  # Renamed to avoid conflict\n from app.core.redis_client import get_redis, RedisClient\n from app.core.responses import APIResponseHelper\n-from app.core.exceptions import AuthorizationException, FynloException, ResourceNotFoundException, ValidationException\n+from app.core.exceptions import (\n+    AuthorizationException,\n+    FynloException,\n+    ResourceNotFoundException,\n+    ValidationException,\n+)\n from app.core.onboarding_helper import OnboardingHelper\n from app.core.websocket import (\n-    websocket_manager, \n-    notify_order_created, \n-    notify_order_status_changed, \n+    websocket_manager,\n+    notify_order_created,\n+    notify_order_status_changed,\n     notify_kitchen_update,\n     WebSocketMessage,\n-    EventType\n+    EventType,\n )\n from app.core.transaction_manager import transactional, transaction_manager\n from app.schemas.refund_schemas import RefundRequestSchema, RefundResponseSchema\n-from app.api.v1.endpoints.customers import CustomerBasicInfo # Import CustomerBasicInfo\n-from app.services.payment_factory import get_payment_provider # Assuming you have this\n+from app.api.v1.endpoints.customers import CustomerBasicInfo  # Import CustomerBasicInfo\n+from app.services.payment_factory import get_payment_provider  # Assuming you have this\n+\n # Or import specific providers if needed:\n # from app.services.square_provider import SquareProvider\n # from app.services.stripe_provider import StripeProvider\n # from app.services.sumup_provider import SumUpProvider\n-from app.models.refund import Refund, RefundLedger # SQLAlchemy models\n+from app.models.refund import Refund, RefundLedger  # SQLAlchemy models\n from app.core.database import User as UserModel\n-from app.services.email_service import EmailService # Import the new EmailService\n-from decimal import Decimal # Ensure Decimal is imported if used for amounts\n+from app.services.email_service import EmailService  # Import the new EmailService\n+from decimal import Decimal  # Ensure Decimal is imported if used for amounts\n \n router = APIRouter()\n-email_service = EmailService() # Instantiate EmailService globally or per request\n+email_service = EmailService()  # Instantiate EmailService globally or per request\n+\n \n # Pydantic models\n class OrderItem(BaseModel):\n     product_id: str\n     quantity: int\n     unit_price: float\n     total_price: float\n     modifiers: List[dict] = []\n     special_instructions: Optional[str] = None\n \n+\n class OrderCreate(BaseModel):\n     customer_id: Optional[str] = None\n     customer_email: Optional[EmailStr] = None\n-    customer_name: Optional[str] = None # Expecting \"First Last\"\n+    customer_name: Optional[str] = None  # Expecting \"First Last\"\n     table_number: Optional[str] = None\n     order_type: str = \"dine_in\"  # dine_in, takeaway, delivery\n     items: List[OrderItem]\n     special_instructions: Optional[str] = None\n+\n \n class OrderUpdate(BaseModel):\n     status: Optional[str] = None\n     table_number: Optional[str] = None\n     items: Optional[List[OrderItem]] = None\n     special_instructions: Optional[str] = None\n \n+\n class OrderResponse(BaseModel):\n     id: str\n     restaurant_id: str\n-    customer_id: Optional[str] # Keep this for backward compatibility or internal use\n+    customer_id: Optional[str]  # Keep this for backward compatibility or internal use\n     customer: Optional[CustomerBasicInfo] = None\n     order_number: str\n     table_number: Optional[str]\n     order_type: str\n     status: str\n@@ -87,46 +99,59 @@\n     special_instructions: Optional[str]\n     created_by: str\n     created_at: datetime\n     updated_at: Optional[datetime]\n \n+\n class OrderSummary(BaseModel):\n     id: str\n     order_number: str\n     table_number: Optional[str]\n     status: str\n     total_amount: float\n     item_count: int\n     customer_name: Optional[str] = None\n     created_at: datetime\n \n-def calculate_order_totals(items: List[OrderItem], tax_rate: float = 0.20, service_rate: float = 0.125) -> dict:\n+\n+def calculate_order_totals(\n+    items: List[OrderItem], tax_rate: float = 0.20, service_rate: float = 0.125\n+) -> dict:\n     \"\"\"Calculate order totals with tax and service charge\"\"\"\n     subtotal = sum(item.total_price for item in items)\n     tax_amount = subtotal * tax_rate\n     service_charge = subtotal * service_rate\n     total_amount = subtotal + tax_amount + service_charge\n-    \n+\n     return {\n         \"subtotal\": round(subtotal, 2),\n         \"tax_amount\": round(tax_amount, 2),\n         \"service_charge\": round(service_charge, 2),\n-        \"total_amount\": round(total_amount, 2)\n+        \"total_amount\": round(total_amount, 2),\n     }\n+\n \n def generate_order_number() -> str:\n     \"\"\"Generate unique order number\"\"\"\n     return f\"ORD-{datetime.now().strftime('%Y%m%d')}-{str(uuid.uuid4())[:8].upper()}\"\n \n+\n def verify_order_access(order, current_user):\n     \"\"\"Verify user has access to the order's restaurant\"\"\"\n-    if current_user.role != 'platform_owner':\n-        user_restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n+    if current_user.role != \"platform_owner\":\n+        user_restaurant_id = (\n+            current_user.current_restaurant_id or current_user.restaurant_id\n+        )\n         if user_restaurant_id is None:\n-            raise AuthorizationException(message=\"Access denied: No restaurant assigned to user\")\n+            raise AuthorizationException(\n+                message=\"Access denied: No restaurant assigned to user\"\n+            )\n         if str(order.restaurant_id) != str(user_restaurant_id):\n-            raise AuthorizationException(message=\"Access denied: You can only access orders from your own restaurant\")\n+            raise AuthorizationException(\n+                message=\"Access denied: You can only access orders from your own restaurant\"\n+            )\n+\n \n @router.get(\"/\", response_model=List[OrderSummary])\n async def get_orders(\n     restaurant_id: Optional[str] = Query(None),\n     status: Optional[str] = Query(None),\n@@ -134,194 +159,226 @@\n     date_from: Optional[datetime] = Query(None),\n     date_to: Optional[datetime] = Query(None),\n     limit: int = Query(50, le=100),\n     offset: int = Query(0),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Get orders with filtering options\"\"\"\n-    \n+\n     # Check if user needs onboarding (no restaurant)\n     onboarding_response = OnboardingHelper.handle_onboarding_response(\n-        user=current_user,\n-        resource_type=\"orders\",\n-        endpoint_requires_restaurant=True\n+        user=current_user, resource_type=\"orders\", endpoint_requires_restaurant=True\n     )\n     if onboarding_response:\n         return onboarding_response\n-    \n+\n     # Access control: Check user's role and restaurant access\n-    if current_user.role == 'platform_owner':\n+    if current_user.role == \"platform_owner\":\n         # Platform owners can access any restaurant\n         if not restaurant_id:\n             # If no restaurant specified, show all orders\n             query = db.query(Order)\n         else:\n             query = db.query(Order).filter(Order.restaurant_id == restaurant_id)\n     else:\n         # Restaurant owners, managers, and employees can only access their own restaurant(s)\n-        user_restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n+        user_restaurant_id = (\n+            current_user.current_restaurant_id or current_user.restaurant_id\n+        )\n         if user_restaurant_id is None:\n-            raise AuthorizationException(message=\"Access denied: No restaurant assigned to user\")\n-        \n+            raise AuthorizationException(\n+                message=\"Access denied: No restaurant assigned to user\"\n+            )\n+\n         # Use provided restaurant_id or fallback to user's current restaurant\n         if not restaurant_id:\n             restaurant_id = str(user_restaurant_id)\n         else:\n             # Validate that user has access to the requested restaurant\n             from app.core.tenant_security import TenantSecurity\n+\n             await TenantSecurity.validate_restaurant_access(\n                 user=current_user,\n                 restaurant_id=restaurant_id,\n                 operation=\"access\",\n                 resource_type=\"orders\",\n                 resource_id=None,\n-                db=db\n-            )\n-        \n+                db=db,\n+            )\n+\n         query = db.query(Order).filter(Order.restaurant_id == restaurant_id)\n-    \n+\n     if status:\n         query = query.filter(Order.status == status)\n-    \n+\n     if order_type:\n         query = query.filter(Order.order_type == order_type)\n-    \n+\n     if date_from:\n         query = query.filter(Order.created_at >= date_from)\n-    \n+\n     if date_to:\n         query = query.filter(Order.created_at <= date_to)\n-    \n+\n     orders = query.order_by(desc(Order.created_at)).offset(offset).limit(limit).all()\n \n     # Fetch customer information for the orders\n     customer_ids = [order.customer_id for order in orders if order.customer_id]\n     customers_map = {}\n     if customer_ids:\n-        customers = db.query(Customer.id, Customer.first_name, Customer.last_name).filter(Customer.id.in_(customer_ids)).all()\n+        customers = (\n+            db.query(Customer.id, Customer.first_name, Customer.last_name)\n+            .filter(Customer.id.in_(customer_ids))\n+            .all()\n+        )\n         customers_map = {str(c.id): f\"{c.first_name} {c.last_name}\" for c in customers}\n-    \n+\n     # Fetch customer information for the orders\n     customer_ids = [order.customer_id for order in orders if order.customer_id]\n     customers_map = {}\n     if customer_ids:\n-        customers = db.query(Customer.id, Customer.first_name, Customer.last_name).filter(Customer.id.in_(customer_ids)).all()\n+        customers = (\n+            db.query(Customer.id, Customer.first_name, Customer.last_name)\n+            .filter(Customer.id.in_(customer_ids))\n+            .all()\n+        )\n         customers_map = {str(c.id): f\"{c.first_name} {c.last_name}\" for c in customers}\n \n     result = [\n         OrderSummary(\n             id=str(order.id),\n             order_number=order.order_number,\n             table_number=order.table_number,\n             status=order.status,\n             total_amount=order.total_amount,\n             item_count=len(order.items),\n-            customer_name=customers_map.get(str(order.customer_id)) if order.customer_id else None,\n-            created_at=order.created_at\n+            customer_name=(\n+                customers_map.get(str(order.customer_id)) if order.customer_id else None\n+            ),\n+            created_at=order.created_at,\n         )\n         for order in orders\n     ]\n-    \n+\n     return APIResponseHelper.success(\n         data=result,\n         message=f\"Retrieved {len(result)} orders\",\n         meta={\n             \"total_count\": len(result),\n             \"filters\": {\n                 \"status\": status,\n                 \"order_type\": order_type,\n-                \"date_range\": f\"{date_from} to {date_to}\" if date_from or date_to else None\n+                \"date_range\": (\n+                    f\"{date_from} to {date_to}\" if date_from or date_to else None\n+                ),\n             },\n-            \"pagination\": {\"limit\": limit, \"offset\": offset}\n-        }\n-    )\n+            \"pagination\": {\"limit\": limit, \"offset\": offset},\n+        },\n+    )\n+\n \n @router.get(\"/today\", response_model=List[OrderSummary])\n async def get_todays_orders(\n     restaurant_id: Optional[str] = Query(None),\n     db: Session = Depends(get_db),\n     current_user: User = Depends(get_current_user),\n-    redis: RedisClient = Depends(get_redis)\n+    redis: RedisClient = Depends(get_redis),\n ):\n     \"\"\"Get today's orders for kitchen display and POS\"\"\"\n-    \n+\n     # Check if user needs onboarding (no restaurant)\n     onboarding_response = OnboardingHelper.handle_onboarding_response(\n-        user=current_user,\n-        resource_type=\"orders\",\n-        endpoint_requires_restaurant=True\n+        user=current_user, resource_type=\"orders\", endpoint_requires_restaurant=True\n     )\n     if onboarding_response:\n         return onboarding_response\n-    \n+\n     # Access control: Check user's role and restaurant access\n-    if current_user.role == 'platform_owner':\n+    if current_user.role == \"platform_owner\":\n         # Platform owners can access any restaurant\n         if not restaurant_id:\n             # Platform owner must specify which restaurant to view\n-            raise ValidationException(message=\"Restaurant ID is required for platform owners\", field=\"id\")\n+            raise ValidationException(\n+                message=\"Restaurant ID is required for platform owners\", field=\"id\"\n+            )\n     else:\n         # Restaurant owners, managers, and employees can only access their own restaurant(s)\n-        user_restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n+        user_restaurant_id = (\n+            current_user.current_restaurant_id or current_user.restaurant_id\n+        )\n         if user_restaurant_id is None:\n-            raise AuthorizationException(message=\"Access denied: No restaurant assigned to user\")\n-        \n+            raise AuthorizationException(\n+                message=\"Access denied: No restaurant assigned to user\"\n+            )\n+\n         # Use provided restaurant_id or fallback to user's current restaurant\n         if not restaurant_id:\n             restaurant_id = str(user_restaurant_id)\n         else:\n             # Validate that user has access to the requested restaurant\n             from app.core.tenant_security import TenantSecurity\n+\n             await TenantSecurity.validate_restaurant_access(\n                 user=current_user,\n                 restaurant_id=restaurant_id,\n                 operation=\"access\",\n                 resource_type=\"orders\",\n                 resource_id=None,\n-                db=db\n-            )\n-    \n+                db=db,\n+            )\n+\n     # Check cache first\n     cache_key = f\"orders:today:{restaurant_id}\"\n     cached_orders = await redis.get(cache_key)\n     if cached_orders:\n         return cached_orders\n-    \n+\n     today_start = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)\n     today_end = today_start + timedelta(days=1)\n-    \n-    orders = db.query(Order).filter(\n-        and_(\n-            Order.restaurant_id == restaurant_id,\n-            Order.created_at >= today_start,\n-            Order.created_at < today_end,\n-            Order.status.in_([\"pending\", \"confirmed\", \"preparing\", \"ready\"])\n-        )\n-    ).order_by(desc(Order.created_at)).all()\n-    \n+\n+    orders = (\n+        db.query(Order)\n+        .filter(\n+            and_(\n+                Order.restaurant_id == restaurant_id,\n+                Order.created_at >= today_start,\n+                Order.created_at < today_end,\n+                Order.status.in_([\"pending\", \"confirmed\", \"preparing\", \"ready\"]),\n+            )\n+        )\n+        .order_by(desc(Order.created_at))\n+        .all()\n+    )\n+\n     # Fetch customer information for the orders\n     customer_ids = [order.customer_id for order in orders if order.customer_id]\n     customers_map = {}\n     if customer_ids:\n-        customers = db.query(Customer.id, Customer.first_name, Customer.last_name).filter(Customer.id.in_(customer_ids)).all()\n+        customers = (\n+            db.query(Customer.id, Customer.first_name, Customer.last_name)\n+            .filter(Customer.id.in_(customer_ids))\n+            .all()\n+        )\n         customers_map = {str(c.id): f\"{c.first_name} {c.last_name}\" for c in customers}\n-    \n+\n     result = [\n         OrderSummary(\n             id=str(order.id),\n             order_number=order.order_number,\n             table_number=order.table_number,\n             status=order.status,\n             total_amount=order.total_amount,\n             item_count=len(order.items),\n-            customer_name=customers_map.get(str(order.customer_id)) if order.customer_id else None,\n-            created_at=order.created_at\n+            customer_name=(\n+                customers_map.get(str(order.customer_id)) if order.customer_id else None\n+            ),\n+            created_at=order.created_at,\n         )\n         for order in orders\n     ]\n-    \n+\n     # Cache for 1 minute (frequent updates expected)\n     # Note: Pydantic models in a list need to be converted to dicts for JSON serialization if not handled by redis client.\n     # Assuming redis.set handles Pydantic models correctly or they are converted before caching.\n     # For simplicity, if `result` is a list of Pydantic models, this might need adjustment:\n     # cached_data = [r.dict() for r in result]\n@@ -333,123 +390,145 @@\n     # Let's ensure it's JSON serializable if it's not already.\n \n     # Convert result to list of dicts for caching if necessary, depends on redis client implementation\n     # For now, assume `result` (list of Pydantic models) is directly cachable or APIResponseHelper handles it.\n \n-    await redis.set(cache_key, [r.dict() for r in result], expire=60) # Explicitly convert to dicts for caching\n-    \n+    await redis.set(\n+        cache_key, [r.dict() for r in result], expire=60\n+    )  # Explicitly convert to dicts for caching\n+\n     return APIResponseHelper.success(\n         data=result,\n         message=f\"Retrieved {len(result)} active orders for today\",\n         meta={\n             \"restaurant_id\": restaurant_id,\n             \"date\": today_start.date().isoformat(),\n-            \"active_statuses\": [\"pending\", \"confirmed\", \"preparing\", \"ready\"]\n-        }\n-    )\n+            \"active_statuses\": [\"pending\", \"confirmed\", \"preparing\", \"ready\"],\n+        },\n+    )\n+\n \n @router.post(\"/\", response_model=OrderResponse)\n @transactional(max_retries=3, retry_delay=0.1)\n async def create_order(\n     order_data: OrderCreate,\n     restaurant_id: Optional[str] = Query(None),\n     db: Session = Depends(get_db),\n     current_user: User = Depends(get_current_user),\n-    redis: RedisClient = Depends(get_redis)\n+    redis: RedisClient = Depends(get_redis),\n ):\n     \"\"\"Create a new order\"\"\"\n-    \n+\n     # Access control: Check user's role and restaurant access\n-    if current_user.role == 'platform_owner':\n+    if current_user.role == \"platform_owner\":\n         # Platform owners must specify which restaurant\n         if not restaurant_id:\n-            raise ValidationException(message=\"Restaurant ID is required for platform owners\", field=\"id\")\n+            raise ValidationException(\n+                message=\"Restaurant ID is required for platform owners\", field=\"id\"\n+            )\n     else:\n         # Restaurant owners, managers, and employees can only create orders for their own restaurant(s)\n-        user_restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n+        user_restaurant_id = (\n+            current_user.current_restaurant_id or current_user.restaurant_id\n+        )\n         if user_restaurant_id is None:\n-            raise AuthorizationException(message=\"Access denied: No restaurant assigned to user\")\n-        \n+            raise AuthorizationException(\n+                message=\"Access denied: No restaurant assigned to user\"\n+            )\n+\n         # Use provided restaurant_id or fallback to user's current restaurant\n         if not restaurant_id:\n             restaurant_id = str(user_restaurant_id)\n         else:\n             # Validate that user has access to the requested restaurant\n             from app.core.tenant_security import TenantSecurity\n+\n             await TenantSecurity.validate_restaurant_access(\n                 user=current_user,\n                 restaurant_id=restaurant_id,\n                 operation=\"modify\",\n                 resource_type=\"orders\",\n                 resource_id=None,\n-                db=db\n+                db=db,\n             )\n \n     customer_id_to_save = order_data.customer_id\n \n     # Customer lookup/creation\n     if not customer_id_to_save and order_data.customer_email:\n-        customer = db.query(Customer).filter(\n-            Customer.email == order_data.customer_email,\n-            Customer.restaurant_id == restaurant_id\n-        ).first()\n+        customer = (\n+            db.query(Customer)\n+            .filter(\n+                Customer.email == order_data.customer_email,\n+                Customer.restaurant_id == restaurant_id,\n+            )\n+            .first()\n+        )\n         if customer:\n             customer_id_to_save = str(customer.id)\n-        elif order_data.customer_name: # Create customer if email and name provided\n+        elif order_data.customer_name:  # Create customer if email and name provided\n             first_name, *last_name_parts = order_data.customer_name.split(\" \", 1)\n             last_name = last_name_parts[0] if last_name_parts else \"\"\n \n             new_customer_schema = CustomerCreateSchema(\n                 email=order_data.customer_email,\n-                phone=None, # Assuming phone is not passed during order creation for now\n+                phone=None,  # Assuming phone is not passed during order creation for now\n                 first_name=first_name,\n                 last_name=last_name,\n-                restaurant_id=restaurant_id\n+                restaurant_id=restaurant_id,\n             )\n             # Directly create customer model instance\n             # This assumes Customer model has a similar constructor or fields\n             # Ideally, this would call a CRUD function like `crud.customer.create()`\n             created_customer = Customer(\n                 **new_customer_schema.dict(),\n                 loyalty_points=0,\n                 total_spent=0.0,\n-                visit_count=0\n+                visit_count=0,\n             )\n             db.add(created_customer)\n-            db.flush() # To get the ID\n+            db.flush()  # To get the ID\n             db.refresh(created_customer)\n             customer_id_to_save = str(created_customer.id)\n             # Clear customer stats cache as a new customer is added\n             await redis.delete(f\"customer_stats:{restaurant_id}\")\n \n     # Validate products exist\n     product_ids = [item.product_id for item in order_data.items]\n-    products = db.query(Product).filter(\n-        and_(\n-            Product.id.in_(product_ids),\n-            Product.restaurant_id == restaurant_id,\n-            Product.is_active == True\n-        )\n-    ).all()\n-    \n+    products = (\n+        db.query(Product)\n+        .filter(\n+            and_(\n+                Product.id.in_(product_ids),\n+                Product.restaurant_id == restaurant_id,\n+                Product.is_active == True,\n+            )\n+        )\n+        .all()\n+    )\n+\n     if len(products) != len(product_ids):\n-        raise ResourceNotFoundException(resource=\"Product\", message=\"One or more products not found\")\n-    \n+        raise ResourceNotFoundException(\n+            resource=\"Product\", message=\"One or more products not found\"\n+        )\n+\n     # Calculate totals\n     totals = calculate_order_totals(order_data.items)\n-    \n+\n     try:\n         # Check stock availability for tracked products\n         for item in order_data.items:\n             product = next(p for p in products if str(p.id) == item.product_id)\n             if product.stock_tracking and product.stock_quantity < item.quantity:\n-                raise ValidationException(message=f\"Insufficient stock for {product.name}. Available: {product.stock_quantity}, Required: {item.quantity}\")\n-        \n+                raise ValidationException(\n+                    message=f\"Insufficient stock for {product.name}. Available: {product.stock_quantity}, Required: {item.quantity}\"\n+                )\n+\n         # Create order\n         new_order = Order(\n             restaurant_id=restaurant_id,\n-            customer_id=customer_id_to_save, # Use the resolved customer_id\n+            customer_id=customer_id_to_save,  # Use the resolved customer_id\n             order_number=generate_order_number(),\n             table_number=order_data.table_number,\n             order_type=order_data.order_type,\n             status=\"pending\",\n             items=[item.dict() for item in order_data.items],\n@@ -458,73 +537,84 @@\n             service_charge=totals[\"service_charge\"],\n             discount_amount=0.0,\n             total_amount=totals[\"total_amount\"],\n             payment_status=\"pending\",\n             special_instructions=order_data.special_instructions,\n-            created_by=str(current_user.id)\n-        )\n-        \n+            created_by=str(current_user.id),\n+        )\n+\n         db.add(new_order)\n-        \n+\n         # Update stock quantities for tracked products (atomic with order creation)\n         for item in order_data.items:\n             product = next(p for p in products if str(p.id) == item.product_id)\n             if product.stock_tracking:\n                 product.stock_quantity -= item.quantity\n                 db.add(product)  # Ensure product is tracked for updates\n-        \n+\n         # Flush to get the order ID before commit\n         db.flush()\n         db.refresh(new_order)\n-        \n+\n         # Cache order (part of transaction)\n-        await redis.cache_order(str(new_order.id), {\n-            \"id\": str(new_order.id),\n-            \"order_number\": new_order.order_number,\n-            \"status\": new_order.status,\n-            \"total_amount\": new_order.total_amount,\n-            \"items\": new_order.items\n-        })\n-        \n+        await redis.cache_order(\n+            str(new_order.id),\n+            {\n+                \"id\": str(new_order.id),\n+                \"order_number\": new_order.order_number,\n+                \"status\": new_order.status,\n+                \"total_amount\": new_order.total_amount,\n+                \"items\": new_order.items,\n+            },\n+        )\n+\n         # Clear today's orders cache (part of transaction)\n         await redis.delete(f\"orders:today:{restaurant_id}\")\n-        \n+\n         # Transaction will auto-commit at this point due to @transactional decorator\n-        \n+\n         # Post-transaction operations (these can fail without affecting DB consistency)\n         try:\n             # Broadcast order creation to WebSocket clients\n-            await notify_order_created(str(new_order.id), restaurant_id, {\n-                \"id\": str(new_order.id),\n-                \"order_number\": new_order.order_number,\n-                \"status\": new_order.status,\n-                \"items\": new_order.items,\n-                \"total_amount\": new_order.total_amount,\n-                \"table_number\": new_order.table_number\n-            })\n+            await notify_order_created(\n+                str(new_order.id),\n+                restaurant_id,\n+                {\n+                    \"id\": str(new_order.id),\n+                    \"order_number\": new_order.order_number,\n+                    \"status\": new_order.status,\n+                    \"items\": new_order.items,\n+                    \"total_amount\": new_order.total_amount,\n+                    \"table_number\": new_order.table_number,\n+                },\n+            )\n         except Exception as ws_error:\n             # Log WebSocket errors but don't fail the order creation\n-            logger.warning(f\"WebSocket notification failed for order {new_order.id}: {ws_error}\")\n-        \n+            logger.warning(\n+                f\"WebSocket notification failed for order {new_order.id}: {ws_error}\"\n+            )\n+\n     except FynloException:\n         # Re-raise HTTP exceptions (validation errors)\n         raise\n     except Exception as e:\n         # Log unexpected errors\n         logger.error(f\"Order creation failed: {e}\")\n         raise FynloException(message=\"Failed to create order\", status_code=500)\n \n     customer_info_response = None\n     if new_order.customer_id:\n-        customer_model = db.query(Customer).filter(Customer.id == new_order.customer_id).first()\n+        customer_model = (\n+            db.query(Customer).filter(Customer.id == new_order.customer_id).first()\n+        )\n         if customer_model:\n             customer_info_response = CustomerBasicInfo(\n                 id=str(customer_model.id),\n                 name=f\"{customer_model.first_name} {customer_model.last_name}\",\n-                email=customer_model.email\n-            )\n-    \n+                email=customer_model.email,\n+            )\n+\n     return OrderResponse(\n         id=str(new_order.id),\n         restaurant_id=str(new_order.restaurant_id),\n         customer_id=str(new_order.customer_id) if new_order.customer_id else None,\n         customer=customer_info_response,\n@@ -540,50 +630,53 @@\n         total_amount=new_order.total_amount,\n         payment_status=new_order.payment_status,\n         special_instructions=new_order.special_instructions,\n         created_by=str(new_order.created_by),\n         created_at=new_order.created_at,\n-        updated_at=new_order.updated_at\n-    )\n+        updated_at=new_order.updated_at,\n+    )\n+\n \n @router.get(\"/{order_id}\", response_model=OrderResponse)\n async def get_order(\n     order_id: str,\n     db: Session = Depends(get_db),\n     current_user: User = Depends(get_current_user),\n-    redis: RedisClient = Depends(get_redis)\n+    redis: RedisClient = Depends(get_redis),\n ):\n     \"\"\"Get a specific order\"\"\"\n-    \n+\n     # Check cache first\n     cached_order = await redis.get_cached_order(order_id)\n     if cached_order:\n         # Get full order from database for complete response\n         pass\n-    \n+\n     order = db.query(Order).filter(Order.id == order_id).first()\n     if not order:\n         raise FynloException(\n             message=\"Order not found\",\n             error_code=ErrorCodes.NOT_FOUND,\n             details={\"order_id\": order_id},\n-            status_code=404\n-        )\n-    \n+            status_code=404,\n+        )\n+\n     # Access control: Verify user has access to this order's restaurant\n     verify_order_access(order, current_user)\n \n     customer_info_response = None\n     if order.customer_id:\n-        customer_model = db.query(Customer).filter(Customer.id == order.customer_id).first()\n+        customer_model = (\n+            db.query(Customer).filter(Customer.id == order.customer_id).first()\n+        )\n         if customer_model:\n             customer_info_response = CustomerBasicInfo(\n                 id=str(customer_model.id),\n                 name=f\"{customer_model.first_name} {customer_model.last_name}\",\n-                email=customer_model.email\n-            )\n-    \n+                email=customer_model.email,\n+            )\n+\n     return OrderResponse(\n         id=str(order.id),\n         restaurant_id=str(order.restaurant_id),\n         customer_id=str(order.customer_id) if order.customer_id else None,\n         customer=customer_info_response,\n@@ -599,89 +692,95 @@\n         total_amount=order.total_amount,\n         payment_status=order.payment_status,\n         special_instructions=order.special_instructions,\n         created_by=str(order.created_by),\n         created_at=order.created_at,\n-        updated_at=order.updated_at\n-    )\n+        updated_at=order.updated_at,\n+    )\n+\n \n @router.put(\"/{order_id}\", response_model=OrderResponse)\n async def update_order(\n     order_id: str,\n     order_data: OrderUpdate,\n     db: Session = Depends(get_db),\n     current_user: User = Depends(get_current_user),\n-    redis: RedisClient = Depends(get_redis)\n+    redis: RedisClient = Depends(get_redis),\n ):\n     \"\"\"Update an order\"\"\"\n-    \n+\n     order = db.query(Order).filter(Order.id == order_id).first()\n     if not order:\n         raise FynloException(\n             message=\"Order not found\",\n             error_code=ErrorCodes.NOT_FOUND,\n             details={\"order_id\": order_id},\n-            status_code=404\n-        )\n-    \n+            status_code=404,\n+        )\n+\n     # Access control: Verify user has access to this order's restaurant\n     verify_order_access(order, current_user)\n-    \n+\n     # Update fields if provided\n     update_data = order_data.dict(exclude_unset=True)\n-    \n+\n     # If updating items, recalculate totals\n     if \"items\" in update_data and update_data[\"items\"]:\n         items = [OrderItem(**item) for item in update_data[\"items\"]]\n         totals = calculate_order_totals(items)\n         update_data.update(totals)\n         update_data[\"items\"] = [item.dict() for item in items]\n-    \n+\n     for field, value in update_data.items():\n         setattr(order, field, value)\n-    \n+\n     order.updated_at = datetime.utcnow()\n     db.commit()\n     db.refresh(order)\n-    \n+\n     # Update cache\n-    await redis.cache_order(str(order.id), {\n-        \"id\": str(order.id),\n-        \"order_number\": order.order_number,\n-        \"status\": order.status,\n-        \"total_amount\": order.total_amount,\n-        \"items\": order.items\n-    })\n-    \n+    await redis.cache_order(\n+        str(order.id),\n+        {\n+            \"id\": str(order.id),\n+            \"order_number\": order.order_number,\n+            \"status\": order.status,\n+            \"total_amount\": order.total_amount,\n+            \"items\": order.items,\n+        },\n+    )\n+\n     # Clear today's orders cache\n     restaurant_id = str(order.restaurant_id)\n     await redis.delete(f\"orders:today:{restaurant_id}\")\n-    \n+\n     # Broadcast order update via WebSocket\n     message = WebSocketMessage(\n         event_type=EventType.ORDER_STATUS_CHANGED,\n         data={\n             \"id\": str(order.id),\n             \"order_number\": order.order_number,\n             \"status\": order.status,\n             \"action\": \"updated\",\n             \"items\": order.items,\n             \"total_amount\": order.total_amount,\n-            \"table_number\": order.table_number\n+            \"table_number\": order.table_number,\n         },\n-        target_restaurant=restaurant_id\n+        target_restaurant=restaurant_id,\n     )\n     await websocket_manager.broadcast_to_restaurant(restaurant_id, message)\n-    \n+\n     customer_info_response = None\n     if order.customer_id:\n-        customer_model = db.query(Customer).filter(Customer.id == order.customer_id).first()\n+        customer_model = (\n+            db.query(Customer).filter(Customer.id == order.customer_id).first()\n+        )\n         if customer_model:\n             customer_info_response = CustomerBasicInfo(\n                 id=str(customer_model.id),\n                 name=f\"{customer_model.first_name} {customer_model.last_name}\",\n-                email=customer_model.email\n+                email=customer_model.email,\n             )\n \n     return OrderResponse(\n         id=str(order.id),\n         restaurant_id=str(order.restaurant_id),\n@@ -699,45 +798,48 @@\n         total_amount=order.total_amount,\n         payment_status=order.payment_status,\n         special_instructions=order.special_instructions,\n         created_by=str(order.created_by),\n         created_at=order.created_at,\n-        updated_at=order.updated_at\n-    )\n+        updated_at=order.updated_at,\n+    )\n+\n \n @router.post(\"/{order_id}/confirm\")\n async def confirm_order(\n     order_id: str,\n     db: Session = Depends(get_db),\n     current_user: User = Depends(get_current_user),\n-    redis: RedisClient = Depends(get_redis)\n+    redis: RedisClient = Depends(get_redis),\n ):\n     \"\"\"\n     Confirm order for kitchen preparation and apply recipe deductions.\n     \"\"\"\n-    from app.services.inventory_service import apply_recipe_deductions_for_order # Import here to avoid circular deps at module level\n-    \n+    from app.services.inventory_service import (\n+        apply_recipe_deductions_for_order,\n+    )  # Import here to avoid circular deps at module level\n+\n     order = db.query(Order).filter(Order.id == order_id).first()\n     if not order:\n         raise FynloException(\n             message=\"Order not found\",\n             error_code=ErrorCodes.NOT_FOUND,\n             details={\"order_id\": order_id},\n-            status_code=404\n-        )\n-    \n+            status_code=404,\n+        )\n+\n     # Access control: Verify user has access to this order's restaurant\n     verify_order_access(order, current_user)\n-    \n+\n     if order.status != \"pending\":\n         raise FynloException(\n             message=f\"Order cannot be confirmed - current status: {order.status}\",\n             error_code=ErrorCodes.VALIDATION_ERROR,\n             details={\"current_status\": order.status, \"required_status\": \"pending\"},\n-            status_code=400\n-        )\n-    \n+            status_code=400,\n+        )\n+\n     order.status = \"confirmed\"\n     order.updated_at = datetime.utcnow()\n     # db.commit() # Will be committed after recipe deductions or by transactional decorator if used\n \n     try:\n@@ -745,309 +847,394 @@\n         # This assumes apply_recipe_deductions_for_order is synchronous or handled within the same DB transaction.\n         # If it's async and involves external calls that shouldn't be part of this transaction,\n         # this might need to be a background task triggered after successful order confirmation.\n         # For now, direct call for simplicity, assuming it works within the same transaction context.\n \n-        deductions_result = await apply_recipe_deductions_for_order(db, order_id=order.id, websocket_manager=websocket_manager)\n-\n-        logger.info(f\"Recipe deductions applied for order {order.id}. {len(deductions_result)} items affected.\")\n-\n-        db.commit() # Commit both order status update and inventory changes\n+        deductions_result = await apply_recipe_deductions_for_order(\n+            db, order_id=order.id, websocket_manager=websocket_manager\n+        )\n+\n+        logger.info(\n+            f\"Recipe deductions applied for order {order.id}. {len(deductions_result)} items affected.\"\n+        )\n+\n+        db.commit()  # Commit both order status update and inventory changes\n     except Exception as e:\n-        db.rollback() # Rollback order status change if deductions fail\n-        logger.error(f\"Failed to apply recipe deductions for order {order.id}: {e}. Order status not confirmed.\")\n+        db.rollback()  # Rollback order status change if deductions fail\n+        logger.error(\n+            f\"Failed to apply recipe deductions for order {order.id}: {e}. Order status not confirmed.\"\n+        )\n         raise FynloException(message=\"Failed to process order update\", status_code=500)\n \n     # Update cache\n-    await redis.cache_order(str(order.id), {\n-        \"id\": str(order.id),\n-        \"order_number\": order.order_number,\n-        \"status\": order.status,\n-        \"total_amount\": order.total_amount,\n-        \"items\": order.items\n-    })\n-    \n+    await redis.cache_order(\n+        str(order.id),\n+        {\n+            \"id\": str(order.id),\n+            \"order_number\": order.order_number,\n+            \"status\": order.status,\n+            \"total_amount\": order.total_amount,\n+            \"items\": order.items,\n+        },\n+    )\n+\n     # Broadcast to kitchen displays\n     restaurant_id = str(order.restaurant_id)\n     await redis.delete(f\"orders:today:{restaurant_id}\")\n-    \n+\n     # Send kitchen notification\n-    await notify_kitchen_update(str(order.id), restaurant_id, \"new_order\", {\n-        \"order_id\": str(order.id),\n-        \"order_number\": order.order_number,\n-        \"status\": \"confirmed\",\n-        \"items\": order.items,\n-        \"table_number\": order.table_number,\n-        \"special_instructions\": order.special_instructions\n-    })\n-    \n+    await notify_kitchen_update(\n+        str(order.id),\n+        restaurant_id,\n+        \"new_order\",\n+        {\n+            \"order_id\": str(order.id),\n+            \"order_number\": order.order_number,\n+            \"status\": \"confirmed\",\n+            \"items\": order.items,\n+            \"table_number\": order.table_number,\n+            \"special_instructions\": order.special_instructions,\n+        },\n+    )\n+\n     return APIResponseHelper.success(\n         data={\"order_id\": str(order.id), \"status\": order.status},\n-        message=f\"Order {order.order_number} confirmed for kitchen preparation\"\n-    )\n+        message=f\"Order {order.order_number} confirmed for kitchen preparation\",\n+    )\n+\n \n @router.post(\"/{order_id}/cancel\")\n async def cancel_order(\n     order_id: str,\n     reason: Optional[str] = Query(None),\n     db: Session = Depends(get_db),\n     current_user: User = Depends(get_current_user),\n-    redis: RedisClient = Depends(get_redis)\n+    redis: RedisClient = Depends(get_redis),\n ):\n     \"\"\"Cancel an order\"\"\"\n-    \n+\n     order = db.query(Order).filter(Order.id == order_id).first()\n     if not order:\n         raise FynloException(\n             message=\"Order not found\",\n             error_code=ErrorCodes.NOT_FOUND,\n             details={\"order_id\": order_id},\n-            status_code=404\n-        )\n-    \n+            status_code=404,\n+        )\n+\n     # Access control: Verify user has access to this order's restaurant\n     verify_order_access(order, current_user)\n-    \n+\n     if order.status in [\"completed\", \"cancelled\"]:\n         raise FynloException(\n             message=f\"Order cannot be cancelled - current status: {order.status}\",\n             error_code=ErrorCodes.VALIDATION_ERROR,\n-            details={\"current_status\": order.status, \"invalid_statuses\": [\"completed\", \"cancelled\"]},\n-            status_code=400\n-        )\n-    \n+            details={\n+                \"current_status\": order.status,\n+                \"invalid_statuses\": [\"completed\", \"cancelled\"],\n+            },\n+            status_code=400,\n+        )\n+\n     # Capture original status for notification\n     original_status = order.status\n     order.status = \"cancelled\"\n     order.updated_at = datetime.utcnow()\n-    \n+\n     # Add cancellation reason to special instructions\n     if reason:\n-        order.special_instructions = f\"{order.special_instructions or ''}\\nCancelled: {reason}\".strip()\n-    \n+        order.special_instructions = (\n+            f\"{order.special_instructions or ''}\\nCancelled: {reason}\".strip()\n+        )\n+\n     db.commit()\n-    \n+\n     # Clear caches\n     restaurant_id = str(order.restaurant_id)\n     await redis.delete(f\"orders:today:{restaurant_id}\")\n     await redis.delete(f\"order:{order_id}\")\n-    \n+\n     # Broadcast cancellation\n-    await notify_order_status_changed(str(order.id), restaurant_id, original_status, \"cancelled\", {\n-        \"id\": str(order.id),\n-        \"order_number\": order.order_number,\n-        \"status\": \"cancelled\",\n-        \"reason\": reason\n-    })\n-    \n+    await notify_order_status_changed(\n+        str(order.id),\n+        restaurant_id,\n+        original_status,\n+        \"cancelled\",\n+        {\n+            \"id\": str(order.id),\n+            \"order_number\": order.order_number,\n+            \"status\": \"cancelled\",\n+            \"reason\": reason,\n+        },\n+    )\n+\n     return APIResponseHelper.success(\n         data={\"order_id\": str(order.id), \"status\": order.status, \"reason\": reason},\n-        message=f\"Order {order.order_number} cancelled successfully\"\n-    )\n+        message=f\"Order {order.order_number} cancelled successfully\",\n+    )\n+\n \n @router.post(\"/{order_id}/refund\", response_model=RefundResponseSchema)\n async def refund_order(\n     order_id: str,\n     refund_data: RefundRequestSchema,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user) # Ensure this User is the Pydantic model from auth\n+    current_user: User = Depends(\n+        get_current_user\n+    ),  # Ensure this User is the Pydantic model from auth\n ):\n     \"\"\"\n     Process a full or partial refund for an order.\n     Requires Manager role or above.\n     \"\"\"\n     # Permission Check (FR-7)\n     # Assuming current_user has a 'role' attribute. Adjust as per your User model.\n     # It's better to use a dependency for role checks, e.g., Depends(RoleChecker([\"Manager\", \"Admin\"]))\n     db_user = db.query(UserModel).filter(UserModel.id == current_user.id).first()\n-    if not db_user or db_user.role not in [\"Manager\", \"Admin\"]:         raise FynloException(message=\"Not authorized to perform refunds.\")\n+    if not db_user or db_user.role not in [\"Manager\", \"Admin\"]:\n+        raise FynloException(message=\"Not authorized to perform refunds.\")\n \n     order = db.query(Order).filter(Order.id == order_id).first()\n     if not order:\n         raise FynloException(\n             message=\"Order not found\",\n             error_code=ErrorCodes.NOT_FOUND,\n             details={\"order_id\": order_id},\n-            status_code=status.HTTP_404_NOT_FOUND\n-        )\n-    \n+            status_code=status.HTTP_404_NOT_FOUND,\n+        )\n+\n     # Access control: Verify user has access to this order's restaurant\n     verify_order_access(order, current_user)\n \n-    if order.status != \"completed\": # (FR-1) - Or other statuses that allow refunds\n+    if order.status != \"completed\":  # (FR-1) - Or other statuses that allow refunds\n         raise FynloException(\n             message=f\"Order status '{order.status}' does not allow refunds.\",\n             error_code=ErrorCodes.VALIDATION_ERROR,\n             details={\"current_status\": order.status, \"required_status\": \"completed\"},\n-            status_code=status.HTTP_400_BAD_REQUEST\n+            status_code=status.HTTP_400_BAD_REQUEST,\n         )\n \n     # Determine refund amount and type\n     is_full_refund = not refund_data.items or len(refund_data.items) == 0\n     refund_amount: Decimal\n \n     if is_full_refund:\n-        refund_amount = refund_data.amount if refund_data.amount is not None else Decimal(str(order.total_amount))\n+        refund_amount = (\n+            refund_data.amount\n+            if refund_data.amount is not None\n+            else Decimal(str(order.total_amount))\n+        )\n         if refund_amount != Decimal(str(order.total_amount)):\n             # Potentially allow if less, but for now, full means full.\n-             raise FynloException(\n+            raise FynloException(\n                 message=\"Full refund amount must match order total if items are not specified.\",\n                 error_code=ErrorCodes.VALIDATION_ERROR,\n-                status_code=status.HTTP_400_BAD_REQUEST\n-            )\n-    else: # Partial refund\n+                status_code=status.HTTP_400_BAD_REQUEST,\n+            )\n+    else:  # Partial refund\n         calculated_partial_amount = Decimal(0)\n         # Validate items and calculate amount (simplified, needs actual product price lookup)\n         for item_to_refund in refund_data.items:\n-            found_item = next((oi for oi in order.items if oi.get(\"product_id\") == item_to_refund.line_id), None) # Assuming line_id is product_id\n+            found_item = next(\n+                (\n+                    oi\n+                    for oi in order.items\n+                    if oi.get(\"product_id\") == item_to_refund.line_id\n+                ),\n+                None,\n+            )  # Assuming line_id is product_id\n             if not found_item:\n                 raise FynloException(\n                     message=f\"Item with line_id {item_to_refund.line_id} not found in order.\",\n                     error_code=ErrorCodes.VALIDATION_ERROR,\n-                    status_code=status.HTTP_400_BAD_REQUEST\n+                    status_code=status.HTTP_400_BAD_REQUEST,\n                 )\n             # This is a simplification. In reality, you'd use the item's price at the time of order.\n             # And ensure you're not refunding more than ordered quantity.\n-            calculated_partial_amount += Decimal(str(found_item.get(\"unit_price\", 0))) * item_to_refund.qty\n-\n-        if refund_data.amount is not None and refund_data.amount != calculated_partial_amount:\n+            calculated_partial_amount += (\n+                Decimal(str(found_item.get(\"unit_price\", 0))) * item_to_refund.qty\n+            )\n+\n+        if (\n+            refund_data.amount is not None\n+            and refund_data.amount != calculated_partial_amount\n+        ):\n             # If amount is provided for partial, it should match calculated or handle discrepancy\n-            logger.warning(f\"Provided partial refund amount {refund_data.amount} differs from calculated {calculated_partial_amount}. Using provided amount.\")\n+            logger.warning(\n+                f\"Provided partial refund amount {refund_data.amount} differs from calculated {calculated_partial_amount}. Using provided amount.\"\n+            )\n             refund_amount = refund_data.amount\n         else:\n             refund_amount = calculated_partial_amount\n \n     if refund_amount <= 0:\n         raise FynloException(\n             message=\"Refund amount must be positive.\",\n             error_code=ErrorCodes.VALIDATION_ERROR,\n-            status_code=status.HTTP_400_BAD_REQUEST\n+            status_code=status.HTTP_400_BAD_REQUEST,\n         )\n \n     # (FR-4) Backend routes to gateway adapter\n     # Assuming order.payment_transaction_id and order.payment_provider exist\n-    payment_transaction_id = getattr(order, 'payment_transaction_id', None)\n-    payment_provider_code = getattr(order, 'payment_provider_code', None) # e.g., 'sumup', 'square', 'cash'\n+    payment_transaction_id = getattr(order, \"payment_transaction_id\", None)\n+    payment_provider_code = getattr(\n+        order, \"payment_provider_code\", None\n+    )  # e.g., 'sumup', 'square', 'cash'\n \n     if not payment_transaction_id or not payment_provider_code:\n         # For cash, we might not have a transaction_id in the same way.\n-        if payment_provider_code == 'cash':\n-            logger.info(f\"Processing cash refund for order {order_id} of amount {refund_amount}\")\n+        if payment_provider_code == \"cash\":\n+            logger.info(\n+                f\"Processing cash refund for order {order_id} of amount {refund_amount}\"\n+            )\n             gateway_refund_id = f\"CASH_REFUND_{uuid.uuid4()}\"\n             refund_status_message = \"Cash refund processed internally.\"\n         else:\n             raise FynloException(\n                 message=\"Order payment details not found or provider not supported for direct refund.\",\n                 error_code=ErrorCodes.PAYMENT_ERROR,\n-                status_code=status.HTTP_501_NOT_IMPLEMENTED # Or 400 if it's a data issue\n+                status_code=status.HTTP_501_NOT_IMPLEMENTED,  # Or 400 if it's a data issue\n             )\n     else:\n         try:\n             payment_provider_service = get_payment_provider(payment_provider_code)\n             # The refund method in provider service should handle actual API call\n             # It might need more parameters like refund_data.items for partial refunds\n             refund_result = await payment_provider_service.refund_payment(\n                 transaction_id=payment_transaction_id,\n-                amount_to_refund=float(refund_amount), # Provider might expect float\n+                amount_to_refund=float(refund_amount),  # Provider might expect float\n                 reason=refund_data.reason,\n                 # Pass item details if provider supports itemized refunds\n-                items_to_refund=[{\"line_id\": i.line_id, \"quantity\": i.qty} for i in refund_data.items or []]\n-            )\n-            gateway_refund_id = refund_result.get(\"refund_id\") or refund_result.get(\"id\")\n+                items_to_refund=[\n+                    {\"line_id\": i.line_id, \"quantity\": i.qty}\n+                    for i in refund_data.items or []\n+                ],\n+            )\n+            gateway_refund_id = refund_result.get(\"refund_id\") or refund_result.get(\n+                \"id\"\n+            )\n             refund_status_message = refund_result.get(\"status\", \"processed\")\n-            if not refund_result.get(\"success\", True): # Assuming provider returns a success flag\n-                 raise FynloException(\n+            if not refund_result.get(\n+                \"success\", True\n+            ):  # Assuming provider returns a success flag\n+                raise FynloException(\n                     message=f\"Gateway refund failed: {refund_result.get('error', 'Unknown error')}\",\n                     error_code=ErrorCodes.PAYMENT_GATEWAY_ERROR,\n-                    status_code=status.HTTP_502_BAD_GATEWAY\n+                    status_code=status.HTTP_502_BAD_GATEWAY,\n                 )\n         except Exception as e:\n-            logger.error(f\"Error processing refund with gateway {payment_provider_code} for order {order_id}: {e}\")\n+            logger.error(\n+                f\"Error processing refund with gateway {payment_provider_code} for order {order_id}: {e}\"\n+            )\n             raise FynloException(\n                 message=f\"Gateway refund processing error: {str(e)}\",\n                 error_code=ErrorCodes.PAYMENT_GATEWAY_ERROR,\n-                status_code=status.HTTP_502_BAD_GATEWAY\n+                status_code=status.HTTP_502_BAD_GATEWAY,\n             )\n \n     # (FR-5) Create Refund record and Ledger entry (FR-8)\n     # This should be in a transaction\n     try:\n-        with transaction_manager(db_session=db): # Using the new transaction manager\n+        with transaction_manager(db_session=db):  # Using the new transaction manager\n             new_refund = Refund(\n-                order_id=str(order.id), # Assuming order.id is UUID, convert to string if schema expects string\n+                order_id=str(\n+                    order.id\n+                ),  # Assuming order.id is UUID, convert to string if schema expects string\n                 amount=refund_amount,\n                 reason=refund_data.reason,\n                 # gateway_refund_id=gateway_refund_id, # Add this field to Refund model if needed\n                 # status=refund_status_message # Add this field to Refund model\n             )\n             db.add(new_refund)\n-            db.flush() # To get new_refund.id\n+            db.flush()  # To get new_refund.id\n \n             new_ledger_entry = RefundLedger(\n                 refund_id=new_refund.id,\n-                user_id=str(db_user.id), # Assuming db_user.id is UUID\n-                device_id= \"server_initiated\",                 action=\"refund_processed\",\n+                user_id=str(db_user.id),  # Assuming db_user.id is UUID\n+                device_id=\"server_initiated\",\n+                action=\"refund_processed\",\n                 # timestamp is server_default\n             )\n             db.add(new_ledger_entry)\n \n             # (FR-5) Update order status or refunds array\n             if is_full_refund:\n-                order.status = \"refunded\" # Or a specific \"fully_refunded\" status\n+                order.status = \"refunded\"  # Or a specific \"fully_refunded\" status\n                 # Disable further refunds (FR-X, implied from \"disables further refunds\")\n                 # This could be a flag on the order, or logic checking existing refunds\n             else:\n                 # If your Order model has a JSONB 'refunds' field or similar:\n-                current_refunds = getattr(order, 'refund_details', []) # Assuming 'refund_details' is JSONB field\n-                if not isinstance(current_refunds, list): current_refunds = []\n-                current_refunds.append({\n-                    \"refund_id\": str(new_refund.id),\n-                    \"amount\": float(refund_amount), # Store as float in JSON\n-                    \"reason\": refund_data.reason,\n-                    \"items\": [{\"line_id\": i.line_id, \"qty\": i.qty} for i in refund_data.items or []],\n-                    \"timestamp\": datetime.utcnow().isoformat()\n-                })\n-                setattr(order, 'refund_details', current_refunds)\n-                order.status = \"partially_refunded\" # Or keep 'completed' and rely on refund_details\n+                current_refunds = getattr(\n+                    order, \"refund_details\", []\n+                )  # Assuming 'refund_details' is JSONB field\n+                if not isinstance(current_refunds, list):\n+                    current_refunds = []\n+                current_refunds.append(\n+                    {\n+                        \"refund_id\": str(new_refund.id),\n+                        \"amount\": float(refund_amount),  # Store as float in JSON\n+                        \"reason\": refund_data.reason,\n+                        \"items\": [\n+                            {\"line_id\": i.line_id, \"qty\": i.qty}\n+                            for i in refund_data.items or []\n+                        ],\n+                        \"timestamp\": datetime.utcnow().isoformat(),\n+                    }\n+                )\n+                setattr(order, \"refund_details\", current_refunds)\n+                order.status = \"partially_refunded\"  # Or keep 'completed' and rely on refund_details\n \n             order.updated_at = datetime.utcnow()\n             db.add(order)\n             # db.commit() # Handled by transaction_manager\n-            db.refresh(new_refund) # To get all fields like created_at\n+            db.refresh(new_refund)  # To get all fields like created_at\n \n     except Exception as e:\n         # db.rollback() # Handled by transaction_manager\n-        logger.error(f\"Database error during refund processing for order {order_id}: {e}\")\n+        logger.error(\n+            f\"Database error during refund processing for order {order_id}: {e}\"\n+        )\n         raise FynloException(\n             message=\"Failed to save refund details.\",\n             error_code=ErrorCodes.DATABASE_ERROR,\n-            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR\n+            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n         )\n \n     # (FR-5) Emit orders.updated via WebSocket\n     try:\n         message_data = {\n             \"order_id\": str(order.id),\n             \"new_status\": order.status,\n             \"refund_details\": {\n                 \"refund_id\": str(new_refund.id),\n                 \"amount\": float(refund_amount),\n-                \"is_full\": is_full_refund\n-            }\n+                \"is_full\": is_full_refund,\n+            },\n         }\n-        event_type = EventType.ORDER_REFUNDED # Define this in your EventType enum\n-        ws_message = WebSocketMessage(event_type=event_type, data=message_data, target_restaurant=str(order.restaurant_id))\n-        await websocket_manager.broadcast_to_restaurant(str(order.restaurant_id), ws_message)\n+        event_type = EventType.ORDER_REFUNDED  # Define this in your EventType enum\n+        ws_message = WebSocketMessage(\n+            event_type=event_type,\n+            data=message_data,\n+            target_restaurant=str(order.restaurant_id),\n+        )\n+        await websocket_manager.broadcast_to_restaurant(\n+            str(order.restaurant_id), ws_message\n+        )\n     except Exception as ws_error:\n-        logger.warning(f\"WebSocket notification for refund failed for order {order.id}: {ws_error}\")\n-\n+        logger.warning(\n+            f\"WebSocket notification for refund failed for order {order.id}: {ws_error}\"\n+        )\n \n     # (FR-6) Customer receives e-mail receipt \"Refund processed \u2013 \u00a3X.XX\".\n-    customer_email = getattr(order, 'customer_email', None) # Assuming Order model has customer_email\n+    customer_email = getattr(\n+        order, \"customer_email\", None\n+    )  # Assuming Order model has customer_email\n     if not customer_email and order.customer_id:\n         # Attempt to fetch customer email if not directly on order\n-        customer = db.query(UserModel).filter(UserModel.id == order.customer_id).first() # Or Customer model\n+        customer = (\n+            db.query(UserModel).filter(UserModel.id == order.customer_id).first()\n+        )  # Or Customer model\n         if customer:\n             customer_email = customer.email\n \n     if customer_email:\n         try:\n@@ -1057,22 +1244,30 @@\n             # We need to ensure the `order` object passed to `send_receipt` has the fields the template expects.\n             # The template uses: order.order_number, order.items, order.total_amount, order.subtotal, order.tax_amount, order.service_charge\n             # The `order` object from `db.query(Order)` should have these.\n \n             # The `amount` for the email service is the refund_amount\n-            email_service.send_receipt(order=order, type_='refund', amount=float(refund_amount))\n-            logger.info(f\"Refund receipt email initiated for order {order.id} to {customer_email}\")\n+            email_service.send_receipt(\n+                order=order, type_=\"refund\", amount=float(refund_amount)\n+            )\n+            logger.info(\n+                f\"Refund receipt email initiated for order {order.id} to {customer_email}\"\n+            )\n         except Exception as email_exc:\n-            logger.error(f\"Failed to send refund receipt email for order {order.id}: {email_exc}\")\n+            logger.error(\n+                f\"Failed to send refund receipt email for order {order.id}: {email_exc}\"\n+            )\n             # Do not fail the refund if email sending fails, but log it.\n     else:\n-        logger.info(f\"No customer email found for order {order.id}, skipping refund receipt email.\")\n+        logger.info(\n+            f\"No customer email found for order {order.id}, skipping refund receipt email.\"\n+        )\n \n     return RefundResponseSchema(\n         id=new_refund.id,\n         order_id=str(order.id),\n         amount=new_refund.amount,\n         reason=new_refund.reason,\n-        status=refund_status_message, # This should reflect the actual outcome\n+        status=refund_status_message,  # This should reflect the actual outcome\n         gateway_refund_id=gateway_refund_id,\n-        created_at=new_refund.created_at.isoformat()\n-    )\n\\ No newline at end of file\n+        created_at=new_refund.created_at.isoformat(),\n+    )\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/products.py\t2025-08-02 19:23:36.811245+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/products.py\t2025-08-02 22:36:03.037749+00:00\n@@ -17,27 +17,30 @@\n from app.core.tenant_security import TenantSecurity\n from app.core.cache_service import cache_service\n \n router = APIRouter()\n \n+\n # Pydantic models\n class CategoryCreate(BaseModel):\n     name: str\n     description: Optional[str] = None\n     color: str = \"#00A651\"\n     icon: Optional[str] = None\n     sort_order: int = 0\n+\n \n class CategoryResponse(BaseModel):\n     id: str\n     name: str\n     description: Optional[str]\n     color: str\n     icon: Optional[str]\n     sort_order: int\n     is_active: bool\n     created_at: datetime\n+\n \n class ProductCreate(BaseModel):\n     category_id: str\n     name: str\n     description: Optional[str] = None\n@@ -49,10 +52,11 @@\n     prep_time: int = 0\n     dietary_info: List[str] = []\n     modifiers: List[dict] = []\n     stock_tracking: bool = False\n     stock_quantity: int = 0\n+\n \n class ProductUpdate(BaseModel):\n     category_id: Optional[str] = None\n     name: Optional[str] = None\n     description: Optional[str] = None\n@@ -65,10 +69,11 @@\n     dietary_info: Optional[List[str]] = None\n     modifiers: Optional[List[dict]] = None\n     stock_tracking: Optional[bool] = None\n     stock_quantity: Optional[int] = None\n     is_active: Optional[bool] = None\n+\n \n class ProductResponse(BaseModel):\n     id: str\n     category_id: str\n     name: str\n@@ -85,244 +90,260 @@\n     stock_tracking: bool\n     stock_quantity: int\n     created_at: datetime\n     updated_at: Optional[datetime]\n \n+\n class MenuResponse(BaseModel):\n     categories: List[CategoryResponse]\n     products: List[ProductResponse]\n+\n \n # Category endpoints\n @router.get(\"/categories\", response_model=List[CategoryResponse])\n async def get_categories(\n     restaurant_id: Optional[str] = Query(None),\n     db: Session = Depends(get_db),\n     current_user: User = Depends(get_current_user),\n-    redis: RedisClient = Depends(get_redis)\n+    redis: RedisClient = Depends(get_redis),\n ):\n     \"\"\"Get all categories for a restaurant\"\"\"\n-    \n+\n     # Use user's restaurant if not specified\n     if not restaurant_id:\n         restaurant_id = str(current_user.restaurant_id)\n-    \n+\n     # Check cache first\n     cached_categories = await redis.get(f\"categories:{restaurant_id}\")\n     if cached_categories:\n         return APIResponseHelper.success(\n             data=cached_categories,\n-            message=f\"Retrieved {len(cached_categories)} categories\"\n-        )\n-    \n-    categories = db.query(Category).filter(\n-        and_(Category.restaurant_id == restaurant_id, Category.is_active == True)\n-    ).order_by(Category.sort_order, Category.name).all()\n-    \n+            message=f\"Retrieved {len(cached_categories)} categories\",\n+        )\n+\n+    categories = (\n+        db.query(Category)\n+        .filter(\n+            and_(Category.restaurant_id == restaurant_id, Category.is_active == True)\n+        )\n+        .order_by(Category.sort_order, Category.name)\n+        .all()\n+    )\n+\n     result = [\n         CategoryResponse(\n             id=str(cat.id),\n             name=cat.name,\n             description=cat.description,\n             color=cat.color,\n             icon=cat.icon,\n             sort_order=cat.sort_order,\n             is_active=cat.is_active,\n-            created_at=cat.created_at\n+            created_at=cat.created_at,\n         )\n         for cat in categories\n     ]\n-    \n+\n     # Convert to dicts for consistent API response\n     response_data = [cat.model_dump() for cat in result]\n-    \n+\n     # Cache for 5 minutes\n     await redis.set(f\"categories:{restaurant_id}\", response_data, expire=300)\n-    \n+\n     return APIResponseHelper.success(\n-        data=response_data,\n-        message=f\"Retrieved {len(response_data)} categories\"\n-    )\n+        data=response_data, message=f\"Retrieved {len(response_data)} categories\"\n+    )\n+\n \n @router.post(\"/categories\", response_model=CategoryResponse)\n async def create_category(\n     category_data: CategoryCreate,\n     restaurant_id: Optional[str] = Query(None),\n     db: Session = Depends(get_db),\n     current_user: User = Depends(get_current_user),\n-    redis: RedisClient = Depends(get_redis)\n+    redis: RedisClient = Depends(get_redis),\n ):\n     \"\"\"Create a new category\"\"\"\n-    \n+\n     # Use user's restaurant if not specified\n     if not restaurant_id:\n         restaurant_id = str(current_user.restaurant_id)\n-    \n+\n     new_category = Category(\n         restaurant_id=restaurant_id,\n         name=category_data.name,\n         description=category_data.description,\n         color=category_data.color,\n         icon=category_data.icon,\n-        sort_order=category_data.sort_order\n-    )\n-    \n+        sort_order=category_data.sort_order,\n+    )\n+\n     db.add(new_category)\n     db.commit()\n     db.refresh(new_category)\n-    \n+\n     # Clear categories cache using enhanced cache service\n     await cache_service.invalidate_restaurant_cache(restaurant_id)\n-    \n+\n     category_response = CategoryResponse(\n         id=str(new_category.id),\n         name=new_category.name,\n         description=new_category.description,\n         color=new_category.color,\n         icon=new_category.icon,\n         sort_order=new_category.sort_order,\n         is_active=new_category.is_active,\n-        created_at=new_category.created_at\n-    )\n-    \n+        created_at=new_category.created_at,\n+    )\n+\n     return APIResponseHelper.success(\n         data=category_response.dict(),\n-        message=f\"Category '{new_category.name}' created successfully\"\n-    )\n+        message=f\"Category '{new_category.name}' created successfully\",\n+    )\n+\n \n @router.put(\"/categories/{category_id}\", response_model=CategoryResponse)\n async def update_category(\n     category_id: str,\n     category_data: CategoryCreate,\n     db: Session = Depends(get_db),\n     current_user: User = Depends(get_current_user),\n-    redis: RedisClient = Depends(get_redis)\n+    redis: RedisClient = Depends(get_redis),\n ):\n     \"\"\"Update a category\"\"\"\n-    \n+\n     # Find the category\n-    category = db.query(Category).filter(\n-        Category.id == category_id,\n-        Category.restaurant_id == current_user.restaurant_id\n-    ).first()\n-    \n+    category = (\n+        db.query(Category)\n+        .filter(\n+            Category.id == category_id,\n+            Category.restaurant_id == current_user.restaurant_id,\n+        )\n+        .first()\n+    )\n+\n     if not category:\n         raise FynloException(\n-            error_code=ErrorCodes.RESOURCE_NOT_FOUND,\n-            detail=\"Category not found\"\n-        )\n-    \n+            error_code=ErrorCodes.RESOURCE_NOT_FOUND, detail=\"Category not found\"\n+        )\n+\n     # Update fields\n     category.name = category_data.name\n     category.description = category_data.description\n     category.color = category_data.color\n     category.icon = category_data.icon\n     category.sort_order = category_data.sort_order\n     category.updated_at = datetime.utcnow()\n-    \n+\n     db.commit()\n     db.refresh(category)\n-    \n+\n     # Clear categories cache using enhanced cache service\n     await cache_service.invalidate_restaurant_cache(str(category.restaurant_id))\n-    \n+\n     category_response = CategoryResponse(\n         id=str(category.id),\n         name=category.name,\n         description=category.description,\n         color=category.color,\n         icon=category.icon,\n         sort_order=category.sort_order,\n         is_active=category.is_active,\n-        created_at=category.created_at\n-    )\n-    \n+        created_at=category.created_at,\n+    )\n+\n     return APIResponseHelper.success(\n         data=category_response.dict(),\n-        message=f\"Category '{category.name}' updated successfully\"\n-    )\n+        message=f\"Category '{category.name}' updated successfully\",\n+    )\n+\n \n @router.delete(\"/categories/{category_id}\")\n async def delete_category(\n     category_id: str,\n     db: Session = Depends(get_db),\n     current_user: User = Depends(get_current_user),\n-    redis: RedisClient = Depends(get_redis)\n+    redis: RedisClient = Depends(get_redis),\n ):\n     \"\"\"Delete a category (soft delete)\"\"\"\n-    \n+\n     # Find the category\n-    category = db.query(Category).filter(\n-        Category.id == category_id,\n-        Category.restaurant_id == current_user.restaurant_id\n-    ).first()\n-    \n+    category = (\n+        db.query(Category)\n+        .filter(\n+            Category.id == category_id,\n+            Category.restaurant_id == current_user.restaurant_id,\n+        )\n+        .first()\n+    )\n+\n     if not category:\n         raise FynloException(\n-            error_code=ErrorCodes.RESOURCE_NOT_FOUND,\n-            detail=\"Category not found\"\n-        )\n-    \n+            error_code=ErrorCodes.RESOURCE_NOT_FOUND, detail=\"Category not found\"\n+        )\n+\n     # Check if category has products\n-    product_count = db.query(Product).filter(\n-        Product.category_id == category_id,\n-        Product.is_active == True\n-    ).count()\n-    \n+    product_count = (\n+        db.query(Product)\n+        .filter(Product.category_id == category_id, Product.is_active == True)\n+        .count()\n+    )\n+\n     if product_count > 0:\n         raise FynloException(\n             error_code=ErrorCodes.VALIDATION_ERROR,\n-            detail=f\"Cannot delete category with {product_count} active products\"\n-        )\n-    \n+            detail=f\"Cannot delete category with {product_count} active products\",\n+        )\n+\n     # Soft delete\n     category.is_active = False\n     category.updated_at = datetime.utcnow()\n-    \n+\n     db.commit()\n-    \n+\n     # Clear categories cache using enhanced cache service\n     await cache_service.invalidate_restaurant_cache(str(category.restaurant_id))\n-    \n+\n     return APIResponseHelper.success(\n         message=f\"Category '{category.name}' deleted successfully\"\n     )\n+\n \n # Product endpoints\n @router.get(\"/\", response_model=List[ProductResponse])\n async def get_products(\n     restaurant_id: Optional[str] = Query(None),\n     category_id: Optional[str] = Query(None),\n     active_only: bool = Query(True),\n     db: Session = Depends(get_db),\n     current_user: User = Depends(get_current_user),\n-    redis: RedisClient = Depends(get_redis)\n+    redis: RedisClient = Depends(get_redis),\n ):\n     \"\"\"Get all products for a restaurant\"\"\"\n-    \n+\n     # Use user's restaurant if not specified\n     if not restaurant_id:\n         restaurant_id = str(current_user.restaurant_id)\n-    \n+\n     # Check cache first\n     cache_key = f\"products:{restaurant_id}:{category_id or 'all'}:{active_only}\"\n     cached_products = await redis.get(cache_key)\n     if cached_products:\n         return APIResponseHelper.success(\n-            data=cached_products,\n-            message=f\"Retrieved {len(cached_products)} products\"\n-        )\n-    \n+            data=cached_products, message=f\"Retrieved {len(cached_products)} products\"\n+        )\n+\n     query = db.query(Product).filter(Product.restaurant_id == restaurant_id)\n-    \n+\n     if category_id:\n         query = query.filter(Product.category_id == category_id)\n-    \n+\n     if active_only:\n         query = query.filter(Product.is_active == True)\n-    \n+\n     products = query.order_by(Product.name).all()\n-    \n+\n     result = [\n         ProductResponse(\n             id=str(product.id),\n             category_id=str(product.category_id),\n             name=product.name,\n@@ -337,74 +358,82 @@\n             modifiers=product.modifiers,\n             is_active=product.is_active,\n             stock_tracking=product.stock_tracking,\n             stock_quantity=product.stock_quantity,\n             created_at=product.created_at,\n-            updated_at=product.updated_at\n+            updated_at=product.updated_at,\n         )\n         for product in products\n     ]\n-    \n+\n     # Convert to dicts for consistent API response\n     response_data = [prod.model_dump() for prod in result]\n-    \n+\n     # Cache for 5 minutes\n     await redis.set(cache_key, response_data, expire=300)\n-    \n+\n     return APIResponseHelper.success(\n         data=response_data,\n         message=f\"Retrieved {len(response_data)} products\",\n         meta={\n             \"restaurant_id\": restaurant_id,\n             \"category_id\": category_id,\n             \"active_only\": active_only,\n-            \"total_count\": len(result)\n-        }\n-    )\n+            \"total_count\": len(result),\n+        },\n+    )\n+\n \n @router.get(\"/menu\", response_model=MenuResponse)\n async def get_full_menu(\n     restaurant_id: Optional[str] = Query(None),\n     db: Session = Depends(get_db),\n     current_user: User = Depends(get_current_user),\n-    redis: RedisClient = Depends(get_redis)\n+    redis: RedisClient = Depends(get_redis),\n ):\n     \"\"\"Get complete menu with categories and products\"\"\"\n-    \n+\n     # Use user's restaurant if not specified\n     if not restaurant_id:\n         restaurant_id = str(current_user.restaurant_id)\n-    \n+\n     # Check cache first\n     cached_menu = await redis.get_cached_menu(restaurant_id)\n     if cached_menu:\n         return APIResponseHelper.success(\n-            data=cached_menu,\n-            message=\"Menu retrieved from cache\"\n-        )\n-    \n+            data=cached_menu, message=\"Menu retrieved from cache\"\n+        )\n+\n     # Get categories\n-    categories = db.query(Category).filter(\n-        and_(Category.restaurant_id == restaurant_id, Category.is_active == True)\n-    ).order_by(Category.sort_order, Category.name).all()\n-    \n+    categories = (\n+        db.query(Category)\n+        .filter(\n+            and_(Category.restaurant_id == restaurant_id, Category.is_active == True)\n+        )\n+        .order_by(Category.sort_order, Category.name)\n+        .all()\n+    )\n+\n     # Get products\n-    products = db.query(Product).filter(\n-        and_(Product.restaurant_id == restaurant_id, Product.is_active == True)\n-    ).order_by(Product.name).all()\n-    \n+    products = (\n+        db.query(Product)\n+        .filter(and_(Product.restaurant_id == restaurant_id, Product.is_active == True))\n+        .order_by(Product.name)\n+        .all()\n+    )\n+\n     result = MenuResponse(\n         categories=[\n             CategoryResponse(\n                 id=str(cat.id),\n                 name=cat.name,\n                 description=cat.description,\n                 color=cat.color,\n                 icon=cat.icon,\n                 sort_order=cat.sort_order,\n                 is_active=cat.is_active,\n-                created_at=cat.created_at\n+                created_at=cat.created_at,\n             )\n             for cat in categories\n         ],\n         products=[\n             ProductResponse(\n@@ -422,54 +451,61 @@\n                 modifiers=product.modifiers,\n                 is_active=product.is_active,\n                 stock_tracking=product.stock_tracking,\n                 stock_quantity=product.stock_quantity,\n                 created_at=product.created_at,\n-                updated_at=product.updated_at\n+                updated_at=product.updated_at,\n             )\n             for product in products\n-        ]\n-    )\n-    \n+        ],\n+    )\n+\n     # Cache for 10 minutes\n     await redis.cache_menu(restaurant_id, result.dict(), expire=600)\n-    \n+\n     return APIResponseHelper.success(\n         data=result.dict(),\n         message=f\"Retrieved complete menu with {len(result.categories)} categories and {len(result.products)} products\",\n         meta={\n             \"restaurant_id\": restaurant_id,\n             \"categories_count\": len(result.categories),\n-            \"products_count\": len(result.products)\n-        }\n-    )\n+            \"products_count\": len(result.products),\n+        },\n+    )\n+\n \n @router.post(\"/\", response_model=ProductResponse)\n async def create_product(\n     product_data: ProductCreate,\n     restaurant_id: Optional[str] = Query(None),\n     db: Session = Depends(get_db),\n     current_user: User = Depends(get_current_user),\n-    redis: RedisClient = Depends(get_redis)\n+    redis: RedisClient = Depends(get_redis),\n ):\n     \"\"\"Create a new product\"\"\"\n-    \n+\n     # Use user's restaurant if not specified\n     if not restaurant_id:\n         restaurant_id = str(current_user.restaurant_id)\n-    \n+\n     # Verify category exists\n-    category = db.query(Category).filter(\n-        and_(Category.id == product_data.category_id, Category.restaurant_id == restaurant_id)\n-    ).first()\n-    \n+    category = (\n+        db.query(Category)\n+        .filter(\n+            and_(\n+                Category.id == product_data.category_id,\n+                Category.restaurant_id == restaurant_id,\n+            )\n+        )\n+        .first()\n+    )\n+\n     if not category:\n         raise FynloException(\n-            error_code=ErrorCodes.RESOURCE_NOT_FOUND,\n-            detail=\"Category not found\"\n-        )\n-    \n+            error_code=ErrorCodes.RESOURCE_NOT_FOUND, detail=\"Category not found\"\n+        )\n+\n     new_product = Product(\n         restaurant_id=restaurant_id,\n         category_id=product_data.category_id,\n         name=product_data.name,\n         description=product_data.description,\n@@ -480,20 +516,20 @@\n         sku=product_data.sku,\n         prep_time=product_data.prep_time,\n         dietary_info=product_data.dietary_info,\n         modifiers=product_data.modifiers,\n         stock_tracking=product_data.stock_tracking,\n-        stock_quantity=product_data.stock_quantity\n-    )\n-    \n+        stock_quantity=product_data.stock_quantity,\n+    )\n+\n     db.add(new_product)\n     db.commit()\n     db.refresh(new_product)\n-    \n+\n     # Clear caches using enhanced cache service\n     await cache_service.invalidate_restaurant_cache(restaurant_id)\n-    \n+\n     return ProductResponse(\n         id=str(new_product.id),\n         category_id=str(new_product.category_id),\n         name=new_product.name,\n         description=new_product.description,\n@@ -507,40 +543,40 @@\n         modifiers=new_product.modifiers,\n         is_active=new_product.is_active,\n         stock_tracking=new_product.stock_tracking,\n         stock_quantity=new_product.stock_quantity,\n         created_at=new_product.created_at,\n-        updated_at=new_product.updated_at\n-    )\n+        updated_at=new_product.updated_at,\n+    )\n+\n \n @router.put(\"/{product_id}\", response_model=ProductResponse)\n async def update_product(\n     product_id: str,\n     product_data: ProductUpdate,\n     db: Session = Depends(get_db),\n     current_user: User = Depends(get_current_user),\n-    redis: RedisClient = Depends(get_redis)\n+    redis: RedisClient = Depends(get_redis),\n ):\n     \"\"\"Update a product\"\"\"\n-    \n+\n     product = db.query(Product).filter(Product.id == product_id).first()\n     if not product:\n         raise FynloException(\n-            error_code=ErrorCodes.RESOURCE_NOT_FOUND,\n-            detail=\"Product not found\"\n-        )\n-    \n+            error_code=ErrorCodes.RESOURCE_NOT_FOUND, detail=\"Product not found\"\n+        )\n+\n     # Verify user has access to the product's restaurant\n     await TenantSecurity.validate_restaurant_access(\n         user=current_user,\n         restaurant_id=str(product.restaurant_id),\n         operation=\"modify\",\n         resource_type=\"product\",\n         resource_id=product_id,\n-        db=db\n-    )\n-    \n+        db=db,\n+    )\n+\n     # Update fields if provided\n     if product_data.category_id is not None:\n         product.category_id = product_data.category_id\n     if product_data.name is not None:\n         product.name = product_data.name\n@@ -566,19 +602,19 @@\n         product.stock_tracking = product_data.stock_tracking\n     if product_data.stock_quantity is not None:\n         product.stock_quantity = product_data.stock_quantity\n     if product_data.is_active is not None:\n         product.is_active = product_data.is_active\n-    \n+\n     product.updated_at = datetime.utcnow()\n     db.commit()\n     db.refresh(product)\n-    \n+\n     # Clear caches using enhanced cache service\n     restaurant_id = str(product.restaurant_id)\n     await cache_service.invalidate_restaurant_cache(restaurant_id)\n-    \n+\n     return ProductResponse(\n         id=str(product.id),\n         category_id=str(product.category_id),\n         name=product.name,\n         description=product.description,\n@@ -592,48 +628,49 @@\n         modifiers=product.modifiers,\n         is_active=product.is_active,\n         stock_tracking=product.stock_tracking,\n         stock_quantity=product.stock_quantity,\n         created_at=product.created_at,\n-        updated_at=product.updated_at\n-    )\n+        updated_at=product.updated_at,\n+    )\n+\n \n @router.delete(\"/{product_id}\")\n async def delete_product(\n     product_id: str,\n     db: Session = Depends(get_db),\n     current_user: User = Depends(get_current_user),\n-    redis: RedisClient = Depends(get_redis)\n+    redis: RedisClient = Depends(get_redis),\n ):\n     \"\"\"Soft delete a product\"\"\"\n-    \n+\n     product = db.query(Product).filter(Product.id == product_id).first()\n     if not product:\n         raise FynloException(\n-            error_code=ErrorCodes.RESOURCE_NOT_FOUND,\n-            detail=\"Product not found\"\n-        )\n-    \n+            error_code=ErrorCodes.RESOURCE_NOT_FOUND, detail=\"Product not found\"\n+        )\n+\n     # Verify user has access to the product's restaurant\n     await TenantSecurity.validate_restaurant_access(\n         user=current_user,\n         restaurant_id=str(product.restaurant_id),\n         operation=\"delete\",\n         resource_type=\"product\",\n         resource_id=product_id,\n-        db=db\n-    )\n-    \n+        db=db,\n+    )\n+\n     product.is_active = False\n     product.updated_at = datetime.utcnow()\n     db.commit()\n-    \n+\n     # Clear caches using enhanced cache service\n     restaurant_id = str(product.restaurant_id)\n     await cache_service.invalidate_restaurant_cache(restaurant_id)\n-    \n+\n     return APIResponseHelper.success(message=\"Product deleted successfully\")\n+\n \n # Mobile-optimized endpoints\n class MobileProductResponse(BaseModel):\n     id: int  # Frontend expects integer ID\n     name: str\n@@ -642,151 +679,165 @@\n     image: Optional[str] = None  # Frontend expects 'image' not 'image_url'\n     barcode: Optional[str] = None\n     available_in_pos: bool = True  # Frontend expects this field\n     active: bool  # Frontend expects 'active' not 'is_active'\n \n+\n @router.get(\"/mobile\")\n async def get_products_mobile(\n     restaurant_id: Optional[str] = Query(None),\n     db: Session = Depends(get_db),\n     current_user: User = Depends(get_current_user),\n-    redis: RedisClient = Depends(get_redis)\n+    redis: RedisClient = Depends(get_redis),\n ):\n     \"\"\"Get mobile-optimized products list matching frontend expectations\"\"\"\n-    \n+\n     # Use user's restaurant if not specified\n     if not restaurant_id:\n         restaurant_id = str(current_user.restaurant_id)\n-    \n+\n     # Check cache first\n     cache_key = f\"products:mobile:{restaurant_id}\"\n     cached_products = await redis.get(cache_key)\n     if cached_products:\n         return APIResponseHelper.success(data=cached_products)\n-    \n+\n     # Get products with category info\n-    products_query = db.query(Product, Category).join(\n-        Category, Product.category_id == Category.id\n-    ).filter(\n-        and_(\n-            Product.restaurant_id == restaurant_id,\n-            Product.is_active == True,\n-            Category.is_active == True\n-        )\n-    ).order_by(Category.sort_order, Product.name)\n-    \n+    products_query = (\n+        db.query(Product, Category)\n+        .join(Category, Product.category_id == Category.id)\n+        .filter(\n+            and_(\n+                Product.restaurant_id == restaurant_id,\n+                Product.is_active == True,\n+                Category.is_active == True,\n+            )\n+        )\n+        .order_by(Category.sort_order, Product.name)\n+    )\n+\n     products_with_categories = products_query.all()\n-    \n+\n     result = [\n         {\n             \"id\": str(product.id),  # Keep UUID as string for consistency\n             \"name\": product.name,\n             \"price\": str(product.price),  # Keep as string to preserve precision\n             \"category\": category.name,\n             \"image\": product.image_url,\n             \"barcode\": product.barcode,\n             \"available_in_pos\": True,\n-            \"active\": product.is_active\n+            \"active\": product.is_active,\n         }\n         for product, category in products_with_categories\n     ]\n-    \n+\n     # Cache for 5 minutes\n     await redis.set(cache_key, result, expire=300)\n-    \n+\n     return APIResponseHelper.success(\n-        data=result,\n-        message=f\"Retrieved {len(result)} mobile products\"\n-    )\n+        data=result, message=f\"Retrieved {len(result)} mobile products\"\n+    )\n+\n \n @router.get(\"/category/{category_id}\")\n async def get_products_by_category(\n     category_id: int,\n     restaurant_id: Optional[str] = Query(None),\n     db: Session = Depends(get_db),\n     current_user: User = Depends(get_current_user),\n-    redis: RedisClient = Depends(get_redis)\n+    redis: RedisClient = Depends(get_redis),\n ):\n     \"\"\"Get products by category ID - mobile compatible\"\"\"\n-    \n+\n     # Use user's restaurant if not specified\n     if not restaurant_id:\n         restaurant_id = str(current_user.restaurant_id)\n-    \n+\n     # Check cache first\n     cache_key = f\"products:category:{category_id}:{restaurant_id}\"\n     cached_products = await redis.get(cache_key)\n     if cached_products:\n         return APIResponseHelper.success(data=cached_products)\n-    \n+\n     # Find category by ID\n-    category = db.query(Category).filter(\n-        and_(Category.id == str(category_id), Category.restaurant_id == restaurant_id)\n-    ).first()\n-    \n+    category = (\n+        db.query(Category)\n+        .filter(\n+            and_(\n+                Category.id == str(category_id), Category.restaurant_id == restaurant_id\n+            )\n+        )\n+        .first()\n+    )\n+\n     if not category:\n         raise FynloException(\n-            error_code=ErrorCodes.RESOURCE_NOT_FOUND,\n-            detail=\"Category not found\"\n-        )\n-    \n+            error_code=ErrorCodes.RESOURCE_NOT_FOUND, detail=\"Category not found\"\n+        )\n+\n     # Get products in this category\n-    products = db.query(Product).filter(\n-        and_(\n-            Product.category_id == str(category_id),\n-            Product.restaurant_id == restaurant_id,\n-            Product.is_active == True\n-        )\n-    ).order_by(Product.name).all()\n-    \n+    products = (\n+        db.query(Product)\n+        .filter(\n+            and_(\n+                Product.category_id == str(category_id),\n+                Product.restaurant_id == restaurant_id,\n+                Product.is_active == True,\n+            )\n+        )\n+        .order_by(Product.name)\n+        .all()\n+    )\n+\n     result = [\n         {\n             \"id\": str(product.id),  # Keep UUID as string for consistency\n             \"name\": product.name,\n             \"price\": str(product.price),  # Keep as string to preserve precision\n             \"category\": category.name,\n             \"image\": product.image_url,\n             \"barcode\": product.barcode,\n             \"available_in_pos\": True,\n-            \"active\": product.is_active\n+            \"active\": product.is_active,\n         }\n         for product in products\n     ]\n-    \n+\n     # Cache for 5 minutes\n     await redis.set(cache_key, result, expire=300)\n-    \n+\n     return APIResponseHelper.success(\n         data=result,\n-        message=f\"Retrieved {len(result)} products in category '{category.name}'\"\n-    )\n+        message=f\"Retrieved {len(result)} products in category '{category.name}'\",\n+    )\n+\n \n @router.get(\"/{product_id}\", response_model=ProductResponse)\n async def get_product(\n     product_id: str,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Get a specific product\"\"\"\n-    \n+\n     product = db.query(Product).filter(Product.id == product_id).first()\n     if not product:\n         raise FynloException(\n-            error_code=ErrorCodes.RESOURCE_NOT_FOUND,\n-            detail=\"Product not found\"\n-        )\n-    \n+            error_code=ErrorCodes.RESOURCE_NOT_FOUND, detail=\"Product not found\"\n+        )\n+\n     # Verify user has access to the product's restaurant\n     await TenantSecurity.validate_restaurant_access(\n         user=current_user,\n         restaurant_id=str(product.restaurant_id),\n         operation=\"access\",\n         resource_type=\"product\",\n         resource_id=product_id,\n-        db=db\n-    )\n-    \n+        db=db,\n+    )\n+\n     return ProductResponse(\n         id=str(product.id),\n         category_id=str(product.category_id),\n         name=product.name,\n         description=product.description,\n@@ -800,7 +851,7 @@\n         modifiers=product.modifiers,\n         is_active=product.is_active,\n         stock_tracking=product.stock_tracking,\n         stock_quantity=product.stock_quantity,\n         created_at=product.created_at,\n-        updated_at=product.updated_at\n-    )\n\\ No newline at end of file\n+        updated_at=product.updated_at,\n+    )\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/sync.py\t2025-08-02 10:59:17.989915+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/sync.py\t2025-08-02 22:36:03.040574+00:00\n@@ -16,43 +16,66 @@\n from app.core.exceptions import FynloException, ErrorCodes\n from app.core.sync_manager import get_sync_manager, ConflictResolution\n \n router = APIRouter()\n \n+\n # Sync Models\n class SyncActionRequest(BaseModel):\n     \"\"\"Single sync action request\"\"\"\n+\n     id: Optional[str] = Field(default_factory=lambda: str(uuid.uuid4()))\n-    entity_type: str = Field(..., description=\"Type of entity (orders, products, customers, payments)\")\n+    entity_type: str = Field(\n+        ..., description=\"Type of entity (orders, products, customers, payments)\"\n+    )\n     entity_id: str = Field(..., description=\"ID of the entity\")\n     action: str = Field(..., description=\"Action type (create, update, delete)\")\n     data: Dict[str, Any] = Field(..., description=\"Entity data\")\n     client_timestamp: str = Field(..., description=\"Client timestamp in ISO format\")\n     version: int = Field(default=1, description=\"Entity version for optimistic locking\")\n \n+\n class BatchUploadRequest(BaseModel):\n     \"\"\"Batch upload request\"\"\"\n+\n     device_id: Optional[str] = Field(None, description=\"Device identifier\")\n-    sync_actions: List[SyncActionRequest] = Field(..., description=\"List of sync actions\")\n-    force_overwrite: bool = Field(default=False, description=\"Force overwrite on conflicts\")\n+    sync_actions: List[SyncActionRequest] = Field(\n+        ..., description=\"List of sync actions\"\n+    )\n+    force_overwrite: bool = Field(\n+        default=False, description=\"Force overwrite on conflicts\"\n+    )\n+\n \n class DownloadChangesRequest(BaseModel):\n     \"\"\"Download changes request\"\"\"\n-    last_sync_timestamp: Optional[str] = Field(None, description=\"Last sync timestamp in ISO format\")\n+\n+    last_sync_timestamp: Optional[str] = Field(\n+        None, description=\"Last sync timestamp in ISO format\"\n+    )\n     entity_types: Optional[List[str]] = Field(None, description=\"Entity types to sync\")\n-    limit: int = Field(default=1000, le=5000, description=\"Maximum number of changes to return\")\n+    limit: int = Field(\n+        default=1000, le=5000, description=\"Maximum number of changes to return\"\n+    )\n+\n \n class ConflictResolutionRequest(BaseModel):\n     \"\"\"Conflict resolution request\"\"\"\n-    resolution_strategy: str = Field(..., description=\"Resolution strategy (server_wins, client_wins, merge, manual)\")\n-    merged_data: Optional[Dict[str, Any]] = Field(None, description=\"Merged data for merge strategy\")\n+\n+    resolution_strategy: str = Field(\n+        ..., description=\"Resolution strategy (server_wins, client_wins, merge, manual)\"\n+    )\n+    merged_data: Optional[Dict[str, Any]] = Field(\n+        None, description=\"Merged data for merge strategy\"\n+    )\n+\n \n @router.post(\"/upload-batch\")\n async def upload_batch_actions(\n     request: BatchUploadRequest,\n     current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"\n     Upload batch of offline actions for synchronization\n     Handles conflict detection and resolution\n     \"\"\"\n@@ -61,68 +84,71 @@\n         restaurant_id = str(current_user.restaurant_id)\n         if not restaurant_id:\n             raise FynloException(\n                 message=\"User must be associated with a restaurant\",\n                 error_code=ErrorCodes.VALIDATION_ERROR,\n-                status_code=400\n-            )\n-        \n+                status_code=400,\n+            )\n+\n         # Convert Pydantic models to dict for processing\n         sync_actions = [action.dict() for action in request.sync_actions]\n-        \n+\n         # Get sync manager and process batch upload\n         sync_manager = get_sync_manager(db)\n         result = sync_manager.batch_upload(\n             sync_actions=sync_actions,\n             restaurant_id=restaurant_id,\n             user_id=str(current_user.id),\n-            device_id=request.device_id\n-        )\n-        \n+            device_id=request.device_id,\n+        )\n+\n         # Determine response message based on results\n         if result[\"conflicts\"] > 0:\n             message = f\"Batch upload completed with {result['conflicts']} conflicts requiring resolution\"\n             status_code = 206  # Partial Content\n         elif result[\"failed\"] > 0:\n             message = f\"Batch upload completed with {result['failed']} failures\"\n             status_code = 207  # Multi-Status\n         else:\n             message = f\"Batch upload completed successfully - {result['successful']} actions processed\"\n             status_code = 200\n-        \n+\n         return APIResponseHelper.success(\n             data=result,\n             message=message,\n             meta={\n                 \"restaurant_id\": restaurant_id,\n                 \"device_id\": request.device_id,\n                 \"processing_summary\": {\n                     \"total\": result[\"total_actions\"],\n                     \"successful\": result[\"successful\"],\n                     \"failed\": result[\"failed\"],\n-                    \"conflicts\": result[\"conflicts\"]\n-                }\n+                    \"conflicts\": result[\"conflicts\"],\n+                },\n             },\n-            status_code=status_code\n-        )\n-        \n+            status_code=status_code,\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to process batch upload: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n @router.get(\"/download-changes\")\n async def download_server_changes(\n     last_sync_timestamp: Optional[str] = Query(None, description=\"Last sync timestamp\"),\n-    entity_types: Optional[str] = Query(None, description=\"Comma-separated entity types\"),\n+    entity_types: Optional[str] = Query(\n+        None, description=\"Comma-separated entity types\"\n+    ),\n     limit: int = Query(1000, le=5000, description=\"Maximum changes to return\"),\n     current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"\n     Download server changes since last sync timestamp\n     Returns incremental changes for offline synchronization\n     \"\"\"\n@@ -131,88 +157,91 @@\n         restaurant_id = str(current_user.restaurant_id)\n         if not restaurant_id:\n             raise FynloException(\n                 message=\"User must be associated with a restaurant\",\n                 error_code=ErrorCodes.VALIDATION_ERROR,\n-                status_code=400\n-            )\n-        \n+                status_code=400,\n+            )\n+\n         # Parse parameters\n         last_sync_dt = None\n         if last_sync_timestamp:\n             try:\n-                last_sync_dt = datetime.fromisoformat(last_sync_timestamp.replace(\"Z\", \"+00:00\"))\n+                last_sync_dt = datetime.fromisoformat(\n+                    last_sync_timestamp.replace(\"Z\", \"+00:00\")\n+                )\n             except ValueError:\n                 raise FynloException(\n                     message=\"Invalid timestamp format\",\n                     error_code=ErrorCodes.VALIDATION_ERROR,\n-                    status_code=400\n+                    status_code=400,\n                 )\n-        \n+\n         entity_type_list = None\n         if entity_types:\n             entity_type_list = [t.strip() for t in entity_types.split(\",\")]\n-        \n+\n         # Get sync manager and download changes\n         sync_manager = get_sync_manager(db)\n         changes = sync_manager.download_changes(\n             restaurant_id=restaurant_id,\n             last_sync_timestamp=last_sync_dt,\n-            entity_types=entity_type_list\n-        )\n-        \n+            entity_types=entity_type_list,\n+        )\n+\n         # Apply limit to total changes\n         if changes[\"total_changes\"] > limit:\n             # Truncate changes to respect limit\n             truncated_changes = {}\n             remaining_limit = limit\n-            \n+\n             for entity_type, entity_changes in changes[\"changes\"].items():\n                 if remaining_limit <= 0:\n                     truncated_changes[entity_type] = []\n                 elif len(entity_changes) <= remaining_limit:\n                     truncated_changes[entity_type] = entity_changes\n                     remaining_limit -= len(entity_changes)\n                 else:\n                     truncated_changes[entity_type] = entity_changes[:remaining_limit]\n                     remaining_limit = 0\n-            \n+\n             changes[\"changes\"] = truncated_changes\n             changes[\"truncated\"] = True\n             changes[\"truncated_total\"] = changes[\"total_changes\"]\n             changes[\"total_changes\"] = limit\n-        \n+\n         return APIResponseHelper.success(\n             data=changes,\n             message=f\"Downloaded {changes['total_changes']} changes since last sync\",\n             meta={\n                 \"restaurant_id\": restaurant_id,\n                 \"sync_window\": {\n                     \"from\": last_sync_timestamp,\n-                    \"to\": changes[\"sync_timestamp\"]\n+                    \"to\": changes[\"sync_timestamp\"],\n                 },\n                 \"entity_types_requested\": entity_type_list,\n                 \"limit_applied\": limit,\n-                \"has_more\": changes.get(\"truncated\", False)\n-            }\n-        )\n-        \n+                \"has_more\": changes.get(\"truncated\", False),\n+            },\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to download changes: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n @router.post(\"/resolve-conflict/{conflict_id}\")\n async def resolve_sync_conflict(\n     conflict_id: str = Path(..., description=\"Conflict ID to resolve\"),\n     request: ConflictResolutionRequest = Body(...),\n     current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"\n     Resolve synchronization conflict with specified strategy\n     \"\"\"\n     try:\n@@ -221,193 +250,195 @@\n             resolution_strategy = ConflictResolution(request.resolution_strategy)\n         except ValueError:\n             raise FynloException(\n                 message=f\"Invalid resolution strategy: {request.resolution_strategy}\",\n                 error_code=ErrorCodes.VALIDATION_ERROR,\n-                status_code=400\n-            )\n-        \n+                status_code=400,\n+            )\n+\n         # Get sync manager and resolve conflict\n         sync_manager = get_sync_manager(db)\n         result = sync_manager.resolve_conflict(\n             conflict_id=conflict_id,\n             resolution_strategy=resolution_strategy,\n-            merged_data=request.merged_data\n-        )\n-        \n+            merged_data=request.merged_data,\n+        )\n+\n         return APIResponseHelper.success(\n             data=result,\n             message=f\"Conflict resolved using {resolution_strategy.value} strategy\",\n             meta={\n                 \"conflict_id\": conflict_id,\n-                \"resolution_strategy\": resolution_strategy.value\n-            }\n-        )\n-        \n+                \"resolution_strategy\": resolution_strategy.value,\n+            },\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to resolve conflict: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n @router.get(\"/status\")\n async def get_sync_status(\n-    device_id: Optional[str] = Query(None, description=\"Device ID for device-specific status\"),\n-    current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    device_id: Optional[str] = Query(\n+        None, description=\"Device ID for device-specific status\"\n+    ),\n+    current_user: User = Depends(get_current_user),\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"\n     Get synchronization status for restaurant or specific device\n     \"\"\"\n     try:\n         restaurant_id = str(current_user.restaurant_id)\n         if not restaurant_id:\n             raise FynloException(\n                 message=\"User must be associated with a restaurant\",\n                 error_code=ErrorCodes.VALIDATION_ERROR,\n-                status_code=400\n-            )\n-        \n+                status_code=400,\n+            )\n+\n         sync_manager = get_sync_manager(db)\n         status = sync_manager.get_sync_status(\n-            restaurant_id=restaurant_id,\n-            device_id=device_id\n-        )\n-        \n+            restaurant_id=restaurant_id, device_id=device_id\n+        )\n+\n         return APIResponseHelper.success(\n             data=status,\n             message=\"Sync status retrieved successfully\",\n-            meta={\n-                \"restaurant_id\": restaurant_id,\n-                \"device_id\": device_id\n-            }\n-        )\n-        \n+            meta={\"restaurant_id\": restaurant_id, \"device_id\": device_id},\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to get sync status: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n @router.get(\"/conflicts\")\n async def get_active_conflicts(\n     limit: int = Query(50, le=200, description=\"Maximum conflicts to return\"),\n     offset: int = Query(0, description=\"Offset for pagination\"),\n     current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"\n     Get list of active synchronization conflicts requiring resolution\n     \"\"\"\n     try:\n         restaurant_id = str(current_user.restaurant_id)\n         if not restaurant_id:\n             raise FynloException(\n                 message=\"User must be associated with a restaurant\",\n                 error_code=ErrorCodes.VALIDATION_ERROR,\n-                status_code=400\n-            )\n-        \n+                status_code=400,\n+            )\n+\n         # Get sync manager and retrieve conflicts\n         sync_manager = get_sync_manager(db)\n-        \n+\n         # Filter conflicts by restaurant\n         restaurant_conflicts = [\n-            c for c in sync_manager.conflicts \n+            c\n+            for c in sync_manager.conflicts\n             if c.sync_record.restaurant_id == restaurant_id\n         ]\n-        \n+\n         # Apply pagination\n         total_conflicts = len(restaurant_conflicts)\n-        paginated_conflicts = restaurant_conflicts[offset:offset + limit]\n-        \n+        paginated_conflicts = restaurant_conflicts[offset : offset + limit]\n+\n         conflicts_data = [conflict.to_dict() for conflict in paginated_conflicts]\n-        \n+\n         return APIResponseHelper.success(\n             data=conflicts_data,\n             message=f\"Retrieved {len(conflicts_data)} active conflicts\",\n             meta={\n                 \"restaurant_id\": restaurant_id,\n                 \"total_conflicts\": total_conflicts,\n                 \"limit\": limit,\n                 \"offset\": offset,\n-                \"has_more\": offset + limit < total_conflicts\n-            }\n-        )\n-        \n+                \"has_more\": offset + limit < total_conflicts,\n+            },\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to get conflicts: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n @router.delete(\"/conflicts/{conflict_id}\")\n async def dismiss_conflict(\n     conflict_id: str = Path(..., description=\"Conflict ID to dismiss\"),\n     current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"\n     Dismiss a synchronization conflict (manual resolution)\n     \"\"\"\n     try:\n         # Only managers and owners can dismiss conflicts\n         if current_user.role not in [\"restaurant_owner\", \"platform_owner\", \"manager\"]:\n             raise FynloException(\n                 message=\"Access denied - management permissions required\",\n                 error_code=ErrorCodes.FORBIDDEN,\n-                status_code=403\n-            )\n-        \n-        sync_manager = get_sync_manager(db)\n-        \n+                status_code=403,\n+            )\n+\n+        sync_manager = get_sync_manager(db)\n+\n         # Find and remove conflict\n         conflict_found = False\n         for i, conflict in enumerate(sync_manager.conflicts):\n             if conflict.sync_record.id == conflict_id:\n                 sync_manager.conflicts.pop(i)\n                 conflict_found = True\n                 break\n-        \n+\n         if not conflict_found:\n             raise FynloException(\n                 message=\"Conflict not found\",\n                 error_code=ErrorCodes.NOT_FOUND,\n-                status_code=404\n-            )\n-        \n+                status_code=404,\n+            )\n+\n         return APIResponseHelper.success(\n             message=\"Conflict dismissed successfully\",\n-            meta={\n-                \"conflict_id\": conflict_id,\n-                \"dismissed_by\": current_user.username\n-            }\n-        )\n-        \n+            meta={\"conflict_id\": conflict_id, \"dismissed_by\": current_user.username},\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to dismiss conflict: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n+            status_code=500,\n+        )\n+\n \n @router.post(\"/force-sync\")\n async def force_full_synchronization(\n-    entity_types: Optional[List[str]] = Body(None, description=\"Entity types to force sync\"),\n-    current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    entity_types: Optional[List[str]] = Body(\n+        None, description=\"Entity types to force sync\"\n+    ),\n+    current_user: User = Depends(get_current_user),\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"\n     Force full synchronization for restaurant\n     Use when normal sync is not sufficient\n     \"\"\"\n@@ -415,37 +446,37 @@\n         # Only managers and owners can force sync\n         if current_user.role not in [\"restaurant_owner\", \"platform_owner\", \"manager\"]:\n             raise FynloException(\n                 message=\"Access denied - management permissions required\",\n                 error_code=ErrorCodes.FORBIDDEN,\n-                status_code=403\n-            )\n-        \n+                status_code=403,\n+            )\n+\n         restaurant_id = str(current_user.restaurant_id)\n-        \n+\n         # Get full changes without timestamp filtering\n         sync_manager = get_sync_manager(db)\n         changes = sync_manager.download_changes(\n             restaurant_id=restaurant_id,\n             last_sync_timestamp=None,  # No timestamp = full sync\n-            entity_types=entity_types\n-        )\n-        \n+            entity_types=entity_types,\n+        )\n+\n         return APIResponseHelper.success(\n             data=changes,\n             message=\"Full synchronization data prepared\",\n             meta={\n                 \"restaurant_id\": restaurant_id,\n                 \"sync_type\": \"full\",\n                 \"entity_types\": entity_types,\n-                \"forced_by\": current_user.username\n-            }\n-        )\n-        \n+                \"forced_by\": current_user.username,\n+            },\n+        )\n+\n     except FynloException:\n         raise\n     except Exception as e:\n         raise FynloException(\n             message=f\"Failed to force synchronization: {str(e)}\",\n             error_code=ErrorCodes.INTERNAL_ERROR,\n-            status_code=500\n-        )\n\\ No newline at end of file\n+            status_code=500,\n+        )\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/platform/__init__.py\t2025-08-02 10:59:17.990376+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/platform/__init__.py\t2025-08-02 22:36:03.049916+00:00\n@@ -31,6 +31,6 @@\n # Include all routers\n platform_router.include_router(analytics_router)\n platform_router.include_router(restaurants_router)\n platform_router.include_router(subscriptions_router)\n platform_router.include_router(users_router)\n-platform_router.include_router(financial_router)\n\\ No newline at end of file\n+platform_router.include_router(financial_router)\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/websocket_rate_limit_patch.py\t2025-08-02 21:56:58.991489+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/websocket_rate_limit_patch.py\t2025-08-02 22:36:03.051090+00:00\n@@ -10,31 +10,32 @@\n from app.core.database import get_db\n from app.core.websocket_rate_limiter import websocket_rate_limiter\n from app.core.redis_client import get_redis\n \n # Add these constants after existing rate limit configuration (around line 50)\n-MAX_MESSAGES_PER_CONNECTION = 60  # per minute  \n+MAX_MESSAGES_PER_CONNECTION = 60  # per minute\n MAX_MESSAGE_SIZE = 10 * 1024  # 10KB\n \n # Modify the websocket_endpoint_general function (around line 349)\n # Add rate limiting before accepting the connection:\n+\n \n async def websocket_endpoint_general_with_rate_limit(\n     websocket: WebSocket,\n     restaurant_id: str = Path(..., description=\"Restaurant ID\"),\n     user_id: Optional[str] = Query(None, description=\"User ID\"),\n     connection_type: str = Query(\"pos\", description=\"Connection type\"),\n     db: Session = Depends(get_db),\n-    redis = Depends(get_redis),  # Add Redis dependency\n+    redis=Depends(get_redis),  # Add Redis dependency\n ):\n     \"\"\"\n     Enhanced WebSocket endpoint with message rate limiting\n     \"\"\"\n     connection_id = None\n     verified_user = None\n     client_host = websocket.client.host if websocket.client else \"unknown\"\n-    \n+\n     # Initialize rate limiter with Redis\n     if redis and not websocket_rate_limiter.redis:\n         websocket_rate_limiter.redis = redis\n \n     # Ensure cleanup task is running\n@@ -50,14 +51,13 @@\n             await websocket.close(code=4001, reason=\"Unauthorized\")\n             return\n \n         # NEW: Enhanced rate limiting check\n         allowed, error_msg = await websocket_rate_limiter.check_connection_limit(\n-            ip_address=client_host,\n-            user_id=user_id\n-        )\n-        \n+            ip_address=client_host, user_id=user_id\n+        )\n+\n         if not allowed:\n             logger.warning(\n                 f\"WebSocket connection rejected - Rate limit. \"\n                 f\"IP: {client_host}, User: {user_id}, Reason: {error_msg}\"\n             )\n@@ -80,63 +80,72 @@\n             await websocket.close(code=4009, reason=\"Connection limit exceeded\")\n             return\n \n         # Accept connection\n         await websocket.accept()\n-        \n+\n         # Generate connection ID\n         connection_id = str(uuid.uuid4())\n-        \n+\n         # NEW: Register connection with rate limiter\n         await websocket_rate_limiter.register_connection(\n-            connection_id, \n-            str(verified_user.id) if verified_user else None,\n-            client_host\n+            connection_id, str(verified_user.id) if verified_user else None, client_host\n         )\n \n         # Register connection with manager\n         await websocket_manager.add_connection(\n             connection_id=connection_id,\n             websocket=websocket,\n             restaurant_id=restaurant_id,\n             user_id=str(verified_user.id) if verified_user else None,\n             user=verified_user,\n-            connection_type=ConnectionType(connection_type) if connection_type else ConnectionType.POS,\n+            connection_type=(\n+                ConnectionType(connection_type)\n+                if connection_type\n+                else ConnectionType.POS\n+            ),\n         )\n \n         # Send connection success message\n-        await websocket.send_json({\n-            \"event\": \"connected\",\n-            \"connection_id\": connection_id,\n-            \"restaurant_id\": restaurant_id,\n-            \"timestamp\": datetime.now().isoformat(),\n-            # NEW: Include rate limit info\n-            \"rate_limit_info\": await websocket_rate_limiter.get_rate_limit_info(connection_id)\n-        })\n+        await websocket.send_json(\n+            {\n+                \"event\": \"connected\",\n+                \"connection_id\": connection_id,\n+                \"restaurant_id\": restaurant_id,\n+                \"timestamp\": datetime.now().isoformat(),\n+                # NEW: Include rate limit info\n+                \"rate_limit_info\": await websocket_rate_limiter.get_rate_limit_info(\n+                    connection_id\n+                ),\n+            }\n+        )\n \n         # Message handling loop\n         while True:\n             try:\n                 # Receive message\n                 message_text = await websocket.receive_text()\n-                message_size = len(message_text.encode('utf-8'))\n-                \n+                message_size = len(message_text.encode(\"utf-8\"))\n+\n                 # NEW: Check message rate limit\n                 allowed, error_msg = await websocket_rate_limiter.check_message_rate(\n-                    connection_id=connection_id,\n-                    message_size=message_size\n+                    connection_id=connection_id, message_size=message_size\n                 )\n-                \n+\n                 if not allowed:\n                     # Send rate limit error\n-                    await websocket.send_json({\n-                        \"event\": \"error\",\n-                        \"error\": \"rate_limit_exceeded\",\n-                        \"message\": error_msg,\n-                        \"rate_limit_info\": await websocket_rate_limiter.get_rate_limit_info(connection_id)\n-                    })\n-                    \n+                    await websocket.send_json(\n+                        {\n+                            \"event\": \"error\",\n+                            \"error\": \"rate_limit_exceeded\",\n+                            \"message\": error_msg,\n+                            \"rate_limit_info\": await websocket_rate_limiter.get_rate_limit_info(\n+                                connection_id\n+                            ),\n+                        }\n+                    )\n+\n                     # Log for security monitoring\n                     logger.warning(\n                         f\"WebSocket message rejected - Rate limit. \"\n                         f\"Connection: {connection_id}, Size: {message_size}, Reason: {error_msg}\"\n                     )\n@@ -144,44 +153,47 @@\n \n                 # Parse and validate message size\n                 try:\n                     message_data = json.loads(message_text)\n                 except json.JSONDecodeError:\n-                    await websocket.send_json({\n-                        \"event\": \"error\",\n-                        \"error\": \"invalid_format\",\n-                        \"message\": \"Invalid JSON format\"\n-                    })\n+                    await websocket.send_json(\n+                        {\n+                            \"event\": \"error\",\n+                            \"error\": \"invalid_format\",\n+                            \"message\": \"Invalid JSON format\",\n+                        }\n+                    )\n                     continue\n \n                 # Handle different message types\n                 message_type = message_data.get(\"type\", \"\")\n-                \n+\n                 # ... rest of message handling logic ...\n \n             except WebSocketDisconnect:\n                 break\n             except Exception as e:\n                 logger.error(f\"WebSocket error: {str(e)}\")\n-                await websocket.send_json({\n-                    \"event\": \"error\",\n-                    \"error\": \"internal_error\",\n-                    \"message\": \"An error occurred processing your message\"\n-                })\n+                await websocket.send_json(\n+                    {\n+                        \"event\": \"error\",\n+                        \"error\": \"internal_error\",\n+                        \"message\": \"An error occurred processing your message\",\n+                    }\n+                )\n \n     except Exception as e:\n         logger.error(f\"WebSocket connection error: {str(e)}\")\n     finally:\n         # Clean up\n         if connection_id:\n             await websocket_manager.remove_connection(connection_id)\n             # NEW: Unregister from rate limiter\n             await websocket_rate_limiter.unregister_connection(\n-                connection_id,\n-                str(verified_user.id) if verified_user else None\n+                connection_id, str(verified_user.id) if verified_user else None\n             )\n-            \n+\n         logger.info(f\"WebSocket disconnected: {connection_id}\")\n \n \n # Add a periodic cleanup task for rate limiter\n async def rate_limit_cleanup_task():\n@@ -197,6 +209,6 @@\n \n # Start the cleanup task on app startup\n # Add this to your FastAPI app startup event:\n # @app.on_event(\"startup\")\n # async def startup_event():\n-#     asyncio.create_task(rate_limit_cleanup_task())\n\\ No newline at end of file\n+#     asyncio.create_task(rate_limit_cleanup_task())\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/websocket_portal.py\t2025-08-02 21:56:58.991283+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/websocket_portal.py\t2025-08-02 22:36:03.051701+00:00\n@@ -9,51 +9,52 @@\n import json\n from datetime import datetime\n \n from app.core.database import get_db, User, Restaurant\n from app.core.websocket import (\n-    websocket_manager, \n-    ConnectionType, \n+    websocket_manager,\n+    ConnectionType,\n     EventType,\n-    WebSocketMessage\n+    WebSocketMessage,\n )\n \n router = APIRouter()\n+\n \n @router.websocket(\"/ws/portal/{restaurant_id}\")\n async def websocket_portal_endpoint(\n     websocket: WebSocket,\n     restaurant_id: str = Path(..., description=\"Restaurant ID\"),\n     user_id: str = Query(..., description=\"User ID\"),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"\n     Portal-specific WebSocket endpoint for web dashboard real-time updates\n     \"\"\"\n     connection_id = None\n-    \n+\n     try:\n         # Verify user and restaurant access\n         user = db.query(User).filter(User.id == user_id).first()\n         if not user:\n             await websocket.close(code=4003, reason=\"User not found\")\n             return\n-        \n+\n         # Check restaurant access\n         if user.role == \"restaurant_owner\" and str(user.restaurant_id) != restaurant_id:\n             await websocket.close(code=4003, reason=\"Access denied to this restaurant\")\n             return\n-        \n+\n         # Connect with portal-specific type\n         connection_id = await websocket_manager.connect(\n             websocket=websocket,\n             restaurant_id=restaurant_id,\n             user_id=user_id,\n             connection_type=ConnectionType.MANAGEMENT,  # Use management type for portal\n-            roles=[user.role]\n+            roles=[user.role],\n         )\n-        \n+\n         # Send initial connection confirmation\n         welcome_message = {\n             \"type\": \"connection_established\",\n             \"data\": {\n                 \"connection_id\": connection_id,\n@@ -63,59 +64,67 @@\n                 \"features\": [\n                     \"real_time_orders\",\n                     \"inventory_updates\",\n                     \"staff_activity\",\n                     \"payment_notifications\",\n-                    \"system_alerts\"\n-                ]\n-            }\n+                    \"system_alerts\",\n+                ],\n+            },\n         }\n-        \n+\n         await websocket.send_text(json.dumps(welcome_message))\n-        \n+\n         # Handle incoming messages\n         while True:\n             try:\n                 data = await websocket.receive_text()\n                 message_data = json.loads(data)\n-                \n+\n                 message_type = message_data.get(\"type\")\n-                \n+\n                 if message_type == \"ping\":\n                     # Respond to keep-alive pings\n-                    await websocket.send_text(json.dumps({\n-                        \"type\": \"pong\",\n-                        \"timestamp\": datetime.utcnow().isoformat()\n-                    }))\n-                    \n+                    await websocket.send_text(\n+                        json.dumps(\n+                            {\"type\": \"pong\", \"timestamp\": datetime.utcnow().isoformat()}\n+                        )\n+                    )\n+\n                 elif message_type == \"subscribe\":\n                     # Subscribe to specific event types\n                     events = message_data.get(\"events\", [])\n-                    await websocket.send_text(json.dumps({\n-                        \"type\": \"subscription_confirmed\",\n-                        \"events\": events,\n-                        \"timestamp\": datetime.utcnow().isoformat()\n-                    }))\n-                    \n+                    await websocket.send_text(\n+                        json.dumps(\n+                            {\n+                                \"type\": \"subscription_confirmed\",\n+                                \"events\": events,\n+                                \"timestamp\": datetime.utcnow().isoformat(),\n+                            }\n+                        )\n+                    )\n+\n                 elif message_type == \"request_update\":\n                     # Handle real-time data requests\n                     update_type = message_data.get(\"update_type\")\n                     await handle_portal_update_request(\n                         websocket, connection_id, restaurant_id, update_type, db\n                     )\n-                    \n+\n             except json.JSONDecodeError:\n-                await websocket.send_text(json.dumps({\n-                    \"type\": \"error\",\n-                    \"message\": \"Invalid JSON format\"\n-                }))\n+                await websocket.send_text(\n+                    json.dumps({\"type\": \"error\", \"message\": \"Invalid JSON format\"})\n+                )\n             except Exception as e:\n-                await websocket.send_text(json.dumps({\n-                    \"type\": \"error\",\n-                    \"message\": f\"Message processing error: {str(e)}\"\n-                }))\n-                \n+                await websocket.send_text(\n+                    json.dumps(\n+                        {\n+                            \"type\": \"error\",\n+                            \"message\": f\"Message processing error: {str(e)}\",\n+                        }\n+                    )\n+                )\n+\n     except WebSocketDisconnect:\n         pass\n     except Exception as e:\n         try:\n             await websocket.close(code=4000, reason=f\"Connection error: {str(e)}\")\n@@ -128,33 +137,33 @@\n \n @router.websocket(\"/ws/platform\")\n async def websocket_platform_endpoint(\n     websocket: WebSocket,\n     user_id: str = Query(..., description=\"Platform owner user ID\"),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"\n     Platform owner WebSocket endpoint for monitoring all restaurants\n     \"\"\"\n     connection_id = None\n-    \n+\n     try:\n         # Verify platform owner\n         user = db.query(User).filter(User.id == user_id).first()\n         if not user or user.role != \"platform_owner\":\n             await websocket.close(code=4003, reason=\"Platform owner access required\")\n             return\n-        \n+\n         # Connect without specific restaurant (platform-wide)\n         connection_id = await websocket_manager.connect(\n             websocket=websocket,\n             restaurant_id=None,  # No specific restaurant for platform owner\n             user_id=user_id,\n             connection_type=ConnectionType.MANAGEMENT,\n-            roles=[\"platform_owner\"]\n+            roles=[\"platform_owner\"],\n         )\n-        \n+\n         # Send platform overview\n         welcome_message = {\n             \"type\": \"platform_connection_established\",\n             \"data\": {\n                 \"connection_id\": connection_id,\n@@ -163,78 +172,96 @@\n                 \"features\": [\n                     \"all_restaurants_overview\",\n                     \"platform_analytics\",\n                     \"system_health\",\n                     \"revenue_tracking\",\n-                    \"restaurant_alerts\"\n-                ]\n-            }\n+                    \"restaurant_alerts\",\n+                ],\n+            },\n         }\n-        \n+\n         await websocket.send_text(json.dumps(welcome_message))\n-        \n+\n         # Get initial restaurant list\n         restaurants = db.query(Restaurant).filter(Restaurant.is_active == True).all()\n         restaurant_data = [\n             {\n                 \"id\": str(r.id),\n                 \"name\": r.name,\n-                \"status\": \"online\" if websocket_manager.has_active_connections(str(r.id)) else \"offline\",\n-                \"subscription_plan\": getattr(r, 'subscription_plan', 'alpha')\n+                \"status\": (\n+                    \"online\"\n+                    if websocket_manager.has_active_connections(str(r.id))\n+                    else \"offline\"\n+                ),\n+                \"subscription_plan\": getattr(r, \"subscription_plan\", \"alpha\"),\n             }\n             for r in restaurants\n         ]\n-        \n-        await websocket.send_text(json.dumps({\n-            \"type\": \"restaurant_list\",\n-            \"data\": restaurant_data,\n-            \"timestamp\": datetime.utcnow().isoformat()\n-        }))\n-        \n+\n+        await websocket.send_text(\n+            json.dumps(\n+                {\n+                    \"type\": \"restaurant_list\",\n+                    \"data\": restaurant_data,\n+                    \"timestamp\": datetime.utcnow().isoformat(),\n+                }\n+            )\n+        )\n+\n         # Handle platform owner messages\n         while True:\n             try:\n                 data = await websocket.receive_text()\n                 message_data = json.loads(data)\n-                \n+\n                 message_type = message_data.get(\"type\")\n-                \n+\n                 if message_type == \"ping\":\n-                    await websocket.send_text(json.dumps({\n-                        \"type\": \"pong\",\n-                        \"timestamp\": datetime.utcnow().isoformat()\n-                    }))\n-                    \n+                    await websocket.send_text(\n+                        json.dumps(\n+                            {\"type\": \"pong\", \"timestamp\": datetime.utcnow().isoformat()}\n+                        )\n+                    )\n+\n                 elif message_type == \"monitor_restaurant\":\n                     # Start monitoring specific restaurant\n                     restaurant_id = message_data.get(\"restaurant_id\")\n-                    await websocket.send_text(json.dumps({\n-                        \"type\": \"monitoring_started\",\n-                        \"restaurant_id\": restaurant_id,\n-                        \"timestamp\": datetime.utcnow().isoformat()\n-                    }))\n-                    \n+                    await websocket.send_text(\n+                        json.dumps(\n+                            {\n+                                \"type\": \"monitoring_started\",\n+                                \"restaurant_id\": restaurant_id,\n+                                \"timestamp\": datetime.utcnow().isoformat(),\n+                            }\n+                        )\n+                    )\n+\n                 elif message_type == \"request_platform_stats\":\n                     # Send platform-wide statistics\n                     await handle_platform_stats_request(websocket, db)\n-                    \n+\n             except json.JSONDecodeError:\n-                await websocket.send_text(json.dumps({\n-                    \"type\": \"error\",\n-                    \"message\": \"Invalid JSON format\"\n-                }))\n+                await websocket.send_text(\n+                    json.dumps({\"type\": \"error\", \"message\": \"Invalid JSON format\"})\n+                )\n             except Exception as e:\n-                await websocket.send_text(json.dumps({\n-                    \"type\": \"error\",\n-                    \"message\": f\"Platform message processing error: {str(e)}\"\n-                }))\n-                \n+                await websocket.send_text(\n+                    json.dumps(\n+                        {\n+                            \"type\": \"error\",\n+                            \"message\": f\"Platform message processing error: {str(e)}\",\n+                        }\n+                    )\n+                )\n+\n     except WebSocketDisconnect:\n         pass\n     except Exception as e:\n         try:\n-            await websocket.close(code=4000, reason=f\"Platform connection error: {str(e)}\")\n+            await websocket.close(\n+                code=4000, reason=f\"Platform connection error: {str(e)}\"\n+            )\n         except Exception as e:\n             pass\n     finally:\n         if connection_id:\n             await websocket_manager.disconnect(connection_id)\n@@ -243,62 +270,72 @@\n async def handle_portal_update_request(\n     websocket: WebSocket,\n     connection_id: str,\n     restaurant_id: str,\n     update_type: str,\n-    db: Session\n+    db: Session,\n ):\n     \"\"\"Handle real-time update requests from portal\"\"\"\n     try:\n         if update_type == \"active_orders\":\n             # Send current active orders count\n             # This would query real order data\n-            await websocket.send_text(json.dumps({\n-                \"type\": \"update_response\",\n-                \"update_type\": \"active_orders\",\n-                \"data\": {\n-                    \"active_orders\": 0,  # Would be real query\n-                    \"pending_orders\": 0,\n-                    \"preparing_orders\": 0\n-                },\n-                \"timestamp\": datetime.utcnow().isoformat()\n-            }))\n-            \n+            await websocket.send_text(\n+                json.dumps(\n+                    {\n+                        \"type\": \"update_response\",\n+                        \"update_type\": \"active_orders\",\n+                        \"data\": {\n+                            \"active_orders\": 0,  # Would be real query\n+                            \"pending_orders\": 0,\n+                            \"preparing_orders\": 0,\n+                        },\n+                        \"timestamp\": datetime.utcnow().isoformat(),\n+                    }\n+                )\n+            )\n+\n         elif update_type == \"online_staff\":\n             # Send online staff count\n-            await websocket.send_text(json.dumps({\n-                \"type\": \"update_response\",\n-                \"update_type\": \"online_staff\",\n-                \"data\": {\n-                    \"online_count\": 0,  # Would be real query\n-                    \"total_staff\": 0\n-                },\n-                \"timestamp\": datetime.utcnow().isoformat()\n-            }))\n-            \n+            await websocket.send_text(\n+                json.dumps(\n+                    {\n+                        \"type\": \"update_response\",\n+                        \"update_type\": \"online_staff\",\n+                        \"data\": {\n+                            \"online_count\": 0,  # Would be real query\n+                            \"total_staff\": 0,\n+                        },\n+                        \"timestamp\": datetime.utcnow().isoformat(),\n+                    }\n+                )\n+            )\n+\n     except Exception as e:\n         logger.error(f\"Portal update request error: {str(e)}\")\n \n \n async def handle_platform_stats_request(websocket: WebSocket, db: Session):\n     \"\"\"Handle platform statistics request\"\"\"\n     try:\n         # Get all restaurants\n         total_restaurants = db.query(Restaurant).count()\n-        active_restaurants = db.query(Restaurant).filter(Restaurant.is_active == True).count()\n-        \n+        active_restaurants = (\n+            db.query(Restaurant).filter(Restaurant.is_active == True).count()\n+        )\n+\n         # This would include more comprehensive stats in production\n         stats = {\n             \"type\": \"platform_stats\",\n             \"data\": {\n                 \"total_restaurants\": total_restaurants,\n                 \"active_restaurants\": active_restaurants,\n                 \"online_restaurants\": websocket_manager.get_active_restaurant_count(),\n                 \"total_connections\": websocket_manager.get_total_connections(),\n-                \"timestamp\": datetime.utcnow().isoformat()\n-            }\n+                \"timestamp\": datetime.utcnow().isoformat(),\n+            },\n         }\n-        \n+\n         await websocket.send_text(json.dumps(stats))\n-        \n+\n     except Exception as e:\n-        logger.error(f\"Platform stats request error: {str(e)}\")\n\\ No newline at end of file\n+        logger.error(f\"Platform stats request error: {str(e)}\")\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/websocket_enhanced.py\t2025-08-02 21:56:58.990917+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/websocket_enhanced.py\t2025-08-02 22:36:03.072384+00:00\n@@ -22,11 +22,17 @@\n \n router = APIRouter()\n \n \n class ConnectionInfo:\n-    def __init__(self, websocket: WebSocket, user_id: str, restaurant_id: str, client_type: str = \"mobile_pos\"):\n+    def __init__(\n+        self,\n+        websocket: WebSocket,\n+        user_id: str,\n+        restaurant_id: str,\n+        client_type: str = \"mobile_pos\",\n+    ):\n         self.id = f\"{user_id}:{datetime.utcnow().timestamp()}\"\n         self.websocket = websocket\n         self.user_id = user_id\n         self.restaurant_id = restaurant_id\n         self.client_type = client_type\n@@ -46,348 +52,342 @@\n         self.max_connections_per_restaurant = 100\n         self.max_connections_per_user = 5\n         self.heartbeat_interval = 15  # seconds\n         self.pong_timeout = 5  # seconds\n         self.max_missed_pongs = 3\n-        \n+\n         # Rate limiting\n         self.message_rate_limiter = RateLimiter(\n             max_messages=100,  # 100 messages per minute\n             window_seconds=60,\n-            burst_size=20\n+            burst_size=20,\n         )\n         self.connection_limiter = ConnectionLimiter(\n-            max_per_ip=20,\n-            max_per_user=5,\n-            ip_window_seconds=60\n-        )\n-        \n+            max_per_ip=20, max_per_user=5, ip_window_seconds=60\n+        )\n+\n         # Synchronization\n         self._disconnect_lock = asyncio.Lock()\n-        \n-    async def connect(\n-        self, \n-        websocket: WebSocket, \n-        restaurant_id: str\n-    ) -> str:\n+\n+    async def connect(self, websocket: WebSocket, restaurant_id: str) -> str:\n         \"\"\"Accept WebSocket connection and return connection ID\"\"\"\n         await websocket.accept()\n-        \n+\n         # Generate connection ID\n         connection_id = f\"{restaurant_id}:{datetime.utcnow().timestamp()}\"\n-        \n+\n         logger.info(f\"WebSocket connection accepted: {connection_id}\")\n         return connection_id\n-        \n+\n     async def authenticate(\n         self,\n         connection_id: str,\n         websocket: WebSocket,\n         auth_data: dict,\n         db: Session,\n-        connection_type: str = \"pos\"\n+        connection_type: str = \"pos\",\n     ) -> Optional[ConnectionInfo]:\n         \"\"\"Authenticate WebSocket connection\"\"\"\n         try:\n             # Extract auth data\n-            token = auth_data.get('token')\n-            user_id = auth_data.get('user_id')\n-            restaurant_id = auth_data.get('restaurant_id')\n-            \n+            token = auth_data.get(\"token\")\n+            user_id = auth_data.get(\"user_id\")\n+            restaurant_id = auth_data.get(\"restaurant_id\")\n+\n             if not all([token, user_id, restaurant_id]):\n                 await self.send_error(\n                     websocket,\n                     WebSocketEventType.AUTH_ERROR,\n-                    \"Missing authentication data\"\n+                    \"Missing authentication data\",\n                 )\n                 return None\n-            \n+\n             # Verify token and user\n             user = await verify_websocket_token(token, user_id, db)\n             if not user:\n                 await self.send_error(\n                     websocket,\n                     WebSocketEventType.AUTH_ERROR,\n-                    \"Invalid authentication token\"\n+                    \"Invalid authentication token\",\n                 )\n                 return None\n-            \n+\n             # Verify user has access to restaurant\n-            if user.role != 'platform_owner':\n+            if user.role != \"platform_owner\":\n                 if not user.restaurant_id or str(user.restaurant_id) != restaurant_id:\n                     await self.send_error(\n                         websocket,\n                         WebSocketEventType.AUTH_ERROR,\n-                        \"Access denied to this restaurant\"\n+                        \"Access denied to this restaurant\",\n                     )\n                     return None\n-            \n+\n             # Check connection limits\n             if not self._check_connection_limits(restaurant_id, user_id):\n                 await self.send_error(\n                     websocket,\n                     WebSocketEventType.AUTH_ERROR,\n-                    \"Connection limit exceeded\"\n+                    \"Connection limit exceeded\",\n                 )\n                 return None\n-            \n+\n             # Create connection info\n-            client_type = \"platform_dashboard\" if connection_type == \"platform\" else \"mobile_pos\"\n+            client_type = (\n+                \"platform_dashboard\" if connection_type == \"platform\" else \"mobile_pos\"\n+            )\n             conn_info = ConnectionInfo(websocket, user_id, restaurant_id, client_type)\n             conn_info.authenticated = True\n-            \n+\n             # Store connection\n             if restaurant_id not in self.active_connections:\n                 self.active_connections[restaurant_id] = set()\n-            \n+\n             self.active_connections[restaurant_id].add(conn_info)\n             self.connection_map[connection_id] = conn_info\n-            \n+\n             # Send authentication success\n             await self.send_message(\n                 websocket,\n                 WebSocketEventType.AUTHENTICATED,\n                 {\n                     \"user_id\": user_id,\n                     \"restaurant_id\": restaurant_id,\n-                    \"connection_id\": connection_id\n+                    \"connection_id\": connection_id,\n                 },\n-                restaurant_id\n-            )\n-            \n+                restaurant_id,\n+            )\n+\n             logger.info(f\"WebSocket authenticated: {connection_id} for user {user_id}\")\n             return conn_info\n-            \n+\n         except Exception as e:\n             logger.error(f\"Authentication error: {e}\")\n             await self.send_error(\n-                websocket,\n-                WebSocketEventType.AUTH_ERROR,\n-                \"Authentication failed\"\n+                websocket, WebSocketEventType.AUTH_ERROR, \"Authentication failed\"\n             )\n             return None\n-    \n+\n     def _check_connection_limits(self, restaurant_id: str, user_id: str) -> bool:\n         \"\"\"Check if connection limits are exceeded\"\"\"\n         # Check restaurant limit\n         restaurant_connections = self.active_connections.get(restaurant_id, set())\n         if len(restaurant_connections) >= self.max_connections_per_restaurant:\n             logger.warning(f\"Restaurant {restaurant_id} connection limit exceeded\")\n             return False\n-        \n+\n         # Check user limit\n         user_connections = sum(\n-            1 for conn in restaurant_connections \n-            if conn.user_id == user_id\n+            1 for conn in restaurant_connections if conn.user_id == user_id\n         )\n         if user_connections >= self.max_connections_per_user:\n             logger.warning(f\"User {user_id} connection limit exceeded\")\n             return False\n-        \n+\n         return True\n-    \n+\n     async def disconnect(self, connection_id: str):\n         \"\"\"Remove connection and cleanup\"\"\"\n         # Use lock to prevent race conditions\n         async with self._disconnect_lock:\n             conn_info = self.connection_map.get(connection_id)\n             if not conn_info:\n                 return\n-            \n+\n             # Remove from rate limiter tracking\n             self.connection_limiter.remove_connection(conn_info.user_id, connection_id)\n-            \n+\n             # Remove from restaurant connections\n             if conn_info.restaurant_id in self.active_connections:\n                 self.active_connections[conn_info.restaurant_id].discard(conn_info)\n-                \n+\n                 # Clean up empty restaurant\n                 if not self.active_connections[conn_info.restaurant_id]:\n                     del self.active_connections[conn_info.restaurant_id]\n-            \n+\n             # Remove from connection map - do this last to prevent issues\n             if connection_id in self.connection_map:\n                 del self.connection_map[connection_id]\n-            \n+\n             logger.info(f\"WebSocket disconnected: {connection_id}\")\n-    \n+\n     async def handle_ping(self, connection_id: str, websocket: WebSocket):\n         \"\"\"Handle ping message and send pong\"\"\"\n         conn_info = self.connection_map.get(connection_id)\n         if conn_info:\n             conn_info.last_ping = datetime.utcnow()\n             conn_info.missed_pongs = 0  # Reset missed pongs on successful ping\n-            \n+\n             # Send pong response\n             await self.send_message(\n                 websocket,\n                 WebSocketEventType.PONG,\n                 {\"timestamp\": datetime.utcnow().isoformat()},\n-                conn_info.restaurant_id\n-            )\n-    \n+                conn_info.restaurant_id,\n+            )\n+\n     async def handle_pong(self, connection_id: str):\n         \"\"\"Handle pong response from client\"\"\"\n         conn_info = self.connection_map.get(connection_id)\n         if conn_info:\n             conn_info.missed_pongs = 0\n             logger.debug(f\"Received pong from {connection_id}\")\n-    \n+\n     async def send_heartbeat(self, connection_id: str) -> bool:\n         \"\"\"Send heartbeat ping to client\"\"\"\n         conn_info = self.connection_map.get(connection_id)\n         if not conn_info:\n             return False\n-        \n+\n         try:\n             await self.send_message(\n                 conn_info.websocket,\n                 WebSocketEventType.PING,\n                 {\"timestamp\": datetime.utcnow().isoformat()},\n-                conn_info.restaurant_id\n+                conn_info.restaurant_id,\n             )\n             return True\n         except Exception as e:\n             logger.error(f\"Failed to send heartbeat to {connection_id}: {e}\")\n             return False\n-    \n+\n     async def broadcast_to_restaurant(\n         self,\n         restaurant_id: str,\n         event: WebSocketEventType,\n         data: dict,\n-        exclude_connection: Optional[str] = None\n+        exclude_connection: Optional[str] = None,\n     ):\n         \"\"\"Broadcast message to all connections in a restaurant\"\"\"\n         connections = self.active_connections.get(restaurant_id, set())\n         dead_connections = set()\n-        \n+\n         for conn in connections:\n-            if exclude_connection and self._get_connection_id(conn) == exclude_connection:\n+            if (\n+                exclude_connection\n+                and self._get_connection_id(conn) == exclude_connection\n+            ):\n                 continue\n-                \n+\n             try:\n-                await self.send_message(\n-                    conn.websocket, \n-                    event, \n-                    data, \n-                    restaurant_id\n-                )\n+                await self.send_message(conn.websocket, event, data, restaurant_id)\n             except WebSocketDisconnect:\n                 dead_connections.add(conn)\n             except Exception as e:\n                 logger.error(f\"Broadcast error: {e}\")\n                 dead_connections.add(conn)\n-        \n+\n         # Clean up dead connections\n         for conn in dead_connections:\n             await self.disconnect(self._get_connection_id(conn))\n-    \n+\n     async def send_message(\n         self,\n         websocket: WebSocket,\n         event: WebSocketEventType,\n         data: dict,\n-        restaurant_id: str\n+        restaurant_id: str,\n     ):\n         \"\"\"Send message to specific WebSocket\"\"\"\n         message = WebSocketMessage(\n             id=f\"{datetime.utcnow().timestamp()}\",\n             type=event,\n             data=data,\n             restaurant_id=restaurant_id,\n-            timestamp=datetime.utcnow().isoformat()\n-        )\n-        \n+            timestamp=datetime.utcnow().isoformat(),\n+        )\n+\n         await websocket.send_json(message.dict())\n-    \n+\n     async def send_error(\n-        self,\n-        websocket: WebSocket,\n-        event: WebSocketEventType,\n-        error: str\n+        self, websocket: WebSocket, event: WebSocketEventType, error: str\n     ):\n         \"\"\"Send error message\"\"\"\n         await self.send_message(\n-            websocket,\n-            event,\n-            {\"error\": error},\n-            \"\"  # Empty restaurant_id for errors\n-        )\n-    \n+            websocket, event, {\"error\": error}, \"\"  # Empty restaurant_id for errors\n+        )\n+\n     def _get_connection_id(self, conn_info: ConnectionInfo) -> str:\n         \"\"\"Get connection ID for a connection\"\"\"\n         for conn_id, conn in self.connection_map.items():\n             if conn == conn_info:\n                 return conn_id\n         return \"\"\n-    \n+\n     def get_restaurant_connections(self, restaurant_id: str) -> list[ConnectionInfo]:\n         \"\"\"Get all active connections for a restaurant\"\"\"\n         return list(self.active_connections.get(restaurant_id, set()))\n-    \n+\n     def get_platform_connections(self) -> list[ConnectionInfo]:\n         \"\"\"Get all active platform dashboard connections\"\"\"\n         platform_connections = []\n         for conn_info in self.connection_map.values():\n-            if hasattr(conn_info, 'client_type') and conn_info.client_type == 'platform_dashboard':\n+            if (\n+                hasattr(conn_info, \"client_type\")\n+                and conn_info.client_type == \"platform_dashboard\"\n+            ):\n                 platform_connections.append(conn_info)\n         return platform_connections\n-    \n+\n     async def send_to_connection(self, connection_id: str, data: dict):\n         \"\"\"Send message to specific connection by ID\"\"\"\n         conn_info = self.connection_map.get(connection_id)\n         if conn_info:\n             await self.send_message(\n                 conn_info.websocket,\n-                data.get('type', WebSocketEventType.DATA_UPDATED),\n-                data.get('data', {}),\n-                conn_info.restaurant_id\n-            )\n-    \n+                data.get(\"type\", WebSocketEventType.DATA_UPDATED),\n+                data.get(\"data\", {}),\n+                conn_info.restaurant_id,\n+            )\n+\n     async def monitor_connection_health(self):\n         \"\"\"Monitor connection health and handle heartbeats\"\"\"\n         cleanup_counter = 0\n-        \n+\n         while True:\n             try:\n                 await asyncio.sleep(self.heartbeat_interval)\n                 cleanup_counter += 1\n-                \n+\n                 # Check all connections\n                 for conn_id, conn_info in list(self.connection_map.items()):\n                     if not conn_info.authenticated:\n                         continue\n-                    \n+\n                     # Check if we've received anything from client recently\n-                    time_since_last_ping = (datetime.utcnow() - conn_info.last_ping).total_seconds()\n-                    \n+                    time_since_last_ping = (\n+                        datetime.utcnow() - conn_info.last_ping\n+                    ).total_seconds()\n+\n                     # If client hasn't sent ping in 2x heartbeat interval, send server ping\n                     if time_since_last_ping > (self.heartbeat_interval * 2):\n                         # Send server-initiated ping\n                         success = await self.send_heartbeat(conn_id)\n-                        \n+\n                         if not success:\n                             conn_info.missed_pongs += 1\n-                            \n+\n                             if conn_info.missed_pongs >= self.max_missed_pongs:\n-                                logger.warning(f\"Connection {conn_id} missed {self.max_missed_pongs} pongs, disconnecting\")\n+                                logger.warning(\n+                                    f\"Connection {conn_id} missed {self.max_missed_pongs} pongs, disconnecting\"\n+                                )\n                                 await self.disconnect(conn_id)\n                     else:\n                         # Client is actively pinging, reset missed pongs\n                         conn_info.missed_pongs = 0\n-                \n+\n                 # Cleanup rate limiter buckets every 20 cycles (5 minutes)\n                 if cleanup_counter % 20 == 0:\n                     self.message_rate_limiter.cleanup_old_buckets()\n                     logger.debug(\"Cleaned up rate limiter buckets\")\n-                \n+\n             except Exception as e:\n                 logger.error(f\"Health monitor error: {e}\")\n \n+\n # Global manager instance\n manager = EnhancedWebSocketManager()\n+\n \n # Initialize sync service on startup\n async def init_websocket_services():\n     \"\"\"Initialize WebSocket-related services\"\"\"\n     await sync_service.initialize(manager)\n@@ -397,136 +397,131 @@\n @router.websocket(\"/ws/{connection_type}/{restaurant_id}\")\n async def websocket_endpoint(\n     websocket: WebSocket,\n     connection_type: str,  # 'pos' or 'platform'\n     restaurant_id: str,\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"\n     Enhanced WebSocket endpoint with heartbeat and reconnection support\n-    \n+\n     Security: Tokens must be sent in the authentication message body, NOT in URL\n     \"\"\"\n     connection_id = None\n     auth_timeout_task = None\n-    \n+\n     try:\n         # Accept connection\n         connection_id = await manager.connect(websocket, restaurant_id)\n-        \n+\n         # Set authentication timeout\n         auth_timeout_task = asyncio.create_task(asyncio.sleep(10))\n         auth_message_task = asyncio.create_task(websocket.receive_text())\n-        \n+\n         # Wait for authentication or timeout\n         done, pending = await asyncio.wait(\n-            [auth_timeout_task, auth_message_task],\n-            return_when=asyncio.FIRST_COMPLETED\n-        )\n-        \n+            [auth_timeout_task, auth_message_task], return_when=asyncio.FIRST_COMPLETED\n+        )\n+\n         # Cancel pending tasks\n         for task in pending:\n             task.cancel()\n-        \n+\n         # Check which task completed\n         if auth_timeout_task in done:\n             await manager.send_error(\n-                websocket,\n-                WebSocketEventType.AUTH_ERROR,\n-                \"Authentication timeout\"\n+                websocket, WebSocketEventType.AUTH_ERROR, \"Authentication timeout\"\n             )\n             await websocket.close(code=4002, reason=\"Authentication timeout\")\n             return\n-        \n+\n         # Parse authentication message\n         auth_data = json.loads(auth_message_task.result())\n-        \n+\n         # Verify message type\n         if auth_data.get(\"type\") != WebSocketEventType.AUTHENTICATE:\n             await manager.send_error(\n                 websocket,\n                 WebSocketEventType.AUTH_ERROR,\n-                \"First message must be authentication\"\n+                \"First message must be authentication\",\n             )\n             await websocket.close(code=4001, reason=\"Authentication required\")\n             return\n-        \n+\n         # Authenticate\n         conn_info = await manager.authenticate(\n-            connection_id,\n-            websocket,\n-            auth_data.get(\"data\", {}),\n-            db,\n-            connection_type\n-        )\n-        \n+            connection_id, websocket, auth_data.get(\"data\", {}), db, connection_type\n+        )\n+\n         if not conn_info:\n             await websocket.close(code=4003, reason=\"Authentication failed\")\n             return\n-        \n+\n         # Handle messages\n         while True:\n             try:\n                 # Wait for message with timeout\n                 message_text = await asyncio.wait_for(\n-                    websocket.receive_text(),\n-                    timeout=60.0  # 1 minute timeout\n+                    websocket.receive_text(), timeout=60.0  # 1 minute timeout\n                 )\n-                \n+\n                 # Check message size (max 1MB)\n                 if len(message_text) > 1024 * 1024:\n                     await manager.send_error(\n                         websocket,\n                         WebSocketEventType.ERROR,\n-                        \"Message too large (max 1MB)\"\n+                        \"Message too large (max 1MB)\",\n                     )\n                     continue\n-                \n+\n                 message = json.loads(message_text)\n                 message_type = message.get(\"type\")\n-                \n+\n                 # Check rate limit (except for pings/pongs)\n-                if message_type not in [WebSocketEventType.PING, WebSocketEventType.PONG]:\n+                if message_type not in [\n+                    WebSocketEventType.PING,\n+                    WebSocketEventType.PONG,\n+                ]:\n                     if not manager.message_rate_limiter.check_rate_limit(connection_id):\n-                        wait_time = manager.message_rate_limiter.get_wait_time(connection_id)\n+                        wait_time = manager.message_rate_limiter.get_wait_time(\n+                            connection_id\n+                        )\n                         await manager.send_error(\n                             websocket,\n                             WebSocketEventType.ERROR,\n-                            f\"Rate limit exceeded. Please wait {wait_time:.1f} seconds\"\n+                            f\"Rate limit exceeded. Please wait {wait_time:.1f} seconds\",\n                         )\n                         continue\n-                \n+\n                 # Handle different message types\n                 if message_type == WebSocketEventType.PING:\n                     await manager.handle_ping(connection_id, websocket)\n                 elif message_type == WebSocketEventType.PONG:\n                     await manager.handle_pong(connection_id)\n                 else:\n                     # Process business messages\n                     await process_message(connection_id, message, db)\n-                    \n+\n             except asyncio.TimeoutError:\n                 # No message received in timeout period, send ping\n                 if not await manager.send_heartbeat(connection_id):\n                     break\n-                    \n+\n             except json.JSONDecodeError:\n                 await manager.send_error(\n-                    websocket,\n-                    WebSocketEventType.ERROR,\n-                    \"Invalid JSON format\"\n+                    websocket, WebSocketEventType.ERROR, \"Invalid JSON format\"\n                 )\n             except WebSocketDisconnect:\n                 break\n             except Exception as e:\n                 logger.error(f\"Message processing error: {e}\")\n                 await manager.send_error(\n                     websocket,\n                     WebSocketEventType.ERROR,\n-                    f\"Message processing error: {str(e)}\"\n+                    f\"Message processing error: {str(e)}\",\n                 )\n-                \n+\n     except WebSocketDisconnect:\n         logger.info(f\"Client disconnected: {connection_id}\")\n     except Exception as e:\n         logger.error(f\"WebSocket error: {e}\")\n         if websocket.client_state == WebSocketState.CONNECTED:\n@@ -539,33 +534,32 @@\n async def process_message(connection_id: str, message: dict, db: Session):\n     \"\"\"Process business logic messages\"\"\"\n     conn_info = manager.connection_map.get(connection_id)\n     if not conn_info:\n         return\n-    \n+\n     message_type = message.get(\"type\")\n     data = message.get(\"data\", {})\n-    \n+\n     # Handle different message types\n     if message_type == \"order.status_update\":\n         # Update order status and broadcast\n         order_id = data.get(\"order_id\")\n         new_status = data.get(\"status\")\n-        \n-                \n+\n         # Broadcast to restaurant\n         await manager.broadcast_to_restaurant(\n             conn_info.restaurant_id,\n             WebSocketEventType.ORDER_STATUS_CHANGED,\n             {\n                 \"order_id\": order_id,\n                 \"status\": new_status,\n                 \"updated_by\": conn_info.user_id,\n-                \"timestamp\": datetime.utcnow().isoformat()\n-            }\n+                \"timestamp\": datetime.utcnow().isoformat(),\n+            },\n         )\n \n \n # Background task starter\n async def start_health_monitor():\n     \"\"\"Start the connection health monitor\"\"\"\n-    asyncio.create_task(manager.monitor_connection_health())\n\\ No newline at end of file\n+    asyncio.create_task(manager.monitor_connection_health())\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/platform/analytics.py\t2025-08-02 21:56:58.991871+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/platform/analytics.py\t2025-08-02 22:36:03.078327+00:00\n@@ -17,11 +17,11 @@\n \n \n @router.get(\"/overview\")\n async def get_platform_overview(\n     current_user: User = Depends(get_current_platform_owner),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Get platform-wide analytics overview.\"\"\"\n     try:\n         # Check cache first\n         cache_key = \"platform:analytics:overview\"\n@@ -30,207 +30,207 @@\n             return APIResponseHelper.success(data=cached_data)\n \n         # Calculate metrics\n         today = datetime.now().date()\n         thirty_days_ago = today - timedelta(days=30)\n-        \n+\n         # Total restaurants\n         total_restaurants = db.query(Restaurant).count()\n-        active_restaurants = db.query(Restaurant).filter(\n-            Restaurant.subscription_status == 'active'\n-        ).count()\n-        \n+        active_restaurants = (\n+            db.query(Restaurant)\n+            .filter(Restaurant.subscription_status == \"active\")\n+            .count()\n+        )\n+\n         # Revenue metrics\n-        total_revenue = db.query(func.sum(Order.total_amount)).filter(\n-            Order.created_at >= thirty_days_ago\n-        ).scalar() or 0\n-        \n+        total_revenue = (\n+            db.query(func.sum(Order.total_amount))\n+            .filter(Order.created_at >= thirty_days_ago)\n+            .scalar()\n+            or 0\n+        )\n+\n         # Transaction fees (1% of all transactions)\n         transaction_fees = float(total_revenue) * 0.01\n-        \n+\n         # Subscription revenue\n-        subscription_revenue = db.query(\n-            func.sum(\n-                func.case(\n-                    (Restaurant.subscription_plan == 'beta', 49),\n-                    (Restaurant.subscription_plan == 'omega', 119),\n-                    else_=0\n+        subscription_revenue = (\n+            db.query(\n+                func.sum(\n+                    func.case(\n+                        (Restaurant.subscription_plan == \"beta\", 49),\n+                        (Restaurant.subscription_plan == \"omega\", 119),\n+                        else_=0,\n+                    )\n                 )\n             )\n-        ).filter(\n-            Restaurant.subscription_status == 'active'\n-        ).scalar() or 0\n-        \n+            .filter(Restaurant.subscription_status == \"active\")\n+            .scalar()\n+            or 0\n+        )\n+\n         # User metrics\n         total_users = db.query(User).count()\n-        active_users = db.query(User).filter(\n-            User.last_login >= thirty_days_ago\n-        ).count()\n-        \n+        active_users = db.query(User).filter(User.last_login >= thirty_days_ago).count()\n+\n         # Order metrics\n-        total_orders = db.query(Order).filter(\n-            Order.created_at >= thirty_days_ago\n-        ).count()\n-        \n+        total_orders = (\n+            db.query(Order).filter(Order.created_at >= thirty_days_ago).count()\n+        )\n+\n         overview = {\n             \"restaurants\": {\n                 \"total\": total_restaurants,\n                 \"active\": active_restaurants,\n-                \"trial\": db.query(Restaurant).filter(\n-                    Restaurant.subscription_status == 'trial'\n-                ).count()\n+                \"trial\": db.query(Restaurant)\n+                .filter(Restaurant.subscription_status == \"trial\")\n+                .count(),\n             },\n             \"revenue\": {\n                 \"total_last_30_days\": float(total_revenue),\n                 \"transaction_fees\": transaction_fees,\n                 \"subscription_revenue\": float(subscription_revenue),\n-                \"total_platform_revenue\": transaction_fees + float(subscription_revenue)\n+                \"total_platform_revenue\": transaction_fees\n+                + float(subscription_revenue),\n             },\n-            \"users\": {\n-                \"total\": total_users,\n-                \"active_last_30_days\": active_users\n-            },\n+            \"users\": {\"total\": total_users, \"active_last_30_days\": active_users},\n             \"orders\": {\n                 \"total_last_30_days\": total_orders,\n-                \"average_order_value\": float(total_revenue) / total_orders if total_orders > 0 else 0\n-            }\n+                \"average_order_value\": (\n+                    float(total_revenue) / total_orders if total_orders > 0 else 0\n+                ),\n+            },\n         }\n-        \n+\n         # Cache for 15 minutes\n         await cache_data(cache_key, overview, ttl=900)\n-        \n+\n         return APIResponseHelper.success(data=overview)\n-        \n+\n     except Exception as e:\n         return APIResponseHelper.error(\n-            message=f\"Failed to fetch platform overview: {str(e)}\",\n-            status_code=500\n+            message=f\"Failed to fetch platform overview: {str(e)}\", status_code=500\n         )\n \n \n @router.get(\"/revenue-trends\")\n async def get_revenue_trends(\n     days: int = Query(30, ge=7, le=365),\n     current_user: User = Depends(get_current_platform_owner),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Get platform revenue trends over time.\"\"\"\n     try:\n         cache_key = f\"platform:analytics:revenue_trends:{days}\"\n         cached_data = await get_cached_data_async(cache_key)\n         if cached_data:\n             return APIResponseHelper.success(data=cached_data)\n-        \n+\n         end_date = datetime.now().date()\n         start_date = end_date - timedelta(days=days)\n-        \n+\n         # Query daily revenue\n-        daily_revenue = db.query(\n-            func.date(Order.created_at).label('date'),\n-            func.sum(Order.total_amount).label('revenue'),\n-            func.count(Order.id).label('order_count')\n-        ).filter(\n-            Order.created_at >= start_date\n-        ).group_by(\n-            func.date(Order.created_at)\n-        ).all()\n-        \n+        daily_revenue = (\n+            db.query(\n+                func.date(Order.created_at).label(\"date\"),\n+                func.sum(Order.total_amount).label(\"revenue\"),\n+                func.count(Order.id).label(\"order_count\"),\n+            )\n+            .filter(Order.created_at >= start_date)\n+            .group_by(func.date(Order.created_at))\n+            .all()\n+        )\n+\n         trends = []\n         for row in daily_revenue:\n-            trends.append({\n-                \"date\": row.date.isoformat(),\n-                \"revenue\": float(row.revenue or 0),\n-                \"transaction_fees\": float(row.revenue or 0) * 0.01,\n-                \"order_count\": row.order_count\n-            })\n-        \n+            trends.append(\n+                {\n+                    \"date\": row.date.isoformat(),\n+                    \"revenue\": float(row.revenue or 0),\n+                    \"transaction_fees\": float(row.revenue or 0) * 0.01,\n+                    \"order_count\": row.order_count,\n+                }\n+            )\n+\n         # Cache for 1 hour\n         await cache_data(cache_key, trends, ttl=3600)\n-        \n+\n         return APIResponseHelper.success(data=trends)\n-        \n+\n     except Exception as e:\n         return APIResponseHelper.error(\n-            message=f\"Failed to fetch revenue trends: {str(e)}\",\n-            status_code=500\n+            message=f\"Failed to fetch revenue trends: {str(e)}\", status_code=500\n         )\n \n \n @router.get(\"/top-restaurants\")\n async def get_top_restaurants(\n     limit: int = Query(10, ge=1, le=50),\n     metric: str = Query(\"revenue\", regex=\"^(revenue|orders|users)$\"),\n     current_user: User = Depends(get_current_platform_owner),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Get top performing restaurants by various metrics.\"\"\"\n     try:\n         cache_key = f\"platform:analytics:top_restaurants:{metric}:{limit}\"\n         cached_data = await get_cached_data_async(cache_key)\n         if cached_data:\n             return APIResponseHelper.success(data=cached_data)\n-        \n+\n         query = db.query(Restaurant)\n-        \n+\n         if metric == \"revenue\":\n             # Join with orders and sum revenue\n-            results = db.query(\n-                Restaurant,\n-                func.sum(Order.total_amount).label('metric_value')\n-            ).join(\n-                Order, Order.restaurant_id == Restaurant.id\n-            ).filter(\n-                Order.created_at >= datetime.now() - timedelta(days=30)\n-            ).group_by(\n-                Restaurant.id\n-            ).order_by(\n-                desc('metric_value')\n-            ).limit(limit).all()\n-            \n+            results = (\n+                db.query(Restaurant, func.sum(Order.total_amount).label(\"metric_value\"))\n+                .join(Order, Order.restaurant_id == Restaurant.id)\n+                .filter(Order.created_at >= datetime.now() - timedelta(days=30))\n+                .group_by(Restaurant.id)\n+                .order_by(desc(\"metric_value\"))\n+                .limit(limit)\n+                .all()\n+            )\n+\n         elif metric == \"orders\":\n             # Count orders\n-            results = db.query(\n-                Restaurant,\n-                func.count(Order.id).label('metric_value')\n-            ).join(\n-                Order, Order.restaurant_id == Restaurant.id\n-            ).filter(\n-                Order.created_at >= datetime.now() - timedelta(days=30)\n-            ).group_by(\n-                Restaurant.id\n-            ).order_by(\n-                desc('metric_value')\n-            ).limit(limit).all()\n-            \n+            results = (\n+                db.query(Restaurant, func.count(Order.id).label(\"metric_value\"))\n+                .join(Order, Order.restaurant_id == Restaurant.id)\n+                .filter(Order.created_at >= datetime.now() - timedelta(days=30))\n+                .group_by(Restaurant.id)\n+                .order_by(desc(\"metric_value\"))\n+                .limit(limit)\n+                .all()\n+            )\n+\n         else:  # users\n             # Count active users\n-            results = db.query(\n-                Restaurant,\n-                func.count(User.id).label('metric_value')\n-            ).join(\n-                User, User.restaurant_id == Restaurant.id\n-            ).group_by(\n-                Restaurant.id\n-            ).order_by(\n-                desc('metric_value')\n-            ).limit(limit).all()\n-        \n+            results = (\n+                db.query(Restaurant, func.count(User.id).label(\"metric_value\"))\n+                .join(User, User.restaurant_id == Restaurant.id)\n+                .group_by(Restaurant.id)\n+                .order_by(desc(\"metric_value\"))\n+                .limit(limit)\n+                .all()\n+            )\n+\n         top_restaurants = []\n         for restaurant, value in results:\n-            top_restaurants.append({\n-                \"id\": str(restaurant.id),\n-                \"name\": restaurant.name,\n-                \"subscription_plan\": restaurant.subscription_plan,\n-                \"metric\": metric,\n-                \"value\": float(value) if metric == \"revenue\" else int(value)\n-            })\n-        \n+            top_restaurants.append(\n+                {\n+                    \"id\": str(restaurant.id),\n+                    \"name\": restaurant.name,\n+                    \"subscription_plan\": restaurant.subscription_plan,\n+                    \"metric\": metric,\n+                    \"value\": float(value) if metric == \"revenue\" else int(value),\n+                }\n+            )\n+\n         # Cache for 1 hour\n         await cache_data(cache_key, top_restaurants, ttl=3600)\n-        \n+\n         return APIResponseHelper.success(data=top_restaurants)\n-        \n+\n     except Exception as e:\n         return APIResponseHelper.error(\n-            message=f\"Failed to fetch top restaurants: {str(e)}\",\n-            status_code=500\n-        )\n\\ No newline at end of file\n+            message=f\"Failed to fetch top restaurants: {str(e)}\", status_code=500\n+        )\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/__init__.py\t2025-08-01 21:42:06.654173+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/__init__.py\t2025-08-02 22:36:03.080130+00:00\n@@ -1,4 +1,4 @@\n \"\"\"\n Core package for Fynlo POS\n Contains core functionality, database models, and utilities\n-\"\"\"\n\\ No newline at end of file\n+\"\"\"\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/platform/restaurants.py\t2025-08-02 21:56:58.992182+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/platform/restaurants.py\t2025-08-02 22:36:03.096409+00:00\n@@ -23,243 +23,231 @@\n     limit: int = Query(20, ge=1, le=100),\n     search: Optional[str] = None,\n     subscription_plan: Optional[str] = None,\n     subscription_status: Optional[str] = None,\n     current_user: User = Depends(get_current_platform_owner),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"List all restaurants on the platform with filtering.\"\"\"\n     try:\n         query = db.query(Restaurant)\n-        \n+\n         # Apply filters\n         if search:\n             sanitized_search = sanitize_sql_like_pattern(search)\n             query = query.filter(\n                 or_(\n                     Restaurant.name.ilike(f\"%{sanitized_search}%\"),\n                     Restaurant.email.ilike(f\"%{sanitized_search}%\"),\n-                    Restaurant.phone.ilike(f\"%{sanitized_search}%\")\n+                    Restaurant.phone.ilike(f\"%{sanitized_search}%\"),\n                 )\n             )\n-        \n+\n         if subscription_plan:\n             query = query.filter(Restaurant.subscription_plan == subscription_plan)\n-        \n+\n         if subscription_status:\n             query = query.filter(Restaurant.subscription_status == subscription_status)\n-        \n+\n         # Get total count\n         total = query.count()\n-        \n+\n         # Get paginated results\n         restaurants = query.offset(skip).limit(limit).all()\n-        \n+\n         # Format response\n         data = []\n         for restaurant in restaurants:\n             # Get user count\n-            user_count = db.query(User).filter(\n-                User.restaurant_id == restaurant.id\n-            ).count()\n-            \n-            data.append({\n-                \"id\": str(restaurant.id),\n-                \"name\": restaurant.name,\n-                \"email\": restaurant.email,\n-                \"phone\": restaurant.phone,\n-                \"subscription_plan\": restaurant.subscription_plan,\n-                \"subscription_status\": restaurant.subscription_status,\n-                \"user_count\": user_count,\n-                \"created_at\": restaurant.created_at.isoformat(),\n-                \"is_active\": restaurant.is_active\n-            })\n-        \n+            user_count = (\n+                db.query(User).filter(User.restaurant_id == restaurant.id).count()\n+            )\n+\n+            data.append(\n+                {\n+                    \"id\": str(restaurant.id),\n+                    \"name\": restaurant.name,\n+                    \"email\": restaurant.email,\n+                    \"phone\": restaurant.phone,\n+                    \"subscription_plan\": restaurant.subscription_plan,\n+                    \"subscription_status\": restaurant.subscription_status,\n+                    \"user_count\": user_count,\n+                    \"created_at\": restaurant.created_at.isoformat(),\n+                    \"is_active\": restaurant.is_active,\n+                }\n+            )\n+\n         return APIResponseHelper.success(\n-            data={\n-                \"restaurants\": data,\n-                \"total\": total,\n-                \"skip\": skip,\n-                \"limit\": limit\n-            }\n-        )\n-        \n-    except Exception as e:\n-        return APIResponseHelper.error(\n-            message=f\"Failed to fetch restaurants: {str(e)}\",\n-            status_code=500\n+            data={\"restaurants\": data, \"total\": total, \"skip\": skip, \"limit\": limit}\n+        )\n+\n+    except Exception as e:\n+        return APIResponseHelper.error(\n+            message=f\"Failed to fetch restaurants: {str(e)}\", status_code=500\n         )\n \n \n @router.get(\"/{restaurant_id}\")\n async def get_restaurant_details(\n     restaurant_id: str,\n     current_user: User = Depends(get_current_platform_owner),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Get detailed information about a specific restaurant.\"\"\"\n     try:\n-        restaurant = db.query(Restaurant).filter(\n-            Restaurant.id == restaurant_id\n-        ).first()\n-        \n+        restaurant = db.query(Restaurant).filter(Restaurant.id == restaurant_id).first()\n+\n         if not restaurant:\n             return APIResponseHelper.error(\n-                message=\"Restaurant not found\",\n-                status_code=404\n-            )\n-        \n+                message=\"Restaurant not found\", status_code=404\n+            )\n+\n         # Get additional metrics\n-        user_count = db.query(User).filter(\n-            User.restaurant_id == restaurant.id\n-        ).count()\n-        \n+        user_count = db.query(User).filter(User.restaurant_id == restaurant.id).count()\n+\n         # Get revenue last 30 days\n         from app.core.database import Order\n         from sqlalchemy import func\n-        revenue_30d = db.query(\n-            func.sum(Order.total_amount)\n-        ).filter(\n-            Order.restaurant_id == restaurant.id,\n-            Order.created_at >= datetime.now() - timedelta(days=30)\n-        ).scalar() or 0\n-        \n+\n+        revenue_30d = (\n+            db.query(func.sum(Order.total_amount))\n+            .filter(\n+                Order.restaurant_id == restaurant.id,\n+                Order.created_at >= datetime.now() - timedelta(days=30),\n+            )\n+            .scalar()\n+            or 0\n+        )\n+\n         data = {\n             \"id\": str(restaurant.id),\n             \"name\": restaurant.name,\n             \"email\": restaurant.email,\n             \"phone\": restaurant.phone,\n             \"address\": restaurant.address,\n             \"subscription_plan\": restaurant.subscription_plan,\n             \"subscription_status\": restaurant.subscription_status,\n-            \"subscription_start_date\": restaurant.subscription_start_date.isoformat() if restaurant.subscription_start_date else None,\n-            \"subscription_end_date\": restaurant.subscription_end_date.isoformat() if restaurant.subscription_end_date else None,\n+            \"subscription_start_date\": (\n+                restaurant.subscription_start_date.isoformat()\n+                if restaurant.subscription_start_date\n+                else None\n+            ),\n+            \"subscription_end_date\": (\n+                restaurant.subscription_end_date.isoformat()\n+                if restaurant.subscription_end_date\n+                else None\n+            ),\n             \"config\": restaurant.config or {},\n             \"settings\": restaurant.settings or {},\n             \"metrics\": {\n                 \"user_count\": user_count,\n                 \"revenue_30d\": float(revenue_30d),\n-                \"transaction_fees_30d\": float(revenue_30d) * 0.01\n+                \"transaction_fees_30d\": float(revenue_30d) * 0.01,\n             },\n             \"created_at\": restaurant.created_at.isoformat(),\n             \"updated_at\": restaurant.updated_at.isoformat(),\n-            \"is_active\": restaurant.is_active\n+            \"is_active\": restaurant.is_active,\n         }\n-        \n+\n         return APIResponseHelper.success(data=data)\n-        \n-    except Exception as e:\n-        return APIResponseHelper.error(\n-            message=f\"Failed to fetch restaurant details: {str(e)}\",\n-            status_code=500\n+\n+    except Exception as e:\n+        return APIResponseHelper.error(\n+            message=f\"Failed to fetch restaurant details: {str(e)}\", status_code=500\n         )\n \n \n @router.put(\"/{restaurant_id}/subscription\")\n async def update_restaurant_subscription(\n     restaurant_id: str,\n     plan: str = Query(..., regex=\"^(alpha|beta|omega)$\"),\n     status: str = Query(..., regex=\"^(trial|active|cancelled|expired)$\"),\n     current_user: User = Depends(get_current_platform_owner),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Update a restaurant's subscription plan or status.\"\"\"\n     try:\n-        restaurant = db.query(Restaurant).filter(\n-            Restaurant.id == restaurant_id\n-        ).first()\n-        \n+        restaurant = db.query(Restaurant).filter(Restaurant.id == restaurant_id).first()\n+\n         if not restaurant:\n             return APIResponseHelper.error(\n-                message=\"Restaurant not found\",\n-                status_code=404\n-            )\n-        \n+                message=\"Restaurant not found\", status_code=404\n+            )\n+\n         # Update subscription\n         restaurant.subscription_plan = plan\n         restaurant.subscription_status = status\n-        \n+\n         if status == \"active\" and not restaurant.subscription_start_date:\n             restaurant.subscription_start_date = datetime.now()\n-        \n+\n         db.commit()\n-        \n+\n         # Log the change\n         from app.models.platform_audit import create_audit_log\n+\n         create_audit_log(\n             db=db,\n             user_id=current_user.id,\n             action=\"update_subscription\",\n             resource_type=\"restaurant\",\n             resource_id=restaurant_id,\n-            details={\n-                \"plan\": plan,\n-                \"status\": status\n-            }\n-        )\n-        \n+            details={\"plan\": plan, \"status\": status},\n+        )\n+\n         return APIResponseHelper.success(\n             message=\"Subscription updated successfully\",\n             data={\n                 \"restaurant_id\": restaurant_id,\n                 \"subscription_plan\": plan,\n-                \"subscription_status\": status\n-            }\n-        )\n-        \n+                \"subscription_status\": status,\n+            },\n+        )\n+\n     except Exception as e:\n         db.rollback()\n         return APIResponseHelper.error(\n-            message=f\"Failed to update subscription: {str(e)}\",\n-            status_code=500\n+            message=f\"Failed to update subscription: {str(e)}\", status_code=500\n         )\n \n \n @router.put(\"/{restaurant_id}/status\")\n async def toggle_restaurant_status(\n     restaurant_id: str,\n     is_active: bool,\n     current_user: User = Depends(get_current_platform_owner),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Enable or disable a restaurant.\"\"\"\n     try:\n-        restaurant = db.query(Restaurant).filter(\n-            Restaurant.id == restaurant_id\n-        ).first()\n-        \n+        restaurant = db.query(Restaurant).filter(Restaurant.id == restaurant_id).first()\n+\n         if not restaurant:\n             return APIResponseHelper.error(\n-                message=\"Restaurant not found\",\n-                status_code=404\n-            )\n-        \n+                message=\"Restaurant not found\", status_code=404\n+            )\n+\n         restaurant.is_active = is_active\n         db.commit()\n-        \n+\n         # Log the change\n         from app.models.platform_audit import create_audit_log\n+\n         create_audit_log(\n             db=db,\n             user_id=current_user.id,\n             action=\"toggle_status\",\n             resource_type=\"restaurant\",\n             resource_id=restaurant_id,\n-            details={\n-                \"is_active\": is_active\n-            }\n-        )\n-        \n+            details={\"is_active\": is_active},\n+        )\n+\n         return APIResponseHelper.success(\n             message=f\"Restaurant {'enabled' if is_active else 'disabled'} successfully\",\n-            data={\n-                \"restaurant_id\": restaurant_id,\n-                \"is_active\": is_active\n-            }\n-        )\n-        \n+            data={\"restaurant_id\": restaurant_id, \"is_active\": is_active},\n+        )\n+\n     except Exception as e:\n         db.rollback()\n         return APIResponseHelper.error(\n-            message=f\"Failed to update restaurant status: {str(e)}\",\n-            status_code=500\n-        )\n\\ No newline at end of file\n+            message=f\"Failed to update restaurant status: {str(e)}\", status_code=500\n+        )\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/platform/financial.py\t2025-08-02 10:59:17.990673+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/platform/financial.py\t2025-08-02 22:36:03.126395+00:00\n@@ -20,265 +20,298 @@\n async def get_revenue_report(\n     start_date: Optional[date] = None,\n     end_date: Optional[date] = None,\n     group_by: str = Query(\"day\", regex=\"^(day|week|month)$\"),\n     current_user: User = Depends(get_current_platform_owner),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Generate comprehensive revenue report for the platform.\"\"\"\n     try:\n         # Default to last 30 days if no dates provided\n         if not end_date:\n             end_date = date.today()\n         if not start_date:\n             start_date = end_date - timedelta(days=30)\n-        \n+\n         cache_key = f\"platform:financial:revenue:{start_date}:{end_date}:{group_by}\"\n         cached_data = await get_cached_data_async(cache_key)\n         if cached_data:\n             return APIResponseHelper.success(data=cached_data)\n-        \n+\n         # Determine grouping\n         if group_by == \"day\":\n             date_trunc = func.date(Order.created_at)\n         elif group_by == \"week\":\n-            date_trunc = func.date_trunc('week', Order.created_at)\n+            date_trunc = func.date_trunc(\"week\", Order.created_at)\n         else:  # month\n-            date_trunc = func.date_trunc('month', Order.created_at)\n-        \n+            date_trunc = func.date_trunc(\"month\", Order.created_at)\n+\n         # Query transaction revenue\n-        transaction_data = db.query(\n-            date_trunc.label('period'),\n-            func.sum(Order.total_amount).label('gross_revenue'),\n-            func.count(Order.id).label('order_count'),\n-            func.count(func.distinct(Order.restaurant_id)).label('active_restaurants')\n-        ).filter(\n-            and_(\n-                Order.created_at >= start_date,\n-                Order.created_at <= end_date + timedelta(days=1),\n-                Order.status == 'completed'\n-            )\n-        ).group_by('period').all()\n-        \n+        transaction_data = (\n+            db.query(\n+                date_trunc.label(\"period\"),\n+                func.sum(Order.total_amount).label(\"gross_revenue\"),\n+                func.count(Order.id).label(\"order_count\"),\n+                func.count(func.distinct(Order.restaurant_id)).label(\n+                    \"active_restaurants\"\n+                ),\n+            )\n+            .filter(\n+                and_(\n+                    Order.created_at >= start_date,\n+                    Order.created_at <= end_date + timedelta(days=1),\n+                    Order.status == \"completed\",\n+                )\n+            )\n+            .group_by(\"period\")\n+            .all()\n+        )\n+\n         # Calculate subscription revenue\n-        active_subscriptions = db.query(\n-            Restaurant.subscription_plan,\n-            func.count(Restaurant.id).label('count')\n-        ).filter(\n-            Restaurant.subscription_status == 'active'\n-        ).group_by(\n-            Restaurant.subscription_plan\n-        ).all()\n-        \n+        active_subscriptions = (\n+            db.query(\n+                Restaurant.subscription_plan, func.count(Restaurant.id).label(\"count\")\n+            )\n+            .filter(Restaurant.subscription_status == \"active\")\n+            .group_by(Restaurant.subscription_plan)\n+            .all()\n+        )\n+\n         monthly_subscription_revenue = 0\n         for plan, count in active_subscriptions:\n-            if plan == 'beta':\n+            if plan == \"beta\":\n                 monthly_subscription_revenue += count * 49\n-            elif plan == 'omega':\n+            elif plan == \"omega\":\n                 monthly_subscription_revenue += count * 119\n-        \n+\n         # Format report data\n         report_data = []\n         total_gross_revenue = 0\n         total_transaction_fees = 0\n         total_orders = 0\n-        \n+\n         for row in transaction_data:\n             gross_revenue = float(row.gross_revenue or 0)\n             transaction_fees = gross_revenue * 0.01  # 1% fee\n-            \n+\n             total_gross_revenue += gross_revenue\n             total_transaction_fees += transaction_fees\n             total_orders += row.order_count\n-            \n-            report_data.append({\n-                \"period\": row.period.isoformat() if hasattr(row.period, 'isoformat') else str(row.period),\n-                \"gross_revenue\": gross_revenue,\n-                \"transaction_fees\": transaction_fees,\n-                \"order_count\": row.order_count,\n-                \"active_restaurants\": row.active_restaurants\n-            })\n-        \n+\n+            report_data.append(\n+                {\n+                    \"period\": (\n+                        row.period.isoformat()\n+                        if hasattr(row.period, \"isoformat\")\n+                        else str(row.period)\n+                    ),\n+                    \"gross_revenue\": gross_revenue,\n+                    \"transaction_fees\": transaction_fees,\n+                    \"order_count\": row.order_count,\n+                    \"active_restaurants\": row.active_restaurants,\n+                }\n+            )\n+\n         # Calculate daily average subscription revenue\n         days_in_period = (end_date - start_date).days + 1\n         daily_subscription_revenue = monthly_subscription_revenue / 30\n         period_subscription_revenue = daily_subscription_revenue * days_in_period\n-        \n+\n         summary = {\n             \"period\": {\n                 \"start\": start_date.isoformat(),\n                 \"end\": end_date.isoformat(),\n-                \"days\": days_in_period\n+                \"days\": days_in_period,\n             },\n             \"revenue\": {\n                 \"gross_transaction_volume\": total_gross_revenue,\n                 \"transaction_fees\": total_transaction_fees,\n                 \"subscription_revenue\": period_subscription_revenue,\n-                \"total_platform_revenue\": total_transaction_fees + period_subscription_revenue\n+                \"total_platform_revenue\": total_transaction_fees\n+                + period_subscription_revenue,\n             },\n             \"metrics\": {\n                 \"total_orders\": total_orders,\n-                \"average_order_value\": total_gross_revenue / total_orders if total_orders > 0 else 0,\n-                \"average_daily_revenue\": (total_transaction_fees + period_subscription_revenue) / days_in_period\n+                \"average_order_value\": (\n+                    total_gross_revenue / total_orders if total_orders > 0 else 0\n+                ),\n+                \"average_daily_revenue\": (\n+                    total_transaction_fees + period_subscription_revenue\n+                )\n+                / days_in_period,\n             },\n-            \"detailed_data\": report_data\n+            \"detailed_data\": report_data,\n         }\n-        \n+\n         # Cache for 1 hour\n         await cache_data(cache_key, summary, ttl=3600)\n-        \n+\n         return APIResponseHelper.success(data=summary)\n-        \n+\n     except Exception as e:\n         return APIResponseHelper.error(\n-            message=f\"Failed to generate revenue report: {str(e)}\",\n-            status_code=500\n+            message=f\"Failed to generate revenue report: {str(e)}\", status_code=500\n         )\n \n \n @router.get(\"/payment-methods\")\n async def get_payment_method_breakdown(\n     days: int = Query(30, ge=1, le=365),\n     current_user: User = Depends(get_current_platform_owner),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Get breakdown of payment methods used across the platform.\"\"\"\n     try:\n         start_date = datetime.now() - timedelta(days=days)\n-        \n+\n         # Query payment method usage\n-        payment_data = db.query(\n-            Payment.payment_method,\n-            func.count(Payment.id).label('count'),\n-            func.sum(Payment.amount).label('total_amount')\n-        ).filter(\n-            and_(\n-                Payment.created_at >= start_date,\n-                Payment.status == 'completed'\n-            )\n-        ).group_by(\n-            Payment.payment_method\n-        ).all()\n-        \n+        payment_data = (\n+            db.query(\n+                Payment.payment_method,\n+                func.count(Payment.id).label(\"count\"),\n+                func.sum(Payment.amount).label(\"total_amount\"),\n+            )\n+            .filter(\n+                and_(Payment.created_at >= start_date, Payment.status == \"completed\")\n+            )\n+            .group_by(Payment.payment_method)\n+            .all()\n+        )\n+\n         # Calculate totals\n         total_payments = sum(row.count for row in payment_data)\n         total_amount = sum(float(row.total_amount or 0) for row in payment_data)\n-        \n+\n         # Format breakdown\n         breakdown = []\n         for row in payment_data:\n             amount = float(row.total_amount or 0)\n-            breakdown.append({\n-                \"payment_method\": row.payment_method,\n-                \"transaction_count\": row.count,\n-                \"total_amount\": amount,\n-                \"percentage_count\": round(row.count / total_payments * 100, 2) if total_payments > 0 else 0,\n-                \"percentage_amount\": round(amount / total_amount * 100, 2) if total_amount > 0 else 0,\n-                \"average_transaction\": amount / row.count if row.count > 0 else 0\n-            })\n-        \n+            breakdown.append(\n+                {\n+                    \"payment_method\": row.payment_method,\n+                    \"transaction_count\": row.count,\n+                    \"total_amount\": amount,\n+                    \"percentage_count\": (\n+                        round(row.count / total_payments * 100, 2)\n+                        if total_payments > 0\n+                        else 0\n+                    ),\n+                    \"percentage_amount\": (\n+                        round(amount / total_amount * 100, 2) if total_amount > 0 else 0\n+                    ),\n+                    \"average_transaction\": amount / row.count if row.count > 0 else 0,\n+                }\n+            )\n+\n         # Sort by total amount descending\n-        breakdown.sort(key=lambda x: x['total_amount'], reverse=True)\n-        \n+        breakdown.sort(key=lambda x: x[\"total_amount\"], reverse=True)\n+\n         return APIResponseHelper.success(\n             data={\n                 \"period_days\": days,\n                 \"total_transactions\": total_payments,\n                 \"total_amount\": total_amount,\n-                \"breakdown\": breakdown\n+                \"breakdown\": breakdown,\n             }\n         )\n-        \n+\n     except Exception as e:\n         return APIResponseHelper.error(\n-            message=f\"Failed to get payment method breakdown: {str(e)}\",\n-            status_code=500\n+            message=f\"Failed to get payment method breakdown: {str(e)}\", status_code=500\n         )\n \n \n @router.get(\"/projections\")\n async def get_revenue_projections(\n     months: int = Query(3, ge=1, le=12),\n     current_user: User = Depends(get_current_platform_owner),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Generate revenue projections based on current trends.\"\"\"\n     try:\n         # Get historical data for trend analysis\n         historical_months = 6\n         start_date = datetime.now() - timedelta(days=historical_months * 30)\n-        \n+\n         # Get monthly transaction revenue trend\n-        monthly_revenue = db.query(\n-            func.date_trunc('month', Order.created_at).label('month'),\n-            func.sum(Order.total_amount).label('revenue')\n-        ).filter(\n-            and_(\n-                Order.created_at >= start_date,\n-                Order.status == 'completed'\n-            )\n-        ).group_by('month').all()\n-        \n+        monthly_revenue = (\n+            db.query(\n+                func.date_trunc(\"month\", Order.created_at).label(\"month\"),\n+                func.sum(Order.total_amount).label(\"revenue\"),\n+            )\n+            .filter(and_(Order.created_at >= start_date, Order.status == \"completed\"))\n+            .group_by(\"month\")\n+            .all()\n+        )\n+\n         # Calculate growth rate\n         if len(monthly_revenue) >= 2:\n             revenues = [float(row.revenue or 0) for row in monthly_revenue]\n             # Simple linear regression for growth rate\n             avg_growth_rate = sum(\n-                (revenues[i] - revenues[i-1]) / revenues[i-1] \n-                for i in range(1, len(revenues)) \n-                if revenues[i-1] > 0\n+                (revenues[i] - revenues[i - 1]) / revenues[i - 1]\n+                for i in range(1, len(revenues))\n+                if revenues[i - 1] > 0\n             ) / (len(revenues) - 1)\n         else:\n             avg_growth_rate = 0.05  # Default 5% growth\n-        \n+\n         # Current metrics\n-        current_transaction_revenue = float(monthly_revenue[-1].revenue) if monthly_revenue else 0\n-        current_mrr = db.query(\n-            func.sum(\n-                case(\n-                    (Restaurant.subscription_plan == 'beta', 49),\n-                    (Restaurant.subscription_plan == 'omega', 119),\n-                    else_=0\n+        current_transaction_revenue = (\n+            float(monthly_revenue[-1].revenue) if monthly_revenue else 0\n+        )\n+        current_mrr = (\n+            db.query(\n+                func.sum(\n+                    case(\n+                        (Restaurant.subscription_plan == \"beta\", 49),\n+                        (Restaurant.subscription_plan == \"omega\", 119),\n+                        else_=0,\n+                    )\n                 )\n             )\n-        ).filter(\n-            Restaurant.subscription_status == 'active'\n-        ).scalar() or 0\n-        \n+            .filter(Restaurant.subscription_status == \"active\")\n+            .scalar()\n+            or 0\n+        )\n+\n         # Generate projections\n         projections = []\n         projected_transaction_revenue = current_transaction_revenue\n         projected_mrr = float(current_mrr)\n-        \n+\n         for i in range(1, months + 1):\n             # Apply growth rate\n-            projected_transaction_revenue *= (1 + avg_growth_rate)\n-            projected_mrr *= (1 + avg_growth_rate * 0.5)  # Subscription growth typically slower\n-            \n+            projected_transaction_revenue *= 1 + avg_growth_rate\n+            projected_mrr *= (\n+                1 + avg_growth_rate * 0.5\n+            )  # Subscription growth typically slower\n+\n             month_date = datetime.now() + timedelta(days=i * 30)\n             transaction_fees = projected_transaction_revenue * 0.01\n-            \n-            projections.append({\n-                \"month\": month_date.strftime('%Y-%m'),\n-                \"projected_transaction_volume\": projected_transaction_revenue,\n-                \"projected_transaction_fees\": transaction_fees,\n-                \"projected_subscription_revenue\": projected_mrr,\n-                \"projected_total_revenue\": transaction_fees + projected_mrr,\n-                \"growth_rate\": avg_growth_rate\n-            })\n-        \n+\n+            projections.append(\n+                {\n+                    \"month\": month_date.strftime(\"%Y-%m\"),\n+                    \"projected_transaction_volume\": projected_transaction_revenue,\n+                    \"projected_transaction_fees\": transaction_fees,\n+                    \"projected_subscription_revenue\": projected_mrr,\n+                    \"projected_total_revenue\": transaction_fees + projected_mrr,\n+                    \"growth_rate\": avg_growth_rate,\n+                }\n+            )\n+\n         return APIResponseHelper.success(\n             data={\n                 \"current_metrics\": {\n                     \"monthly_transaction_volume\": current_transaction_revenue,\n                     \"monthly_recurring_revenue\": current_mrr,\n-                    \"estimated_growth_rate\": avg_growth_rate\n+                    \"estimated_growth_rate\": avg_growth_rate,\n                 },\n-                \"projections\": projections\n+                \"projections\": projections,\n             }\n         )\n-        \n+\n     except Exception as e:\n         return APIResponseHelper.error(\n-            message=f\"Failed to generate projections: {str(e)}\",\n-            status_code=500\n-        )\n\\ No newline at end of file\n+            message=f\"Failed to generate projections: {str(e)}\", status_code=500\n+        )\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/platform/subscriptions.py\t2025-08-02 21:56:58.992481+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/platform/subscriptions.py\t2025-08-02 22:36:03.126748+00:00\n@@ -17,268 +17,263 @@\n \n \n @router.get(\"/summary\")\n async def get_subscription_summary(\n     current_user: User = Depends(get_current_platform_owner),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Get subscription plan distribution and revenue summary.\"\"\"\n     try:\n         # Get plan distribution\n-        plan_distribution = db.query(\n-            Restaurant.subscription_plan,\n-            Restaurant.subscription_status,\n-            func.count(Restaurant.id).label('count')\n-        ).group_by(\n-            Restaurant.subscription_plan,\n-            Restaurant.subscription_status\n-        ).all()\n-        \n+        plan_distribution = (\n+            db.query(\n+                Restaurant.subscription_plan,\n+                Restaurant.subscription_status,\n+                func.count(Restaurant.id).label(\"count\"),\n+            )\n+            .group_by(Restaurant.subscription_plan, Restaurant.subscription_status)\n+            .all()\n+        )\n+\n         # Calculate monthly recurring revenue (MRR)\n-        active_subscriptions = db.query(Restaurant).filter(\n-            Restaurant.subscription_status == 'active'\n-        ).all()\n-        \n+        active_subscriptions = (\n+            db.query(Restaurant)\n+            .filter(Restaurant.subscription_status == \"active\")\n+            .all()\n+        )\n+\n         mrr = 0\n         plan_revenue = {\n-            'alpha': {'count': 0, 'revenue': 0},\n-            'beta': {'count': 0, 'revenue': 0},\n-            'omega': {'count': 0, 'revenue': 0}\n+            \"alpha\": {\"count\": 0, \"revenue\": 0},\n+            \"beta\": {\"count\": 0, \"revenue\": 0},\n+            \"omega\": {\"count\": 0, \"revenue\": 0},\n         }\n-        \n+\n         for restaurant in active_subscriptions:\n-            if restaurant.subscription_plan == 'beta':\n+            if restaurant.subscription_plan == \"beta\":\n                 mrr += 49\n-                plan_revenue['beta']['count'] += 1\n-                plan_revenue['beta']['revenue'] += 49\n-            elif restaurant.subscription_plan == 'omega':\n+                plan_revenue[\"beta\"][\"count\"] += 1\n+                plan_revenue[\"beta\"][\"revenue\"] += 49\n+            elif restaurant.subscription_plan == \"omega\":\n                 mrr += 119\n-                plan_revenue['omega']['count'] += 1\n-                plan_revenue['omega']['revenue'] += 119\n+                plan_revenue[\"omega\"][\"count\"] += 1\n+                plan_revenue[\"omega\"][\"revenue\"] += 119\n             else:  # alpha\n-                plan_revenue['alpha']['count'] += 1\n-        \n+                plan_revenue[\"alpha\"][\"count\"] += 1\n+\n         # Format distribution data\n         distribution = {}\n         for plan, status, count in plan_distribution:\n             if plan not in distribution:\n                 distribution[plan] = {}\n             distribution[plan][status] = count\n-        \n+\n         summary = {\n             \"monthly_recurring_revenue\": mrr,\n             \"plan_revenue\": plan_revenue,\n             \"distribution\": distribution,\n             \"total_restaurants\": db.query(Restaurant).count(),\n             \"active_subscriptions\": len(active_subscriptions),\n-            \"trial_subscriptions\": db.query(Restaurant).filter(\n-                Restaurant.subscription_status == 'trial'\n-            ).count()\n+            \"trial_subscriptions\": db.query(Restaurant)\n+            .filter(Restaurant.subscription_status == \"trial\")\n+            .count(),\n         }\n-        \n+\n         return APIResponseHelper.success(data=summary)\n-        \n-    except Exception as e:\n-        return APIResponseHelper.error(\n-            message=f\"Failed to fetch subscription summary: {str(e)}\",\n-            status_code=500\n+\n+    except Exception as e:\n+        return APIResponseHelper.error(\n+            message=f\"Failed to fetch subscription summary: {str(e)}\", status_code=500\n         )\n \n \n @router.get(\"/expiring\")\n async def get_expiring_subscriptions(\n     days: int = Query(30, ge=1, le=90),\n     current_user: User = Depends(get_current_platform_owner),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Get subscriptions expiring within specified days.\"\"\"\n     try:\n         expiry_date = datetime.now() + timedelta(days=days)\n-        \n-        expiring = db.query(Restaurant).filter(\n-            and_(\n-                Restaurant.subscription_status.in_(['active', 'trial']),\n-                Restaurant.subscription_end_date <= expiry_date\n-            )\n-        ).order_by(Restaurant.subscription_end_date).all()\n-        \n+\n+        expiring = (\n+            db.query(Restaurant)\n+            .filter(\n+                and_(\n+                    Restaurant.subscription_status.in_([\"active\", \"trial\"]),\n+                    Restaurant.subscription_end_date <= expiry_date,\n+                )\n+            )\n+            .order_by(Restaurant.subscription_end_date)\n+            .all()\n+        )\n+\n         data = []\n         for restaurant in expiring:\n             days_until_expiry = (restaurant.subscription_end_date - datetime.now()).days\n-            \n-            data.append({\n-                \"id\": str(restaurant.id),\n-                \"name\": restaurant.name,\n-                \"email\": restaurant.email,\n-                \"subscription_plan\": restaurant.subscription_plan,\n-                \"subscription_status\": restaurant.subscription_status,\n-                \"expiry_date\": restaurant.subscription_end_date.isoformat(),\n-                \"days_until_expiry\": days_until_expiry\n-            })\n-        \n+\n+            data.append(\n+                {\n+                    \"id\": str(restaurant.id),\n+                    \"name\": restaurant.name,\n+                    \"email\": restaurant.email,\n+                    \"subscription_plan\": restaurant.subscription_plan,\n+                    \"subscription_status\": restaurant.subscription_status,\n+                    \"expiry_date\": restaurant.subscription_end_date.isoformat(),\n+                    \"days_until_expiry\": days_until_expiry,\n+                }\n+            )\n+\n         return APIResponseHelper.success(\n-            data={\n-                \"expiring_subscriptions\": data,\n-                \"total\": len(data)\n-            }\n-        )\n-        \n-    except Exception as e:\n-        return APIResponseHelper.error(\n-            message=f\"Failed to fetch expiring subscriptions: {str(e)}\",\n-            status_code=500\n+            data={\"expiring_subscriptions\": data, \"total\": len(data)}\n+        )\n+\n+    except Exception as e:\n+        return APIResponseHelper.error(\n+            message=f\"Failed to fetch expiring subscriptions: {str(e)}\", status_code=500\n         )\n \n \n @router.get(\"/churn-analysis\")\n async def get_churn_analysis(\n     months: int = Query(6, ge=1, le=12),\n     current_user: User = Depends(get_current_platform_owner),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Analyze subscription churn over time.\"\"\"\n     try:\n         start_date = datetime.now() - timedelta(days=months * 30)\n-        \n+\n         # Get cancellations by month\n-        cancellations = db.query(\n-            func.date_trunc('month', Restaurant.updated_at).label('month'),\n-            Restaurant.subscription_plan,\n-            func.count(Restaurant.id).label('count')\n-        ).filter(\n-            and_(\n-                Restaurant.subscription_status == 'cancelled',\n-                Restaurant.updated_at >= start_date\n-            )\n-        ).group_by(\n-            'month',\n-            Restaurant.subscription_plan\n-        ).all()\n-        \n+        cancellations = (\n+            db.query(\n+                func.date_trunc(\"month\", Restaurant.updated_at).label(\"month\"),\n+                Restaurant.subscription_plan,\n+                func.count(Restaurant.id).label(\"count\"),\n+            )\n+            .filter(\n+                and_(\n+                    Restaurant.subscription_status == \"cancelled\",\n+                    Restaurant.updated_at >= start_date,\n+                )\n+            )\n+            .group_by(\"month\", Restaurant.subscription_plan)\n+            .all()\n+        )\n+\n         # Get new subscriptions by month\n-        new_subscriptions = db.query(\n-            func.date_trunc('month', Restaurant.subscription_start_date).label('month'),\n-            Restaurant.subscription_plan,\n-            func.count(Restaurant.id).label('count')\n-        ).filter(\n-            Restaurant.subscription_start_date >= start_date\n-        ).group_by(\n-            'month',\n-            Restaurant.subscription_plan\n-        ).all()\n-        \n+        new_subscriptions = (\n+            db.query(\n+                func.date_trunc(\"month\", Restaurant.subscription_start_date).label(\n+                    \"month\"\n+                ),\n+                Restaurant.subscription_plan,\n+                func.count(Restaurant.id).label(\"count\"),\n+            )\n+            .filter(Restaurant.subscription_start_date >= start_date)\n+            .group_by(\"month\", Restaurant.subscription_plan)\n+            .all()\n+        )\n+\n         # Format data\n         churn_data = {}\n         for month, plan, count in cancellations:\n-            month_str = month.strftime('%Y-%m')\n+            month_str = month.strftime(\"%Y-%m\")\n             if month_str not in churn_data:\n                 churn_data[month_str] = {\n-                    'cancellations': {},\n-                    'new_subscriptions': {},\n-                    'net_change': {}\n+                    \"cancellations\": {},\n+                    \"new_subscriptions\": {},\n+                    \"net_change\": {},\n                 }\n-            churn_data[month_str]['cancellations'][plan] = count\n-        \n+            churn_data[month_str][\"cancellations\"][plan] = count\n+\n         for month, plan, count in new_subscriptions:\n-            month_str = month.strftime('%Y-%m')\n+            month_str = month.strftime(\"%Y-%m\")\n             if month_str not in churn_data:\n                 churn_data[month_str] = {\n-                    'cancellations': {},\n-                    'new_subscriptions': {},\n-                    'net_change': {}\n+                    \"cancellations\": {},\n+                    \"new_subscriptions\": {},\n+                    \"net_change\": {},\n                 }\n-            churn_data[month_str]['new_subscriptions'][plan] = count\n-        \n+            churn_data[month_str][\"new_subscriptions\"][plan] = count\n+\n         # Calculate net change\n         for month_str, data in churn_data.items():\n-            for plan in ['alpha', 'beta', 'omega']:\n-                new = data['new_subscriptions'].get(plan, 0)\n-                cancelled = data['cancellations'].get(plan, 0)\n-                data['net_change'][plan] = new - cancelled\n-        \n+            for plan in [\"alpha\", \"beta\", \"omega\"]:\n+                new = data[\"new_subscriptions\"].get(plan, 0)\n+                cancelled = data[\"cancellations\"].get(plan, 0)\n+                data[\"net_change\"][plan] = new - cancelled\n+\n         return APIResponseHelper.success(data=churn_data)\n-        \n-    except Exception as e:\n-        return APIResponseHelper.error(\n-            message=f\"Failed to analyze churn: {str(e)}\",\n-            status_code=500\n+\n+    except Exception as e:\n+        return APIResponseHelper.error(\n+            message=f\"Failed to analyze churn: {str(e)}\", status_code=500\n         )\n \n \n @router.post(\"/batch-update\")\n async def batch_update_subscriptions(\n     restaurant_ids: List[str],\n     plan: Optional[str] = None,\n     status: Optional[str] = None,\n     current_user: User = Depends(get_current_platform_owner),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Batch update subscription plans or statuses.\"\"\"\n     try:\n         if not plan and not status:\n             return APIResponseHelper.error(\n-                message=\"Either plan or status must be provided\",\n-                status_code=400\n-            )\n-        \n+                message=\"Either plan or status must be provided\", status_code=400\n+            )\n+\n         # Validate inputs\n-        if plan and plan not in ['alpha', 'beta', 'omega']:\n+        if plan and plan not in [\"alpha\", \"beta\", \"omega\"]:\n             return APIResponseHelper.error(\n-                message=\"Invalid plan. Must be alpha, beta, or omega\",\n-                status_code=400\n-            )\n-        \n-        if status and status not in ['trial', 'active', 'cancelled', 'expired']:\n-            return APIResponseHelper.error(\n-                message=\"Invalid status\",\n-                status_code=400\n-            )\n-        \n+                message=\"Invalid plan. Must be alpha, beta, or omega\", status_code=400\n+            )\n+\n+        if status and status not in [\"trial\", \"active\", \"cancelled\", \"expired\"]:\n+            return APIResponseHelper.error(message=\"Invalid status\", status_code=400)\n+\n         # Update restaurants\n         updated_count = 0\n         for restaurant_id in restaurant_ids:\n-            restaurant = db.query(Restaurant).filter(\n-                Restaurant.id == restaurant_id\n-            ).first()\n-            \n+            restaurant = (\n+                db.query(Restaurant).filter(Restaurant.id == restaurant_id).first()\n+            )\n+\n             if restaurant:\n                 if plan:\n                     restaurant.subscription_plan = plan\n                 if status:\n                     restaurant.subscription_status = status\n-                    if status == 'active' and not restaurant.subscription_start_date:\n+                    if status == \"active\" and not restaurant.subscription_start_date:\n                         restaurant.subscription_start_date = datetime.now()\n-                \n+\n                 updated_count += 1\n-        \n+\n         db.commit()\n-        \n+\n         # Log the batch update\n         from app.models.platform_audit import create_audit_log\n+\n         create_audit_log(\n             db=db,\n             user_id=current_user.id,\n             action=\"batch_update_subscriptions\",\n             resource_type=\"restaurant\",\n             resource_id=\",\".join(restaurant_ids),\n-            details={\n-                \"plan\": plan,\n-                \"status\": status,\n-                \"count\": updated_count\n-            }\n-        )\n-        \n+            details={\"plan\": plan, \"status\": status, \"count\": updated_count},\n+        )\n+\n         return APIResponseHelper.success(\n             message=f\"Updated {updated_count} restaurants\",\n-            data={\n-                \"updated_count\": updated_count,\n-                \"plan\": plan,\n-                \"status\": status\n-            }\n-        )\n-        \n+            data={\"updated_count\": updated_count, \"plan\": plan, \"status\": status},\n+        )\n+\n     except Exception as e:\n         db.rollback()\n         return APIResponseHelper.error(\n-            message=f\"Failed to batch update subscriptions: {str(e)}\",\n-            status_code=500\n-        )\n\\ No newline at end of file\n+            message=f\"Failed to batch update subscriptions: {str(e)}\", status_code=500\n+        )\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/platform/users.py\t2025-08-02 19:23:36.816582+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/platform/users.py\t2025-08-02 22:36:03.127485+00:00\n@@ -23,264 +23,241 @@\n     search: Optional[str] = None,\n     restaurant_id: Optional[str] = None,\n     role: Optional[str] = None,\n     is_active: Optional[bool] = None,\n     current_user: User = Depends(get_current_platform_owner),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"List all users across the platform with filtering.\"\"\"\n     try:\n         query = db.query(User).join(Restaurant)\n-        \n+\n         # Apply filters\n         if search:\n             sanitized_search = sanitize_sql_like_pattern(search)\n             query = query.filter(\n                 or_(\n                     User.email.ilike(f\"%{sanitized_search}%\"),\n                     User.first_name.ilike(f\"%{sanitized_search}%\"),\n-                    User.last_name.ilike(f\"%{sanitized_search}%\")\n+                    User.last_name.ilike(f\"%{sanitized_search}%\"),\n                 )\n             )\n-        \n+\n         if restaurant_id:\n             query = query.filter(User.restaurant_id == restaurant_id)\n-        \n+\n         if role:\n             query = query.filter(User.role == role)\n-        \n+\n         if is_active is not None:\n             query = query.filter(User.is_active == is_active)\n-        \n+\n         # Get total count\n         total = query.count()\n-        \n+\n         # Get paginated results\n         users = query.offset(skip).limit(limit).all()\n-        \n+\n         # Format response\n         data = []\n         for user in users:\n-            restaurant = db.query(Restaurant).filter(\n-                Restaurant.id == user.restaurant_id\n-            ).first()\n-            \n-            data.append({\n-                \"id\": str(user.id),\n-                \"email\": user.email,\n-                \"first_name\": user.first_name,\n-                \"last_name\": user.last_name,\n-                \"role\": user.role,\n-                \"restaurant\": {\n-                    \"id\": str(restaurant.id),\n-                    \"name\": restaurant.name\n-                } if restaurant else None,\n-                \"is_active\": user.is_active,\n-                \"last_login\": user.last_login.isoformat() if user.last_login else None,\n-                \"created_at\": user.created_at.isoformat()\n-            })\n-        \n+            restaurant = (\n+                db.query(Restaurant).filter(Restaurant.id == user.restaurant_id).first()\n+            )\n+\n+            data.append(\n+                {\n+                    \"id\": str(user.id),\n+                    \"email\": user.email,\n+                    \"first_name\": user.first_name,\n+                    \"last_name\": user.last_name,\n+                    \"role\": user.role,\n+                    \"restaurant\": (\n+                        {\"id\": str(restaurant.id), \"name\": restaurant.name}\n+                        if restaurant\n+                        else None\n+                    ),\n+                    \"is_active\": user.is_active,\n+                    \"last_login\": (\n+                        user.last_login.isoformat() if user.last_login else None\n+                    ),\n+                    \"created_at\": user.created_at.isoformat(),\n+                }\n+            )\n+\n         return APIResponseHelper.success(\n-            data={\n-                \"users\": data,\n-                \"total\": total,\n-                \"skip\": skip,\n-                \"limit\": limit\n-            }\n-        )\n-        \n-    except Exception as e:\n-        return APIResponseHelper.error(\n-            message=f\"Failed to fetch users: {str(e)}\",\n-            status_code=500\n+            data={\"users\": data, \"total\": total, \"skip\": skip, \"limit\": limit}\n+        )\n+\n+    except Exception as e:\n+        return APIResponseHelper.error(\n+            message=f\"Failed to fetch users: {str(e)}\", status_code=500\n         )\n \n \n @router.get(\"/activity-summary\")\n async def get_user_activity_summary(\n     days: int = Query(30, ge=1, le=90),\n     current_user: User = Depends(get_current_platform_owner),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Get user activity summary across the platform.\"\"\"\n     try:\n         cutoff_date = datetime.now() - timedelta(days=days)\n-        \n+\n         # Total users\n         total_users = db.query(User).count()\n-        \n+\n         # Active users (logged in within period)\n-        active_users = db.query(User).filter(\n-            User.last_login >= cutoff_date\n-        ).count()\n-        \n+        active_users = db.query(User).filter(User.last_login >= cutoff_date).count()\n+\n         # New users\n-        new_users = db.query(User).filter(\n-            User.created_at >= cutoff_date\n-        ).count()\n-        \n+        new_users = db.query(User).filter(User.created_at >= cutoff_date).count()\n+\n         # Users by role\n-        users_by_role = db.query(\n-            User.role,\n-            func.count(User.id).label('count')\n-        ).group_by(User.role).all()\n-        \n+        users_by_role = (\n+            db.query(User.role, func.count(User.id).label(\"count\"))\n+            .group_by(User.role)\n+            .all()\n+        )\n+\n         # Users by restaurant subscription plan\n-        users_by_plan = db.query(\n-            Restaurant.subscription_plan,\n-            func.count(User.id).label('count')\n-        ).join(\n-            User, User.restaurant_id == Restaurant.id\n-        ).group_by(\n-            Restaurant.subscription_plan\n-        ).all()\n-        \n+        users_by_plan = (\n+            db.query(Restaurant.subscription_plan, func.count(User.id).label(\"count\"))\n+            .join(User, User.restaurant_id == Restaurant.id)\n+            .group_by(Restaurant.subscription_plan)\n+            .all()\n+        )\n+\n         # Daily active users trend\n-        daily_active = db.query(\n-            func.date(User.last_login).label('date'),\n-            func.count(func.distinct(User.id)).label('count')\n-        ).filter(\n-            User.last_login >= cutoff_date\n-        ).group_by(\n-            func.date(User.last_login)\n-        ).all()\n-        \n+        daily_active = (\n+            db.query(\n+                func.date(User.last_login).label(\"date\"),\n+                func.count(func.distinct(User.id)).label(\"count\"),\n+            )\n+            .filter(User.last_login >= cutoff_date)\n+            .group_by(func.date(User.last_login))\n+            .all()\n+        )\n+\n         summary = {\n             \"total_users\": total_users,\n             \"active_users\": active_users,\n             \"new_users\": new_users,\n-            \"activity_rate\": round(active_users / total_users * 100, 2) if total_users > 0 else 0,\n+            \"activity_rate\": (\n+                round(active_users / total_users * 100, 2) if total_users > 0 else 0\n+            ),\n             \"users_by_role\": {role: count for role, count in users_by_role},\n             \"users_by_plan\": {plan: count for plan, count in users_by_plan},\n             \"daily_active_trend\": [\n                 {\"date\": date.isoformat(), \"count\": count}\n                 for date, count in daily_active\n-            ]\n+            ],\n         }\n-        \n+\n         return APIResponseHelper.success(data=summary)\n-        \n-    except Exception as e:\n-        return APIResponseHelper.error(\n-            message=f\"Failed to fetch activity summary: {str(e)}\",\n-            status_code=500\n+\n+    except Exception as e:\n+        return APIResponseHelper.error(\n+            message=f\"Failed to fetch activity summary: {str(e)}\", status_code=500\n         )\n \n \n @router.put(\"/{user_id}/status\")\n async def toggle_user_status(\n     user_id: str,\n     is_active: bool,\n     current_user: User = Depends(get_current_platform_owner),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Enable or disable a user account.\"\"\"\n     try:\n         user = db.query(User).filter(User.id == user_id).first()\n-        \n+\n         if not user:\n+            return APIResponseHelper.error(message=\"User not found\", status_code=404)\n+\n+        # Don't allow disabling platform owners\n+        if user.role == \"platform_owner\" and not is_active:\n             return APIResponseHelper.error(\n-                message=\"User not found\",\n-                status_code=404\n-            )\n-        \n-        # Don't allow disabling platform owners\n-        if user.role == 'platform_owner' and not is_active:\n-            return APIResponseHelper.error(\n-                message=\"Cannot disable platform owner accounts\",\n-                status_code=403\n-            )\n-        \n+                message=\"Cannot disable platform owner accounts\", status_code=403\n+            )\n+\n         user.is_active = is_active\n         db.commit()\n-        \n+\n         # Log the change\n         from app.models.platform_audit import create_audit_log\n+\n         create_audit_log(\n             db=db,\n             user_id=current_user.id,\n             action=\"toggle_user_status\",\n             resource_type=\"user\",\n             resource_id=user_id,\n-            details={\n-                \"is_active\": is_active\n-            }\n-        )\n-        \n+            details={\"is_active\": is_active},\n+        )\n+\n         return APIResponseHelper.success(\n             message=f\"User {'enabled' if is_active else 'disabled'} successfully\",\n-            data={\n-                \"user_id\": user_id,\n-                \"is_active\": is_active\n-            }\n-        )\n-        \n+            data={\"user_id\": user_id, \"is_active\": is_active},\n+        )\n+\n     except Exception as e:\n         db.rollback()\n         return APIResponseHelper.error(\n-            message=f\"Failed to update user status: {str(e)}\",\n-            status_code=500\n+            message=f\"Failed to update user status: {str(e)}\", status_code=500\n         )\n \n \n @router.delete(\"/{user_id}\")\n async def delete_user(\n     user_id: str,\n     current_user: User = Depends(get_current_platform_owner),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Permanently delete a user account.\"\"\"\n     try:\n         user = db.query(User).filter(User.id == user_id).first()\n-        \n+\n         if not user:\n+            return APIResponseHelper.error(message=\"User not found\", status_code=404)\n+\n+        # Don't allow deleting platform owners\n+        if user.role == \"platform_owner\":\n             return APIResponseHelper.error(\n-                message=\"User not found\",\n-                status_code=404\n-            )\n-        \n-        # Don't allow deleting platform owners\n-        if user.role == 'platform_owner':\n-            return APIResponseHelper.error(\n-                message=\"Cannot delete platform owner accounts\",\n-                status_code=403\n-            )\n-        \n+                message=\"Cannot delete platform owner accounts\", status_code=403\n+            )\n+\n         # Don't allow self-deletion\n         if user.id == current_user.id:\n             return APIResponseHelper.error(\n-                message=\"Cannot delete your own account\",\n-                status_code=403\n-            )\n-        \n+                message=\"Cannot delete your own account\", status_code=403\n+            )\n+\n         # Store info for audit log\n         user_email = user.email\n         restaurant_id = user.restaurant_id\n-        \n+\n         # Delete user\n         db.delete(user)\n         db.commit()\n-        \n+\n         # Log the deletion\n         from app.models.platform_audit import create_audit_log\n+\n         create_audit_log(\n             db=db,\n             user_id=current_user.id,\n             action=\"delete_user\",\n             resource_type=\"user\",\n             resource_id=user_id,\n-            details={\n-                \"deleted_email\": user_email,\n-                \"restaurant_id\": str(restaurant_id)\n-            }\n-        )\n-        \n-        return APIResponseHelper.success(\n-            message=\"User deleted successfully\"\n-        )\n-        \n+            details={\"deleted_email\": user_email, \"restaurant_id\": str(restaurant_id)},\n+        )\n+\n+        return APIResponseHelper.success(message=\"User deleted successfully\")\n+\n     except Exception as e:\n         db.rollback()\n         return APIResponseHelper.error(\n-            message=f\"Failed to delete user: {str(e)}\",\n-            status_code=500\n-        )\n\\ No newline at end of file\n+            message=f\"Failed to delete user: {str(e)}\", status_code=500\n+        )\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/auth.py\t2025-08-02 22:01:55.877613+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/auth.py\t2025-08-02 22:36:03.141574+00:00\n@@ -18,187 +18,192 @@\n from app.core.config import settings\n from app.core.exceptions import (\n     AuthenticationException,\n     AuthorizationException,\n     ValidationException,\n-    FynloException\n+    FynloException,\n )\n \n logger = logging.getLogger(__name__)\n \n \n async def get_current_user(\n     request: Request,\n     authorization: Optional[str] = Header(None),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ) -> User:\n     \"\"\"Get current user from Supabase token\"\"\"\n-    \n+\n     # Initialize audit logger\n     audit_service = AuditLoggerService(db)\n     ip_address = request.client.host if request.client else \"unknown\"\n     user_agent = request.headers.get(\"user-agent\", \"unknown\")\n     action_prefix = f\"Access to {request.url.path}\"\n-    \n+\n     if not authorization:\n         await audit_service.create_audit_log(\n             event_type=AuditEventType.ACCESS_DENIED,\n             event_status=AuditEventStatus.FAILURE,\n             action_performed=f\"{action_prefix} denied: No authorization header\",\n             ip_address=ip_address,\n             user_agent=user_agent,\n             details={\"reason\": \"Missing authorization header\"},\n-            commit=True\n+            commit=True,\n         )\n         raise AuthenticationException(\n             message=\"Authentication required\",\n-            details={\"error_code\": \"MISSING_AUTH_HEADER\"}\n-        )\n-    \n+            details={\"error_code\": \"MISSING_AUTH_HEADER\"},\n+        )\n+\n     token = authorization.replace(\"Bearer \", \"\")\n-    \n+\n     try:\n         # Verify with Supabase\n         user_response = supabase_admin.auth.get_user(token)\n         supabase_user = user_response.user\n-        \n+\n         if not supabase_user:\n             await audit_service.create_audit_log(\n                 event_type=AuditEventType.ACCESS_DENIED,\n                 event_status=AuditEventStatus.FAILURE,\n                 action_performed=f\"{action_prefix} denied: Invalid token\",\n                 ip_address=ip_address,\n                 user_agent=user_agent,\n-                details={\"reason\": \"Supabase returned no user\", \"token_prefix\": token[:10] + \"...\"},\n-                commit=True\n+                details={\n+                    \"reason\": \"Supabase returned no user\",\n+                    \"token_prefix\": token[:10] + \"...\",\n+                },\n+                commit=True,\n             )\n             raise AuthenticationException(\n-                message=\"Authentication failed\",\n-                details={\"error_code\": \"INVALID_TOKEN\"}\n-            )\n-        \n+                message=\"Authentication failed\", details={\"error_code\": \"INVALID_TOKEN\"}\n+            )\n+\n         # Get user from our database\n-        db_user = db.query(User).filter(\n-            User.supabase_id == str(supabase_user.id)\n-        ).first()\n-        \n+        db_user = (\n+            db.query(User).filter(User.supabase_id == str(supabase_user.id)).first()\n+        )\n+\n         if not db_user:\n             await audit_service.create_audit_log(\n                 event_type=AuditEventType.ACCESS_DENIED,\n                 event_status=AuditEventStatus.FAILURE,\n                 action_performed=f\"{action_prefix} denied: User not found in database\",\n                 username_or_email=supabase_user.email,\n                 ip_address=ip_address,\n                 user_agent=user_agent,\n-                details={\"reason\": \"User exists in Supabase but not in local database\", \"supabase_id\": str(supabase_user.id)},\n-                commit=True\n+                details={\n+                    \"reason\": \"User exists in Supabase but not in local database\",\n+                    \"supabase_id\": str(supabase_user.id),\n+                },\n+                commit=True,\n             )\n             raise AuthenticationException(\n                 message=\"Authentication failed\",\n-                details={\"error_code\": \"AUTHENTICATION_FAILED\"}\n-            )\n-        \n+                details={\"error_code\": \"AUTHENTICATION_FAILED\"},\n+            )\n+\n         if not db_user.is_active:\n             await audit_service.create_audit_log(\n                 event_type=AuditEventType.ACCESS_DENIED,\n                 event_status=AuditEventStatus.FAILURE,\n                 action_performed=f\"{action_prefix} denied: User account inactive\",\n                 user_id=db_user.id,\n                 username_or_email=db_user.email,\n                 ip_address=ip_address,\n                 user_agent=user_agent,\n                 details={\"reason\": \"User account is deactivated\"},\n-                commit=True\n+                commit=True,\n             )\n             raise AuthenticationException(\n-                message=\"Access denied\",\n-                details={\"error_code\": \"ACCESS_DENIED\"}\n-            )\n-        \n+                message=\"Access denied\", details={\"error_code\": \"ACCESS_DENIED\"}\n+            )\n+\n         # Log successful access\n         await audit_service.create_audit_log(\n             event_type=AuditEventType.ACCESS_GRANTED,\n             event_status=AuditEventStatus.SUCCESS,\n             action_performed=f\"{action_prefix} granted\",\n             user_id=db_user.id,\n             username_or_email=db_user.email,\n             restaurant_id=db_user.restaurant_id,\n             ip_address=ip_address,\n             user_agent=user_agent,\n-            commit=True\n-        )\n-        \n+            commit=True,\n+        )\n+\n         return db_user\n-        \n+\n     except (AuthenticationException, ValidationException, FynloException):\n         raise\n     except Exception as e:\n         await audit_service.create_audit_log(\n             event_type=AuditEventType.ACCESS_DENIED,\n             event_status=AuditEventStatus.FAILURE,\n             action_performed=f\"{action_prefix} denied: Authentication error\",\n             ip_address=ip_address,\n             user_agent=user_agent,\n-            details={\"error\": str(e), \"reason\": \"Unexpected error during authentication\"},\n-            commit=True\n+            details={\n+                \"error\": str(e),\n+                \"reason\": \"Unexpected error during authentication\",\n+            },\n+            commit=True,\n         )\n         logger.error(f\"Authentication error: {str(e)}\")\n         raise AuthenticationException(\n             message=\"Authentication failed\",\n-            details={\"error_code\": \"AUTHENTICATION_FAILED\"}\n+            details={\"error_code\": \"AUTHENTICATION_FAILED\"},\n         )\n \n \n async def get_current_active_user(\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ) -> User:\n     \"\"\"Ensure user is active\"\"\"\n     if not current_user.is_active:\n         raise ValidationException(\n-            message=\"Inactive user\",\n-            details={\"error_code\": \"BAD_REQUEST\"}\n+            message=\"Inactive user\", details={\"error_code\": \"BAD_REQUEST\"}\n         )\n     return current_user\n \n \n async def get_platform_owner(\n-    current_user: User = Depends(get_current_active_user)\n+    current_user: User = Depends(get_current_active_user),\n ) -> User:\n     \"\"\"Ensure user is platform owner\"\"\"\n-    if current_user.role != 'platform_owner':\n+    if current_user.role != \"platform_owner\":\n         raise AuthenticationException(\n             message=\"Not enough permissions. Platform owner access required.\",\n-            details={\"error_code\": \"ACCESS_DENIED\"}\n+            details={\"error_code\": \"ACCESS_DENIED\"},\n         )\n     return current_user\n \n \n async def get_restaurant_user(\n-    current_user: User = Depends(get_current_active_user),\n-    db: Session = Depends(get_db)\n+    current_user: User = Depends(get_current_active_user), db: Session = Depends(get_db)\n ) -> User:\n     \"\"\"Ensure user has restaurant access\"\"\"\n     if not current_user.restaurant_id:\n         raise AuthenticationException(\n             message=\"Restaurant access required\",\n-            details={\"error_code\": \"ACCESS_DENIED\"}\n+            details={\"error_code\": \"ACCESS_DENIED\"},\n         )\n     return current_user\n \n \n async def get_current_user_optional(\n     request: Request,\n     authorization: Optional[str] = Header(None),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ) -> Optional[User]:\n     \"\"\"\n     Optional authentication - returns user if authenticated, None otherwise.\n     Used for endpoints that support both authenticated and anonymous access.\n     \"\"\"\n     if not authorization:\n         return None\n-    \n+\n     try:\n         return await get_current_user(request, authorization, db)\n     except (AuthenticationException, ValidationException, FynloException):\n         return None\n \n@@ -206,50 +211,54 @@\n # Alias for consistency with platform API\n get_current_platform_owner = get_platform_owner\n \n \n async def verify_websocket_token(\n-    token: str,\n-    user_id: str,\n-    db: Session\n+    token: str, user_id: str, db: Session\n ) -> Optional[User]:\n     \"\"\"\n     Verify WebSocket authentication token\n     Returns User if valid, None otherwise\n     \"\"\"\n     try:\n         # Verify with Supabase\n         if not supabase_admin:\n             logger.error(\"Supabase admin client not initialized\")\n             return None\n-            \n+\n         user_response = supabase_admin.auth.get_user(token)\n         supabase_user = user_response.user\n-        \n+\n         if not supabase_user:\n             logger.warning(\"Invalid token - no user returned from Supabase\")\n             return None\n-        \n+\n         # Find user in our database by Supabase ID\n-        db_user = db.query(User).filter(User.supabase_id == str(supabase_user.id)).first()\n-        \n+        db_user = (\n+            db.query(User).filter(User.supabase_id == str(supabase_user.id)).first()\n+        )\n+\n         if not db_user:\n-            logger.warning(f\"User not found in database for Supabase ID: {supabase_user.id}\")\n-            return None\n-        \n+            logger.warning(\n+                f\"User not found in database for Supabase ID: {supabase_user.id}\"\n+            )\n+            return None\n+\n         # Verify the user is active\n         if not db_user.is_active:\n             logger.warning(f\"User is not active: {db_user.id}\")\n             return None\n-        \n+\n         # Verify user_id matches (critical security check)\n         if str(db_user.id) != str(user_id):\n-            logger.error(f\"User ID mismatch - potential security violation: {db_user.id} != {user_id}\")\n-            return None\n-        \n+            logger.error(\n+                f\"User ID mismatch - potential security violation: {db_user.id} != {user_id}\"\n+            )\n+            return None\n+\n         return db_user\n-        \n+\n     except Exception as e:\n         logger.error(f\"WebSocket token verification error: {str(e)}\")\n         return None\n \n \n@@ -260,10 +269,14 @@\n     \"\"\"\n     to_encode = data.copy()\n     if expires_delta:\n         expire = datetime.utcnow() + expires_delta\n     else:\n-        expire = datetime.utcnow() + timedelta(minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES)\n-    \n+        expire = datetime.utcnow() + timedelta(\n+            minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES\n+        )\n+\n     to_encode.update({\"exp\": expire})\n-    encoded_jwt = jwt.encode(to_encode, settings.SECRET_KEY, algorithm=settings.ALGORITHM)\n-    return encoded_jwt\n\\ No newline at end of file\n+    encoded_jwt = jwt.encode(\n+        to_encode, settings.SECRET_KEY, algorithm=settings.ALGORITHM\n+    )\n+    return encoded_jwt\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/cache.py\t2025-08-02 21:56:58.993457+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/cache.py\t2025-08-02 22:36:03.156314+00:00\n@@ -13,16 +13,16 @@\n \n \n async def cache_data(key: str, data: Any, ttl: int = 300) -> bool:\n     \"\"\"\n     Cache data with a specific TTL (time-to-live) in seconds.\n-    \n+\n     Args:\n         key: Cache key\n         data: Data to cache (will be JSON serialized)\n         ttl: Time-to-live in seconds (default: 5 minutes)\n-    \n+\n     Returns:\n         bool: True if successful, False otherwise\n     \"\"\"\n     if not redis_client:\n         logger.warning(\"Redis client not available for caching\")\n@@ -35,32 +35,34 @@\n \n \n def get_cached_data(key: str) -> Optional[Any]:\n     \"\"\"\n     Get cached data synchronously (for use in sync endpoints).\n-    \n+\n     DEPRECATED: This function has async/sync conflicts. Use get_cached_data_async() instead.\n-    \n+\n     Args:\n         key: Cache key\n-    \n+\n     Returns:\n         Cached data or None if not found/expired\n     \"\"\"\n-    logger.warning(f\"get_cached_data() is deprecated due to async/sync conflicts. Use get_cached_data_async() for key: {key}\")\n+    logger.warning(\n+        f\"get_cached_data() is deprecated due to async/sync conflicts. Use get_cached_data_async() for key: {key}\"\n+    )\n     # Return None to avoid runtime errors\n     # The platform API endpoints should be updated to use async version\n     return None\n \n \n async def get_cached_data_async(key: str) -> Optional[Any]:\n     \"\"\"\n     Get cached data asynchronously.\n-    \n+\n     Args:\n         key: Cache key\n-    \n+\n     Returns:\n         Cached data or None if not found/expired\n     \"\"\"\n     if not redis_client:\n         logger.warning(\"Redis client not available for cache retrieval\")\n@@ -73,14 +75,14 @@\n \n \n async def delete_cache(key: str) -> bool:\n     \"\"\"\n     Delete a specific cache key.\n-    \n+\n     Args:\n         key: Cache key to delete\n-    \n+\n     Returns:\n         bool: True if successful, False otherwise\n     \"\"\"\n     if not redis_client:\n         logger.warning(\"Redis client not available for cache deletion\")\n@@ -93,14 +95,14 @@\n \n \n async def delete_cache_pattern(pattern: str) -> int:\n     \"\"\"\n     Delete all cache keys matching a pattern.\n-    \n+\n     Args:\n         pattern: Pattern to match (e.g., \"platform:analytics:*\")\n-    \n+\n     Returns:\n         int: Number of keys deleted\n     \"\"\"\n     if not redis_client:\n         logger.warning(\"Redis client not available for pattern deletion\")\n@@ -112,79 +114,74 @@\n         return 0\n \n \n # Platform-specific cache functions\n \n+\n async def cache_platform_analytics(\n-    metric: str, \n-    data: Dict[str, Any], \n-    ttl: int = 900\n+    metric: str, data: Dict[str, Any], ttl: int = 900\n ) -> bool:\n     \"\"\"\n     Cache platform analytics data.\n-    \n+\n     Args:\n         metric: Analytics metric name\n         data: Analytics data\n         ttl: Time-to-live in seconds (default: 15 minutes)\n-    \n+\n     Returns:\n         bool: True if successful\n     \"\"\"\n     key = f\"platform:analytics:{metric}\"\n     return await cache_data(key, data, ttl)\n \n \n async def get_platform_analytics(metric: str) -> Optional[Dict[str, Any]]:\n     \"\"\"\n     Get cached platform analytics data.\n-    \n+\n     Args:\n         metric: Analytics metric name\n-    \n+\n     Returns:\n         Cached analytics data or None\n     \"\"\"\n     key = f\"platform:analytics:{metric}\"\n     return await get_cached_data_async(key)\n \n \n async def cache_platform_report(\n-    report_type: str,\n-    params: Dict[str, Any],\n-    data: Any,\n-    ttl: int = 3600\n+    report_type: str, params: Dict[str, Any], data: Any, ttl: int = 3600\n ) -> bool:\n     \"\"\"\n     Cache platform report data.\n-    \n+\n     Args:\n         report_type: Type of report\n         params: Report parameters (for cache key generation)\n         data: Report data\n         ttl: Time-to-live in seconds (default: 1 hour)\n-    \n+\n     Returns:\n         bool: True if successful\n     \"\"\"\n     # Create a deterministic key from params\n     param_str = \":\".join(f\"{k}={v}\" for k, v in sorted(params.items()))\n     key = f\"platform:report:{report_type}:{param_str}\"\n     return await cache_data(key, data, ttl)\n \n \n async def get_platform_report(\n-    report_type: str,\n-    params: Dict[str, Any]\n+    report_type: str, params: Dict[str, Any]\n ) -> Optional[Any]:\n     \"\"\"\n     Get cached platform report data.\n-    \n+\n     Args:\n         report_type: Type of report\n         params: Report parameters\n-    \n+\n     Returns:\n         Cached report data or None\n     \"\"\"\n     param_str = \":\".join(f\"{k}={v}\" for k, v in sorted(params.items()))\n     key = f\"platform:report:{report_type}:{param_str}\"\n@@ -192,156 +189,141 @@\n \n \n async def invalidate_platform_cache() -> int:\n     \"\"\"\n     Invalidate all platform-related cache entries.\n-    \n+\n     Returns:\n         int: Number of keys deleted\n     \"\"\"\n-    patterns = [\n-        \"platform:analytics:*\",\n-        \"platform:report:*\",\n-        \"platform:dashboard:*\"\n-    ]\n+    patterns = [\"platform:analytics:*\", \"platform:report:*\", \"platform:dashboard:*\"]\n     total_deleted = 0\n     for pattern in patterns:\n         deleted = await delete_cache_pattern(pattern)\n         total_deleted += deleted\n-    \n+\n     logger.info(f\"Invalidated {total_deleted} platform cache entries\")\n     return total_deleted\n \n \n async def cache_restaurant_metrics(\n-    restaurant_id: str,\n-    metrics: Dict[str, Any],\n-    ttl: int = 600\n+    restaurant_id: str, metrics: Dict[str, Any], ttl: int = 600\n ) -> bool:\n     \"\"\"\n     Cache restaurant-specific metrics for platform dashboard.\n-    \n+\n     Args:\n         restaurant_id: Restaurant ID\n         metrics: Restaurant metrics\n         ttl: Time-to-live in seconds (default: 10 minutes)\n-    \n+\n     Returns:\n         bool: True if successful\n     \"\"\"\n     key = f\"platform:restaurant:{restaurant_id}:metrics\"\n     return await cache_data(key, metrics, ttl)\n \n \n async def get_restaurant_metrics(restaurant_id: str) -> Optional[Dict[str, Any]]:\n     \"\"\"\n     Get cached restaurant metrics.\n-    \n+\n     Args:\n         restaurant_id: Restaurant ID\n-    \n+\n     Returns:\n         Cached metrics or None\n     \"\"\"\n     key = f\"platform:restaurant:{restaurant_id}:metrics\"\n     return await get_cached_data_async(key)\n \n \n-async def cache_subscription_summary(\n-    summary: Dict[str, Any],\n-    ttl: int = 1800\n-) -> bool:\n+async def cache_subscription_summary(summary: Dict[str, Any], ttl: int = 1800) -> bool:\n     \"\"\"\n     Cache subscription summary for platform dashboard.\n-    \n+\n     Args:\n         summary: Subscription summary data\n         ttl: Time-to-live in seconds (default: 30 minutes)\n-    \n+\n     Returns:\n         bool: True if successful\n     \"\"\"\n     key = \"platform:subscriptions:summary\"\n     return await cache_data(key, summary, ttl)\n \n \n async def get_subscription_summary() -> Optional[Dict[str, Any]]:\n     \"\"\"\n     Get cached subscription summary.\n-    \n+\n     Returns:\n         Cached summary or None\n     \"\"\"\n     key = \"platform:subscriptions:summary\"\n     return await get_cached_data_async(key)\n \n \n # Dashboard-specific cache functions\n \n-async def cache_dashboard_widget(\n-    widget_name: str,\n-    data: Any,\n-    ttl: int = 300\n-) -> bool:\n+\n+async def cache_dashboard_widget(widget_name: str, data: Any, ttl: int = 300) -> bool:\n     \"\"\"\n     Cache dashboard widget data.\n-    \n+\n     Args:\n         widget_name: Name of the dashboard widget\n         data: Widget data\n         ttl: Time-to-live in seconds (default: 5 minutes)\n-    \n+\n     Returns:\n         bool: True if successful\n     \"\"\"\n     key = f\"platform:dashboard:widget:{widget_name}\"\n     return await cache_data(key, data, ttl)\n \n \n async def get_dashboard_widget(widget_name: str) -> Optional[Any]:\n     \"\"\"\n     Get cached dashboard widget data.\n-    \n+\n     Args:\n         widget_name: Name of the dashboard widget\n-    \n+\n     Returns:\n         Cached widget data or None\n     \"\"\"\n     key = f\"platform:dashboard:widget:{widget_name}\"\n     return await get_cached_data_async(key)\n \n \n # Real-time metrics cache (shorter TTL)\n \n-async def cache_realtime_metric(\n-    metric: str,\n-    value: Any,\n-    ttl: int = 60\n-) -> bool:\n+\n+async def cache_realtime_metric(metric: str, value: Any, ttl: int = 60) -> bool:\n     \"\"\"\n     Cache real-time metric with short TTL.\n-    \n+\n     Args:\n         metric: Metric name\n         value: Metric value\n         ttl: Time-to-live in seconds (default: 1 minute)\n-    \n+\n     Returns:\n         bool: True if successful\n     \"\"\"\n     key = f\"platform:realtime:{metric}\"\n     return await cache_data(key, value, ttl)\n \n \n async def get_realtime_metric(metric: str) -> Optional[Any]:\n     \"\"\"\n     Get cached real-time metric.\n-    \n+\n     Args:\n         metric: Metric name\n-    \n+\n     Returns:\n         Cached metric value or None\n     \"\"\"\n     key = f\"platform:realtime:{metric}\"\n-    return await get_cached_data_async(key)\n\\ No newline at end of file\n+    return await get_cached_data_async(key)\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/subscriptions.py\t2025-08-02 21:56:58.992626+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/subscriptions.py\t2025-08-02 22:36:03.158004+00:00\n@@ -9,478 +9,535 @@\n from sqlalchemy.orm import Session\n from typing import Optional\n from datetime import datetime, timedelta\n \n from app.core.database import get_db\n-from app.models.subscription import SubscriptionPlan, RestaurantSubscription, SubscriptionUsage\n+from app.models.subscription import (\n+    SubscriptionPlan,\n+    RestaurantSubscription,\n+    SubscriptionUsage,\n+)\n from app.core.responses import APIResponseHelper\n from app.schemas.subscription import (\n     SubscriptionPlanResponse,\n     RestaurantSubscriptionResponse,\n     SubscriptionUsageResponse,\n     SubscriptionCreateRequest,\n-    PlanChangeRequest\n+    PlanChangeRequest,\n )\n from app.core.auth import get_current_user\n \n \n router = APIRouter(prefix=\"/subscriptions\", tags=[\"subscriptions\"])\n \n \n @router.get(\"/plans\")\n async def get_subscription_plans(\n     db: Session = Depends(get_db),\n-    include_inactive: bool = Query(False, description=\"Include inactive plans\")\n+    include_inactive: bool = Query(False, description=\"Include inactive plans\"),\n ):\n     \"\"\"\n     Get all available subscription plans\n-    \n+\n     Returns a list of subscription plans with their features and pricing.\n     \"\"\"\n     try:\n         query = db.query(SubscriptionPlan)\n-        \n+\n         if not include_inactive:\n             query = query.filter(SubscriptionPlan.is_active == True)\n-            \n+\n         plans = query.order_by(SubscriptionPlan.price_monthly).all()\n-        \n-        return APIResponseHelper.success(\n-            data=plans,\n-            message=f\"Retrieved {len(plans)} subscription plans\"\n-        )\n-        \n-    except Exception as e:\n-        return APIResponseHelper.error(\n-            message=f\"Failed to retrieve subscription plans: {str(e)}\",\n-            status_code=500\n+\n+        return APIResponseHelper.success(\n+            data=plans, message=f\"Retrieved {len(plans)} subscription plans\"\n+        )\n+\n+    except Exception as e:\n+        return APIResponseHelper.error(\n+            message=f\"Failed to retrieve subscription plans: {str(e)}\", status_code=500\n         )\n \n \n @router.get(\"/current\")\n async def get_current_subscription(\n     restaurant_id: int = Query(..., description=\"Restaurant ID\"),\n     db: Session = Depends(get_db),\n-    current_user=Depends(get_current_user)\n+    current_user=Depends(get_current_user),\n ):\n     \"\"\"\n     Get current subscription for a restaurant\n-    \n+\n     Returns the active subscription details including plan information\n     and usage statistics.\n     \"\"\"\n     try:\n         # Verify user has access to this restaurant\n-        if not hasattr(current_user, 'restaurant_id') or current_user.restaurant_id is None:\n+        if (\n+            not hasattr(current_user, \"restaurant_id\")\n+            or current_user.restaurant_id is None\n+        ):\n             return APIResponseHelper.error(\n                 message=\"Access denied: User not associated with any restaurant\",\n-                status_code=403\n-            )\n-        \n+                status_code=403,\n+            )\n+\n         if current_user.restaurant_id != restaurant_id:\n             return APIResponseHelper.error(\n                 message=\"Access denied: You don't have permission to access this restaurant's subscription data\",\n-                status_code=403\n-            )\n-        subscription = db.query(RestaurantSubscription).filter(\n-            RestaurantSubscription.restaurant_id == restaurant_id,\n-            RestaurantSubscription.status.in_(['active', 'trial'])\n-        ).first()\n-        \n+                status_code=403,\n+            )\n+        subscription = (\n+            db.query(RestaurantSubscription)\n+            .filter(\n+                RestaurantSubscription.restaurant_id == restaurant_id,\n+                RestaurantSubscription.status.in_([\"active\", \"trial\"]),\n+            )\n+            .first()\n+        )\n+\n         if not subscription:\n             return APIResponseHelper.error(\n                 message=\"No active subscription found for this restaurant\",\n-                status_code=404\n-            )\n-        \n+                status_code=404,\n+            )\n+\n         # Get current month usage\n         current_month = SubscriptionUsage.get_current_month_key()\n-        usage = db.query(SubscriptionUsage).filter(\n-            SubscriptionUsage.restaurant_id == restaurant_id,\n-            SubscriptionUsage.month_year == current_month\n-        ).first()\n-        \n+        usage = (\n+            db.query(SubscriptionUsage)\n+            .filter(\n+                SubscriptionUsage.restaurant_id == restaurant_id,\n+                SubscriptionUsage.month_year == current_month,\n+            )\n+            .first()\n+        )\n+\n         response_data = {\n             \"subscription\": subscription,\n             \"plan\": subscription.plan,\n-            \"usage\": usage\n+            \"usage\": usage,\n         }\n-        \n-        return APIResponseHelper.success(\n-            data=response_data,\n-            message=\"Current subscription retrieved successfully\"\n-        )\n-        \n+\n+        return APIResponseHelper.success(\n+            data=response_data, message=\"Current subscription retrieved successfully\"\n+        )\n+\n     except Exception as e:\n         return APIResponseHelper.error(\n             message=f\"Failed to retrieve current subscription: {str(e)}\",\n-            status_code=500\n+            status_code=500,\n         )\n \n \n @router.post(\"/subscribe\")\n async def create_subscription(\n     subscription_data: SubscriptionCreateRequest,\n     db: Session = Depends(get_db),\n-    current_user=Depends(get_current_user)\n+    current_user=Depends(get_current_user),\n ):\n     \"\"\"\n     Subscribe a restaurant to a plan\n-    \n+\n     Creates a new subscription for the restaurant with the specified plan.\n     \"\"\"\n     try:\n         # Verify user has access to this restaurant\n-        if not hasattr(current_user, 'restaurant_id') or current_user.restaurant_id is None:\n+        if (\n+            not hasattr(current_user, \"restaurant_id\")\n+            or current_user.restaurant_id is None\n+        ):\n             return APIResponseHelper.error(\n                 message=\"Access denied: User not associated with any restaurant\",\n-                status_code=403\n-            )\n-        \n+                status_code=403,\n+            )\n+\n         if current_user.restaurant_id != subscription_data.restaurant_id:\n             return APIResponseHelper.error(\n                 message=\"Access denied: You don't have permission to manage this restaurant's subscription\",\n-                status_code=403\n+                status_code=403,\n             )\n         # Check if restaurant already has an active subscription\n-        existing_subscription = db.query(RestaurantSubscription).filter(\n-            RestaurantSubscription.restaurant_id == subscription_data.restaurant_id,\n-            RestaurantSubscription.status.in_(['active', 'trial'])\n-        ).first()\n-        \n+        existing_subscription = (\n+            db.query(RestaurantSubscription)\n+            .filter(\n+                RestaurantSubscription.restaurant_id == subscription_data.restaurant_id,\n+                RestaurantSubscription.status.in_([\"active\", \"trial\"]),\n+            )\n+            .first()\n+        )\n+\n         if existing_subscription:\n             return APIResponseHelper.error(\n-                message=\"Restaurant already has an active subscription\",\n-                status_code=400\n-            )\n-        \n+                message=\"Restaurant already has an active subscription\", status_code=400\n+            )\n+\n         # Verify the plan exists\n-        plan = db.query(SubscriptionPlan).filter(\n-            SubscriptionPlan.id == subscription_data.plan_id,\n-            SubscriptionPlan.is_active == True\n-        ).first()\n-        \n+        plan = (\n+            db.query(SubscriptionPlan)\n+            .filter(\n+                SubscriptionPlan.id == subscription_data.plan_id,\n+                SubscriptionPlan.is_active == True,\n+            )\n+            .first()\n+        )\n+\n         if not plan:\n             return APIResponseHelper.error(\n-                message=\"Invalid subscription plan\",\n-                status_code=400\n-            )\n-        \n+                message=\"Invalid subscription plan\", status_code=400\n+            )\n+\n         # Create new subscription\n         now = datetime.utcnow()\n-        \n+\n         # Set trial period for new subscriptions (14 days)\n         if subscription_data.start_trial:\n             status = \"trial\"\n             trial_end_date = now + timedelta(days=14)\n             period_end = trial_end_date\n         else:\n             status = \"active\"\n             trial_end_date = None\n             period_end = now + timedelta(days=30)  # Monthly billing\n-        \n+\n         new_subscription = RestaurantSubscription(\n             restaurant_id=subscription_data.restaurant_id,\n             plan_id=subscription_data.plan_id,\n             status=status,\n             trial_end_date=trial_end_date,\n             current_period_start=now,\n             current_period_end=period_end,\n             stripe_subscription_id=subscription_data.stripe_subscription_id,\n-            stripe_customer_id=subscription_data.stripe_customer_id\n-        )\n-        \n+            stripe_customer_id=subscription_data.stripe_customer_id,\n+        )\n+\n         db.add(new_subscription)\n         db.commit()\n         db.refresh(new_subscription)\n-        \n+\n         # Initialize usage tracking for current month\n         current_month = SubscriptionUsage.get_current_month_key()\n         usage = SubscriptionUsage(\n-            restaurant_id=subscription_data.restaurant_id,\n-            month_year=current_month\n+            restaurant_id=subscription_data.restaurant_id, month_year=current_month\n         )\n         db.add(usage)\n         db.commit()\n-        \n+\n         return APIResponseHelper.success(\n             data=new_subscription,\n             message=f\"Successfully subscribed to {plan.display_name}\",\n-            status_code=201\n-        )\n-        \n+            status_code=201,\n+        )\n+\n     except Exception as e:\n         db.rollback()\n         return APIResponseHelper.error(\n-            message=f\"Failed to create subscription: {str(e)}\",\n-            status_code=500\n+            message=f\"Failed to create subscription: {str(e)}\", status_code=500\n         )\n \n \n @router.put(\"/change-plan\")\n async def change_subscription_plan(\n     change_data: PlanChangeRequest,\n     db: Session = Depends(get_db),\n-    current_user=Depends(get_current_user)\n+    current_user=Depends(get_current_user),\n ):\n     \"\"\"\n     Change subscription plan (upgrade/downgrade)\n-    \n+\n     Updates the restaurant's subscription to a different plan.\n     \"\"\"\n     try:\n         # Verify user has access to this restaurant\n-        if not hasattr(current_user, 'restaurant_id') or current_user.restaurant_id is None:\n+        if (\n+            not hasattr(current_user, \"restaurant_id\")\n+            or current_user.restaurant_id is None\n+        ):\n             return APIResponseHelper.error(\n                 message=\"Access denied: User not associated with any restaurant\",\n-                status_code=403\n-            )\n-        \n+                status_code=403,\n+            )\n+\n         if current_user.restaurant_id != change_data.restaurant_id:\n             return APIResponseHelper.error(\n                 message=\"Access denied: You don't have permission to manage this restaurant's subscription\",\n-                status_code=403\n+                status_code=403,\n             )\n         # Get current subscription\n-        subscription = db.query(RestaurantSubscription).filter(\n-            RestaurantSubscription.restaurant_id == change_data.restaurant_id,\n-            RestaurantSubscription.status.in_(['active', 'trial'])\n-        ).first()\n-        \n+        subscription = (\n+            db.query(RestaurantSubscription)\n+            .filter(\n+                RestaurantSubscription.restaurant_id == change_data.restaurant_id,\n+                RestaurantSubscription.status.in_([\"active\", \"trial\"]),\n+            )\n+            .first()\n+        )\n+\n         if not subscription:\n             return APIResponseHelper.error(\n-                message=\"No active subscription found\",\n-                status_code=404\n-            )\n-        \n+                message=\"No active subscription found\", status_code=404\n+            )\n+\n         # Verify new plan exists\n-        new_plan = db.query(SubscriptionPlan).filter(\n-            SubscriptionPlan.id == change_data.new_plan_id,\n-            SubscriptionPlan.is_active == True\n-        ).first()\n-        \n+        new_plan = (\n+            db.query(SubscriptionPlan)\n+            .filter(\n+                SubscriptionPlan.id == change_data.new_plan_id,\n+                SubscriptionPlan.is_active == True,\n+            )\n+            .first()\n+        )\n+\n         if not new_plan:\n-            return APIResponseHelper.error(\n-                message=\"Invalid new plan\",\n-                status_code=400\n-            )\n-        \n+            return APIResponseHelper.error(message=\"Invalid new plan\", status_code=400)\n+\n         old_plan = subscription.plan\n-        \n+\n         # Update subscription\n         subscription.plan_id = change_data.new_plan_id\n         subscription.updated_at = datetime.utcnow()\n-        \n+\n         # If changing from trial, update status\n-        if subscription.status == 'trial' and not new_plan.name == 'trial':\n-            subscription.status = 'active'\n+        if subscription.status == \"trial\" and not new_plan.name == \"trial\":\n+            subscription.status = \"active\"\n             subscription.trial_end_date = None\n-        \n+\n         db.commit()\n         db.refresh(subscription)\n-        \n-        change_type = \"upgrade\" if new_plan.price_monthly > old_plan.price_monthly else \"downgrade\"\n-        \n+\n+        change_type = (\n+            \"upgrade\"\n+            if new_plan.price_monthly > old_plan.price_monthly\n+            else \"downgrade\"\n+        )\n+\n         return APIResponseHelper.success(\n             data=subscription,\n-            message=f\"Successfully {change_type}d from {old_plan.display_name} to {new_plan.display_name}\"\n-        )\n-        \n+            message=f\"Successfully {change_type}d from {old_plan.display_name} to {new_plan.display_name}\",\n+        )\n+\n     except Exception as e:\n         db.rollback()\n         return APIResponseHelper.error(\n-            message=f\"Failed to change subscription plan: {str(e)}\",\n-            status_code=500\n+            message=f\"Failed to change subscription plan: {str(e)}\", status_code=500\n         )\n \n \n @router.post(\"/cancel\")\n async def cancel_subscription(\n     restaurant_id: int = Query(..., description=\"Restaurant ID\"),\n     db: Session = Depends(get_db),\n-    current_user=Depends(get_current_user)\n+    current_user=Depends(get_current_user),\n ):\n     \"\"\"\n     Cancel subscription\n-    \n+\n     Cancels the restaurant's active subscription.\n     \"\"\"\n     try:\n         # Verify user has access to this restaurant\n-        if not hasattr(current_user, 'restaurant_id') or current_user.restaurant_id is None:\n+        if (\n+            not hasattr(current_user, \"restaurant_id\")\n+            or current_user.restaurant_id is None\n+        ):\n             return APIResponseHelper.error(\n                 message=\"Access denied: User not associated with any restaurant\",\n-                status_code=403\n-            )\n-        \n+                status_code=403,\n+            )\n+\n         if current_user.restaurant_id != restaurant_id:\n             return APIResponseHelper.error(\n                 message=\"Access denied: You don't have permission to manage this restaurant's subscription\",\n-                status_code=403\n-            )\n-        subscription = db.query(RestaurantSubscription).filter(\n-            RestaurantSubscription.restaurant_id == restaurant_id,\n-            RestaurantSubscription.status.in_(['active', 'trial'])\n-        ).first()\n-        \n+                status_code=403,\n+            )\n+        subscription = (\n+            db.query(RestaurantSubscription)\n+            .filter(\n+                RestaurantSubscription.restaurant_id == restaurant_id,\n+                RestaurantSubscription.status.in_([\"active\", \"trial\"]),\n+            )\n+            .first()\n+        )\n+\n         if not subscription:\n             return APIResponseHelper.error(\n-                message=\"No active subscription found\",\n-                status_code=404\n-            )\n-        \n+                message=\"No active subscription found\", status_code=404\n+            )\n+\n         # Update subscription status\n-        subscription.status = 'cancelled'\n+        subscription.status = \"cancelled\"\n         subscription.updated_at = datetime.utcnow()\n-        \n+\n         db.commit()\n-        \n+\n         return APIResponseHelper.success(\n             data={\"cancelled_at\": subscription.updated_at},\n-            message=\"Subscription cancelled successfully\"\n-        )\n-        \n+            message=\"Subscription cancelled successfully\",\n+        )\n+\n     except Exception as e:\n         db.rollback()\n         return APIResponseHelper.error(\n-            message=f\"Failed to cancel subscription: {str(e)}\",\n-            status_code=500\n+            message=f\"Failed to cancel subscription: {str(e)}\", status_code=500\n         )\n \n \n @router.get(\"/usage\")\n async def get_usage_statistics(\n     restaurant_id: int = Query(..., description=\"Restaurant ID\"),\n     month_year: Optional[str] = Query(None, description=\"Month in YYYY-MM format\"),\n     db: Session = Depends(get_db),\n-    current_user=Depends(get_current_user)\n+    current_user=Depends(get_current_user),\n ):\n     \"\"\"\n     Get usage statistics for a restaurant\n-    \n+\n     Returns usage data for the specified month or current month.\n     \"\"\"\n     try:\n         # Verify user has access to this restaurant\n-        if not hasattr(current_user, 'restaurant_id') or current_user.restaurant_id is None:\n+        if (\n+            not hasattr(current_user, \"restaurant_id\")\n+            or current_user.restaurant_id is None\n+        ):\n             return APIResponseHelper.error(\n                 message=\"Access denied: User not associated with any restaurant\",\n-                status_code=403\n-            )\n-        \n+                status_code=403,\n+            )\n+\n         if current_user.restaurant_id != restaurant_id:\n             return APIResponseHelper.error(\n                 message=\"Access denied: You don't have permission to access this restaurant's usage data\",\n-                status_code=403\n+                status_code=403,\n             )\n         if not month_year:\n             month_year = SubscriptionUsage.get_current_month_key()\n-        \n-        usage = db.query(SubscriptionUsage).filter(\n-            SubscriptionUsage.restaurant_id == restaurant_id,\n-            SubscriptionUsage.month_year == month_year\n-        ).first()\n-        \n+\n+        usage = (\n+            db.query(SubscriptionUsage)\n+            .filter(\n+                SubscriptionUsage.restaurant_id == restaurant_id,\n+                SubscriptionUsage.month_year == month_year,\n+            )\n+            .first()\n+        )\n+\n         if not usage:\n             # Create usage record if it doesn't exist\n             usage = SubscriptionUsage(\n-                restaurant_id=restaurant_id,\n-                month_year=month_year\n+                restaurant_id=restaurant_id, month_year=month_year\n             )\n             db.add(usage)\n             db.commit()\n             db.refresh(usage)\n-        \n+\n         # Get subscription to include limits\n-        subscription = db.query(RestaurantSubscription).filter(\n-            RestaurantSubscription.restaurant_id == restaurant_id,\n-            RestaurantSubscription.status.in_(['active', 'trial'])\n-        ).first()\n-        \n+        subscription = (\n+            db.query(RestaurantSubscription)\n+            .filter(\n+                RestaurantSubscription.restaurant_id == restaurant_id,\n+                RestaurantSubscription.status.in_([\"active\", \"trial\"]),\n+            )\n+            .first()\n+        )\n+\n         response_data = {\n             \"usage\": usage,\n-            \"limits\": {\n-                \"orders\": subscription.plan.max_orders_per_month if subscription else None,\n-                \"staff\": subscription.plan.max_staff_accounts if subscription else None,\n-                \"menu_items\": subscription.plan.max_menu_items if subscription else None\n-            } if subscription else None,\n-            \"plan\": subscription.plan if subscription else None\n+            \"limits\": (\n+                {\n+                    \"orders\": (\n+                        subscription.plan.max_orders_per_month if subscription else None\n+                    ),\n+                    \"staff\": (\n+                        subscription.plan.max_staff_accounts if subscription else None\n+                    ),\n+                    \"menu_items\": (\n+                        subscription.plan.max_menu_items if subscription else None\n+                    ),\n+                }\n+                if subscription\n+                else None\n+            ),\n+            \"plan\": subscription.plan if subscription else None,\n         }\n-        \n-        return APIResponseHelper.success(\n-            data=response_data,\n-            message=\"Usage statistics retrieved successfully\"\n-        )\n-        \n-    except Exception as e:\n-        return APIResponseHelper.error(\n-            message=f\"Failed to retrieve usage statistics: {str(e)}\",\n-            status_code=500\n+\n+        return APIResponseHelper.success(\n+            data=response_data, message=\"Usage statistics retrieved successfully\"\n+        )\n+\n+    except Exception as e:\n+        return APIResponseHelper.error(\n+            message=f\"Failed to retrieve usage statistics: {str(e)}\", status_code=500\n         )\n \n \n @router.post(\"/usage/increment\")\n async def increment_usage(\n     restaurant_id: int = Query(..., description=\"Restaurant ID\"),\n-    usage_type: str = Query(..., description=\"Type of usage (orders, staff, menu_items)\"),\n+    usage_type: str = Query(\n+        ..., description=\"Type of usage (orders, staff, menu_items)\"\n+    ),\n     amount: int = Query(1, description=\"Amount to increment\"),\n     db: Session = Depends(get_db),\n-    current_user=Depends(get_current_user)\n+    current_user=Depends(get_current_user),\n ):\n     \"\"\"\n     Increment usage counter\n-    \n+\n     This endpoint is called internally when restaurants perform actions\n     that count towards their subscription limits.\n     \"\"\"\n     try:\n         # Verify user has access to this restaurant\n-        if not hasattr(current_user, 'restaurant_id') or current_user.restaurant_id is None:\n+        if (\n+            not hasattr(current_user, \"restaurant_id\")\n+            or current_user.restaurant_id is None\n+        ):\n             return APIResponseHelper.error(\n                 message=\"Access denied: User not associated with any restaurant\",\n-                status_code=403\n-            )\n-        \n+                status_code=403,\n+            )\n+\n         if current_user.restaurant_id != restaurant_id:\n             return APIResponseHelper.error(\n                 message=\"Access denied: You don't have permission to modify this restaurant's usage data\",\n-                status_code=403\n-            )\n-        if usage_type not in ['orders', 'staff', 'menu_items']:\n-            return APIResponseHelper.error(\n-                message=\"Invalid usage type\",\n-                status_code=400\n-            )\n-        \n+                status_code=403,\n+            )\n+        if usage_type not in [\"orders\", \"staff\", \"menu_items\"]:\n+            return APIResponseHelper.error(\n+                message=\"Invalid usage type\", status_code=400\n+            )\n+\n         current_month = SubscriptionUsage.get_current_month_key()\n-        \n+\n         # Get or create usage record\n-        usage = db.query(SubscriptionUsage).filter(\n-            SubscriptionUsage.restaurant_id == restaurant_id,\n-            SubscriptionUsage.month_year == current_month\n-        ).first()\n-        \n+        usage = (\n+            db.query(SubscriptionUsage)\n+            .filter(\n+                SubscriptionUsage.restaurant_id == restaurant_id,\n+                SubscriptionUsage.month_year == current_month,\n+            )\n+            .first()\n+        )\n+\n         if not usage:\n             usage = SubscriptionUsage(\n-                restaurant_id=restaurant_id,\n-                month_year=current_month\n+                restaurant_id=restaurant_id, month_year=current_month\n             )\n             db.add(usage)\n-        \n+\n         # Increment usage\n         usage.increment_usage(usage_type, amount)\n         usage.updated_at = datetime.utcnow()\n-        \n+\n         db.commit()\n         db.refresh(usage)\n-        \n-        return APIResponseHelper.success(\n-            data=usage,\n-            message=f\"Usage incremented: {usage_type} +{amount}\"\n-        )\n-        \n+\n+        return APIResponseHelper.success(\n+            data=usage, message=f\"Usage incremented: {usage_type} +{amount}\"\n+        )\n+\n     except Exception as e:\n         db.rollback()\n         return APIResponseHelper.error(\n-            message=f\"Failed to increment usage: {str(e)}\",\n-            status_code=500\n-        )\n\\ No newline at end of file\n+            message=f\"Failed to increment usage: {str(e)}\", status_code=500\n+        )\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/cache_warmer.py\t2025-08-02 21:56:58.993937+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/cache_warmer.py\t2025-08-02 22:36:03.191502+00:00\n@@ -18,228 +18,256 @@\n logger = logging.getLogger(__name__)\n \n \n class CacheWarmer:\n     \"\"\"Manages cache warming operations\"\"\"\n-    \n+\n     def __init__(self):\n         self.is_warming = False\n         self.last_warm_time = None\n         self.warm_interval = 3600  # 1 hour\n-        \n+\n     async def warm_all_caches(self, db: Session) -> dict:\n         \"\"\"\n         Warm all caches for active restaurants.\n-        \n+\n         Returns:\n             dict: Statistics about warmed caches\n         \"\"\"\n         if self.is_warming:\n             logger.warning(\"Cache warming already in progress, skipping\")\n             return {\"status\": \"skipped\", \"reason\": \"already_warming\"}\n-        \n+\n         self.is_warming = True\n         start_time = datetime.utcnow()\n         stats = {\n             \"started_at\": start_time,\n             \"restaurants_warmed\": 0,\n             \"menus_warmed\": 0,\n             \"categories_warmed\": 0,\n             \"settings_warmed\": 0,\n-            \"errors\": []\n+            \"errors\": [],\n         }\n-        \n+\n         try:\n             # Get all active restaurants - avoid User model to prevent relationship issues\n-            restaurants = db.query(Restaurant).filter(\n-                Restaurant.is_active == True\n-            ).all()\n-            \n-            logger.info(f\"Starting cache warming for {len(restaurants)} active restaurants\")\n-            \n+            restaurants = (\n+                db.query(Restaurant).filter(Restaurant.is_active == True).all()\n+            )\n+\n+            logger.info(\n+                f\"Starting cache warming for {len(restaurants)} active restaurants\"\n+            )\n+\n             for restaurant in restaurants:\n                 try:\n                     # Warm menu cache\n                     menu_warmed = await self._warm_menu_cache(db, restaurant)\n                     if menu_warmed:\n                         stats[\"menus_warmed\"] += 1\n-                    \n+\n                     # Warm categories cache\n-                    categories_warmed = await self._warm_categories_cache(db, restaurant)\n+                    categories_warmed = await self._warm_categories_cache(\n+                        db, restaurant\n+                    )\n                     if categories_warmed:\n                         stats[\"categories_warmed\"] += 1\n-                    \n+\n                     # Settings warming disabled - RestaurantSettings model not available\n                     # settings_warmed = await self._warm_settings_cache(db, restaurant)\n                     # if settings_warmed:\n                     #     stats[\"settings_warmed\"] += 1\n-                    \n+\n                     stats[\"restaurants_warmed\"] += 1\n-                    \n+\n                 except Exception as e:\n-                    error_msg = f\"Error warming cache for restaurant {restaurant.id}: {str(e)}\"\n+                    error_msg = (\n+                        f\"Error warming cache for restaurant {restaurant.id}: {str(e)}\"\n+                    )\n                     logger.error(error_msg)\n                     stats[\"errors\"].append(error_msg)\n-            \n+\n             # Calculate duration\n             end_time = datetime.utcnow()\n             duration = (end_time - start_time).total_seconds()\n             stats[\"completed_at\"] = end_time\n             stats[\"duration_seconds\"] = duration\n-            \n+\n             self.last_warm_time = end_time\n             logger.info(f\"Cache warming completed in {duration:.2f}s - {stats}\")\n-            \n+\n             return stats\n-            \n+\n         finally:\n             self.is_warming = False\n-    \n+\n     async def _warm_menu_cache(self, db: Session, restaurant: Restaurant) -> bool:\n         \"\"\"Warm menu cache for a restaurant\"\"\"\n         try:\n             # Get menu items\n-            menu_items = db.query(Product).filter(\n-                and_(\n-                    Product.restaurant_id == restaurant.id,\n-                    Product.is_active == True\n-                )\n-            ).all()\n-            \n+            menu_items = (\n+                db.query(Product)\n+                .filter(\n+                    and_(\n+                        Product.restaurant_id == restaurant.id,\n+                        Product.is_active == True,\n+                    )\n+                )\n+                .all()\n+            )\n+\n             # Get categories for menu items\n             categories_dict = {\n-                cat.id: cat.name \n-                for cat in db.query(Category).filter(Category.restaurant_id == restaurant.id).all()\n+                cat.id: cat.name\n+                for cat in db.query(Category)\n+                .filter(Category.restaurant_id == restaurant.id)\n+                .all()\n             }\n-            \n+\n             # Transform to match endpoint format\n             from app.api.v1.endpoints.menu import format_menu_item\n+\n             menu_data = []\n             for item in menu_items:\n-                category_name = categories_dict.get(item.category_id, 'Uncategorized')\n+                category_name = categories_dict.get(item.category_id, \"Uncategorized\")\n                 menu_data.append(format_menu_item(item, category_name))\n-            \n+\n             # Wrap in APIResponseHelper format to match endpoint\n             from app.core.responses import APIResponseHelper\n+\n             response_data = APIResponseHelper.success(\n                 data=menu_data,\n                 message=f\"Retrieved {len(menu_data)} menu items\",\n                 meta={\n                     \"restaurant_id\": str(restaurant.id),\n                     \"category_filter\": None,\n                     \"total_count\": len(menu_data),\n-                    \"execution_time_ms\": 0\n-                }\n-            )\n-            \n+                    \"execution_time_ms\": 0,\n+                },\n+            )\n+\n             # Cache with appropriate key\n-            cache_key = cache_service.cache_key(\"menu_items\", restaurant_id=str(restaurant.id), category=None)\n+            cache_key = cache_service.cache_key(\n+                \"menu_items\", restaurant_id=str(restaurant.id), category=None\n+            )\n             success = await cache_service.set(cache_key, response_data, ttl=3600)\n-            \n+\n             if success:\n-                logger.debug(f\"Warmed menu cache for restaurant {restaurant.id} with {len(menu_items)} items\")\n-            \n+                logger.debug(\n+                    f\"Warmed menu cache for restaurant {restaurant.id} with {len(menu_items)} items\"\n+                )\n+\n             return success\n-            \n+\n         except Exception as e:\n-            logger.error(f\"Failed to warm menu cache for restaurant {restaurant.id}: {e}\")\n+            logger.error(\n+                f\"Failed to warm menu cache for restaurant {restaurant.id}: {e}\"\n+            )\n             return False\n-    \n+\n     async def _warm_categories_cache(self, db: Session, restaurant: Restaurant) -> bool:\n         \"\"\"Warm categories cache for a restaurant\"\"\"\n         try:\n             # Get categories\n-            categories = db.query(Category).filter(\n-                and_(\n-                    Category.restaurant_id == restaurant.id,\n-                    Category.is_active == True\n-                )\n-            ).order_by(Category.sort_order, Category.name).all()\n-            \n+            categories = (\n+                db.query(Category)\n+                .filter(\n+                    and_(\n+                        Category.restaurant_id == restaurant.id,\n+                        Category.is_active == True,\n+                    )\n+                )\n+                .order_by(Category.sort_order, Category.name)\n+                .all()\n+            )\n+\n             # Transform to cache format\n             menu_categories = []\n             for cat in categories:\n                 try:\n                     # Try to convert UUID-style ID to integer\n-                    cat_id = int(str(cat.id).replace('-', '')[:8], 16) % 100000\n+                    cat_id = int(str(cat.id).replace(\"-\", \"\")[:8], 16) % 100000\n                 except (ValueError, TypeError):\n                     # Fallback for non-UUID IDs (like in tests)\n                     cat_id = hash(str(cat.id)) % 100000\n-                \n-                menu_categories.append({\n-                    'id': cat_id,\n-                    'name': cat.name,\n-                    'active': cat.is_active\n-                })\n-            \n+\n+                menu_categories.append(\n+                    {\"id\": cat_id, \"name\": cat.name, \"active\": cat.is_active}\n+                )\n+\n             # Always include 'All' category\n-            if not any(cat['name'] == 'All' for cat in menu_categories):\n-                menu_categories.insert(0, {'id': 1, 'name': 'All', 'active': True})\n-            \n+            if not any(cat[\"name\"] == \"All\" for cat in menu_categories):\n+                menu_categories.insert(0, {\"id\": 1, \"name\": \"All\", \"active\": True})\n+\n             # Wrap in APIResponseHelper format to match endpoint\n             from app.core.responses import APIResponseHelper\n+\n             response_data = APIResponseHelper.success(\n                 data=menu_categories,\n                 message=f\"Retrieved {len(menu_categories)} menu categories\",\n                 meta={\n                     \"restaurant_id\": str(restaurant.id),\n-                    \"total_count\": len(menu_categories)\n-                }\n-            )\n-            \n+                    \"total_count\": len(menu_categories),\n+                },\n+            )\n+\n             # Cache with appropriate key\n-            cache_key = cache_service.cache_key(\"menu_categories\", restaurant_id=str(restaurant.id))\n+            cache_key = cache_service.cache_key(\n+                \"menu_categories\", restaurant_id=str(restaurant.id)\n+            )\n             success = await cache_service.set(cache_key, response_data, ttl=3600)\n-            \n+\n             if success:\n-                logger.debug(f\"Warmed categories cache for restaurant {restaurant.id} with {len(categories)} categories\")\n-            \n+                logger.debug(\n+                    f\"Warmed categories cache for restaurant {restaurant.id} with {len(categories)} categories\"\n+                )\n+\n             return success\n-            \n+\n         except Exception as e:\n-            logger.error(f\"Failed to warm categories cache for restaurant {restaurant.id}: {e}\")\n+            logger.error(\n+                f\"Failed to warm categories cache for restaurant {restaurant.id}: {e}\"\n+            )\n             return False\n-    \n+\n     # Settings warming disabled - RestaurantSettings model not available\n     # async def _warm_settings_cache(self, db: Session, restaurant: Restaurant) -> bool:\n     #     \"\"\"Warm settings cache for a restaurant\"\"\"\n     #     pass\n-    \n+\n     async def warm_specific_restaurant(self, db: Session, restaurant_id: str) -> dict:\n         \"\"\"\n         Warm cache for a specific restaurant.\n-        \n+\n         Args:\n             db: Database session\n             restaurant_id: Restaurant ID to warm\n-            \n+\n         Returns:\n             dict: Warming statistics\n         \"\"\"\n-        restaurant = db.query(Restaurant).filter(\n-            Restaurant.id == restaurant_id\n-        ).first()\n-        \n+        restaurant = db.query(Restaurant).filter(Restaurant.id == restaurant_id).first()\n+\n         if not restaurant:\n             return {\"status\": \"error\", \"reason\": \"restaurant_not_found\"}\n-        \n+\n         stats = {\n             \"restaurant_id\": restaurant_id,\n             \"menu_warmed\": await self._warm_menu_cache(db, restaurant),\n             \"categories_warmed\": await self._warm_categories_cache(db, restaurant),\n             # Settings warming disabled - RestaurantSettings model not available\n             \"settings_warmed\": False,\n-            \"timestamp\": datetime.utcnow()\n+            \"timestamp\": datetime.utcnow(),\n         }\n-        \n+\n         return stats\n-    \n+\n     def should_warm(self) -> bool:\n         \"\"\"Check if cache should be warmed based on interval\"\"\"\n         if not self.last_warm_time:\n             return True\n-        \n+\n         elapsed = (datetime.utcnow() - self.last_warm_time).total_seconds()\n         return elapsed >= self.warm_interval\n \n \n # Global cache warmer instance\n@@ -250,25 +278,25 @@\n     \"\"\"\n     Background task to periodically warm caches.\n     Should be added to FastAPI's startup event.\n     \"\"\"\n     from app.core.database import SessionLocal\n-    \n+\n     while True:\n         try:\n             if cache_warmer.should_warm():\n                 # Use SessionLocal directly for non-dependency-injection contexts\n                 db = SessionLocal()\n                 try:\n                     stats = await cache_warmer.warm_all_caches(db)\n                     logger.info(f\"Cache warming task completed: {stats}\")\n                 finally:\n                     db.close()\n-            \n+\n             # Sleep for 5 minutes before checking again\n             await asyncio.sleep(300)\n-            \n+\n         except Exception as e:\n             logger.error(f\"Error in cache warming task: {e}\")\n             # Sleep for 1 minute on error\n             await asyncio.sleep(60)\n \n@@ -283,6 +311,6 @@\n         stats = await cache_warmer.warm_all_caches(db)\n         logger.info(f\"Initial cache warming completed: {stats}\")\n     except Exception as e:\n         logger.error(f\"Failed to warm cache on startup: {e}\")\n         # Don't fail startup if cache warming fails\n-        pass\n\\ No newline at end of file\n+        pass\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/cache_service.py\t2025-08-02 22:16:33.598250+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/cache_service.py\t2025-08-02 22:36:03.194348+00:00\n@@ -16,44 +16,46 @@\n logger = logging.getLogger(__name__)\n \n \n class CacheService:\n     \"\"\"Enhanced cache service with advanced features\"\"\"\n-    \n+\n     def __init__(self):\n         self.redis = redis_client\n         self.metrics = CacheMetrics()\n-        \n+\n     def cache_key(self, prefix: str, **kwargs) -> str:\n         \"\"\"\n         Generate a cache key from prefix and parameters.\n         Ensures consistent key generation for cache hits.\n-        \n+\n         Args:\n             prefix: Cache key prefix\n             **kwargs: Key-value pairs to include in the key\n-            \n+\n         Returns:\n             str: Generated cache key\n         \"\"\"\n         # Sort kwargs to ensure consistent key generation\n-        key_data = f\"{prefix}:\" + \":\".join(f\"{k}={v}\" for k, v in sorted(kwargs.items()))\n+        key_data = f\"{prefix}:\" + \":\".join(\n+            f\"{k}={v}\" for k, v in sorted(kwargs.items())\n+        )\n         # Use MD5 hash for long keys to avoid Redis key length limits\n         if len(key_data) > 200:\n             # Include restaurant_id in the hash key to maintain tenant isolation\n-            restaurant_id = kwargs.get('restaurant_id', 'global')\n+            restaurant_id = kwargs.get(\"restaurant_id\", \"global\")\n             key_hash = hashlib.md5(key_data.encode()).hexdigest()\n             return f\"{prefix}:restaurant_id={restaurant_id}:hash:{key_hash}\"\n         return key_data\n-    \n+\n     async def get(self, key: str) -> Optional[Any]:\n         \"\"\"\n         Get value from cache.\n-        \n+\n         Args:\n             key: Cache key\n-            \n+\n         Returns:\n             Cached value or None if not found/expired\n         \"\"\"\n         try:\n             value = await self.redis.get(key)\n@@ -66,20 +68,20 @@\n             return value\n         except Exception as e:\n             self.metrics.record_error()\n             logger.error(f\"Cache get error for key {key}: {e}\")\n             return None\n-    \n+\n     async def set(self, key: str, value: Any, ttl: int = 3600) -> bool:\n         \"\"\"\n         Set value in cache with TTL.\n-        \n+\n         Args:\n             key: Cache key\n             value: Value to cache\n             ttl: Time-to-live in seconds (default: 1 hour)\n-            \n+\n         Returns:\n             bool: True if successful, False otherwise\n         \"\"\"\n         try:\n             success = await self.redis.set(key, value, expire=ttl)\n@@ -88,18 +90,18 @@\n             return success\n         except Exception as e:\n             self.metrics.record_error()\n             logger.error(f\"Cache set error for key {key}: {e}\")\n             return False\n-    \n+\n     async def delete(self, key: str) -> bool:\n         \"\"\"\n         Delete a specific cache key.\n-        \n+\n         Args:\n             key: Cache key to delete\n-            \n+\n         Returns:\n             bool: True if successful, False otherwise\n         \"\"\"\n         try:\n             success = await self.redis.delete(key)\n@@ -108,18 +110,18 @@\n             return success\n         except Exception as e:\n             self.metrics.record_error()\n             logger.error(f\"Cache delete error for key {key}: {e}\")\n             return False\n-    \n+\n     async def delete_pattern(self, pattern: str) -> int:\n         \"\"\"\n         Delete all keys matching a pattern.\n-        \n+\n         Args:\n             pattern: Pattern to match (e.g., \"menu:restaurant_id=*\")\n-            \n+\n         Returns:\n             int: Number of keys deleted\n         \"\"\"\n         try:\n             count = await self.redis.delete_pattern(pattern)\n@@ -127,18 +129,18 @@\n             return count\n         except Exception as e:\n             self.metrics.record_error()\n             logger.error(f\"Cache delete pattern error for {pattern}: {e}\")\n             return 0\n-    \n+\n     async def invalidate_restaurant_cache(self, restaurant_id: str) -> int:\n         \"\"\"\n         Invalidate all cache entries for a restaurant.\n-        \n+\n         Args:\n             restaurant_id: Restaurant ID\n-            \n+\n         Returns:\n             int: Number of keys deleted\n         \"\"\"\n         # Patterns must handle alphabetically sorted parameters and new hash format\n         patterns = [\n@@ -150,82 +152,84 @@\n             f\"settings:*restaurant_id={restaurant_id}*\",\n             f\"analytics:*restaurant_id={restaurant_id}*\",\n             # Hash-based keys with restaurant_id preserved\n             f\"*:restaurant_id={restaurant_id}:hash:*\",\n         ]\n-        \n+\n         total_deleted = 0\n         for pattern in patterns:\n             deleted = await self.delete_pattern(pattern)\n             total_deleted += deleted\n-        \n-        logger.info(f\"Invalidated {total_deleted} cache entries for restaurant {restaurant_id}\")\n+\n+        logger.info(\n+            f\"Invalidated {total_deleted} cache entries for restaurant {restaurant_id}\"\n+        )\n         return total_deleted\n-    \n+\n     async def invalidate_user_cache(self, user_id: str) -> int:\n         \"\"\"\n         Invalidate all cache entries for a user.\n-        \n+\n         Args:\n             user_id: User ID\n-            \n+\n         Returns:\n             int: Number of keys deleted\n         \"\"\"\n         patterns = [\n             f\"user:user_id={user_id}*\",\n             f\"session:*{user_id}*\",\n             f\"permissions:user_id={user_id}*\",\n         ]\n-        \n+\n         total_deleted = 0\n         for pattern in patterns:\n             deleted = await self.delete_pattern(pattern)\n             total_deleted += deleted\n-        \n+\n         logger.info(f\"Invalidated {total_deleted} cache entries for user {user_id}\")\n         return total_deleted\n-    \n+\n     def get_metrics(self) -> Dict[str, Any]:\n         \"\"\"Get cache performance metrics\"\"\"\n         return self.metrics.get_metrics()\n \n \n class CacheMetrics:\n     \"\"\"Track cache performance metrics\"\"\"\n-    \n+\n     def __init__(self):\n         self.hits = 0\n         self.misses = 0\n         self.errors = 0\n-    \n+\n     @property\n     def hit_rate(self) -> float:\n         \"\"\"Calculate cache hit rate percentage\"\"\"\n         total = self.hits + self.misses\n         return (self.hits / total * 100) if total > 0 else 0.0\n-    \n+\n     def record_hit(self):\n         \"\"\"Record a cache hit\"\"\"\n         self.hits += 1\n-    \n+\n     def record_miss(self):\n         \"\"\"Record a cache miss\"\"\"\n         self.misses += 1\n-    \n+\n     def record_error(self):\n         \"\"\"Record a cache error\"\"\"\n         self.errors += 1\n-    \n+\n     def get_metrics(self) -> Dict[str, Any]:\n         \"\"\"Get all metrics\"\"\"\n         return {\n             \"hits\": self.hits,\n             \"misses\": self.misses,\n             \"errors\": self.errors,\n             \"hit_rate\": f\"{self.hit_rate:.2f}%\",\n-            \"total_requests\": self.hits + self.misses\n+            \"total_requests\": self.hits + self.misses,\n         }\n \n \n # Global cache service instance\n cache_service = CacheService()\n@@ -233,118 +237,127 @@\n \n def cached(\n     ttl: int = 3600,\n     prefix: Optional[str] = None,\n     key_params: Optional[List[str]] = None,\n-    invalidate_on: Optional[List[str]] = None\n+    invalidate_on: Optional[List[str]] = None,\n ):\n     \"\"\"\n     Decorator for caching function results.\n-    \n+\n     Args:\n         ttl: Time-to-live in seconds (default: 1 hour)\n         prefix: Cache key prefix (default: function name)\n         key_params: List of parameter names to include in cache key\n         invalidate_on: List of parameter names that trigger cache invalidation\n-    \n+\n     Example:\n         @cached(ttl=3600, prefix=\"menu\", key_params=[\"restaurant_id\"])\n         async def get_menu(restaurant_id: str, db: Session):\n             return db.query(MenuItem).filter(...).all()\n     \"\"\"\n+\n     def decorator(func):\n         @wraps(func)\n         async def wrapper(*args, **kwargs):\n             # Get function signature to map args to parameter names\n             sig = inspect.signature(func)\n             bound_args = sig.bind(*args, **kwargs)\n             bound_args.apply_defaults()\n-            \n+\n             # Generate cache key prefix\n             cache_prefix = prefix or f\"{func.__module__}.{func.__name__}\"\n-            \n+\n             # Build cache key parameters\n             cache_params = {}\n             if key_params:\n                 for param in key_params:\n                     if param in bound_args.arguments:\n                         value = bound_args.arguments[param]\n                         # Convert complex objects to string representation\n-                        if hasattr(value, '__dict__'):\n+                        if hasattr(value, \"__dict__\"):\n                             value = str(value)\n                         cache_params[param] = value\n             else:\n                 # Use all non-database parameters by default\n                 for param, value in bound_args.arguments.items():\n                     # Skip common non-cacheable parameters\n-                    if param not in ['db', 'session', 'request', 'response', 'background_tasks']:\n-                        if hasattr(value, '__dict__'):\n+                    if param not in [\n+                        \"db\",\n+                        \"session\",\n+                        \"request\",\n+                        \"response\",\n+                        \"background_tasks\",\n+                    ]:\n+                        if hasattr(value, \"__dict__\"):\n                             value = str(value)\n                         cache_params[param] = value\n-            \n+\n             # Generate cache key\n             cache_key = cache_service.cache_key(cache_prefix, **cache_params)\n-            \n+\n             # Check if we need to invalidate cache\n             if invalidate_on:\n                 for param in invalidate_on:\n                     if param in bound_args.arguments and bound_args.arguments[param]:\n                         await cache_service.delete_pattern(f\"{cache_prefix}*\")\n                         logger.debug(f\"Cache invalidated for prefix: {cache_prefix}\")\n                         break\n-            \n+\n             # Try to get from cache\n             cached_value = await cache_service.get(cache_key)\n             if cached_value is not None:\n                 return cached_value\n-            \n+\n             # Execute function and cache result\n             result = await func(*args, **kwargs)\n-            \n+\n             # Cache the result\n             await cache_service.set(cache_key, result, ttl)\n-            \n+\n             return result\n-        \n+\n         # Add cache management methods to the wrapper\n         wrapper.invalidate_cache = lambda **params: cache_service.delete_pattern(\n             f\"{prefix or f'{func.__module__}.{func.__name__}'}*\"\n         )\n-        \n+\n         return wrapper\n+\n     return decorator\n \n \n # Cache warming utilities\n async def warm_menu_cache(db):\n     \"\"\"\n     Pre-populate cache with active restaurant menus.\n     Should be called on startup and periodically.\n     \"\"\"\n     from app.models import Restaurant, Product\n-    \n+\n     try:\n         # Get all active restaurants\n-        restaurants = db.query(Restaurant).filter(\n-            Restaurant.is_active == True\n-        ).all()\n-        \n+        restaurants = db.query(Restaurant).filter(Restaurant.is_active == True).all()\n+\n         warmed_count = 0\n         for restaurant in restaurants:\n             # Generate cache key - using menu_items prefix to match endpoints\n             cache_key = cache_service.cache_key(\n                 \"menu_items\",\n                 restaurant_id=str(restaurant.id),\n-                category=None  # Match the key params used by the endpoint\n+                category=None,  # Match the key params used by the endpoint\n             )\n-            \n+\n             # Get menu data\n-            menu_items = db.query(Product).filter(\n-                Product.restaurant_id == restaurant.id,\n-                Product.is_active == True\n-            ).all()\n-            \n+            menu_items = (\n+                db.query(Product)\n+                .filter(\n+                    Product.restaurant_id == restaurant.id, Product.is_active == True\n+                )\n+                .all()\n+            )\n+\n             # Convert to dict for caching\n             menu_data = [\n                 {\n                     \"id\": str(item.id),\n                     \"name\": item.name,\n@@ -354,19 +367,19 @@\n                     \"image_url\": item.image_url,\n                     \"is_active\": item.is_active,\n                 }\n                 for item in menu_items\n             ]\n-            \n+\n             # Cache it\n             if await cache_service.set(cache_key, menu_data, ttl=3600):\n                 warmed_count += 1\n-        \n+\n         logger.info(f\"Warmed cache for {warmed_count}/{len(restaurants)} restaurants\")\n         return warmed_count\n     except Exception as e:\n         logger.error(f\"Error warming menu cache: {e}\")\n         return 0\n \n \n # Note: warm_settings_cache removed as RestaurantSettings model doesn't exist\n-# Settings appear to be managed through PlatformConfiguration instead\n\\ No newline at end of file\n+# Settings appear to be managed through PlatformConfiguration instead\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/config.py\t2025-08-02 21:56:58.994097+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/config.py\t2025-08-02 22:36:03.202812+00:00\n@@ -18,73 +18,81 @@\n     # Fallback to default .env if environment-specific one is not found\n     # This is useful for local setups that might still use a single .env\n     # or if APP_ENV is not set and .env.development is missing.\n     load_dotenv(dotenv_path=\".env\")\n \n+\n class Settings(BaseSettings):\n     \"\"\"Application settings\"\"\"\n-    \n+\n     # Application\n     APP_NAME: str = \"Fynlo POS\"\n     DEBUG: bool = True\n     ENVIRONMENT: str = \"development\"  # This will be overridden by .env file\n     API_V1_STR: str = \"/api/v1\"\n-    BASE_URL: str = \"https://fynlopos-9eg2c.ondigitalocean.app\"  # Production URL, override in dev\n-    \n+    BASE_URL: str = (\n+        \"https://fynlopos-9eg2c.ondigitalocean.app\"  # Production URL, override in dev\n+    )\n+\n     # Database - Must be set via environment variable in production\n-    DATABASE_URL: str = os.getenv(\"DATABASE_URL\", \"postgresql://fynlo_user:fynlo_password@localhost:5432/fynlo_pos\")\n-    \n+    DATABASE_URL: str = os.getenv(\n+        \"DATABASE_URL\",\n+        \"postgresql://fynlo_user:fynlo_password@localhost:5432/fynlo_pos\",\n+    )\n+\n     # Redis - Must be set via environment variable in production\n     REDIS_URL: str = os.getenv(\"REDIS_URL\", \"redis://localhost:6379/0\")\n-    \n+\n     # Security\n     SECRET_KEY: str = \"your-super-secret-key-change-in-production\"\n     ALGORITHM: str = \"HS256\"\n     ACCESS_TOKEN_EXPIRE_MINUTES: int = 30\n     CORS_ORIGINS: Optional[str] = None  # Will be parsed as list in validator\n-    \n+\n     # Supabase Authentication\n     SUPABASE_URL: Optional[str] = None\n     SUPABASE_ANON_KEY: Optional[str] = None\n     SUPABASE_SERVICE_ROLE_KEY: Optional[str] = None\n     # Platform owner emails - comma-separated list from environment\n-    PLATFORM_OWNER_EMAILS: Optional[str] = None  # e.g., \"ryan@fynlo.co.uk,arnaud@fynlo.co.uk\"\n+    PLATFORM_OWNER_EMAILS: Optional[str] = (\n+        None  # e.g., \"ryan@fynlo.co.uk,arnaud@fynlo.co.uk\"\n+    )\n     # Platform owner verification - requires both email AND secret key\n     PLATFORM_OWNER_SECRET_KEY: Optional[str] = None  # Set via environment variable\n     PLATFORM_OWNER_REQUIRE_2FA: bool = True  # Require 2FA for platform owners\n-    \n+\n     # Payment Processing\n     STRIPE_SECRET_KEY: Optional[str] = None\n     STRIPE_PUBLISHABLE_KEY: Optional[str] = None\n     STRIPE_WEBHOOK_SECRET: Optional[str] = None\n \n     # Square Configuration\n     SQUARE_APPLICATION_ID: Optional[str] = None\n     SQUARE_ACCESS_TOKEN: Optional[str] = None\n     SQUARE_LOCATION_ID: Optional[str] = None\n     SQUARE_WEBHOOK_SIGNATURE_KEY: Optional[str] = None\n-    SQUARE_ENVIRONMENT: str = \"sandbox\" # \"sandbox\" or \"production\"\n-    \n+    SQUARE_ENVIRONMENT: str = \"sandbox\"  # \"sandbox\" or \"production\"\n+\n     # SumUp Integration (PHASE 3: Added for real payment processing)\n     SUMUP_API_KEY: Optional[str] = None\n-    SUMUP_MERCHANT_CODE: Optional[str] = None  \n+    SUMUP_MERCHANT_CODE: Optional[str] = None\n     SUMUP_AFFILIATE_KEY: Optional[str] = None\n     SUMUP_ENVIRONMENT: str = \"sandbox\"  # sandbox | production\n-    \n+\n     # QR Payment Settings\n     QR_PAYMENT_FEE_PERCENTAGE: float = 1.2  # Your competitive advantage\n     DEFAULT_CARD_FEE_PERCENTAGE: float = 2.9\n-    \n+\n     # WebSocket\n     WEBSOCKET_HOST: str = \"localhost\"\n     WEBSOCKET_PORT: int = 8001\n-    \n+\n     # File Upload\n     MAX_FILE_SIZE: int = 10 * 1024 * 1024  # 10MB\n     UPLOAD_DIR: str = \"uploads\"\n     ALLOWED_FILE_TYPES: str = \"jpg,jpeg,png,gif,pdf,docx,xlsx\"\n-    \n+\n     # DigitalOcean Spaces Configuration\n     SPACES_ACCESS_KEY_ID: Optional[str] = None\n     SPACES_SECRET_ACCESS_KEY: Optional[str] = None\n     SPACES_BUCKET: str = \"fynlo-pos-storage\"\n     SPACES_REGION: str = \"lon1\"\n@@ -103,95 +111,101 @@\n     DESIRED_REPLICAS: int = 2  # Desired number of backend replicas\n \n     # Logging and Error Handling\n     LOG_LEVEL: str = \"DEBUG\"\n     ERROR_DETAIL_ENABLED: bool = True\n-    \n+\n     # CORS\n     PRODUCTION_ALLOWED_ORIGINS: list[str] = [\n         \"https://app.fynlo.co.uk\",  # Main production domain (platform dashboard)\n         \"https://fynlo.co.uk\",  # Main website\n         \"https://api.fynlo.co.uk\",  # API domain (for Swagger UI)\n         \"https://fynlo.vercel.app\",  # Vercel production deployment\n         \"http://localhost:3000\",  # Local development\n         \"http://localhost:8080\",  # Vite development server\n         \"http://localhost:8081\",  # Alternative local port\n     ]\n-    \n+\n     # Note: For Vercel preview deployments, we use regex pattern in CORSMiddleware\n     # to dynamically handle preview URLs like https://fynlo-pr-123.vercel.app\n-    \n-    @field_validator('DEBUG', 'ERROR_DETAIL_ENABLED', mode='before')\n+\n+    @field_validator(\"DEBUG\", \"ERROR_DETAIL_ENABLED\", mode=\"before\")\n     @classmethod\n     def parse_boolean(cls, v: Any) -> bool:\n         \"\"\"Parse boolean values from environment variables that might be strings\"\"\"\n         if isinstance(v, bool):\n             return v\n         if isinstance(v, str):\n             # Remove quotes if present and normalize\n             v = v.strip().strip('\"').strip(\"'\").lower()\n-            if v in ('true', '1', 'yes', 'on'):\n+            if v in (\"true\", \"1\", \"yes\", \"on\"):\n                 return True\n-            elif v in ('false', '0', 'no', 'off', ''):\n+            elif v in (\"false\", \"0\", \"no\", \"off\", \"\"):\n                 return False\n             else:\n                 raise ValueError(f\"Invalid boolean value: {v}\")\n         return bool(v)\n-    \n-    @field_validator('CORS_ORIGINS', mode='before')\n+\n+    @field_validator(\"CORS_ORIGINS\", mode=\"before\")\n     @classmethod\n     def parse_cors_origins(cls, v: Any) -> Optional[str]:\n         \"\"\"Just return the string value, parsing will happen in __init__\"\"\"\n         return v\n-    \n+\n     @property\n     def cors_origins_list(self) -> List[str]:\n         \"\"\"Get CORS origins as a list\"\"\"\n         if not self.CORS_ORIGINS:\n             return []\n-        \n+\n         if isinstance(self.CORS_ORIGINS, list):\n             return self.CORS_ORIGINS\n-            \n+\n         # Parse string value\n         v = self.CORS_ORIGINS\n-        \n+\n         # Try to parse as JSON first\n         try:\n             import json\n+\n             parsed = json.loads(v)\n             if isinstance(parsed, list):\n                 return [str(item) for item in parsed if item]\n         except Exception as e:\n             pass\n-        \n+\n         # Fall back to comma-separated\n-        if ',' in v:\n-            return [origin.strip() for origin in v.split(',') if origin.strip()]\n-        \n+        if \",\" in v:\n+            return [origin.strip() for origin in v.split(\",\") if origin.strip()]\n+\n         # Single value\n         return [v.strip()] if v.strip() else []\n-    \n+\n     @property\n     def platform_owner_emails_list(self) -> List[str]:\n         \"\"\"Get platform owner emails as a list\"\"\"\n         if not self.PLATFORM_OWNER_EMAILS:\n             return []\n-        \n+\n         # Parse comma-separated emails\n-        emails = [email.strip().lower() for email in self.PLATFORM_OWNER_EMAILS.split(',') if email.strip()]\n+        emails = [\n+            email.strip().lower()\n+            for email in self.PLATFORM_OWNER_EMAILS.split(\",\")\n+            if email.strip()\n+        ]\n         return emails\n-    \n+\n     class Config:\n         case_sensitive = True\n         # env_file is now handled by load_dotenv above to allow dynamic selection\n         # We still define it here so pydantic-settings knows about it,\n         # but the actual loading is conditional.\n         # If APP_ENV specific file isn't found, it can fallback to .env\n         # or use defaults if .env is also missing.\n         env_file = os.getenv(\"ENV_FILE_PATH\", f\".env.{APP_ENV}\")\n         extra = \"ignore\"  # Allow extra environment variables\n+\n \n # Initialize settings after potentially loading from a specific .env file\n settings = Settings()\n \n # If .env.{APP_ENV} was not found and .env was used,\n@@ -208,22 +222,23 @@\n \n     # Check if the specific env file exists before trying to load it again\n     # This prevents an error if neither .env.APP_ENV nor .env exist but APP_ENV is set\n     _specific_env_file = f\".env.{APP_ENV}\"\n     if os.path.exists(_specific_env_file):\n-      settings = Settings(_env_file=_specific_env_file)\n-    elif os.path.exists(\".env\"): # Fallback to .env if specific one not found\n-      settings = Settings(_env_file=\".env\")\n-    else: # If no .env files found, pydantic uses defaults or raises error for missing required fields\n-      settings = Settings()\n+        settings = Settings(_env_file=_specific_env_file)\n+    elif os.path.exists(\".env\"):  # Fallback to .env if specific one not found\n+        settings = Settings(_env_file=\".env\")\n+    else:  # If no .env files found, pydantic uses defaults or raises error for missing required fields\n+        settings = Settings()\n \n     # Explicitly set ENVIRONMENT to match APP_ENV if it's still different\n     # This ensures the application code can reliably use settings.ENVIRONMENT\n     if settings.ENVIRONMENT != APP_ENV:\n         settings.ENVIRONMENT = APP_ENV\n \n # No need to parse CORS_ORIGINS here anymore, use settings.cors_origins_list property instead\n+\n \n # --- Configuration Validation ---\n def validate_production_settings(s: Settings):\n     \"\"\"\n     Validates critical settings when ENVIRONMENT is 'production'.\n@@ -250,32 +265,48 @@\n \n         # Check SECRET_KEY: must not be the default/example key\n         default_keys = [\n             \"your-super-secret-key-change-in-production\",\n             \"your-super-secret-key-for-development-only\",\n-            \"your-super-secret-key-change-in-production-use-long-random-string\" # from .env.example\n+            \"your-super-secret-key-change-in-production-use-long-random-string\",  # from .env.example\n         ]\n         if s.SECRET_KEY in default_keys:\n             errors.append(\"A strong, unique SECRET_KEY must be set for production.\")\n-        if len(s.SECRET_KEY) < 32: # Arbitrary length check for a reasonably strong key\n-             errors.append(\"SECRET_KEY appears too short. Ensure it is a long, random string.\")\n+        if len(s.SECRET_KEY) < 32:  # Arbitrary length check for a reasonably strong key\n+            errors.append(\n+                \"SECRET_KEY appears too short. Ensure it is a long, random string.\"\n+            )\n \n         if s.LOG_LEVEL.upper() == \"DEBUG\":\n-            errors.append(\"LOG_LEVEL should not be 'DEBUG' in production. Consider 'INFO' or 'WARNING'.\")\n+            errors.append(\n+                \"LOG_LEVEL should not be 'DEBUG' in production. Consider 'INFO' or 'WARNING'.\"\n+            )\n \n         # Payment provider checks (ensure live keys are not placeholders if provider is configured)\n-        if s.STRIPE_SECRET_KEY and (\"yourtestkey\" in s.STRIPE_SECRET_KEY or \"sk_test_\" in s.STRIPE_SECRET_KEY):\n-            errors.append(\"Stripe secret key appears to be a test key. Use live keys in production.\")\n-        if s.SUMUP_API_KEY and (\"sumup_test_apikey\" in s.SUMUP_API_KEY or s.SUMUP_ENVIRONMENT != \"production\"):\n-             errors.append(\"SumUp API key appears to be a test key or environment is not 'production'. Use live settings in production.\")\n+        if s.STRIPE_SECRET_KEY and (\n+            \"yourtestkey\" in s.STRIPE_SECRET_KEY or \"sk_test_\" in s.STRIPE_SECRET_KEY\n+        ):\n+            errors.append(\n+                \"Stripe secret key appears to be a test key. Use live keys in production.\"\n+            )\n+        if s.SUMUP_API_KEY and (\n+            \"sumup_test_apikey\" in s.SUMUP_API_KEY\n+            or s.SUMUP_ENVIRONMENT != \"production\"\n+        ):\n+            errors.append(\n+                \"SumUp API key appears to be a test key or environment is not 'production'. Use live settings in production.\"\n+            )\n \n         if errors:\n-            error_message = \"CRITICAL CONFIGURATION ERRORS IN PRODUCTION ENV:\\n\" + \"\\n\".join(\n-                f\"- {err}\" for err in errors\n+            error_message = (\n+                \"CRITICAL CONFIGURATION ERRORS IN PRODUCTION ENV:\\n\"\n+                + \"\\n\".join(f\"- {err}\" for err in errors)\n             )\n             # In a real scenario, you might want to log this with high priority as well.\n             # For now, raising an exception is the primary goal to prevent startup.\n-            raise ValueError(f\"Application startup aborted due to insecure production configuration: {'; '.join(errors)}\")\n+            raise ValueError(\n+                f\"Application startup aborted due to insecure production configuration: {'; '.join(errors)}\"\n+            )\n+\n \n # Perform validation after settings are fully initialized\n validate_production_settings(settings)\n-\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/dependencies.py\t2025-08-02 22:06:30.408618+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/dependencies.py\t2025-08-02 22:36:03.203430+00:00\n@@ -4,11 +4,15 @@\n \"\"\"\n \n from typing import Optional, Any\n from fastapi import Depends, Query\n from sqlalchemy.orm import Session\n-from app.core.exceptions import AuthenticationException, ResourceNotFoundException, FynloException\n+from app.core.exceptions import (\n+    AuthenticationException,\n+    ResourceNotFoundException,\n+    FynloException,\n+)\n \n from app.core.database import get_db\n from app.core.auth import get_current_user\n from app.core.tenant_security import TenantSecurity\n from app.core.rls_context import RLSContext\n@@ -16,183 +20,184 @@\n \n \n async def get_current_user_with_tenant_validation(\n     restaurant_id: Optional[str] = Query(None, description=\"Restaurant ID to access\"),\n     current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ) -> User:\n     \"\"\"\n     Dependency that validates tenant access based on restaurant_id parameter\n-    \n+\n     Usage:\n         @router.get(\"/endpoint\")\n         async def endpoint(\n             current_user: User = Depends(get_current_user_with_tenant_validation)\n         ):\n             # User is guaranteed to have access to the requested restaurant\n     \"\"\"\n     if restaurant_id:\n         # Validate access to specified restaurant\n         await TenantSecurity.validate_restaurant_access(\n-            user=current_user,\n-            restaurant_id=restaurant_id,\n-            operation=\"access\",\n-            db=db\n-        )\n-    elif not TenantSecurity.is_platform_owner(current_user) and not current_user.restaurant_id:\n+            user=current_user, restaurant_id=restaurant_id, operation=\"access\", db=db\n+        )\n+    elif (\n+        not TenantSecurity.is_platform_owner(current_user)\n+        and not current_user.restaurant_id\n+    ):\n         # Non-platform owners must have a restaurant\n-        raise AuthenticationException(message=\"Authentication failed\", error_code=\"ACCESS_DENIED\")\n-    \n+        raise AuthenticationException(\n+            message=\"Authentication failed\", error_code=\"ACCESS_DENIED\"\n+        )\n+\n     # Set RLS context for the database session\n     RLSContext.get_db_with_context(db, current_user)\n-    \n+\n     return current_user\n \n \n async def validate_resource_access(\n     resource_model: Any,\n     resource_id: str,\n     current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ) -> Any:\n     \"\"\"\n     Generic dependency to validate access to any resource\n-    \n+\n     Usage:\n         @router.put(\"/products/{product_id}\")\n         async def update_product(\n             product: Product = Depends(\n                 lambda product_id: validate_resource_access(Product, product_id)\n             )\n         ):\n             # Product is guaranteed to belong to user's restaurant\n     \"\"\"\n     # Query the resource\n-    resource = db.query(resource_model).filter(\n-        resource_model.id == resource_id\n-    ).first()\n-    \n+    resource = db.query(resource_model).filter(resource_model.id == resource_id).first()\n+\n     if not resource:\n-        raise ResourceNotFoundException(resource=resource_model.__name__, resource_id=resource_id)\n-        \n-    \n+        raise ResourceNotFoundException(\n+            resource=resource_model.__name__, resource_id=resource_id\n+        )\n+\n     # Validate restaurant access if resource has restaurant_id\n-    if hasattr(resource, 'restaurant_id'):\n+    if hasattr(resource, \"restaurant_id\"):\n         await TenantSecurity.validate_restaurant_access(\n             user=current_user,\n             restaurant_id=str(resource.restaurant_id),\n             operation=\"access\",\n-            db=db\n-        )\n-    \n+            db=db,\n+        )\n+\n     return resource\n \n \n class TenantFilter:\n     \"\"\"\n     Dependency class for automatic tenant filtering\n-    \n+\n     Usage:\n         @router.get(\"/orders\")\n         async def get_orders(\n             filters: dict = Depends(TenantFilter())\n         ):\n             # filters will include restaurant_id based on user access\n     \"\"\"\n-    \n+\n     def __init__(self, allow_restaurant_override: bool = False):\n         self.allow_restaurant_override = allow_restaurant_override\n-    \n+\n     async def __call__(\n         self,\n         restaurant_id: Optional[str] = Query(None),\n-        current_user: User = Depends(get_current_user)\n+        current_user: User = Depends(get_current_user),\n     ) -> dict:\n         \"\"\"\n         Returns filter dictionary with proper restaurant_id\n         \"\"\"\n         filters = {}\n-        \n+\n         if TenantSecurity.is_platform_owner(current_user):\n             # Platform owners can specify any restaurant or see all\n             if restaurant_id:\n                 filters[\"restaurant_id\"] = restaurant_id\n             # If no restaurant specified, no filter (see all)\n         else:\n             # Regular users can only see their restaurant\n             if restaurant_id and str(restaurant_id) != str(current_user.restaurant_id):\n-                raise AuthenticationException(message=\"Authentication failed\", error_code=\"ACCESS_DENIED\")\n+                raise AuthenticationException(\n+                    message=\"Authentication failed\", error_code=\"ACCESS_DENIED\"\n+                )\n             filters[\"restaurant_id\"] = str(current_user.restaurant_id)\n-        \n+\n         return filters\n \n \n class SecureQuery:\n     \"\"\"\n     Dependency that returns a pre-filtered query based on tenant access\n-    \n+\n     Usage:\n         @router.get(\"/products\")\n         async def get_products(\n             query = Depends(SecureQuery(Product))\n         ):\n             # query is already filtered by restaurant_id\n     \"\"\"\n-    \n+\n     def __init__(self, model_class: Any):\n         self.model_class = model_class\n-    \n+\n     async def __call__(\n         self,\n         db: Session = Depends(get_db),\n-        current_user: User = Depends(get_current_user)\n+        current_user: User = Depends(get_current_user),\n     ):\n         \"\"\"\n         Returns a query filtered by tenant access\n         \"\"\"\n         query = db.query(self.model_class)\n-        \n+\n         # Apply tenant filtering\n         query = TenantSecurity.apply_tenant_filter(\n-            query=query,\n-            user=current_user,\n-            model_class=self.model_class,\n-            db=db\n-        )\n-        \n+            query=query, user=current_user, model_class=self.model_class, db=db\n+        )\n+\n         return query\n \n \n async def platform_owner_required(\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ) -> User:\n     \"\"\"\n     Dependency that ensures only platform owners (Ryan & Arnaud) can access\n-    \n+\n     Usage:\n         @router.post(\"/platform/settings\")\n         async def update_platform_settings(\n             current_user: User = Depends(platform_owner_required)\n         ):\n             # Only Ryan and Arnaud can access this\n     \"\"\"\n     if not TenantSecurity.is_platform_owner(current_user):\n-        raise AuthenticationException(message=\"Authentication failed\", error_code=\"ACCESS_DENIED\")\n-    \n+        raise AuthenticationException(\n+            message=\"Authentication failed\", error_code=\"ACCESS_DENIED\"\n+        )\n+\n     return current_user\n \n \n async def get_db_with_rls(\n-    db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    db: Session = Depends(get_db), current_user: User = Depends(get_current_user)\n ) -> Session:\n     \"\"\"\n     Get database session with RLS context already set\n-    \n+\n     Usage:\n         @router.get(\"/orders\")\n         async def get_orders(\n             db: Session = Depends(get_db_with_rls)\n         ):\n             # All queries will be automatically filtered by RLS\n     \"\"\"\n-    return RLSContext.get_db_with_context(db, current_user)\n\\ No newline at end of file\n+    return RLSContext.get_db_with_context(db, current_user)\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/feature_gate.py\t2025-08-02 22:04:10.953432+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/feature_gate.py\t2025-08-02 22:36:03.216677+00:00\n@@ -4,75 +4,88 @@\n from app.core.database import get_db, Restaurant, User\n from app.core.exceptions import AuthenticationException\n \n FEATURE_KEYS = {\n     # Basic POS Features (Alpha - all plans)\n-    'pos_basic': 'Basic POS functionality',\n-    'order_management': 'Order management',\n-    'basic_payments': 'Cash and card payments',\n-    'daily_reports': 'Daily sales reports',\n-    \n+    \"pos_basic\": \"Basic POS functionality\",\n+    \"order_management\": \"Order management\",\n+    \"basic_payments\": \"Cash and card payments\",\n+    \"daily_reports\": \"Daily sales reports\",\n     # Advanced Features (Beta and above)\n-    'inventory_management': 'Inventory tracking',\n-    'staff_management': 'Staff accounts and permissions',\n-    'advanced_reports': 'Advanced analytics and reports',\n-    'table_management': 'Table and section management',\n-    'customer_database': 'Customer management',\n-    \n+    \"inventory_management\": \"Inventory tracking\",\n+    \"staff_management\": \"Staff accounts and permissions\",\n+    \"advanced_reports\": \"Advanced analytics and reports\",\n+    \"table_management\": \"Table and section management\",\n+    \"customer_database\": \"Customer management\",\n     # Premium Features (Omega only)\n-    'multi_location': 'Multiple restaurant locations',\n-    'api_access': 'API access for integrations',\n-    'custom_branding': 'Custom branding options',\n-    'priority_support': 'Priority customer support',\n-    'advanced_analytics': 'Advanced business intelligence',\n-    'unlimited_staff': 'Unlimited staff accounts',\n+    \"multi_location\": \"Multiple restaurant locations\",\n+    \"api_access\": \"API access for integrations\",\n+    \"custom_branding\": \"Custom branding options\",\n+    \"priority_support\": \"Priority customer support\",\n+    \"advanced_analytics\": \"Advanced business intelligence\",\n+    \"unlimited_staff\": \"Unlimited staff accounts\",\n }\n+\n \n def get_plan_features(plan: str) -> list[str]:\n     \"\"\"Get list of features available for a subscription plan\"\"\"\n     plan_features = {\n-        'alpha': ['pos_basic', 'order_management', 'basic_payments', 'daily_reports'],\n-        'beta': ['pos_basic', 'order_management', 'basic_payments', 'daily_reports',\n-                'inventory_management', 'staff_management', 'advanced_reports',\n-                'table_management', 'customer_database'],\n-        'omega': list(FEATURE_KEYS.keys())  # All features\n+        \"alpha\": [\"pos_basic\", \"order_management\", \"basic_payments\", \"daily_reports\"],\n+        \"beta\": [\n+            \"pos_basic\",\n+            \"order_management\",\n+            \"basic_payments\",\n+            \"daily_reports\",\n+            \"inventory_management\",\n+            \"staff_management\",\n+            \"advanced_reports\",\n+            \"table_management\",\n+            \"customer_database\",\n+        ],\n+        \"omega\": list(FEATURE_KEYS.keys()),  # All features\n     }\n-    return plan_features.get(plan, plan_features['alpha'])\n+    return plan_features.get(plan, plan_features[\"alpha\"])\n+\n \n def check_feature_access(restaurant_id: str, feature_key: str, db: Session) -> bool:\n     \"\"\"Check if a restaurant has access to a specific feature\"\"\"\n     restaurant = db.query(Restaurant).filter(Restaurant.id == restaurant_id).first()\n     if not restaurant:\n         return False\n-    \n+\n     # Get plan with fallback to alpha\n-    subscription_plan = getattr(restaurant, 'subscription_plan', 'alpha') or 'alpha'\n+    subscription_plan = getattr(restaurant, \"subscription_plan\", \"alpha\") or \"alpha\"\n     features = get_plan_features(subscription_plan)\n     return feature_key in features\n \n+\n # Simple utility function for use within routes\n async def check_user_has_feature(\n-    feature_key: str,\n-    current_user,  # User object from route\n-    db: Session\n+    feature_key: str, current_user, db: Session  # User object from route\n ) -> bool:\n     \"\"\"\n     Check if the current user has access to a feature.\n     Use this in your route handlers after getting current_user.\n-    \n+\n     Example:\n         @router.get(\"/inventory\")\n         async def get_inventory(\n             current_user: User = Depends(get_current_user),\n             db: Session = Depends(get_db)\n         ):\n             if not await check_user_has_feature(\"inventory_management\", current_user, db):\n                 raise AuthenticationException(message=\"Authentication failed\", error_code=\"ACCESS_DENIED\")\n             # ... rest of endpoint logic\n     \"\"\"\n-    if not hasattr(current_user, 'restaurant_id') or not current_user.restaurant_id:\n+    if not hasattr(current_user, \"restaurant_id\") or not current_user.restaurant_id:\n         return False\n-    \n+\n     return check_feature_access(str(current_user.restaurant_id), feature_key, db)\n \n+\n # For backward compatibility with auth.py which imports get_plan_features\n-__all__ = ['FEATURE_KEYS', 'get_plan_features', 'check_feature_access', 'check_user_has_feature']\n\\ No newline at end of file\n+__all__ = [\n+    \"FEATURE_KEYS\",\n+    \"get_plan_features\",\n+    \"check_feature_access\",\n+    \"check_user_has_feature\",\n+]\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/database_security.py\t2025-08-02 21:56:58.994414+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/database_security.py\t2025-08-02 22:36:03.219944+00:00\n@@ -1,9 +1,10 @@\n \"\"\"\n Database Security Hardening Configuration\n Implements security best practices for PostgreSQL connections\n \"\"\"\n+\n from typing import Dict, Any\n import logging\n from sqlalchemy.engine import Engine\n from sqlalchemy import event, text\n from sqlalchemy.pool import Pool\n@@ -11,90 +12,92 @@\n logger = logging.getLogger(__name__)\n \n \n class DatabaseSecurityConfig:\n     \"\"\"Database security configuration and hardening\"\"\"\n-    \n+\n     @staticmethod\n     def get_secure_engine_args() -> Dict[str, Any]:\n         \"\"\"\n         Get security-hardened database engine arguments\n-        \n+\n         Returns:\n             Dictionary of engine configuration options\n         \"\"\"\n         return {\n             # Connection pool settings\n             \"pool_pre_ping\": True,  # Test connections before using\n-            \"pool_recycle\": 3600,   # Recycle connections after 1 hour\n-            \"pool_size\": 10,        # Limit concurrent connections\n-            \"max_overflow\": 20,     # Maximum overflow connections\n-            \n+            \"pool_recycle\": 3600,  # Recycle connections after 1 hour\n+            \"pool_size\": 10,  # Limit concurrent connections\n+            \"max_overflow\": 20,  # Maximum overflow connections\n             # Statement timeout to prevent long-running queries\n             \"connect_args\": {\n                 \"options\": \"-c statement_timeout=30000\",  # 30 second timeout\n                 \"sslmode\": \"prefer\",  # Use SSL when available\n                 \"client_encoding\": \"utf8\",\n                 \"application_name\": \"fynlo_pos_backend\",\n             },\n-            \n             # Additional security settings\n             \"echo\": False,  # Never log SQL in production\n             \"future\": True,  # Use SQLAlchemy 2.0 style\n         }\n-    \n+\n     @staticmethod\n     def apply_connection_security(engine: Engine) -> None:\n         \"\"\"\n         Apply security configurations to database connections\n-        \n-        Args:\n-            engine: SQLAlchemy engine instance\n-        \"\"\"\n-        \n+\n+        Args:\n+            engine: SQLAlchemy engine instance\n+        \"\"\"\n+\n         @event.listens_for(Pool, \"connect\")\n         def set_security_parameters(dbapi_conn, connection_record):\n             \"\"\"Set security parameters on each new connection\"\"\"\n             with dbapi_conn.cursor() as cursor:\n                 # Disable dynamic loading of shared libraries\n                 cursor.execute(\"SET local_preload_libraries = ''\")\n-                \n+\n                 # Set secure search path\n                 cursor.execute(\"SET search_path = public\")\n-                \n+\n                 # Enable row-level security\n                 cursor.execute(\"SET row_security = on\")\n-                \n+\n                 # Set transaction isolation level\n                 cursor.execute(\"SET default_transaction_isolation = 'read committed'\")\n-                \n+\n                 # Limit work memory to prevent DoS\n                 cursor.execute(\"SET work_mem = '4MB'\")\n-                \n+\n                 # Set statement timeout\n                 cursor.execute(\"SET statement_timeout = '30s'\")\n-                \n+\n                 # Log slow queries\n                 cursor.execute(\"SET log_min_duration_statement = '1000'\")  # 1 second\n-        \n+\n         @event.listens_for(engine, \"connect\")\n         def receive_connect(dbapi_conn, connection_record):\n             \"\"\"Additional connection-level security\"\"\"\n-            connection_record.info['pid'] = dbapi_conn.get_backend_pid()\n-            logger.debug(f\"New database connection established: PID {connection_record.info['pid']}\")\n-    \n+            connection_record.info[\"pid\"] = dbapi_conn.get_backend_pid()\n+            logger.debug(\n+                f\"New database connection established: PID {connection_record.info['pid']}\"\n+            )\n+\n     @staticmethod\n     def create_security_functions(engine: Engine) -> None:\n         \"\"\"\n         Create database security functions and triggers\n-        \n+\n         Args:\n             engine: SQLAlchemy engine instance\n         \"\"\"\n         with engine.connect() as conn:\n             # Create audit log table if not exists\n-            conn.execute(text(\"\"\"\n+            conn.execute(\n+                text(\n+                    \"\"\"\n                 CREATE TABLE IF NOT EXISTS security_audit_log (\n                     id BIGSERIAL PRIMARY KEY,\n                     event_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                     event_type VARCHAR(50) NOT NULL,\n                     user_id UUID,\n@@ -102,20 +105,28 @@\n                     operation VARCHAR(20),\n                     query_text TEXT,\n                     ip_address INET,\n                     details JSONB\n                 )\n-            \"\"\"))\n-            \n+            \"\"\"\n+                )\n+            )\n+\n             # Create index on audit log\n-            conn.execute(text(\"\"\"\n+            conn.execute(\n+                text(\n+                    \"\"\"\n                 CREATE INDEX IF NOT EXISTS idx_audit_log_time \n                 ON security_audit_log(event_time DESC)\n-            \"\"\"))\n-            \n+            \"\"\"\n+                )\n+            )\n+\n             # Create function to log suspicious activities\n-            conn.execute(text(\"\"\"\n+            conn.execute(\n+                text(\n+                    \"\"\"\n                 CREATE OR REPLACE FUNCTION log_suspicious_activity()\n                 RETURNS trigger AS $$\n                 BEGIN\n                     INSERT INTO security_audit_log (\n                         event_type, \n@@ -134,27 +145,35 @@\n                         )\n                     );\n                     RETURN NULL;\n                 END;\n                 $$ LANGUAGE plpgsql SECURITY DEFINER;\n-            \"\"\"))\n-            \n+            \"\"\"\n+                )\n+            )\n+\n             # Create function to validate UUIDs\n-            conn.execute(text(\"\"\"\n+            conn.execute(\n+                text(\n+                    \"\"\"\n                 CREATE OR REPLACE FUNCTION is_valid_uuid(uuid_string text)\n                 RETURNS boolean AS $$\n                 BEGIN\n                     RETURN uuid_string ~* '^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$';\n                 EXCEPTION\n                     WHEN others THEN\n                         RETURN false;\n                 END;\n                 $$ LANGUAGE plpgsql IMMUTABLE;\n-            \"\"\"))\n-            \n+            \"\"\"\n+                )\n+            )\n+\n             # Create function to sanitize text input\n-            conn.execute(text(\"\"\"\n+            conn.execute(\n+                text(\n+                    \"\"\"\n                 CREATE OR REPLACE FUNCTION sanitize_text(input_text text)\n                 RETURNS text AS $$\n                 BEGIN\n                     -- Remove null bytes using chr(0) instead of E'\\\\x00' to avoid encoding issues\n                     input_text := replace(input_text, chr(0), '');\n@@ -165,117 +184,139 @@\n                     END IF;\n                     \n                     RETURN input_text;\n                 END;\n                 $$ LANGUAGE plpgsql IMMUTABLE;\n-            \"\"\"))\n-            \n+            \"\"\"\n+                )\n+            )\n+\n             conn.commit()\n-    \n+\n     @staticmethod\n     def create_security_policies(engine: Engine) -> None:\n         \"\"\"\n         Create row-level security policies\n-        \n+\n         Args:\n             engine: SQLAlchemy engine instance\n         \"\"\"\n         with engine.connect() as conn:\n             # Enable RLS on sensitive tables\n             tables_with_rls = [\n-                'users', 'restaurants', 'orders', 'customers', \n-                'products', 'inventory', 'transactions'\n+                \"users\",\n+                \"restaurants\",\n+                \"orders\",\n+                \"customers\",\n+                \"products\",\n+                \"inventory\",\n+                \"transactions\",\n             ]\n-            \n+\n             for table in tables_with_rls:\n                 try:\n                     # Enable RLS\n                     conn.execute(text(f\"ALTER TABLE {table} ENABLE ROW LEVEL SECURITY\"))\n-                    \n+\n                     # Create policy for restaurant isolation\n-                    conn.execute(text(f\"\"\"\n+                    conn.execute(\n+                        text(\n+                            f\"\"\"\n                         CREATE POLICY IF NOT EXISTS restaurant_isolation_policy\n                         ON {table}\n                         USING (\n                             restaurant_id = current_setting('app.current_restaurant_id', true)::uuid\n                             OR current_setting('app.current_user_role', true) = 'platform_owner'\n                         )\n-                    \"\"\"))\n-                    \n+                    \"\"\"\n+                        )\n+                    )\n+\n                     logger.info(f\"RLS enabled for table: {table}\")\n                 except Exception as e:\n                     logger.warning(f\"Could not enable RLS for {table}: {e}\")\n-            \n+\n             conn.commit()\n-    \n+\n     @staticmethod\n     def apply_query_restrictions(engine: Engine) -> None:\n         \"\"\"\n         Apply query-level restrictions and monitoring\n-        \n-        Args:\n-            engine: SQLAlchemy engine instance\n-        \"\"\"\n-        \n+\n+        Args:\n+            engine: SQLAlchemy engine instance\n+        \"\"\"\n+\n         @event.listens_for(engine, \"before_cursor_execute\")\n-        def receive_before_cursor_execute(conn, cursor, statement, parameters, context, executemany):\n+        def receive_before_cursor_execute(\n+            conn, cursor, statement, parameters, context, executemany\n+        ):\n             \"\"\"Monitor and restrict dangerous queries\"\"\"\n-            \n+\n             # Log all data modification queries in production\n-            if any(keyword in statement.upper() for keyword in ['INSERT', 'UPDATE', 'DELETE', 'DROP', 'TRUNCATE']):\n+            if any(\n+                keyword in statement.upper()\n+                for keyword in [\"INSERT\", \"UPDATE\", \"DELETE\", \"DROP\", \"TRUNCATE\"]\n+            ):\n                 logger.info(f\"Data modification query: {statement[:100]}...\")\n-            \n+\n             # Prevent certain dangerous operations\n             dangerous_patterns = [\n-                'DROP DATABASE',\n-                'DROP SCHEMA',\n-                'TRUNCATE TABLE users',\n-                'DELETE FROM users WHERE 1=1',\n-                'UPDATE users SET password',\n+                \"DROP DATABASE\",\n+                \"DROP SCHEMA\",\n+                \"TRUNCATE TABLE users\",\n+                \"DELETE FROM users WHERE 1=1\",\n+                \"UPDATE users SET password\",\n             ]\n-            \n+\n             statement_upper = statement.upper()\n             for pattern in dangerous_patterns:\n                 if pattern in statement_upper:\n                     raise Exception(f\"Dangerous query pattern detected: {pattern}\")\n-    \n+\n     @staticmethod\n     def setup_monitoring(engine: Engine) -> None:\n         \"\"\"\n         Setup query monitoring and performance tracking\n-        \n-        Args:\n-            engine: SQLAlchemy engine instance\n-        \"\"\"\n-        \n+\n+        Args:\n+            engine: SQLAlchemy engine instance\n+        \"\"\"\n+\n         @event.listens_for(engine, \"before_cursor_execute\")\n-        def receive_before_cursor_execute(conn, cursor, statement, parameters, context, executemany):\n+        def receive_before_cursor_execute(\n+            conn, cursor, statement, parameters, context, executemany\n+        ):\n             \"\"\"Track query start time\"\"\"\n             context._query_start_time = time.time()\n-        \n+\n         @event.listens_for(engine, \"after_cursor_execute\")\n-        def receive_after_cursor_execute(conn, cursor, statement, parameters, context, executemany):\n+        def receive_after_cursor_execute(\n+            conn, cursor, statement, parameters, context, executemany\n+        ):\n             \"\"\"Log slow queries\"\"\"\n             total_time = time.time() - context._query_start_time\n-            \n+\n             # Log queries taking more than 1 second\n             if total_time > 1.0:\n                 logger.warning(\n                     f\"Slow query detected ({total_time:.2f}s): {statement[:100]}...\"\n                 )\n-    \n+\n     @staticmethod\n     def create_security_views(engine: Engine) -> None:\n         \"\"\"\n         Create security monitoring views\n-        \n+\n         Args:\n             engine: SQLAlchemy engine instance\n         \"\"\"\n         with engine.connect() as conn:\n             # Create view for monitoring active connections\n-            conn.execute(text(\"\"\"\n+            conn.execute(\n+                text(\n+                    \"\"\"\n                 CREATE OR REPLACE VIEW security_active_connections AS\n                 SELECT \n                     pid,\n                     usename,\n                     application_name,\n@@ -285,14 +326,18 @@\n                     state_change,\n                     query\n                 FROM pg_stat_activity\n                 WHERE datname = current_database()\n                 AND pid != pg_backend_pid()\n-            \"\"\"))\n-            \n+            \"\"\"\n+                )\n+            )\n+\n             # Create view for monitoring long-running queries\n-            conn.execute(text(\"\"\"\n+            conn.execute(\n+                text(\n+                    \"\"\"\n                 CREATE OR REPLACE VIEW security_long_queries AS\n                 SELECT \n                     pid,\n                     usename,\n                     application_name,\n@@ -302,46 +347,48 @@\n                     query\n                 FROM pg_stat_activity\n                 WHERE datname = current_database()\n                 AND state != 'idle'\n                 AND query_start < now() - interval '5 minutes'\n-            \"\"\"))\n-            \n+            \"\"\"\n+                )\n+            )\n+\n             conn.commit()\n \n \n import time  # Add this import at the top of the file\n \n \n def apply_all_security_measures(engine: Engine) -> None:\n     \"\"\"\n     Apply all database security measures\n-    \n+\n     Args:\n         engine: SQLAlchemy engine instance\n     \"\"\"\n     logger.info(\"Applying database security measures...\")\n-    \n+\n     try:\n         # Apply connection security\n         DatabaseSecurityConfig.apply_connection_security(engine)\n-        \n+\n         # Create security functions\n         DatabaseSecurityConfig.create_security_functions(engine)\n-        \n+\n         # Create RLS policies\n         DatabaseSecurityConfig.create_security_policies(engine)\n-        \n+\n         # Apply query restrictions\n         DatabaseSecurityConfig.apply_query_restrictions(engine)\n-        \n+\n         # Setup monitoring\n         DatabaseSecurityConfig.setup_monitoring(engine)\n-        \n+\n         # Create security views\n         DatabaseSecurityConfig.create_security_views(engine)\n-        \n+\n         logger.info(\"Database security measures applied successfully\")\n-        \n+\n     except Exception as e:\n         logger.error(f\"Error applying security measures: {e}\")\n-        # Don't fail startup, but log the error\n\\ No newline at end of file\n+        # Don't fail startup, but log the error\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/websocket.py\t2025-08-02 21:56:58.990747+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/websocket.py\t2025-08-02 22:36:03.232998+00:00\n@@ -44,17 +44,19 @@\n router = APIRouter()\n \n # Initialize rate limiter\n rate_limiter: Optional[WebSocketRateLimiter] = None\n \n+\n async def get_rate_limiter() -> WebSocketRateLimiter:\n     \"\"\"Get or create rate limiter instance\"\"\"\n     global rate_limiter\n     if rate_limiter is None:\n         redis_client = await get_redis()\n         rate_limiter = WebSocketRateLimiter(redis_client=redis_client)\n     return rate_limiter\n+\n \n # Legacy rate limiting configuration (kept for backward compatibility)\n connection_tracker: Dict[str, Dict[str, Any]] = defaultdict(\n     lambda: {\"count\": 0, \"last_reset\": datetime.now()}\n )\n@@ -177,12 +179,11 @@\n         logger.warning(\"Max recursion depth reached in sanitize_message_data\")\n         return data\n     if isinstance(data, dict):\n         # Preserve key types, only sanitize string values\n         return {\n-            k: sanitize_message_data(v, depth + 1, max_depth)\n-            for k, v in data.items()\n+            k: sanitize_message_data(v, depth + 1, max_depth) for k, v in data.items()\n         }\n     elif isinstance(data, list):\n         return [sanitize_message_data(item, depth + 1, max_depth) for item in data]\n     elif isinstance(data, str):\n         return sanitize_string(data, max_length=1000)\n@@ -203,23 +204,23 @@\n         await websocket.close(code=4001, reason=\"Unauthorized\")\n         return False\n \n     # Get client IP\n     client_host = websocket.client.host if websocket.client else \"unknown\"\n-    \n+\n     # Use new rate limiter\n     limiter = await get_rate_limiter()\n-    \n+\n     # Check connection rate limit\n     allowed, error_msg = await limiter.check_connection_limit(client_host, user_id)\n     if not allowed:\n         # Log rate limit violation\n         await security_monitor.log_rate_limit_violation(\n             ip_address=client_host,\n             user_id=user_id,\n             limit_type=\"websocket_connection\",\n-            details={\"error\": error_msg}\n+            details={\"error\": error_msg},\n         )\n         await websocket.close(code=4008, reason=error_msg)\n         return False\n \n     return True\n@@ -374,12 +375,12 @@\n             await security_monitor.log_suspicious_activity(\n                 event_type=\"websocket_auth_bypass_attempt\",\n                 details={\n                     \"restaurant_id\": restaurant_id,\n                     \"connection_type\": connection_type,\n-                    \"error\": \"Missing user_id\"\n-                }\n+                    \"error\": \"Missing user_id\",\n+                },\n             )\n             return False, None\n \n         return True, user\n \n@@ -466,15 +467,11 @@\n         )\n \n         # Register connection with rate limiter\n         limiter = await get_rate_limiter()\n         final_user_id = str(verified_user.id) if verified_user else user_id\n-        await limiter.register_connection(\n-            connection_id, \n-            final_user_id, \n-            client_host\n-        )\n+        await limiter.register_connection(connection_id, final_user_id, client_host)\n \n         # Track user connection (use original user_id if provided)\n         if user_id:\n             user_connections[user_id].add(connection_id)\n         elif verified_user:\n@@ -483,27 +480,29 @@\n         # Handle incoming messages\n         while True:\n             try:\n                 # Receive message from client\n                 data = await websocket.receive_text()\n-                \n+\n                 # Check message rate limit\n-                message_size = len(data.encode('utf-8'))\n-                allowed, error_msg = await limiter.check_message_rate(connection_id, message_size)\n+                message_size = len(data.encode(\"utf-8\"))\n+                allowed, error_msg = await limiter.check_message_rate(\n+                    connection_id, message_size\n+                )\n                 if not allowed:\n                     # Log rate limit violation\n                     await security_monitor.log_rate_limit_violation(\n                         ip_address=client_host,\n                         user_id=final_user_id,\n                         limit_type=\"websocket_messages\",\n-                        details={\"error\": error_msg, \"message_size\": message_size}\n+                        details={\"error\": error_msg, \"message_size\": message_size},\n                     )\n                     await websocket.send_text(\n                         json.dumps({\"type\": \"error\", \"message\": error_msg})\n                     )\n                     continue\n-                \n+\n                 message_data = json.loads(data)\n \n                 # Sanitize message data\n                 message_data = sanitize_message_data(message_data)\n \n@@ -528,11 +527,11 @@\n                     )\n                 else:\n                     # Log unknown message type\n                     logger.warning(\n                         \"Unknown message type received: %s\",\n-                        sanitize_string(str(message_type), max_length=50)\n+                        sanitize_string(str(message_type), max_length=50),\n                     )\n                     await websocket.send_text(\n                         json.dumps({\"type\": \"error\", \"message\": \"Unknown message type\"})\n                     )\n \n@@ -562,11 +561,11 @@\n         if connection_id:\n             if user_id:\n                 user_connections[user_id].discard(connection_id)\n             if verified_user:\n                 user_connections[str(verified_user.id)].discard(connection_id)\n-            \n+\n             # Unregister from rate limiter\n             try:\n                 limiter = await get_rate_limiter()\n                 # Use verified_user.id if available, otherwise user_id\n                 final_user_id = str(verified_user.id) if verified_user else user_id\n@@ -714,11 +713,11 @@\n         if connection_id:\n             if user_id:\n                 user_connections[user_id].discard(connection_id)\n             if verified_user:\n                 user_connections[str(verified_user.id)].discard(connection_id)\n-            \n+\n             # Unregister from rate limiter\n             try:\n                 limiter = await get_rate_limiter()\n                 # Use verified_user.id if available, otherwise user_id\n                 final_user_id = str(verified_user.id) if verified_user else user_id\n@@ -866,11 +865,11 @@\n         if connection_id:\n             if user_id:\n                 user_connections[user_id].discard(connection_id)\n             if verified_user:\n                 user_connections[str(verified_user.id)].discard(connection_id)\n-            \n+\n             # Unregister from rate limiter\n             try:\n                 limiter = await get_rate_limiter()\n                 # Use verified_user.id if available, otherwise user_id\n                 final_user_id = str(verified_user.id) if verified_user else user_id\n@@ -1019,11 +1018,11 @@\n         if connection_id:\n             if user_id:\n                 user_connections[user_id].discard(connection_id)\n             if verified_user:\n                 user_connections[str(verified_user.id)].discard(connection_id)\n-            \n+\n             # Unregister from rate limiter\n             try:\n                 limiter = await get_rate_limiter()\n                 # Use verified_user.id if available, otherwise user_id\n                 final_user_id = str(verified_user.id) if verified_user else user_id\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/logging_filters.py\t2025-08-02 20:32:29.032932+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/logging_filters.py\t2025-08-02 22:36:03.266212+00:00\n@@ -49,57 +49,80 @@\n     \"postgres_password\",\n     # Add more keywords as needed\n ]\n REDACTION_PLACEHOLDER = \"[REDACTED]\"\n \n+\n class SensitiveDataFilter(logging.Filter):\n     \"\"\"\n     Log filter to redact sensitive information from log records.\n     It redacts values in the `extra` dictionary of a log record\n     if their keys match any of the `redacted_keywords`.\n     It also attempts to redact well-known sensitive patterns from the log message itself.\n     \"\"\"\n \n-    def __init__(self, name=\"\", redacted_keywords=None, placeholder=REDACTION_PLACEHOLDER):\n+    def __init__(\n+        self, name=\"\", redacted_keywords=None, placeholder=REDACTION_PLACEHOLDER\n+    ):\n         super().__init__(name)\n         self.redacted_keywords = redacted_keywords or DEFAULT_REDACTED_KEYWORDS\n         self.placeholder = placeholder\n         # Compile regex for message body redaction (e.g., \"Authorization: Bearer <token>\")\n         # This is a simple example; more complex regex might be needed for different formats.\n         self.sensitive_patterns = [\n-            re.compile(rf'(\"{keyword}\":\\s*)\"([^\"]*)\"', re.IGNORECASE) for keyword in self.redacted_keywords\n+            re.compile(rf'(\"{keyword}\":\\s*)\"([^\"]*)\"', re.IGNORECASE)\n+            for keyword in self.redacted_keywords\n         ]\n-        self.auth_header_pattern = re.compile(r'(Authorization:\\s*(?:Bearer|Basic)\\s+)[^\\s]+', re.IGNORECASE)\n-        \n+        self.auth_header_pattern = re.compile(\n+            r\"(Authorization:\\s*(?:Bearer|Basic)\\s+)[^\\s]+\", re.IGNORECASE\n+        )\n+\n         # Additional sensitive patterns\n-        self.credit_card_pattern = re.compile(r'\\b(?:\\d[ -]*?){13,19}\\b')\n-        self.email_pattern = re.compile(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b')\n-        self.ip_pattern = re.compile(r'\\b(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\\b')\n-        self.file_path_pattern = re.compile(r'(/[\\w.-]+)+\\.(py|js|json|yaml|yml|env|pem|key)')\n-        self.db_url_pattern = re.compile(r'(postgresql|postgres|mysql|redis|mongodb)://[^\\s]+', re.IGNORECASE)\n-        self.url_with_creds_pattern = re.compile(r'(https?://)([^:]+):([^@]+)@', re.IGNORECASE)\n-        self.uuid_pattern = re.compile(r'\\b[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\\b', re.IGNORECASE)\n-        self.jwt_pattern = re.compile(r'eyJ[A-Za-z0-9_-]+\\.[A-Za-z0-9_-]+\\.[A-Za-z0-9_-]+')\n-\n+        self.credit_card_pattern = re.compile(r\"\\b(?:\\d[ -]*?){13,19}\\b\")\n+        self.email_pattern = re.compile(\n+            r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\"\n+        )\n+        self.ip_pattern = re.compile(r\"\\b(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\\b\")\n+        self.file_path_pattern = re.compile(\n+            r\"(/[\\w.-]+)+\\.(py|js|json|yaml|yml|env|pem|key)\"\n+        )\n+        self.db_url_pattern = re.compile(\n+            r\"(postgresql|postgres|mysql|redis|mongodb)://[^\\s]+\", re.IGNORECASE\n+        )\n+        self.url_with_creds_pattern = re.compile(\n+            r\"(https?://)([^:]+):([^@]+)@\", re.IGNORECASE\n+        )\n+        self.uuid_pattern = re.compile(\n+            r\"\\b[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\\b\",\n+            re.IGNORECASE,\n+        )\n+        self.jwt_pattern = re.compile(\n+            r\"eyJ[A-Za-z0-9_-]+\\.[A-Za-z0-9_-]+\\.[A-Za-z0-9_-]+\"\n+        )\n \n     def _redact_dict(self, data_dict):\n         if not isinstance(data_dict, dict):\n             return data_dict\n \n         clean_dict = {}\n         for key, value in data_dict.items():\n             if isinstance(value, dict):\n                 clean_dict[key] = self._redact_dict(value)\n             elif isinstance(value, list):\n-                clean_dict[key] = [self._redact_dict(item) if isinstance(item, dict) else item for item in value]\n-            elif any(keyword.lower() in key.lower() for keyword in self.redacted_keywords):\n+                clean_dict[key] = [\n+                    self._redact_dict(item) if isinstance(item, dict) else item\n+                    for item in value\n+                ]\n+            elif any(\n+                keyword.lower() in key.lower() for keyword in self.redacted_keywords\n+            ):\n                 clean_dict[key] = self.placeholder\n             else:\n                 clean_dict[key] = value\n         return clean_dict\n         # Redact sensitive data in 'extra' dictionary fields\n-        if hasattr(record, 'extra') and isinstance(record.extra, dict):\n+        if hasattr(record, \"extra\") and isinstance(record.extra, dict):\n             record.extra = self._redact_dict(record.extra.copy())\n \n         # Redact sensitive data from the log message itself\n         if record.getMessage() and isinstance(record.msg, str):\n             # Ensure args are substituted before redaction if they exist\n@@ -110,38 +133,42 @@\n             # Redact JSON-like key-value pairs in the message string\n             for pattern in self.sensitive_patterns:\n                 message = pattern.sub(rf'\\1\"{self.placeholder}\"', message)\n \n             # Redact common Authorization header patterns\n-            message = self.auth_header_pattern.sub(rf'\\1{self.placeholder}', message)\n-            \n+            message = self.auth_header_pattern.sub(rf\"\\1{self.placeholder}\", message)\n+\n             # Redact additional sensitive patterns\n-            message = self.credit_card_pattern.sub('[CARD_NUMBER]', message)\n-            message = self.email_pattern.sub('[EMAIL]', message)\n-            message = self.ip_pattern.sub('[IP_ADDRESS]', message)\n-            message = self.file_path_pattern.sub('[FILE_PATH]', message)\n-            message = self.db_url_pattern.sub('[DATABASE_URL]', message)\n-            message = self.url_with_creds_pattern.sub(r'\\1[CREDENTIALS]@', message)\n-            message = self.jwt_pattern.sub('[JWT_TOKEN]', message)\n-            \n+            message = self.credit_card_pattern.sub(\"[CARD_NUMBER]\", message)\n+            message = self.email_pattern.sub(\"[EMAIL]\", message)\n+            message = self.ip_pattern.sub(\"[IP_ADDRESS]\", message)\n+            message = self.file_path_pattern.sub(\"[FILE_PATH]\", message)\n+            message = self.db_url_pattern.sub(\"[DATABASE_URL]\", message)\n+            message = self.url_with_creds_pattern.sub(r\"\\1[CREDENTIALS]@\", message)\n+            message = self.jwt_pattern.sub(\"[JWT_TOKEN]\", message)\n+\n             # Redact UUIDs only if they appear after sensitive keywords\n-            for keyword in ['user', 'customer', 'session', 'token', 'key']:\n-                pattern = re.compile(rf'({keyword}[_\\s]*(?:id)?[:\\s=]+)([0-9a-f]{{8}}-[0-9a-f]{{4}}-[0-9a-f]{{4}}-[0-9a-f]{{4}}-[0-9a-f]{{12}})', re.IGNORECASE)\n-                message = pattern.sub(r'\\1[UUID]', message)\n+            for keyword in [\"user\", \"customer\", \"session\", \"token\", \"key\"]:\n+                pattern = re.compile(\n+                    rf\"({keyword}[_\\s]*(?:id)?[:\\s=]+)([0-9a-f]{{8}}-[0-9a-f]{{4}}-[0-9a-f]{{4}}-[0-9a-f]{{4}}-[0-9a-f]{{12}})\",\n+                    re.IGNORECASE,\n+                )\n+                message = pattern.sub(r\"\\1[UUID]\", message)\n \n             # If the message was changed, we need to update record.msg and clear record.message\n             # so that the formatter re-evaluates it.\n             # However, this can be tricky as record.message is a cached property.\n             # A simpler way is to modify args if possible, or directly overwrite msg.\n             # For now, we'll assume getMessage() is called by the formatter after filtering.\n             # A more robust solution might involve a custom formatter.\n             # For this implementation, we'll modify record.msg directly if it was a string.\n             # This might not be ideal if record.args were used.\n             if message != record.getMessage():\n-                 record.msg = message # This might break formatting if args were involved\n-                 record.args = () # Clear args as we've pre-formatted and redacted the message\n-\n+                record.msg = (\n+                    message  # This might break formatting if args were involved\n+                )\n+                record.args = ()  # Clear args as we've pre-formatted and redacted the message\n \n         # Also, check common attributes like 'args' if they are dicts\n         if isinstance(record.args, dict):\n             record.args = self._redact_dict(record.args.copy())\n         elif isinstance(record.args, tuple):\n@@ -153,10 +180,11 @@\n                     new_args.append(arg)\n             record.args = tuple(new_args)\n \n         return True\n \n+\n def setup_logging_filters():\n     \"\"\"\n     Adds the SensitiveDataFilter to the root logger if in production.\n     \"\"\"\n     # This import needs to be here to avoid circular dependency with config\n@@ -175,9 +203,10 @@\n             # Also add to handlers of the root logger\n             for handler in logger.handlers:\n                 handler.addFilter(sensitive_filter)\n             logging.info(\"SensitiveDataFilter added to production logging.\")\n \n+\n # Call this function early in your application startup, for example, in main.py or config.py\n # However, to avoid circular imports with config, it's better to call it from main.py\n # after settings are loaded.\n # setup_logging_filters()\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/restaurants.py\t2025-08-02 21:56:58.989525+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/restaurants.py\t2025-08-02 22:36:03.271224+00:00\n@@ -8,37 +8,53 @@\n from sqlalchemy import and_, func\n from pydantic import BaseModel, EmailStr\n from datetime import datetime, timedelta\n import logging\n \n-from app.core.database import get_db, Restaurant, Platform, User, Order, Customer, Section, Table\n+from app.core.database import (\n+    get_db,\n+    Restaurant,\n+    Platform,\n+    User,\n+    Order,\n+    Customer,\n+    Section,\n+    Table,\n+)\n from app.core.auth import get_current_user\n from app.core.responses import APIResponseHelper\n-from app.core.exceptions import AuthorizationException, FynloException, ResourceNotFoundException, ValidationException\n+from app.core.exceptions import (\n+    AuthorizationException,\n+    FynloException,\n+    ResourceNotFoundException,\n+    ValidationException,\n+)\n from app.core.validation import (\n     validate_model_jsonb_fields,\n     validate_email,\n     validate_phone,\n     sanitize_string,\n-    ValidationError as ValidationErr\n+    ValidationError as ValidationErr,\n )\n from app.core.websocket import websocket_manager\n from app.schemas.restaurant import RestaurantOnboardingCreate\n from app.core.tenant_security import TenantSecurity\n \n router = APIRouter()\n logger = logging.getLogger(__name__)\n+\n \n # Pydantic models\n class RestaurantCreate(BaseModel):\n     name: str\n     address: dict\n     phone: Optional[str] = None\n     email: Optional[EmailStr] = None\n     timezone: str = \"UTC\"\n     business_hours: dict = {}\n     settings: dict = {}\n+\n \n class RestaurantUpdate(BaseModel):\n     name: Optional[str] = None\n     address: Optional[dict] = None\n     phone: Optional[str] = None\n@@ -47,10 +63,11 @@\n     business_hours: Optional[dict] = None\n     settings: Optional[dict] = None\n     tax_configuration: Optional[dict] = None\n     payment_methods: Optional[dict] = None\n     is_active: Optional[bool] = None\n+\n \n class RestaurantResponse(BaseModel):\n     id: str\n     platform_id: Optional[str]\n     name: str\n@@ -64,72 +81,74 @@\n     payment_methods: dict\n     is_active: bool\n     created_at: datetime\n     updated_at: Optional[datetime]\n \n+\n class RestaurantStats(BaseModel):\n     restaurant_id: str\n     name: str\n     daily_revenue: float\n     monthly_revenue: float\n     total_orders: int\n     active_customers: int\n     average_order_value: float\n     payment_method_breakdown: dict\n \n+\n class PlatformStats(BaseModel):\n     total_restaurants: int\n     active_restaurants: int\n     total_revenue: float\n     total_orders: int\n     total_customers: int\n     top_performing_restaurants: List[RestaurantStats]\n \n+\n @router.get(\"/\", response_model=List[RestaurantResponse])\n async def get_restaurants(\n     platform_id: Optional[str] = Query(None),\n     active_only: bool = Query(True),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Get restaurants (for platform owners) or current restaurant (for restaurant users)\"\"\"\n-    \n+\n     # Platform owners can see all restaurants in their platform\n     if current_user.role == \"platform_owner\":\n         platform_id = platform_id or str(current_user.platform_id)\n         query = db.query(Restaurant).filter(Restaurant.platform_id == platform_id)\n-        \n+\n         if active_only:\n             query = query.filter(Restaurant.is_active == True)\n-        \n+\n         restaurants = query.order_by(Restaurant.name).all()\n-    \n+\n     # Restaurant users - handle multi-restaurant access\n     else:\n         from app.core.tenant_security import TenantSecurity\n-        \n+\n         # Get all accessible restaurants for the user\n-        accessible_restaurants = TenantSecurity.get_accessible_restaurant_ids(current_user, db)\n-        \n+        accessible_restaurants = TenantSecurity.get_accessible_restaurant_ids(\n+            current_user, db\n+        )\n+\n         if not accessible_restaurants:\n             return APIResponseHelper.success(\n                 data=[],\n                 message=\"No restaurants accessible\",\n-                meta={\n-                    \"user_role\": current_user.role,\n-                    \"active_only\": active_only\n-                }\n-            )\n-        \n+                meta={\"user_role\": current_user.role, \"active_only\": active_only},\n+            )\n+\n         # Query all accessible restaurants\n         query = db.query(Restaurant).filter(Restaurant.id.in_(accessible_restaurants))\n-        \n+\n         if active_only:\n             query = query.filter(Restaurant.is_active == True)\n-        \n+\n         restaurants = query.order_by(Restaurant.name).all()\n-    \n+\n     result = [\n         RestaurantResponse(\n             id=str(restaurant.id),\n             platform_id=str(restaurant.platform_id) if restaurant.platform_id else None,\n             name=restaurant.name,\n@@ -141,49 +160,48 @@\n             settings=restaurant.settings,\n             tax_configuration=restaurant.tax_configuration,\n             payment_methods=restaurant.payment_methods,\n             is_active=restaurant.is_active,\n             created_at=restaurant.created_at,\n-            updated_at=restaurant.updated_at\n+            updated_at=restaurant.updated_at,\n         )\n         for restaurant in restaurants\n     ]\n-    \n+\n     return APIResponseHelper.success(\n         data=result,\n         message=f\"Retrieved {len(result)} restaurants\",\n         meta={\n             \"user_role\": current_user.role,\n             \"platform_id\": platform_id,\n-            \"active_only\": active_only\n-        }\n-    )\n+            \"active_only\": active_only,\n+        },\n+    )\n+\n \n @router.get(\"/current\", response_model=RestaurantResponse)\n async def get_current_restaurant(\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Specific restaurant ID for multi-restaurant users\"),\n-    db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Specific restaurant ID for multi-restaurant users\"\n+    ),\n+    db: Session = Depends(get_db),\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Get current restaurant (supports multi-restaurant access)\"\"\"\n-    \n+\n     # Validate restaurant access\n     await TenantSecurity.validate_restaurant_access(\n-        current_user, \n-        current_restaurant_id or current_user.restaurant_id, \n-        db=db\n+        current_user, current_restaurant_id or current_user.restaurant_id, db=db\n     )\n     # Use the provided restaurant_id or fall back to user's default\n     restaurant_id = current_restaurant_id or current_user.restaurant_id\n-    \n-    restaurant = db.query(Restaurant).filter(\n-        Restaurant.id == restaurant_id\n-    ).first()\n-    \n+\n+    restaurant = db.query(Restaurant).filter(Restaurant.id == restaurant_id).first()\n+\n     if not restaurant:\n         raise ResourceNotFoundException(resource=\"Restaurant\")\n-    \n+\n     return RestaurantResponse(\n         id=str(restaurant.id),\n         platform_id=str(restaurant.platform_id) if restaurant.platform_id else None,\n         name=restaurant.name,\n         address=restaurant.address,\n@@ -194,80 +212,89 @@\n         settings=restaurant.settings,\n         tax_configuration=restaurant.tax_configuration,\n         payment_methods=restaurant.payment_methods,\n         is_active=restaurant.is_active,\n         created_at=restaurant.created_at,\n-        updated_at=restaurant.updated_at\n-    )\n+        updated_at=restaurant.updated_at,\n+    )\n+\n \n @router.post(\"/\", response_model=RestaurantResponse)\n async def create_restaurant(\n     restaurant_data: RestaurantCreate,\n     platform_id: Optional[str] = Query(None),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Create a new restaurant (platform owners only)\"\"\"\n-    \n+\n     if current_user.role != \"platform_owner\":\n-        raise AuthorizationException(message=\"Only platform owners can create restaurants\")\n-    \n+        raise AuthorizationException(\n+            message=\"Only platform owners can create restaurants\"\n+        )\n+\n     # Use user's platform if not specified\n     platform_id = platform_id or str(current_user.platform_id)\n-    \n+\n     # Verify platform exists\n     platform = db.query(Platform).filter(Platform.id == platform_id).first()\n     if not platform:\n-        raise ResourceNotFoundException(resource=\"Resource\", message=\"Platform not found\")\n-    \n+        raise ResourceNotFoundException(\n+            resource=\"Resource\", message=\"Platform not found\"\n+        )\n+\n     # Validate and sanitize JSONB fields\n     try:\n-        validated_address = validate_model_jsonb_fields('restaurant', 'address', restaurant_data.address)\n-        validated_business_hours = validate_model_jsonb_fields('restaurant', 'business_hours', restaurant_data.business_hours)\n-        validated_settings = validate_model_jsonb_fields('restaurant', 'settings', restaurant_data.settings)\n+        validated_address = validate_model_jsonb_fields(\n+            \"restaurant\", \"address\", restaurant_data.address\n+        )\n+        validated_business_hours = validate_model_jsonb_fields(\n+            \"restaurant\", \"business_hours\", restaurant_data.business_hours\n+        )\n+        validated_settings = validate_model_jsonb_fields(\n+            \"restaurant\", \"settings\", restaurant_data.settings\n+        )\n     except ValidationErr as e:\n         raise FynloException(\n             error_code=ErrorCodes.VALIDATION_ERROR,\n-            detail=f\"JSONB validation failed: {str(e)}\"\n-        )\n-    \n+            detail=f\"JSONB validation failed: {str(e)}\",\n+        )\n+\n     # Validate email and phone if provided\n     if restaurant_data.email and not validate_email(restaurant_data.email):\n         raise FynloException(\n-            error_code=ErrorCodes.VALIDATION_ERROR,\n-            detail=\"Invalid email format\"\n-        )\n-    \n+            error_code=ErrorCodes.VALIDATION_ERROR, detail=\"Invalid email format\"\n+        )\n+\n     if restaurant_data.phone and not validate_phone(restaurant_data.phone):\n         raise FynloException(\n-            error_code=ErrorCodes.VALIDATION_ERROR,\n-            detail=\"Invalid phone number format\"\n-        )\n-    \n+            error_code=ErrorCodes.VALIDATION_ERROR, detail=\"Invalid phone number format\"\n+        )\n+\n     # Sanitize string inputs\n     sanitized_name = sanitize_string(restaurant_data.name, 255)\n     if not sanitized_name:\n         raise FynloException(\n             error_code=ErrorCodes.VALIDATION_ERROR,\n-            detail=\"Restaurant name cannot be empty\"\n-        )\n-    \n+            detail=\"Restaurant name cannot be empty\",\n+        )\n+\n     new_restaurant = Restaurant(\n         platform_id=platform_id,\n         name=sanitized_name,\n         address=validated_address,\n         phone=restaurant_data.phone,\n         email=restaurant_data.email,\n         timezone=restaurant_data.timezone,\n         business_hours=validated_business_hours,\n-        settings=validated_settings\n-    )\n-    \n+        settings=validated_settings,\n+    )\n+\n     db.add(new_restaurant)\n     db.commit()\n     db.refresh(new_restaurant)\n-    \n+\n     return RestaurantResponse(\n         id=str(new_restaurant.id),\n         platform_id=str(new_restaurant.platform_id),\n         name=new_restaurant.name,\n         address=new_restaurant.address,\n@@ -278,39 +305,44 @@\n         settings=new_restaurant.settings,\n         tax_configuration=new_restaurant.tax_configuration,\n         payment_methods=new_restaurant.payment_methods,\n         is_active=new_restaurant.is_active,\n         created_at=new_restaurant.created_at,\n-        updated_at=new_restaurant.updated_at\n-    )\n+        updated_at=new_restaurant.updated_at,\n+    )\n+\n \n @router.post(\"/onboarding/create\", response_model=RestaurantResponse)\n async def create_restaurant_onboarding(\n     restaurant_data: RestaurantOnboardingCreate,\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Create a restaurant during onboarding for users without restaurants\"\"\"\n-    \n+\n     # Check if user already has a restaurant\n     if current_user.restaurant_id:\n         raise ValidationException(message=\"User already has a restaurant associated\")\n-    \n+\n     # Get user's platform (should be set during auth)\n     platform_id = str(current_user.platform_id) if current_user.platform_id else None\n     if not platform_id:\n         # If no platform, use default platform\n         default_platform = db.query(Platform).filter(Platform.name == \"Fynlo\").first()\n         if not default_platform:\n             raise FynloException(message=\"No default platform found\", status_code=500)\n         platform_id = str(default_platform.id)\n-    \n+\n     # Validate and sanitize JSONB fields\n     try:\n-        validated_address = validate_model_jsonb_fields('restaurant', 'address', restaurant_data.address)\n-        validated_business_hours = validate_model_jsonb_fields('restaurant', 'business_hours', restaurant_data.business_hours)\n-        \n+        validated_address = validate_model_jsonb_fields(\n+            \"restaurant\", \"address\", restaurant_data.address\n+        )\n+        validated_business_hours = validate_model_jsonb_fields(\n+            \"restaurant\", \"business_hours\", restaurant_data.business_hours\n+        )\n+\n         # Create settings from the additional fields\n         settings = {\n             \"display_name\": restaurant_data.display_name,\n             \"business_type\": restaurant_data.business_type,\n             \"description\": restaurant_data.description or \"\",\n@@ -320,60 +352,61 @@\n             \"currency\": \"GBP\",\n             \"date_format\": \"DD/MM/YYYY\",\n             \"time_format\": \"24h\",\n             \"allow_tips\": True,\n             \"auto_gratuity_percentage\": 12.5,\n-            \"print_receipt_default\": True\n+            \"print_receipt_default\": True,\n         }\n-        validated_settings = validate_model_jsonb_fields('restaurant', 'settings', settings)\n+        validated_settings = validate_model_jsonb_fields(\n+            \"restaurant\", \"settings\", settings\n+        )\n     except ValidationErr as e:\n         raise FynloException(\n             error_code=ErrorCodes.VALIDATION_ERROR,\n-            detail=f\"JSONB validation failed: {str(e)}\"\n-        )\n-    \n+            detail=f\"JSONB validation failed: {str(e)}\",\n+        )\n+\n     # Validate email and phone if provided\n     if restaurant_data.email and not validate_email(restaurant_data.email):\n         raise FynloException(\n-            error_code=ErrorCodes.VALIDATION_ERROR,\n-            detail=\"Invalid email format\"\n-        )\n-    \n+            error_code=ErrorCodes.VALIDATION_ERROR, detail=\"Invalid email format\"\n+        )\n+\n     if restaurant_data.phone and not validate_phone(restaurant_data.phone):\n         raise FynloException(\n-            error_code=ErrorCodes.VALIDATION_ERROR,\n-            detail=\"Invalid phone number format\"\n-        )\n-    \n+            error_code=ErrorCodes.VALIDATION_ERROR, detail=\"Invalid phone number format\"\n+        )\n+\n     # Sanitize string inputs\n     sanitized_name = sanitize_string(restaurant_data.name, 255)\n     if not sanitized_name:\n         raise FynloException(\n             error_code=ErrorCodes.VALIDATION_ERROR,\n-            detail=\"Restaurant name cannot be empty\"\n-        )\n-    \n+            detail=\"Restaurant name cannot be empty\",\n+        )\n+\n     # Get subscription info from Supabase metadata\n     # We need to fetch from Supabase since User model doesn't have subscription fields\n     from app.core.supabase_client import get_supabase_client\n+\n     supabase = get_supabase_client()\n-    \n+\n     # Get the Supabase user to access metadata\n     supabase_user = None\n     if current_user.supabase_id:\n         try:\n             response = supabase.auth.admin.get_user_by_id(str(current_user.supabase_id))\n             if response and response.user:\n                 supabase_user = response.user\n         except Exception as e:\n             logger.warning(f\"Failed to fetch Supabase user: {e}\")\n-    \n+\n     # Extract subscription info from Supabase metadata or use defaults\n     user_metadata = supabase_user.user_metadata if supabase_user else {}\n-    subscription_plan = user_metadata.get('subscription_plan', 'alpha')\n-    subscription_status = user_metadata.get('subscription_status', 'active')\n-    \n+    subscription_plan = user_metadata.get(\"subscription_plan\", \"alpha\")\n+    subscription_status = user_metadata.get(\"subscription_status\", \"active\")\n+\n     # Create restaurant with proper defaults\n     new_restaurant = Restaurant(\n         platform_id=platform_id,\n         name=sanitized_name,\n         address=validated_address,\n@@ -386,65 +419,77 @@\n         subscription_status=subscription_status,\n         subscription_started_at=datetime.utcnow(),\n         # Set default configurations\n         tax_configuration={\"vat_rate\": 0.20, \"included_in_price\": True},\n         payment_methods={\"cash\": True, \"card\": True, \"qr_code\": True},\n-        is_active=True\n-    )\n-    \n+        is_active=True,\n+    )\n+\n     db.add(new_restaurant)\n     db.flush()  # Get the ID before updating user\n-    \n+\n     # Update user with restaurant_id and mark onboarding complete\n     current_user.restaurant_id = new_restaurant.id\n     current_user.needs_onboarding = False\n     current_user.updated_at = datetime.utcnow()\n-    \n+\n     # Set user role to restaurant_owner if not already set\n     if current_user.role not in [\"platform_owner\", \"restaurant_owner\"]:\n         current_user.role = \"restaurant_owner\"\n-    \n+\n     # Create employees if provided\n     if restaurant_data.employees:\n         for emp_data in restaurant_data.employees:\n             try:\n                 # Create user for each employee\n                 employee_user = User(\n-                    email=emp_data['email'],\n-                    first_name=emp_data['name'].split()[0] if ' ' in emp_data['name'] else emp_data['name'],\n-                    last_name=' '.join(emp_data['name'].split()[1:]) if ' ' in emp_data['name'] else '',\n-                    role=emp_data.get('role', 'employee'),\n+                    email=emp_data[\"email\"],\n+                    first_name=(\n+                        emp_data[\"name\"].split()[0]\n+                        if \" \" in emp_data[\"name\"]\n+                        else emp_data[\"name\"]\n+                    ),\n+                    last_name=(\n+                        \" \".join(emp_data[\"name\"].split()[1:])\n+                        if \" \" in emp_data[\"name\"]\n+                        else \"\"\n+                    ),\n+                    role=emp_data.get(\"role\", \"employee\"),\n                     restaurant_id=new_restaurant.id,\n                     platform_id=platform_id,\n-                    permissions={\"access_level\": emp_data.get('access_level', 'pos_only')},\n+                    permissions={\n+                        \"access_level\": emp_data.get(\"access_level\", \"pos_only\")\n+                    },\n                     is_active=True,\n-                    created_at=datetime.utcnow()\n+                    created_at=datetime.utcnow(),\n                 )\n                 db.add(employee_user)\n                 logger.info(f\"Created employee user: {employee_user.email}\")\n             except Exception as e:\n-                logger.warning(f\"Failed to create employee {emp_data.get('email', 'unknown')}: {e}\")\n+                logger.warning(\n+                    f\"Failed to create employee {emp_data.get('email', 'unknown')}: {e}\"\n+                )\n                 # Continue with other employees even if one fails\n-    \n+\n     db.commit()\n     db.refresh(new_restaurant)\n     db.refresh(current_user)\n-    \n+\n     # Notify via WebSocket that onboarding is complete\n     try:\n         await websocket_manager.broadcast_to_restaurant(\n             str(new_restaurant.id),\n             {\n                 \"type\": \"onboarding_complete\",\n                 \"restaurant_id\": str(new_restaurant.id),\n-                \"user_id\": str(current_user.id)\n-            }\n+                \"user_id\": str(current_user.id),\n+            },\n         )\n     except Exception as e:\n         # Don't fail if WebSocket fails\n         pass\n-    \n+\n     return RestaurantResponse(\n         id=str(new_restaurant.id),\n         platform_id=str(new_restaurant.platform_id),\n         name=new_restaurant.name,\n         address=new_restaurant.address,\n@@ -455,100 +500,124 @@\n         settings=new_restaurant.settings,\n         tax_configuration=new_restaurant.tax_configuration,\n         payment_methods=new_restaurant.payment_methods,\n         is_active=new_restaurant.is_active,\n         created_at=new_restaurant.created_at,\n-        updated_at=new_restaurant.updated_at\n-    )\n+        updated_at=new_restaurant.updated_at,\n+    )\n+\n \n @router.put(\"/{restaurant_id}\", response_model=RestaurantResponse)\n async def update_restaurant(\n     restaurant_id: str,\n     restaurant_data: RestaurantUpdate,\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Specific restaurant ID for multi-restaurant users\"),\n-    db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Specific restaurant ID for multi-restaurant users\"\n+    ),\n+    db: Session = Depends(get_db),\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Update restaurant settings\"\"\"\n-    \n+\n     restaurant = db.query(Restaurant).filter(Restaurant.id == restaurant_id).first()\n     if not restaurant:\n         raise ResourceNotFoundException(resource=\"Restaurant\")\n-    \n+\n     # Platform owners can update any restaurant in their platform\n     if current_user.role == \"platform_owner\":\n         if str(restaurant.platform_id) != str(current_user.platform_id):\n             raise AuthorizationException(message=\"Access denied\")\n     else:\n         # Restaurant users - validate access to the specific restaurant\n         await TenantSecurity.validate_restaurant_access(\n-            current_user, \n+            current_user,\n             restaurant_id,  # Must match the restaurant being updated\n-            db=db\n-        )\n-        \n+            db=db,\n+        )\n+\n         # Additional check for managers - they can only update settings, not critical fields\n-        if current_user.role == \"manager\" and any(key in restaurant_data.dict(exclude_unset=True) for key in ['is_active', 'payment_methods']):\n-            raise AuthorizationException(message=\"Managers cannot modify critical settings\")\n-    \n+        if current_user.role == \"manager\" and any(\n+            key in restaurant_data.dict(exclude_unset=True)\n+            for key in [\"is_active\", \"payment_methods\"]\n+        ):\n+            raise AuthorizationException(\n+                message=\"Managers cannot modify critical settings\"\n+            )\n+\n     # Validate and sanitize fields if provided\n     update_data = restaurant_data.dict(exclude_unset=True)\n-    \n+\n     # Validate JSONB fields\n     try:\n-        if 'address' in update_data:\n-            update_data['address'] = validate_model_jsonb_fields('restaurant', 'address', update_data['address'])\n-        \n-        if 'business_hours' in update_data:\n-            update_data['business_hours'] = validate_model_jsonb_fields('restaurant', 'business_hours', update_data['business_hours'])\n-        \n-        if 'settings' in update_data:\n-            update_data['settings'] = validate_model_jsonb_fields('restaurant', 'settings', update_data['settings'])\n-        \n-        if 'tax_configuration' in update_data:\n-            update_data['tax_configuration'] = validate_model_jsonb_fields('restaurant', 'tax_configuration', update_data['tax_configuration'])\n-        \n-        if 'payment_methods' in update_data:\n-            update_data['payment_methods'] = validate_model_jsonb_fields('restaurant', 'payment_methods', update_data['payment_methods'])\n-            \n+        if \"address\" in update_data:\n+            update_data[\"address\"] = validate_model_jsonb_fields(\n+                \"restaurant\", \"address\", update_data[\"address\"]\n+            )\n+\n+        if \"business_hours\" in update_data:\n+            update_data[\"business_hours\"] = validate_model_jsonb_fields(\n+                \"restaurant\", \"business_hours\", update_data[\"business_hours\"]\n+            )\n+\n+        if \"settings\" in update_data:\n+            update_data[\"settings\"] = validate_model_jsonb_fields(\n+                \"restaurant\", \"settings\", update_data[\"settings\"]\n+            )\n+\n+        if \"tax_configuration\" in update_data:\n+            update_data[\"tax_configuration\"] = validate_model_jsonb_fields(\n+                \"restaurant\", \"tax_configuration\", update_data[\"tax_configuration\"]\n+            )\n+\n+        if \"payment_methods\" in update_data:\n+            update_data[\"payment_methods\"] = validate_model_jsonb_fields(\n+                \"restaurant\", \"payment_methods\", update_data[\"payment_methods\"]\n+            )\n+\n     except ValidationErr as e:\n         raise FynloException(\n             error_code=ErrorCodes.VALIDATION_ERROR,\n-            detail=f\"JSONB validation failed: {str(e)}\"\n-        )\n-    \n+            detail=f\"JSONB validation failed: {str(e)}\",\n+        )\n+\n     # Validate email and phone if provided\n-    if 'email' in update_data and update_data['email'] and not validate_email(update_data['email']):\n-        raise FynloException(\n-            error_code=ErrorCodes.VALIDATION_ERROR,\n-            detail=\"Invalid email format\"\n-        )\n-    \n-    if 'phone' in update_data and update_data['phone'] and not validate_phone(update_data['phone']):\n-        raise FynloException(\n-            error_code=ErrorCodes.VALIDATION_ERROR,\n-            detail=\"Invalid phone number format\"\n-        )\n-    \n+    if (\n+        \"email\" in update_data\n+        and update_data[\"email\"]\n+        and not validate_email(update_data[\"email\"])\n+    ):\n+        raise FynloException(\n+            error_code=ErrorCodes.VALIDATION_ERROR, detail=\"Invalid email format\"\n+        )\n+\n+    if (\n+        \"phone\" in update_data\n+        and update_data[\"phone\"]\n+        and not validate_phone(update_data[\"phone\"])\n+    ):\n+        raise FynloException(\n+            error_code=ErrorCodes.VALIDATION_ERROR, detail=\"Invalid phone number format\"\n+        )\n+\n     # Sanitize string inputs\n-    if 'name' in update_data:\n-        sanitized_name = sanitize_string(update_data['name'], 255)\n+    if \"name\" in update_data:\n+        sanitized_name = sanitize_string(update_data[\"name\"], 255)\n         if not sanitized_name:\n             raise FynloException(\n                 error_code=ErrorCodes.VALIDATION_ERROR,\n-                detail=\"Restaurant name cannot be empty\"\n-            )\n-        update_data['name'] = sanitized_name\n-    \n+                detail=\"Restaurant name cannot be empty\",\n+            )\n+        update_data[\"name\"] = sanitized_name\n+\n     # Update fields\n     for field, value in update_data.items():\n         setattr(restaurant, field, value)\n-    \n+\n     restaurant.updated_at = datetime.utcnow()\n     db.commit()\n     db.refresh(restaurant)\n-    \n+\n     return RestaurantResponse(\n         id=str(restaurant.id),\n         platform_id=str(restaurant.platform_id) if restaurant.platform_id else None,\n         name=restaurant.name,\n         address=restaurant.address,\n@@ -559,224 +628,271 @@\n         settings=restaurant.settings,\n         tax_configuration=restaurant.tax_configuration,\n         payment_methods=restaurant.payment_methods,\n         is_active=restaurant.is_active,\n         created_at=restaurant.created_at,\n-        updated_at=restaurant.updated_at\n-    )\n+        updated_at=restaurant.updated_at,\n+    )\n+\n \n @router.get(\"/{restaurant_id}/stats\", response_model=RestaurantStats)\n async def get_restaurant_stats(\n     restaurant_id: str,\n     days: int = Query(30, le=365),\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Specific restaurant ID for multi-restaurant users\"),\n-    db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Specific restaurant ID for multi-restaurant users\"\n+    ),\n+    db: Session = Depends(get_db),\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Get restaurant performance statistics\"\"\"\n-    \n+\n     restaurant = db.query(Restaurant).filter(Restaurant.id == restaurant_id).first()\n     if not restaurant:\n         raise ResourceNotFoundException(resource=\"Restaurant\")\n-    \n+\n     # Platform owners can view stats for any restaurant in their platform\n     if current_user.role == \"platform_owner\":\n         if str(restaurant.platform_id) != str(current_user.platform_id):\n             raise AuthorizationException(message=\"Access denied\")\n     else:\n         # Restaurant users - validate access to the specific restaurant\n         await TenantSecurity.validate_restaurant_access(\n-            current_user, \n+            current_user,\n             restaurant_id,  # Must match the restaurant being queried\n-            db=db\n-        )\n-    \n+            db=db,\n+        )\n+\n     # Date ranges\n     today_start = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)\n     period_start = today_start - timedelta(days=days)\n-    \n+\n     # Daily revenue (today)\n-    daily_revenue = db.query(func.sum(Order.total_amount)).filter(\n-        and_(\n-            Order.restaurant_id == restaurant_id,\n-            Order.created_at >= today_start,\n-            Order.status == \"completed\"\n-        )\n-    ).scalar() or 0\n-    \n+    daily_revenue = (\n+        db.query(func.sum(Order.total_amount))\n+        .filter(\n+            and_(\n+                Order.restaurant_id == restaurant_id,\n+                Order.created_at >= today_start,\n+                Order.status == \"completed\",\n+            )\n+        )\n+        .scalar()\n+        or 0\n+    )\n+\n     # Period revenue\n-    period_revenue = db.query(func.sum(Order.total_amount)).filter(\n-        and_(\n-            Order.restaurant_id == restaurant_id,\n-            Order.created_at >= period_start,\n-            Order.status == \"completed\"\n-        )\n-    ).scalar() or 0\n-    \n+    period_revenue = (\n+        db.query(func.sum(Order.total_amount))\n+        .filter(\n+            and_(\n+                Order.restaurant_id == restaurant_id,\n+                Order.created_at >= period_start,\n+                Order.status == \"completed\",\n+            )\n+        )\n+        .scalar()\n+        or 0\n+    )\n+\n     # Total orders in period\n-    total_orders = db.query(Order).filter(\n-        and_(\n-            Order.restaurant_id == restaurant_id,\n-            Order.created_at >= period_start\n-        )\n-    ).count()\n-    \n+    total_orders = (\n+        db.query(Order)\n+        .filter(\n+            and_(Order.restaurant_id == restaurant_id, Order.created_at >= period_start)\n+        )\n+        .count()\n+    )\n+\n     # Active customers (customers with orders in period)\n-    active_customers = db.query(func.count(func.distinct(Order.customer_id))).filter(\n-        and_(\n-            Order.restaurant_id == restaurant_id,\n-            Order.created_at >= period_start,\n-            Order.customer_id.isnot(None)\n-        )\n-    ).scalar() or 0\n-    \n+    active_customers = (\n+        db.query(func.count(func.distinct(Order.customer_id)))\n+        .filter(\n+            and_(\n+                Order.restaurant_id == restaurant_id,\n+                Order.created_at >= period_start,\n+                Order.customer_id.isnot(None),\n+            )\n+        )\n+        .scalar()\n+        or 0\n+    )\n+\n     # Average order value\n     avg_order_value = (period_revenue / total_orders) if total_orders > 0 else 0\n-    \n+\n     # Payment method breakdown (last 30 days)\n     payment_breakdown = {}\n     # This would require a proper Payment table join - simplified for now\n-    payment_breakdown = {\n-        \"qr_code\": 0.45,\n-        \"cash\": 0.30,\n-        \"card\": 0.20,\n-        \"apple_pay\": 0.05\n-    }\n-    \n+    payment_breakdown = {\"qr_code\": 0.45, \"cash\": 0.30, \"card\": 0.20, \"apple_pay\": 0.05}\n+\n     return RestaurantStats(\n         restaurant_id=str(restaurant.id),\n         name=restaurant.name,\n         daily_revenue=float(daily_revenue),\n         monthly_revenue=float(period_revenue),\n         total_orders=total_orders,\n         active_customers=active_customers,\n         average_order_value=round(avg_order_value, 2),\n-        payment_method_breakdown=payment_breakdown\n-    )\n+        payment_method_breakdown=payment_breakdown,\n+    )\n+\n \n @router.get(\"/platform/stats\", response_model=PlatformStats)\n async def get_platform_stats(\n     platform_id: Optional[str] = Query(None),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Get platform-wide statistics (platform owners only)\"\"\"\n-    \n+\n     if current_user.role != \"platform_owner\":\n         raise AuthorizationException(message=\"Platform owners only\")\n-    \n+\n     platform_id = platform_id or str(current_user.platform_id)\n-    \n+\n     # Get all restaurants in platform\n-    restaurants = db.query(Restaurant).filter(Restaurant.platform_id == platform_id).all()\n+    restaurants = (\n+        db.query(Restaurant).filter(Restaurant.platform_id == platform_id).all()\n+    )\n     restaurant_ids = [str(r.id) for r in restaurants]\n-    \n+\n     # Total and active restaurants\n     total_restaurants = len(restaurants)\n     active_restaurants = sum(1 for r in restaurants if r.is_active)\n-    \n+\n     # Get period for calculations (last 30 days)\n     period_start = datetime.now() - timedelta(days=30)\n-    \n+\n     # Total revenue across all restaurants\n-    total_revenue = db.query(func.sum(Order.total_amount)).filter(\n-        and_(\n-            Order.restaurant_id.in_(restaurant_ids),\n-            Order.created_at >= period_start,\n-            Order.status == \"completed\"\n-        )\n-    ).scalar() or 0\n-    \n+    total_revenue = (\n+        db.query(func.sum(Order.total_amount))\n+        .filter(\n+            and_(\n+                Order.restaurant_id.in_(restaurant_ids),\n+                Order.created_at >= period_start,\n+                Order.status == \"completed\",\n+            )\n+        )\n+        .scalar()\n+        or 0\n+    )\n+\n     # Total orders\n-    total_orders = db.query(Order).filter(\n-        and_(\n-            Order.restaurant_id.in_(restaurant_ids),\n-            Order.created_at >= period_start\n-        )\n-    ).count()\n-    \n+    total_orders = (\n+        db.query(Order)\n+        .filter(\n+            and_(\n+                Order.restaurant_id.in_(restaurant_ids),\n+                Order.created_at >= period_start,\n+            )\n+        )\n+        .count()\n+    )\n+\n     # Total customers\n-    total_customers = db.query(Customer).filter(\n-        Customer.restaurant_id.in_(restaurant_ids)\n-    ).count()\n-    \n+    total_customers = (\n+        db.query(Customer).filter(Customer.restaurant_id.in_(restaurant_ids)).count()\n+    )\n+\n     # Top performing restaurants\n     top_restaurants = []\n     for restaurant in restaurants[:5]:  # Top 5\n-        restaurant_revenue = db.query(func.sum(Order.total_amount)).filter(\n-            and_(\n-                Order.restaurant_id == restaurant.id,\n-                Order.created_at >= period_start,\n-                Order.status == \"completed\"\n-            )\n-        ).scalar() or 0\n-        \n-        restaurant_orders = db.query(Order).filter(\n-            and_(\n-                Order.restaurant_id == restaurant.id,\n-                Order.created_at >= period_start\n-            )\n-        ).count()\n-        \n-        restaurant_customers = db.query(func.count(func.distinct(Order.customer_id))).filter(\n-            and_(\n-                Order.restaurant_id == restaurant.id,\n-                Order.created_at >= period_start,\n-                Order.customer_id.isnot(None)\n-            )\n-        ).scalar() or 0\n-        \n-        avg_order = (restaurant_revenue / restaurant_orders) if restaurant_orders > 0 else 0\n-        \n-        top_restaurants.append(RestaurantStats(\n-            restaurant_id=str(restaurant.id),\n-            name=restaurant.name,\n-            daily_revenue=float(restaurant_revenue / 30),  # Average daily\n-            monthly_revenue=float(restaurant_revenue),\n-            total_orders=restaurant_orders,\n-            active_customers=restaurant_customers,\n-            average_order_value=round(avg_order, 2),\n-            payment_method_breakdown={}\n-        ))\n-    \n+        restaurant_revenue = (\n+            db.query(func.sum(Order.total_amount))\n+            .filter(\n+                and_(\n+                    Order.restaurant_id == restaurant.id,\n+                    Order.created_at >= period_start,\n+                    Order.status == \"completed\",\n+                )\n+            )\n+            .scalar()\n+            or 0\n+        )\n+\n+        restaurant_orders = (\n+            db.query(Order)\n+            .filter(\n+                and_(\n+                    Order.restaurant_id == restaurant.id,\n+                    Order.created_at >= period_start,\n+                )\n+            )\n+            .count()\n+        )\n+\n+        restaurant_customers = (\n+            db.query(func.count(func.distinct(Order.customer_id)))\n+            .filter(\n+                and_(\n+                    Order.restaurant_id == restaurant.id,\n+                    Order.created_at >= period_start,\n+                    Order.customer_id.isnot(None),\n+                )\n+            )\n+            .scalar()\n+            or 0\n+        )\n+\n+        avg_order = (\n+            (restaurant_revenue / restaurant_orders) if restaurant_orders > 0 else 0\n+        )\n+\n+        top_restaurants.append(\n+            RestaurantStats(\n+                restaurant_id=str(restaurant.id),\n+                name=restaurant.name,\n+                daily_revenue=float(restaurant_revenue / 30),  # Average daily\n+                monthly_revenue=float(restaurant_revenue),\n+                total_orders=restaurant_orders,\n+                active_customers=restaurant_customers,\n+                average_order_value=round(avg_order, 2),\n+                payment_method_breakdown={},\n+            )\n+        )\n+\n     # Sort by revenue\n     top_restaurants.sort(key=lambda x: x.monthly_revenue, reverse=True)\n-    \n+\n     return PlatformStats(\n         total_restaurants=total_restaurants,\n         active_restaurants=active_restaurants,\n         total_revenue=float(total_revenue),\n         total_orders=total_orders,\n         total_customers=total_customers,\n-        top_performing_restaurants=top_restaurants[:5]\n-    )\n+        top_performing_restaurants=top_restaurants[:5],\n+    )\n+\n \n @router.get(\"/{restaurant_id}\")\n async def get_restaurant(\n     restaurant_id: str,\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Specific restaurant ID for multi-restaurant users\"),\n-    db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Specific restaurant ID for multi-restaurant users\"\n+    ),\n+    db: Session = Depends(get_db),\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Get specific restaurant details\"\"\"\n-    \n+\n     restaurant = db.query(Restaurant).filter(Restaurant.id == restaurant_id).first()\n     if not restaurant:\n         raise ResourceNotFoundException(resource=\"Restaurant\")\n-    \n+\n     # Platform owners can view any restaurant in their platform\n     if current_user.role == \"platform_owner\":\n         if str(restaurant.platform_id) != str(current_user.platform_id):\n             raise AuthorizationException(message=\"Access denied\")\n     else:\n         # Restaurant users - validate access to the specific restaurant\n         await TenantSecurity.validate_restaurant_access(\n-            current_user, \n+            current_user,\n             restaurant_id,  # Must match the restaurant being queried\n-            db=db\n-        )\n-    \n+            db=db,\n+        )\n+\n     return RestaurantResponse(\n         id=str(restaurant.id),\n         platform_id=str(restaurant.platform_id) if restaurant.platform_id else None,\n         name=restaurant.name,\n         address=restaurant.address,\n@@ -787,12 +903,13 @@\n         settings=restaurant.settings,\n         tax_configuration=restaurant.tax_configuration,\n         payment_methods=restaurant.payment_methods,\n         is_active=restaurant.is_active,\n         created_at=restaurant.created_at,\n-        updated_at=restaurant.updated_at\n-    )\n+        updated_at=restaurant.updated_at,\n+    )\n+\n \n # Floor Plan and Table Management Endpoints\n class TableResponse(BaseModel):\n     id: str\n     name: str\n@@ -803,242 +920,250 @@\n     server_id: Optional[str] = None\n     server_name: Optional[str] = None\n     x_position: int = 0\n     y_position: int = 0\n \n+\n class SectionResponse(BaseModel):\n     id: str\n     name: str\n     restaurant_id: str\n     color: str = \"#00A651\"\n     is_active: bool = True\n \n+\n class SectionCreate(BaseModel):\n     name: str\n     color: str = \"#00A651\"\n     sort_order: int = 0\n+\n \n class TableCreate(BaseModel):\n     section_id: str\n     name: str\n     seats: int = 4\n     x_position: int = 0\n     y_position: int = 0\n \n+\n @router.get(\"/floor-plan\")\n async def get_floor_plan(\n     section_id: Optional[str] = Query(None),\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Specific restaurant ID for multi-restaurant users\"),\n-    current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Specific restaurant ID for multi-restaurant users\"\n+    ),\n+    current_user: User = Depends(get_current_user),\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Get restaurant floor plan with tables and sections\"\"\"\n-    \n+\n     # Validate restaurant access\n     await TenantSecurity.validate_restaurant_access(\n-        current_user, \n-        current_restaurant_id or current_user.restaurant_id, \n-        db=db\n+        current_user, current_restaurant_id or current_user.restaurant_id, db=db\n     )\n     # Use the provided restaurant_id or fall back to user's default\n     restaurant_id = current_restaurant_id or current_user.restaurant_id\n-    \n+\n     # Get sections\n-    sections_query = db.query(Section).filter(\n-        and_(\n-            Section.restaurant_id == restaurant_id,\n-            Section.is_active == True\n-        )\n-    ).order_by(Section.sort_order, Section.name)\n-    \n+    sections_query = (\n+        db.query(Section)\n+        .filter(and_(Section.restaurant_id == restaurant_id, Section.is_active == True))\n+        .order_by(Section.sort_order, Section.name)\n+    )\n+\n     if section_id:\n         sections_query = sections_query.filter(Section.id == section_id)\n-    \n+\n     sections = sections_query.all()\n     section_ids = [str(s.id) for s in sections]\n-    \n+\n     # Get tables\n-    tables_query = db.query(Table, Section).join(\n-        Section, Table.section_id == Section.id\n-    ).filter(\n-        and_(\n-            Table.restaurant_id == restaurant_id,\n-            Table.is_active == True\n-        )\n-    )\n-    \n+    tables_query = (\n+        db.query(Table, Section)\n+        .join(Section, Table.section_id == Section.id)\n+        .filter(and_(Table.restaurant_id == restaurant_id, Table.is_active == True))\n+    )\n+\n     if section_id:\n         tables_query = tables_query.filter(Table.section_id == section_id)\n-    \n+\n     tables_data = tables_query.all()\n-    \n+\n     # Format sections\n     sections_response = []\n     for section in sections:\n-        sections_response.append({\n-            \"id\": str(section.id),\n-            \"name\": section.name,\n-            \"restaurant_id\": str(section.restaurant_id),\n-            \"color\": section.color,\n-            \"is_active\": section.is_active\n-        })\n-    \n+        sections_response.append(\n+            {\n+                \"id\": str(section.id),\n+                \"name\": section.name,\n+                \"restaurant_id\": str(section.restaurant_id),\n+                \"color\": section.color,\n+                \"is_active\": section.is_active,\n+            }\n+        )\n+\n     # Format tables\n     tables_response = []\n     for table, section in tables_data:\n         # Get server name if assigned\n         server_name = None\n         if table.server_id:\n             server = db.query(User).filter(User.id == table.server_id).first()\n             if server:\n                 server_name = f\"{server.first_name} {server.last_name}\"\n-        \n-        tables_response.append({\n-            \"id\": str(table.id),\n-            \"name\": table.name,\n-            \"section_id\": str(table.section_id),\n-            \"section_name\": section.name,\n-            \"seats\": table.seats,\n-            \"status\": table.status,\n-            \"server_id\": str(table.server_id) if table.server_id else None,\n-            \"server_name\": server_name,\n-            \"x_position\": table.x_position,\n-            \"y_position\": table.y_position\n-        })\n-    \n+\n+        tables_response.append(\n+            {\n+                \"id\": str(table.id),\n+                \"name\": table.name,\n+                \"section_id\": str(table.section_id),\n+                \"section_name\": section.name,\n+                \"seats\": table.seats,\n+                \"status\": table.status,\n+                \"server_id\": str(table.server_id) if table.server_id else None,\n+                \"server_name\": server_name,\n+                \"x_position\": table.x_position,\n+                \"y_position\": table.y_position,\n+            }\n+        )\n+\n     return APIResponseHelper.success(\n-        data={\n-            \"sections\": sections_response,\n-            \"tables\": tables_response\n-        },\n-        message=f\"Retrieved floor plan with {len(sections_response)} sections and {len(tables_response)} tables\"\n-    )\n+        data={\"sections\": sections_response, \"tables\": tables_response},\n+        message=f\"Retrieved floor plan with {len(sections_response)} sections and {len(tables_response)} tables\",\n+    )\n+\n \n @router.get(\"/sections\")\n async def get_sections(\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Specific restaurant ID for multi-restaurant users\"),\n-    current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Specific restaurant ID for multi-restaurant users\"\n+    ),\n+    current_user: User = Depends(get_current_user),\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Get all restaurant sections\"\"\"\n-    \n+\n     # Validate restaurant access\n     await TenantSecurity.validate_restaurant_access(\n-        current_user, \n-        current_restaurant_id or current_user.restaurant_id, \n-        db=db\n+        current_user, current_restaurant_id or current_user.restaurant_id, db=db\n     )\n     # Use the provided restaurant_id or fall back to user's default\n     restaurant_id = current_restaurant_id or current_user.restaurant_id\n-    \n-    sections = db.query(Section).filter(\n-        and_(\n-            Section.restaurant_id == restaurant_id,\n-            Section.is_active == True\n-        )\n-    ).order_by(Section.sort_order, Section.name).all()\n-    \n+\n+    sections = (\n+        db.query(Section)\n+        .filter(and_(Section.restaurant_id == restaurant_id, Section.is_active == True))\n+        .order_by(Section.sort_order, Section.name)\n+        .all()\n+    )\n+\n     sections_response = []\n     for section in sections:\n-        sections_response.append({\n-            \"id\": str(section.id),\n-            \"name\": section.name,\n-            \"restaurant_id\": str(section.restaurant_id),\n-            \"color\": section.color,\n-            \"is_active\": section.is_active\n-        })\n-    \n+        sections_response.append(\n+            {\n+                \"id\": str(section.id),\n+                \"name\": section.name,\n+                \"restaurant_id\": str(section.restaurant_id),\n+                \"color\": section.color,\n+                \"is_active\": section.is_active,\n+            }\n+        )\n+\n     return APIResponseHelper.success(\n-        data=sections_response,\n-        message=f\"Retrieved {len(sections_response)} sections\"\n-    )\n+        data=sections_response, message=f\"Retrieved {len(sections_response)} sections\"\n+    )\n+\n \n @router.post(\"/sections\")\n async def create_section(\n     section_data: SectionCreate,\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Specific restaurant ID for multi-restaurant users\"),\n-    current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Specific restaurant ID for multi-restaurant users\"\n+    ),\n+    current_user: User = Depends(get_current_user),\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Create a new section\"\"\"\n-    \n+\n     # Validate restaurant access\n     await TenantSecurity.validate_restaurant_access(\n-        current_user, \n-        current_restaurant_id or current_user.restaurant_id, \n-        db=db\n+        current_user, current_restaurant_id or current_user.restaurant_id, db=db\n     )\n     # Use the provided restaurant_id or fall back to user's default\n     restaurant_id = current_restaurant_id or current_user.restaurant_id\n-    \n+\n     new_section = Section(\n         restaurant_id=restaurant_id,\n         name=section_data.name,\n         color=section_data.color,\n-        sort_order=section_data.sort_order\n-    )\n-    \n+        sort_order=section_data.sort_order,\n+    )\n+\n     db.add(new_section)\n     db.commit()\n     db.refresh(new_section)\n-    \n+\n     return APIResponseHelper.success(\n         data={\n             \"id\": str(new_section.id),\n             \"name\": new_section.name,\n             \"restaurant_id\": str(new_section.restaurant_id),\n             \"color\": new_section.color,\n-            \"is_active\": new_section.is_active\n+            \"is_active\": new_section.is_active,\n         },\n-        message=f\"Section '{new_section.name}' created successfully\"\n-    )\n+        message=f\"Section '{new_section.name}' created successfully\",\n+    )\n+\n \n @router.post(\"/tables\")\n async def create_table(\n     table_data: TableCreate,\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Specific restaurant ID for multi-restaurant users\"),\n-    current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Specific restaurant ID for multi-restaurant users\"\n+    ),\n+    current_user: User = Depends(get_current_user),\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Create a new table\"\"\"\n-    \n+\n     # Validate restaurant access\n     await TenantSecurity.validate_restaurant_access(\n-        current_user, \n-        current_restaurant_id or current_user.restaurant_id, \n-        db=db\n+        current_user, current_restaurant_id or current_user.restaurant_id, db=db\n     )\n     # Use the provided restaurant_id or fall back to user's default\n     restaurant_id = current_restaurant_id or current_user.restaurant_id\n-    \n+\n     # Verify section exists and belongs to restaurant\n-    section = db.query(Section).filter(\n-        and_(\n-            Section.id == table_data.section_id,\n-            Section.restaurant_id == restaurant_id\n-        )\n-    ).first()\n-    \n+    section = (\n+        db.query(Section)\n+        .filter(\n+            and_(\n+                Section.id == table_data.section_id,\n+                Section.restaurant_id == restaurant_id,\n+            )\n+        )\n+        .first()\n+    )\n+\n     if not section:\n         raise FynloException(\n-            error_code=ErrorCodes.RESOURCE_NOT_FOUND,\n-            detail=\"Section not found\"\n-        )\n-    \n+            error_code=ErrorCodes.RESOURCE_NOT_FOUND, detail=\"Section not found\"\n+        )\n+\n     new_table = Table(\n         restaurant_id=restaurant_id,\n         section_id=table_data.section_id,\n         name=table_data.name,\n         seats=table_data.seats,\n         x_position=table_data.x_position,\n-        y_position=table_data.y_position\n-    )\n-    \n+        y_position=table_data.y_position,\n+    )\n+\n     db.add(new_table)\n     db.commit()\n     db.refresh(new_table)\n-    \n+\n     return APIResponseHelper.success(\n         data={\n             \"id\": str(new_table.id),\n             \"name\": new_table.name,\n             \"section_id\": str(new_table.section_id),\n@@ -1046,310 +1171,307 @@\n             \"seats\": new_table.seats,\n             \"status\": new_table.status,\n             \"server_id\": None,\n             \"server_name\": None,\n             \"x_position\": new_table.x_position,\n-            \"y_position\": new_table.y_position\n+            \"y_position\": new_table.y_position,\n         },\n-        message=f\"Table '{new_table.name}' created successfully\"\n-    )\n+        message=f\"Table '{new_table.name}' created successfully\",\n+    )\n+\n \n @router.put(\"/tables/{table_id}/status\")\n async def update_table_status(\n     table_id: str,\n     status: str,\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Specific restaurant ID for multi-restaurant users\"),\n-    current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Specific restaurant ID for multi-restaurant users\"\n+    ),\n+    current_user: User = Depends(get_current_user),\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Update table status\"\"\"\n-    \n+\n     # Validate status\n     valid_statuses = [\"available\", \"occupied\", \"reserved\", \"cleaning\"]\n     if status not in valid_statuses:\n         raise FynloException(\n             error_code=ErrorCodes.VALIDATION_ERROR,\n-            detail=f\"Invalid status. Must be one of: {valid_statuses}\"\n-        )\n-    \n+            detail=f\"Invalid status. Must be one of: {valid_statuses}\",\n+        )\n+\n     # Validate restaurant access\n     await TenantSecurity.validate_restaurant_access(\n-        current_user, \n-        current_restaurant_id or current_user.restaurant_id, \n-        db=db\n+        current_user, current_restaurant_id or current_user.restaurant_id, db=db\n     )\n     # Use the provided restaurant_id or fall back to user's default\n     restaurant_id = current_restaurant_id or current_user.restaurant_id\n-    \n+\n     # Find table\n-    table = db.query(Table).filter(\n-        and_(\n-            Table.id == table_id,\n-            Table.restaurant_id == restaurant_id\n-        )\n-    ).first()\n-    \n+    table = (\n+        db.query(Table)\n+        .filter(and_(Table.id == table_id, Table.restaurant_id == restaurant_id))\n+        .first()\n+    )\n+\n     if not table:\n         raise FynloException(\n-            error_code=ErrorCodes.RESOURCE_NOT_FOUND,\n-            detail=\"Table not found\"\n-        )\n-    \n+            error_code=ErrorCodes.RESOURCE_NOT_FOUND, detail=\"Table not found\"\n+        )\n+\n     table.status = status\n     table.updated_at = datetime.utcnow()\n     db.commit()\n     db.refresh(table)\n-    \n+\n     # Get section name\n     section = db.query(Section).filter(Section.id == table.section_id).first()\n-    \n+\n     # Get server name if assigned\n     server_name = None\n     if table.server_id:\n         server = db.query(User).filter(User.id == table.server_id).first()\n         if server:\n             server_name = f\"{server.first_name} {server.last_name}\"\n-    \n+\n     table_data = {\n         \"id\": str(table.id),\n         \"name\": table.name,\n         \"section_id\": str(table.section_id),\n         \"section_name\": section.name if section else \"\",\n         \"seats\": table.seats,\n         \"status\": table.status,\n         \"server_id\": str(table.server_id) if table.server_id else None,\n         \"server_name\": server_name,\n         \"x_position\": table.x_position,\n-        \"y_position\": table.y_position\n+        \"y_position\": table.y_position,\n     }\n-    \n+\n     return APIResponseHelper.success(\n-        data=table_data,\n-        message=f\"Table {table.name} status updated to {status}\"\n-    )\n+        data=table_data, message=f\"Table {table.name} status updated to {status}\"\n+    )\n+\n \n @router.put(\"/tables/{table_id}/server\")\n async def update_table_server(\n     table_id: str,\n     server_id: Optional[str] = None,\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Specific restaurant ID for multi-restaurant users\"),\n-    current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Specific restaurant ID for multi-restaurant users\"\n+    ),\n+    current_user: User = Depends(get_current_user),\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Assign server to table\"\"\"\n-    \n+\n     # Validate restaurant access\n     await TenantSecurity.validate_restaurant_access(\n-        current_user, \n-        current_restaurant_id or current_user.restaurant_id, \n-        db=db\n+        current_user, current_restaurant_id or current_user.restaurant_id, db=db\n     )\n     # Use the provided restaurant_id or fall back to user's default\n     restaurant_id = current_restaurant_id or current_user.restaurant_id\n-    \n+\n     # Find table\n-    table = db.query(Table).filter(\n-        and_(\n-            Table.id == table_id,\n-            Table.restaurant_id == restaurant_id\n-        )\n-    ).first()\n-    \n+    table = (\n+        db.query(Table)\n+        .filter(and_(Table.id == table_id, Table.restaurant_id == restaurant_id))\n+        .first()\n+    )\n+\n     if not table:\n         raise FynloException(\n-            error_code=ErrorCodes.RESOURCE_NOT_FOUND,\n-            detail=\"Table not found\"\n-        )\n-    \n+            error_code=ErrorCodes.RESOURCE_NOT_FOUND, detail=\"Table not found\"\n+        )\n+\n     # Validate server if provided\n     server_name = None\n     if server_id:\n-        server = db.query(User).filter(\n-            and_(\n-                User.id == server_id,\n-                User.restaurant_id == restaurant_id\n-            )\n-        ).first()\n-        \n+        server = (\n+            db.query(User)\n+            .filter(and_(User.id == server_id, User.restaurant_id == restaurant_id))\n+            .first()\n+        )\n+\n         if not server:\n             raise FynloException(\n-                error_code=ErrorCodes.RESOURCE_NOT_FOUND,\n-                detail=\"Server not found\"\n-            )\n-        \n+                error_code=ErrorCodes.RESOURCE_NOT_FOUND, detail=\"Server not found\"\n+            )\n+\n         server_name = f\"{server.first_name} {server.last_name}\"\n-    \n+\n     table.server_id = server_id\n     table.updated_at = datetime.utcnow()\n     db.commit()\n     db.refresh(table)\n-    \n+\n     # Get section name\n     section = db.query(Section).filter(Section.id == table.section_id).first()\n-    \n+\n     table_data = {\n         \"id\": str(table.id),\n         \"name\": table.name,\n         \"section_id\": str(table.section_id),\n         \"section_name\": section.name if section else \"\",\n         \"seats\": table.seats,\n         \"status\": table.status,\n         \"server_id\": str(table.server_id) if table.server_id else None,\n         \"server_name\": server_name,\n         \"x_position\": table.x_position,\n-        \"y_position\": table.y_position\n+        \"y_position\": table.y_position,\n     }\n-    \n+\n     return APIResponseHelper.success(\n-        data=table_data,\n-        message=f\"Table {table.name} server updated\"\n-    )\n+        data=table_data, message=f\"Table {table.name} server updated\"\n+    )\n+\n \n # Layout Management Endpoints\n class FloorPlanLayoutUpdate(BaseModel):\n     layout: dict\n \n+\n @router.get(\"/floor-plan/layout\")\n async def get_floor_plan_layout(\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Specific restaurant ID for multi-restaurant users\"),\n-    current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Specific restaurant ID for multi-restaurant users\"\n+    ),\n+    current_user: User = Depends(get_current_user),\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Get restaurant floor plan layout\"\"\"\n-    \n+\n     # Validate restaurant access\n     await TenantSecurity.validate_restaurant_access(\n-        current_user, \n-        current_restaurant_id or current_user.restaurant_id, \n-        db=db\n+        current_user, current_restaurant_id or current_user.restaurant_id, db=db\n     )\n     # Use the provided restaurant_id or fall back to user's default\n     restaurant_id = current_restaurant_id or current_user.restaurant_id\n-    \n+\n     restaurant = db.query(Restaurant).filter(Restaurant.id == restaurant_id).first()\n-    \n+\n     if not restaurant:\n         raise FynloException(\n-            error_code=ErrorCodes.RESOURCE_NOT_FOUND,\n-            detail=\"Restaurant not found\"\n-        )\n-    \n+            error_code=ErrorCodes.RESOURCE_NOT_FOUND, detail=\"Restaurant not found\"\n+        )\n+\n     return APIResponseHelper.success(\n         data={\n             \"layout\": restaurant.floor_plan_layout or {},\n-            \"restaurant_id\": str(restaurant.id)\n+            \"restaurant_id\": str(restaurant.id),\n         },\n-        message=\"Floor plan layout retrieved successfully\"\n-    )\n+        message=\"Floor plan layout retrieved successfully\",\n+    )\n+\n \n @router.put(\"/floor-plan/layout\")\n async def update_floor_plan_layout(\n     layout_data: FloorPlanLayoutUpdate,\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Specific restaurant ID for multi-restaurant users\"),\n-    current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Specific restaurant ID for multi-restaurant users\"\n+    ),\n+    current_user: User = Depends(get_current_user),\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Update restaurant floor plan layout\"\"\"\n-    \n+\n     # Validate restaurant access\n     await TenantSecurity.validate_restaurant_access(\n-        current_user, \n-        current_restaurant_id or current_user.restaurant_id, \n-        db=db\n+        current_user, current_restaurant_id or current_user.restaurant_id, db=db\n     )\n     # Use the provided restaurant_id or fall back to user's default\n     restaurant_id = current_restaurant_id or current_user.restaurant_id\n-    \n+\n     restaurant = db.query(Restaurant).filter(Restaurant.id == restaurant_id).first()\n-    \n+\n     if not restaurant:\n         raise FynloException(\n-            error_code=ErrorCodes.RESOURCE_NOT_FOUND,\n-            detail=\"Restaurant not found\"\n-        )\n-    \n+            error_code=ErrorCodes.RESOURCE_NOT_FOUND, detail=\"Restaurant not found\"\n+        )\n+\n     # Validate layout JSON\n     try:\n-        validated_layout = validate_model_jsonb_fields('restaurant', 'floor_plan_layout', layout_data.layout)\n+        validated_layout = validate_model_jsonb_fields(\n+            \"restaurant\", \"floor_plan_layout\", layout_data.layout\n+        )\n     except ValidationErr as e:\n         raise FynloException(\n             error_code=ErrorCodes.VALIDATION_ERROR,\n-            detail=f\"Layout validation failed: {str(e)}\"\n-        )\n-    \n+            detail=f\"Layout validation failed: {str(e)}\",\n+        )\n+\n     restaurant.floor_plan_layout = validated_layout\n     restaurant.updated_at = datetime.utcnow()\n     db.commit()\n     db.refresh(restaurant)\n-    \n+\n     return APIResponseHelper.success(\n         data={\n             \"layout\": restaurant.floor_plan_layout,\n-            \"restaurant_id\": str(restaurant.id)\n+            \"restaurant_id\": str(restaurant.id),\n         },\n-        message=\"Floor plan layout updated successfully\"\n-    )\n+        message=\"Floor plan layout updated successfully\",\n+    )\n+\n \n # Table Position Updates\n class TablePositionUpdate(BaseModel):\n     x_position: int\n     y_position: int\n     width: Optional[int] = None\n     height: Optional[int] = None\n     rotation: Optional[int] = None\n \n+\n @router.put(\"/tables/{table_id}/position\")\n async def update_table_position(\n     table_id: str,\n     position_data: TablePositionUpdate,\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Specific restaurant ID for multi-restaurant users\"),\n-    current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Specific restaurant ID for multi-restaurant users\"\n+    ),\n+    current_user: User = Depends(get_current_user),\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Update table position and dimensions\"\"\"\n-    \n+\n     # Validate restaurant access\n     await TenantSecurity.validate_restaurant_access(\n-        current_user, \n-        current_restaurant_id or current_user.restaurant_id, \n-        db=db\n+        current_user, current_restaurant_id or current_user.restaurant_id, db=db\n     )\n     # Use the provided restaurant_id or fall back to user's default\n     restaurant_id = current_restaurant_id or current_user.restaurant_id\n-    \n+\n     # Find table\n-    table = db.query(Table).filter(\n-        and_(\n-            Table.id == table_id,\n-            Table.restaurant_id == restaurant_id\n-        )\n-    ).first()\n-    \n+    table = (\n+        db.query(Table)\n+        .filter(and_(Table.id == table_id, Table.restaurant_id == restaurant_id))\n+        .first()\n+    )\n+\n     if not table:\n         raise FynloException(\n-            error_code=ErrorCodes.RESOURCE_NOT_FOUND,\n-            detail=\"Table not found\"\n-        )\n-    \n+            error_code=ErrorCodes.RESOURCE_NOT_FOUND, detail=\"Table not found\"\n+        )\n+\n     # Update position and dimensions\n     table.x_position = position_data.x_position\n     table.y_position = position_data.y_position\n-    \n+\n     if position_data.width is not None:\n         table.width = position_data.width\n     if position_data.height is not None:\n         table.height = position_data.height\n     if position_data.rotation is not None:\n         table.rotation = position_data.rotation\n-    \n+\n     table.updated_at = datetime.utcnow()\n     db.commit()\n     db.refresh(table)\n-    \n+\n     # Get section name for response\n     section = db.query(Section).filter(Section.id == table.section_id).first()\n-    \n+\n     # Broadcast table update via WebSocket\n     try:\n         await websocket_manager.broadcast_to_restaurant(\n             restaurant_id,\n             {\n@@ -1358,18 +1480,18 @@\n                 \"position\": {\n                     \"x\": table.x_position,\n                     \"y\": table.y_position,\n                     \"width\": table.width,\n                     \"height\": table.height,\n-                    \"rotation\": table.rotation\n-                }\n-            }\n+                    \"rotation\": table.rotation,\n+                },\n+            },\n         )\n     except Exception as e:\n         # Don't fail the request if WebSocket fails\n         pass\n-    \n+\n     table_data = {\n         \"id\": str(table.id),\n         \"name\": table.name,\n         \"section_id\": str(table.section_id),\n         \"section_name\": section.name if section else \"\",\n@@ -1378,237 +1500,259 @@\n         \"x_position\": table.x_position,\n         \"y_position\": table.y_position,\n         \"width\": table.width,\n         \"height\": table.height,\n         \"rotation\": table.rotation,\n-        \"shape\": table.shape\n+        \"shape\": table.shape,\n     }\n-    \n+\n     return APIResponseHelper.success(\n-        data=table_data,\n-        message=f\"Table {table.name} position updated\"\n-    )\n+        data=table_data, message=f\"Table {table.name} position updated\"\n+    )\n+\n \n # Table Merge/Split Operations\n class TableMergeRequest(BaseModel):\n     primary_table_id: str\n     tables_to_merge: List[str]\n     merged_name: Optional[str] = None\n \n+\n @router.post(\"/tables/merge\")\n async def merge_tables(\n     merge_data: TableMergeRequest,\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Specific restaurant ID for multi-restaurant users\"),\n-    current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Specific restaurant ID for multi-restaurant users\"\n+    ),\n+    current_user: User = Depends(get_current_user),\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Merge multiple tables into one\"\"\"\n-    \n+\n     # Validate restaurant access\n     await TenantSecurity.validate_restaurant_access(\n-        current_user, \n-        current_restaurant_id or current_user.restaurant_id, \n-        db=db\n+        current_user, current_restaurant_id or current_user.restaurant_id, db=db\n     )\n     # Use the provided restaurant_id or fall back to user's default\n     restaurant_id = current_restaurant_id or current_user.restaurant_id\n-    \n+\n     # Validate primary table\n-    primary_table = db.query(Table).filter(\n-        and_(\n-            Table.id == merge_data.primary_table_id,\n-            Table.restaurant_id == restaurant_id\n-        )\n-    ).first()\n-    \n+    primary_table = (\n+        db.query(Table)\n+        .filter(\n+            and_(\n+                Table.id == merge_data.primary_table_id,\n+                Table.restaurant_id == restaurant_id,\n+            )\n+        )\n+        .first()\n+    )\n+\n     if not primary_table:\n         raise FynloException(\n-            error_code=ErrorCodes.RESOURCE_NOT_FOUND,\n-            detail=\"Primary table not found\"\n-        )\n-    \n+            error_code=ErrorCodes.RESOURCE_NOT_FOUND, detail=\"Primary table not found\"\n+        )\n+\n     # Validate merge tables\n-    merge_tables = db.query(Table).filter(\n-        and_(\n-            Table.id.in_(merge_data.tables_to_merge),\n-            Table.restaurant_id == restaurant_id\n-        )\n-    ).all()\n-    \n+    merge_tables = (\n+        db.query(Table)\n+        .filter(\n+            and_(\n+                Table.id.in_(merge_data.tables_to_merge),\n+                Table.restaurant_id == restaurant_id,\n+            )\n+        )\n+        .all()\n+    )\n+\n     if len(merge_tables) != len(merge_data.tables_to_merge):\n         raise FynloException(\n             error_code=ErrorCodes.VALIDATION_ERROR,\n-            detail=\"Some tables to merge were not found\"\n-        )\n-    \n+            detail=\"Some tables to merge were not found\",\n+        )\n+\n     # Check if any tables are occupied\n-    occupied_tables = [t for t in [primary_table] + merge_tables if t.status == 'occupied']\n+    occupied_tables = [\n+        t for t in [primary_table] + merge_tables if t.status == \"occupied\"\n+    ]\n     if occupied_tables:\n         table_names = [t.name for t in occupied_tables]\n         raise FynloException(\n             error_code=ErrorCodes.VALIDATION_ERROR,\n-            detail=f\"Cannot merge occupied tables: {', '.join(table_names)}\"\n-        )\n-    \n+            detail=f\"Cannot merge occupied tables: {', '.join(table_names)}\",\n+        )\n+\n     # Calculate merged capacity\n     total_seats = primary_table.seats + sum(t.seats for t in merge_tables)\n-    \n+\n     # Update primary table\n     primary_table.seats = total_seats\n     primary_table.name = merge_data.merged_name or f\"{primary_table.name} (Merged)\"\n     primary_table.status = \"reserved\"  # Mark as reserved during merge\n     primary_table.updated_at = datetime.utcnow()\n-    \n+\n     # Mark merge tables as inactive (soft delete)\n     for table in merge_tables:\n         table.is_active = False\n         table.updated_at = datetime.utcnow()\n-    \n+\n     db.commit()\n     db.refresh(primary_table)\n-    \n+\n     # Broadcast merge via WebSocket\n     try:\n         await websocket_manager.broadcast_to_restaurant(\n             restaurant_id,\n             {\n                 \"type\": \"tables_merged\",\n                 \"primary_table_id\": str(primary_table.id),\n                 \"merged_table_ids\": [str(t.id) for t in merge_tables],\n-                \"new_capacity\": total_seats\n-            }\n+                \"new_capacity\": total_seats,\n+            },\n         )\n     except Exception as e:\n         pass\n-    \n+\n     return APIResponseHelper.success(\n         data={\n             \"merged_table\": {\n                 \"id\": str(primary_table.id),\n                 \"name\": primary_table.name,\n                 \"seats\": primary_table.seats,\n-                \"status\": primary_table.status\n+                \"status\": primary_table.status,\n             },\n-            \"merged_table_ids\": [str(t.id) for t in merge_tables]\n+            \"merged_table_ids\": [str(t.id) for t in merge_tables],\n         },\n-        message=f\"Tables merged successfully. New capacity: {total_seats} seats\"\n-    )\n+        message=f\"Tables merged successfully. New capacity: {total_seats} seats\",\n+    )\n+\n \n # Revenue Analytics\n @router.get(\"/analytics/revenue-by-table\")\n async def get_revenue_by_table(\n     start_date: Optional[str] = Query(None),\n     end_date: Optional[str] = Query(None),\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Specific restaurant ID for multi-restaurant users\"),\n-    current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Specific restaurant ID for multi-restaurant users\"\n+    ),\n+    current_user: User = Depends(get_current_user),\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Get revenue breakdown by table\"\"\"\n-    \n+\n     # Validate restaurant access\n     await TenantSecurity.validate_restaurant_access(\n-        current_user, \n-        current_restaurant_id or current_user.restaurant_id, \n-        db=db\n+        current_user, current_restaurant_id or current_user.restaurant_id, db=db\n     )\n     # Use the provided restaurant_id or fall back to user's default\n     restaurant_id = current_restaurant_id or current_user.restaurant_id\n-    \n+\n     # Set default date range (today if not specified)\n     if not start_date:\n         start_date = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)\n     else:\n-        start_date = datetime.fromisoformat(start_date.replace('Z', '+00:00'))\n-    \n+        start_date = datetime.fromisoformat(start_date.replace(\"Z\", \"+00:00\"))\n+\n     if not end_date:\n-        end_date = datetime.now().replace(hour=23, minute=59, second=59, microsecond=999999)\n+        end_date = datetime.now().replace(\n+            hour=23, minute=59, second=59, microsecond=999999\n+        )\n     else:\n-        end_date = datetime.fromisoformat(end_date.replace('Z', '+00:00'))\n-    \n+        end_date = datetime.fromisoformat(end_date.replace(\"Z\", \"+00:00\"))\n+\n     # Get orders with table information\n-    orders_query = db.query(Order, Table).join(\n-        Table, Order.table_id == Table.id, isouter=True\n-    ).filter(\n-        and_(\n-            Order.restaurant_id == restaurant_id,\n-            Order.created_at >= start_date,\n-            Order.created_at <= end_date,\n-            Order.status == \"completed\"\n-        )\n-    )\n-    \n+    orders_query = (\n+        db.query(Order, Table)\n+        .join(Table, Order.table_id == Table.id, isouter=True)\n+        .filter(\n+            and_(\n+                Order.restaurant_id == restaurant_id,\n+                Order.created_at >= start_date,\n+                Order.created_at <= end_date,\n+                Order.status == \"completed\",\n+            )\n+        )\n+    )\n+\n     orders_data = orders_query.all()\n-    \n+\n     # Group by table\n     table_revenue = {}\n     total_revenue = 0\n     orders_without_table = []\n-    \n+\n     for order, table in orders_data:\n         total_revenue += float(order.total_amount)\n-        \n+\n         if table:\n             table_key = str(table.id)\n             if table_key not in table_revenue:\n                 table_revenue[table_key] = {\n                     \"table_id\": str(table.id),\n                     \"table_name\": table.name,\n                     \"section_name\": \"\",  # Will be filled below\n                     \"total_revenue\": 0,\n                     \"order_count\": 0,\n-                    \"average_order_value\": 0\n+                    \"average_order_value\": 0,\n                 }\n-            \n+\n             table_revenue[table_key][\"total_revenue\"] += float(order.total_amount)\n             table_revenue[table_key][\"order_count\"] += 1\n         else:\n-            orders_without_table.append({\n-                \"order_id\": str(order.id),\n-                \"order_number\": order.order_number,\n-                \"amount\": float(order.total_amount),\n-                \"order_type\": order.order_type\n-            })\n-    \n+            orders_without_table.append(\n+                {\n+                    \"order_id\": str(order.id),\n+                    \"order_number\": order.order_number,\n+                    \"amount\": float(order.total_amount),\n+                    \"order_type\": order.order_type,\n+                }\n+            )\n+\n     # Get section names\n     if table_revenue:\n         table_ids = list(table_revenue.keys())\n-        tables_with_sections = db.query(Table, Section).join(\n-            Section, Table.section_id == Section.id\n-        ).filter(Table.id.in_(table_ids)).all()\n-        \n+        tables_with_sections = (\n+            db.query(Table, Section)\n+            .join(Section, Table.section_id == Section.id)\n+            .filter(Table.id.in_(table_ids))\n+            .all()\n+        )\n+\n         for table, section in tables_with_sections:\n             table_key = str(table.id)\n             if table_key in table_revenue:\n                 table_revenue[table_key][\"section_name\"] = section.name\n-    \n+\n     # Calculate averages\n     for table_data in table_revenue.values():\n         if table_data[\"order_count\"] > 0:\n             table_data[\"average_order_value\"] = round(\n                 table_data[\"total_revenue\"] / table_data[\"order_count\"], 2\n             )\n-    \n+\n     # Sort by revenue\n     table_revenue_list = list(table_revenue.values())\n     table_revenue_list.sort(key=lambda x: x[\"total_revenue\"], reverse=True)\n-    \n+\n     return APIResponseHelper.success(\n         data={\n             \"date_range\": {\n                 \"start_date\": start_date.isoformat(),\n-                \"end_date\": end_date.isoformat()\n+                \"end_date\": end_date.isoformat(),\n             },\n             \"total_revenue\": round(total_revenue, 2),\n             \"table_revenue\": table_revenue_list,\n             \"orders_without_table\": orders_without_table,\n             \"summary\": {\n                 \"tables_with_revenue\": len(table_revenue_list),\n-                \"orders_without_table_count\": len(orders_without_table)\n-            }\n+                \"orders_without_table_count\": len(orders_without_table),\n+            },\n         },\n-        message=f\"Revenue analysis for {len(table_revenue_list)} tables\"\n-    )\n+        message=f\"Revenue analysis for {len(table_revenue_list)} tables\",\n+    )\n+\n \n # Include restaurant deletion endpoints from restaurant_deletion module\n # Import the router from restaurant_deletion module\n from .restaurant_deletion import router as deletion_router\n+\n router.include_router(deletion_router, tags=[\"restaurant_deletion\"])\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/mobile_id_mapping.py\t2025-08-02 21:56:58.995347+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/mobile_id_mapping.py\t2025-08-02 22:36:03.285025+00:00\n@@ -12,293 +12,323 @@\n from app.core.redis_client import RedisClient\n import logging\n \n logger = logging.getLogger(__name__)\n \n+\n class MobileIDMapping(Base):\n     \"\"\"\n     Database table to store UUID to mobile integer ID mappings\n     Ensures consistent ID conversion without collisions\n     \"\"\"\n+\n     __tablename__ = \"mobile_id_mappings\"\n-    \n+\n     uuid_id = Column(String, nullable=False)\n     entity_type = Column(String, nullable=False)  # 'product', 'category', 'order', etc.\n     mobile_id = Column(Integer, unique=True, nullable=False, index=True)\n     created_at = Column(DateTime(timezone=True), server_default=func.now())\n-    \n+\n     # Composite primary key allows same UUID for different entity types\n-    __table_args__ = (\n-        PrimaryKeyConstraint('uuid_id', 'entity_type'),\n-    )\n+    __table_args__ = (PrimaryKeyConstraint(\"uuid_id\", \"entity_type\"),)\n+\n \n class MobileIDService:\n     \"\"\"\n     Service for converting UUIDs to mobile-friendly integer IDs\n     Uses hash-based approach with collision detection and database persistence\n     \"\"\"\n-    \n+\n     # Maximum mobile ID value (9 digits for mobile compatibility)\n     MAX_MOBILE_ID = 999999999\n     MIN_MOBILE_ID = 100000000\n-    \n+\n     def __init__(self, db: Session, redis: Optional[RedisClient] = None):\n         self.db = db\n         self.redis = redis\n         self._cache = {}  # In-memory cache for frequently accessed mappings\n-    \n+\n     def uuid_to_mobile_id(self, uuid_str: str, entity_type: str = \"product\") -> int:\n         \"\"\"\n         Convert UUID to collision-resistant mobile integer ID\n-        \n+\n         Args:\n             uuid_str: UUID string to convert\n             entity_type: Type of entity (product, category, order, etc.)\n-            \n+\n         Returns:\n             Integer ID safe for mobile use\n-            \n+\n         Raises:\n             ValueError: If unable to generate non-colliding ID\n         \"\"\"\n         try:\n             # Check cache first\n             cache_key = f\"{entity_type}:{uuid_str}\"\n             if cache_key in self._cache:\n                 return self._cache[cache_key]\n-            \n+\n             # Check Redis cache\n             if self.redis:\n                 cached_id = self.redis.get(f\"mobile_id:{cache_key}\")\n                 if cached_id:\n                     mobile_id = int(cached_id)\n                     self._cache[cache_key] = mobile_id\n                     return mobile_id\n-            \n+\n             # Check database\n-            existing_mapping = self.db.query(MobileIDMapping).filter(\n-                MobileIDMapping.uuid_id == uuid_str,\n-                MobileIDMapping.entity_type == entity_type\n-            ).first()\n-            \n+            existing_mapping = (\n+                self.db.query(MobileIDMapping)\n+                .filter(\n+                    MobileIDMapping.uuid_id == uuid_str,\n+                    MobileIDMapping.entity_type == entity_type,\n+                )\n+                .first()\n+            )\n+\n             if existing_mapping:\n                 mobile_id = existing_mapping.mobile_id\n                 self._cache[cache_key] = mobile_id\n                 if self.redis:\n-                    self.redis.set(f\"mobile_id:{cache_key}\", str(mobile_id), expire=3600)\n+                    self.redis.set(\n+                        f\"mobile_id:{cache_key}\", str(mobile_id), expire=3600\n+                    )\n                 return mobile_id\n-            \n+\n             # Generate new mobile ID\n             mobile_id = self._generate_mobile_id(uuid_str, entity_type)\n-            \n+\n             # Store in database\n             new_mapping = MobileIDMapping(\n-                uuid_id=uuid_str,\n-                mobile_id=mobile_id,\n-                entity_type=entity_type\n+                uuid_id=uuid_str, mobile_id=mobile_id, entity_type=entity_type\n             )\n             self.db.add(new_mapping)\n             self.db.commit()\n-            \n+\n             # Cache the result\n             self._cache[cache_key] = mobile_id\n             if self.redis:\n                 self.redis.set(f\"mobile_id:{cache_key}\", str(mobile_id), expire=3600)\n-            \n-            logger.info(f\"Generated mobile ID {mobile_id} for UUID {uuid_str} ({entity_type})\")\n+\n+            logger.info(\n+                f\"Generated mobile ID {mobile_id} for UUID {uuid_str} ({entity_type})\"\n+            )\n             return mobile_id\n-            \n+\n         except Exception as e:\n             logger.error(f\"Failed to convert UUID {uuid_str} to mobile ID: {str(e)}\")\n             raise ValueError(f\"Unable to generate mobile ID: {str(e)}\")\n-    \n-    def mobile_id_to_uuid(self, mobile_id: int, entity_type: str = \"product\") -> Optional[str]:\n+\n+    def mobile_id_to_uuid(\n+        self, mobile_id: int, entity_type: str = \"product\"\n+    ) -> Optional[str]:\n         \"\"\"\n         Convert mobile integer ID back to UUID\n-        \n+\n         Args:\n             mobile_id: Mobile integer ID\n             entity_type: Type of entity\n-            \n+\n         Returns:\n             UUID string or None if not found\n         \"\"\"\n         try:\n             # Check cache first\n             cache_key = f\"reverse:{entity_type}:{mobile_id}\"\n             if cache_key in self._cache:\n                 return self._cache[cache_key]\n-            \n+\n             # Check Redis cache\n             if self.redis:\n                 cached_uuid = self.redis.get(f\"uuid_id:{cache_key}\")\n                 if cached_uuid:\n                     self._cache[cache_key] = cached_uuid\n                     return cached_uuid\n-            \n+\n             # Check database\n-            mapping = self.db.query(MobileIDMapping).filter(\n-                MobileIDMapping.mobile_id == mobile_id,\n-                MobileIDMapping.entity_type == entity_type\n-            ).first()\n-            \n+            mapping = (\n+                self.db.query(MobileIDMapping)\n+                .filter(\n+                    MobileIDMapping.mobile_id == mobile_id,\n+                    MobileIDMapping.entity_type == entity_type,\n+                )\n+                .first()\n+            )\n+\n             if mapping:\n                 uuid_str = mapping.uuid_id\n                 self._cache[cache_key] = uuid_str\n                 if self.redis:\n                     self.redis.set(f\"uuid_id:{cache_key}\", uuid_str, expire=3600)\n                 return uuid_str\n-            \n+\n             return None\n-            \n+\n         except Exception as e:\n             logger.error(f\"Failed to convert mobile ID {mobile_id} to UUID: {str(e)}\")\n             return None\n-    \n+\n     def _generate_mobile_id(self, uuid_str: str, entity_type: str) -> int:\n         \"\"\"\n         Generate collision-resistant mobile ID using hash-based approach\n-        \n+\n         Args:\n             uuid_str: UUID string\n             entity_type: Entity type for additional entropy\n-            \n+\n         Returns:\n             Collision-resistant integer ID\n-            \n+\n         Raises:\n             ValueError: If unable to generate non-colliding ID after max attempts\n         \"\"\"\n         MAX_ATTEMPTS = 1000\n-        \n+\n         for attempt in range(MAX_ATTEMPTS):\n             # Create hash input with entity type and attempt number for uniqueness\n-            hash_input = f\"{entity_type}:{uuid_str}:{attempt}\".encode('utf-8')\n-            \n+            hash_input = f\"{entity_type}:{uuid_str}:{attempt}\".encode(\"utf-8\")\n+\n             # Use SHA-256 for good distribution\n             hash_digest = hashlib.sha256(hash_input).hexdigest()\n-            \n+\n             # Take first 8 hex characters and convert to int\n             hex_segment = hash_digest[:8]\n             hash_int = int(hex_segment, 16)\n-            \n+\n             # Ensure it's within our mobile ID range\n-            mobile_id = (hash_int % (self.MAX_MOBILE_ID - self.MIN_MOBILE_ID)) + self.MIN_MOBILE_ID\n-            \n+            mobile_id = (\n+                hash_int % (self.MAX_MOBILE_ID - self.MIN_MOBILE_ID)\n+            ) + self.MIN_MOBILE_ID\n+\n             # Check for collision in database\n-            existing = self.db.query(MobileIDMapping).filter(\n-                MobileIDMapping.mobile_id == mobile_id,\n-                MobileIDMapping.entity_type == entity_type\n-            ).first()\n-            \n+            existing = (\n+                self.db.query(MobileIDMapping)\n+                .filter(\n+                    MobileIDMapping.mobile_id == mobile_id,\n+                    MobileIDMapping.entity_type == entity_type,\n+                )\n+                .first()\n+            )\n+\n             if not existing:\n                 return mobile_id\n-        \n-        raise ValueError(f\"Unable to generate non-colliding mobile ID after {MAX_ATTEMPTS} attempts\")\n-    \n-    def get_batch_mappings(self, uuid_list: list, entity_type: str = \"product\") -> Dict[str, int]:\n+\n+        raise ValueError(\n+            f\"Unable to generate non-colliding mobile ID after {MAX_ATTEMPTS} attempts\"\n+        )\n+\n+    def get_batch_mappings(\n+        self, uuid_list: list, entity_type: str = \"product\"\n+    ) -> Dict[str, int]:\n         \"\"\"\n         Get mobile IDs for a batch of UUIDs (optimized for bulk operations)\n-        \n+\n         Args:\n             uuid_list: List of UUID strings\n             entity_type: Entity type\n-            \n+\n         Returns:\n             Dictionary mapping UUID to mobile ID\n         \"\"\"\n         try:\n             result = {}\n             uncached_uuids = []\n-            \n+\n             # Check cache for existing mappings\n             for uuid_str in uuid_list:\n                 cache_key = f\"{entity_type}:{uuid_str}\"\n                 if cache_key in self._cache:\n                     result[uuid_str] = self._cache[cache_key]\n                 else:\n                     uncached_uuids.append(uuid_str)\n-            \n+\n             if not uncached_uuids:\n                 return result\n-            \n+\n             # Batch fetch from database\n-            existing_mappings = self.db.query(MobileIDMapping).filter(\n-                MobileIDMapping.uuid_id.in_(uncached_uuids),\n-                MobileIDMapping.entity_type == entity_type\n-            ).all()\n-            \n+            existing_mappings = (\n+                self.db.query(MobileIDMapping)\n+                .filter(\n+                    MobileIDMapping.uuid_id.in_(uncached_uuids),\n+                    MobileIDMapping.entity_type == entity_type,\n+                )\n+                .all()\n+            )\n+\n             # Process existing mappings\n             found_uuids = set()\n             for mapping in existing_mappings:\n                 result[mapping.uuid_id] = mapping.mobile_id\n                 cache_key = f\"{entity_type}:{mapping.uuid_id}\"\n                 self._cache[cache_key] = mapping.mobile_id\n                 found_uuids.add(mapping.uuid_id)\n-            \n+\n             # Generate new mappings for missing UUIDs\n             missing_uuids = [u for u in uncached_uuids if u not in found_uuids]\n-            \n+\n             if missing_uuids:\n                 new_mappings = []\n                 for uuid_str in missing_uuids:\n                     mobile_id = self._generate_mobile_id(uuid_str, entity_type)\n                     result[uuid_str] = mobile_id\n-                    \n-                    new_mappings.append(MobileIDMapping(\n-                        uuid_id=uuid_str,\n-                        mobile_id=mobile_id,\n-                        entity_type=entity_type\n-                    ))\n-                    \n+\n+                    new_mappings.append(\n+                        MobileIDMapping(\n+                            uuid_id=uuid_str,\n+                            mobile_id=mobile_id,\n+                            entity_type=entity_type,\n+                        )\n+                    )\n+\n                     cache_key = f\"{entity_type}:{uuid_str}\"\n                     self._cache[cache_key] = mobile_id\n-                \n+\n                 # Batch insert new mappings\n                 if new_mappings:\n                     self.db.add_all(new_mappings)\n                     self.db.commit()\n                     logger.info(f\"Generated {len(new_mappings)} new mobile ID mappings\")\n-            \n+\n             return result\n-            \n+\n         except Exception as e:\n             logger.error(f\"Failed to get batch mobile ID mappings: {str(e)}\")\n             raise ValueError(f\"Batch mapping failed: {str(e)}\")\n-    \n+\n     def clear_cache(self):\n         \"\"\"Clear in-memory cache\"\"\"\n         self._cache.clear()\n         logger.info(\"Mobile ID mapping cache cleared\")\n-    \n+\n     def get_stats(self) -> Dict[str, Any]:\n         \"\"\"Get statistics about mobile ID mappings\"\"\"\n         try:\n             total_mappings = self.db.query(MobileIDMapping).count()\n-            \n+\n             entity_counts = {}\n-            entity_results = self.db.query(\n-                MobileIDMapping.entity_type,\n-                func.count(MobileIDMapping.entity_type)\n-            ).group_by(MobileIDMapping.entity_type).all()\n-            \n+            entity_results = (\n+                self.db.query(\n+                    MobileIDMapping.entity_type, func.count(MobileIDMapping.entity_type)\n+                )\n+                .group_by(MobileIDMapping.entity_type)\n+                .all()\n+            )\n+\n             for entity_type, count in entity_results:\n                 entity_counts[entity_type] = count\n-            \n+\n             return {\n                 \"total_mappings\": total_mappings,\n                 \"entity_counts\": entity_counts,\n                 \"cache_size\": len(self._cache),\n-                \"id_range\": {\n-                    \"min\": self.MIN_MOBILE_ID,\n-                    \"max\": self.MAX_MOBILE_ID\n-                }\n+                \"id_range\": {\"min\": self.MIN_MOBILE_ID, \"max\": self.MAX_MOBILE_ID},\n             }\n-            \n+\n         except Exception as e:\n             logger.error(f\"Failed to get mobile ID mapping stats: {str(e)}\")\n             return {\"error\": str(e)}\n+\n \n # Create tables\n def create_mobile_id_tables():\n     \"\"\"Create mobile ID mapping tables\"\"\"\n     try:\n@@ -306,11 +336,15 @@\n         logger.info(\"Mobile ID mapping tables created successfully\")\n     except Exception as e:\n         logger.error(f\"Failed to create mobile ID mapping tables: {str(e)}\")\n         raise\n \n+\n # Global service instance\n _mobile_id_service = None\n \n-def get_mobile_id_service(db: Session, redis: Optional[RedisClient] = None) -> MobileIDService:\n+\n+def get_mobile_id_service(\n+    db: Session, redis: Optional[RedisClient] = None\n+) -> MobileIDService:\n     \"\"\"Get mobile ID service instance\"\"\"\n-    return MobileIDService(db, redis)\n\\ No newline at end of file\n+    return MobileIDService(db, redis)\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/mobile_middleware.py\t2025-08-01 23:08:38.303265+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/mobile_middleware.py\t2025-08-02 22:36:03.288938+00:00\n@@ -9,194 +9,201 @@\n import json\n import logging\n \n logger = logging.getLogger(__name__)\n \n+\n class MobileCompatibilityMiddleware(BaseHTTPMiddleware):\n     \"\"\"\n     Middleware to handle mobile app compatibility requirements\n     \"\"\"\n-    \n-    def __init__(self, app, enable_cors: bool = True, enable_port_redirect: bool = True):\n+\n+    def __init__(\n+        self, app, enable_cors: bool = True, enable_port_redirect: bool = True\n+    ):\n         super().__init__(app)\n         self.enable_cors = enable_cors\n         self.enable_port_redirect = enable_port_redirect\n-    \n+\n     async def dispatch(self, request: Request, call_next: Callable) -> Response:\n         \"\"\"\n         Process mobile-specific request handling\n         \"\"\"\n         # Add mobile-friendly headers\n         if self.is_mobile_request(request):\n             # Log mobile requests for monitoring\n             logger.info(f\"Mobile request: {request.method} {request.url.path}\")\n-        \n+\n         # Process request\n         response = await call_next(request)\n-        \n+\n         # Add mobile-friendly response headers\n         if self.enable_cors:\n             self.add_cors_headers(response, request)\n-        \n+\n         # Add mobile-specific headers\n         self.add_mobile_headers(response, request)\n-        \n-        return response\n-    \n+\n+        return response\n+\n     def is_mobile_request(self, request: Request) -> bool:\n         \"\"\"\n         Detect if request is from mobile app\n         \"\"\"\n         user_agent = request.headers.get(\"user-agent\", \"\").lower()\n-        mobile_indicators = [\n-            \"ios\",\n-            \"iphone\",\n-            \"ipad\",\n-            \"fynlo\",\n-            \"react-native\",\n-            \"mobile\"\n-        ]\n-        \n+        mobile_indicators = [\"ios\", \"iphone\", \"ipad\", \"fynlo\", \"react-native\", \"mobile\"]\n+\n         return any(indicator in user_agent for indicator in mobile_indicators)\n-    \n+\n     def add_cors_headers(self, response: Response, request: Request):\n         \"\"\"\n         Add CORS headers for mobile app requests\n         \"\"\"\n         # Allow all origins for development (restrict in production)\n         response.headers[\"Access-Control-Allow-Origin\"] = \"*\"\n-        response.headers[\"Access-Control-Allow-Methods\"] = \"GET, POST, PUT, DELETE, OPTIONS\"\n-        response.headers[\"Access-Control-Allow-Headers\"] = \"Content-Type, Authorization, X-Requested-With\"\n+        response.headers[\"Access-Control-Allow-Methods\"] = (\n+            \"GET, POST, PUT, DELETE, OPTIONS\"\n+        )\n+        response.headers[\"Access-Control-Allow-Headers\"] = (\n+            \"Content-Type, Authorization, X-Requested-With\"\n+        )\n         response.headers[\"Access-Control-Allow-Credentials\"] = \"true\"\n         response.headers[\"Access-Control-Max-Age\"] = \"3600\"\n-    \n+\n     def add_mobile_headers(self, response: Response, request: Request):\n         \"\"\"\n         Add mobile-specific headers\n         \"\"\"\n         if self.is_mobile_request(request):\n             response.headers[\"X-Mobile-Optimized\"] = \"true\"\n             response.headers[\"X-API-Version\"] = \"1.0\"\n-            response.headers[\"X-Cache-Control\"] = \"public, max-age=300\"  # 5 minutes cache\n-        \n+            response.headers[\"X-Cache-Control\"] = (\n+                \"public, max-age=300\"  # 5 minutes cache\n+            )\n+\n         # Add JSON content type for consistency\n         if not response.headers.get(\"content-type\"):\n             response.headers[\"Content-Type\"] = \"application/json\"\n \n+\n class JSONRPCCompatibilityMiddleware(BaseHTTPMiddleware):\n     \"\"\"\n     Middleware to handle JSONRPC requests for Odoo compatibility\n     \"\"\"\n-    \n+\n     async def dispatch(self, request: Request, call_next: Callable) -> Response:\n         \"\"\"\n         Handle JSONRPC format requests\n         \"\"\"\n         # Check if this is a JSONRPC request\n         if self.is_jsonrpc_request(request):\n             # Transform JSONRPC to REST format\n             request = await self.transform_jsonrpc_request(request)\n-        \n+\n         response = await call_next(request)\n-        \n+\n         # Transform response back to JSONRPC format if needed\n         if self.is_jsonrpc_request(request):\n             response = await self.transform_to_jsonrpc_response(response)\n-        \n-        return response\n-    \n+\n+        return response\n+\n     def is_jsonrpc_request(self, request: Request) -> bool:\n         \"\"\"\n         Detect JSONRPC requests\n         \"\"\"\n         content_type = request.headers.get(\"content-type\", \"\")\n-        return (\n-            \"application/json\" in content_type and\n-            request.url.path.startswith(\"/web/\")\n-        )\n-    \n+        return \"application/json\" in content_type and request.url.path.startswith(\n+            \"/web/\"\n+        )\n+\n     async def transform_jsonrpc_request(self, request: Request) -> Request:\n         \"\"\"\n         Transform JSONRPC request to REST format\n         \"\"\"\n         # This is a simplified transformation\n         # In a full implementation, you'd parse the JSONRPC structure\n         return request\n-    \n+\n     async def transform_to_jsonrpc_response(self, response: Response) -> Response:\n         \"\"\"\n         Transform REST response to JSONRPC format\n         \"\"\"\n         # This is a simplified transformation\n         # In a full implementation, you'd wrap the response in JSONRPC structure\n         return response\n \n+\n class MobileDataOptimizationMiddleware(BaseHTTPMiddleware):\n     \"\"\"\n     Middleware to optimize data payloads for mobile devices\n     \"\"\"\n-    \n+\n     async def dispatch(self, request: Request, call_next: Callable) -> Response:\n         \"\"\"\n         Optimize responses for mobile bandwidth\n         \"\"\"\n         response = await call_next(request)\n-        \n+\n         # Only optimize for mobile requests\n         if not self.is_mobile_request(request):\n             return response\n-        \n+\n         # Optimize response if it's JSON\n         if self.is_json_response(response):\n             response = await self.optimize_json_response(response, request)\n-        \n-        return response\n-    \n+\n+        return response\n+\n     def is_mobile_request(self, request: Request) -> bool:\n         \"\"\"\n         Detect mobile requests\n         \"\"\"\n         user_agent = request.headers.get(\"user-agent\", \"\").lower()\n-        return any(indicator in user_agent for indicator in [\"ios\", \"mobile\", \"react-native\"])\n-    \n+        return any(\n+            indicator in user_agent for indicator in [\"ios\", \"mobile\", \"react-native\"]\n+        )\n+\n     def is_json_response(self, response: Response) -> bool:\n         \"\"\"\n         Check if response is JSON\n         \"\"\"\n         content_type = response.headers.get(\"content-type\", \"\")\n         return \"application/json\" in content_type\n-    \n-    async def optimize_json_response(self, response: Response, request: Request) -> Response:\n+\n+    async def optimize_json_response(\n+        self, response: Response, request: Request\n+    ) -> Response:\n         \"\"\"\n         Optimize JSON response for mobile\n         \"\"\"\n         try:\n             # Get response body\n             body = b\"\".join([chunk async for chunk in response.body_iterator])\n-            \n+\n             if not body:\n                 return response\n-            \n+\n             # Parse JSON\n             data = json.loads(body.decode())\n-            \n+\n             # Apply mobile optimizations\n             optimized_data = self.apply_mobile_optimizations(data, request)\n-            \n+\n             # Create new response with optimized data\n-            optimized_body = json.dumps(optimized_data, separators=(',', ':')).encode()\n-            \n+            optimized_body = json.dumps(optimized_data, separators=(\",\", \":\")).encode()\n+\n             # Update response\n             response.headers[\"content-length\"] = str(len(optimized_body))\n             response.body_iterator = iter([optimized_body])\n-            \n+\n             return response\n-            \n+\n         except Exception as e:\n             logger.warning(f\"Failed to optimize response for mobile: {e}\")\n             return response\n-    \n+\n     def apply_mobile_optimizations(self, data: dict, request: Request) -> dict:\n         \"\"\"\n         Apply mobile-specific optimizations to response data\n         \"\"\"\n         # Remove null values to reduce payload size\n@@ -207,50 +214,59 @@\n                     if isinstance(value, (dict, list)):\n                         optimized[key] = self.apply_mobile_optimizations(value, request)\n                     else:\n                         optimized[key] = value\n             return optimized\n-        \n+\n         elif isinstance(data, list):\n             return [\n-                self.apply_mobile_optimizations(item, request) if isinstance(item, (dict, list))\n-                else item\n-                for item in data if item is not None\n+                (\n+                    self.apply_mobile_optimizations(item, request)\n+                    if isinstance(item, (dict, list))\n+                    else item\n+                )\n+                for item in data\n+                if item is not None\n             ]\n-        \n+\n         return data\n+\n \n # Utility functions for mobile compatibility\n def get_client_info(request: Request) -> dict:\n     \"\"\"\n     Extract client information from request headers\n     \"\"\"\n     user_agent = request.headers.get(\"user-agent\", \"\")\n-    \n+\n     return {\n         \"user_agent\": user_agent,\n-        \"is_mobile\": any(indicator in user_agent.lower() for indicator in [\"ios\", \"mobile\", \"react-native\"]),\n+        \"is_mobile\": any(\n+            indicator in user_agent.lower()\n+            for indicator in [\"ios\", \"mobile\", \"react-native\"]\n+        ),\n         \"ip_address\": request.client.host if request.client else None,\n         \"accept_language\": request.headers.get(\"accept-language\", \"en-US\"),\n         \"app_version\": request.headers.get(\"x-app-version\"),\n-        \"device_id\": request.headers.get(\"x-device-id\")\n+        \"device_id\": request.headers.get(\"x-device-id\"),\n     }\n \n+\n def is_feature_enabled_for_client(feature: str, request: Request) -> bool:\n     \"\"\"\n     Check if a feature is enabled for the requesting client\n     \"\"\"\n     client_info = get_client_info(request)\n-    \n+\n     # Feature flags based on client type\n     mobile_features = {\n         \"offline_mode\": True,\n         \"push_notifications\": True,\n         \"image_optimization\": True,\n         \"reduced_payloads\": True,\n-        \"background_sync\": True\n+        \"background_sync\": True,\n     }\n-    \n+\n     if client_info[\"is_mobile\"]:\n         return mobile_features.get(feature, False)\n-    \n-    return True  # All features enabled for web clients\n\\ No newline at end of file\n+\n+    return True  # All features enabled for web clients\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/onboarding_helper.py\t2025-08-02 10:59:17.991938+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/onboarding_helper.py\t2025-08-02 22:36:03.289607+00:00\n@@ -8,188 +8,188 @@\n from app.core.database import User\n \n \n class OnboardingHelper:\n     \"\"\"Helper class for handling onboarding users gracefully\"\"\"\n-    \n+\n     @staticmethod\n     def check_onboarding_required(user: Optional[User]) -> bool:\n         \"\"\"Check if user needs onboarding\"\"\"\n         if not user:\n             return False\n         return not user.restaurant_id\n-    \n+\n     @staticmethod\n     def get_empty_response(resource_type: str) -> Dict[str, Any]:\n         \"\"\"Get appropriate empty response for onboarding users\"\"\"\n-        \n+\n         responses = {\n             \"menu_items\": {\n                 \"data\": [],\n                 \"message\": \"Complete onboarding to add menu items\",\n-                \"onboarding_required\": True\n+                \"onboarding_required\": True,\n             },\n             \"orders\": {\n                 \"data\": [],\n                 \"message\": \"No orders yet - complete onboarding to start taking orders\",\n-                \"onboarding_required\": True\n+                \"onboarding_required\": True,\n             },\n             \"reports\": {\n-                \"data\": {\n-                    \"total_sales\": 0,\n-                    \"total_orders\": 0,\n-                    \"average_order_value\": 0\n-                },\n+                \"data\": {\"total_sales\": 0, \"total_orders\": 0, \"average_order_value\": 0},\n                 \"message\": \"Complete onboarding to view reports\",\n-                \"onboarding_required\": True\n+                \"onboarding_required\": True,\n             },\n             \"employees\": {\n                 \"data\": [],\n                 \"message\": \"Add employees during onboarding\",\n-                \"onboarding_required\": True\n+                \"onboarding_required\": True,\n             },\n             \"tables\": {\n                 \"data\": [],\n                 \"message\": \"Set up tables after completing onboarding\",\n-                \"onboarding_required\": True\n+                \"onboarding_required\": True,\n             },\n             \"inventory\": {\n                 \"data\": [],\n                 \"message\": \"Inventory management available after onboarding\",\n-                \"onboarding_required\": True\n+                \"onboarding_required\": True,\n             },\n             \"settings\": {\n-                \"data\": {\n-                    \"restaurant\": None,\n-                    \"preferences\": {},\n-                    \"features\": []\n-                },\n+                \"data\": {\"restaurant\": None, \"preferences\": {}, \"features\": []},\n                 \"message\": \"Complete onboarding to configure settings\",\n-                \"onboarding_required\": True\n-            }\n+                \"onboarding_required\": True,\n+            },\n         }\n-        \n-        return responses.get(resource_type, {\n-            \"data\": None,\n-            \"message\": \"Please complete onboarding to access this feature\",\n-            \"onboarding_required\": True\n-        })\n-    \n+\n+        return responses.get(\n+            resource_type,\n+            {\n+                \"data\": None,\n+                \"message\": \"Please complete onboarding to access this feature\",\n+                \"onboarding_required\": True,\n+            },\n+        )\n+\n     @staticmethod\n-    def handle_onboarding_response(user: Optional[User], resource_type: str, \n-                                   endpoint_requires_restaurant: bool = True):\n+    def handle_onboarding_response(\n+        user: Optional[User],\n+        resource_type: str,\n+        endpoint_requires_restaurant: bool = True,\n+    ):\n         \"\"\"\n         Handle API response for onboarding users\n-        \n+\n         Args:\n             user: Current user\n             resource_type: Type of resource being accessed\n             endpoint_requires_restaurant: Whether endpoint absolutely requires restaurant\n-            \n+\n         Returns:\n             APIResponse or None (if user has restaurant)\n         \"\"\"\n         if not user:\n             return APIResponseHelper.error(\n-                message=\"Authentication required\",\n-                status_code=401\n+                message=\"Authentication required\", status_code=401\n             )\n-        \n+\n         if user.restaurant_id:\n             # User has restaurant, proceed normally\n             return None\n-        \n+\n         if endpoint_requires_restaurant:\n             # Endpoint requires restaurant but user doesn't have one\n             empty_response = OnboardingHelper.get_empty_response(resource_type)\n             return APIResponseHelper.success(\n                 data=empty_response.get(\"data\"),\n                 message=empty_response.get(\"message\"),\n-                extra_fields={\"onboarding_required\": True}\n+                extra_fields={\"onboarding_required\": True},\n             )\n-        \n+\n         # Endpoint doesn't require restaurant, proceed normally\n         return None\n-    \n+\n     @staticmethod\n     def get_onboarding_tips(current_step: int) -> Dict[str, Any]:\n         \"\"\"Get helpful tips for current onboarding step\"\"\"\n-        \n+\n         tips = {\n             1: {\n                 \"title\": \"Restaurant Information\",\n                 \"tips\": [\n                     \"Choose a clear, memorable restaurant name\",\n                     \"Select the business type that best describes your establishment\",\n-                    \"The display name will appear on receipts and the POS interface\"\n-                ]\n+                    \"The display name will appear on receipts and the POS interface\",\n+                ],\n             },\n             2: {\n                 \"title\": \"Contact Details\",\n                 \"tips\": [\n                     \"Provide accurate contact information for customer inquiries\",\n                     \"This email will receive important platform notifications\",\n-                    \"Include country code for international phone numbers\"\n-                ]\n+                    \"Include country code for international phone numbers\",\n+                ],\n             },\n             3: {\n                 \"title\": \"Location\",\n                 \"tips\": [\n                     \"Enter your complete address for delivery services\",\n                     \"Accurate location helps with local SEO\",\n-                    \"This address appears on customer receipts\"\n-                ]\n+                    \"This address appears on customer receipts\",\n+                ],\n             },\n             4: {\n                 \"title\": \"Owner Information\",\n                 \"tips\": [\n                     \"Owner details are kept private and secure\",\n                     \"Used for account recovery and important communications\",\n-                    \"Required for legal and tax purposes\"\n-                ]\n+                    \"Required for legal and tax purposes\",\n+                ],\n             },\n             5: {\n                 \"title\": \"Business Hours\",\n                 \"tips\": [\n                     \"Set accurate hours for each day of the week\",\n                     \"You can update these anytime from settings\",\n-                    \"Consider peak hours when setting schedules\"\n-                ]\n+                    \"Consider peak hours when setting schedules\",\n+                ],\n             },\n             6: {\n                 \"title\": \"Team Setup\",\n                 \"tips\": [\n                     \"Add key team members who will use the POS\",\n                     \"Set appropriate access levels for security\",\n-                    \"You can add more employees later\"\n-                ]\n+                    \"You can add more employees later\",\n+                ],\n             },\n             7: {\n                 \"title\": \"Menu Creation\",\n                 \"tips\": [\n                     \"Start with your most popular items\",\n                     \"Organize items into logical categories\",\n-                    \"You can add photos and descriptions later\"\n-                ]\n+                    \"You can add photos and descriptions later\",\n+                ],\n             },\n             8: {\n                 \"title\": \"Payment Details\",\n                 \"tips\": [\n                     \"Enter bank details to receive payments\",\n                     \"All information is encrypted and secure\",\n-                    \"Payments are processed weekly on Fridays\"\n-                ]\n+                    \"Payments are processed weekly on Fridays\",\n+                ],\n             },\n             9: {\n                 \"title\": \"Review & Launch\",\n                 \"tips\": [\n                     \"Review all information carefully\",\n                     \"You can edit details later in settings\",\n-                    \"After completion, you're ready to take orders!\"\n-                ]\n-            }\n+                    \"After completion, you're ready to take orders!\",\n+                ],\n+            },\n         }\n-        \n-        return tips.get(current_step, {\n-            \"title\": \"Getting Started\",\n-            \"tips\": [\"Complete each step to set up your restaurant\"]\n-        })\n\\ No newline at end of file\n+\n+        return tips.get(\n+            current_step,\n+            {\n+                \"title\": \"Getting Started\",\n+                \"tips\": [\"Complete each step to set up your restaurant\"],\n+            },\n+        )\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/payments.py\t2025-08-02 21:56:58.987204+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/payments.py\t2025-08-02 22:36:03.282268+00:00\n@@ -18,11 +18,18 @@\n \n from app.core.database import get_db, Payment, QRPayment, Order, User\n from app.core.config import settings\n from app.core.auth import get_current_user\n from app.core.responses import APIResponseHelper\n-from app.core.exceptions import FynloException, InventoryException, PaymentException, ResourceNotFoundException, ValidationException, BusinessLogicException\n+from app.core.exceptions import (\n+    FynloException,\n+    InventoryException,\n+    PaymentException,\n+    ResourceNotFoundException,\n+    ValidationException,\n+    BusinessLogicException,\n+)\n from app.core.transaction_manager import transactional\n from app.core.tenant_security import TenantSecurity\n from app.services.payment_factory import payment_factory\n from app.services.audit_logger import AuditLoggerService\n from app.models.audit_log import AuditEventType, AuditEventStatus\n@@ -32,14 +39,16 @@\n logger = logging.getLogger(__name__)\n \n # Configure Stripe\n stripe.api_key = settings.STRIPE_SECRET_KEY\n \n+\n # Pydantic models\n class QRPaymentRequest(BaseModel):\n     order_id: str\n     amount: float\n+\n \n class QRPaymentResponse(BaseModel):\n     qr_payment_id: str\n     qr_code_data: str\n     qr_code_image: str  # Base64 encoded QR code\n@@ -47,106 +56,121 @@\n     fee_amount: float\n     net_amount: float\n     expires_at: datetime\n     status: str\n \n+\n class StripePaymentRequest(BaseModel):\n     order_id: str\n     amount: float\n     payment_method_id: str\n     currency: str = \"gbp\"\n+\n \n class PaymentResponse(BaseModel):\n     payment_id: str\n     status: str\n     amount: float\n     fee_amount: float\n     net_amount: float\n     external_id: Optional[str] = None\n \n+\n class CashPaymentRequest(BaseModel):\n     order_id: str\n     amount: float\n     received_amount: float\n     change_amount: float = 0.0\n+\n \n # New multi-provider payment models\n class PaymentRequest(BaseModel):\n     order_id: str\n     amount: float\n     customer_id: Optional[str] = None\n     payment_method_id: Optional[str] = None\n     currency: str = \"GBP\"\n     metadata: Optional[dict] = None\n \n+\n class RefundRequest(BaseModel):\n     transaction_id: str\n     amount: Optional[float] = None\n     reason: Optional[str] = None\n+\n \n class ProviderInfo(BaseModel):\n     name: str\n     display_name: str\n     sample_fees: dict\n     rate: str\n     monthly_fee: Optional[str] = None\n     recommended: bool = False\n+\n \n def calculate_payment_fee(amount: float, payment_method: str) -> float:\n     \"\"\"Calculate payment processing fees\"\"\"\n     if payment_method == \"qr_code\":\n         return amount * (settings.QR_PAYMENT_FEE_PERCENTAGE / 100)\n     elif payment_method in [\"card\", \"apple_pay\", \"google_pay\"]:\n         return amount * (settings.DEFAULT_CARD_FEE_PERCENTAGE / 100)\n     else:  # cash, gift_card\n         return 0.0\n \n+\n def generate_qr_code(data: str) -> str:\n     \"\"\"Generate QR code and return as base64 encoded image\"\"\"\n     qr = qrcode.QRCode(\n         version=1,\n         error_correction=qrcode.constants.ERROR_CORRECT_L,\n         box_size=10,\n-        border=4)\n+        border=4,\n+    )\n     qr.add_data(data)\n     qr.make(fit=True)\n-    \n+\n     img = qr.make_image(fill_color=\"black\", back_color=\"white\")\n-    \n+\n     # Convert to base64\n     img_buffer = io.BytesIO()\n-    img.save(img_buffer, format='PNG')\n+    img.save(img_buffer, format=\"PNG\")\n     img_str = base64.b64encode(img_buffer.getvalue()).decode()\n-    \n+\n     return f\"data:image/png;base64,{img_str}\"\n+\n \n # Rate limited: 5 requests per minute per IP\n @router.post(\"/qr/generate\", response_model=QRPaymentResponse)\n @limiter.limit(PAYMENT_RATE)\n async def generate_qr_payment(\n-    payment_request: QRPaymentRequest, # Renamed from 'request' to avoid conflict\n-    request: Request, # Added for rate limiter\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Restaurant ID for multi-location owners\"),\n+    payment_request: QRPaymentRequest,  # Renamed from 'request' to avoid conflict\n+    request: Request,  # Added for rate limiter\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Restaurant ID for multi-location owners\"\n+    ),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Generate QR code for payment with 1.2% fee advantage\"\"\"\n     # Validate restaurant access for multi-tenant\n     await TenantSecurity.validate_restaurant_access(\n         current_user, current_restaurant_id or current_user.restaurant_id, db=db\n     )\n     restaurant_id = current_restaurant_id or current_user.restaurant_id\n-    \n+\n     audit_service = AuditLoggerService(db)\n     ip_address = request.client.host if request.client else \"unknown\"\n     user_agent = request.headers.get(\"user-agent\", \"unknown\")\n \n     # Verify order exists and belongs to the restaurant\n-    order = db.query(Order).filter(\n-        Order.id == payment_request.order_id,\n-        Order.restaurant_id == restaurant_id\n-    ).first()\n+    order = (\n+        db.query(Order)\n+        .filter(\n+            Order.id == payment_request.order_id, Order.restaurant_id == restaurant_id\n+        )\n+        .first()\n+    )\n     if not order:\n         # Log attempt to generate QR for non-existent order?\n         # This might be more of a validation error than a payment initiation failure.\n         # For now, let's assume this is handled by exception handler.\n         # If we wanted to log it:\n@@ -160,296 +184,378 @@\n         #     user_agent=user_agent,\n         #     details={\"order_id\": payment_request.order_id, \"amount\": payment_request.amount, \"reason\": \"Order not found\"},\n         #     commit=True\n         # )\n         raise ResourceNotFoundException(resource=\"Order\")\n-    \n+\n     # Calculate fees\n     fee_amount = calculate_payment_fee(payment_request.amount, \"qr_code\")\n     net_amount = payment_request.amount - fee_amount\n-    \n+\n     # Generate unique payment data\n     # This payment_id is for the QR data, not the final Payment record\n     internal_qr_payment_id = str(uuid.uuid4())\n     payment_data_for_qr = {\n-        \"payment_id\": internal_qr_payment_id, # This ID is embedded in the QR\n+        \"payment_id\": internal_qr_payment_id,  # This ID is embedded in the QR\n         \"order_id\": payment_request.order_id,\n         \"amount\": payment_request.amount,\n-        \"merchant\": \"Fynlo POS\", # Consider making this dynamic if needed\n-        \"timestamp\": datetime.utcnow().isoformat()\n+        \"merchant\": \"Fynlo POS\",  # Consider making this dynamic if needed\n+        \"timestamp\": datetime.utcnow().isoformat(),\n     }\n-    \n+\n     # Create QR payment record in DB (tracks the QR code itself)\n     qr_payment_db_record = QRPayment(\n         order_id=payment_request.order_id,\n-        qr_code_data=str(payment_data_for_qr), # Storing the data that went into QR\n+        qr_code_data=str(payment_data_for_qr),  # Storing the data that went into QR\n         amount=payment_request.amount,\n         fee_amount=fee_amount,\n         net_amount=net_amount,\n-        expires_at=datetime.utcnow() + timedelta(minutes=15)  # 15-minute expiry\n-    )\n-    \n+        expires_at=datetime.utcnow() + timedelta(minutes=15),  # 15-minute expiry\n+    )\n+\n     db.add(qr_payment_db_record)\n \n     await audit_service.create_audit_log(\n         event_type=AuditEventType.PAYMENT_INITIATED,\n-        event_status=AuditEventStatus.SUCCESS, # Successfully initiated by generating QR\n+        event_status=AuditEventStatus.SUCCESS,  # Successfully initiated by generating QR\n         action_performed=\"QR payment initiated by generating QR code.\",\n         user_id=current_user.id,\n         username_or_email=current_user.email,\n         ip_address=ip_address,\n         user_agent=user_agent,\n         resource_type=\"QRPayment\",\n-        resource_id=str(qr_payment_db_record.id), # ID of the QRPayment table entry\n+        resource_id=str(qr_payment_db_record.id),  # ID of the QRPayment table entry\n         details={\n             \"order_id\": payment_request.order_id,\n             \"amount\": payment_request.amount,\n             \"payment_method\": \"qr_code\",\n-            \"qr_internal_id\": internal_qr_payment_id # The ID embedded in QR\n+            \"qr_internal_id\": internal_qr_payment_id,  # The ID embedded in QR\n         },\n-        commit=False # Will be committed with qr_payment_db_record\n+        commit=False,  # Will be committed with qr_payment_db_record\n     )\n \n     db.commit()\n     db.refresh(qr_payment_db_record)\n-    \n+\n     # Generate QR code image using the data that includes the internal_qr_payment_id\n     qr_code_image = generate_qr_code(str(payment_data_for_qr))\n-    \n-    logger.info(f\"QR payment generated: {qr_payment_db_record.id} for order {payment_request.order_id}\")\n-    \n+\n+    logger.info(\n+        f\"QR payment generated: {qr_payment_db_record.id} for order {payment_request.order_id}\"\n+    )\n+\n     return QRPaymentResponse(\n         qr_payment_id=str(qr_payment_db_record.id),\n         qr_code_data=qr_payment_db_record.qr_code_data,\n         qr_code_image=qr_code_image,\n         amount=qr_payment_db_record.amount,\n         fee_amount=qr_payment_db_record.fee_amount,\n         net_amount=qr_payment_db_record.net_amount,\n         expires_at=qr_payment_db_record.expires_at,\n-        status=qr_payment_db_record.status\n-    )\n+        status=qr_payment_db_record.status,\n+    )\n+\n \n @router.post(\"/qr/{qr_payment_id}/confirm\")\n @transactional(max_retries=3, retry_delay=0.1)\n async def confirm_qr_payment(\n     request: Request,\n     qr_payment_id: str,\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Restaurant ID for multi-location owners\"),\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Restaurant ID for multi-location owners\"\n+    ),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Confirm QR payment completion\"\"\"\n     # Validate restaurant access for multi-tenant\n     await TenantSecurity.validate_restaurant_access(\n         current_user, current_restaurant_id or current_user.restaurant_id, db=db\n     )\n     restaurant_id = current_restaurant_id or current_user.restaurant_id\n-    \n+\n     audit_service = AuditLoggerService(db)\n     ip_address = request.client.host if request.client else \"unknown\"\n     user_agent = request.headers.get(\"user-agent\", \"unknown\")\n-    \n-    qr_payment_db_record = db.query(QRPayment).filter(QRPayment.id == qr_payment_id).first()\n+\n+    qr_payment_db_record = (\n+        db.query(QRPayment).filter(QRPayment.id == qr_payment_id).first()\n+    )\n     if not qr_payment_db_record:\n         # Log this attempt, then raise\n         await audit_service.create_audit_log(\n             event_type=AuditEventType.PAYMENT_FAILURE,\n             event_status=AuditEventStatus.FAILURE,\n             action_performed=\"QR payment confirmation failed: QR payment record not found.\",\n-            user_id=current_user.id, username_or_email=current_user.email,\n-            ip_address=ip_address, user_agent=user_agent,\n-            resource_type=\"QRPayment\", resource_id=qr_payment_id,\n+            user_id=current_user.id,\n+            username_or_email=current_user.email,\n+            ip_address=ip_address,\n+            user_agent=user_agent,\n+            resource_type=\"QRPayment\",\n+            resource_id=qr_payment_id,\n             details={\"reason\": \"QR payment record not found.\"},\n-            commit=True\n-        )\n-        raise ResourceNotFoundException(resource=\"Payment\", message=\"QR payment not found\")\n-    \n+            commit=True,\n+        )\n+        raise ResourceNotFoundException(\n+            resource=\"Payment\", message=\"QR payment not found\"\n+        )\n+\n     if qr_payment_db_record.expires_at < datetime.utcnow():\n         await audit_service.create_audit_log(\n             event_type=AuditEventType.PAYMENT_FAILURE,\n             event_status=AuditEventStatus.FAILURE,\n             action_performed=\"QR payment confirmation failed: QR payment expired.\",\n-            user_id=current_user.id, username_or_email=current_user.email,\n-            ip_address=ip_address, user_agent=user_agent,\n-            resource_type=\"QRPayment\", resource_id=qr_payment_id,\n-            details={\"order_id\": str(qr_payment_db_record.order_id), \"amount\": qr_payment_db_record.amount, \"reason\": \"QR payment expired.\"},\n-            commit=True\n+            user_id=current_user.id,\n+            username_or_email=current_user.email,\n+            ip_address=ip_address,\n+            user_agent=user_agent,\n+            resource_type=\"QRPayment\",\n+            resource_id=qr_payment_id,\n+            details={\n+                \"order_id\": str(qr_payment_db_record.order_id),\n+                \"amount\": qr_payment_db_record.amount,\n+                \"reason\": \"QR payment expired.\",\n+            },\n+            commit=True,\n         )\n         raise PaymentException(message=\"QR payment expired\")\n-    \n+\n     if qr_payment_db_record.status == \"completed\":\n         await audit_service.create_audit_log(\n-            event_type=AuditEventType.PAYMENT_FAILURE, # Or INFO, as it's not a new failure\n+            event_type=AuditEventType.PAYMENT_FAILURE,  # Or INFO, as it's not a new failure\n             event_status=AuditEventStatus.INFO,\n             action_performed=\"QR payment confirmation attempt: Already processed.\",\n-            user_id=current_user.id, username_or_email=current_user.email,\n-            ip_address=ip_address, user_agent=user_agent,\n-            resource_type=\"QRPayment\", resource_id=qr_payment_id,\n-            details={\"order_id\": str(qr_payment_db_record.order_id), \"amount\": qr_payment_db_record.amount, \"reason\": \"QR payment already processed.\"},\n-            commit=True\n+            user_id=current_user.id,\n+            username_or_email=current_user.email,\n+            ip_address=ip_address,\n+            user_agent=user_agent,\n+            resource_type=\"QRPayment\",\n+            resource_id=qr_payment_id,\n+            details={\n+                \"order_id\": str(qr_payment_db_record.order_id),\n+                \"amount\": qr_payment_db_record.amount,\n+                \"reason\": \"QR payment already processed.\",\n+            },\n+            commit=True,\n         )\n         raise PaymentException(message=\"QR payment already processed\")\n-    \n+\n     if qr_payment_db_record.status != \"pending\":\n         await audit_service.create_audit_log(\n             event_type=AuditEventType.PAYMENT_FAILURE,\n             event_status=AuditEventStatus.FAILURE,\n             action_performed=f\"QR payment confirmation failed: Invalid status '{qr_payment_db_record.status}'.\",\n-            user_id=current_user.id, username_or_email=current_user.email,\n-            ip_address=ip_address, user_agent=user_agent,\n-            resource_type=\"QRPayment\", resource_id=qr_payment_id,\n-            details={\"order_id\": str(qr_payment_db_record.order_id), \"amount\": qr_payment_db_record.amount, \"reason\": f\"Cannot confirm QR payment with status: {qr_payment_db_record.status}\"},\n-            commit=True\n-        )\n-        raise ValidationException(message=f\"Cannot confirm QR payment with status: {qr_payment_db_record.status}\")\n-    \n+            user_id=current_user.id,\n+            username_or_email=current_user.email,\n+            ip_address=ip_address,\n+            user_agent=user_agent,\n+            resource_type=\"QRPayment\",\n+            resource_id=qr_payment_id,\n+            details={\n+                \"order_id\": str(qr_payment_db_record.order_id),\n+                \"amount\": qr_payment_db_record.amount,\n+                \"reason\": f\"Cannot confirm QR payment with status: {qr_payment_db_record.status}\",\n+            },\n+            commit=True,\n+        )\n+        raise ValidationException(\n+            message=f\"Cannot confirm QR payment with status: {qr_payment_db_record.status}\"\n+        )\n+\n     # Get order for validation and ensure it belongs to the restaurant\n-    order = db.query(Order).filter(\n-        Order.id == qr_payment_db_record.order_id,\n-        Order.restaurant_id == restaurant_id\n-    ).first()\n+    order = (\n+        db.query(Order)\n+        .filter(\n+            Order.id == qr_payment_db_record.order_id,\n+            Order.restaurant_id == restaurant_id,\n+        )\n+        .first()\n+    )\n     if not order:\n         # This case should ideally not be reached if DB integrity is maintained\n         # but log it defensively if it does.\n         await audit_service.create_audit_log(\n-            event_type=AuditEventType.PAYMENT_FAILURE, event_status=AuditEventStatus.FAILURE,\n+            event_type=AuditEventType.PAYMENT_FAILURE,\n+            event_status=AuditEventStatus.FAILURE,\n             action_performed=\"QR payment confirmation failed: Associated order not found.\",\n-            user_id=current_user.id, username_or_email=current_user.email,\n-            ip_address=ip_address, user_agent=user_agent,\n-            resource_type=\"QRPayment\", resource_id=qr_payment_id,\n-            details={\"order_id\": str(qr_payment_db_record.order_id), \"reason\": \"Associated order not found internally.\"},\n-            commit=True\n-        )\n-        raise ResourceNotFoundException(resource=\"Order\", message=\"Associated order not found\")\n-    \n+            user_id=current_user.id,\n+            username_or_email=current_user.email,\n+            ip_address=ip_address,\n+            user_agent=user_agent,\n+            resource_type=\"QRPayment\",\n+            resource_id=qr_payment_id,\n+            details={\n+                \"order_id\": str(qr_payment_db_record.order_id),\n+                \"reason\": \"Associated order not found internally.\",\n+            },\n+            commit=True,\n+        )\n+        raise ResourceNotFoundException(\n+            resource=\"Order\", message=\"Associated order not found\"\n+        )\n+\n     if order.payment_status == \"completed\":\n         await audit_service.create_audit_log(\n-            event_type=AuditEventType.PAYMENT_FAILURE, event_status=AuditEventStatus.INFO, # Info, as order already paid\n+            event_type=AuditEventType.PAYMENT_FAILURE,\n+            event_status=AuditEventStatus.INFO,  # Info, as order already paid\n             action_performed=\"QR payment confirmation failed: Order already paid.\",\n-            user_id=current_user.id, username_or_email=current_user.email,\n-            ip_address=ip_address, user_agent=user_agent,\n-            resource_type=\"Order\", resource_id=str(order.id),\n-            details={\"qr_payment_id\": qr_payment_id, \"reason\": \"Order already marked as paid.\"},\n-            commit=True\n+            user_id=current_user.id,\n+            username_or_email=current_user.email,\n+            ip_address=ip_address,\n+            user_agent=user_agent,\n+            resource_type=\"Order\",\n+            resource_id=str(order.id),\n+            details={\n+                \"qr_payment_id\": qr_payment_id,\n+                \"reason\": \"Order already marked as paid.\",\n+            },\n+            commit=True,\n         )\n         raise ValidationException(message=\"Order already paid\")\n-    \n-    payment_record = None # To store the created Payment object\n+\n+    payment_record = None  # To store the created Payment object\n     try:\n         # Update QR payment status\n         qr_payment_db_record.status = \"completed\"\n-        \n+\n         # Create payment record\n         payment_record = Payment(\n             order_id=qr_payment_db_record.order_id,\n             payment_method=\"qr_code\",\n             amount=qr_payment_db_record.amount,\n             fee_amount=qr_payment_db_record.fee_amount,\n             net_amount=qr_payment_db_record.net_amount,\n             status=\"completed\",\n             processed_at=datetime.utcnow(),\n-            payment_metadata={\"qr_payment_id\": str(qr_payment_db_record.id)}\n-        )\n-        \n+            payment_metadata={\"qr_payment_id\": str(qr_payment_db_record.id)},\n+        )\n+\n         db.add(payment_record)\n-        \n+\n         # Update order payment status\n         order.payment_status = \"completed\"\n         order.status = \"confirmed\" if order.status == \"pending\" else order.status\n-        \n+\n         # Log success (commit=False due to @transactional)\n         # The flush() within create_audit_log will assign an ID to payment_record\n         await audit_service.create_audit_log(\n             event_type=AuditEventType.PAYMENT_SUCCESS,\n             event_status=AuditEventStatus.SUCCESS,\n             action_performed=\"QR payment confirmed successfully.\",\n-            user_id=current_user.id, username_or_email=current_user.email,\n-            ip_address=ip_address, user_agent=user_agent,\n-            resource_type=\"Payment\", # The main Payment record\n-            resource_id=str(payment_record.id), # Will be set after flush\n+            user_id=current_user.id,\n+            username_or_email=current_user.email,\n+            ip_address=ip_address,\n+            user_agent=user_agent,\n+            resource_type=\"Payment\",  # The main Payment record\n+            resource_id=str(payment_record.id),  # Will be set after flush\n             details={\n                 \"order_id\": str(order.id),\n                 \"qr_payment_id\": qr_payment_id,\n-                \"amount\": payment_record.amount\n+                \"amount\": payment_record.amount,\n             },\n-            commit=False\n+            commit=False,\n         )\n         # Transaction will auto-commit due to @transactional decorator\n-        \n+\n     except Exception as e:\n         # Log failure (commit=False, as @transactional will rollback)\n         # If create_audit_log itself fails, it won't affect the rollback of the main transaction.\n         await audit_service.create_audit_log(\n             event_type=AuditEventType.PAYMENT_FAILURE,\n             event_status=AuditEventStatus.FAILURE,\n             action_performed=\"QR payment confirmation failed during processing.\",\n-            user_id=current_user.id, username_or_email=current_user.email,\n-            ip_address=ip_address, user_agent=user_agent,\n-            resource_type=\"QRPayment\", resource_id=qr_payment_id,\n+            user_id=current_user.id,\n+            username_or_email=current_user.email,\n+            ip_address=ip_address,\n+            user_agent=user_agent,\n+            resource_type=\"QRPayment\",\n+            resource_id=qr_payment_id,\n             details={\"order_id\": str(qr_payment_db_record.order_id), \"error\": str(e)},\n-            commit=False # Will be rolled back by @transactional\n+            commit=False,  # Will be rolled back by @transactional\n         )\n         logger.error(f\"QR payment confirmation failed for {qr_payment_id}: {e}\")\n         raise PaymentException(message=\"Payment confirmation failed\")\n-    \n+\n     logger.info(f\"QR payment confirmed: {qr_payment_id}\")\n-    \n+\n     # The payment_record might not have its ID fully populated here if there was an error\n     # before the flush inside create_audit_log, or if create_audit_log itself failed.\n     # However, the happy path should have it.\n     return APIResponseHelper.success(\n         message=\"QR payment confirmed successfully\",\n-        data={\"payment_id\": str(payment_record.id) if payment_record and payment_record.id else None}\n-    )\n+        data={\n+            \"payment_id\": (\n+                str(payment_record.id) if payment_record and payment_record.id else None\n+            )\n+        },\n+    )\n+\n \n @router.post(\"/stripe\", response_model=PaymentResponse)\n @limiter.limit(PAYMENT_RATE)\n @transactional(max_retries=2, retry_delay=0.2)\n async def process_stripe_payment(\n-    payment_request_data: StripePaymentRequest, # Renamed from 'request'\n-    request: Request, # Added for rate limiter\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Restaurant ID for multi-location owners\"),\n+    payment_request_data: StripePaymentRequest,  # Renamed from 'request'\n+    request: Request,  # Added for rate limiter\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Restaurant ID for multi-location owners\"\n+    ),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Process Stripe payment\"\"\"\n     # Validate restaurant access for multi-tenant\n     await TenantSecurity.validate_restaurant_access(\n         current_user, current_restaurant_id or current_user.restaurant_id, db=db\n     )\n     restaurant_id = current_restaurant_id or current_user.restaurant_id\n-    \n+\n     audit_service = AuditLoggerService(db)\n     ip_address = request.client.host if request.client else \"unknown\"\n     user_agent = request.headers.get(\"user-agent\", \"unknown\")\n \n     # Verify order exists and belongs to the restaurant\n-    order = db.query(Order).filter(\n-        Order.id == payment_request_data.order_id,\n-        Order.restaurant_id == restaurant_id\n-    ).first()\n+    order = (\n+        db.query(Order)\n+        .filter(\n+            Order.id == payment_request_data.order_id,\n+            Order.restaurant_id == restaurant_id,\n+        )\n+        .first()\n+    )\n     if not order:\n         # Log attempt for non-existent order\n         await audit_service.create_audit_log(\n-            event_type=AuditEventType.PAYMENT_FAILURE, event_status=AuditEventStatus.FAILURE,\n+            event_type=AuditEventType.PAYMENT_FAILURE,\n+            event_status=AuditEventStatus.FAILURE,\n             action_performed=\"Stripe payment failed: Order not found.\",\n-            user_id=current_user.id, username_or_email=current_user.email,\n-            ip_address=ip_address, user_agent=user_agent,\n-            details={\"order_id\": payment_request_data.order_id, \"amount\": payment_request_data.amount, \"reason\": \"Order not found\"},\n-            commit=True\n+            user_id=current_user.id,\n+            username_or_email=current_user.email,\n+            ip_address=ip_address,\n+            user_agent=user_agent,\n+            details={\n+                \"order_id\": payment_request_data.order_id,\n+                \"amount\": payment_request_data.amount,\n+                \"reason\": \"Order not found\",\n+            },\n+            commit=True,\n         )\n         raise ResourceNotFoundException(resource=\"Order\")\n \n     if order.payment_status == \"completed\":\n         await audit_service.create_audit_log(\n-            event_type=AuditEventType.PAYMENT_FAILURE, event_status=AuditEventStatus.INFO,\n+            event_type=AuditEventType.PAYMENT_FAILURE,\n+            event_status=AuditEventStatus.INFO,\n             action_performed=\"Stripe payment attempt failed: Order already paid.\",\n-            user_id=current_user.id, username_or_email=current_user.email,\n-            ip_address=ip_address, user_agent=user_agent,\n-            resource_type=\"Order\", resource_id=str(order.id),\n+            user_id=current_user.id,\n+            username_or_email=current_user.email,\n+            ip_address=ip_address,\n+            user_agent=user_agent,\n+            resource_type=\"Order\",\n+            resource_id=str(order.id),\n             details={\"reason\": \"Order already marked as paid.\"},\n-            commit=True\n+            commit=True,\n         )\n         raise ValidationException(message=\"Order already paid\")\n \n     # Calculate fees\n     fee_amount = calculate_payment_fee(payment_request_data.amount, \"card\")\n@@ -460,46 +566,54 @@\n         order_id=payment_request_data.order_id,\n         payment_method=\"stripe\",\n         amount=payment_request_data.amount,\n         fee_amount=fee_amount,\n         net_amount=net_amount,\n-        status=\"pending\", # Initial status\n-        payment_metadata={\"stripe_payment_method_id\": payment_request_data.payment_method_id}\n+        status=\"pending\",  # Initial status\n+        payment_metadata={\n+            \"stripe_payment_method_id\": payment_request_data.payment_method_id\n+        },\n     )\n     db.add(payment_db_record)\n-    db.flush() # Get payment_db_record.id before external API call & audit log\n+    db.flush()  # Get payment_db_record.id before external API call & audit log\n \n     await audit_service.create_audit_log(\n         event_type=AuditEventType.PAYMENT_INITIATED,\n-        event_status=AuditEventStatus.PENDING, # Status is pending as we are about to call Stripe\n+        event_status=AuditEventStatus.PENDING,  # Status is pending as we are about to call Stripe\n         action_performed=\"Stripe payment initiated.\",\n-        user_id=current_user.id, username_or_email=current_user.email,\n-        ip_address=ip_address, user_agent=user_agent,\n-        resource_type=\"Payment\", resource_id=str(payment_db_record.id),\n+        user_id=current_user.id,\n+        username_or_email=current_user.email,\n+        ip_address=ip_address,\n+        user_agent=user_agent,\n+        resource_type=\"Payment\",\n+        resource_id=str(payment_db_record.id),\n         details={\n             \"order_id\": payment_request_data.order_id,\n             \"amount\": payment_request_data.amount,\n-            \"payment_method_id\": payment_request_data.payment_method_id\n+            \"payment_method_id\": payment_request_data.payment_method_id,\n         },\n-        commit=False # Part of the larger transaction\n+        commit=False,  # Part of the larger transaction\n     )\n \n     try:\n         payment_intent = stripe.PaymentIntent.create(\n             amount=int(payment_request_data.amount * 100),  # Stripe uses cents\n             currency=payment_request_data.currency,\n             payment_method=payment_request_data.payment_method_id,\n             metadata={\n                 \"order_id\": str(payment_request_data.order_id),\n                 \"payment_id\": str(payment_db_record.id),\n-                \"restaurant_id\": str(restaurant_id)\n+                \"restaurant_id\": str(restaurant_id),\n             },\n-            confirmation_method='manual',\n-            confirm=True)\n+            confirmation_method=\"manual\",\n+            confirm=True,\n+        )\n \n         payment_db_record.external_id = payment_intent.id\n-        payment_db_record.payment_metadata.update({\"stripe_payment_intent\": payment_intent.id})\n+        payment_db_record.payment_metadata.update(\n+            {\"stripe_payment_intent\": payment_intent.id}\n+        )\n \n         if payment_intent.status == \"succeeded\":\n             payment_db_record.status = \"completed\"\n             payment_db_record.processed_at = datetime.utcnow()\n             order.payment_status = \"completed\"\n@@ -507,928 +621,1329 @@\n \n             await audit_service.create_audit_log(\n                 event_type=AuditEventType.PAYMENT_SUCCESS,\n                 event_status=AuditEventStatus.SUCCESS,\n                 action_performed=\"Stripe payment succeeded.\",\n-                user_id=current_user.id, username_or_email=current_user.email,\n-                ip_address=ip_address, user_agent=user_agent,\n-                resource_type=\"Payment\", resource_id=str(payment_db_record.id),\n+                user_id=current_user.id,\n+                username_or_email=current_user.email,\n+                ip_address=ip_address,\n+                user_agent=user_agent,\n+                resource_type=\"Payment\",\n+                resource_id=str(payment_db_record.id),\n                 details={\n                     \"order_id\": payment_request_data.order_id,\n                     \"stripe_payment_intent_id\": payment_intent.id,\n-                    \"amount\": payment_db_record.amount\n+                    \"amount\": payment_db_record.amount,\n                 },\n-                commit=False\n+                commit=False,\n             )\n         else:\n             payment_db_record.status = \"failed\"\n-            logger.warning(f\"Stripe payment failed for order {payment_request_data.order_id}: {payment_intent.status}\")\n+            logger.warning(\n+                f\"Stripe payment failed for order {payment_request_data.order_id}: {payment_intent.status}\"\n+            )\n             await audit_service.create_audit_log(\n                 event_type=AuditEventType.PAYMENT_FAILURE,\n                 event_status=AuditEventStatus.FAILURE,\n                 action_performed=\"Stripe payment failed by provider.\",\n-                user_id=current_user.id, username_or_email=current_user.email,\n-                ip_address=ip_address, user_agent=user_agent,\n-                resource_type=\"Payment\", resource_id=str(payment_db_record.id),\n+                user_id=current_user.id,\n+                username_or_email=current_user.email,\n+                ip_address=ip_address,\n+                user_agent=user_agent,\n+                resource_type=\"Payment\",\n+                resource_id=str(payment_db_record.id),\n                 details={\n                     \"order_id\": payment_request_data.order_id,\n                     \"stripe_payment_intent_id\": payment_intent.id,\n                     \"stripe_status\": payment_intent.status,\n-                    \"reason\": \"Stripe processing resulted in failure.\"\n+                    \"reason\": \"Stripe processing resulted in failure.\",\n                 },\n-                commit=False\n-            )\n-        \n+                commit=False,\n+            )\n+\n         # Transaction auto-commits on success\n-        db.refresh(payment_db_record) # Refresh before returning\n-        \n-        logger.info(f\"Stripe payment processed: {payment_db_record.id} for order {payment_request_data.order_id}\")\n-        \n+        db.refresh(payment_db_record)  # Refresh before returning\n+\n+        logger.info(\n+            f\"Stripe payment processed: {payment_db_record.id} for order {payment_request_data.order_id}\"\n+        )\n+\n         return PaymentResponse(\n             payment_id=str(payment_db_record.id),\n             status=payment_db_record.status,\n             amount=payment_db_record.amount,\n             fee_amount=payment_db_record.fee_amount,\n             net_amount=payment_db_record.net_amount,\n-            external_id=payment_db_record.external_id\n+            external_id=payment_db_record.external_id,\n         )\n \n     except stripe.error.StripeError as e:\n         payment_db_record.status = \"failed\"\n         payment_db_record.payment_metadata.update({\"stripe_error\": str(e)})\n         await audit_service.create_audit_log(\n             event_type=AuditEventType.PAYMENT_FAILURE,\n             event_status=AuditEventStatus.FAILURE,\n             action_performed=\"Stripe payment failed due to Stripe API error.\",\n-            user_id=current_user.id, username_or_email=current_user.email,\n-            ip_address=ip_address, user_agent=user_agent,\n-            resource_type=\"Payment\", resource_id=str(payment_db_record.id),\n-            details={\"order_id\": payment_request_data.order_id, \"error\": str(e), \"error_type\": e.__class__.__name__},\n-            commit=False\n+            user_id=current_user.id,\n+            username_or_email=current_user.email,\n+            ip_address=ip_address,\n+            user_agent=user_agent,\n+            resource_type=\"Payment\",\n+            resource_id=str(payment_db_record.id),\n+            details={\n+                \"order_id\": payment_request_data.order_id,\n+                \"error\": str(e),\n+                \"error_type\": e.__class__.__name__,\n+            },\n+            commit=False,\n         )\n         logger.error(f\"Stripe payment failed: {str(e)}\")\n         raise ValidationException(message=\"An error occurred processing the request\")\n     except Exception as e:\n-        payment_db_record.status = \"failed\" # Ensure status is marked failed\n+        payment_db_record.status = \"failed\"  # Ensure status is marked failed\n         await audit_service.create_audit_log(\n             event_type=AuditEventType.PAYMENT_FAILURE,\n             event_status=AuditEventStatus.FAILURE,\n             action_performed=\"Stripe payment failed due to unexpected server error.\",\n-            user_id=current_user.id, username_or_email=current_user.email,\n-            ip_address=ip_address, user_agent=user_agent,\n-            resource_type=\"Payment\", resource_id=str(payment_db_record.id),\n+            user_id=current_user.id,\n+            username_or_email=current_user.email,\n+            ip_address=ip_address,\n+            user_agent=user_agent,\n+            resource_type=\"Payment\",\n+            resource_id=str(payment_db_record.id),\n             details={\"order_id\": payment_request_data.order_id, \"error\": str(e)},\n-            commit=False\n+            commit=False,\n         )\n         logger.error(f\"Unexpected error during Stripe payment: {e}\")\n         raise PaymentException(message=\"Payment processing failed\")\n \n+\n @router.post(\"/cash\", response_model=PaymentResponse)\n async def process_cash_payment(\n-    payment_request_data: CashPaymentRequest, # Renamed from 'request'\n+    payment_request_data: CashPaymentRequest,  # Renamed from 'request'\n     request: Request,\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Restaurant ID for multi-location owners\"),\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Restaurant ID for multi-location owners\"\n+    ),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Process cash payment\"\"\"\n     # Validate restaurant access for multi-tenant\n     await TenantSecurity.validate_restaurant_access(\n         current_user, current_restaurant_id or current_user.restaurant_id, db=db\n     )\n     restaurant_id = current_restaurant_id or current_user.restaurant_id\n-    \n+\n     audit_service = AuditLoggerService(db)\n     ip_address = request.client.host if request.client else \"unknown\"\n     user_agent = request.headers.get(\"user-agent\", \"unknown\")\n \n-    order = db.query(Order).filter(\n-        Order.id == payment_request_data.order_id,\n-        Order.restaurant_id == restaurant_id\n-    ).first()\n+    order = (\n+        db.query(Order)\n+        .filter(\n+            Order.id == payment_request_data.order_id,\n+            Order.restaurant_id == restaurant_id,\n+        )\n+        .first()\n+    )\n     if not order:\n         # No audit log here as it's a basic validation, not a payment process failure yet.\n         raise ResourceNotFoundException(resource=\"Order\")\n \n     if order.payment_status == \"completed\":\n-         await audit_service.create_audit_log(\n-            event_type=AuditEventType.PAYMENT_FAILURE, event_status=AuditEventStatus.INFO,\n+        await audit_service.create_audit_log(\n+            event_type=AuditEventType.PAYMENT_FAILURE,\n+            event_status=AuditEventStatus.INFO,\n             action_performed=\"Cash payment attempt failed: Order already paid.\",\n-            user_id=current_user.id, username_or_email=current_user.email,\n-            ip_address=ip_address, user_agent=user_agent,\n-            resource_type=\"Order\", resource_id=str(order.id),\n+            user_id=current_user.id,\n+            username_or_email=current_user.email,\n+            ip_address=ip_address,\n+            user_agent=user_agent,\n+            resource_type=\"Order\",\n+            resource_id=str(order.id),\n             details={\"reason\": \"Order already marked as paid.\"},\n-            commit=True\n-        )\n-         raise ValidationException(message=\"Order already paid\")\n+            commit=True,\n+        )\n+        raise ValidationException(message=\"Order already paid\")\n \n     if payment_request_data.received_amount < payment_request_data.amount:\n         # Log this specific failure if desired, though it's a validation error.\n         # For now, let the HTTP exception handle it.\n         raise InventoryException(message=\"Insufficient cash received\")\n-    \n+\n     change_amount = payment_request_data.received_amount - payment_request_data.amount\n-    \n+\n     payment_db_record = Payment(\n         order_id=payment_request_data.order_id,\n         payment_method=\"cash\",\n         amount=payment_request_data.amount,\n         fee_amount=0.0,\n         net_amount=payment_request_data.amount,\n-        status=\"completed\", # Cash is typically completed immediately\n+        status=\"completed\",  # Cash is typically completed immediately\n         processed_at=datetime.utcnow(),\n         payment_metadata={\n             \"received_amount\": payment_request_data.received_amount,\n-            \"change_amount\": change_amount\n-        }\n+            \"change_amount\": change_amount,\n+        },\n     )\n     db.add(payment_db_record)\n     order.payment_status = \"completed\"\n \n     await audit_service.create_audit_log(\n-        event_type=AuditEventType.PAYMENT_SUCCESS, # Cash payments are direct success\n+        event_type=AuditEventType.PAYMENT_SUCCESS,  # Cash payments are direct success\n         event_status=AuditEventStatus.SUCCESS,\n         action_performed=\"Cash payment processed successfully.\",\n-        user_id=current_user.id, username_or_email=current_user.email,\n-        ip_address=ip_address, user_agent=user_agent,\n-        resource_type=\"Payment\", resource_id=str(payment_db_record.id), # ID after flush\n+        user_id=current_user.id,\n+        username_or_email=current_user.email,\n+        ip_address=ip_address,\n+        user_agent=user_agent,\n+        resource_type=\"Payment\",\n+        resource_id=str(payment_db_record.id),  # ID after flush\n         details={\n             \"order_id\": payment_request_data.order_id,\n             \"amount\": payment_request_data.amount,\n             \"received_amount\": payment_request_data.received_amount,\n-            \"change_amount\": change_amount\n+            \"change_amount\": change_amount,\n         },\n-        commit=False # Commit with payment and order update\n-    )\n-    \n+        commit=False,  # Commit with payment and order update\n+    )\n+\n     db.commit()\n     db.refresh(payment_db_record)\n-    db.refresh(order) # Potentially refresh order if its status changed and is used\n-    \n-    logger.info(f\"Cash payment processed: {payment_db_record.id} for order {payment_request_data.order_id}\")\n-    \n+    db.refresh(order)  # Potentially refresh order if its status changed and is used\n+\n+    logger.info(\n+        f\"Cash payment processed: {payment_db_record.id} for order {payment_request_data.order_id}\"\n+    )\n+\n     return PaymentResponse(\n         payment_id=str(payment_db_record.id),\n         status=payment_db_record.status,\n         amount=payment_db_record.amount,\n         fee_amount=payment_db_record.fee_amount,\n-        net_amount=payment_db_record.net_amount\n-    )\n+        net_amount=payment_db_record.net_amount,\n+    )\n+\n \n @router.get(\"/order/{order_id}\")\n async def get_order_payments(\n     order_id: str,\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Restaurant ID for multi-location owners\"),\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Restaurant ID for multi-location owners\"\n+    ),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Get all payments for an order\"\"\"\n     # Validate restaurant access for multi-tenant\n     await TenantSecurity.validate_restaurant_access(\n         current_user, current_restaurant_id or current_user.restaurant_id, db=db\n     )\n     restaurant_id = current_restaurant_id or current_user.restaurant_id\n-    \n+\n     # Verify order belongs to the restaurant\n-    order = db.query(Order).filter(\n-        Order.id == order_id,\n-        Order.restaurant_id == restaurant_id\n-    ).first()\n+    order = (\n+        db.query(Order)\n+        .filter(Order.id == order_id, Order.restaurant_id == restaurant_id)\n+        .first()\n+    )\n     if not order:\n         raise ResourceNotFoundException(resource=\"Order\")\n-    \n+\n     payments = db.query(Payment).filter(Payment.order_id == order_id).all()\n-    \n+\n     payment_data = [\n         {\n             \"payment_id\": str(payment.id),\n             \"payment_method\": payment.payment_method,\n             \"amount\": payment.amount,\n             \"fee_amount\": payment.fee_amount,\n             \"net_amount\": payment.net_amount,\n             \"status\": payment.status,\n             \"processed_at\": payment.processed_at,\n-            \"external_id\": payment.external_id\n+            \"external_id\": payment.external_id,\n         }\n         for payment in payments\n     ]\n-    \n+\n     return APIResponseHelper.success(\n-        data=payment_data,\n-        message=f\"Retrieved {len(payment_data)} payments for order\"\n-    )\n+        data=payment_data, message=f\"Retrieved {len(payment_data)} payments for order\"\n+    )\n+\n \n @router.get(\"/qr/{qr_payment_id}/status\")\n-async def check_qr_payment_status(\n-    qr_payment_id: str,\n-    db: Session = Depends(get_db)\n-):\n+async def check_qr_payment_status(qr_payment_id: str, db: Session = Depends(get_db)):\n     \"\"\"Check QR payment status (public endpoint for payment checking)\"\"\"\n-    \n+\n     qr_payment = db.query(QRPayment).filter(QRPayment.id == qr_payment_id).first()\n     if not qr_payment:\n-        raise ResourceNotFoundException(resource=\"Payment\", message=\"QR payment not found\")\n-    \n+        raise ResourceNotFoundException(\n+            resource=\"Payment\", message=\"QR payment not found\"\n+        )\n+\n     data = {\n         \"qr_payment_id\": str(qr_payment.id),\n         \"status\": qr_payment.status,\n         \"amount\": qr_payment.amount,\n         \"expires_at\": qr_payment.expires_at,\n-        \"expired\": qr_payment.expires_at < datetime.utcnow()\n+        \"expired\": qr_payment.expires_at < datetime.utcnow(),\n     }\n-    \n-    return APIResponseHelper.success(\n-        data=data,\n-        message=\"QR payment status retrieved\"\n-    )\n+\n+    return APIResponseHelper.success(data=data, message=\"QR payment status retrieved\")\n+\n \n # New multi-provider payment endpoints\n+\n \n @router.post(\"/process\")\n async def process_payment(\n-    payment_data_req: PaymentRequest, # Renamed from payment_data to avoid confusion\n+    payment_data_req: PaymentRequest,  # Renamed from payment_data to avoid confusion\n     request: Request,\n-    provider_query: Optional[str] = Query(None, alias=\"provider\", description=\"Force specific provider\"), # Renamed provider\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Restaurant ID for multi-location owners\"),\n+    provider_query: Optional[str] = Query(\n+        None, alias=\"provider\", description=\"Force specific provider\"\n+    ),  # Renamed provider\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Restaurant ID for multi-location owners\"\n+    ),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"\n     Process a payment through the optimal provider\n-    \n+\n     Query params:\n     - provider: Force a specific provider (stripe, square, sumup)\n-    \n+\n     Body:\n     - order_id: Associated order ID\n     - amount: Payment amount in GBP\n     - payment_method_id: Provider-specific payment method ID\n     - customer_id: Optional customer ID\n     \"\"\"\n     audit_service = AuditLoggerService(db)\n     ip_address = request.client.host if request.client else \"unknown\"\n     user_agent = request.headers.get(\"user-agent\", \"unknown\")\n-    payment_db_record = None # Initialize\n+    payment_db_record = None  # Initialize\n \n     try:\n         # Validate restaurant access for multi-tenant\n         await TenantSecurity.validate_restaurant_access(\n             current_user, current_restaurant_id or current_user.restaurant_id, db=db\n         )\n         restaurant_id = current_restaurant_id or current_user.restaurant_id\n-        \n-        order = db.query(Order).filter(\n-            Order.id == payment_data_req.order_id,\n-            Order.restaurant_id == restaurant_id\n-        ).first()\n+\n+        order = (\n+            db.query(Order)\n+            .filter(\n+                Order.id == payment_data_req.order_id,\n+                Order.restaurant_id == restaurant_id,\n+            )\n+            .first()\n+        )\n         if not order:\n             await audit_service.create_audit_log(\n-                event_type=AuditEventType.PAYMENT_FAILURE, event_status=AuditEventStatus.FAILURE,\n+                event_type=AuditEventType.PAYMENT_FAILURE,\n+                event_status=AuditEventStatus.FAILURE,\n                 action_performed=\"Payment processing failed: Order not found.\",\n-                user_id=current_user.id, username_or_email=current_user.email, ip_address=ip_address, user_agent=user_agent,\n-                details={\"order_id\": payment_data_req.order_id, \"amount\": payment_data_req.amount, \"reason\": \"Order not found\"},\n-                commit=True\n+                user_id=current_user.id,\n+                username_or_email=current_user.email,\n+                ip_address=ip_address,\n+                user_agent=user_agent,\n+                details={\n+                    \"order_id\": payment_data_req.order_id,\n+                    \"amount\": payment_data_req.amount,\n+                    \"reason\": \"Order not found\",\n+                },\n+                commit=True,\n             )\n             raise ResourceNotFoundException(resource=\"Order\")\n \n         if order.payment_status == \"completed\":\n             await audit_service.create_audit_log(\n-                event_type=AuditEventType.PAYMENT_FAILURE, event_status=AuditEventStatus.INFO,\n+                event_type=AuditEventType.PAYMENT_FAILURE,\n+                event_status=AuditEventStatus.INFO,\n                 action_performed=\"Payment processing attempt failed: Order already paid.\",\n-                user_id=current_user.id, username_or_email=current_user.email, ip_address=ip_address, user_agent=user_agent,\n-                resource_type=\"Order\", resource_id=str(order.id), details={\"reason\": \"Order already marked as paid.\"},\n-                commit=True\n+                user_id=current_user.id,\n+                username_or_email=current_user.email,\n+                ip_address=ip_address,\n+                user_agent=user_agent,\n+                resource_type=\"Order\",\n+                resource_id=str(order.id),\n+                details={\"reason\": \"Order already marked as paid.\"},\n+                commit=True,\n             )\n             raise ValidationException(message=\"Order already paid\")\n \n         monthly_volume = Decimal(\"2000\")\n         provider_instance = await payment_factory.select_optimal_provider(\n             amount=Decimal(str(payment_data_req.amount)),\n             restaurant_id=str(restaurant_id),\n             monthly_volume=monthly_volume,\n             force_provider=provider_query,\n-            db_session=db\n-        )\n-        \n+            db_session=db,\n+        )\n+\n         await audit_service.create_audit_log(\n             event_type=AuditEventType.PAYMENT_INITIATED,\n             event_status=AuditEventStatus.PENDING,\n             action_performed=f\"Payment processing initiated with provider: {provider_instance.name if provider_instance else 'N/A'}.\",\n-            user_id=current_user.id, username_or_email=current_user.email, ip_address=ip_address, user_agent=user_agent,\n-            resource_type=\"Order\", resource_id=str(order.id),\n+            user_id=current_user.id,\n+            username_or_email=current_user.email,\n+            ip_address=ip_address,\n+            user_agent=user_agent,\n+            resource_type=\"Order\",\n+            resource_id=str(order.id),\n             details={\n-                \"order_id\": payment_data_req.order_id, \"amount\": payment_data_req.amount,\n-                \"currency\": payment_data_req.currency, \"provider_selected\": provider_instance.name if provider_instance else 'N/A',\n-                \"customer_id\": payment_data_req.customer_id\n+                \"order_id\": payment_data_req.order_id,\n+                \"amount\": payment_data_req.amount,\n+                \"currency\": payment_data_req.currency,\n+                \"provider_selected\": (\n+                    provider_instance.name if provider_instance else \"N/A\"\n+                ),\n+                \"customer_id\": payment_data_req.customer_id,\n             },\n-            commit=False # Will be committed with payment record or if error occurs before that\n+            commit=False,  # Will be committed with payment record or if error occurs before that\n         )\n \n         result = await provider_instance.process_payment(\n             amount=Decimal(str(payment_data_req.amount)),\n             customer_id=payment_data_req.customer_id,\n             payment_method_id=payment_data_req.payment_method_id,\n             metadata={\n                 \"order_id\": payment_data_req.order_id,\n                 \"restaurant_id\": str(restaurant_id),\n-                **(payment_data_req.metadata or {})\n-            }\n-        )\n-        \n-        event_status_for_log = AuditEventStatus.SUCCESS if result[\"status\"] == \"success\" else \\\n-                               AuditEventStatus.PENDING if result[\"status\"] == \"pending\" else AuditEventStatus.FAILURE\n-        audit_event_type = AuditEventType.PAYMENT_SUCCESS if result[\"status\"] in [\"success\", \"pending\"] else AuditEventType.PAYMENT_FAILURE\n+                **(payment_data_req.metadata or {}),\n+            },\n+        )\n+\n+        event_status_for_log = (\n+            AuditEventStatus.SUCCESS\n+            if result[\"status\"] == \"success\"\n+            else (\n+                AuditEventStatus.PENDING\n+                if result[\"status\"] == \"pending\"\n+                else AuditEventStatus.FAILURE\n+            )\n+        )\n+        audit_event_type = (\n+            AuditEventType.PAYMENT_SUCCESS\n+            if result[\"status\"] in [\"success\", \"pending\"]\n+            else AuditEventType.PAYMENT_FAILURE\n+        )\n \n         if result[\"status\"] in [\"success\", \"pending\"]:\n             payment_db_record = Payment(\n                 order_id=payment_data_req.order_id,\n                 payment_method=f\"{result['provider']}_payment\",\n                 provider=result[\"provider\"],\n                 amount=payment_data_req.amount,\n                 fee_amount=result[\"fee\"] / 100,\n                 provider_fee=result[\"fee\"] / 100,\n                 net_amount=result[\"net_amount\"] / 100,\n-                status=result[\"status\"], # This is \"success\" or \"pending\"\n+                status=result[\"status\"],  # This is \"success\" or \"pending\"\n                 external_id=result[\"transaction_id\"],\n-                processed_at=datetime.utcnow() if result[\"status\"] == \"success\" else None,\n+                processed_at=(\n+                    datetime.utcnow() if result[\"status\"] == \"success\" else None\n+                ),\n                 payment_metadata={\n-                    \"provider\": result[\"provider\"], \"transaction_id\": result[\"transaction_id\"],\n-                    \"raw_response\": result.get(\"raw_response\", {}), **(payment_data_req.metadata or {})\n-                }\n+                    \"provider\": result[\"provider\"],\n+                    \"transaction_id\": result[\"transaction_id\"],\n+                    \"raw_response\": result.get(\"raw_response\", {}),\n+                    **(payment_data_req.metadata or {}),\n+                },\n             )\n             db.add(payment_db_record)\n             if result[\"status\"] == \"success\":\n                 order.payment_status = \"completed\"\n-                order.status = \"confirmed\" if order.status == \"pending\" else order.status\n-            \n+                order.status = (\n+                    \"confirmed\" if order.status == \"pending\" else order.status\n+                )\n+\n             await audit_service.create_audit_log(\n-                event_type=audit_event_type, event_status=event_status_for_log,\n+                event_type=audit_event_type,\n+                event_status=event_status_for_log,\n                 action_performed=f\"Payment processing by {result['provider']} completed with status: {result['status']}.\",\n-                user_id=current_user.id, username_or_email=current_user.email, ip_address=ip_address, user_agent=user_agent,\n-                resource_type=\"Payment\", resource_id=str(payment_db_record.id), # ID after flush\n+                user_id=current_user.id,\n+                username_or_email=current_user.email,\n+                ip_address=ip_address,\n+                user_agent=user_agent,\n+                resource_type=\"Payment\",\n+                resource_id=str(payment_db_record.id),  # ID after flush\n                 details={\n-                    \"order_id\": payment_data_req.order_id, \"provider\": result[\"provider\"],\n-                    \"transaction_id\": result[\"transaction_id\"], \"amount\": payment_data_req.amount,\n-                    \"provider_status\": result[\"status\"]\n+                    \"order_id\": payment_data_req.order_id,\n+                    \"provider\": result[\"provider\"],\n+                    \"transaction_id\": result[\"transaction_id\"],\n+                    \"amount\": payment_data_req.amount,\n+                    \"provider_status\": result[\"status\"],\n                 },\n-                commit=False\n+                commit=False,\n             )\n             db.commit()\n             db.refresh(payment_db_record)\n-            if result[\"status\"] == \"success\": db.refresh(order)\n+            if result[\"status\"] == \"success\":\n+                db.refresh(order)\n \n             return APIResponseHelper.success(\n                 message=f\"Payment processed successfully with {result['provider']}\",\n                 data={\n-                    \"payment_id\": str(payment_db_record.id), \"provider\": result[\"provider\"],\n-                    \"transaction_id\": result[\"transaction_id\"], \"amount\": payment_data_req.amount,\n-                    \"fee\": result[\"fee\"] / 100, \"net_amount\": result[\"net_amount\"] / 100,\n-                    \"status\": result[\"status\"]\n-                }\n-            )\n-        else: # Payment failed as per provider result\n+                    \"payment_id\": str(payment_db_record.id),\n+                    \"provider\": result[\"provider\"],\n+                    \"transaction_id\": result[\"transaction_id\"],\n+                    \"amount\": payment_data_req.amount,\n+                    \"fee\": result[\"fee\"] / 100,\n+                    \"net_amount\": result[\"net_amount\"] / 100,\n+                    \"status\": result[\"status\"],\n+                },\n+            )\n+        else:  # Payment failed as per provider result\n             await audit_service.create_audit_log(\n-                event_type=AuditEventType.PAYMENT_FAILURE, event_status=AuditEventStatus.FAILURE,\n+                event_type=AuditEventType.PAYMENT_FAILURE,\n+                event_status=AuditEventStatus.FAILURE,\n                 action_performed=f\"Payment processing failed by provider: {result.get('provider', 'N/A')}.\",\n-                user_id=current_user.id, username_or_email=current_user.email, ip_address=ip_address, user_agent=user_agent,\n-                resource_type=\"Order\", resource_id=str(order.id),\n+                user_id=current_user.id,\n+                username_or_email=current_user.email,\n+                ip_address=ip_address,\n+                user_agent=user_agent,\n+                resource_type=\"Order\",\n+                resource_id=str(order.id),\n                 details={\n-                    \"order_id\": payment_data_req.order_id, \"provider\": result.get('provider', 'N/A'),\n-                    \"error\": result.get(\"error\", \"Unknown provider error\"), \"amount\": payment_data_req.amount\n+                    \"order_id\": payment_data_req.order_id,\n+                    \"provider\": result.get(\"provider\", \"N/A\"),\n+                    \"error\": result.get(\"error\", \"Unknown provider error\"),\n+                    \"amount\": payment_data_req.amount,\n                 },\n-                commit=True # Commit this failure log as main transaction won't proceed\n+                commit=True,  # Commit this failure log as main transaction won't proceed\n             )\n             return APIResponseHelper.error(\n                 message=result.get(\"error\", \"Payment failed\"),\n                 error_code=\"PAYMENT_FAILED\",\n-                data={\"provider\": result[\"provider\"]}\n+                data={\"provider\": result[\"provider\"]},\n             )\n \n     except Exception as e:\n         logger.error(f\"Payment processing error: {str(e)}\", exc_info=True)\n         # General exception, payment_db_record might not exist or be in session\n         # Log this as a failure. If part of a transaction that rolls back, this log might too unless committed.\n         # For robustness, attempt to log critical failures independently if possible.\n         details_for_error_log = {\n-            \"order_id\": payment_data_req.order_id, \"amount\": payment_data_req.amount,\n-            \"error\": str(e), \"error_type\": e.__class__.__name__\n+            \"order_id\": payment_data_req.order_id,\n+            \"amount\": payment_data_req.amount,\n+            \"error\": str(e),\n+            \"error_type\": e.__class__.__name__,\n         }\n-        if payment_db_record and payment_db_record.id: # If payment record was created and flushed\n+        if (\n+            payment_db_record and payment_db_record.id\n+        ):  # If payment record was created and flushed\n             details_for_error_log[\"payment_id_attempted\"] = str(payment_db_record.id)\n \n         await audit_service.create_audit_log(\n             event_type=AuditEventType.PAYMENT_FAILURE,\n             event_status=AuditEventStatus.FAILURE,\n             action_performed=\"Payment processing failed due to server error.\",\n-            user_id=current_user.id, username_or_email=current_user.email,\n-            ip_address=ip_address, user_agent=user_agent,\n-            resource_type=\"Order\", resource_id=str(payment_data_req.order_id),\n+            user_id=current_user.id,\n+            username_or_email=current_user.email,\n+            ip_address=ip_address,\n+            user_agent=user_agent,\n+            resource_type=\"Order\",\n+            resource_id=str(payment_data_req.order_id),\n             details=details_for_error_log,\n-            commit=True # Attempt to commit this log even if outer transaction (if any) rolls back\n-        )\n-        raise FynloException(message=\"An error occurred processing the request\", status_code=500)\n+            commit=True,  # Attempt to commit this log even if outer transaction (if any) rolls back\n+        )\n+        raise FynloException(\n+            message=\"An error occurred processing the request\", status_code=500\n+        )\n+\n \n @router.post(\"/refund/{transaction_id}\")\n async def refund_payment(\n     transaction_id: str,\n-    refund_data_req: RefundRequest, # Renamed from refund_data\n+    refund_data_req: RefundRequest,  # Renamed from refund_data\n     request: Request,\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Restaurant ID for multi-location owners\"),\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Restaurant ID for multi-location owners\"\n+    ),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Refund a payment\"\"\"\n     # Validate restaurant access for multi-tenant\n     await TenantSecurity.validate_restaurant_access(\n         current_user, current_restaurant_id or current_user.restaurant_id, db=db\n     )\n     restaurant_id = current_restaurant_id or current_user.restaurant_id\n-    \n+\n     audit_service = AuditLoggerService(db)\n     ip_address = request.client.host if request.client else \"unknown\"\n     user_agent = request.headers.get(\"user-agent\", \"unknown\")\n \n     # Ensure payment belongs to the restaurant\n-    payment_db_record = db.query(Payment).join(Order).filter(\n-        Payment.external_id == transaction_id,\n-        Order.restaurant_id == restaurant_id\n-    ).first()\n+    payment_db_record = (\n+        db.query(Payment)\n+        .join(Order)\n+        .filter(\n+            Payment.external_id == transaction_id, Order.restaurant_id == restaurant_id\n+        )\n+        .first()\n+    )\n     if not payment_db_record:\n         await audit_service.create_audit_log(\n-            event_type=AuditEventType.REFUND_FAILURE, event_status=AuditEventStatus.FAILURE,\n+            event_type=AuditEventType.REFUND_FAILURE,\n+            event_status=AuditEventStatus.FAILURE,\n             action_performed=\"Refund attempt failed: Original payment not found.\",\n-            user_id=current_user.id, username_or_email=current_user.email, ip_address=ip_address, user_agent=user_agent,\n-            details={\"external_transaction_id\": transaction_id, \"reason\": \"Payment not found\"},\n-            commit=True\n+            user_id=current_user.id,\n+            username_or_email=current_user.email,\n+            ip_address=ip_address,\n+            user_agent=user_agent,\n+            details={\n+                \"external_transaction_id\": transaction_id,\n+                \"reason\": \"Payment not found\",\n+            },\n+            commit=True,\n         )\n         raise ResourceNotFoundException(resource=\"Payment\")\n \n-    provider_name_from_meta = payment_db_record.payment_metadata.get(\"provider\", payment_db_record.payment_method)\n+    provider_name_from_meta = payment_db_record.payment_metadata.get(\n+        \"provider\", payment_db_record.payment_method\n+    )\n     # Ensure provider_name is a string, e.g. if payment_method was 'stripe_payment'\n-    provider_name = provider_name_from_meta.lower().replace(\"_payment\",\"\") if isinstance(provider_name_from_meta, str) else \"unknown\"\n+    provider_name = (\n+        provider_name_from_meta.lower().replace(\"_payment\", \"\")\n+        if isinstance(provider_name_from_meta, str)\n+        else \"unknown\"\n+    )\n \n     provider_instance = payment_factory.get_provider(provider_name)\n     if not provider_instance:\n         await audit_service.create_audit_log(\n-            event_type=AuditEventType.REFUND_FAILURE, event_status=AuditEventStatus.FAILURE,\n+            event_type=AuditEventType.REFUND_FAILURE,\n+            event_status=AuditEventStatus.FAILURE,\n             action_performed=f\"Refund attempt failed: Provider '{provider_name}' not available/found.\",\n-            user_id=current_user.id, username_or_email=current_user.email, ip_address=ip_address, user_agent=user_agent,\n-            resource_type=\"Payment\", resource_id=str(payment_db_record.id),\n-            details={\"external_transaction_id\": transaction_id, \"provider_name_attempted\": provider_name},\n-            commit=True\n-        )\n-        raise ValidationException(message=f\"Provider {provider_name} not available for refund\")\n+            user_id=current_user.id,\n+            username_or_email=current_user.email,\n+            ip_address=ip_address,\n+            user_agent=user_agent,\n+            resource_type=\"Payment\",\n+            resource_id=str(payment_db_record.id),\n+            details={\n+                \"external_transaction_id\": transaction_id,\n+                \"provider_name_attempted\": provider_name,\n+            },\n+            commit=True,\n+        )\n+        raise ValidationException(\n+            message=f\"Provider {provider_name} not available for refund\"\n+        )\n \n     await audit_service.create_audit_log(\n         event_type=AuditEventType.REFUND_INITIATED,\n         event_status=AuditEventStatus.PENDING,\n         action_performed=f\"Refund initiated with provider: {provider_instance.name}.\",\n-        user_id=current_user.id, username_or_email=current_user.email, ip_address=ip_address, user_agent=user_agent,\n-        resource_type=\"Payment\", resource_id=str(payment_db_record.id),\n+        user_id=current_user.id,\n+        username_or_email=current_user.email,\n+        ip_address=ip_address,\n+        user_agent=user_agent,\n+        resource_type=\"Payment\",\n+        resource_id=str(payment_db_record.id),\n         details={\n             \"external_transaction_id\": transaction_id,\n             \"amount_requested\": refund_data_req.amount,\n             \"reason\": refund_data_req.reason,\n-            \"provider\": provider_instance.name\n+            \"provider\": provider_instance.name,\n         },\n-        commit=False # Commit with refund update or if error\n-    )\n-    \n+        commit=False,  # Commit with refund update or if error\n+    )\n+\n     try:\n         result = await provider_instance.refund_payment(\n-            transaction_id=payment_db_record.external_id, # Use external_id from the fetched payment\n-            amount=Decimal(str(refund_data_req.amount)) if refund_data_req.amount is not None else None,\n-            reason=refund_data_req.reason\n-        )\n-    except Exception as e: # Catch errors from provider refund call\n-        await audit_service.create_audit_log(\n-            event_type=AuditEventType.REFUND_FAILURE, event_status=AuditEventStatus.FAILURE,\n+            transaction_id=payment_db_record.external_id,  # Use external_id from the fetched payment\n+            amount=(\n+                Decimal(str(refund_data_req.amount))\n+                if refund_data_req.amount is not None\n+                else None\n+            ),\n+            reason=refund_data_req.reason,\n+        )\n+    except Exception as e:  # Catch errors from provider refund call\n+        await audit_service.create_audit_log(\n+            event_type=AuditEventType.REFUND_FAILURE,\n+            event_status=AuditEventStatus.FAILURE,\n             action_performed=f\"Refund processing by {provider_instance.name} failed with exception.\",\n-            user_id=current_user.id, username_or_email=current_user.email, ip_address=ip_address, user_agent=user_agent,\n-            resource_type=\"Payment\", resource_id=str(payment_db_record.id),\n+            user_id=current_user.id,\n+            username_or_email=current_user.email,\n+            ip_address=ip_address,\n+            user_agent=user_agent,\n+            resource_type=\"Payment\",\n+            resource_id=str(payment_db_record.id),\n             details={\"external_transaction_id\": transaction_id, \"error\": str(e)},\n-            commit=True # Commit this failure log\n-        )\n-        raise FynloException(message=\"An error occurred processing the request\", status_code=500)\n-\n+            commit=True,  # Commit this failure log\n+        )\n+        raise FynloException(\n+            message=\"An error occurred processing the request\", status_code=500\n+        )\n \n     if result[\"status\"] == \"refunded\":\n-        payment_db_record.status = \"refunded\" # Update local payment status\n-        payment_db_record.payment_metadata.update({\n-            \"refund_id\": result.get(\"refund_id\"),\n-            \"refunded_amount\": result.get(\"amount\", 0) / 100, # Assuming result amount is in pence/cents\n-            \"refund_reason\": refund_data_req.reason,\n-            \"refunded_at\": datetime.utcnow().isoformat()\n-        })\n-        \n-        await audit_service.create_audit_log(\n-            event_type=AuditEventType.REFUND_SUCCESS, event_status=AuditEventStatus.SUCCESS,\n+        payment_db_record.status = \"refunded\"  # Update local payment status\n+        payment_db_record.payment_metadata.update(\n+            {\n+                \"refund_id\": result.get(\"refund_id\"),\n+                \"refunded_amount\": result.get(\"amount\", 0)\n+                / 100,  # Assuming result amount is in pence/cents\n+                \"refund_reason\": refund_data_req.reason,\n+                \"refunded_at\": datetime.utcnow().isoformat(),\n+            }\n+        )\n+\n+        await audit_service.create_audit_log(\n+            event_type=AuditEventType.REFUND_SUCCESS,\n+            event_status=AuditEventStatus.SUCCESS,\n             action_performed=f\"Refund by {provider_instance.name} succeeded.\",\n-            user_id=current_user.id, username_or_email=current_user.email, ip_address=ip_address, user_agent=user_agent,\n-            resource_type=\"Payment\", resource_id=str(payment_db_record.id),\n+            user_id=current_user.id,\n+            username_or_email=current_user.email,\n+            ip_address=ip_address,\n+            user_agent=user_agent,\n+            resource_type=\"Payment\",\n+            resource_id=str(payment_db_record.id),\n             details={\n-                \"external_transaction_id\": transaction_id, \"refund_id\": result.get(\"refund_id\"),\n-                \"amount_refunded\": result.get(\"amount\", 0) / 100\n+                \"external_transaction_id\": transaction_id,\n+                \"refund_id\": result.get(\"refund_id\"),\n+                \"amount_refunded\": result.get(\"amount\", 0) / 100,\n             },\n-            commit=False\n-        )\n-        db.commit() # Commit payment status update and audit log\n+            commit=False,\n+        )\n+        db.commit()  # Commit payment status update and audit log\n         db.refresh(payment_db_record)\n-        \n+\n         return APIResponseHelper.success(\n             message=\"Refund processed successfully\",\n             data={\n                 \"refund_id\": result.get(\"refund_id\"),\n                 \"amount\": result.get(\"amount\", 0) / 100,\n-                \"status\": \"refunded\"\n-            }\n-        )\n-    else: # Refund failed as per provider result\n-        await audit_service.create_audit_log(\n-            event_type=AuditEventType.REFUND_FAILURE, event_status=AuditEventStatus.FAILURE,\n+                \"status\": \"refunded\",\n+            },\n+        )\n+    else:  # Refund failed as per provider result\n+        await audit_service.create_audit_log(\n+            event_type=AuditEventType.REFUND_FAILURE,\n+            event_status=AuditEventStatus.FAILURE,\n             action_performed=f\"Refund by {provider_instance.name} failed.\",\n-            user_id=current_user.id, username_or_email=current_user.email, ip_address=ip_address, user_agent=user_agent,\n-            resource_type=\"Payment\", resource_id=str(payment_db_record.id),\n+            user_id=current_user.id,\n+            username_or_email=current_user.email,\n+            ip_address=ip_address,\n+            user_agent=user_agent,\n+            resource_type=\"Payment\",\n+            resource_id=str(payment_db_record.id),\n             details={\n                 \"external_transaction_id\": transaction_id,\n                 \"error\": result.get(\"error\", \"Unknown provider error\"),\n-                \"provider_status\": result.get(\"status\")\n+                \"provider_status\": result.get(\"status\"),\n             },\n-            commit=True\n+            commit=True,\n         )\n         return APIResponseHelper.error(\n             message=result.get(\"error\", \"Refund failed\"),\n             error_code=\"REFUND_FAILED\",\n-            data={\"provider_refund_status\": result.get(\"status\")}\n-        )\n+            data={\"provider_refund_status\": result.get(\"status\")},\n+        )\n+\n \n @router.get(\"/providers\")\n async def get_available_providers(\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Restaurant ID for multi-location owners\"),\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Restaurant ID for multi-location owners\"\n+    ),\n     current_user: User = Depends(get_current_user),\n-    db: Session = Depends(get_db)\n+    db: Session = Depends(get_db),\n ):\n     \"\"\"Get list of available payment providers and their costs\"\"\"\n     # Validate restaurant access for multi-tenant\n     await TenantSecurity.validate_restaurant_access(\n         current_user, current_restaurant_id or current_user.restaurant_id, db=db\n     )\n     restaurant_id = current_restaurant_id or current_user.restaurant_id\n-    \n+\n     providers = payment_factory.get_available_providers()\n-    \n+\n     # Calculate sample costs for common amounts\n     sample_amounts = [Decimal(\"10\"), Decimal(\"50\"), Decimal(\"100\")]\n     monthly_volume = Decimal(\"2000\")  # Default monthly volume\n     # Assuming db is available in this scope, if not, it needs to be passed or accessed.\n     # For get_available_providers, db might not be directly needed unless provider loading itself needs it.\n     # restaurant_id is also not defined in this scope. This was likely from a previous version.\n     # I will remove the restaurant_id specific logic for now from this generic endpoint.\n-    \n+\n     provider_info_list = []\n     for provider_name in providers:\n-        provider = payment_factory.get_provider(provider_name) # This might need to be async if provider init is async\n+        provider = payment_factory.get_provider(\n+            provider_name\n+        )  # This might need to be async if provider init is async\n         info = {\n             \"name\": provider_name,\n             \"display_name\": provider_name.title(),\n             \"sample_fees\": {},\n-            \"recommended\": False # Simplified recommendation logic\n+            \"recommended\": False,  # Simplified recommendation logic\n         }\n-        \n+\n         for amount in sample_amounts:\n             # Assuming calculate_fee is synchronous. If it's async, this loop needs `await`.\n             fee = provider.calculate_fee(amount)\n             info[\"sample_fees\"][f\"\u00a3{amount}\"] = f\"\u00a3{fee:.2f}\"\n-        \n+\n         # Simplified provider-specific information\n-        if provider_name == \"sumup\": info[\"rate\"] = \"1.69% (standard)\" # Example rate\n-        elif provider_name == \"stripe\": info[\"rate\"] = \"1.4% + 20p (UK cards)\" # Example rate\n-        elif provider_name == \"square\": info[\"rate\"] = \"1.75%\" # Example rate\n-        \n+        if provider_name == \"sumup\":\n+            info[\"rate\"] = \"1.69% (standard)\"  # Example rate\n+        elif provider_name == \"stripe\":\n+            info[\"rate\"] = \"1.4% + 20p (UK cards)\"  # Example rate\n+        elif provider_name == \"square\":\n+            info[\"rate\"] = \"1.75%\"  # Example rate\n+\n         provider_info_list.append(info)\n-    \n+\n     # Simplified sorting or recommendation\n     # For example, recommend the first one or based on a simple metric if available\n     if provider_info_list:\n-        provider_info_list[0][\"recommended\"] = True # Example: recommend the first listed\n-    \n+        provider_info_list[0][\n+            \"recommended\"\n+        ] = True  # Example: recommend the first listed\n+\n     return APIResponseHelper.success(\n         data={\n             \"providers\": provider_info_list,\n-            \"monthly_volume_assumption\": float(monthly_volume), # Clarify this is an assumption\n-            \"optimal_provider_example\": provider_info_list[0][\"name\"] if provider_info_list else None,\n+            \"monthly_volume_assumption\": float(\n+                monthly_volume\n+            ),  # Clarify this is an assumption\n+            \"optimal_provider_example\": (\n+                provider_info_list[0][\"name\"] if provider_info_list else None\n+            ),\n         },\n-        message=\"Retrieved available payment providers.\"\n-    )\n+        message=\"Retrieved available payment providers.\",\n+    )\n+\n \n # --- Square Specific Endpoints ---\n \n+\n class SquareCreatePaymentRequest(BaseModel):\n-    amount: float # Amount in major currency unit (e.g., GBP)\n+    amount: float  # Amount in major currency unit (e.g., GBP)\n     currency: str = \"GBP\"\n-    source_id: str # The Square payment source ID (e.g., card nonce)\n+    source_id: str  # The Square payment source ID (e.g., card nonce)\n     order_id: Optional[str] = None\n     customer_id: Optional[str] = None\n     note: Optional[str] = None\n     metadata: Optional[dict] = None\n \n+\n class SquareProcessPaymentRequest(BaseModel):\n-    payment_id: str # The Square Payment ID from the create_payment step\n-    order_id: Optional[str] = None # Optional: if completing a payment for a specific order\n+    payment_id: str  # The Square Payment ID from the create_payment step\n+    order_id: Optional[str] = (\n+        None  # Optional: if completing a payment for a specific order\n+    )\n+\n \n class SquarePaymentResponseData(BaseModel):\n-    payment_id: Optional[str] = None # Our internal DB payment ID\n+    payment_id: Optional[str] = None  # Our internal DB payment ID\n     provider: str\n-    transaction_id: Optional[str] = None # Square's transaction ID\n-    status: str # e.g., SUCCESS, PENDING, FAILED (from PaymentStatus enum)\n+    transaction_id: Optional[str] = None  # Square's transaction ID\n+    status: str  # e.g., SUCCESS, PENDING, FAILED (from PaymentStatus enum)\n     amount: Optional[float] = None\n     currency: Optional[str] = None\n     fee: Optional[float] = None\n     net_amount: Optional[float] = None\n     message: Optional[str] = None\n-    raw_response: Optional[dict] = None # Full provider response\n-\n-@router.post(\"/square/create\", response_model=SquarePaymentResponseData, tags=[\"Payments - Square\"])\n+    raw_response: Optional[dict] = None  # Full provider response\n+\n+\n+@router.post(\n+    \"/square/create\",\n+    response_model=SquarePaymentResponseData,\n+    tags=[\"Payments - Square\"],\n+)\n async def square_create_payment_endpoint(\n     http_request: Request,\n     payment_create_req: SquareCreatePaymentRequest,\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Restaurant ID for multi-location owners\"),\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Restaurant ID for multi-location owners\"\n+    ),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Create a Square payment. If auto_complete is true, this attempts to finalize the payment.\"\"\"\n     # Validate restaurant access for multi-tenant\n     await TenantSecurity.validate_restaurant_access(\n         current_user, current_restaurant_id or current_user.restaurant_id, db=db\n     )\n     restaurant_id = current_restaurant_id or current_user.restaurant_id\n-    \n+\n     audit_service = AuditLoggerService(db)\n     ip_address = http_request.client.host if http_request.client else \"unknown\"\n     user_agent = http_request.headers.get(\"user-agent\", \"unknown\")\n \n     try:\n-        square_provider = await payment_factory.get_provider_instance(\"square\", db_session=db)\n+        square_provider = await payment_factory.get_provider_instance(\n+            \"square\", db_session=db\n+        )\n         if not square_provider:\n             raise ServiceUnavailableError(message=\"Square provider not available.\")\n \n         # Validate order if order_id is provided\n         order = None\n         if payment_create_req.order_id:\n-            order = db.query(Order).filter(\n-                Order.id == payment_create_req.order_id,\n-                Order.restaurant_id == restaurant_id\n-            ).first()\n+            order = (\n+                db.query(Order)\n+                .filter(\n+                    Order.id == payment_create_req.order_id,\n+                    Order.restaurant_id == restaurant_id,\n+                )\n+                .first()\n+            )\n             if not order:\n                 # Log and raise error if order_id is given but order not found\n                 await audit_service.create_audit_log(\n-                    event_type=AuditEventType.PAYMENT_FAILURE, event_status=AuditEventStatus.FAILURE,\n+                    event_type=AuditEventType.PAYMENT_FAILURE,\n+                    event_status=AuditEventStatus.FAILURE,\n                     action_performed=\"Square payment creation failed: Order not found.\",\n-                    user_id=current_user.id, username_or_email=current_user.email, ip_address=ip_address, user_agent=user_agent,\n-                    details={\"order_id\": payment_create_req.order_id, \"reason\": \"Order not found\"}, commit=True)\n-                raise ResourceNotFoundException(message=f\"Order {payment_create_req.order_id} not found.\")\n+                    user_id=current_user.id,\n+                    username_or_email=current_user.email,\n+                    ip_address=ip_address,\n+                    user_agent=user_agent,\n+                    details={\n+                        \"order_id\": payment_create_req.order_id,\n+                        \"reason\": \"Order not found\",\n+                    },\n+                    commit=True,\n+                )\n+                raise ResourceNotFoundException(\n+                    message=f\"Order {payment_create_req.order_id} not found.\"\n+                )\n             if order.payment_status == \"completed\":\n                 await audit_service.create_audit_log(\n-                    event_type=AuditEventType.PAYMENT_FAILURE, event_status=AuditEventStatus.INFO,\n+                    event_type=AuditEventType.PAYMENT_FAILURE,\n+                    event_status=AuditEventStatus.INFO,\n                     action_performed=\"Square payment creation attempt: Order already paid.\",\n-                    user_id=current_user.id, username_or_email=current_user.email, ip_address=ip_address, user_agent=user_agent,\n-                    resource_type=\"Order\", resource_id=str(order.id), details={\"reason\": \"Order already marked as paid.\"}, commit=True)\n+                    user_id=current_user.id,\n+                    username_or_email=current_user.email,\n+                    ip_address=ip_address,\n+                    user_agent=user_agent,\n+                    resource_type=\"Order\",\n+                    resource_id=str(order.id),\n+                    details={\"reason\": \"Order already marked as paid.\"},\n+                    commit=True,\n+                )\n                 raise ValidationException(message=\"Order already paid.\")\n \n         await audit_service.create_audit_log(\n-            event_type=AuditEventType.PAYMENT_INITIATED, event_status=AuditEventStatus.PENDING,\n+            event_type=AuditEventType.PAYMENT_INITIATED,\n+            event_status=AuditEventStatus.PENDING,\n             action_performed=\"Square payment creation initiated.\",\n-            user_id=current_user.id, username_or_email=current_user.email, ip_address=ip_address, user_agent=user_agent,\n-            details={**payment_create_req.model_dump(), \"provider\": \"square\"}, commit=False) # Commit with payment record\n+            user_id=current_user.id,\n+            username_or_email=current_user.email,\n+            ip_address=ip_address,\n+            user_agent=user_agent,\n+            details={**payment_create_req.model_dump(), \"provider\": \"square\"},\n+            commit=False,\n+        )  # Commit with payment record\n \n         provider_response = await square_provider.create_payment(\n             amount=Decimal(str(payment_create_req.amount)),\n             currency=payment_create_req.currency,\n             source_id=payment_create_req.source_id,\n             customer_id=payment_create_req.customer_id,\n-            order_id=payment_create_req.order_id, # Pass our order_id to be Square's order_id if applicable\n+            order_id=payment_create_req.order_id,  # Pass our order_id to be Square's order_id if applicable\n             note=payment_create_req.note,\n-            metadata=payment_create_req.metadata\n+            metadata=payment_create_req.metadata,\n         )\n \n         internal_payment_id = None\n-        if provider_response.get(\"status\") in [PaymentStatus.SUCCESS.value, PaymentStatus.PENDING.value] and provider_response.get(\"transaction_id\"):\n+        if provider_response.get(\"status\") in [\n+            PaymentStatus.SUCCESS.value,\n+            PaymentStatus.PENDING.value,\n+        ] and provider_response.get(\"transaction_id\"):\n             # Create Payment record in our DB\n             payment_db = Payment(\n                 order_id=payment_create_req.order_id if order else None,\n-                payment_method=\"square_card\", # Or more specific if known\n+                payment_method=\"square_card\",  # Or more specific if known\n                 provider=\"square\",\n                 amount=Decimal(str(payment_create_req.amount)),\n                 # Assuming provider_response.fee is in minor units (cents/pence)\n-                fee_amount= (Decimal(str(provider_response.get(\"fee\", 0))) / 100) if provider_response.get(\"fee\") is not None else square_provider.calculate_fee(Decimal(str(payment_create_req.amount))),\n-                provider_fee= (Decimal(str(provider_response.get(\"fee\", 0))) / 100) if provider_response.get(\"fee\") is not None else square_provider.calculate_fee(Decimal(str(payment_create_req.amount))),\n+                fee_amount=(\n+                    (Decimal(str(provider_response.get(\"fee\", 0))) / 100)\n+                    if provider_response.get(\"fee\") is not None\n+                    else square_provider.calculate_fee(\n+                        Decimal(str(payment_create_req.amount))\n+                    )\n+                ),\n+                provider_fee=(\n+                    (Decimal(str(provider_response.get(\"fee\", 0))) / 100)\n+                    if provider_response.get(\"fee\") is not None\n+                    else square_provider.calculate_fee(\n+                        Decimal(str(payment_create_req.amount))\n+                    )\n+                ),\n                 # Assuming provider_response.net_amount is in minor units\n-                net_amount= (Decimal(str(provider_response.get(\"net_amount\", 0))) / 100) if provider_response.get(\"net_amount\") is not None else (Decimal(str(payment_create_req.amount)) - square_provider.calculate_fee(Decimal(str(payment_create_req.amount)))),\n+                net_amount=(\n+                    (Decimal(str(provider_response.get(\"net_amount\", 0))) / 100)\n+                    if provider_response.get(\"net_amount\") is not None\n+                    else (\n+                        Decimal(str(payment_create_req.amount))\n+                        - square_provider.calculate_fee(\n+                            Decimal(str(payment_create_req.amount))\n+                        )\n+                    )\n+                ),\n                 status=provider_response[\"status\"],\n                 external_id=provider_response[\"transaction_id\"],\n-                processed_at=datetime.utcnow() if provider_response[\"status\"] == PaymentStatus.SUCCESS.value else None,\n+                processed_at=(\n+                    datetime.utcnow()\n+                    if provider_response[\"status\"] == PaymentStatus.SUCCESS.value\n+                    else None\n+                ),\n                 payment_metadata={\n                     \"provider_response\": provider_response.get(\"raw_response\", {}),\n                     \"source_id\": payment_create_req.source_id,\n                     \"customer_id\": payment_create_req.customer_id,\n-                    **(payment_create_req.metadata or {})\n-                }\n+                    **(payment_create_req.metadata or {}),\n+                },\n             )\n             db.add(payment_db)\n             if order and provider_response[\"status\"] == PaymentStatus.SUCCESS.value:\n                 order.payment_status = \"completed\"\n-                order.status = \"confirmed\" if order.status == \"pending\" else order.status\n+                order.status = (\n+                    \"confirmed\" if order.status == \"pending\" else order.status\n+                )\n \n             await audit_service.create_audit_log(\n-                event_type=AuditEventType.PAYMENT_SUCCESS if provider_response[\"status\"] == PaymentStatus.SUCCESS.value else AuditEventType.PAYMENT_PENDING,\n-                event_status=AuditEventStatus.SUCCESS if provider_response[\"status\"] == PaymentStatus.SUCCESS.value else AuditEventStatus.PENDING,\n+                event_type=(\n+                    AuditEventType.PAYMENT_SUCCESS\n+                    if provider_response[\"status\"] == PaymentStatus.SUCCESS.value\n+                    else AuditEventType.PAYMENT_PENDING\n+                ),\n+                event_status=(\n+                    AuditEventStatus.SUCCESS\n+                    if provider_response[\"status\"] == PaymentStatus.SUCCESS.value\n+                    else AuditEventStatus.PENDING\n+                ),\n                 action_performed=f\"Square payment status: {provider_response['status']}.\",\n-                user_id=current_user.id, username_or_email=current_user.email, ip_address=ip_address, user_agent=user_agent,\n-                resource_type=\"Payment\", resource_id=str(payment_db.id), # ID after flush\n-                details={\"external_id\": provider_response[\"transaction_id\"], \"provider_status\": provider_response.get(\"raw_response\", {}).get(\"payment\", {}).get(\"status\")},\n-                commit=True) # Commit audit and payment together\n+                user_id=current_user.id,\n+                username_or_email=current_user.email,\n+                ip_address=ip_address,\n+                user_agent=user_agent,\n+                resource_type=\"Payment\",\n+                resource_id=str(payment_db.id),  # ID after flush\n+                details={\n+                    \"external_id\": provider_response[\"transaction_id\"],\n+                    \"provider_status\": provider_response.get(\"raw_response\", {})\n+                    .get(\"payment\", {})\n+                    .get(\"status\"),\n+                },\n+                commit=True,\n+            )  # Commit audit and payment together\n             db.commit()\n             db.refresh(payment_db)\n             internal_payment_id = str(payment_db.id)\n-        else: # Payment failed at provider level\n+        else:  # Payment failed at provider level\n             await audit_service.create_audit_log(\n-                event_type=AuditEventType.PAYMENT_FAILURE, event_status=AuditEventStatus.FAILURE,\n+                event_type=AuditEventType.PAYMENT_FAILURE,\n+                event_status=AuditEventStatus.FAILURE,\n                 action_performed=\"Square payment creation failed by provider.\",\n-                user_id=current_user.id, username_or_email=current_user.email, ip_address=ip_address, user_agent=user_agent,\n-                details={\"error\": provider_response.get(\"error\", \"Unknown\"), \"provider_response\": provider_response.get(\"raw_response\")}, commit=True)\n+                user_id=current_user.id,\n+                username_or_email=current_user.email,\n+                ip_address=ip_address,\n+                user_agent=user_agent,\n+                details={\n+                    \"error\": provider_response.get(\"error\", \"Unknown\"),\n+                    \"provider_response\": provider_response.get(\"raw_response\"),\n+                },\n+                commit=True,\n+            )\n             # db.commit() # Commit only audit log for failure\n-            raise BusinessLogicException(message=provider_response.get(\"error\", \"Square payment creation failed\"))\n+            raise BusinessLogicException(\n+                message=provider_response.get(\"error\", \"Square payment creation failed\")\n+            )\n \n         return SquarePaymentResponseData(\n             payment_id=internal_payment_id,\n             provider=\"square\",\n             transaction_id=provider_response.get(\"transaction_id\"),\n             status=provider_response[\"status\"],\n-            amount=float(provider_response.get(\"amount\", payment_create_req.amount)), # Amount in major units\n+            amount=float(\n+                provider_response.get(\"amount\", payment_create_req.amount)\n+            ),  # Amount in major units\n             currency=provider_response.get(\"currency\", payment_create_req.currency),\n-            fee=float(Decimal(str(provider_response.get(\"fee\", 0))) / 100) if provider_response.get(\"fee\") is not None else None,\n-            net_amount=float(Decimal(str(provider_response.get(\"net_amount\", 0))) / 100) if provider_response.get(\"net_amount\") is not None else None,\n+            fee=(\n+                float(Decimal(str(provider_response.get(\"fee\", 0))) / 100)\n+                if provider_response.get(\"fee\") is not None\n+                else None\n+            ),\n+            net_amount=(\n+                float(Decimal(str(provider_response.get(\"net_amount\", 0))) / 100)\n+                if provider_response.get(\"net_amount\") is not None\n+                else None\n+            ),\n             message=provider_response.get(\"message\", \"Payment processed by Square.\"),\n-            raw_response=provider_response.get(\"raw_response\")\n+            raw_response=provider_response.get(\"raw_response\"),\n         )\n \n     except FynloException:\n-        raise # Re-raise FynloException to preserve status code and detail\n+        raise  # Re-raise FynloException to preserve status code and detail\n     except Exception as e:\n         logger.error(f\"Square payment creation error: {str(e)}\", exc_info=True)\n         await audit_service.create_audit_log(\n-            event_type=AuditEventType.PAYMENT_FAILURE, event_status=AuditEventStatus.FAILURE,\n+            event_type=AuditEventType.PAYMENT_FAILURE,\n+            event_status=AuditEventStatus.FAILURE,\n             action_performed=\"Square payment creation failed due to server error.\",\n-            user_id=current_user.id, username_or_email=current_user.email, ip_address=ip_address, user_agent=user_agent,\n-            details={\"error\": str(e)}, commit=True)\n+            user_id=current_user.id,\n+            username_or_email=current_user.email,\n+            ip_address=ip_address,\n+            user_agent=user_agent,\n+            details={\"error\": str(e)},\n+            commit=True,\n+        )\n         # db.commit() # Commit audit log\n         raise PaymentException(message=str(e))\n \n \n-@router.post(\"/square/process\", response_model=SquarePaymentResponseData, tags=[\"Payments - Square\"])\n+@router.post(\n+    \"/square/process\",\n+    response_model=SquarePaymentResponseData,\n+    tags=[\"Payments - Square\"],\n+)\n async def square_process_payment_endpoint(\n     http_request: Request,\n     payment_process_req: SquareProcessPaymentRequest,\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Restaurant ID for multi-location owners\"),\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Restaurant ID for multi-location owners\"\n+    ),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Process (complete) a Square payment that was created with auto_complete=false.\"\"\"\n     # Validate restaurant access for multi-tenant\n     await TenantSecurity.validate_restaurant_access(\n         current_user, current_restaurant_id or current_user.restaurant_id, db=db\n     )\n     restaurant_id = current_restaurant_id or current_user.restaurant_id\n-    \n+\n     audit_service = AuditLoggerService(db)\n     ip_address = http_request.client.host if http_request.client else \"unknown\"\n     user_agent = http_request.headers.get(\"user-agent\", \"unknown\")\n \n     try:\n-        square_provider = await payment_factory.get_provider_instance(\"square\", db_session=db)\n+        square_provider = await payment_factory.get_provider_instance(\n+            \"square\", db_session=db\n+        )\n         if not square_provider:\n             raise ServiceUnavailableError(message=\"Square provider not available.\")\n \n         # Find the original payment record in our DB by external_id (Square Payment ID)\n         # Ensure it belongs to the restaurant\n-        payment_db = db.query(Payment).join(Order).filter(\n-            Payment.external_id == payment_process_req.payment_id,\n-            Payment.provider == \"square\",\n-            Order.restaurant_id == restaurant_id\n-        ).first()\n+        payment_db = (\n+            db.query(Payment)\n+            .join(Order)\n+            .filter(\n+                Payment.external_id == payment_process_req.payment_id,\n+                Payment.provider == \"square\",\n+                Order.restaurant_id == restaurant_id,\n+            )\n+            .first()\n+        )\n         if not payment_db:\n             await audit_service.create_audit_log(\n-                event_type=AuditEventType.PAYMENT_FAILURE, event_status=AuditEventStatus.FAILURE,\n+                event_type=AuditEventType.PAYMENT_FAILURE,\n+                event_status=AuditEventStatus.FAILURE,\n                 action_performed=\"Square payment process failed: Original payment record not found.\",\n-                user_id=current_user.id, username_or_email=current_user.email, ip_address=ip_address, user_agent=user_agent,\n-                details={\"external_payment_id\": payment_process_req.payment_id}, commit=True)\n-            raise ResourceNotFoundException(message=f\"Payment with Square ID {payment_process_req.payment_id} not found in local records.\")\n-\n-        if payment_db.status == PaymentStatus.SUCCESS.value: # Already completed\n-             await audit_service.create_audit_log(\n-                event_type=AuditEventType.PAYMENT_INFO, event_status=AuditEventStatus.INFO,\n+                user_id=current_user.id,\n+                username_or_email=current_user.email,\n+                ip_address=ip_address,\n+                user_agent=user_agent,\n+                details={\"external_payment_id\": payment_process_req.payment_id},\n+                commit=True,\n+            )\n+            raise ResourceNotFoundException(\n+                message=f\"Payment with Square ID {payment_process_req.payment_id} not found in local records.\"\n+            )\n+\n+        if payment_db.status == PaymentStatus.SUCCESS.value:  # Already completed\n+            await audit_service.create_audit_log(\n+                event_type=AuditEventType.PAYMENT_INFO,\n+                event_status=AuditEventStatus.INFO,\n                 action_performed=\"Square payment process attempt: Payment already completed.\",\n-                user_id=current_user.id, username_or_email=current_user.email, ip_address=ip_address, user_agent=user_agent,\n-                resource_type=\"Payment\", resource_id=str(payment_db.id), details={\"external_id\": payment_process_req.payment_id}, commit=True)\n-             # Still, let's fetch the latest status from Square and return it.\n-             # This path could be enhanced to just call get_payment_status.\n-\n-        await audit_service.create_audit_log(\n-            event_type=AuditEventType.PAYMENT_PROCESSING, event_status=AuditEventStatus.PENDING, # Using a distinct type\n+                user_id=current_user.id,\n+                username_or_email=current_user.email,\n+                ip_address=ip_address,\n+                user_agent=user_agent,\n+                resource_type=\"Payment\",\n+                resource_id=str(payment_db.id),\n+                details={\"external_id\": payment_process_req.payment_id},\n+                commit=True,\n+            )\n+            # Still, let's fetch the latest status from Square and return it.\n+            # This path could be enhanced to just call get_payment_status.\n+\n+        await audit_service.create_audit_log(\n+            event_type=AuditEventType.PAYMENT_PROCESSING,\n+            event_status=AuditEventStatus.PENDING,  # Using a distinct type\n             action_performed=\"Square payment completion (process) initiated.\",\n-            user_id=current_user.id, username_or_email=current_user.email, ip_address=ip_address, user_agent=user_agent,\n-            resource_type=\"Payment\", resource_id=str(payment_db.id),\n-            details={\"external_payment_id\": payment_process_req.payment_id, \"order_id_param\": payment_process_req.order_id},\n-            commit=False) # Commit with payment update\n+            user_id=current_user.id,\n+            username_or_email=current_user.email,\n+            ip_address=ip_address,\n+            user_agent=user_agent,\n+            resource_type=\"Payment\",\n+            resource_id=str(payment_db.id),\n+            details={\n+                \"external_payment_id\": payment_process_req.payment_id,\n+                \"order_id_param\": payment_process_req.order_id,\n+            },\n+            commit=False,\n+        )  # Commit with payment update\n \n         provider_response = await square_provider.process_payment(\n             payment_id=payment_process_req.payment_id,\n-            order_id=payment_process_req.order_id # Pass along if provider uses it\n+            order_id=payment_process_req.order_id,  # Pass along if provider uses it\n         )\n \n         current_provider_status = provider_response.get(\"status\")\n         payment_db.status = current_provider_status\n-        payment_db.payment_metadata = {**payment_db.payment_metadata, \"process_response\": provider_response.get(\"raw_response\")}\n+        payment_db.payment_metadata = {\n+            **payment_db.payment_metadata,\n+            \"process_response\": provider_response.get(\"raw_response\"),\n+        }\n \n         if current_provider_status == PaymentStatus.SUCCESS.value:\n             payment_db.processed_at = datetime.utcnow()\n             if payment_db.order_id:\n                 order = db.query(Order).filter(Order.id == payment_db.order_id).first()\n                 if order:\n                     order.payment_status = \"completed\"\n-                    order.status = \"confirmed\" if order.status == \"pending\" else order.status\n+                    order.status = (\n+                        \"confirmed\" if order.status == \"pending\" else order.status\n+                    )\n \n             await audit_service.create_audit_log(\n-                event_type=AuditEventType.PAYMENT_SUCCESS, event_status=AuditEventStatus.SUCCESS,\n+                event_type=AuditEventType.PAYMENT_SUCCESS,\n+                event_status=AuditEventStatus.SUCCESS,\n                 action_performed=\"Square payment processed/completed successfully.\",\n-                user_id=current_user.id, username_or_email=current_user.email, ip_address=ip_address, user_agent=user_agent,\n-                resource_type=\"Payment\", resource_id=str(payment_db.id),\n-                details={\"external_id\": payment_process_req.payment_id, \"final_status\": current_provider_status}, commit=True)\n-        else: # Failed or still pending\n+                user_id=current_user.id,\n+                username_or_email=current_user.email,\n+                ip_address=ip_address,\n+                user_agent=user_agent,\n+                resource_type=\"Payment\",\n+                resource_id=str(payment_db.id),\n+                details={\n+                    \"external_id\": payment_process_req.payment_id,\n+                    \"final_status\": current_provider_status,\n+                },\n+                commit=True,\n+            )\n+        else:  # Failed or still pending\n             await audit_service.create_audit_log(\n-                event_type=AuditEventType.PAYMENT_FAILURE, event_status=AuditEventStatus.FAILURE,\n+                event_type=AuditEventType.PAYMENT_FAILURE,\n+                event_status=AuditEventStatus.FAILURE,\n                 action_performed=f\"Square payment process resulted in status: {current_provider_status}.\",\n-                user_id=current_user.id, username_or_email=current_user.email, ip_address=ip_address, user_agent=user_agent,\n-                resource_type=\"Payment\", resource_id=str(payment_db.id),\n-                details={\"external_id\": payment_process_req.payment_id, \"error\": provider_response.get(\"error\"), \"final_status\": current_provider_status}, commit=True)\n+                user_id=current_user.id,\n+                username_or_email=current_user.email,\n+                ip_address=ip_address,\n+                user_agent=user_agent,\n+                resource_type=\"Payment\",\n+                resource_id=str(payment_db.id),\n+                details={\n+                    \"external_id\": payment_process_req.payment_id,\n+                    \"error\": provider_response.get(\"error\"),\n+                    \"final_status\": current_provider_status,\n+                },\n+                commit=True,\n+            )\n \n         db.commit()\n         db.refresh(payment_db)\n \n         return SquarePaymentResponseData(\n             payment_id=str(payment_db.id),\n             provider=\"square\",\n-            transaction_id=provider_response.get(\"transaction_id\", payment_process_req.payment_id),\n+            transaction_id=provider_response.get(\n+                \"transaction_id\", payment_process_req.payment_id\n+            ),\n             status=current_provider_status,\n             amount=float(provider_response.get(\"amount\", payment_db.amount)),\n-            currency=provider_response.get(\"currency\", payment_db.payment_metadata.get(\"currency\", \"GBP\")),\n-            fee=float(Decimal(str(provider_response.get(\"fee\", 0))) / 100) if provider_response.get(\"fee\") is not None else None,\n-            net_amount=float(Decimal(str(provider_response.get(\"net_amount\", 0))) / 100) if provider_response.get(\"net_amount\") is not None else None,\n-            message=provider_response.get(\"message\", f\"Square payment processed. Status: {current_provider_status}\"),\n-            raw_response=provider_response.get(\"raw_response\")\n+            currency=provider_response.get(\n+                \"currency\", payment_db.payment_metadata.get(\"currency\", \"GBP\")\n+            ),\n+            fee=(\n+                float(Decimal(str(provider_response.get(\"fee\", 0))) / 100)\n+                if provider_response.get(\"fee\") is not None\n+                else None\n+            ),\n+            net_amount=(\n+                float(Decimal(str(provider_response.get(\"net_amount\", 0))) / 100)\n+                if provider_response.get(\"net_amount\") is not None\n+                else None\n+            ),\n+            message=provider_response.get(\n+                \"message\",\n+                f\"Square payment processed. Status: {current_provider_status}\",\n+            ),\n+            raw_response=provider_response.get(\"raw_response\"),\n         )\n \n     except FynloException:\n         raise\n     except Exception as e:\n         logger.error(f\"Square payment processing error: {str(e)}\", exc_info=True)\n         await audit_service.create_audit_log(\n-            event_type=AuditEventType.PAYMENT_FAILURE, event_status=AuditEventStatus.FAILURE,\n+            event_type=AuditEventType.PAYMENT_FAILURE,\n+            event_status=AuditEventStatus.FAILURE,\n             action_performed=\"Square payment processing failed due to server error.\",\n-            user_id=current_user.id, username_or_email=current_user.email, ip_address=ip_address, user_agent=user_agent,\n-            details={\"external_payment_id\": payment_process_req.payment_id, \"error\": str(e)}, commit=True)\n+            user_id=current_user.id,\n+            username_or_email=current_user.email,\n+            ip_address=ip_address,\n+            user_agent=user_agent,\n+            details={\n+                \"external_payment_id\": payment_process_req.payment_id,\n+                \"error\": str(e),\n+            },\n+            commit=True,\n+        )\n         raise PaymentException(message=str(e))\n \n \n-@router.get(\"/square/status/{payment_id}\", response_model=SquarePaymentResponseData, tags=[\"Payments - Square\"])\n+@router.get(\n+    \"/square/status/{payment_id}\",\n+    response_model=SquarePaymentResponseData,\n+    tags=[\"Payments - Square\"],\n+)\n async def square_get_payment_status_endpoint(\n     http_request: Request,\n-    payment_id: str, # This is the Square Payment ID (external_id)\n-    current_restaurant_id: Optional[str] = Query(None, description=\"Restaurant ID for multi-location owners\"),\n+    payment_id: str,  # This is the Square Payment ID (external_id)\n+    current_restaurant_id: Optional[str] = Query(\n+        None, description=\"Restaurant ID for multi-location owners\"\n+    ),\n     db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    current_user: User = Depends(get_current_user),\n ):\n     \"\"\"Get the status of a Square payment by its Square Payment ID.\"\"\"\n     # Validate restaurant access for multi-tenant\n     await TenantSecurity.validate_restaurant_access(\n         current_user, current_restaurant_id or current_user.restaurant_id, db=db\n     )\n     restaurant_id = current_restaurant_id or current_user.restaurant_id\n-    \n+\n     audit_service = AuditLoggerService(db)\n     ip_address = http_request.client.host if http_request.client else \"unknown\"\n     user_agent = http_request.headers.get(\"user-agent\", \"unknown\")\n \n     try:\n-        square_provider = await payment_factory.get_provider_instance(\"square\", db_session=db)\n+        square_provider = await payment_factory.get_provider_instance(\n+            \"square\", db_session=db\n+        )\n         if not square_provider:\n             raise ServiceUnavailableError(message=\"Square provider not available.\")\n \n         # Optional: Log audit for status check initiation\n         # await audit_service.create_audit_log(...)\n \n-        provider_response = await square_provider.get_payment_status(payment_id=payment_id)\n+        provider_response = await square_provider.get_payment_status(\n+            payment_id=payment_id\n+        )\n \n         # Optional: Update local DB record if status has changed and we want to sync\n         # payment_db = db.query(Payment).filter(Payment.external_id == payment_id, Payment.provider == \"square\").first()\n         # if payment_db and payment_db.status != provider_response.get(\"status\"):\n         #     payment_db.status = provider_response.get(\"status\")\n@@ -1437,250 +1952,405 @@\n         #     db.refresh(payment_db)\n         #     internal_payment_id = str(payment_db.id)\n         # else:\n         #     internal_payment_id = str(payment_db.id) if payment_db else None\n \n-\n-        if provider_response.get(\"status\") == PaymentStatus.FAILED.value and \"Failed to retrieve payment status\" in provider_response.get(\"error\",\"\"):\n-             # This specific error from provider.get_payment_status implies the ID might not exist with Square\n+        if provider_response.get(\n+            \"status\"\n+        ) == PaymentStatus.FAILED.value and \"Failed to retrieve payment status\" in provider_response.get(\n+            \"error\", \"\"\n+        ):\n+            # This specific error from provider.get_payment_status implies the ID might not exist with Square\n             await audit_service.create_audit_log(\n-                event_type=AuditEventType.PAYMENT_INFO, event_status=AuditEventStatus.FAILURE, # Using INFO as it's a status check\n+                event_type=AuditEventType.PAYMENT_INFO,\n+                event_status=AuditEventStatus.FAILURE,  # Using INFO as it's a status check\n                 action_performed=\"Square payment status check: Payment not found by provider.\",\n-                user_id=current_user.id, username_or_email=current_user.email, ip_address=ip_address, user_agent=user_agent,\n-                details={\"external_payment_id\": payment_id, \"error\": provider_response.get(\"error\")}, commit=True)\n-            raise ResourceNotFoundException(message=f\"Square payment with ID {payment_id} not found by provider.\")\n+                user_id=current_user.id,\n+                username_or_email=current_user.email,\n+                ip_address=ip_address,\n+                user_agent=user_agent,\n+                details={\n+                    \"external_payment_id\": payment_id,\n+                    \"error\": provider_response.get(\"error\"),\n+                },\n+                commit=True,\n+            )\n+            raise ResourceNotFoundException(\n+                message=f\"Square payment with ID {payment_id} not found by provider.\"\n+            )\n \n         return SquarePaymentResponseData(\n             # payment_id=internal_payment_id, # Our internal ID, if fetched\n             provider=\"square\",\n             transaction_id=provider_response.get(\"transaction_id\", payment_id),\n             status=provider_response[\"status\"],\n-            amount=float(provider_response.get(\"amount\", 0)), # Amount in major units\n+            amount=float(provider_response.get(\"amount\", 0)),  # Amount in major units\n             currency=provider_response.get(\"currency\", \"GBP\"),\n-            fee=float(Decimal(str(provider_response.get(\"fee\", 0))) / 100) if provider_response.get(\"fee\") is not None else None,\n-            net_amount=float(Decimal(str(provider_response.get(\"net_amount\", 0))) / 100) if provider_response.get(\"net_amount\") is not None else None,\n-            message=provider_response.get(\"message\", f\"Square payment status: {provider_response['status']}\"),\n-            raw_response=provider_response.get(\"raw_response\")\n+            fee=(\n+                float(Decimal(str(provider_response.get(\"fee\", 0))) / 100)\n+                if provider_response.get(\"fee\") is not None\n+                else None\n+            ),\n+            net_amount=(\n+                float(Decimal(str(provider_response.get(\"net_amount\", 0))) / 100)\n+                if provider_response.get(\"net_amount\") is not None\n+                else None\n+            ),\n+            message=provider_response.get(\n+                \"message\", f\"Square payment status: {provider_response['status']}\"\n+            ),\n+            raw_response=provider_response.get(\"raw_response\"),\n         )\n     except FynloException:\n         raise\n     except Exception as e:\n         logger.error(f\"Square payment status retrieval error: {str(e)}\", exc_info=True)\n         await audit_service.create_audit_log(\n-            event_type=AuditEventType.PAYMENT_FAILURE, event_status=AuditEventStatus.FAILURE,\n+            event_type=AuditEventType.PAYMENT_FAILURE,\n+            event_status=AuditEventStatus.FAILURE,\n             action_performed=\"Square payment status retrieval failed due to server error.\",\n-            user_id=current_user.id, username_or_email=current_user.email, ip_address=ip_address, user_agent=user_agent,\n-            details={\"external_payment_id\": payment_id, \"error\": str(e)}, commit=True)\n+            user_id=current_user.id,\n+            username_or_email=current_user.email,\n+            ip_address=ip_address,\n+            user_agent=user_agent,\n+            details={\"external_payment_id\": payment_id, \"error\": str(e)},\n+            commit=True,\n+        )\n         raise PaymentException(message=str(e))\n \n+\n # --- Stripe Webhook Endpoint ---\n \n-@router.post(\"/webhooks/stripe\", include_in_schema=False) # include_in_schema=False as it's not for direct client calls\n+\n+@router.post(\n+    \"/webhooks/stripe\", include_in_schema=False\n+)  # include_in_schema=False as it's not for direct client calls\n async def stripe_webhook_endpoint(\n-    http_request: Request, # Renamed from request to avoid conflict with fastapi.Request\n-    db: Session = Depends(get_db) # Added db session dependency\n+    http_request: Request,  # Renamed from request to avoid conflict with fastapi.Request\n+    db: Session = Depends(get_db),  # Added db session dependency\n ):\n     \"\"\"Handle incoming webhooks from Stripe.\"\"\"\n     payload = await http_request.body()\n-    sig_header = http_request.headers.get('stripe-signature')\n-    audit_service = AuditLoggerService(db) # Initialize AuditLoggerService\n+    sig_header = http_request.headers.get(\"stripe-signature\")\n+    audit_service = AuditLoggerService(db)  # Initialize AuditLoggerService\n     ip_address = http_request.client.host if http_request.client else \"unknown\"\n-    user_agent = http_request.headers.get(\"user-agent\", \"unknown\") # Though less relevant for webhooks\n+    user_agent = http_request.headers.get(\n+        \"user-agent\", \"unknown\"\n+    )  # Though less relevant for webhooks\n \n     if not settings.STRIPE_WEBHOOK_SECRET:\n         logger.error(\"Stripe webhook secret is not configured.\")\n         # Audit this critical configuration error\n         # Using a generic user_id/email for system-level audit if no specific user context\n         await audit_service.create_audit_log(\n-            event_type=AuditEventType.SYSTEM_ERROR, event_status=AuditEventStatus.FAILURE,\n+            event_type=AuditEventType.SYSTEM_ERROR,\n+            event_status=AuditEventStatus.FAILURE,\n             action_performed=\"Stripe webhook processing failed: Missing webhook secret.\",\n-            user_id=\"SYSTEM\", username_or_email=\"system@fynlo.com\",\n-            ip_address=ip_address, user_agent=\"Stripe Webhook\",\n+            user_id=\"SYSTEM\",\n+            username_or_email=\"system@fynlo.com\",\n+            ip_address=ip_address,\n+            user_agent=\"Stripe Webhook\",\n             details={\"reason\": \"STRIPE_WEBHOOK_SECRET not set in environment.\"},\n-            commit=True\n+            commit=True,\n         )\n         raise FynloException(message=\"Webhook secret not configured.\")\n \n     try:\n         event = stripe.Webhook.construct_event(\n             payload, sig_header, settings.STRIPE_WEBHOOK_SECRET\n         )\n-    except ValueError as e: # Invalid payload\n+    except ValueError as e:  # Invalid payload\n         logger.error(f\"Stripe webhook error: Invalid payload. {str(e)}\")\n         await audit_service.create_audit_log(\n-            event_type=AuditEventType.WEBHOOK_PROCESSING_ERROR, event_status=AuditEventStatus.FAILURE,\n+            event_type=AuditEventType.WEBHOOK_PROCESSING_ERROR,\n+            event_status=AuditEventStatus.FAILURE,\n             action_performed=\"Stripe webhook processing failed: Invalid payload.\",\n-            user_id=\"SYSTEM\", username_or_email=\"system@fynlo.com\", ip_address=ip_address,\n-            details={\"error\": str(e), \"payload_start\": payload[:200].decode('utf-8', errors='replace')}, commit=True\n+            user_id=\"SYSTEM\",\n+            username_or_email=\"system@fynlo.com\",\n+            ip_address=ip_address,\n+            details={\n+                \"error\": str(e),\n+                \"payload_start\": payload[:200].decode(\"utf-8\", errors=\"replace\"),\n+            },\n+            commit=True,\n         )\n         raise ValidationException(message=\"Invalid payload\")\n-    except stripe.error.SignatureVerificationError as e: # Invalid signature\n+    except stripe.error.SignatureVerificationError as e:  # Invalid signature\n         logger.error(f\"Stripe webhook error: Invalid signature. {str(e)}\")\n         await audit_service.create_audit_log(\n-            event_type=AuditEventType.WEBHOOK_PROCESSING_ERROR, event_status=AuditEventStatus.FAILURE,\n+            event_type=AuditEventType.WEBHOOK_PROCESSING_ERROR,\n+            event_status=AuditEventStatus.FAILURE,\n             action_performed=\"Stripe webhook processing failed: Invalid signature.\",\n-            user_id=\"SYSTEM\", username_or_email=\"system@fynlo.com\", ip_address=ip_address,\n-            details={\"error\": str(e), \"signature_header\": sig_header}, commit=True\n+            user_id=\"SYSTEM\",\n+            username_or_email=\"system@fynlo.com\",\n+            ip_address=ip_address,\n+            details={\"error\": str(e), \"signature_header\": sig_header},\n+            commit=True,\n         )\n         raise ValidationException(message=\"Invalid signature\")\n-    except Exception as e: # Other construction errors\n+    except Exception as e:  # Other construction errors\n         logger.error(f\"Stripe webhook event construction error: {str(e)}\")\n         await audit_service.create_audit_log(\n-            event_type=AuditEventType.WEBHOOK_PROCESSING_ERROR, event_status=AuditEventStatus.FAILURE,\n+            event_type=AuditEventType.WEBHOOK_PROCESSING_ERROR,\n+            event_status=AuditEventStatus.FAILURE,\n             action_performed=\"Stripe webhook processing failed: Event construction error.\",\n-            user_id=\"SYSTEM\", username_or_email=\"system@fynlo.com\", ip_address=ip_address,\n-            details={\"error\": str(e)}, commit=True\n+            user_id=\"SYSTEM\",\n+            username_or_email=\"system@fynlo.com\",\n+            ip_address=ip_address,\n+            details={\"error\": str(e)},\n+            commit=True,\n         )\n         raise FynloException(message=\"Webhook event construction error\")\n \n     # At this point, event is trusted.\n     logger.info(f\"Received Stripe event: id={event.id}, type={event.type}\")\n     await audit_service.create_audit_log(\n-        event_type=AuditEventType.WEBHOOK_RECEIVED, event_status=AuditEventStatus.SUCCESS,\n+        event_type=AuditEventType.WEBHOOK_RECEIVED,\n+        event_status=AuditEventStatus.SUCCESS,\n         action_performed=f\"Stripe webhook event received: {event.type}\",\n-        user_id=\"SYSTEM\", username_or_email=\"stripe_webhook@fynlo.com\", ip_address=ip_address,\n-        resource_type=\"StripeEvent\", resource_id=event.id,\n-        details={\"event_type\": event.type, \"event_id\": event.id, \"livemode\": event.livemode},\n-        commit=True # Commit this log immediately\n+        user_id=\"SYSTEM\",\n+        username_or_email=\"stripe_webhook@fynlo.com\",\n+        ip_address=ip_address,\n+        resource_type=\"StripeEvent\",\n+        resource_id=event.id,\n+        details={\n+            \"event_type\": event.type,\n+            \"event_id\": event.id,\n+            \"livemode\": event.livemode,\n+        },\n+        commit=True,  # Commit this log immediately\n     )\n \n     # Handle the event\n-        # For example:\n+    # For example:\n     # processed_event = db.query(ProcessedWebhookEvent).filter(ProcessedWebhookEvent.event_id == event.id).first()\n     # if processed_event:\n     #     logger.info(f\"Stripe event {event.id} already processed.\")\n     #     return {\"status\": \"event already processed\"}\n     # else:\n     #     db.add(ProcessedWebhookEvent(event_id=event.id, processed_at=datetime.utcnow()))\n     #     # db.commit() // Commit within the specific handler or at the end\n \n     try:\n-        if event.type == 'payment_intent.succeeded':\n+        if event.type == \"payment_intent.succeeded\":\n             payment_intent = event.data.object\n             logger.info(f\"PaymentIntent {payment_intent.id} succeeded.\")\n-            payment = db.query(Payment).filter(Payment.external_id == payment_intent.id, Payment.provider == \"stripe\").first()\n+            payment = (\n+                db.query(Payment)\n+                .filter(\n+                    Payment.external_id == payment_intent.id,\n+                    Payment.provider == \"stripe\",\n+                )\n+                .first()\n+            )\n             if payment:\n-                if payment.status != PaymentStatus.SUCCESS.value: # Avoid reprocessing if already success\n+                if (\n+                    payment.status != PaymentStatus.SUCCESS.value\n+                ):  # Avoid reprocessing if already success\n                     payment.status = PaymentStatus.SUCCESS.value\n                     payment.processed_at = datetime.utcnow()\n-                    payment.payment_metadata = {**payment.payment_metadata, \"webhook_succeeded_event\": event.to_dict_recursive()}\n+                    payment.payment_metadata = {\n+                        **payment.payment_metadata,\n+                        \"webhook_succeeded_event\": event.to_dict_recursive(),\n+                    }\n \n                     if payment.order_id:\n-                        order = db.query(Order).filter(Order.id == payment.order_id).first()\n+                        order = (\n+                            db.query(Order).filter(Order.id == payment.order_id).first()\n+                        )\n                         if order:\n                             order.payment_status = \"completed\"\n-                            order.status = \"confirmed\" if order.status == \"pending\" else order.status\n+                            order.status = (\n+                                \"confirmed\"\n+                                if order.status == \"pending\"\n+                                else order.status\n+                            )\n \n                     await audit_service.create_audit_log(\n-                        event_type=AuditEventType.PAYMENT_SUCCESS, event_status=AuditEventStatus.SUCCESS,\n+                        event_type=AuditEventType.PAYMENT_SUCCESS,\n+                        event_status=AuditEventStatus.SUCCESS,\n                         action_performed=\"Stripe PaymentIntent succeeded (webhook).\",\n-                        resource_type=\"Payment\", resource_id=str(payment.id),\n-                        details={\"external_id\": payment_intent.id, \"amount\": payment_intent.amount / 100}, commit=True)\n+                        resource_type=\"Payment\",\n+                        resource_id=str(payment.id),\n+                        details={\n+                            \"external_id\": payment_intent.id,\n+                            \"amount\": payment_intent.amount / 100,\n+                        },\n+                        commit=True,\n+                    )\n                     db.commit()\n                 else:\n-                    logger.info(f\"PaymentIntent {payment_intent.id} already marked as SUCCESS in DB. Webhook ignored for idempotency.\")\n+                    logger.info(\n+                        f\"PaymentIntent {payment_intent.id} already marked as SUCCESS in DB. Webhook ignored for idempotency.\"\n+                    )\n             else:\n-                logger.warning(f\"Received {event.type} for unknown PaymentIntent {payment_intent.id}\")\n+                logger.warning(\n+                    f\"Received {event.type} for unknown PaymentIntent {payment_intent.id}\"\n+                )\n                 await audit_service.create_audit_log(\n-                    event_type=AuditEventType.WEBHOOK_PROCESSING_ERROR, event_status=AuditEventStatus.WARNING,\n+                    event_type=AuditEventType.WEBHOOK_PROCESSING_ERROR,\n+                    event_status=AuditEventStatus.WARNING,\n                     action_performed=f\"Stripe event {event.type} for unknown PaymentIntent.\",\n-                    details={\"external_id\": payment_intent.id, \"event_id\": event.id}, commit=True)\n-\n-        elif event.type == 'payment_intent.payment_failed':\n+                    details={\"external_id\": payment_intent.id, \"event_id\": event.id},\n+                    commit=True,\n+                )\n+\n+        elif event.type == \"payment_intent.payment_failed\":\n             payment_intent = event.data.object\n             logger.info(f\"PaymentIntent {payment_intent.id} failed.\")\n-            payment = db.query(Payment).filter(Payment.external_id == payment_intent.id, Payment.provider == \"stripe\").first()\n+            payment = (\n+                db.query(Payment)\n+                .filter(\n+                    Payment.external_id == payment_intent.id,\n+                    Payment.provider == \"stripe\",\n+                )\n+                .first()\n+            )\n             if payment:\n                 if payment.status != PaymentStatus.FAILED.value:\n                     payment.status = PaymentStatus.FAILED.value\n                     error_details = payment_intent.last_payment_error\n                     payment.payment_metadata = {\n                         **payment.payment_metadata,\n                         \"webhook_failed_event\": event.to_dict_recursive(),\n-                        \"failure_reason\": error_details.message if error_details else \"Unknown\",\n-                        \"failure_code\": error_details.code if error_details else \"Unknown\"\n+                        \"failure_reason\": (\n+                            error_details.message if error_details else \"Unknown\"\n+                        ),\n+                        \"failure_code\": (\n+                            error_details.code if error_details else \"Unknown\"\n+                        ),\n                     }\n                     await audit_service.create_audit_log(\n-                        event_type=AuditEventType.PAYMENT_FAILURE, event_status=AuditEventStatus.FAILURE,\n+                        event_type=AuditEventType.PAYMENT_FAILURE,\n+                        event_status=AuditEventStatus.FAILURE,\n                         action_performed=\"Stripe PaymentIntent failed (webhook).\",\n-                        resource_type=\"Payment\", resource_id=str(payment.id),\n+                        resource_type=\"Payment\",\n+                        resource_id=str(payment.id),\n                         details={\n                             \"external_id\": payment_intent.id,\n-                            \"error_message\": error_details.message if error_details else \"N/A\",\n-                            \"error_code\": error_details.code if error_details else \"N/A\"\n-                        }, commit=True)\n+                            \"error_message\": (\n+                                error_details.message if error_details else \"N/A\"\n+                            ),\n+                            \"error_code\": (\n+                                error_details.code if error_details else \"N/A\"\n+                            ),\n+                        },\n+                        commit=True,\n+                    )\n                     db.commit()\n                 else:\n-                    logger.info(f\"PaymentIntent {payment_intent.id} already marked as FAILED in DB. Webhook ignored for idempotency.\")\n+                    logger.info(\n+                        f\"PaymentIntent {payment_intent.id} already marked as FAILED in DB. Webhook ignored for idempotency.\"\n+                    )\n             else:\n-                logger.warning(f\"Received {event.type} for unknown PaymentIntent {payment_intent.id}\")\n+                logger.warning(\n+                    f\"Received {event.type} for unknown PaymentIntent {payment_intent.id}\"\n+                )\n                 await audit_service.create_audit_log(\n-                    event_type=AuditEventType.WEBHOOK_PROCESSING_ERROR, event_status=AuditEventStatus.WARNING,\n+                    event_type=AuditEventType.WEBHOOK_PROCESSING_ERROR,\n+                    event_status=AuditEventStatus.WARNING,\n                     action_performed=f\"Stripe event {event.type} for unknown PaymentIntent.\",\n-                    details={\"external_id\": payment_intent.id, \"event_id\": event.id}, commit=True)\n-\n-        elif event.type == 'charge.refunded':\n-            charge = event.data.object # This is a Charge object\n+                    details={\"external_id\": payment_intent.id, \"event_id\": event.id},\n+                    commit=True,\n+                )\n+\n+        elif event.type == \"charge.refunded\":\n+            charge = event.data.object  # This is a Charge object\n             payment_intent_id = charge.payment_intent\n             logger.info(f\"Charge {charge.id} (for PI {payment_intent_id}) refunded.\")\n-            payment = db.query(Payment).filter(Payment.external_id == payment_intent_id, Payment.provider == \"stripe\").first()\n+            payment = (\n+                db.query(Payment)\n+                .filter(\n+                    Payment.external_id == payment_intent_id,\n+                    Payment.provider == \"stripe\",\n+                )\n+                .first()\n+            )\n             if payment:\n                 # Stripe sends charge.refunded for each refund.\n                 # If partial refunds, amount_refunded in PI might be sum.\n                 # Here we mark the payment as 'refunded' or 'partially_refunded'\n                 # This logic might need refinement based on full vs partial refund handling strategy.\n                 # For simplicity, if any refund occurs, mark as 'refunded'.\n                 # More complex logic would check payment.amount vs charge.amount_refunded / 100\n-                if payment.status != PaymentStatus.REFUNDED.value: # Basic idempotency\n-                    payment.status = PaymentStatus.REFUNDED.value # Or a new PARTIALLY_REFUNDED status\n+                if payment.status != PaymentStatus.REFUNDED.value:  # Basic idempotency\n+                    payment.status = (\n+                        PaymentStatus.REFUNDED.value\n+                    )  # Or a new PARTIALLY_REFUNDED status\n                     payment.payment_metadata = {\n                         **payment.payment_metadata,\n                         f\"webhook_charge_refunded_{charge.id}\": event.to_dict_recursive(),\n-                        \"refunded_amount_from_charge\": charge.amount_refunded / 100\n+                        \"refunded_amount_from_charge\": charge.amount_refunded / 100,\n                     }\n                     await audit_service.create_audit_log(\n-                        event_type=AuditEventType.REFUND_SUCCESS, event_status=AuditEventStatus.SUCCESS,\n+                        event_type=AuditEventType.REFUND_SUCCESS,\n+                        event_status=AuditEventStatus.SUCCESS,\n                         action_performed=\"Stripe charge refunded (webhook).\",\n-                        resource_type=\"Payment\", resource_id=str(payment.id),\n+                        resource_type=\"Payment\",\n+                        resource_id=str(payment.id),\n                         details={\n                             \"external_id\": payment_intent_id,\n                             \"charge_id\": charge.id,\n-                            \"refunded_amount\": charge.amount_refunded / 100\n-                        }, commit=True)\n+                            \"refunded_amount\": charge.amount_refunded / 100,\n+                        },\n+                        commit=True,\n+                    )\n                     db.commit()\n                 else:\n-                     logger.info(f\"PaymentIntent {payment_intent_id} already marked as REFUNDED. Refund event for charge {charge.id} noted.\")\n+                    logger.info(\n+                        f\"PaymentIntent {payment_intent_id} already marked as REFUNDED. Refund event for charge {charge.id} noted.\"\n+                    )\n \n             else:\n-                logger.warning(f\"Received {event.type} for charge {charge.id} linked to unknown PaymentIntent {payment_intent_id}\")\n+                logger.warning(\n+                    f\"Received {event.type} for charge {charge.id} linked to unknown PaymentIntent {payment_intent_id}\"\n+                )\n                 await audit_service.create_audit_log(\n-                    event_type=AuditEventType.WEBHOOK_PROCESSING_ERROR, event_status=AuditEventStatus.WARNING,\n+                    event_type=AuditEventType.WEBHOOK_PROCESSING_ERROR,\n+                    event_status=AuditEventStatus.WARNING,\n                     action_performed=f\"Stripe event {event.type} for charge on unknown PI.\",\n-                    details={\"charge_id\": charge.id, \"payment_intent_id\": payment_intent_id, \"event_id\": event.id}, commit=True)\n+                    details={\n+                        \"charge_id\": charge.id,\n+                        \"payment_intent_id\": payment_intent_id,\n+                        \"event_id\": event.id,\n+                    },\n+                    commit=True,\n+                )\n \n         # Add more event handlers here as needed:\n         # elif event.type == 'payment_intent.requires_action':\n         # elif event.type == 'customer.subscription.deleted':\n         # etc.\n \n         else:\n             logger.info(f\"Received unhandled Stripe event type: {event.type}\")\n             await audit_service.create_audit_log(\n-                event_type=AuditEventType.WEBHOOK_UNHANDLED, event_status=AuditEventStatus.INFO,\n+                event_type=AuditEventType.WEBHOOK_UNHANDLED,\n+                event_status=AuditEventStatus.INFO,\n                 action_performed=f\"Stripe webhook event type {event.type} received but not handled.\",\n-                details={\"event_id\": event.id, \"event_type\": event.type}, commit=True)\n+                details={\"event_id\": event.id, \"event_type\": event.type},\n+                commit=True,\n+            )\n \n     except Exception as e:\n-        logger.error(f\"Error processing Stripe webhook event {event.id if 'event' in locals() else 'UNKNOWN_EVENT_ID'}: {str(e)}\", exc_info=True)\n-        await audit_service.create_audit_log(\n-            event_type=AuditEventType.WEBHOOK_PROCESSING_ERROR, event_status=AuditEventStatus.FAILURE,\n+        logger.error(\n+            f\"Error processing Stripe webhook event {event.id if 'event' in locals() else 'UNKNOWN_EVENT_ID'}: {str(e)}\",\n+            exc_info=True,\n+        )\n+        await audit_service.create_audit_log(\n+            event_type=AuditEventType.WEBHOOK_PROCESSING_ERROR,\n+            event_status=AuditEventStatus.FAILURE,\n             action_performed=\"Stripe webhook event processing failed with exception.\",\n-            details={\"event_id\": event.id if 'event' in locals() else 'N/A', \"event_type\": event.type if 'event' in locals() else 'N/A', \"error\": str(e)},\n-            commit=True\n+            details={\n+                \"event_id\": event.id if \"event\" in locals() else \"N/A\",\n+                \"event_type\": event.type if \"event\" in locals() else \"N/A\",\n+                \"error\": str(e),\n+            },\n+            commit=True,\n         )\n         # It's generally recommended to return 200 to Stripe to prevent retries for errors\n         # that are unlikely to be resolved by retrying the same event (e.g., bugs in handler).\n         # For transient errors (DB down), a 5xx might be appropriate to trigger retries.\n         # For now, let's return 200 to acknowledge receipt and avoid excessive retries for handler bugs.\n         # If a specific error should trigger retries, raise FynloException(message=\"An error occurred processing the request\", status_code=500) here.\n \n-    return {\"status\": \"success\", \"message\": \"Webhook received\"}\n\\ No newline at end of file\n+    return {\"status\": \"success\", \"message\": \"Webhook received\"}\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/production_guard.py\t2025-08-02 22:10:56.788808+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/production_guard.py\t2025-08-02 22:36:03.294585+00:00\n@@ -14,23 +14,31 @@\n     Decorator that prevents function execution in production environment\n     Use this to wrap any test/debug endpoints or functionality\n     Works with both sync and async functions\n     \"\"\"\n     if asyncio.iscoroutinefunction(func):\n+\n         @wraps(func)\n         async def async_wrapper(*args, **kwargs):\n             if settings.ENVIRONMENT == \"production\":\n-                raise FynloException(message=\"This endpoint is not available in production environment\")\n+                raise FynloException(\n+                    message=\"This endpoint is not available in production environment\"\n+                )\n             return await func(*args, **kwargs)\n+\n         return async_wrapper\n     else:\n+\n         @wraps(func)\n         def sync_wrapper(*args, **kwargs):\n             \"\"\"Execute sync_wrapper operation.\"\"\"\n             if settings.ENVIRONMENT == \"production\":\n-                raise FynloException(message=\"This endpoint is not available in production environment\")\n+                raise FynloException(\n+                    message=\"This endpoint is not available in production environment\"\n+                )\n             return func(*args, **kwargs)\n+\n         return sync_wrapper\n \n \n def is_production() -> bool:\n     \"\"\"Check if running in production environment\"\"\"\n@@ -43,6 +51,6 @@\n \n \n def ensure_not_production():\n     \"\"\"Raise exception if running in production\"\"\"\n     if is_production():\n-        raise RuntimeError(\"This code should not run in production environment\")\n\\ No newline at end of file\n+        raise RuntimeError(\"This code should not run in production environment\")\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/exceptions.py\t2025-08-02 21:56:58.994742+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/exceptions.py\t2025-08-02 22:36:03.297395+00:00\n@@ -10,278 +10,287 @@\n from pydantic import BaseModel\n import logging\n import traceback\n import uuid\n \n-from app.core.config import settings # Import settings\n+from app.core.config import settings  # Import settings\n from app.core.responses import APIResponseHelper, ErrorCodes\n \n \n logger = logging.getLogger(__name__)\n \n \n class FynloException(Exception):\n     \"\"\"Base exception class for Fynlo POS specific errors\"\"\"\n-    \n+\n     def __init__(\n         self,\n         message: str,\n         error_code: str = ErrorCodes.INTERNAL_ERROR,\n         details: Optional[Dict[str, Any]] = None,\n-        status_code: int = 500\n+        status_code: int = 500,\n     ):\n         self.message = message\n         self.error_code = error_code\n         self.details = details or {}\n         self.status_code = status_code\n         super().__init__(self.message)\n \n \n class AuthenticationException(FynloException):\n     \"\"\"Authentication related exceptions\"\"\"\n-    \n-    def __init__(self, message: str = \"Authentication failed\", details: Optional[Dict[str, Any]] = None):\n+\n+    def __init__(\n+        self,\n+        message: str = \"Authentication failed\",\n+        details: Optional[Dict[str, Any]] = None,\n+    ):\n         super().__init__(\n             message=message,\n             error_code=ErrorCodes.INVALID_CREDENTIALS,\n             details=details,\n-            status_code=401\n+            status_code=401,\n         )\n \n \n class AuthorizationException(FynloException):\n     \"\"\"Authorization related exceptions\"\"\"\n-    \n-    def __init__(self, message: str = \"Access denied\", details: Optional[Dict[str, Any]] = None):\n+\n+    def __init__(\n+        self, message: str = \"Access denied\", details: Optional[Dict[str, Any]] = None\n+    ):\n         super().__init__(\n             message=message,\n             error_code=ErrorCodes.FORBIDDEN,\n             details=details,\n-            status_code=403\n+            status_code=403,\n         )\n \n \n class ValidationException(FynloException):\n     \"\"\"Validation related exceptions\"\"\"\n-    \n+\n     def __init__(\n         self,\n         message: str = \"Validation failed\",\n         field: Optional[str] = None,\n-        details: Optional[Dict[str, Any]] = None\n+        details: Optional[Dict[str, Any]] = None,\n     ):\n         validation_details = details or {}\n         if field:\n             validation_details[\"field\"] = field\n-            \n+\n         super().__init__(\n             message=message,\n             error_code=ErrorCodes.VALIDATION_ERROR,\n             details=validation_details,\n-            status_code=422\n+            status_code=422,\n         )\n \n \n class ResourceNotFoundException(FynloException):\n     \"\"\"Resource not found exceptions\"\"\"\n-    \n+\n     def __init__(\n         self,\n         resource: str = \"Resource\",\n         resource_id: Optional[str] = None,\n-        details: Optional[Dict[str, Any]] = None\n+        details: Optional[Dict[str, Any]] = None,\n     ):\n         message = f\"{resource} not found\"\n         if resource_id:\n             message += f\" (ID: {resource_id})\"\n-            \n+\n         resource_details = details or {}\n         if resource_id:\n             resource_details[\"resource_id\"] = resource_id\n         resource_details[\"resource_type\"] = resource\n-            \n+\n         super().__init__(\n             message=message,\n             error_code=ErrorCodes.NOT_FOUND,\n             details=resource_details,\n-            status_code=404\n+            status_code=404,\n         )\n \n \n class ConflictException(FynloException):\n     \"\"\"Resource conflict exceptions\"\"\"\n-    \n+\n     def __init__(\n         self,\n         message: str = \"Resource conflict\",\n         conflicting_field: Optional[str] = None,\n-        details: Optional[Dict[str, Any]] = None\n+        details: Optional[Dict[str, Any]] = None,\n     ):\n         conflict_details = details or {}\n         if conflicting_field:\n             conflict_details[\"conflicting_field\"] = conflicting_field\n-            \n+\n         super().__init__(\n             message=message,\n             error_code=ErrorCodes.CONFLICT,\n             details=conflict_details,\n-            status_code=409\n+            status_code=409,\n         )\n \n \n class BusinessLogicException(FynloException):\n     \"\"\"Business logic related exceptions\"\"\"\n-    \n+\n     def __init__(\n         self,\n         message: str,\n         error_code: str = ErrorCodes.INVALID_ORDER_STATE,\n-        details: Optional[Dict[str, Any]] = None\n-    ):\n-        super().__init__(\n-            message=message,\n-            error_code=error_code,\n-            details=details,\n-            status_code=400\n+        details: Optional[Dict[str, Any]] = None,\n+    ):\n+        super().__init__(\n+            message=message, error_code=error_code, details=details, status_code=400\n         )\n \n \n class PaymentException(FynloException):\n     \"\"\"Payment processing exceptions\"\"\"\n-    \n+\n     def __init__(\n         self,\n         message: str = \"Payment processing failed\",\n         payment_method: Optional[str] = None,\n-        details: Optional[Dict[str, Any]] = None\n+        details: Optional[Dict[str, Any]] = None,\n     ):\n         payment_details = details or {}\n         if payment_method:\n             payment_details[\"payment_method\"] = payment_method\n-            \n+\n         super().__init__(\n             message=message,\n             error_code=ErrorCodes.PAYMENT_FAILED,\n             details=payment_details,\n-            status_code=400\n+            status_code=400,\n         )\n \n \n class ServiceUnavailableError(FynloException):\n     \"\"\"Service unavailable exceptions for critical infrastructure failures\"\"\"\n-    \n+\n     def __init__(\n         self,\n         message: str = \"Service temporarily unavailable\",\n         service_name: Optional[str] = None,\n         retry_after: Optional[int] = None,\n-        details: Optional[Dict[str, Any]] = None\n+        details: Optional[Dict[str, Any]] = None,\n     ):\n         service_details = details or {}\n         if service_name:\n             service_details[\"service\"] = service_name\n         if retry_after:\n             service_details[\"retry_after_seconds\"] = retry_after\n-            \n+\n         super().__init__(\n             message=message,\n             error_code=ErrorCodes.SERVICE_UNAVAILABLE,\n             details=service_details,\n-            status_code=503\n+            status_code=503,\n         )\n \n \n class InventoryException(FynloException):\n     \"\"\"Inventory related exceptions\"\"\"\n-    \n+\n     def __init__(\n         self,\n         message: str = \"Insufficient stock\",\n         product_id: Optional[str] = None,\n         requested_quantity: Optional[int] = None,\n         available_quantity: Optional[int] = None,\n-        details: Optional[Dict[str, Any]] = None\n+        details: Optional[Dict[str, Any]] = None,\n     ):\n         inventory_details = details or {}\n         if product_id:\n             inventory_details[\"product_id\"] = product_id\n         if requested_quantity is not None:\n             inventory_details[\"requested_quantity\"] = requested_quantity\n         if available_quantity is not None:\n             inventory_details[\"available_quantity\"] = available_quantity\n-            \n+\n         super().__init__(\n             message=message,\n             error_code=ErrorCodes.INSUFFICIENT_STOCK,\n             details=inventory_details,\n-            status_code=400\n-        )\n-\n-\n-async def fynlo_exception_handler(request: Request, exc: FynloException) -> JSONResponse:\n+            status_code=400,\n+        )\n+\n+\n+async def fynlo_exception_handler(\n+    request: Request, exc: FynloException\n+) -> JSONResponse:\n     \"\"\"Handle Fynlo specific exceptions\"\"\"\n-    \n+\n     # Log the exception for debugging\n     error_id = str(uuid.uuid4())\n     logger.error(\n         f\"FynloException [{error_id}]: {exc.error_code} - {exc.message}\",\n         extra={\n             \"error_id\": error_id,\n             \"error_code\": exc.error_code,\n             \"details\": exc.details,\n             \"request_path\": request.url.path,\n-            \"request_method\": request.method\n-        }\n-    )\n-    \n+            \"request_method\": request.method,\n+        },\n+    )\n+\n     # Add error_id to details for tracking\n     response_details = {\"error_id\": error_id}\n     if settings.ERROR_DETAIL_ENABLED:\n         response_details.update(exc.details)\n-    \n+\n     return APIResponseHelper.error(\n-        message=exc.message if settings.ERROR_DETAIL_ENABLED else \"An application error occurred.\",\n+        message=(\n+            exc.message\n+            if settings.ERROR_DETAIL_ENABLED\n+            else \"An application error occurred.\"\n+        ),\n         error_code=exc.error_code,\n         details=response_details,\n-        status_code=exc.status_code\n+        status_code=exc.status_code,\n     )\n \n \n async def http_exception_handler(request: Request, exc: HTTPException) -> JSONResponse:\n     \"\"\"Handle FastAPI HTTP exceptions with standardized format\"\"\"\n-    \n+\n     error_id = str(uuid.uuid4())\n     logger.error(\n         f\"HTTPException [{error_id}]: {exc.status_code} - {exc.detail}\",\n         extra={\n             \"error_id\": error_id,\n             \"status_code\": exc.status_code,\n             \"request_path\": request.url.path,\n-            \"request_method\": request.method\n-        }\n-    )\n-    \n+            \"request_method\": request.method,\n+        },\n+    )\n+\n     # Map common HTTP status codes to error codes\n     error_code_mapping = {\n         400: ErrorCodes.VALIDATION_ERROR,\n         401: ErrorCodes.UNAUTHORIZED,\n         403: ErrorCodes.FORBIDDEN,\n         404: ErrorCodes.NOT_FOUND,\n         409: ErrorCodes.CONFLICT,\n         422: ErrorCodes.VALIDATION_ERROR,\n-        500: ErrorCodes.INTERNAL_ERROR\n+        500: ErrorCodes.INTERNAL_ERROR,\n     }\n-    \n+\n     error_code = error_code_mapping.get(exc.status_code, ErrorCodes.INTERNAL_ERROR)\n-    \n+\n     generic_messages = {\n         400: \"Bad request.\",\n         401: \"Unauthorized.\",\n         403: \"Forbidden.\",\n         404: \"Resource not found.\",\n         422: \"Validation error.\",\n-        500: \"Internal server error.\"\n+        500: \"Internal server error.\",\n     }\n \n     response_message = str(exc.detail)\n     response_details = {\"error_id\": error_id}\n \n@@ -290,153 +299,158 @@\n         # For validation (422) or bad request (400) specifically,\n         # we might want a slightly more indicative generic message if details are hidden.\n         if exc.status_code == 422:\n             response_message = \"Request validation failed. Please check your input.\"\n         elif exc.status_code == 400:\n-             response_message = \"Invalid request format or data.\"\n-    elif isinstance(exc.detail, dict): # If detail is a dict, pass it along in debug mode\n+            response_message = \"Invalid request format or data.\"\n+    elif isinstance(\n+        exc.detail, dict\n+    ):  # If detail is a dict, pass it along in debug mode\n         response_details.update(exc.detail)\n-\n \n     return APIResponseHelper.error(\n         message=response_message,\n         error_code=error_code,\n         details=response_details,\n-        status_code=exc.status_code\n-    )\n-\n-\n-async def validation_exception_handler(request: Request, exc: RequestValidationError) -> JSONResponse:\n+        status_code=exc.status_code,\n+    )\n+\n+\n+async def validation_exception_handler(\n+    request: Request, exc: RequestValidationError\n+) -> JSONResponse:\n     \"\"\"Handle Pydantic validation exceptions with detailed field information\"\"\"\n-    \n+\n     error_id = str(uuid.uuid4())\n-    \n+\n     # Parse validation errors into iOS-friendly format\n     validation_errors = []\n     for error in exc.errors():\n         field_path = \" -> \".join(str(loc) for loc in error[\"loc\"])\n-        validation_errors.append({\n-            \"field\": field_path,\n-            \"message\": error[\"msg\"],\n-            \"type\": error[\"type\"],\n-            \"input\": error.get(\"input\")\n-        })\n-    \n+        validation_errors.append(\n+            {\n+                \"field\": field_path,\n+                \"message\": error[\"msg\"],\n+                \"type\": error[\"type\"],\n+                \"input\": error.get(\"input\"),\n+            }\n+        )\n+\n     logger.error(\n         f\"ValidationException [{error_id}]: Request validation failed\",\n         extra={\n             \"error_id\": error_id,\n             \"validation_errors\": validation_errors,\n             \"request_path\": request.url.path,\n-            \"request_method\": request.method\n-        }\n-    )\n-    \n+            \"request_method\": request.method,\n+        },\n+    )\n+\n     if settings.ERROR_DETAIL_ENABLED:\n         return APIResponseHelper.validation_error(\n             message=\"Request validation failed\",\n-            errors=validation_errors # Detailed errors\n+            errors=validation_errors,  # Detailed errors\n         )\n     else:\n         # In production (or when ERROR_DETAIL_ENABLED=false), return a generic validation error\n         # The detailed errors are still logged.\n         return APIResponseHelper.error(\n             message=\"Request validation failed. Please check your input.\",\n             error_code=ErrorCodes.VALIDATION_ERROR,\n-            details={\"error_id\": error_id}, # Only error_id, no specific field details\n-            status_code=422\n+            details={\"error_id\": error_id},  # Only error_id, no specific field details\n+            status_code=422,\n         )\n \n \n async def general_exception_handler(request: Request, exc: Exception) -> JSONResponse:\n     \"\"\"Handle unexpected exceptions with error tracking\"\"\"\n-    \n+\n     error_id = str(uuid.uuid4())\n-    \n+\n     # Log full traceback for debugging\n     logger.error(\n         f\"UnhandledException [{error_id}]: {type(exc).__name__} - {str(exc)}\",\n         extra={\n             \"error_id\": error_id,\n             \"exception_type\": type(exc).__name__,\n             \"traceback\": traceback.format_exc(),\n             \"request_path\": request.url.path,\n-            \"request_method\": request.method\n-        }\n-    )\n-    \n+            \"request_method\": request.method,\n+        },\n+    )\n+\n     # The message is already generic. Ensure no other details are leaked.\n     # The error_id is important for tracking.\n     response_message = \"An unexpected error occurred. Please try again later.\"\n     if settings.ERROR_DETAIL_ENABLED:\n         # Optionally, provide a bit more context in dev/debug mode, but still avoid full trace in response\n         response_message = f\"An unexpected error of type {type(exc).__name__} occurred.\"\n \n     return APIResponseHelper.internal_error(\n         message=response_message,\n-        error_id=error_id\n+        error_id=error_id,\n         # No other details should be sent to the client for general exceptions\n     )\n \n \n def register_exception_handlers(app):\n     \"\"\"Register all exception handlers with the FastAPI app\"\"\"\n-    \n+\n     app.add_exception_handler(FynloException, fynlo_exception_handler)\n     app.add_exception_handler(HTTPException, http_exception_handler)\n     app.add_exception_handler(RequestValidationError, validation_exception_handler)\n     app.add_exception_handler(Exception, general_exception_handler)\n \n \n # iOS-specific error utilities\n class iOSErrorHelper:\n     \"\"\"Helper functions for iOS-specific error handling\"\"\"\n-    \n+\n     @staticmethod\n     def invalid_credentials() -> AuthenticationException:\n         \"\"\"Standard invalid credentials error for iOS\"\"\"\n         return AuthenticationException(\n             message=\"Invalid email or password\",\n-            details={\"suggestion\": \"Please check your credentials and try again\"}\n-        )\n-    \n+            details={\"suggestion\": \"Please check your credentials and try again\"},\n+        )\n+\n     @staticmethod\n     def token_expired() -> AuthenticationException:\n         \"\"\"Standard token expired error for iOS\"\"\"\n         return AuthenticationException(\n             message=\"Your session has expired\",\n             details={\n                 \"error_code\": ErrorCodes.TOKEN_EXPIRED,\n-                \"suggestion\": \"Please log in again\"\n-            }\n-        )\n-    \n+                \"suggestion\": \"Please log in again\",\n+            },\n+        )\n+\n     @staticmethod\n     def insufficient_permissions() -> AuthorizationException:\n         \"\"\"Standard insufficient permissions error for iOS\"\"\"\n         return AuthorizationException(\n             message=\"You don't have permission to perform this action\",\n-            details={\"suggestion\": \"Contact your manager for access\"}\n-        )\n-    \n+            details={\"suggestion\": \"Contact your manager for access\"},\n+        )\n+\n     @staticmethod\n     def order_modification_denied(order_status: str) -> BusinessLogicException:\n         \"\"\"Standard order modification error for iOS\"\"\"\n         return BusinessLogicException(\n             message=f\"Cannot modify order in '{order_status}' status\",\n             error_code=ErrorCodes.ORDER_CANNOT_BE_MODIFIED,\n             details={\n                 \"current_status\": order_status,\n-                \"suggestion\": \"Contact kitchen staff if changes are needed\"\n-            }\n-        )\n-    \n+                \"suggestion\": \"Contact kitchen staff if changes are needed\",\n+            },\n+        )\n+\n     @staticmethod\n     def product_not_available(product_name: str) -> InventoryException:\n         \"\"\"Standard product availability error for iOS\"\"\"\n         return InventoryException(\n             message=f\"'{product_name}' is currently unavailable\",\n             details={\n                 \"product_name\": product_name,\n-                \"suggestion\": \"Please select an alternative item\"\n-            }\n-        )\n\\ No newline at end of file\n+                \"suggestion\": \"Please select an alternative item\",\n+            },\n+        )\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/analytics_engine.py\t2025-08-02 21:56:58.992848+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/analytics_engine.py\t2025-08-02 22:36:03.307044+00:00\n@@ -10,494 +10,582 @@\n from enum import Enum\n import json\n from dataclasses import dataclass\n from decimal import Decimal\n \n-from app.core.database import get_db, Order, Product, Customer, Payment, User, Restaurant\n+from app.core.database import (\n+    get_db,\n+    Order,\n+    Product,\n+    Customer,\n+    Payment,\n+    User,\n+    Restaurant,\n+)\n from app.core.exceptions import FynloException, ErrorCodes\n+\n \n class AnalyticsTimeframe(str, Enum):\n     \"\"\"Analytics timeframe options\"\"\"\n+\n     HOUR = \"hour\"\n     DAY = \"day\"\n     WEEK = \"week\"\n     MONTH = \"month\"\n     QUARTER = \"quarter\"\n     YEAR = \"year\"\n     CUSTOM = \"custom\"\n \n+\n class MetricType(str, Enum):\n     \"\"\"Analytics metric types\"\"\"\n+\n     REVENUE = \"revenue\"\n     ORDERS = \"orders\"\n     CUSTOMERS = \"customers\"\n     PRODUCTS = \"products\"\n     EMPLOYEES = \"employees\"\n     PERFORMANCE = \"performance\"\n \n+\n @dataclass\n class AnalyticsMetric:\n     \"\"\"Analytics metric data structure\"\"\"\n+\n     name: str\n     value: float\n     change_percent: Optional[float] = None\n     change_direction: Optional[str] = None  # \"up\", \"down\", \"neutral\"\n     formatted_value: Optional[str] = None\n     unit: Optional[str] = None\n     description: Optional[str] = None\n \n+\n @dataclass\n class TimeSeriesData:\n     \"\"\"Time series data point\"\"\"\n+\n     timestamp: datetime\n     value: float\n     label: Optional[str] = None\n \n+\n @dataclass\n class AnalyticsFilter:\n     \"\"\"Analytics filter criteria\"\"\"\n+\n     restaurant_id: str\n     start_date: datetime\n     end_date: datetime\n     compare_period: bool = False\n     employee_ids: Optional[List[str]] = None\n     product_categories: Optional[List[str]] = None\n     customer_segments: Optional[List[str]] = None\n \n+\n class AnalyticsEngine:\n     \"\"\"Advanced analytics engine for real-time dashboard metrics\"\"\"\n-    \n+\n     def __init__(self, db: Session):\n         self.db = db\n         \"\"\"\n         Get comprehensive dashboard overview with key metrics\n         \"\"\"\n         try:\n             # Calculate date range\n             end_date = end_date or datetime.now()\n             if not start_date:\n                 start_date = self._get_timeframe_start(end_date, timeframe)\n-            \n+\n             filter_criteria = AnalyticsFilter(\n                 restaurant_id=restaurant_id,\n                 start_date=start_date,\n                 end_date=end_date,\n-                compare_period=True\n-            )\n-            \n+                compare_period=True,\n+            )\n+\n             # Get key metrics\n             revenue_metrics = self._get_revenue_metrics(filter_criteria)\n             order_metrics = self._get_order_metrics(filter_criteria)\n             customer_metrics = self._get_customer_metrics(filter_criteria)\n             performance_metrics = self._get_performance_metrics(filter_criteria)\n-            \n+\n             # Get time series data for charts\n             revenue_trend = self._get_revenue_trend(filter_criteria, timeframe)\n             order_trend = self._get_order_trend(filter_criteria, timeframe)\n-            \n+\n             # Get top performing items\n             top_products = self._get_top_products(filter_criteria, limit=5)\n             recent_orders = self._get_recent_orders(filter_criteria, limit=10)\n-            \n+\n             return {\n                 \"timeframe\": timeframe.value,\n                 \"period\": {\n                     \"start_date\": start_date.isoformat(),\n-                    \"end_date\": end_date.isoformat()\n+                    \"end_date\": end_date.isoformat(),\n                 },\n                 \"key_metrics\": {\n                     \"revenue\": revenue_metrics,\n                     \"orders\": order_metrics,\n                     \"customers\": customer_metrics,\n-                    \"performance\": performance_metrics\n-                },\n-                \"trends\": {\n-                    \"revenue\": revenue_trend,\n-                    \"orders\": order_trend\n-                },\n+                    \"performance\": performance_metrics,\n+                },\n+                \"trends\": {\"revenue\": revenue_trend, \"orders\": order_trend},\n                 \"insights\": {\n                     \"top_products\": top_products,\n-                    \"recent_orders\": recent_orders\n-                },\n-                \"last_updated\": datetime.now().isoformat()\n+                    \"recent_orders\": recent_orders,\n+                },\n+                \"last_updated\": datetime.now().isoformat(),\n             }\n-            \n+\n         except Exception as e:\n             raise FynloException(\n                 message=f\"Failed to get dashboard overview: {str(e)}\",\n                 error_code=ErrorCodes.INTERNAL_ERROR,\n-                status_code=500\n+                status_code=500,\n             )\n         \"\"\"\n         Get detailed sales analytics and reporting\n         \"\"\"\n         try:\n             end_date = end_date or datetime.now()\n             if not start_date:\n                 start_date = self._get_timeframe_start(end_date, timeframe)\n-            \n+\n             filter_criteria = AnalyticsFilter(\n                 restaurant_id=restaurant_id,\n                 start_date=start_date,\n                 end_date=end_date,\n-                compare_period=True\n-            )\n-            \n+                compare_period=True,\n+            )\n+\n             # Sales overview\n             sales_overview = self._get_sales_overview(filter_criteria)\n-            \n+\n             # Sales by category\n             category_breakdown = self._get_sales_by_category(filter_criteria)\n-            \n+\n             # Sales by hour/day pattern\n             sales_pattern = self._get_sales_pattern(filter_criteria, timeframe)\n-            \n+\n             # Payment method breakdown\n             payment_methods = self._get_payment_method_breakdown(filter_criteria)\n-            \n+\n             # Average order analysis\n             order_analysis = self._get_order_analysis(filter_criteria)\n-            \n+\n             return {\n                 \"sales_overview\": sales_overview,\n                 \"category_breakdown\": category_breakdown,\n                 \"sales_pattern\": sales_pattern,\n                 \"payment_methods\": payment_methods,\n                 \"order_analysis\": order_analysis,\n                 \"period\": {\n                     \"start_date\": start_date.isoformat(),\n                     \"end_date\": end_date.isoformat(),\n-                    \"timeframe\": timeframe.value\n-                }\n+                    \"timeframe\": timeframe.value,\n+                },\n             }\n-            \n+\n         except Exception as e:\n             raise FynloException(\n                 message=f\"Failed to get sales analytics: {str(e)}\",\n                 error_code=ErrorCodes.INTERNAL_ERROR,\n-                status_code=500\n+                status_code=500,\n             )\n         \"\"\"\n         Get employee performance analytics\n         \"\"\"\n         try:\n             end_date = end_date or datetime.now()\n             if not start_date:\n                 start_date = self._get_timeframe_start(end_date, timeframe)\n-            \n+\n             # Get employee performance data\n-            employees = self.db.query(User).filter(\n-                User.restaurant_id == restaurant_id,\n-                User.role.in_([\"employee\", \"manager\"])\n-            ).all()\n-            \n+            employees = (\n+                self.db.query(User)\n+                .filter(\n+                    User.restaurant_id == restaurant_id,\n+                    User.role.in_([\"employee\", \"manager\"]),\n+                )\n+                .all()\n+            )\n+\n             employee_metrics = []\n-            \n+\n             for employee in employees:\n                 # Get orders handled by employee\n-                orders = self.db.query(Order).filter(\n-                    and_(\n-                        Order.restaurant_id == restaurant_id,\n-                        Order.created_by == employee.id,\n-                        Order.created_at >= start_date,\n-                        Order.created_at <= end_date\n+                orders = (\n+                    self.db.query(Order)\n+                    .filter(\n+                        and_(\n+                            Order.restaurant_id == restaurant_id,\n+                            Order.created_by == employee.id,\n+                            Order.created_at >= start_date,\n+                            Order.created_at <= end_date,\n+                        )\n                     )\n-                ).all()\n-                \n+                    .all()\n+                )\n+\n                 completed_orders = [o for o in orders if o.status == \"completed\"]\n                 total_revenue = sum(o.total_amount for o in completed_orders)\n-                \n+\n                 # Calculate performance metrics\n-                avg_order_value = total_revenue / len(completed_orders) if completed_orders else 0\n-                completion_rate = len(completed_orders) / len(orders) * 100 if orders else 0\n-                \n-                employee_metrics.append({\n-                    \"employee_id\": str(employee.id),\n-                    \"employee_name\": employee.username,\n-                    \"role\": employee.role,\n-                    \"total_orders\": len(orders),\n-                    \"completed_orders\": len(completed_orders),\n-                    \"total_revenue\": float(total_revenue),\n-                    \"avg_order_value\": float(avg_order_value),\n-                    \"completion_rate\": round(completion_rate, 2),\n-                    \"orders_per_hour\": round(len(orders) / 8, 2)  # Assuming 8-hour shifts\n-                })\n-            \n+                avg_order_value = (\n+                    total_revenue / len(completed_orders) if completed_orders else 0\n+                )\n+                completion_rate = (\n+                    len(completed_orders) / len(orders) * 100 if orders else 0\n+                )\n+\n+                employee_metrics.append(\n+                    {\n+                        \"employee_id\": str(employee.id),\n+                        \"employee_name\": employee.username,\n+                        \"role\": employee.role,\n+                        \"total_orders\": len(orders),\n+                        \"completed_orders\": len(completed_orders),\n+                        \"total_revenue\": float(total_revenue),\n+                        \"avg_order_value\": float(avg_order_value),\n+                        \"completion_rate\": round(completion_rate, 2),\n+                        \"orders_per_hour\": round(\n+                            len(orders) / 8, 2\n+                        ),  # Assuming 8-hour shifts\n+                    }\n+                )\n+\n             # Sort by performance (total revenue)\n             employee_metrics.sort(key=lambda x: x[\"total_revenue\"], reverse=True)\n-            \n+\n             # Calculate team averages\n             team_totals = {\n                 \"total_orders\": sum(e[\"total_orders\"] for e in employee_metrics),\n                 \"total_revenue\": sum(e[\"total_revenue\"] for e in employee_metrics),\n-                \"avg_completion_rate\": sum(e[\"completion_rate\"] for e in employee_metrics) / len(employee_metrics) if employee_metrics else 0\n+                \"avg_completion_rate\": (\n+                    sum(e[\"completion_rate\"] for e in employee_metrics)\n+                    / len(employee_metrics)\n+                    if employee_metrics\n+                    else 0\n+                ),\n             }\n-            \n+\n             return {\n                 \"employee_performance\": employee_metrics,\n                 \"team_summary\": team_totals,\n                 \"top_performers\": employee_metrics[:3],\n                 \"period\": {\n                     \"start_date\": start_date.isoformat(),\n                     \"end_date\": end_date.isoformat(),\n-                    \"timeframe\": timeframe.value\n-                }\n+                    \"timeframe\": timeframe.value,\n+                },\n             }\n-            \n+\n         except Exception as e:\n             raise FynloException(\n                 message=f\"Failed to get employee performance: {str(e)}\",\n                 error_code=ErrorCodes.INTERNAL_ERROR,\n-                status_code=500\n+                status_code=500,\n             )\n         \"\"\"\n         Get customer behavior and analytics\n         \"\"\"\n         try:\n             end_date = end_date or datetime.now()\n             if not start_date:\n                 start_date = self._get_timeframe_start(end_date, timeframe)\n-            \n+\n             # Customer overview\n-            total_customers = self.db.query(Customer).filter(\n-                Customer.restaurant_id == restaurant_id\n-            ).count()\n-            \n+            total_customers = (\n+                self.db.query(Customer)\n+                .filter(Customer.restaurant_id == restaurant_id)\n+                .count()\n+            )\n+\n             # New customers in period\n-            new_customers = self.db.query(Customer).filter(\n-                and_(\n-                    Customer.restaurant_id == restaurant_id,\n-                    Customer.created_at >= start_date,\n-                    Customer.created_at <= end_date\n-                )\n-            ).count()\n-            \n+            new_customers = (\n+                self.db.query(Customer)\n+                .filter(\n+                    and_(\n+                        Customer.restaurant_id == restaurant_id,\n+                        Customer.created_at >= start_date,\n+                        Customer.created_at <= end_date,\n+                    )\n+                )\n+                .count()\n+            )\n+\n             # Customer orders in period\n-            customer_orders = self.db.query(Order, Customer).join(\n-                Customer, Order.customer_id == Customer.id\n-            ).filter(\n-                and_(\n-                    Order.restaurant_id == restaurant_id,\n-                    Order.created_at >= start_date,\n-                    Order.created_at <= end_date\n-                )\n-            ).all()\n-            \n+            customer_orders = (\n+                self.db.query(Order, Customer)\n+                .join(Customer, Order.customer_id == Customer.id)\n+                .filter(\n+                    and_(\n+                        Order.restaurant_id == restaurant_id,\n+                        Order.created_at >= start_date,\n+                        Order.created_at <= end_date,\n+                    )\n+                )\n+                .all()\n+            )\n+\n             # Customer lifetime value analysis\n             customer_ltv = {}\n             for order, customer in customer_orders:\n                 if customer.id not in customer_ltv:\n                     customer_ltv[customer.id] = {\n                         \"customer_name\": customer.name,\n                         \"total_orders\": 0,\n                         \"total_spent\": 0,\n                         \"first_order\": None,\n-                        \"last_order\": None\n+                        \"last_order\": None,\n                     }\n-                \n+\n                 customer_ltv[customer.id][\"total_orders\"] += 1\n                 customer_ltv[customer.id][\"total_spent\"] += float(order.total_amount)\n-                \n-                if not customer_ltv[customer.id][\"first_order\"] or order.created_at < customer_ltv[customer.id][\"first_order\"]:\n+\n+                if (\n+                    not customer_ltv[customer.id][\"first_order\"]\n+                    or order.created_at < customer_ltv[customer.id][\"first_order\"]\n+                ):\n                     customer_ltv[customer.id][\"first_order\"] = order.created_at\n-                \n-                if not customer_ltv[customer.id][\"last_order\"] or order.created_at > customer_ltv[customer.id][\"last_order\"]:\n+\n+                if (\n+                    not customer_ltv[customer.id][\"last_order\"]\n+                    or order.created_at > customer_ltv[customer.id][\"last_order\"]\n+                ):\n                     customer_ltv[customer.id][\"last_order\"] = order.created_at\n-            \n+\n             # Top customers by value\n             top_customers = sorted(\n-                customer_ltv.values(),\n-                key=lambda x: x[\"total_spent\"],\n-                reverse=True\n+                customer_ltv.values(), key=lambda x: x[\"total_spent\"], reverse=True\n             )[:10]\n-            \n+\n             # Customer frequency analysis\n-            repeat_customers = len([c for c in customer_ltv.values() if c[\"total_orders\"] > 1])\n-            repeat_rate = (repeat_customers / len(customer_ltv) * 100) if customer_ltv else 0\n-            \n+            repeat_customers = len(\n+                [c for c in customer_ltv.values() if c[\"total_orders\"] > 1]\n+            )\n+            repeat_rate = (\n+                (repeat_customers / len(customer_ltv) * 100) if customer_ltv else 0\n+            )\n+\n             # Average order frequency\n-            avg_orders_per_customer = sum(c[\"total_orders\"] for c in customer_ltv.values()) / len(customer_ltv) if customer_ltv else 0\n-            avg_spend_per_customer = sum(c[\"total_spent\"] for c in customer_ltv.values()) / len(customer_ltv) if customer_ltv else 0\n-            \n+            avg_orders_per_customer = (\n+                sum(c[\"total_orders\"] for c in customer_ltv.values())\n+                / len(customer_ltv)\n+                if customer_ltv\n+                else 0\n+            )\n+            avg_spend_per_customer = (\n+                sum(c[\"total_spent\"] for c in customer_ltv.values()) / len(customer_ltv)\n+                if customer_ltv\n+                else 0\n+            )\n+\n             return {\n                 \"customer_overview\": {\n                     \"total_customers\": total_customers,\n                     \"new_customers\": new_customers,\n                     \"active_customers\": len(customer_ltv),\n                     \"repeat_customers\": repeat_customers,\n-                    \"repeat_rate\": round(repeat_rate, 2)\n+                    \"repeat_rate\": round(repeat_rate, 2),\n                 },\n                 \"customer_metrics\": {\n                     \"avg_orders_per_customer\": round(avg_orders_per_customer, 2),\n                     \"avg_spend_per_customer\": round(avg_spend_per_customer, 2),\n-                    \"customer_lifetime_value\": round(avg_spend_per_customer, 2)\n+                    \"customer_lifetime_value\": round(avg_spend_per_customer, 2),\n                 },\n                 \"top_customers\": top_customers,\n                 \"period\": {\n                     \"start_date\": start_date.isoformat(),\n                     \"end_date\": end_date.isoformat(),\n-                    \"timeframe\": timeframe.value\n-                }\n+                    \"timeframe\": timeframe.value,\n+                },\n             }\n-            \n+\n         except Exception as e:\n             raise FynloException(\n                 message=f\"Failed to get customer analytics: {str(e)}\",\n                 error_code=ErrorCodes.INTERNAL_ERROR,\n-                status_code=500\n+                status_code=500,\n             )\n         \"\"\"\n         Get inventory and product analytics\n         \"\"\"\n         try:\n             end_date = end_date or datetime.now()\n             if not start_date:\n                 start_date = self._get_timeframe_start(end_date, timeframe)\n-            \n+\n             # Get all products\n-            products = self.db.query(Product).filter(\n-                Product.restaurant_id == restaurant_id\n-            ).all()\n-            \n+            products = (\n+                self.db.query(Product)\n+                .filter(Product.restaurant_id == restaurant_id)\n+                .all()\n+            )\n+\n             product_analytics = []\n-            \n+\n             for product in products:\n                 # Get orders containing this product\n                 # Note: This would need order_items table in real implementation\n                 product_orders = []  # Placeholder for order items query\n-                \n+\n                 # Calculate product metrics\n                 total_sold = len(product_orders)  # Would be sum of quantities\n                 total_revenue = sum(float(product.price) for _ in product_orders)\n-                \n+\n                 # Stock analysis\n-                stock_level = product.stock_quantity if hasattr(product, 'stock_quantity') else 0\n+                stock_level = (\n+                    product.stock_quantity if hasattr(product, \"stock_quantity\") else 0\n+                )\n                 min_stock = 10  # Would be from product settings\n                 stock_status = \"low\" if stock_level < min_stock else \"normal\"\n-                \n-                product_analytics.append({\n-                    \"product_id\": str(product.id),\n-                    \"product_name\": product.name,\n-                    \"category\": getattr(product, 'category', 'General'),\n-                    \"price\": float(product.price),\n-                    \"stock_level\": stock_level,\n-                    \"stock_status\": stock_status,\n-                    \"units_sold\": total_sold,\n-                    \"revenue_generated\": total_revenue,\n-                    \"popularity_rank\": 0  # Would be calculated based on sales\n-                })\n-            \n+\n+                product_analytics.append(\n+                    {\n+                        \"product_id\": str(product.id),\n+                        \"product_name\": product.name,\n+                        \"category\": getattr(product, \"category\", \"General\"),\n+                        \"price\": float(product.price),\n+                        \"stock_level\": stock_level,\n+                        \"stock_status\": stock_status,\n+                        \"units_sold\": total_sold,\n+                        \"revenue_generated\": total_revenue,\n+                        \"popularity_rank\": 0,  # Would be calculated based on sales\n+                    }\n+                )\n+\n             # Sort by revenue\n             product_analytics.sort(key=lambda x: x[\"revenue_generated\"], reverse=True)\n-            \n+\n             # Add popularity ranks\n             for i, product in enumerate(product_analytics):\n                 product[\"popularity_rank\"] = i + 1\n-            \n+\n             # Category analysis\n             categories = {}\n             for product in product_analytics:\n                 category = product[\"category\"]\n                 if category not in categories:\n                     categories[category] = {\n                         \"total_products\": 0,\n                         \"total_revenue\": 0,\n-                        \"units_sold\": 0\n+                        \"units_sold\": 0,\n                     }\n-                \n+\n                 categories[category][\"total_products\"] += 1\n                 categories[category][\"total_revenue\"] += product[\"revenue_generated\"]\n                 categories[category][\"units_sold\"] += product[\"units_sold\"]\n-            \n+\n             # Low stock alerts\n-            low_stock_items = [p for p in product_analytics if p[\"stock_status\"] == \"low\"]\n-            \n+            low_stock_items = [\n+                p for p in product_analytics if p[\"stock_status\"] == \"low\"\n+            ]\n+\n             return {\n                 \"product_performance\": product_analytics,\n                 \"category_analysis\": categories,\n                 \"inventory_alerts\": {\n                     \"low_stock_items\": low_stock_items,\n-                    \"out_of_stock_count\": len([p for p in product_analytics if p[\"stock_level\"] == 0])\n+                    \"out_of_stock_count\": len(\n+                        [p for p in product_analytics if p[\"stock_level\"] == 0]\n+                    ),\n                 },\n                 \"top_products\": product_analytics[:10],\n                 \"period\": {\n                     \"start_date\": start_date.isoformat(),\n                     \"end_date\": end_date.isoformat(),\n-                    \"timeframe\": timeframe.value\n-                }\n+                    \"timeframe\": timeframe.value,\n+                },\n             }\n-            \n+\n         except Exception as e:\n             raise FynloException(\n                 message=f\"Failed to get inventory analytics: {str(e)}\",\n                 error_code=ErrorCodes.INTERNAL_ERROR,\n-                status_code=500\n-            )\n-    \n+                status_code=500,\n+            )\n+\n     def get_real_time_metrics(self, restaurant_id: str) -> Dict[str, Any]:\n         \"\"\"\n         Get real-time metrics for live dashboard\n         \"\"\"\n         try:\n             now = datetime.now()\n             today_start = now.replace(hour=0, minute=0, second=0, microsecond=0)\n-            \n+\n             # Today's metrics\n-            today_orders = self.db.query(Order).filter(\n-                and_(\n-                    Order.restaurant_id == restaurant_id,\n-                    Order.created_at >= today_start\n-                )\n-            ).all()\n-            \n+            today_orders = (\n+                self.db.query(Order)\n+                .filter(\n+                    and_(\n+                        Order.restaurant_id == restaurant_id,\n+                        Order.created_at >= today_start,\n+                    )\n+                )\n+                .all()\n+            )\n+\n             completed_orders = [o for o in today_orders if o.status == \"completed\"]\n-            pending_orders = [o for o in today_orders if o.status in [\"pending\", \"preparing\"]]\n-            \n+            pending_orders = [\n+                o for o in today_orders if o.status in [\"pending\", \"preparing\"]\n+            ]\n+\n             # Real-time calculations\n             total_revenue_today = sum(o.total_amount for o in completed_orders)\n-            avg_order_value = total_revenue_today / len(completed_orders) if completed_orders else 0\n-            \n+            avg_order_value = (\n+                total_revenue_today / len(completed_orders) if completed_orders else 0\n+            )\n+\n             # Current hour metrics\n             current_hour_start = now.replace(minute=0, second=0, microsecond=0)\n             current_hour_orders = [\n-                o for o in today_orders \n-                if o.created_at >= current_hour_start\n+                o for o in today_orders if o.created_at >= current_hour_start\n             ]\n-            \n+\n             # Performance indicators\n             orders_per_hour = len(current_hour_orders)\n-            revenue_per_hour = sum(o.total_amount for o in current_hour_orders if o.status == \"completed\")\n-            \n+            revenue_per_hour = sum(\n+                o.total_amount for o in current_hour_orders if o.status == \"completed\"\n+            )\n+\n             return {\n                 \"current_time\": now.isoformat(),\n                 \"today_metrics\": {\n                     \"total_orders\": len(today_orders),\n                     \"completed_orders\": len(completed_orders),\n                     \"pending_orders\": len(pending_orders),\n                     \"total_revenue\": float(total_revenue_today),\n-                    \"avg_order_value\": float(avg_order_value)\n+                    \"avg_order_value\": float(avg_order_value),\n                 },\n                 \"current_hour\": {\n                     \"orders_count\": len(current_hour_orders),\n                     \"revenue\": float(revenue_per_hour),\n-                    \"orders_per_hour_rate\": orders_per_hour\n+                    \"orders_per_hour_rate\": orders_per_hour,\n                 },\n                 \"operational_status\": {\n                     \"active_orders\": len(pending_orders),\n-                    \"completion_rate\": len(completed_orders) / len(today_orders) * 100 if today_orders else 0,\n-                    \"avg_order_time\": \"15 minutes\"  # Would calculate from actual data\n-                }\n+                    \"completion_rate\": (\n+                        len(completed_orders) / len(today_orders) * 100\n+                        if today_orders\n+                        else 0\n+                    ),\n+                    \"avg_order_time\": \"15 minutes\",  # Would calculate from actual data\n+                },\n             }\n-            \n+\n         except Exception as e:\n             raise FynloException(\n                 message=f\"Failed to get real-time metrics: {str(e)}\",\n                 error_code=ErrorCodes.INTERNAL_ERROR,\n-                status_code=500\n-            )\n-    \n-    def _get_timeframe_start(self, end_date: datetime, timeframe: AnalyticsTimeframe) -> datetime:\n+                status_code=500,\n+            )\n+\n+    def _get_timeframe_start(\n+        self, end_date: datetime, timeframe: AnalyticsTimeframe\n+    ) -> datetime:\n         \"\"\"Calculate start date based on timeframe\"\"\"\n         if timeframe == AnalyticsTimeframe.HOUR:\n             return end_date - timedelta(hours=1)\n         elif timeframe == AnalyticsTimeframe.DAY:\n             return end_date - timedelta(days=1)\n@@ -509,259 +597,327 @@\n             return end_date - timedelta(days=90)\n         elif timeframe == AnalyticsTimeframe.YEAR:\n             return end_date - timedelta(days=365)\n         else:\n             return end_date - timedelta(days=1)\n-    \n+\n     def _get_revenue_metrics(self, filter_criteria: AnalyticsFilter) -> Dict[str, Any]:\n         \"\"\"Calculate revenue metrics\"\"\"\n         # Current period revenue\n-        current_orders = self.db.query(Order).filter(\n-            and_(\n-                Order.restaurant_id == filter_criteria.restaurant_id,\n-                Order.created_at >= filter_criteria.start_date,\n-                Order.created_at <= filter_criteria.end_date,\n-                Order.status == \"completed\"\n-            )\n-        ).all()\n-        \n+        current_orders = (\n+            self.db.query(Order)\n+            .filter(\n+                and_(\n+                    Order.restaurant_id == filter_criteria.restaurant_id,\n+                    Order.created_at >= filter_criteria.start_date,\n+                    Order.created_at <= filter_criteria.end_date,\n+                    Order.status == \"completed\",\n+                )\n+            )\n+            .all()\n+        )\n+\n         current_revenue = sum(o.total_amount for o in current_orders)\n-        \n+\n         # Previous period for comparison\n         period_length = filter_criteria.end_date - filter_criteria.start_date\n         prev_start = filter_criteria.start_date - period_length\n         prev_end = filter_criteria.start_date\n-        \n-        prev_orders = self.db.query(Order).filter(\n-            and_(\n-                Order.restaurant_id == filter_criteria.restaurant_id,\n-                Order.created_at >= prev_start,\n-                Order.created_at <= prev_end,\n-                Order.status == \"completed\"\n-            )\n-        ).all()\n-        \n+\n+        prev_orders = (\n+            self.db.query(Order)\n+            .filter(\n+                and_(\n+                    Order.restaurant_id == filter_criteria.restaurant_id,\n+                    Order.created_at >= prev_start,\n+                    Order.created_at <= prev_end,\n+                    Order.status == \"completed\",\n+                )\n+            )\n+            .all()\n+        )\n+\n         prev_revenue = sum(o.total_amount for o in prev_orders)\n-        \n+\n         # Calculate change\n         change_percent = 0\n         change_direction = \"neutral\"\n-        \n+\n         if prev_revenue > 0:\n             change_percent = ((current_revenue - prev_revenue) / prev_revenue) * 100\n-            change_direction = \"up\" if change_percent > 0 else \"down\" if change_percent < 0 else \"neutral\"\n-        \n+            change_direction = (\n+                \"up\"\n+                if change_percent > 0\n+                else \"down\" if change_percent < 0 else \"neutral\"\n+            )\n+\n         return {\n             \"total_revenue\": float(current_revenue),\n             \"previous_revenue\": float(prev_revenue),\n             \"change_percent\": round(change_percent, 2),\n             \"change_direction\": change_direction,\n-            \"formatted_value\": f\"${current_revenue:,.2f}\"\n+            \"formatted_value\": f\"${current_revenue:,.2f}\",\n         }\n-    \n+\n     def _get_order_metrics(self, filter_criteria: AnalyticsFilter) -> Dict[str, Any]:\n         \"\"\"Calculate order metrics\"\"\"\n-        current_orders = self.db.query(Order).filter(\n-            and_(\n-                Order.restaurant_id == filter_criteria.restaurant_id,\n-                Order.created_at >= filter_criteria.start_date,\n-                Order.created_at <= filter_criteria.end_date\n-            )\n-        ).count()\n-        \n+        current_orders = (\n+            self.db.query(Order)\n+            .filter(\n+                and_(\n+                    Order.restaurant_id == filter_criteria.restaurant_id,\n+                    Order.created_at >= filter_criteria.start_date,\n+                    Order.created_at <= filter_criteria.end_date,\n+                )\n+            )\n+            .count()\n+        )\n+\n         return {\n             \"total_orders\": current_orders,\n-            \"formatted_value\": f\"{current_orders:,}\"\n+            \"formatted_value\": f\"{current_orders:,}\",\n         }\n-    \n+\n     def _get_customer_metrics(self, filter_criteria: AnalyticsFilter) -> Dict[str, Any]:\n         \"\"\"Calculate customer metrics\"\"\"\n-        unique_customers = self.db.query(Order.customer_id).filter(\n-            and_(\n-                Order.restaurant_id == filter_criteria.restaurant_id,\n-                Order.created_at >= filter_criteria.start_date,\n-                Order.created_at <= filter_criteria.end_date,\n-                Order.customer_id.isnot(None)\n-            )\n-        ).distinct().count()\n-        \n+        unique_customers = (\n+            self.db.query(Order.customer_id)\n+            .filter(\n+                and_(\n+                    Order.restaurant_id == filter_criteria.restaurant_id,\n+                    Order.created_at >= filter_criteria.start_date,\n+                    Order.created_at <= filter_criteria.end_date,\n+                    Order.customer_id.isnot(None),\n+                )\n+            )\n+            .distinct()\n+            .count()\n+        )\n+\n         return {\n             \"unique_customers\": unique_customers,\n-            \"formatted_value\": f\"{unique_customers:,}\"\n+            \"formatted_value\": f\"{unique_customers:,}\",\n         }\n-    \n-    def _get_performance_metrics(self, filter_criteria: AnalyticsFilter) -> Dict[str, Any]:\n+\n+    def _get_performance_metrics(\n+        self, filter_criteria: AnalyticsFilter\n+    ) -> Dict[str, Any]:\n         \"\"\"Calculate performance metrics\"\"\"\n-        orders = self.db.query(Order).filter(\n-            and_(\n-                Order.restaurant_id == filter_criteria.restaurant_id,\n-                Order.created_at >= filter_criteria.start_date,\n-                Order.created_at <= filter_criteria.end_date\n-            )\n-        ).all()\n-        \n+        orders = (\n+            self.db.query(Order)\n+            .filter(\n+                and_(\n+                    Order.restaurant_id == filter_criteria.restaurant_id,\n+                    Order.created_at >= filter_criteria.start_date,\n+                    Order.created_at <= filter_criteria.end_date,\n+                )\n+            )\n+            .all()\n+        )\n+\n         completed_orders = [o for o in orders if o.status == \"completed\"]\n         completion_rate = len(completed_orders) / len(orders) * 100 if orders else 0\n-        \n+\n         total_revenue = sum(o.total_amount for o in completed_orders)\n-        avg_order_value = total_revenue / len(completed_orders) if completed_orders else 0\n-        \n+        avg_order_value = (\n+            total_revenue / len(completed_orders) if completed_orders else 0\n+        )\n+\n         return {\n             \"completion_rate\": round(completion_rate, 2),\n             \"avg_order_value\": float(avg_order_value),\n-            \"formatted_aov\": f\"${avg_order_value:.2f}\"\n+            \"formatted_aov\": f\"${avg_order_value:.2f}\",\n         }\n-    \n-    def _get_revenue_trend(self, filter_criteria: AnalyticsFilter, timeframe: AnalyticsTimeframe) -> List[Dict[str, Any]]:\n+\n+    def _get_revenue_trend(\n+        self, filter_criteria: AnalyticsFilter, timeframe: AnalyticsTimeframe\n+    ) -> List[Dict[str, Any]]:\n         \"\"\"Get revenue trend data\"\"\"\n         # This would generate time series data based on timeframe\n         # For now, returning sample data\n         return [\n             {\"timestamp\": filter_criteria.start_date.isoformat(), \"value\": 1000.0},\n-            {\"timestamp\": filter_criteria.end_date.isoformat(), \"value\": 1200.0}\n+            {\"timestamp\": filter_criteria.end_date.isoformat(), \"value\": 1200.0},\n         ]\n-    \n-    def _get_order_trend(self, filter_criteria: AnalyticsFilter, timeframe: AnalyticsTimeframe) -> List[Dict[str, Any]]:\n+\n+    def _get_order_trend(\n+        self, filter_criteria: AnalyticsFilter, timeframe: AnalyticsTimeframe\n+    ) -> List[Dict[str, Any]]:\n         \"\"\"Get order trend data\"\"\"\n         return [\n             {\"timestamp\": filter_criteria.start_date.isoformat(), \"value\": 25},\n-            {\"timestamp\": filter_criteria.end_date.isoformat(), \"value\": 30}\n+            {\"timestamp\": filter_criteria.end_date.isoformat(), \"value\": 30},\n         ]\n-    \n-    def _get_top_products(self, filter_criteria: AnalyticsFilter, limit: int = 5) -> List[Dict[str, Any]]:\n+\n+    def _get_top_products(\n+        self, filter_criteria: AnalyticsFilter, limit: int = 5\n+    ) -> List[Dict[str, Any]]:\n         \"\"\"Get top performing products\"\"\"\n-        products = self.db.query(Product).filter(\n-            Product.restaurant_id == filter_criteria.restaurant_id\n-        ).limit(limit).all()\n-        \n+        products = (\n+            self.db.query(Product)\n+            .filter(Product.restaurant_id == filter_criteria.restaurant_id)\n+            .limit(limit)\n+            .all()\n+        )\n+\n         return [\n             {\n                 \"product_id\": str(product.id),\n                 \"product_name\": product.name,\n                 \"price\": float(product.price),\n                 \"units_sold\": 10,  # Would calculate from order items\n-                \"revenue\": float(product.price) * 10\n+                \"revenue\": float(product.price) * 10,\n             }\n             for product in products\n         ]\n-    \n-    def _get_recent_orders(self, filter_criteria: AnalyticsFilter, limit: int = 10) -> List[Dict[str, Any]]:\n+\n+    def _get_recent_orders(\n+        self, filter_criteria: AnalyticsFilter, limit: int = 10\n+    ) -> List[Dict[str, Any]]:\n         \"\"\"Get recent orders\"\"\"\n-        orders = self.db.query(Order).filter(\n-            and_(\n-                Order.restaurant_id == filter_criteria.restaurant_id,\n-                Order.created_at >= filter_criteria.start_date,\n-                Order.created_at <= filter_criteria.end_date\n-            )\n-        ).order_by(desc(Order.created_at)).limit(limit).all()\n-        \n+        orders = (\n+            self.db.query(Order)\n+            .filter(\n+                and_(\n+                    Order.restaurant_id == filter_criteria.restaurant_id,\n+                    Order.created_at >= filter_criteria.start_date,\n+                    Order.created_at <= filter_criteria.end_date,\n+                )\n+            )\n+            .order_by(desc(Order.created_at))\n+            .limit(limit)\n+            .all()\n+        )\n+\n         return [\n             {\n                 \"order_id\": str(order.id),\n                 \"order_number\": order.order_number,\n                 \"total_amount\": float(order.total_amount),\n                 \"status\": order.status,\n-                \"created_at\": order.created_at.isoformat()\n+                \"created_at\": order.created_at.isoformat(),\n             }\n             for order in orders\n         ]\n-    \n+\n     def _get_sales_overview(self, filter_criteria: AnalyticsFilter) -> Dict[str, Any]:\n         \"\"\"Get sales overview data\"\"\"\n-        orders = self.db.query(Order).filter(\n-            and_(\n-                Order.restaurant_id == filter_criteria.restaurant_id,\n-                Order.created_at >= filter_criteria.start_date,\n-                Order.created_at <= filter_criteria.end_date,\n-                Order.status == \"completed\"\n-            )\n-        ).all()\n-        \n+        orders = (\n+            self.db.query(Order)\n+            .filter(\n+                and_(\n+                    Order.restaurant_id == filter_criteria.restaurant_id,\n+                    Order.created_at >= filter_criteria.start_date,\n+                    Order.created_at <= filter_criteria.end_date,\n+                    Order.status == \"completed\",\n+                )\n+            )\n+            .all()\n+        )\n+\n         total_revenue = sum(o.total_amount for o in orders)\n         total_orders = len(orders)\n         avg_order_value = total_revenue / total_orders if total_orders else 0\n-        \n+\n         return {\n             \"total_revenue\": float(total_revenue),\n             \"total_orders\": total_orders,\n             \"avg_order_value\": float(avg_order_value),\n-            \"revenue_per_day\": float(total_revenue / 1)  # Would calculate based on actual days\n+            \"revenue_per_day\": float(\n+                total_revenue / 1\n+            ),  # Would calculate based on actual days\n         }\n-    \n-    def _get_sales_by_category(self, filter_criteria: AnalyticsFilter) -> Dict[str, Any]:\n+\n+    def _get_sales_by_category(\n+        self, filter_criteria: AnalyticsFilter\n+    ) -> Dict[str, Any]:\n         \"\"\"Get sales breakdown by category\"\"\"\n         # Would join with order_items and products to get category data\n         return {\n             \"Food\": {\"revenue\": 5000.0, \"orders\": 100},\n             \"Beverages\": {\"revenue\": 2000.0, \"orders\": 80},\n-            \"Desserts\": {\"revenue\": 800.0, \"orders\": 40}\n+            \"Desserts\": {\"revenue\": 800.0, \"orders\": 40},\n         }\n-    \n-    def _get_sales_pattern(self, filter_criteria: AnalyticsFilter, timeframe: AnalyticsTimeframe) -> List[Dict[str, Any]]:\n+\n+    def _get_sales_pattern(\n+        self, filter_criteria: AnalyticsFilter, timeframe: AnalyticsTimeframe\n+    ) -> List[Dict[str, Any]]:\n         \"\"\"Get sales pattern by time\"\"\"\n         # Would analyze sales by hour/day/week patterns\n         return [\n             {\"period\": \"Morning\", \"revenue\": 2000.0, \"orders\": 50},\n             {\"period\": \"Afternoon\", \"revenue\": 3000.0, \"orders\": 75},\n-            {\"period\": \"Evening\", \"revenue\": 4000.0, \"orders\": 90}\n+            {\"period\": \"Evening\", \"revenue\": 4000.0, \"orders\": 90},\n         ]\n-    \n-    def _get_payment_method_breakdown(self, filter_criteria: AnalyticsFilter) -> Dict[str, Any]:\n+\n+    def _get_payment_method_breakdown(\n+        self, filter_criteria: AnalyticsFilter\n+    ) -> Dict[str, Any]:\n         \"\"\"Get payment method breakdown\"\"\"\n-        payments = self.db.query(Payment).filter(\n-            and_(\n-                Payment.restaurant_id == filter_criteria.restaurant_id,\n-                Payment.created_at >= filter_criteria.start_date,\n-                Payment.created_at <= filter_criteria.end_date,\n-                Payment.status == \"completed\"\n-            )\n-        ).all()\n-        \n+        payments = (\n+            self.db.query(Payment)\n+            .filter(\n+                and_(\n+                    Payment.restaurant_id == filter_criteria.restaurant_id,\n+                    Payment.created_at >= filter_criteria.start_date,\n+                    Payment.created_at <= filter_criteria.end_date,\n+                    Payment.status == \"completed\",\n+                )\n+            )\n+            .all()\n+        )\n+\n         method_breakdown = {}\n         for payment in payments:\n             method = payment.payment_method\n             if method not in method_breakdown:\n                 method_breakdown[method] = {\"count\": 0, \"amount\": 0.0}\n-            \n+\n             method_breakdown[method][\"count\"] += 1\n             method_breakdown[method][\"amount\"] += float(payment.amount)\n-        \n+\n         return method_breakdown\n-    \n+\n     def _get_order_analysis(self, filter_criteria: AnalyticsFilter) -> Dict[str, Any]:\n         \"\"\"Get detailed order analysis\"\"\"\n-        orders = self.db.query(Order).filter(\n-            and_(\n-                Order.restaurant_id == filter_criteria.restaurant_id,\n-                Order.created_at >= filter_criteria.start_date,\n-                Order.created_at <= filter_criteria.end_date\n-            )\n-        ).all()\n-        \n+        orders = (\n+            self.db.query(Order)\n+            .filter(\n+                and_(\n+                    Order.restaurant_id == filter_criteria.restaurant_id,\n+                    Order.created_at >= filter_criteria.start_date,\n+                    Order.created_at <= filter_criteria.end_date,\n+                )\n+            )\n+            .all()\n+        )\n+\n         order_values = [float(o.total_amount) for o in orders]\n-        \n+\n         if order_values:\n             avg_value = sum(order_values) / len(order_values)\n             max_value = max(order_values)\n             min_value = min(order_values)\n         else:\n             avg_value = max_value = min_value = 0\n-        \n+\n         return {\n             \"avg_order_value\": avg_value,\n             \"max_order_value\": max_value,\n             \"min_order_value\": min_value,\n-            \"total_orders\": len(orders)\n+            \"total_orders\": len(orders),\n         }\n \n-    def get_financial_analytics(self, restaurant_id: str, timeframe: AnalyticsTimeframe, db: Session) -> Dict[str, Any]:\n+    def get_financial_analytics(\n+        self, restaurant_id: str, timeframe: AnalyticsTimeframe, db: Session\n+    ) -> Dict[str, Any]:\n         \"\"\"\n         Get comprehensive financial analytics using report aggregation service\n         \"\"\"\n         try:\n             from app.services.report_service import get_report_service\n-            \n+\n             # Get date range based on timeframe\n             end_date = date.today()\n             if timeframe == AnalyticsTimeframe.TODAY:\n                 start_date = end_date\n             elif timeframe == AnalyticsTimeframe.WEEK:\n@@ -772,40 +928,46 @@\n                 start_date = end_date - timedelta(days=90)\n             elif timeframe == AnalyticsTimeframe.YEAR:\n                 start_date = end_date - timedelta(days=365)\n             else:\n                 start_date = end_date - timedelta(days=7)  # Default to week\n-            \n+\n             # Get report service and generate any missing reports\n             report_service = get_report_service(db)\n-            \n+\n             # Generate reports for the range if they don't exist\n             current_date = start_date\n             while current_date <= end_date:\n                 report_service.generate_daily_report(restaurant_id, current_date)\n                 current_date += timedelta(days=1)\n-            \n+\n             # Get financial summary\n-            financial_summary = report_service.get_financial_summary(restaurant_id, start_date, end_date)\n-            \n+            financial_summary = report_service.get_financial_summary(\n+                restaurant_id, start_date, end_date\n+            )\n+\n             # Add trend data\n             trends = []\n             trend_date = start_date\n             while trend_date <= end_date:\n-                daily_summary = report_service.get_financial_summary(restaurant_id, trend_date, trend_date)\n+                daily_summary = report_service.get_financial_summary(\n+                    restaurant_id, trend_date, trend_date\n+                )\n                 if daily_summary:\n-                    trends.append({\n-                        \"date\": trend_date.isoformat(),\n-                        \"revenue\": daily_summary.get(\"total_revenue\", 0),\n-                        \"costs\": daily_summary.get(\"total_costs\", 0),\n-                        \"profit\": daily_summary.get(\"gross_profit\", 0)\n-                    })\n+                    trends.append(\n+                        {\n+                            \"date\": trend_date.isoformat(),\n+                            \"revenue\": daily_summary.get(\"total_revenue\", 0),\n+                            \"costs\": daily_summary.get(\"total_costs\", 0),\n+                            \"profit\": daily_summary.get(\"gross_profit\", 0),\n+                        }\n+                    )\n                 trend_date += timedelta(days=1)\n-            \n+\n             financial_summary[\"trends\"] = trends\n             return financial_summary\n-            \n+\n         except Exception as e:\n             # Return fallback financial data\n             return {\n                 \"total_revenue\": 15847.50,\n                 \"total_costs\": 8956.25,\n@@ -817,11 +979,12 @@\n                 \"cash_payments\": 2377.13,\n                 \"card_payments\": 10577.88,\n                 \"qr_payments\": 2892.49,\n                 \"vat_collected\": 2641.25,\n                 \"service_charge_collected\": 1979.44,\n-                \"trends\": []\n+                \"trends\": [],\n             }\n+\n \n def get_analytics_engine(db: Session) -> AnalyticsEngine:\n     \"\"\"Get analytics engine instance\"\"\"\n-    return AnalyticsEngine(db)\n\\ No newline at end of file\n+    return AnalyticsEngine(db)\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/response_helper.py\t2025-08-02 22:32:12.160505+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/response_helper.py\t2025-08-02 22:36:03.316925+00:00\n@@ -11,117 +11,123 @@\n \n class APIResponseHelper:\n     \"\"\"Helper class for creating standardized API responses\"\"\"\n \n     @staticmethod\n-    def success(data: Any = None, message: str = \"Success\", status_code: int = 200) -> JSONResponse:\n+    def success(\n+        data: Any = None, message: str = \"Success\", status_code: int = 200\n+    ) -> JSONResponse:\n         \"\"\"\n         Create a successful API response\n-        \n+\n         Args:\n             data: The response data\n             message: Success message\n             status_code: HTTP status code\n             meta: Additional metadata\n-            \n+\n         Returns:\n             JSONResponse with standardized format\n         \"\"\"\n         response = {\n             \"success\": True,\n             \"message\": message,\n             \"timestamp\": datetime.utcnow().isoformat(),\n         }\n-        \n+\n         if data is not None:\n             response[\"data\"] = data\n-            \n+\n         if meta:\n             response[\"meta\"] = meta\n-            \n-        return JSONResponse(\n-            content=response,\n-            status_code=status_code\n-        )\n+\n+        return JSONResponse(content=response, status_code=status_code)\n \n     @staticmethod\n     def error(\n         message: str = \"An error occurred\",\n         status_code: int = 400,\n         error_code: Optional[str] = None,\n-        details: Optional[Dict[str, Any]] = None\n+        details: Optional[Dict[str, Any]] = None,\n     ) -> JSONResponse:\n         \"\"\"\n         Create an error API response\n-        \n+\n         Args:\n             message: Error message\n             status_code: HTTP status code\n             error_code: Application-specific error code\n             details: Additional error details\n-            \n+\n         Returns:\n             JSONResponse with standardized error format\n         \"\"\"\n         response = {\n             \"success\": False,\n             \"message\": message,\n             \"timestamp\": datetime.utcnow().isoformat(),\n         }\n-        \n+\n         if error_code:\n             response[\"error_code\"] = error_code\n-            \n+\n         if details:\n             response[\"details\"] = details\n-            \n-        return JSONResponse(\n-            content=response,\n-            status_code=status_code\n-        )\n+\n+        return JSONResponse(content=response, status_code=status_code)\n \n     @staticmethod\n-    def paginated(data: List[Any], page: int = 1, page_size: int = 20, total: Optional[int] = None, message: str = \"Success\", meta: Optional[Dict[str, Any]] = None) -> JSONResponse:\n+    def paginated(\n+        data: List[Any],\n+        page: int = 1,\n+        page_size: int = 20,\n+        total: Optional[int] = None,\n+        message: str = \"Success\",\n+        meta: Optional[Dict[str, Any]] = None,\n+    ) -> JSONResponse:\n         \"\"\"\n         Create a paginated API response\n-        \n+\n         Args:\n             data: List of items for current page\n             page: Current page number\n             page_size: Items per page\n             total: Total number of items\n             message: Success message\n-            \n+\n         Returns:\n             JSONResponse with pagination metadata\n         \"\"\"\n         total_pages = (total + page_size - 1) // page_size\n-        \n+\n         return APIResponseHelper.success(\n             data=data,\n             message=message,\n             meta={\n                 \"pagination\": {\n                     \"page\": page,\n                     \"page_size\": page_size,\n                     \"total\": total,\n                     \"total_pages\": total_pages,\n                     \"has_next\": page < total_pages,\n-                    \"has_prev\": page > 1\n+                    \"has_prev\": page > 1,\n                 }\n-            }\n+            },\n         )\n \n     @staticmethod\n-    def needs_onboarding(user_data: Dict[str, Any], message: str = \"Please complete onboarding to continue\") -> JSONResponse:\n+    def needs_onboarding(\n+        user_data: Dict[str, Any],\n+        message: str = \"Please complete onboarding to continue\",\n+    ) -> JSONResponse:\n         \"\"\"\n         Create response for users who need to complete onboarding\n-        \n+\n         Args:\n             user_data: Basic user information\n             message: Onboarding message\n-            \n+\n         Returns:\n             JSONResponse indicating onboarding is required\n         \"\"\"\n         return JSONResponse(\n             content={\n@@ -129,7 +135,7 @@\n                 \"requires_onboarding\": True,\n                 \"message\": message,\n                 \"user\": user_data,\n                 \"timestamp\": datetime.utcnow().isoformat(),\n             },\n-            status_code=status.HTTP_403_FORBIDDEN\n-        )\n\\ No newline at end of file\n+            status_code=status.HTTP_403_FORBIDDEN,\n+        )\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/file_upload.py\t2025-08-02 21:56:58.995028+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/file_upload.py\t2025-08-02 22:36:03.319068+00:00\n@@ -5,13 +5,15 @@\n \n import base64\n import os\n import uuid\n import logging\n+\n # Import python-magic with proper error handling\n try:\n     import magic\n+\n     MAGIC_AVAILABLE = True\n except (ImportError, OSError):\n     # This should not happen with python-magic-bin, but keep fallback for safety\n     MAGIC_AVAILABLE = False\n from typing import Optional, Tuple\n@@ -24,342 +26,362 @@\n from app.core.responses import APIResponseHelper\n from app.core.config import settings\n \n logger = logging.getLogger(__name__)\n \n+\n class FileUploadConfig:\n     \"\"\"Configuration for file uploads\"\"\"\n-    \n+\n     # Storage paths\n     UPLOAD_DIR = \"uploads\"\n     PRODUCT_IMAGES_DIR = \"products\"\n     RESTAURANT_LOGOS_DIR = \"restaurants\"\n     RECEIPT_IMAGES_DIR = \"receipts\"\n     PROFILE_PHOTOS_DIR = \"profiles\"\n-    \n+\n     # File constraints\n     MAX_FILE_SIZE = 10 * 1024 * 1024  # 10MB\n-    ALLOWED_MIME_TYPES = [\n-        'image/jpeg',\n-        'image/png', \n-        'image/webp',\n-        'image/gif'\n-    ]\n-    ALLOWED_EXTENSIONS = ['.jpg', '.jpeg', '.png', '.webp', '.gif']\n-    \n+    ALLOWED_MIME_TYPES = [\"image/jpeg\", \"image/png\", \"image/webp\", \"image/gif\"]\n+    ALLOWED_EXTENSIONS = [\".jpg\", \".jpeg\", \".png\", \".webp\", \".gif\"]\n+\n     # Image processing\n     IMAGE_QUALITY = 85\n     MAX_DIMENSION = 2048\n     THUMBNAIL_SIZE = (300, 300)\n-    \n+\n     # Mobile optimized sizes\n     MOBILE_SIZES = {\n-        'thumbnail': (150, 150),\n-        'small': (300, 300),\n-        'medium': (600, 600),\n-        'large': (1200, 1200)\n+        \"thumbnail\": (150, 150),\n+        \"small\": (300, 300),\n+        \"medium\": (600, 600),\n+        \"large\": (1200, 1200),\n     }\n+\n \n class ImageUploadRequest(BaseModel):\n     \"\"\"Request model for base64 image uploads\"\"\"\n+\n     image_data: str  # Base64 encoded image\n     filename: Optional[str] = None\n     alt_text: Optional[str] = None\n     generate_thumbnails: bool = True\n \n+\n class ImageUploadResponse(BaseModel):\n     \"\"\"Response model for image uploads\"\"\"\n+\n     success: bool\n     file_id: str\n     original_url: str\n     thumbnail_url: Optional[str] = None\n     variants: dict = {}\n     metadata: dict\n \n+\n class FileUploadService:\n     \"\"\"Service for handling file uploads with iOS optimization\"\"\"\n-    \n+\n     def __init__(self):\n         self.config = FileUploadConfig()\n         self._ensure_directories()\n-        \n+\n         # Initialize Spaces storage if enabled\n         self.spaces_service = None\n         if settings.ENABLE_SPACES_STORAGE:\n             try:\n                 from app.services.storage_service import storage_service\n+\n                 self.spaces_service = storage_service\n                 if self.spaces_service.enabled:\n                     logger.info(\"Spaces storage integration enabled\")\n                 else:\n                     logger.warning(\"Spaces storage configured but not available\")\n             except ImportError:\n                 logger.warning(\"Spaces storage service not available\")\n-    \n+\n     def _ensure_directories(self):\n         \"\"\"Create upload directories if they don't exist\"\"\"\n         base_dir = self.config.UPLOAD_DIR\n         subdirs = [\n             self.config.PRODUCT_IMAGES_DIR,\n             self.config.RESTAURANT_LOGOS_DIR,\n             self.config.RECEIPT_IMAGES_DIR,\n-            self.config.PROFILE_PHOTOS_DIR\n+            self.config.PROFILE_PHOTOS_DIR,\n         ]\n-        \n+\n         os.makedirs(base_dir, exist_ok=True)\n         for subdir in subdirs:\n             os.makedirs(os.path.join(base_dir, subdir), exist_ok=True)\n-    \n+\n     def validate_base64_image(self, base64_data: str) -> Tuple[bytes, str]:\n         \"\"\"\n         Validate base64 image data and return decoded bytes and MIME type\n         \"\"\"\n         try:\n             # Handle data URL format (data:image/jpeg;base64,...)\n-            if base64_data.startswith('data:'):\n-                header, data = base64_data.split(',', 1)\n-                mime_type = header.split(':')[1].split(';')[0]\n+            if base64_data.startswith(\"data:\"):\n+                header, data = base64_data.split(\",\", 1)\n+                mime_type = header.split(\":\")[1].split(\";\")[0]\n             else:\n                 data = base64_data\n                 mime_type = None\n-            \n+\n             # Decode base64\n             image_bytes = base64.b64decode(data)\n-            \n+\n             # Check file size\n             if len(image_bytes) > self.config.MAX_FILE_SIZE:\n                 raise FynloException(\n                     message=f\"Image too large. Maximum size is {self.config.MAX_FILE_SIZE / (1024*1024):.1f}MB\",\n                     error_code=ErrorCodes.VALIDATION_ERROR,\n-                    status_code=413\n-                )\n-            \n+                    status_code=413,\n+                )\n+\n             # Validate MIME type using python-magic\n             if MAGIC_AVAILABLE:\n                 detected_mime = magic.from_buffer(image_bytes, mime=True)\n-                \n+\n                 if detected_mime not in self.config.ALLOWED_MIME_TYPES:\n                     raise FynloException(\n                         message=f\"Unsupported image format. Allowed types: {', '.join(self.config.ALLOWED_MIME_TYPES)}\",\n                         error_code=ErrorCodes.VALIDATION_ERROR,\n-                        status_code=400\n+                        status_code=400,\n                     )\n-                \n+\n                 # Use detected MIME type if not provided\n-                final_mime_type = mime_type if mime_type in self.config.ALLOWED_MIME_TYPES else detected_mime\n+                final_mime_type = (\n+                    mime_type\n+                    if mime_type in self.config.ALLOWED_MIME_TYPES\n+                    else detected_mime\n+                )\n             else:\n                 # Temporary fallback without magic\n                 final_mime_type = mime_type if mime_type else \"image/jpeg\"\n-            \n+\n             return image_bytes, final_mime_type\n-            \n+\n         except base64.binascii.Error:\n             raise FynloException(\n                 message=\"Invalid base64 image data\",\n                 error_code=ErrorCodes.VALIDATION_ERROR,\n-                status_code=400\n+                status_code=400,\n             )\n         except Exception as e:\n             raise FynloException(\n                 message=f\"Image validation failed: {str(e)}\",\n                 error_code=ErrorCodes.VALIDATION_ERROR,\n-                status_code=400\n-            )\n-    \n-    def process_image(self, image_bytes: bytes, mime_type: str) -> Tuple[Image.Image, dict]:\n+                status_code=400,\n+            )\n+\n+    def process_image(\n+        self, image_bytes: bytes, mime_type: str\n+    ) -> Tuple[Image.Image, dict]:\n         \"\"\"\n         Process image for mobile optimization\n         \"\"\"\n         try:\n             # Open image with PIL\n             image = Image.open(BytesIO(image_bytes))\n-            \n+\n             # Get original metadata\n             metadata = {\n-                'format': image.format,\n-                'mode': image.mode,\n-                'size': image.size,\n-                'mime_type': mime_type\n+                \"format\": image.format,\n+                \"mode\": image.mode,\n+                \"size\": image.size,\n+                \"mime_type\": mime_type,\n             }\n-            \n+\n             # Handle EXIF orientation\n             image = ImageOps.exif_transpose(image)\n-            \n+\n             # Convert to RGB if necessary (for JPEG output)\n-            if image.mode in ('RGBA', 'LA', 'P'):\n+            if image.mode in (\"RGBA\", \"LA\", \"P\"):\n                 # Create white background for transparent images\n-                background = Image.new('RGB', image.size, (255, 255, 255))\n-                if image.mode == 'P':\n-                    image = image.convert('RGBA')\n-                background.paste(image, mask=image.split()[-1] if image.mode == 'RGBA' else None)\n+                background = Image.new(\"RGB\", image.size, (255, 255, 255))\n+                if image.mode == \"P\":\n+                    image = image.convert(\"RGBA\")\n+                background.paste(\n+                    image, mask=image.split()[-1] if image.mode == \"RGBA\" else None\n+                )\n                 image = background\n-            \n+\n             # Resize if too large\n             if max(image.size) > self.config.MAX_DIMENSION:\n-                image.thumbnail((self.config.MAX_DIMENSION, self.config.MAX_DIMENSION), Image.Resampling.LANCZOS)\n-                metadata['resized'] = True\n-            \n+                image.thumbnail(\n+                    (self.config.MAX_DIMENSION, self.config.MAX_DIMENSION),\n+                    Image.Resampling.LANCZOS,\n+                )\n+                metadata[\"resized\"] = True\n+\n             return image, metadata\n-            \n+\n         except Exception as e:\n             raise FynloException(\n                 message=f\"Image processing failed: {str(e)}\",\n                 error_code=ErrorCodes.INTERNAL_ERROR,\n-                status_code=500\n-            )\n-    \n-    def generate_variants(self, image: Image.Image, base_filename: str, upload_path: str) -> dict:\n+                status_code=500,\n+            )\n+\n+    def generate_variants(\n+        self, image: Image.Image, base_filename: str, upload_path: str\n+    ) -> dict:\n         \"\"\"\n         Generate multiple size variants for mobile optimization\n         \"\"\"\n         variants = {}\n-        \n+\n         try:\n             for size_name, dimensions in self.config.MOBILE_SIZES.items():\n                 # Create variant\n                 variant = image.copy()\n                 variant.thumbnail(dimensions, Image.Resampling.LANCZOS)\n-                \n+\n                 # Save variant\n                 variant_filename = f\"{base_filename}_{size_name}.jpg\"\n                 variant_path = os.path.join(upload_path, variant_filename)\n-                \n+\n                 variant.save(\n-                    variant_path, \n-                    'JPEG', \n+                    variant_path,\n+                    \"JPEG\",\n                     quality=self.config.IMAGE_QUALITY,\n-                    optimize=True\n-                )\n-                \n+                    optimize=True,\n+                )\n+\n                 variants[size_name] = {\n-                    'filename': variant_filename,\n-                    'size': variant.size,\n-                    'url': f\"/files/{upload_path.split('/', 1)[1]}/{variant_filename}\"\n+                    \"filename\": variant_filename,\n+                    \"size\": variant.size,\n+                    \"url\": f\"/files/{upload_path.split('/', 1)[1]}/{variant_filename}\",\n                 }\n-            \n+\n             return variants\n-            \n+\n         except Exception as e:\n             raise FynloException(\n                 message=f\"Variant generation failed: {str(e)}\",\n                 error_code=ErrorCodes.INTERNAL_ERROR,\n-                status_code=500\n-            )\n-    \n-    def save_image(self, image: Image.Image, upload_type: str, filename: str = None) -> Tuple[str, str]:\n+                status_code=500,\n+            )\n+\n+    def save_image(\n+        self, image: Image.Image, upload_type: str, filename: str = None\n+    ) -> Tuple[str, str]:\n         \"\"\"\n         Save processed image to disk\n         \"\"\"\n         try:\n             # Generate unique filename\n             file_id = str(uuid.uuid4())\n             timestamp = datetime.now().strftime(\"%Y%m%d\")\n-            \n+\n             if filename:\n                 name, ext = os.path.splitext(filename)\n                 base_filename = f\"{timestamp}_{file_id}_{name}\"\n             else:\n                 base_filename = f\"{timestamp}_{file_id}\"\n-            \n+\n             filename = f\"{base_filename}.jpg\"\n-            \n+\n             # Determine upload path\n             type_dirs = {\n-                'product': self.config.PRODUCT_IMAGES_DIR,\n-                'restaurant': self.config.RESTAURANT_LOGOS_DIR,\n-                'receipt': self.config.RECEIPT_IMAGES_DIR,\n-                'profile': self.config.PROFILE_PHOTOS_DIR\n+                \"product\": self.config.PRODUCT_IMAGES_DIR,\n+                \"restaurant\": self.config.RESTAURANT_LOGOS_DIR,\n+                \"receipt\": self.config.RECEIPT_IMAGES_DIR,\n+                \"profile\": self.config.PROFILE_PHOTOS_DIR,\n             }\n-            \n+\n             upload_dir = type_dirs.get(upload_type, self.config.PRODUCT_IMAGES_DIR)\n             upload_path = os.path.join(self.config.UPLOAD_DIR, upload_dir)\n             file_path = os.path.join(upload_path, filename)\n-            \n+\n             # Save main image\n             image.save(\n-                file_path,\n-                'JPEG',\n-                quality=self.config.IMAGE_QUALITY,\n-                optimize=True\n-            )\n-            \n+                file_path, \"JPEG\", quality=self.config.IMAGE_QUALITY, optimize=True\n+            )\n+\n             return file_id, filename\n-            \n+\n         except Exception as e:\n             raise FynloException(\n                 message=f\"Image save failed: {str(e)}\",\n                 error_code=ErrorCodes.INTERNAL_ERROR,\n-                status_code=500\n-            )\n-    \n-    async def upload_base64_image_to_spaces(self, \n-                                       base64_data: str, \n-                                       upload_type: str,\n-                                       filename: str = None,\n-                                       user_id: int = None) -> ImageUploadResponse:\n+                status_code=500,\n+            )\n+\n+    async def upload_base64_image_to_spaces(\n+        self,\n+        base64_data: str,\n+        upload_type: str,\n+        filename: str = None,\n+        user_id: int = None,\n+    ) -> ImageUploadResponse:\n         \"\"\"\n         Upload base64 image to DigitalOcean Spaces\n         \"\"\"\n         try:\n             # Validate and decode\n             image_bytes, mime_type = self.validate_base64_image(base64_data)\n-            \n+\n             # Convert to file-like object for Spaces service\n             image_file = BytesIO(image_bytes)\n-            \n+\n             # Map upload types to folder names\n             folder_map = {\n-                'product': 'uploads/products',\n-                'restaurant': 'uploads/restaurants',\n-                'receipt': 'uploads/receipts',\n-                'profile': 'uploads/profiles'\n+                \"product\": \"uploads/products\",\n+                \"restaurant\": \"uploads/restaurants\",\n+                \"receipt\": \"uploads/receipts\",\n+                \"profile\": \"uploads/profiles\",\n             }\n-            \n-            folder = folder_map.get(upload_type, 'uploads')\n-            \n+\n+            folder = folder_map.get(upload_type, \"uploads\")\n+\n             # Upload to Spaces\n             upload_result = await self.spaces_service.upload_file(\n                 file=image_file,\n                 filename=filename or f\"{upload_type}_image.jpg\",\n                 folder=folder,\n                 user_id=user_id,\n-                optimize_image=True\n-            )\n-            \n+                optimize_image=True,\n+            )\n+\n             return ImageUploadResponse(\n                 success=True,\n-                file_id=upload_result['file_path'].split('/')[-1].split('.')[0],  # Extract ID from path\n-                original_url=upload_result['cdn_url'],\n-                thumbnail_url=upload_result['cdn_url'],  # CDN handles optimization\n+                file_id=upload_result[\"file_path\"]\n+                .split(\"/\")[-1]\n+                .split(\".\")[0],  # Extract ID from path\n+                original_url=upload_result[\"cdn_url\"],\n+                thumbnail_url=upload_result[\"cdn_url\"],  # CDN handles optimization\n                 variants={\n-                    'cdn': {'url': upload_result['cdn_url']},\n-                    'spaces': {'url': upload_result['spaces_url']}\n+                    \"cdn\": {\"url\": upload_result[\"cdn_url\"]},\n+                    \"spaces\": {\"url\": upload_result[\"spaces_url\"]},\n                 },\n                 metadata={\n-                    'file_size': upload_result['file_size'],\n-                    'content_type': upload_result['content_type'],\n-                    'upload_type': upload_type,\n-                    'storage_type': 'spaces',\n-                    'created_at': datetime.utcnow().isoformat(),\n-                    'file_path': upload_result['file_path']\n-                }\n-            )\n-            \n+                    \"file_size\": upload_result[\"file_size\"],\n+                    \"content_type\": upload_result[\"content_type\"],\n+                    \"upload_type\": upload_type,\n+                    \"storage_type\": \"spaces\",\n+                    \"created_at\": datetime.utcnow().isoformat(),\n+                    \"file_path\": upload_result[\"file_path\"],\n+                },\n+            )\n+\n         except Exception as e:\n             logger.error(f\"Spaces upload failed: {str(e)}\")\n             raise FynloException(\n                 message=f\"Spaces upload failed: {str(e)}\",\n                 error_code=ErrorCodes.INTERNAL_ERROR,\n-                status_code=500\n-            )\n-\n-    async def upload_base64_image(self, \n-                                 base64_data: str, \n-                                 upload_type: str,\n-                                 filename: str = None,\n-                                 generate_variants: bool = True,\n-                                 user_id: int = None) -> ImageUploadResponse:\n+                status_code=500,\n+            )\n+\n+    async def upload_base64_image(\n+        self,\n+        base64_data: str,\n+        upload_type: str,\n+        filename: str = None,\n+        generate_variants: bool = True,\n+        user_id: int = None,\n+    ) -> ImageUploadResponse:\n         \"\"\"\n         Complete base64 image upload workflow - uses Spaces if enabled, local storage as fallback\n         \"\"\"\n         # Try Spaces first if enabled\n         if self.spaces_service and self.spaces_service.enabled:\n@@ -369,97 +391,98 @@\n                     base64_data, upload_type, filename, user_id\n                 )\n             except Exception as e:\n                 logger.warning(f\"Spaces upload failed, falling back to local: {str(e)}\")\n                 # Continue to local storage fallback\n-        \n+\n         # Local storage implementation (existing code)\n         try:\n             # Validate and decode\n             image_bytes, mime_type = self.validate_base64_image(base64_data)\n-            \n+\n             # Process image\n             image, metadata = self.process_image(image_bytes, mime_type)\n-            \n+\n             # Save image\n             file_id, saved_filename = self.save_image(image, upload_type, filename)\n-            \n+\n             # Determine upload directory for URLs\n             type_dirs = {\n-                'product': self.config.PRODUCT_IMAGES_DIR,\n-                'restaurant': self.config.RESTAURANT_LOGOS_DIR,\n-                'receipt': self.config.RECEIPT_IMAGES_DIR,\n-                'profile': self.config.PROFILE_PHOTOS_DIR\n+                \"product\": self.config.PRODUCT_IMAGES_DIR,\n+                \"restaurant\": self.config.RESTAURANT_LOGOS_DIR,\n+                \"receipt\": self.config.RECEIPT_IMAGES_DIR,\n+                \"profile\": self.config.PROFILE_PHOTOS_DIR,\n             }\n-            \n+\n             upload_dir = type_dirs.get(upload_type, self.config.PRODUCT_IMAGES_DIR)\n             upload_path = os.path.join(self.config.UPLOAD_DIR, upload_dir)\n-            \n+\n             # Generate variants\n             variants = {}\n             if generate_variants:\n                 base_name = os.path.splitext(saved_filename)[0]\n                 variants = self.generate_variants(image, base_name, upload_path)\n-            \n+\n             # Create response\n             original_url = f\"/files/{upload_dir}/{saved_filename}\"\n-            thumbnail_url = variants.get('thumbnail', {}).get('url')\n-            \n+            thumbnail_url = variants.get(\"thumbnail\", {}).get(\"url\")\n+\n             return ImageUploadResponse(\n                 success=True,\n                 file_id=file_id,\n                 original_url=original_url,\n                 thumbnail_url=thumbnail_url,\n                 variants=variants,\n                 metadata={\n                     **metadata,\n-                    'file_size': len(image_bytes),\n-                    'upload_type': upload_type,\n-                    'storage_type': 'local',\n-                    'created_at': datetime.utcnow().isoformat(),\n-                    'processed_size': image.size\n-                }\n-            )\n-            \n+                    \"file_size\": len(image_bytes),\n+                    \"upload_type\": upload_type,\n+                    \"storage_type\": \"local\",\n+                    \"created_at\": datetime.utcnow().isoformat(),\n+                    \"processed_size\": image.size,\n+                },\n+            )\n+\n         except FynloException:\n             raise\n         except Exception as e:\n             raise FynloException(\n                 message=f\"Upload failed: {str(e)}\",\n                 error_code=ErrorCodes.INTERNAL_ERROR,\n-                status_code=500\n-            )\n-    \n+                status_code=500,\n+            )\n+\n     def delete_image(self, file_id: str, upload_type: str) -> bool:\n         \"\"\"\n         Delete image and all its variants\n         \"\"\"\n         try:\n             type_dirs = {\n-                'product': self.config.PRODUCT_IMAGES_DIR,\n-                'restaurant': self.config.RESTAURANT_LOGOS_DIR,\n-                'receipt': self.config.RECEIPT_IMAGES_DIR,\n-                'profile': self.config.PROFILE_PHOTOS_DIR\n+                \"product\": self.config.PRODUCT_IMAGES_DIR,\n+                \"restaurant\": self.config.RESTAURANT_LOGOS_DIR,\n+                \"receipt\": self.config.RECEIPT_IMAGES_DIR,\n+                \"profile\": self.config.PROFILE_PHOTOS_DIR,\n             }\n-            \n+\n             upload_dir = type_dirs.get(upload_type, self.config.PRODUCT_IMAGES_DIR)\n             upload_path = os.path.join(self.config.UPLOAD_DIR, upload_dir)\n-            \n+\n             # Find and delete all files with this file_id\n             deleted = False\n             for filename in os.listdir(upload_path):\n                 if file_id in filename:\n                     file_path = os.path.join(upload_path, filename)\n                     os.remove(file_path)\n                     deleted = True\n-            \n+\n             return deleted\n-            \n+\n         except Exception as e:\n             raise FynloException(\n                 message=f\"Delete failed: {str(e)}\",\n                 error_code=ErrorCodes.INTERNAL_ERROR,\n-                status_code=500\n-            )\n+                status_code=500,\n+            )\n+\n \n # Singleton instance\n-file_upload_service = FileUploadService()\n\\ No newline at end of file\n+file_upload_service = FileUploadService()\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/rate_limit_config.py\t2025-08-02 21:56:58.996149+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/rate_limit_config.py\t2025-08-02 22:36:03.322705+00:00\n@@ -16,36 +16,36 @@\n AUTH_RATES = {\n     \"login\": \"5/minute\",\n     \"register\": \"3/minute\",\n     \"password_reset\": \"3/minute\",\n     \"verify_email\": \"10/minute\",\n-    \"refresh_token\": \"10/minute\"\n+    \"refresh_token\": \"10/minute\",\n }\n \n # Payment endpoints - balanced for security and usability\n PAYMENT_RATES = {\n     \"create_payment\": \"15/minute\",\n     \"process_payment\": \"15/minute\",\n     \"payment_status\": \"30/minute\",\n     \"payment_history\": \"30/minute\",\n-    \"refund\": \"5/minute\"\n+    \"refund\": \"5/minute\",\n }\n \n # Platform-specific rates based on client type\n PLATFORM_RATES = {\n     \"mobile_app\": \"100/minute\",\n     \"portal_dashboard\": \"300/minute\",\n     \"portal_export\": \"10/minute\",\n-    \"portal_analytics\": \"200/minute\"\n+    \"portal_analytics\": \"200/minute\",\n }\n \n # API operation rates\n API_RATES = {\n     \"sync\": \"200/minute\",\n     \"websocket\": \"500/minute\",\n     \"file_upload\": \"10/minute\",\n-    \"bulk_operation\": \"5/minute\"\n+    \"bulk_operation\": \"5/minute\",\n }\n \n # Health and monitoring endpoints - high limits for infrastructure\n MONITORING_RATES = {\n     \"health_basic\": \"1000/minute\",\n@@ -55,44 +55,46 @@\n     \"health_live\": \"1000/minute\",\n     \"monitoring_replicas\": DEFAULT_RATE,\n     \"monitoring_metrics\": DEFAULT_RATE,\n     \"monitoring_refresh\": \"10/minute\",\n     \"monitoring_deployments\": DEFAULT_RATE,\n-    \"monitoring_trigger\": \"2/hour\"\n+    \"monitoring_trigger\": \"2/hour\",\n }\n \n # Critical operation rates - very restrictive\n CRITICAL_RATES = {\n     \"deployment_trigger\": \"2/hour\",\n     \"system_restart\": \"1/hour\",\n     \"config_update\": \"10/hour\",\n-    \"user_delete\": \"5/hour\"\n-}\n+    \"user_delete\": \"5/hour\",\n+}\n+\n \n # Get rate limit configuration\n def get_rate_limit(endpoint_type: str, operation: str) -> str:\n     \"\"\"\n     Get the appropriate rate limit for an endpoint.\n-    \n+\n     Args:\n         endpoint_type: Category of endpoint (auth, payment, monitoring, etc.)\n         operation: Specific operation within the category\n-        \n+\n     Returns:\n         Rate limit string (e.g., \"5/minute\")\n     \"\"\"\n     rate_configs = {\n         \"auth\": AUTH_RATES,\n         \"payment\": PAYMENT_RATES,\n         \"platform\": PLATFORM_RATES,\n         \"api\": API_RATES,\n         \"monitoring\": MONITORING_RATES,\n-        \"critical\": CRITICAL_RATES\n+        \"critical\": CRITICAL_RATES,\n     }\n-    \n+\n     category = rate_configs.get(endpoint_type, {})\n     return category.get(operation, DEFAULT_RATE)\n+\n \n # Environment-specific multipliers\n def get_environment_multiplier() -> float:\n     \"\"\"\n     Get rate limit multiplier based on environment.\n@@ -100,115 +102,104 @@\n     \"\"\"\n     multipliers = {\n         \"development\": 2.0,\n         \"staging\": 1.5,\n         \"production\": 1.0,\n-        \"test\": 10.0  # Very high for automated tests\n+        \"test\": 10.0,  # Very high for automated tests\n     }\n     return multipliers.get(settings.ENVIRONMENT, 1.0)\n \n+\n # Apply environment multiplier to rate\n def adjust_rate_for_environment(rate: str) -> str:\n     \"\"\"\n     Adjust rate limit based on environment.\n-    \n+\n     Args:\n         rate: Base rate limit (e.g., \"5/minute\")\n-        \n+\n     Returns:\n         Adjusted rate limit\n     \"\"\"\n     if settings.ENVIRONMENT == \"production\":\n         return rate\n-    \n+\n     # Parse rate\n     parts = rate.split(\"/\")\n     if len(parts) != 2:\n         return rate\n-    \n+\n     try:\n         limit = int(parts[0])\n         period = parts[1]\n-        \n+\n         # Apply multiplier\n         multiplier = get_environment_multiplier()\n         adjusted_limit = int(limit * multiplier)\n-        \n+\n         return f\"{adjusted_limit}/{period}\"\n     except ValueError:\n         return rate\n+\n \n # Rate limit groups for bulk configuration\n RATE_LIMIT_GROUPS = {\n     \"public\": {\n         \"rate\": \"100/minute\",\n-        \"endpoints\": [\n-            \"/api/v1/health\",\n-            \"/api/v1/health/basic\",\n-            \"/api/v1/public/*\"\n-        ]\n+        \"endpoints\": [\"/api/v1/health\", \"/api/v1/health/basic\", \"/api/v1/public/*\"],\n     },\n     \"authenticated\": {\n         \"rate\": DEFAULT_RATE,\n-        \"endpoints\": [\n-            \"/api/v1/users/*\",\n-            \"/api/v1/restaurants/*\",\n-            \"/api/v1/menu/*\"\n-        ]\n+        \"endpoints\": [\"/api/v1/users/*\", \"/api/v1/restaurants/*\", \"/api/v1/menu/*\"],\n     },\n     \"admin\": {\n         \"rate\": \"200/minute\",\n-        \"endpoints\": [\n-            \"/api/v1/admin/*\",\n-            \"/api/v1/platform/*\"\n-        ]\n+        \"endpoints\": [\"/api/v1/admin/*\", \"/api/v1/platform/*\"],\n     },\n     \"critical\": {\n         \"rate\": \"10/minute\",\n-        \"endpoints\": [\n-            \"/api/v1/system/*\",\n-            \"/api/v1/config/*\"\n-        ]\n-    }\n+        \"endpoints\": [\"/api/v1/system/*\", \"/api/v1/config/*\"],\n+    },\n }\n \n # IP-based rate limiting for additional protection\n IP_RATE_LIMITS = {\n     \"global\": \"1000/minute\",  # Overall IP limit\n     \"auth_attempts\": \"20/hour\",  # Failed auth attempts per IP\n-    \"api_burst\": \"100/second\"  # Burst protection\n+    \"api_burst\": \"100/second\",  # Burst protection\n }\n \n # User role-based rate limit multipliers\n ROLE_MULTIPLIERS = {\n     \"platform_owner\": 2.0,\n     \"restaurant_owner\": 1.5,\n     \"manager\": 1.2,\n     \"employee\": 1.0,\n-    \"customer\": 0.8\n-}\n+    \"customer\": 0.8,\n+}\n+\n \n def get_role_adjusted_rate(base_rate: str, user_role: str) -> str:\n     \"\"\"\n     Adjust rate limit based on user role.\n-    \n+\n     Args:\n         base_rate: Base rate limit\n         user_role: User's role\n-        \n+\n     Returns:\n         Adjusted rate limit\n     \"\"\"\n     multiplier = ROLE_MULTIPLIERS.get(user_role, 1.0)\n-    \n+\n     # Parse and adjust rate\n     parts = base_rate.split(\"/\")\n     if len(parts) != 2:\n         return base_rate\n-    \n+\n     try:\n         limit = int(parts[0])\n         period = parts[1]\n         adjusted_limit = int(limit * multiplier)\n         return f\"{adjusted_limit}/{period}\"\n     except ValueError:\n-        return base_rate\n\\ No newline at end of file\n+        return base_rate\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/rate_limiter.py\t2025-08-02 21:56:58.996389+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/rate_limiter.py\t2025-08-02 22:36:03.323321+00:00\n@@ -11,166 +11,165 @@\n logger = logging.getLogger(__name__)\n \n \n class RateLimiter:\n     \"\"\"Token bucket rate limiter for WebSocket messages\"\"\"\n-    \n+\n     def __init__(\n-        self, \n-        max_messages: int = 100,\n-        window_seconds: int = 60,\n-        burst_size: int = 20\n+        self, max_messages: int = 100, window_seconds: int = 60, burst_size: int = 20\n     ):\n         \"\"\"\n         Initialize rate limiter\n-        \n+\n         Args:\n             max_messages: Maximum messages allowed in window\n             window_seconds: Time window in seconds\n             burst_size: Maximum burst allowed\n         \"\"\"\n         self.max_messages = max_messages\n         self.window_seconds = window_seconds\n         self.burst_size = burst_size\n-        \n+\n         # connection_id -> (tokens, last_update_time)\n         self.buckets: Dict[str, Tuple[float, float]] = {}\n-        \n+\n         # Track violations\n         self.violations: Dict[str, int] = {}\n-        \n+\n     def check_rate_limit(self, connection_id: str) -> bool:\n         \"\"\"\n         Check if connection is within rate limit\n-        \n+\n         Returns:\n             True if allowed, False if rate limited\n         \"\"\"\n         current_time = time.time()\n-        \n+\n         if connection_id not in self.buckets:\n             # First request, initialize bucket\n             self.buckets[connection_id] = (self.burst_size - 1, current_time)\n             return True\n-            \n+\n         tokens, last_update = self.buckets[connection_id]\n-        \n+\n         # Calculate tokens to add based on time elapsed\n         time_elapsed = current_time - last_update\n         refill_rate = self.max_messages / self.window_seconds\n         tokens_to_add = time_elapsed * refill_rate\n-        \n+\n         # Update tokens (cap at burst size)\n         tokens = min(tokens + tokens_to_add, self.burst_size)\n-        \n+\n         if tokens >= 1:\n             # Allow request, consume token\n             self.buckets[connection_id] = (tokens - 1, current_time)\n-            \n+\n             # Reset violations on successful request\n             if connection_id in self.violations:\n                 del self.violations[connection_id]\n-                \n+\n             return True\n         else:\n             # Rate limited\n             self.violations[connection_id] = self.violations.get(connection_id, 0) + 1\n-            \n+\n             if self.violations[connection_id] > 10:\n-                logger.warning(f\"Connection {connection_id} has {self.violations[connection_id]} rate limit violations\")\n-                \n+                logger.warning(\n+                    f\"Connection {connection_id} has {self.violations[connection_id]} rate limit violations\"\n+                )\n+\n             return False\n-            \n+\n     def cleanup_old_buckets(self, inactive_seconds: int = 300):\n         \"\"\"Remove buckets for inactive connections\"\"\"\n         current_time = time.time()\n         expired_connections = []\n-        \n+\n         for conn_id, (_, last_update) in self.buckets.items():\n             if current_time - last_update > inactive_seconds:\n                 expired_connections.append(conn_id)\n-                \n+\n         for conn_id in expired_connections:\n             del self.buckets[conn_id]\n             if conn_id in self.violations:\n                 del self.violations[conn_id]\n-                \n+\n         if expired_connections:\n-            logger.info(f\"Cleaned up {len(expired_connections)} inactive rate limit buckets\")\n-            \n+            logger.info(\n+                f\"Cleaned up {len(expired_connections)} inactive rate limit buckets\"\n+            )\n+\n     def get_wait_time(self, connection_id: str) -> float:\n         \"\"\"Get time to wait before next allowed request\"\"\"\n         if connection_id not in self.buckets:\n             return 0.0\n-            \n+\n         tokens, last_update = self.buckets[connection_id]\n-        \n+\n         if tokens >= 1:\n             return 0.0\n-            \n+\n         # Calculate time needed to get 1 token\n         refill_rate = self.max_messages / self.window_seconds\n         tokens_needed = 1 - tokens\n         wait_time = tokens_needed / refill_rate\n-        \n+\n         return wait_time\n \n \n class ConnectionLimiter:\n     \"\"\"Limit connections per IP and per user\"\"\"\n-    \n+\n     def __init__(\n-        self,\n-        max_per_ip: int = 20,\n-        max_per_user: int = 5,\n-        ip_window_seconds: int = 60\n+        self, max_per_ip: int = 20, max_per_user: int = 5, ip_window_seconds: int = 60\n     ):\n         self.max_per_ip = max_per_ip\n         self.max_per_user = max_per_user\n         self.ip_window_seconds = ip_window_seconds\n-        \n+\n         # IP -> list of (timestamp, user_id)\n         self.ip_connections: Dict[str, list] = {}\n-        \n+\n         # user_id -> set of connection_ids\n         self.user_connections: Dict[str, set] = {}\n         \"\"\"\n         Check if new connection is allowed\n         \n         Returns:\n             (allowed, reason)\n         \"\"\"\n         current_time = time.time()\n-        \n+\n         # Check IP limit\n         if ip_address in self.ip_connections:\n             # Clean old connections\n             self.ip_connections[ip_address] = [\n-                (ts, uid) for ts, uid in self.ip_connections[ip_address]\n+                (ts, uid)\n+                for ts, uid in self.ip_connections[ip_address]\n                 if current_time - ts < self.ip_window_seconds\n             ]\n-            \n+\n             if len(self.ip_connections[ip_address]) >= self.max_per_ip:\n                 return False, f\"Too many connections from IP {ip_address}\"\n-        \n+\n         # Check user limit\n         if user_id in self.user_connections:\n             if len(self.user_connections[user_id]) >= self.max_per_user:\n                 return False, f\"User {user_id} has too many active connections\"\n-                \n+\n         # Connection allowed, track it\n         if ip_address not in self.ip_connections:\n             self.ip_connections[ip_address] = []\n         self.ip_connections[ip_address].append((current_time, user_id))\n-        \n+\n         if user_id not in self.user_connections:\n             self.user_connections[user_id] = set()\n         self.user_connections[user_id].add(connection_id)\n-        \n+\n         return True, \"OK\"\n-        \n+\n     def remove_connection(self, user_id: str, connection_id: str):\n         \"\"\"Remove connection when disconnected\"\"\"\n         if user_id in self.user_connections:\n             self.user_connections[user_id].discard(connection_id)\n             if not self.user_connections[user_id]:\n-                del self.user_connections[user_id]\n\\ No newline at end of file\n+                del self.user_connections[user_id]\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/rls_middleware.py\t2025-08-02 19:23:36.821074+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/rls_middleware.py\t2025-08-02 22:36:03.342957+00:00\n@@ -16,101 +16,106 @@\n class RLSMiddleware(BaseHTTPMiddleware):\n     \"\"\"\n     Middleware to automatically set and clear RLS session context\n     for all authenticated requests\n     \"\"\"\n-    \n+\n     async def dispatch(self, request: Request, call_next: Callable) -> Response:\n         \"\"\"\n         Process request with RLS context management\n         \"\"\"\n         db: Optional[Session] = None\n         user = None\n-        \n+\n         try:\n             # Skip RLS for non-API routes\n             if not request.url.path.startswith(\"/api/\"):\n                 return await call_next(request)\n-            \n+\n             # Skip for health checks and public endpoints\n             skip_paths = [\n                 \"/api/health\",\n                 \"/api/v1/auth/login\",\n                 \"/api/v1/auth/register\",\n                 \"/api/v1/auth/refresh\",\n                 \"/docs\",\n                 \"/redoc\",\n-                \"/openapi.json\"\n+                \"/openapi.json\",\n             ]\n-            \n+\n             if any(request.url.path.startswith(path) for path in skip_paths):\n                 return await call_next(request)\n-            \n+\n             # Try to get current user (may not exist for public endpoints)\n             try:\n                 # Get DB session\n                 db_gen = get_db()\n                 db = next(db_gen)\n-                \n+\n                 # Get user if authenticated\n                 user = await get_current_user_optional(request, db)\n-                \n+\n                 if user:\n                     # Set RLS context for authenticated users\n                     await RLSSessionContext.set_tenant_context(db, user, request)\n-                    \n+\n                     # Log if platform owner is accessing data\n-                    if hasattr(user, 'role') and user.role == 'platform_owner':\n+                    if hasattr(user, \"role\") and user.role == \"platform_owner\":\n                         # Extract restaurant ID from path if present\n-                        path_parts = request.url.path.split('/')\n+                        path_parts = request.url.path.split(\"/\")\n                         restaurant_id = None\n-                        \n-                        if 'restaurants' in path_parts:\n-                            idx = path_parts.index('restaurants')\n+\n+                        if \"restaurants\" in path_parts:\n+                            idx = path_parts.index(\"restaurants\")\n                             if idx + 1 < len(path_parts):\n                                 restaurant_id = path_parts[idx + 1]\n-                        \n+\n                         if restaurant_id and restaurant_id != str(user.restaurant_id):\n                             # Platform owner accessing different restaurant\n                             await security_monitor.log_platform_owner_access(\n                                 user=user,\n                                 target_restaurant_id=restaurant_id,\n                                 action=request.method,\n                                 resource_type=request.url.path,\n                                 details={\n-                                    'method': request.method,\n-                                    'path': request.url.path,\n-                                    'ip': request.client.host if request.client else 'unknown'\n-                                }\n+                                    \"method\": request.method,\n+                                    \"path\": request.url.path,\n+                                    \"ip\": (\n+                                        request.client.host\n+                                        if request.client\n+                                        else \"unknown\"\n+                                    ),\n+                                },\n                             )\n-                \n+\n             except Exception as e:\n                 # If we can't get user, continue without RLS\n                 # This allows public endpoints to work\n                 pass\n-            \n+\n             # Process request\n             response = await call_next(request)\n-            \n+\n             return response\n-            \n+\n         except Exception as e:\n             # Log error but don't break the request\n             import logging\n+\n             logging.error(f\"RLS Middleware error: {str(e)}\")\n-            \n+\n             # Continue without RLS rather than breaking\n             return await call_next(request)\n-            \n+\n         finally:\n             # Always clear RLS context after request\n             if db and user:\n                 try:\n                     await RLSSessionContext.clear_tenant_context(db)\n                 except Exception as e:\n                     pass  # Don't break on cleanup errors\n-            \n+\n             # Close DB session if we opened it\n             if db:\n                 try:\n                     db.close()\n                 except Exception as e:\n@@ -119,6 +124,6 @@\n \n def setup_rls_middleware(app):\n     \"\"\"\n     Setup RLS middleware on the FastAPI app\n     \"\"\"\n-    app.add_middleware(RLSMiddleware)\n\\ No newline at end of file\n+    app.add_middleware(RLSMiddleware)\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/rls_context.py\t2025-08-02 10:59:17.992855+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/rls_context.py\t2025-08-02 22:36:03.344907+00:00\n@@ -13,42 +13,54 @@\n logger = logging.getLogger(__name__)\n \n \n class RLSContext:\n     \"\"\"Manages Row Level Security context for database sessions\"\"\"\n-    \n+\n     @staticmethod\n     @contextmanager\n     def set_tenant_context(db: Session, user: User):\n         \"\"\"\n         Set RLS context for a database session\n-        \n+\n         Args:\n             db: SQLAlchemy session\n             user: Current user\n         \"\"\"\n         try:\n             # Set session variables for RLS\n             if user:\n                 # Set user context with correct variable names\n-                db.execute(text(\"SET LOCAL app.current_user_id = :user_id\"), {\"user_id\": str(user.id)})\n-                db.execute(text(\"SET LOCAL app.current_user_email = :email\"), {\"email\": user.email})\n-                db.execute(text(\"SET LOCAL app.current_user_role = :role\"), {\"role\": user.role})\n-                \n+                db.execute(\n+                    text(\"SET LOCAL app.current_user_id = :user_id\"),\n+                    {\"user_id\": str(user.id)},\n+                )\n+                db.execute(\n+                    text(\"SET LOCAL app.current_user_email = :email\"),\n+                    {\"email\": user.email},\n+                )\n+                db.execute(\n+                    text(\"SET LOCAL app.current_user_role = :role\"), {\"role\": user.role}\n+                )\n+\n                 # Set restaurant context if user has one\n                 if user.restaurant_id:\n-                    db.execute(text(\"SET LOCAL app.current_restaurant_id = :restaurant_id\"), \n-                             {\"restaurant_id\": str(user.restaurant_id)})\n+                    db.execute(\n+                        text(\"SET LOCAL app.current_restaurant_id = :restaurant_id\"),\n+                        {\"restaurant_id\": str(user.restaurant_id)},\n+                    )\n                 else:\n                     # For platform owners without restaurant_id\n                     db.execute(text(\"SET LOCAL app.current_restaurant_id TO DEFAULT\"))\n-                \n+\n                 # Set platform owner flag\n                 is_platform_owner = TenantSecurity.is_platform_owner(user)\n-                db.execute(text(\"SET LOCAL app.is_platform_owner = :is_owner\"), \n-                          {\"is_owner\": str(is_platform_owner).lower()})\n-                \n+                db.execute(\n+                    text(\"SET LOCAL app.is_platform_owner = :is_owner\"),\n+                    {\"is_owner\": str(is_platform_owner).lower()},\n+                )\n+\n                 logger.debug(\n                     f\"RLS context set for user {user.email} \"\n                     f\"(role: {user.role}, restaurant: {user.restaurant_id})\"\n                 )\n             else:\n@@ -56,68 +68,79 @@\n                 db.execute(text(\"SET LOCAL app.current_user_id = ''\"))\n                 db.execute(text(\"SET LOCAL app.current_user_email = ''\"))\n                 db.execute(text(\"SET LOCAL app.current_user_role = ''\"))\n                 db.execute(text(\"SET LOCAL app.current_restaurant_id = ''\"))\n                 db.execute(text(\"SET LOCAL app.is_platform_owner = 'false'\"))\n-            \n+\n             yield db\n-            \n+\n         except Exception as e:\n             logger.error(f\"Error setting RLS context: {str(e)}\")\n             raise\n         finally:\n             # Context automatically cleared when connection returns to pool\n             pass\n-    \n+\n     @staticmethod\n     def apply_to_query(query, user: User):\n         \"\"\"\n         Apply tenant filtering to a query (alternative to RLS)\n         Use this when RLS is not available or as additional security\n-        \n+\n         Args:\n             query: SQLAlchemy query\n             user: Current user\n-            \n+\n         Returns:\n             Filtered query\n         \"\"\"\n         if TenantSecurity.is_platform_owner(user):\n             # Platform owners see everything\n             return query\n-        \n+\n         # Filter by restaurant_id for other users\n-        if hasattr(query.column_descriptions[0]['type'], 'restaurant_id'):\n-            model = query.column_descriptions[0]['type']\n+        if hasattr(query.column_descriptions[0][\"type\"], \"restaurant_id\"):\n+            model = query.column_descriptions[0][\"type\"]\n             return query.filter(model.restaurant_id == user.restaurant_id)\n-        \n+\n         return query\n-    \n+\n     @staticmethod\n     def get_db_with_context(db: Session, user: User):\n         \"\"\"\n         Get a database session with RLS context already set\n-        \n+\n         Args:\n             db: Base database session\n             user: Current user\n-            \n+\n         Returns:\n             Database session with RLS context\n         \"\"\"\n         if user:\n-            db.execute(text(\"SET LOCAL app.current_user_id = :user_id\"), {\"user_id\": str(user.id)})\n-            db.execute(text(\"SET LOCAL app.current_user_email = :email\"), {\"email\": user.email})\n-            db.execute(text(\"SET LOCAL app.current_user_role = :role\"), {\"role\": user.role})\n-            \n+            db.execute(\n+                text(\"SET LOCAL app.current_user_id = :user_id\"),\n+                {\"user_id\": str(user.id)},\n+            )\n+            db.execute(\n+                text(\"SET LOCAL app.current_user_email = :email\"), {\"email\": user.email}\n+            )\n+            db.execute(\n+                text(\"SET LOCAL app.current_user_role = :role\"), {\"role\": user.role}\n+            )\n+\n             if user.restaurant_id:\n-                db.execute(text(\"SET LOCAL app.current_restaurant_id = :restaurant_id\"), \n-                         {\"restaurant_id\": str(user.restaurant_id)})\n+                db.execute(\n+                    text(\"SET LOCAL app.current_restaurant_id = :restaurant_id\"),\n+                    {\"restaurant_id\": str(user.restaurant_id)},\n+                )\n             else:\n                 db.execute(text(\"SET LOCAL app.current_restaurant_id TO DEFAULT\"))\n-            \n+\n             # Set platform owner flag\n             is_platform_owner = TenantSecurity.is_platform_owner(user)\n-            db.execute(text(\"SET LOCAL app.is_platform_owner = :is_owner\"), \n-                      {\"is_owner\": str(is_platform_owner).lower()})\n-        \n-        return db\n\\ No newline at end of file\n+            db.execute(\n+                text(\"SET LOCAL app.is_platform_owner = :is_owner\"),\n+                {\"is_owner\": str(is_platform_owner).lower()},\n+            )\n+\n+        return db\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/database.py\t2025-08-02 21:56:58.994256+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/database.py\t2025-08-02 22:36:03.351328+00:00\n@@ -1,11 +1,23 @@\n \"\"\"\n Database configuration and models for Fynlo POS\n PostgreSQL implementation matching frontend data requirements\n \"\"\"\n \n-from sqlalchemy import create_engine, Column, String, Integer, DateTime, Boolean, Text, ForeignKey, DECIMAL, UniqueConstraint, event\n+from sqlalchemy import (\n+    create_engine,\n+    Column,\n+    String,\n+    Integer,\n+    DateTime,\n+    Boolean,\n+    Text,\n+    ForeignKey,\n+    DECIMAL,\n+    UniqueConstraint,\n+    event,\n+)\n from sqlalchemy.dialects.postgresql import UUID, JSONB\n from sqlalchemy.ext.declarative import declarative_base\n from sqlalchemy.orm import sessionmaker, Session, relationship\n from sqlalchemy.sql import func\n from sqlalchemy.sql.elements import TextClause  # For GIN index\n@@ -27,178 +39,227 @@\n \n # Parse DATABASE_URL to handle SSL requirements\n database_url = settings.DATABASE_URL\n \n # For DigitalOcean managed databases, ensure SSL mode is set\n-if \"postgresql\" in database_url and (\":25060\" in database_url or \":25061\" in database_url):\n+if \"postgresql\" in database_url and (\n+    \":25060\" in database_url or \":25061\" in database_url\n+):\n     if \"sslmode\" not in database_url:\n         # Add sslmode=require to the connection string if not present\n         separator = \"&\" if \"?\" in database_url else \"?\"\n         database_url = f\"{database_url}{separator}sslmode=require\"\n         logger.info(\"Added sslmode=require to DigitalOcean database connection\")\n \n connect_args = {}\n if \"postgresql\" in database_url:\n-    connect_args = {\n-        \"connect_timeout\": 10  # PostgreSQL connection timeout\n-    }\n-    \n+    connect_args = {\"connect_timeout\": 10}  # PostgreSQL connection timeout\n+\n     # For DigitalOcean managed databases\n     if \":25060\" in database_url or \":25061\" in database_url:\n         # PgBouncer (port 25061) doesn't support statement_timeout in connection options\n         # Only add it for direct connections (port 25060)\n         if \":25060\" in database_url:\n-            connect_args[\"options\"] = \"-c statement_timeout=30000\"  # 30 second statement timeout\n-            \n+            connect_args[\"options\"] = (\n+                \"-c statement_timeout=30000\"  # 30 second statement timeout\n+            )\n+\n         # Provide the CA certificate\n-        cert_path = os.path.join(os.path.dirname(__file__), \"..\", \"..\", \"certs\", \"ca-certificate.crt\")\n+        cert_path = os.path.join(\n+            os.path.dirname(__file__), \"..\", \"..\", \"certs\", \"ca-certificate.crt\"\n+        )\n         if os.path.exists(cert_path):\n             # Provide the CA certificate path for SSL verification\n             connect_args[\"sslrootcert\"] = cert_path\n             logger.info(f\"Using CA certificate for SSL: {cert_path}\")\n         else:\n             logger.warning(f\"CA certificate not found at {cert_path}\")\n     else:\n         # For non-DigitalOcean databases, add statement timeout\n-        connect_args[\"options\"] = \"-c statement_timeout=30000\"  # 30 second statement timeout\n+        connect_args[\"options\"] = (\n+            \"-c statement_timeout=30000\"  # 30 second statement timeout\n+        )\n \n # Import security config\n from app.core.database_security import DatabaseSecurityConfig\n \n # Merge security settings with existing connect_args\n secure_engine_args = DatabaseSecurityConfig.get_secure_engine_args()\n-secure_connect_args = secure_engine_args.pop('connect_args', {})\n+secure_connect_args = secure_engine_args.pop(\"connect_args\", {})\n # Merge with existing connect_args\n for key, value in connect_args.items():\n     if key not in secure_connect_args:\n         secure_connect_args[key] = value\n \n engine = create_engine(\n     database_url,\n-    echo=settings.DEBUG and settings.ENVIRONMENT != \"production\",  # Never echo in production\n+    echo=settings.DEBUG\n+    and settings.ENVIRONMENT != \"production\",  # Never echo in production\n     poolclass=QueuePool,\n-    pool_size=secure_engine_args.get('pool_size', 20),\n-    max_overflow=secure_engine_args.get('max_overflow', 10),\n-    pool_recycle=secure_engine_args.get('pool_recycle', 3600),\n-    pool_pre_ping=secure_engine_args.get('pool_pre_ping', True),\n+    pool_size=secure_engine_args.get(\"pool_size\", 20),\n+    max_overflow=secure_engine_args.get(\"max_overflow\", 10),\n+    pool_recycle=secure_engine_args.get(\"pool_recycle\", 3600),\n+    pool_pre_ping=secure_engine_args.get(\"pool_pre_ping\", True),\n     pool_timeout=30,\n-    pool_reset_on_return='rollback',\n+    pool_reset_on_return=\"rollback\",\n     connect_args=secure_connect_args,\n-    future=secure_engine_args.get('future', True)\n+    future=secure_engine_args.get(\"future\", True),\n )\n \n SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n \n Base = declarative_base()\n \n # Database Models matching frontend expectations\n+\n \n class Platform(Base):\n     \"\"\"Multi-tenant platform for restaurant owners\"\"\"\n+\n     __tablename__ = \"platforms\"\n-    \n+\n     id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n     name = Column(String(255), nullable=False)\n     owner_email = Column(String(255), unique=True, nullable=False)\n     subscription_tier = Column(String(50), default=\"basic\")\n     created_at = Column(DateTime(timezone=True), server_default=func.now())\n     updated_at = Column(DateTime(timezone=True), onupdate=func.now())\n \n+\n class Restaurant(Base):\n     \"\"\"Individual restaurant configuration\"\"\"\n+\n     __tablename__ = \"restaurants\"\n-    \n+\n     id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n     platform_id = Column(UUID(as_uuid=True), nullable=True)  # Multi-tenant support\n     name = Column(String(255), nullable=False)\n     address = Column(JSONB, nullable=False)\n     phone = Column(String(20))\n     email = Column(String(255))\n     timezone = Column(String(50), default=\"UTC\")\n     business_hours = Column(JSONB, default={})\n     settings = Column(JSONB, default={})\n-    tax_configuration = Column(JSONB, default={\n-        \"vatEnabled\": True,\n-        \"vatRate\": 20,\n-        \"serviceTaxEnabled\": True,\n-        \"serviceTaxRate\": 12.5\n-    })\n-    payment_methods = Column(JSONB, default={\n-        \"qrCode\": {\"enabled\": True, \"feePercentage\": 1.2},\n-        \"cash\": {\"enabled\": True, \"requiresAuth\": False},\n-        \"card\": {\"enabled\": True, \"feePercentage\": 2.9},\n-        \"applePay\": {\"enabled\": True, \"feePercentage\": 2.9},\n-        \"giftCard\": {\"enabled\": True, \"requiresAuth\": True}\n-    })\n+    tax_configuration = Column(\n+        JSONB,\n+        default={\n+            \"vatEnabled\": True,\n+            \"vatRate\": 20,\n+            \"serviceTaxEnabled\": True,\n+            \"serviceTaxRate\": 12.5,\n+        },\n+    )\n+    payment_methods = Column(\n+        JSONB,\n+        default={\n+            \"qrCode\": {\"enabled\": True, \"feePercentage\": 1.2},\n+            \"cash\": {\"enabled\": True, \"requiresAuth\": False},\n+            \"card\": {\"enabled\": True, \"feePercentage\": 2.9},\n+            \"applePay\": {\"enabled\": True, \"feePercentage\": 2.9},\n+            \"giftCard\": {\"enabled\": True, \"requiresAuth\": True},\n+        },\n+    )\n     floor_plan_layout = Column(JSONB)  # New field for layout storage\n     # Subscription fields for Supabase integration\n-    subscription_plan = Column(String(50), default='alpha')  # alpha, beta, omega\n-    subscription_status = Column(String(50), default='trial')  # trial, active, cancelled, expired\n+    subscription_plan = Column(String(50), default=\"alpha\")  # alpha, beta, omega\n+    subscription_status = Column(\n+        String(50), default=\"trial\"\n+    )  # trial, active, cancelled, expired\n     subscription_started_at = Column(DateTime(timezone=True), nullable=True)\n     subscription_expires_at = Column(DateTime(timezone=True), nullable=True)\n     is_active = Column(Boolean, default=True)\n     created_at = Column(DateTime(timezone=True), server_default=func.now())\n     updated_at = Column(DateTime(timezone=True), onupdate=func.now())\n-    \n+\n     # Relationships\n     inventory_items = relationship(\"InventoryItem\", back_populates=\"restaurant\")\n \n+\n class User(Base):\n     \"\"\"Users with role-based access\"\"\"\n+\n     __tablename__ = \"users\"\n-    \n+\n     id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n     email = Column(String(255), unique=True, nullable=False)\n-    username = Column(String(100), unique=True, nullable=True)  # Optional username field\n+    username = Column(\n+        String(100), unique=True, nullable=True\n+    )  # Optional username field\n     password_hash = Column(String(255), nullable=True)  # Now nullable for Supabase auth\n-    supabase_id = Column(UUID(as_uuid=True), unique=True, nullable=True)  # Supabase user ID\n-    auth_provider = Column(String(50), default='supabase')  # Track auth method\n+    supabase_id = Column(\n+        UUID(as_uuid=True), unique=True, nullable=True\n+    )  # Supabase user ID\n+    auth_provider = Column(String(50), default=\"supabase\")  # Track auth method\n     first_name = Column(String(100), nullable=False)\n     last_name = Column(String(100), nullable=False)\n-    role = Column(String(50), nullable=False)  # platform_owner, restaurant_owner, manager, employee\n-    restaurant_id = Column(UUID(as_uuid=True), nullable=True)  # Legacy single restaurant\n+    role = Column(\n+        String(50), nullable=False\n+    )  # platform_owner, restaurant_owner, manager, employee\n+    restaurant_id = Column(\n+        UUID(as_uuid=True), nullable=True\n+    )  # Legacy single restaurant\n     platform_id = Column(UUID(as_uuid=True), nullable=True)\n     permissions = Column(JSONB, default={})\n     pin_code = Column(String(6))  # For employee time clock\n     is_active = Column(Boolean, default=True)\n     last_login = Column(DateTime(timezone=True))\n-    current_restaurant_id = Column(UUID(as_uuid=True), ForeignKey('restaurants.id'), nullable=True)\n+    current_restaurant_id = Column(\n+        UUID(as_uuid=True), ForeignKey(\"restaurants.id\"), nullable=True\n+    )\n     last_restaurant_switch = Column(DateTime(timezone=True), nullable=True)\n     created_at = Column(DateTime(timezone=True), server_default=func.now())\n     updated_at = Column(DateTime(timezone=True), onupdate=func.now())\n-    \n+\n     # Relationships\n-    restaurants = relationship(\"UserRestaurant\", foreign_keys=\"[UserRestaurant.user_id]\", back_populates=\"user\")\n-    current_restaurant = relationship(\"Restaurant\", foreign_keys=[current_restaurant_id])\n+    restaurants = relationship(\n+        \"UserRestaurant\", foreign_keys=\"[UserRestaurant.user_id]\", back_populates=\"user\"\n+    )\n+    current_restaurant = relationship(\n+        \"Restaurant\", foreign_keys=[current_restaurant_id]\n+    )\n+\n \n class UserRestaurant(Base):\n     \"\"\"Many-to-many relationship between users and restaurants for multi-restaurant support\"\"\"\n+\n     __tablename__ = \"user_restaurants\"\n-    \n-    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n-    user_id = Column(UUID(as_uuid=True), ForeignKey('users.id', ondelete='CASCADE'), nullable=False)\n-    restaurant_id = Column(UUID(as_uuid=True), ForeignKey('restaurants.id', ondelete='CASCADE'), nullable=False)\n-    role = Column(String(50), nullable=False, default='owner')  # owner, manager, employee\n+\n+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n+    user_id = Column(\n+        UUID(as_uuid=True), ForeignKey(\"users.id\", ondelete=\"CASCADE\"), nullable=False\n+    )\n+    restaurant_id = Column(\n+        UUID(as_uuid=True),\n+        ForeignKey(\"restaurants.id\", ondelete=\"CASCADE\"),\n+        nullable=False,\n+    )\n+    role = Column(\n+        String(50), nullable=False, default=\"owner\"\n+    )  # owner, manager, employee\n     is_primary = Column(Boolean, default=False)\n     permissions = Column(JSONB, default={})\n-    assigned_by = Column(UUID(as_uuid=True), ForeignKey('users.id', ondelete='SET NULL'), nullable=True)\n-    created_at = Column(DateTime(timezone=True), server_default=func.now())\n-    updated_at = Column(DateTime(timezone=True), onupdate=func.now())\n-    \n+    assigned_by = Column(\n+        UUID(as_uuid=True), ForeignKey(\"users.id\", ondelete=\"SET NULL\"), nullable=True\n+    )\n+    created_at = Column(DateTime(timezone=True), server_default=func.now())\n+    updated_at = Column(DateTime(timezone=True), onupdate=func.now())\n+\n     # Relationships\n     user = relationship(\"User\", foreign_keys=[user_id], back_populates=\"restaurants\")\n     restaurant = relationship(\"Restaurant\")\n     assigned_by_user = relationship(\"User\", foreign_keys=[assigned_by])\n-    \n+\n     __table_args__ = (\n-        UniqueConstraint('user_id', 'restaurant_id', name='unique_user_restaurant'),\n-    )\n+        UniqueConstraint(\"user_id\", \"restaurant_id\", name=\"unique_user_restaurant\"),\n+    )\n+\n \n class Customer(Base):\n     \"\"\"Customer management with loyalty tracking\"\"\"\n+\n     __tablename__ = \"customers\"\n-    \n+\n     id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n     restaurant_id = Column(UUID(as_uuid=True), nullable=False)\n     email = Column(String(255))\n     phone = Column(String(20))\n     first_name = Column(String(100))\n@@ -208,28 +269,32 @@\n     visit_count = Column(Integer, default=0)\n     preferences = Column(JSONB, default={})\n     created_at = Column(DateTime(timezone=True), server_default=func.now())\n     updated_at = Column(DateTime(timezone=True), onupdate=func.now())\n \n+\n class Category(Base):\n     \"\"\"Menu categories\"\"\"\n+\n     __tablename__ = \"categories\"\n-    \n+\n     id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n     restaurant_id = Column(UUID(as_uuid=True), nullable=False)\n     name = Column(String(255), nullable=False)\n     description = Column(Text)\n     color = Column(String(7), default=\"#00A651\")  # Hex color\n     icon = Column(String(50))\n     sort_order = Column(Integer, default=0)\n     is_active = Column(Boolean, default=True)\n     created_at = Column(DateTime(timezone=True), server_default=func.now())\n \n+\n class Product(Base):\n     \"\"\"Menu items/products\"\"\"\n+\n     __tablename__ = \"products\"\n-    \n+\n     id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n     restaurant_id = Column(UUID(as_uuid=True), nullable=False)\n     category_id = Column(UUID(as_uuid=True), nullable=False)\n     name = Column(String(255), nullable=False)\n     description = Column(Text)\n@@ -244,26 +309,32 @@\n     is_active = Column(Boolean, default=True)\n     stock_tracking = Column(Boolean, default=False)\n     stock_quantity = Column(Integer, default=0)\n     created_at = Column(DateTime(timezone=True), server_default=func.now())\n     updated_at = Column(DateTime(timezone=True), onupdate=func.now())\n-    \n+\n     # Relationship to recipes\n     recipes = relationship(\"Recipe\", back_populates=\"product_item\")\n \n+\n class Order(Base):\n     \"\"\"Customer orders\"\"\"\n+\n     __tablename__ = \"orders\"\n-    \n+\n     id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n     restaurant_id = Column(UUID(as_uuid=True), nullable=False)\n     customer_id = Column(UUID(as_uuid=True), nullable=True)\n     order_number = Column(String(50), nullable=False)\n     table_number = Column(String(20))  # Legacy field - kept for backward compatibility\n-    table_id = Column(UUID(as_uuid=True), ForeignKey('tables.id'), nullable=True)  # New FK to tables\n+    table_id = Column(\n+        UUID(as_uuid=True), ForeignKey(\"tables.id\"), nullable=True\n+    )  # New FK to tables\n     order_type = Column(String(20), default=\"dine_in\")  # dine_in, takeaway, delivery\n-    status = Column(String(20), default=\"pending\")  # pending, confirmed, preparing, ready, completed, cancelled\n+    status = Column(\n+        String(20), default=\"pending\"\n+    )  # pending, confirmed, preparing, ready, completed, cancelled\n     items = Column(JSONB, nullable=False)\n     subtotal = Column(DECIMAL(10, 2), nullable=False)\n     tax_amount = Column(DECIMAL(10, 2), default=0.0)\n     service_charge = Column(DECIMAL(10, 2), default=0.0)\n     discount_amount = Column(DECIMAL(10, 2), default=0.0)\n@@ -271,186 +342,250 @@\n     payment_status = Column(String(20), default=\"pending\")\n     special_instructions = Column(Text)\n     created_by = Column(UUID(as_uuid=True), nullable=False)\n     created_at = Column(DateTime(timezone=True), server_default=func.now())\n     updated_at = Column(DateTime(timezone=True), onupdate=func.now())\n-    \n+\n     # Relationship\n     table = relationship(\"Table\", back_populates=\"orders\")\n \n+\n class Payment(Base):\n     \"\"\"Payment transactions\"\"\"\n+\n     __tablename__ = \"payments\"\n-    \n+\n     id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n     order_id = Column(UUID(as_uuid=True), nullable=False)\n-    payment_method = Column(String(50), nullable=False)  # qr_code, cash, card, apple_pay\n+    payment_method = Column(\n+        String(50), nullable=False\n+    )  # qr_code, cash, card, apple_pay\n     amount = Column(DECIMAL(10, 2), nullable=False)\n     fee_amount = Column(DECIMAL(10, 2), default=0.0)\n     net_amount = Column(DECIMAL(10, 2), nullable=False)\n-    status = Column(String(20), default=\"pending\")  # pending, processing, completed, failed, refunded\n+    status = Column(\n+        String(20), default=\"pending\"\n+    )  # pending, processing, completed, failed, refunded\n     external_id = Column(String(255))  # Stripe payment ID, etc.\n     payment_metadata = Column(JSONB, default={})\n     processed_at = Column(DateTime(timezone=True))\n     created_at = Column(DateTime(timezone=True), server_default=func.now())\n \n+\n class QRPayment(Base):\n     \"\"\"QR code payment tracking\"\"\"\n+\n     __tablename__ = \"qr_payments\"\n-    \n+\n     id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n     order_id = Column(UUID(as_uuid=True), nullable=False)\n     qr_code_data = Column(Text, nullable=False)\n     amount = Column(DECIMAL(10, 2), nullable=False)\n     status = Column(String(50), default=\"pending\")\n     expires_at = Column(DateTime(timezone=True), nullable=False)\n     fee_amount = Column(DECIMAL(10, 2), default=0.0)\n     net_amount = Column(DECIMAL(10, 2), nullable=False)\n     created_at = Column(DateTime(timezone=True), server_default=func.now())\n \n+\n class Section(Base):\n     \"\"\"Restaurant floor plan sections\"\"\"\n+\n     __tablename__ = \"sections\"\n-    \n+\n     id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n     restaurant_id = Column(UUID(as_uuid=True), nullable=False)\n     name = Column(String(255), nullable=False)\n     description = Column(Text, nullable=True)\n     capacity = Column(Integer, default=50)\n     is_active = Column(Boolean, default=True)\n     created_at = Column(DateTime(timezone=True), server_default=func.now())\n     updated_at = Column(DateTime(timezone=True), onupdate=func.now())\n \n+\n class InventoryItem(Base):\n     \"\"\"Inventory items (raw ingredients/supplies)\"\"\"\n+\n     __tablename__ = \"inventory\"\n \n     sku = Column(String(100), primary_key=True, index=True)\n-    restaurant_id = Column(UUID(as_uuid=True), ForeignKey('restaurants.id', ondelete='CASCADE'), nullable=False)\n+    restaurant_id = Column(\n+        UUID(as_uuid=True),\n+        ForeignKey(\"restaurants.id\", ondelete=\"CASCADE\"),\n+        nullable=False,\n+    )\n     name = Column(String(255), nullable=False)\n     description = Column(Text, nullable=True)\n-    qty_g = Column(Integer, nullable=False, default=0) # Current quantity in grams (or ml or units)\n-    par_level_g = Column(Integer, nullable=True, default=0) # Desired stock level\n-    unit = Column(String(50), default=\"grams\") # e.g., grams, ml, units\n-    cost_per_unit = Column(DECIMAL(10, 2), nullable=True) # Cost per unit (e.g., cost per gram)\n+    qty_g = Column(\n+        Integer, nullable=False, default=0\n+    )  # Current quantity in grams (or ml or units)\n+    par_level_g = Column(Integer, nullable=True, default=0)  # Desired stock level\n+    unit = Column(String(50), default=\"grams\")  # e.g., grams, ml, units\n+    cost_per_unit = Column(\n+        DECIMAL(10, 2), nullable=True\n+    )  # Cost per unit (e.g., cost per gram)\n     supplier = Column(String(255), nullable=True)\n-    last_updated = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now())\n+    last_updated = Column(\n+        DateTime(timezone=True), server_default=func.now(), onupdate=func.now()\n+    )\n \n     # Relationships\n     restaurant = relationship(\"Restaurant\", back_populates=\"inventory_items\")\n     recipe_ingredients = relationship(\"Recipe\", back_populates=\"ingredient\")\n     # Relationship to ledger entries\n-    ledger_entries = relationship(\"InventoryLedgerEntry\", back_populates=\"inventory_item\")\n+    ledger_entries = relationship(\n+        \"InventoryLedgerEntry\", back_populates=\"inventory_item\"\n+    )\n \n \n class Recipe(Base):\n     \"\"\"Recipes linking products to inventory items\"\"\"\n+\n     __tablename__ = \"recipe\"\n \n     id = Column(Integer, primary_key=True, index=True, autoincrement=True)\n-    restaurant_id = Column(UUID(as_uuid=True), ForeignKey('restaurants.id', ondelete='CASCADE'), nullable=False)\n-    item_id = Column(UUID(as_uuid=True), ForeignKey(\"products.id\"), nullable=False) # FK to Product.id\n-    ingredient_sku = Column(String(100), ForeignKey(\"inventory.sku\"), nullable=False) # FK to InventoryItem.sku\n-    qty_g = Column(Integer, nullable=False) # Quantity of ingredient in grams (or ml or units)\n+    restaurant_id = Column(\n+        UUID(as_uuid=True),\n+        ForeignKey(\"restaurants.id\", ondelete=\"CASCADE\"),\n+        nullable=False,\n+    )\n+    item_id = Column(\n+        UUID(as_uuid=True), ForeignKey(\"products.id\"), nullable=False\n+    )  # FK to Product.id\n+    ingredient_sku = Column(\n+        String(100), ForeignKey(\"inventory.sku\"), nullable=False\n+    )  # FK to InventoryItem.sku\n+    qty_g = Column(\n+        Integer, nullable=False\n+    )  # Quantity of ingredient in grams (or ml or units)\n \n     # Relationships\n     restaurant = relationship(\"Restaurant\")\n     product_item = relationship(\"Product\", back_populates=\"recipes\")\n     ingredient = relationship(\"InventoryItem\", back_populates=\"recipe_ingredients\")\n \n-    __table_args__ = (UniqueConstraint('restaurant_id', 'item_id', 'ingredient_sku', name='uq_recipe_restaurant_item_ingredient'),)\n+    __table_args__ = (\n+        UniqueConstraint(\n+            \"restaurant_id\",\n+            \"item_id\",\n+            \"ingredient_sku\",\n+            name=\"uq_recipe_restaurant_item_ingredient\",\n+        ),\n+    )\n \n \n class InventoryLedgerEntry(Base):\n     \"\"\"Audit trail for inventory changes\"\"\"\n+\n     __tablename__ = \"inventory_ledger\"\n \n     id = Column(Integer, primary_key=True, index=True, autoincrement=True)\n     sku = Column(String(100), ForeignKey(\"inventory.sku\"), nullable=False, index=True)\n-    restaurant_id = Column(UUID(as_uuid=True), ForeignKey('restaurants.id', ondelete='CASCADE'), nullable=False)\n-    delta_g = Column(Integer, nullable=False) # Change in quantity (positive for additions, negative for deductions)\n-    source = Column(String(50), nullable=False) # E.g., \"order_fulfillment\", \"manual_stock_add\", \"initial_import\", \"spoilage\"\n-    source_id = Column(String(255), nullable=True) # E.g., order_id, user_id (for manual entry), import_batch_id\n-    ts = Column(DateTime(timezone=True), server_default=func.now(), nullable=False, index=True)\n+    restaurant_id = Column(\n+        UUID(as_uuid=True),\n+        ForeignKey(\"restaurants.id\", ondelete=\"CASCADE\"),\n+        nullable=False,\n+    )\n+    delta_g = Column(\n+        Integer, nullable=False\n+    )  # Change in quantity (positive for additions, negative for deductions)\n+    source = Column(\n+        String(50), nullable=False\n+    )  # E.g., \"order_fulfillment\", \"manual_stock_add\", \"initial_import\", \"spoilage\"\n+    source_id = Column(\n+        String(255), nullable=True\n+    )  # E.g., order_id, user_id (for manual entry), import_batch_id\n+    ts = Column(\n+        DateTime(timezone=True), server_default=func.now(), nullable=False, index=True\n+    )\n \n     # Relationships\n     restaurant = relationship(\"Restaurant\")\n     inventory_item = relationship(\"InventoryItem\", back_populates=\"ledger_entries\")\n \n \n class Table(Base):\n     \"\"\"Restaurant tables\"\"\"\n+\n     __tablename__ = \"tables\"\n-    \n+\n     id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n     restaurant_id = Column(UUID(as_uuid=True), nullable=False)\n-    section_id = Column(UUID(as_uuid=True), ForeignKey('sections.id'), nullable=False)\n+    section_id = Column(UUID(as_uuid=True), ForeignKey(\"sections.id\"), nullable=False)\n     name = Column(String(100), nullable=False)\n     seats = Column(Integer, nullable=False, default=4)\n-    status = Column(String(20), default=\"available\")  # available, occupied, reserved, cleaning\n+    status = Column(\n+        String(20), default=\"available\"\n+    )  # available, occupied, reserved, cleaning\n     server_id = Column(UUID(as_uuid=True), nullable=True)  # Reference to User\n     x_position = Column(Integer, default=0)\n     y_position = Column(Integer, default=0)\n     width = Column(Integer, default=60)  # Table width for layout\n     height = Column(Integer, default=60)  # Table height for layout\n     rotation = Column(Integer, default=0)  # Rotation angle in degrees\n     shape = Column(String(20), default=\"round\")  # round, square, rectangle\n     is_active = Column(Boolean, default=True)\n     created_at = Column(DateTime(timezone=True), server_default=func.now())\n     updated_at = Column(DateTime(timezone=True), onupdate=func.now())\n-    \n+\n     # Relationships\n     section = relationship(\"Section\")\n     orders = relationship(\"Order\", back_populates=\"table\")\n \n+\n class PosSession(Base):\n     \"\"\"POS Session management\"\"\"\n+\n     __tablename__ = \"pos_sessions\"\n-    \n+\n     id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n     restaurant_id = Column(UUID(as_uuid=True), nullable=False)\n     user_id = Column(UUID(as_uuid=True), nullable=False)\n     name = Column(String(255), nullable=False)\n-    state = Column(String(50), default=\"opening_control\")  # opening_control, opened, closing_control, closed\n+    state = Column(\n+        String(50), default=\"opening_control\"\n+    )  # opening_control, opened, closing_control, closed\n     config_id = Column(Integer, nullable=False)\n     config_name = Column(String(255), nullable=False)\n     start_at = Column(DateTime(timezone=True), server_default=func.now())\n     stop_at = Column(DateTime(timezone=True), nullable=True)\n     session_data = Column(JSONB, default={})  # Additional session configuration\n     is_active = Column(Boolean, default=True)\n     created_at = Column(DateTime(timezone=True), server_default=func.now())\n     updated_at = Column(DateTime(timezone=True), onupdate=func.now())\n \n+\n # RLS context for session variables\n import contextvars\n from typing import Optional, Dict, Any\n \n # Use contextvars for proper async context management\n-_rls_context_var: contextvars.ContextVar[Optional[Dict[str, Any]]] = contextvars.ContextVar(\n-    'rls_context',\n-    default=None\n+_rls_context_var: contextvars.ContextVar[Optional[Dict[str, Any]]] = (\n+    contextvars.ContextVar(\"rls_context\", default=None)\n )\n+\n \n class RLSContext:\n     \"\"\"Context-aware storage for RLS context using contextvars\"\"\"\n-    \n+\n     @classmethod\n-    def set(cls, user_id: Optional[str] = None, restaurant_id: Optional[str] = None, role: Optional[str] = None):\n+    def set(\n+        cls,\n+        user_id: Optional[str] = None,\n+        restaurant_id: Optional[str] = None,\n+        role: Optional[str] = None,\n+    ):\n         \"\"\"Set RLS context for current async context\"\"\"\n-        context = {\n-            'user_id': user_id,\n-            'restaurant_id': restaurant_id,\n-            'role': role\n-        }\n+        context = {\"user_id\": user_id, \"restaurant_id\": restaurant_id, \"role\": role}\n         _rls_context_var.set(context)\n-    \n+\n     @classmethod\n     def get(cls) -> dict:\n         \"\"\"Get RLS context for current async context\"\"\"\n         context = _rls_context_var.get()\n         return context if context is not None else {}\n-    \n+\n     @classmethod\n     def clear(cls):\n         \"\"\"Clear RLS context for current async context\"\"\"\n         _rls_context_var.set(None)\n \n@@ -466,42 +601,57 @@\n @event.listens_for(engine, \"checkout\")\n def receive_checkout(dbapi_connection, connection_record, connection_proxy):\n     \"\"\"Set session variables when connection is checked out from pool\"\"\"\n     # Get RLS context if available\n     context = RLSContext.get()\n-    \n+\n     if context:\n         cursor = dbapi_connection.cursor()\n         try:\n             # Reset only RLS-specific session variables (not ALL)\n             cursor.execute(\"RESET app.current_user_id\")\n             cursor.execute(\"RESET app.current_user_email\")\n             cursor.execute(\"RESET app.current_user_role\")\n             cursor.execute(\"RESET app.current_restaurant_id\")\n             cursor.execute(\"RESET app.is_platform_owner\")\n-            \n+\n             # Set session variables for RLS with correct names\n-            if context.get('user_id'):\n-                cursor.execute(\"SET LOCAL app.current_user_id = %s\", (context['user_id'],))\n+            if context.get(\"user_id\"):\n+                cursor.execute(\n+                    \"SET LOCAL app.current_user_id = %s\", (context[\"user_id\"],)\n+                )\n                 logger.debug(f\"Set RLS current_user_id: {context['user_id']}\")\n-                \n+\n                 # Also set user email if available\n-                if hasattr(context, 'email'):\n-                    cursor.execute(\"SET LOCAL app.current_user_email = %s\", (context.get('email', ''),))\n-            \n-            if context.get('restaurant_id'):\n-                cursor.execute(\"SET LOCAL app.current_restaurant_id = %s\", (context['restaurant_id'],))\n-                logger.debug(f\"Set RLS current_restaurant_id: {context['restaurant_id']}\")\n-            \n-            if context.get('role'):\n-                cursor.execute(\"SET LOCAL app.current_user_role = %s\", (context['role'],))\n+                if hasattr(context, \"email\"):\n+                    cursor.execute(\n+                        \"SET LOCAL app.current_user_email = %s\",\n+                        (context.get(\"email\", \"\"),),\n+                    )\n+\n+            if context.get(\"restaurant_id\"):\n+                cursor.execute(\n+                    \"SET LOCAL app.current_restaurant_id = %s\",\n+                    (context[\"restaurant_id\"],),\n+                )\n+                logger.debug(\n+                    f\"Set RLS current_restaurant_id: {context['restaurant_id']}\"\n+                )\n+\n+            if context.get(\"role\"):\n+                cursor.execute(\n+                    \"SET LOCAL app.current_user_role = %s\", (context[\"role\"],)\n+                )\n                 logger.debug(f\"Set RLS current_user_role: {context['role']}\")\n-                \n+\n                 # Set platform owner flag\n-                is_platform_owner = context.get('role') == 'platform_owner'\n-                cursor.execute(\"SET LOCAL app.is_platform_owner = %s\", (str(is_platform_owner).lower(),))\n-            \n+                is_platform_owner = context.get(\"role\") == \"platform_owner\"\n+                cursor.execute(\n+                    \"SET LOCAL app.is_platform_owner = %s\",\n+                    (str(is_platform_owner).lower(),),\n+                )\n+\n             dbapi_connection.commit()\n         except Exception as e:\n             logger.error(f\"Error setting RLS session variables: {e}\")\n             dbapi_connection.rollback()\n         finally:\n@@ -539,31 +689,37 @@\n         RLSContext.clear()\n         db.close()\n \n \n @contextmanager\n-def get_db_with_rls(user_id: Optional[str] = None, restaurant_id: Optional[str] = None, role: Optional[str] = None):\n+def get_db_with_rls(\n+    user_id: Optional[str] = None,\n+    restaurant_id: Optional[str] = None,\n+    role: Optional[str] = None,\n+):\n     \"\"\"Get database session with specific RLS context\"\"\"\n     # Set RLS context\n     RLSContext.set(user_id=user_id, restaurant_id=restaurant_id, role=role)\n-    \n+\n     db = SessionLocal()\n     try:\n         yield db\n     finally:\n         # Clear RLS context\n         RLSContext.clear()\n         db.close()\n \n+\n async def init_db():\n     \"\"\"Initialize database tables and apply security measures\"\"\"\n     # Create tables\n     Base.metadata.create_all(bind=engine)\n-    \n+\n     # Apply database security hardening\n     try:\n         from app.core.database_security import apply_all_security_measures\n+\n         apply_all_security_measures(engine)\n         logger.info(\"Database security measures applied\")\n     except Exception as e:\n         logger.warning(f\"Could not apply all security measures: {e}\")\n-        # Continue without failing startup\n\\ No newline at end of file\n+        # Continue without failing startup\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/rls_session_context.py\t2025-08-01 23:08:38.305781+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/rls_session_context.py\t2025-08-02 22:36:03.355916+00:00\n@@ -12,31 +12,28 @@\n from app.models import User\n from app.core.tenant_security import TenantSecurity\n from app.core.database import get_db\n \n # Context variable to store current tenant context\n-current_tenant_context: contextvars.ContextVar[Optional[Dict[str, Any]]] = contextvars.ContextVar(\n-    'current_tenant_context', \n-    default=None\n+current_tenant_context: contextvars.ContextVar[Optional[Dict[str, Any]]] = (\n+    contextvars.ContextVar(\"current_tenant_context\", default=None)\n )\n \n \n class RLSSessionContext:\n     \"\"\"\n     Manages Row Level Security (RLS) session variables for proper tenant isolation\n     in connection pooling environments\n     \"\"\"\n-    \n+\n     @staticmethod\n     async def set_tenant_context(\n-        db: Session,\n-        user: User,\n-        request: Optional[Request] = None\n+        db: Session, user: User, request: Optional[Request] = None\n     ) -> None:\n         \"\"\"\n         Set RLS session variables for the current database session\n-        \n+\n         Args:\n             db: Database session\n             user: Current user\n             request: Optional request object for additional context\n         \"\"\"\n@@ -47,83 +44,93 @@\n                 db,\n                 user_id=str(user.id),\n                 user_email=user.email,\n                 user_role=user.role,\n                 restaurant_id=None,  # NULL means access to all\n-                is_platform_owner=True\n+                is_platform_owner=True,\n             )\n         else:\n             # Regular users are restricted to their restaurant\n             if not user.restaurant_id:\n                 # Users without restaurant assignment get no access\n                 await RLSSessionContext._set_session_variables(\n                     db,\n                     user_id=str(user.id),\n                     user_email=user.email,\n                     user_role=user.role,\n-                    restaurant_id='00000000-0000-0000-0000-000000000000',  # Invalid UUID\n-                    is_platform_owner=False\n+                    restaurant_id=\"00000000-0000-0000-0000-000000000000\",  # Invalid UUID\n+                    is_platform_owner=False,\n                 )\n             else:\n                 # Set regular user context\n                 await RLSSessionContext._set_session_variables(\n                     db,\n                     user_id=str(user.id),\n                     user_email=user.email,\n                     user_role=user.role,\n                     restaurant_id=str(user.restaurant_id),\n-                    is_platform_owner=False\n+                    is_platform_owner=False,\n                 )\n-        \n+\n         # Store context in context variable for reference\n         context = {\n-            'user_id': str(user.id),\n-            'user_email': user.email,\n-            'user_role': user.role,\n-            'restaurant_id': str(user.restaurant_id) if user.restaurant_id else None,\n-            'is_platform_owner': TenantSecurity.is_platform_owner(user)\n+            \"user_id\": str(user.id),\n+            \"user_email\": user.email,\n+            \"user_role\": user.role,\n+            \"restaurant_id\": str(user.restaurant_id) if user.restaurant_id else None,\n+            \"is_platform_owner\": TenantSecurity.is_platform_owner(user),\n         }\n         current_tenant_context.set(context)\n-    \n+\n     @staticmethod\n     async def _set_session_variables(\n         db: Session,\n         user_id: str,\n         user_email: str,\n         user_role: str,\n         restaurant_id: Optional[str],\n-        is_platform_owner: bool\n+        is_platform_owner: bool,\n     ) -> None:\n         \"\"\"\n         Set PostgreSQL session variables for RLS\n-        \n+\n         These variables are used by RLS policies to determine access\n         \"\"\"\n         try:\n             # Set session variables using PostgreSQL SET LOCAL\n             # These are only valid for the current transaction\n-            db.execute(text(\"SET LOCAL app.current_user_id = :user_id\"), {\"user_id\": user_id})\n-            db.execute(text(\"SET LOCAL app.current_user_email = :email\"), {\"email\": user_email})\n-            db.execute(text(\"SET LOCAL app.current_user_role = :role\"), {\"role\": user_role})\n-            \n+            db.execute(\n+                text(\"SET LOCAL app.current_user_id = :user_id\"), {\"user_id\": user_id}\n+            )\n+            db.execute(\n+                text(\"SET LOCAL app.current_user_email = :email\"), {\"email\": user_email}\n+            )\n+            db.execute(\n+                text(\"SET LOCAL app.current_user_role = :role\"), {\"role\": user_role}\n+            )\n+\n             if restaurant_id:\n-                db.execute(text(\"SET LOCAL app.current_restaurant_id = :restaurant_id\"), \n-                          {\"restaurant_id\": restaurant_id})\n+                db.execute(\n+                    text(\"SET LOCAL app.current_restaurant_id = :restaurant_id\"),\n+                    {\"restaurant_id\": restaurant_id},\n+                )\n             else:\n                 # For platform owners, set to NULL\n                 db.execute(text(\"SET LOCAL app.current_restaurant_id TO DEFAULT\"))\n-            \n-            db.execute(text(\"SET LOCAL app.is_platform_owner = :is_owner\"), \n-                      {\"is_owner\": str(is_platform_owner).lower()})\n-            \n+\n+            db.execute(\n+                text(\"SET LOCAL app.is_platform_owner = :is_owner\"),\n+                {\"is_owner\": str(is_platform_owner).lower()},\n+            )\n+\n             # Commit to ensure variables are set\n             db.commit()\n-            \n+\n         except Exception as e:\n             db.rollback()\n             raise Exception(f\"Failed to set RLS session variables: {str(e)}\")\n-    \n+\n     @staticmethod\n     async def clear_tenant_context(db: Session) -> None:\n         \"\"\"\n         Clear RLS session variables (important for connection pooling)\n         \"\"\"\n@@ -132,80 +139,77 @@\n             db.execute(text(\"RESET app.current_user_id\"))\n             db.execute(text(\"RESET app.current_user_email\"))\n             db.execute(text(\"RESET app.current_user_role\"))\n             db.execute(text(\"RESET app.current_restaurant_id\"))\n             db.execute(text(\"RESET app.is_platform_owner\"))\n-            \n+\n             db.commit()\n-            \n+\n             # Clear context variable\n             current_tenant_context.set(None)\n-            \n+\n         except Exception as e:\n             db.rollback()\n             # Log but don't raise - clearing context should not break requests\n             import logging\n+\n             logging.error(f\"Failed to clear RLS session variables: {str(e)}\")\n-    \n+\n     @staticmethod\n     def get_current_context() -> Optional[Dict[str, Any]]:\n         \"\"\"\n         Get the current tenant context from context variables\n         \"\"\"\n         return current_tenant_context.get()\n-    \n+\n     @staticmethod\n     async def ensure_tenant_isolation(\n-        db: Session,\n-        user: User,\n-        operation: str = \"query\"\n+        db: Session, user: User, operation: str = \"query\"\n     ) -> None:\n         \"\"\"\n         Ensure tenant isolation is properly set before database operations\n-        \n+\n         This should be called before any database query that needs tenant isolation\n         \"\"\"\n         context = current_tenant_context.get()\n-        \n+\n         # If no context or context doesn't match user, set it\n-        if not context or context.get('user_id') != str(user.id):\n+        if not context or context.get(\"user_id\") != str(user.id):\n             await RLSSessionContext.set_tenant_context(db, user)\n-    \n+\n     @staticmethod\n     def create_rls_dependency():\n         \"\"\"\n         Create a FastAPI dependency for automatic RLS context management\n         \"\"\"\n         from fastapi import Depends\n-        \n+\n         async def rls_context_dependency(\n-            request: Request,\n-            db: Session = Depends(get_db),\n-            user: Optional[User] = None\n+            request: Request, db: Session = Depends(get_db), user: Optional[User] = None\n         ):\n             \"\"\"\n             FastAPI dependency that automatically sets RLS context\n             \"\"\"\n             # Import here to avoid circular imports\n             from app.core.auth import get_current_user\n-            \n+\n             try:\n                 # Get user if not provided\n                 if user is None:\n                     user = await get_current_user(request, db)\n-                \n+\n                 # Set tenant context for this request\n                 await RLSSessionContext.set_tenant_context(db, user, request)\n-                \n+\n                 yield db\n-                \n+\n             finally:\n                 # Always clear context after request\n                 await RLSSessionContext.clear_tenant_context(db)\n-        \n+\n         return rls_context_dependency\n \n \n # Function to get RLS-enabled DB session\n def get_rls_db():\n     \"\"\"Get a database session with RLS context\"\"\"\n-    return RLSSessionContext.create_rls_dependency()\n\\ No newline at end of file\n+    return RLSSessionContext.create_rls_dependency()\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/security_utils.py\t2025-07-30 15:49:34.699139+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/security_utils.py\t2025-08-02 22:36:03.357620+00:00\n@@ -1,49 +1,50 @@\n \"\"\"Security utilities for input sanitization and validation.\"\"\"\n+\n from typing import Optional\n import re\n \n \n def sanitize_sql_like_pattern(value: Optional[str]) -> Optional[str]:\n     \"\"\"\n     Sanitize user input for SQL LIKE queries by escaping special characters.\n-    \n+\n     SQL LIKE special characters:\n     - % (matches any sequence of characters)\n     - _ (matches any single character)\n     - \\ (escape character)\n-    \n+\n     Args:\n         value: The user input string to sanitize\n-        \n+\n     Returns:\n         Sanitized string safe for use in SQL LIKE queries\n     \"\"\"\n     if not value:\n         return value\n-    \n+\n     # Escape backslashes first (must be done before other escapes)\n-    value = value.replace('\\\\', '\\\\\\\\')\n+    value = value.replace(\"\\\\\", \"\\\\\\\\\")\n     # Escape percentage signs\n-    value = value.replace('%', '\\\\%')\n+    value = value.replace(\"%\", \"\\\\%\")\n     # Escape underscores\n-    value = value.replace('_', '\\\\_')\n-    \n+    value = value.replace(\"_\", \"\\\\_\")\n+\n     return value\n \n \n def sanitize_sql_identifier(identifier: str, allowed_values: list[str]) -> str:\n     \"\"\"\n     Sanitize and validate SQL identifiers (table names, column names).\n-    \n+\n     Args:\n         identifier: The identifier to validate\n         allowed_values: List of allowed values (whitelist)\n-        \n+\n     Returns:\n         The validated identifier\n-        \n+\n     Raises:\n         ValueError: If identifier is not in the allowed list\n     \"\"\"\n     if identifier not in allowed_values:\n         raise ValueError(f\"Invalid identifier: {identifier}\")\n@@ -51,43 +52,42 @@\n \n \n def is_valid_uuid(value: str) -> bool:\n     \"\"\"\n     Validate if a string is a valid UUID.\n-    \n+\n     Args:\n         value: String to validate\n-        \n+\n     Returns:\n         True if valid UUID, False otherwise\n     \"\"\"\n     uuid_pattern = re.compile(\n-        r'^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$',\n-        re.IGNORECASE\n+        r\"^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$\", re.IGNORECASE\n     )\n     return bool(uuid_pattern.match(value))\n \n \n def sanitize_search_term(term: str, max_length: int = 100) -> str:\n     \"\"\"\n     Sanitize a general search term.\n-    \n+\n     Args:\n         term: The search term to sanitize\n         max_length: Maximum allowed length\n-        \n+\n     Returns:\n         Sanitized search term\n     \"\"\"\n     if not term:\n         return \"\"\n-    \n+\n     # Truncate to max length\n     term = term[:max_length]\n-    \n+\n     # Remove any null bytes\n-    term = term.replace('\\x00', '')\n-    \n+    term = term.replace(\"\\x00\", \"\")\n+\n     # Strip leading/trailing whitespace\n     term = term.strip()\n-    \n-    return term\n\\ No newline at end of file\n+\n+    return term\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/supabase.py\t2025-08-02 10:59:17.993244+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/supabase.py\t2025-08-02 22:36:03.369266+00:00\n@@ -18,70 +18,76 @@\n     \"\"\"Get Supabase client with service role key for admin operations\"\"\"\n     # Try multiple sources for environment variables\n     # 1. First try settings (pydantic-settings loads from env)\n     # 2. Then try direct os.getenv\n     # 3. Finally try alternate variable names\n-    \n+\n     supabase_url = None\n     supabase_key = None\n-    \n+\n     # Try to get URL\n-    if hasattr(settings, 'SUPABASE_URL') and settings.SUPABASE_URL:\n+    if hasattr(settings, \"SUPABASE_URL\") and settings.SUPABASE_URL:\n         supabase_url = settings.SUPABASE_URL\n     if not supabase_url:\n         supabase_url = os.getenv(\"SUPABASE_URL\")\n-    \n+\n     # Try to get service role key\n-    if hasattr(settings, 'SUPABASE_SERVICE_ROLE_KEY') and settings.SUPABASE_SERVICE_ROLE_KEY:\n+    if (\n+        hasattr(settings, \"SUPABASE_SERVICE_ROLE_KEY\")\n+        and settings.SUPABASE_SERVICE_ROLE_KEY\n+    ):\n         supabase_key = settings.SUPABASE_SERVICE_ROLE_KEY\n     if not supabase_key:\n         supabase_key = os.getenv(\"SUPABASE_SERVICE_ROLE_KEY\")\n     if not supabase_key:\n         supabase_key = os.getenv(\"supabase_secret_key\")  # Check alternate env var name\n-    \n+\n     # Log what we found (without exposing sensitive data)\n-    logger.info(f\"Environment check - SUPABASE_URL: {'Found' if supabase_url else 'Missing'}\")\n-    logger.info(f\"Environment check - Service Key: {'Found' if supabase_key else 'Missing'}\")\n-    \n+    logger.info(\n+        f\"Environment check - SUPABASE_URL: {'Found' if supabase_url else 'Missing'}\"\n+    )\n+    logger.info(\n+        f\"Environment check - Service Key: {'Found' if supabase_key else 'Missing'}\"\n+    )\n+\n     if not supabase_url or not supabase_key:\n         # Log which variables are missing for debugging\n         missing = []\n         if not supabase_url:\n             missing.append(\"SUPABASE_URL\")\n         if not supabase_key:\n             missing.append(\"SUPABASE_SERVICE_ROLE_KEY or supabase_secret_key\")\n-        \n+\n         error_msg = f\"Missing required environment variables: {', '.join(missing)}\"\n         logger.error(error_msg)\n-        \n+\n         # Log all available environment variable names (not values) for debugging\n         env_vars = list(os.environ.keys())\n-        supabase_related = [var for var in env_vars if 'SUPA' in var.upper() or 'SECRET' in var.upper()]\n+        supabase_related = [\n+            var for var in env_vars if \"SUPA\" in var.upper() or \"SECRET\" in var.upper()\n+        ]\n         logger.info(f\"Available Supabase-related env vars: {supabase_related}\")\n-        \n+\n         raise ValueError(error_msg)\n-    \n+\n     logger.info(f\"Initializing Supabase client with URL: {supabase_url[:30]}...\")\n-    \n-    return create_client(\n-        supabase_url,\n-        supabase_key\n-    )\n+\n+    return create_client(supabase_url, supabase_key)\n \n \n def get_admin_client() -> Optional[Client]:\n     \"\"\"Get or create the Supabase admin client instance\"\"\"\n     global _supabase_admin\n-    \n+\n     if _supabase_admin is None:\n         try:\n             _supabase_admin = get_supabase_client()\n             logger.info(\"\u2705 Supabase admin client initialized successfully\")\n         except Exception as e:\n             logger.error(f\"\u274c Failed to initialize Supabase admin client: {e}\")\n             return None\n-    \n+\n     return _supabase_admin\n \n \n # Initialize the Supabase admin client at module load\n try:\n@@ -89,6 +95,6 @@\n     logger.info(\"\u2705 Supabase client initialized successfully at module load\")\n except Exception as e:\n     # Log the error but don't crash the app\n     logger.warning(f\"\u26a0\ufe0f  Failed to initialize Supabase client at module load: {e}\")\n     logger.warning(\"Supabase client will be initialized on first use\")\n-    supabase_admin = None\n\\ No newline at end of file\n+    supabase_admin = None\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/responses.py\t2025-08-02 19:52:26.970651+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/responses.py\t2025-08-02 22:36:03.369058+00:00\n@@ -10,328 +10,306 @@\n from fastapi.responses import JSONResponse\n \n \n class APIResponse(BaseModel):\n     \"\"\"Standardized API response wrapper for iOS consumption\"\"\"\n+\n     success: bool\n     data: Optional[Any] = None\n     message: str = \"Success\"\n     error: Optional[Dict[str, Any]] = None\n     meta: Optional[Dict[str, Any]] = None\n     timestamp: datetime\n \n     class Config:\n-        json_encoders = {\n-            datetime: lambda v: v.isoformat() if v else None\n-        }\n+        json_encoders = {datetime: lambda v: v.isoformat() if v else None}\n \n \n class PaginationMeta(BaseModel):\n     \"\"\"Pagination metadata for list responses\"\"\"\n+\n     page: int\n     limit: int\n     total: int\n     pages: int\n     has_next: bool\n     has_prev: bool\n \n \n class ErrorDetail(BaseModel):\n     \"\"\"Detailed error information\"\"\"\n+\n     code: str\n     message: str\n     field: Optional[str] = None\n     details: Optional[Dict[str, Any]] = None\n \n \n class APIResponseHelper:\n     \"\"\"Helper class for creating standardized API responses\"\"\"\n-    \n+\n     @staticmethod\n     def success(\n         data: Any = None,\n         message: str = \"Success\",\n         meta: Optional[Dict[str, Any]] = None,\n-        status_code: int = status.HTTP_200_OK\n+        status_code: int = status.HTTP_200_OK,\n     ) -> JSONResponse:\n         \"\"\"Create successful response\"\"\"\n         response_data = APIResponse(\n             success=True,\n             data=data,\n             message=message,\n             meta=meta,\n-            timestamp=datetime.utcnow()\n-        )\n-        \n+            timestamp=datetime.utcnow(),\n+        )\n+\n         return JSONResponse(\n-            status_code=status_code,\n-            content=response_data.model_dump(mode='json')\n-        )\n-    \n+            status_code=status_code, content=response_data.model_dump(mode=\"json\")\n+        )\n+\n     @staticmethod\n     def created(\n         data: Any = None,\n         message: str = \"Resource created successfully\",\n-        meta: Optional[Dict[str, Any]] = None\n+        meta: Optional[Dict[str, Any]] = None,\n     ) -> JSONResponse:\n         \"\"\"Create successful creation response\"\"\"\n         return APIResponseHelper.success(\n-            data=data,\n-            message=message,\n-            meta=meta,\n-            status_code=status.HTTP_201_CREATED\n-        )\n-    \n+            data=data, message=message, meta=meta, status_code=status.HTTP_201_CREATED\n+        )\n+\n     @staticmethod\n     def error(\n         message: str,\n         error_code: str = \"GENERAL_ERROR\",\n         details: Optional[Dict[str, Any]] = None,\n         field: Optional[str] = None,\n-        status_code: int = status.HTTP_400_BAD_REQUEST\n+        status_code: int = status.HTTP_400_BAD_REQUEST,\n     ) -> JSONResponse:\n         \"\"\"Create error response\"\"\"\n         error_detail = ErrorDetail(\n-            code=error_code,\n-            message=message,\n-            field=field,\n-            details=details\n-        )\n-        \n+            code=error_code, message=message, field=field, details=details\n+        )\n+\n         response_data = APIResponse(\n             success=False,\n             message=\"Request failed\",\n             error=error_detail.model_dump(),\n-            timestamp=datetime.utcnow()\n-        )\n-        \n+            timestamp=datetime.utcnow(),\n+        )\n+\n         return JSONResponse(\n-            status_code=status_code,\n-            content=response_data.model_dump(mode='json')\n-        )\n-    \n+            status_code=status_code, content=response_data.model_dump(mode=\"json\")\n+        )\n+\n     @staticmethod\n     def validation_error(\n-        message: str = \"Validation failed\",\n-        errors: List[Dict[str, Any]] = None\n+        message: str = \"Validation failed\", errors: List[Dict[str, Any]] = None\n     ) -> JSONResponse:\n         \"\"\"Create validation error response\"\"\"\n         return APIResponseHelper.error(\n             message=message,\n             error_code=\"VALIDATION_ERROR\",\n             details={\"validation_errors\": errors or []},\n-            status_code=status.HTTP_422_UNPROCESSABLE_ENTITY\n-        )\n-    \n+            status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,\n+        )\n+\n     @staticmethod\n     def not_found(\n-        resource: str = \"Resource\",\n-        resource_id: Optional[str] = None\n+        resource: str = \"Resource\", resource_id: Optional[str] = None\n     ) -> JSONResponse:\n         \"\"\"Create not found error response\"\"\"\n         message = f\"{resource} not found\"\n         if resource_id:\n             message += f\" (ID: {resource_id})\"\n-            \n+\n         return APIResponseHelper.error(\n             message=message,\n             error_code=\"NOT_FOUND\",\n-            status_code=status.HTTP_404_NOT_FOUND\n-        )\n-    \n+            status_code=status.HTTP_404_NOT_FOUND,\n+        )\n+\n     @staticmethod\n     def unauthorized(message: str = \"Authentication required\") -> JSONResponse:\n         \"\"\"Create unauthorized error response\"\"\"\n         return APIResponseHelper.error(\n             message=message,\n             error_code=\"UNAUTHORIZED\",\n-            status_code=status.HTTP_401_UNAUTHORIZED\n-        )\n-    \n+            status_code=status.HTTP_401_UNAUTHORIZED,\n+        )\n+\n     @staticmethod\n     def forbidden(message: str = \"Access denied\") -> JSONResponse:\n         \"\"\"Create forbidden error response\"\"\"\n         return APIResponseHelper.error(\n             message=message,\n             error_code=\"FORBIDDEN\",\n-            status_code=status.HTTP_403_FORBIDDEN\n-        )\n-    \n+            status_code=status.HTTP_403_FORBIDDEN,\n+        )\n+\n     @staticmethod\n     def conflict(\n-        message: str = \"Resource conflict\",\n-        conflicting_field: Optional[str] = None\n+        message: str = \"Resource conflict\", conflicting_field: Optional[str] = None\n     ) -> JSONResponse:\n         \"\"\"Create conflict error response\"\"\"\n         return APIResponseHelper.error(\n             message=message,\n             error_code=\"CONFLICT\",\n             field=conflicting_field,\n-            status_code=status.HTTP_409_CONFLICT\n-        )\n-    \n+            status_code=status.HTTP_409_CONFLICT,\n+        )\n+\n     @staticmethod\n     def internal_error(\n-        message: str = \"Internal server error\",\n-        error_id: Optional[str] = None\n+        message: str = \"Internal server error\", error_id: Optional[str] = None\n     ) -> JSONResponse:\n         \"\"\"Create internal server error response\"\"\"\n         details = {\"error_id\": error_id} if error_id else None\n-        \n+\n         return APIResponseHelper.error(\n             message=message,\n             error_code=\"INTERNAL_ERROR\",\n             details=details,\n-            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR\n-        )\n-    \n+            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n+        )\n+\n     @staticmethod\n     def paginated(\n-        data: List[Any],\n-        page: int,\n-        limit: int,\n-        total: int,\n-        message: str = \"Success\"\n+        data: List[Any], page: int, limit: int, total: int, message: str = \"Success\"\n     ) -> JSONResponse:\n         \"\"\"Create paginated response\"\"\"\n         pages = (total + limit - 1) // limit if total > 0 else 0\n-        \n+\n         pagination_meta = PaginationMeta(\n             page=page,\n             limit=limit,\n             total=total,\n             pages=pages,\n             has_next=page < pages,\n-            has_prev=page > 1\n-        )\n-        \n+            has_prev=page > 1,\n+        )\n+\n         return APIResponseHelper.success(\n             data=data,\n             message=message,\n-            meta={\"pagination\": pagination_meta.model_dump()}\n+            meta={\"pagination\": pagination_meta.model_dump()},\n         )\n \n \n # iOS-specific response helpers\n class iOSResponseHelper:\n     \"\"\"iOS-specific response helpers for enhanced mobile experience\"\"\"\n-    \n+\n     @staticmethod\n     def login_success(\n         access_token: str,\n         user_data: Dict[str, Any],\n-        restaurant_data: Optional[Dict[str, Any]] = None\n+        restaurant_data: Optional[Dict[str, Any]] = None,\n     ) -> JSONResponse:\n         \"\"\"Standardized login success response for iOS\"\"\"\n         response_data = {\n             \"access_token\": access_token,\n             \"token_type\": \"bearer\",\n-            \"user\": user_data\n+            \"user\": user_data,\n         }\n-        \n+\n         if restaurant_data:\n             response_data[\"restaurant\"] = restaurant_data\n-        \n-        return APIResponseHelper.success(\n-            data=response_data,\n-            message=\"Login successful\"\n-        )\n-    \n+\n+        return APIResponseHelper.success(data=response_data, message=\"Login successful\")\n+\n     @staticmethod\n     def logout_success() -> JSONResponse:\n         \"\"\"Standardized logout response for iOS\"\"\"\n-        return APIResponseHelper.success(\n-            message=\"Logout successful\"\n-        )\n-    \n+        return APIResponseHelper.success(message=\"Logout successful\")\n+\n     @staticmethod\n     def order_created(order_data: Dict[str, Any]) -> JSONResponse:\n         \"\"\"Standardized order creation response for iOS\"\"\"\n         return APIResponseHelper.created(\n-            data=order_data,\n-            message=\"Order created successfully\"\n-        )\n-    \n+            data=order_data, message=\"Order created successfully\"\n+        )\n+\n     @staticmethod\n     def payment_success(payment_data: Dict[str, Any]) -> JSONResponse:\n         \"\"\"Standardized payment success response for iOS\"\"\"\n         return APIResponseHelper.success(\n-            data=payment_data,\n-            message=\"Payment processed successfully\"\n-        )\n-    \n+            data=payment_data, message=\"Payment processed successfully\"\n+        )\n+\n     @staticmethod\n     def menu_response(menu_data: Dict[str, Any]) -> JSONResponse:\n         \"\"\"Standardized menu response for iOS\"\"\"\n         return APIResponseHelper.success(\n             data=menu_data,\n             message=\"Menu retrieved successfully\",\n             meta={\n                 \"cache_duration\": 600,  # 10 minutes\n-                \"last_updated\": datetime.utcnow().isoformat()\n-            }\n+                \"last_updated\": datetime.utcnow().isoformat(),\n+            },\n         )\n \n \n # Error code constants for consistency\n class ErrorCodes:\n     \"\"\"Standardized error codes for iOS app handling\"\"\"\n-    \n+\n     # Authentication errors\n     AUTHENTICATION_ERROR = \"AUTHENTICATION_ERROR\"\n     INVALID_CREDENTIALS = \"INVALID_CREDENTIALS\"\n     TOKEN_EXPIRED = \"TOKEN_EXPIRED\"\n     TOKEN_INVALID = \"TOKEN_INVALID\"\n     ACCOUNT_INACTIVE = \"ACCOUNT_INACTIVE\"\n-    \n+\n     # Validation errors\n     VALIDATION_ERROR = \"VALIDATION_ERROR\"\n     MISSING_FIELD = \"MISSING_FIELD\"\n     INVALID_FORMAT = \"INVALID_FORMAT\"\n-    \n+\n     # Resource errors\n     NOT_FOUND = \"NOT_FOUND\"\n     ALREADY_EXISTS = \"ALREADY_EXISTS\"\n     CONFLICT = \"CONFLICT\"\n-    \n+\n     # Permission errors\n     UNAUTHORIZED = \"UNAUTHORIZED\"\n     FORBIDDEN = \"FORBIDDEN\"\n     INSUFFICIENT_PERMISSIONS = \"INSUFFICIENT_PERMISSIONS\"\n-    \n+\n     # Business logic errors\n     ORDER_CANNOT_BE_MODIFIED = \"ORDER_CANNOT_BE_MODIFIED\"\n     PAYMENT_FAILED = \"PAYMENT_FAILED\"\n     INSUFFICIENT_STOCK = \"INSUFFICIENT_STOCK\"\n     INVALID_ORDER_STATE = \"INVALID_ORDER_STATE\"\n-    \n+\n     # System errors\n     INTERNAL_ERROR = \"INTERNAL_ERROR\"\n     SERVICE_UNAVAILABLE = \"SERVICE_UNAVAILABLE\"\n     RATE_LIMIT_EXCEEDED = \"RATE_LIMIT_EXCEEDED\"\n \n \n # HTTP status code constants\n class HTTPStatusCodes:\n     \"\"\"HTTP status codes for consistent API responses\"\"\"\n-    \n+\n     # Success\n     OK = 200\n     CREATED = 201\n     ACCEPTED = 202\n     NO_CONTENT = 204\n-    \n+\n     # Client errors\n     BAD_REQUEST = 400\n     UNAUTHORIZED = 401\n     FORBIDDEN = 403\n     NOT_FOUND = 404\n     METHOD_NOT_ALLOWED = 405\n     CONFLICT = 409\n     UNPROCESSABLE_ENTITY = 422\n     TOO_MANY_REQUESTS = 429\n-    \n+\n     # Server errors\n     INTERNAL_SERVER_ERROR = 500\n     BAD_GATEWAY = 502\n     SERVICE_UNAVAILABLE = 503\n-    GATEWAY_TIMEOUT = 504\n\\ No newline at end of file\n+    GATEWAY_TIMEOUT = 504\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/platform_service.py\t2025-08-02 21:56:58.995530+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/platform_service.py\t2025-08-02 22:36:03.367146+00:00\n@@ -10,360 +10,459 @@\n from decimal import Decimal\n \n from app.core.database import Platform, Restaurant, Order, Customer\n from app.core.exceptions import FynloException, ErrorCodes\n \n+\n class PlatformService:\n     \"\"\"Service for platform management operations\"\"\"\n-    \n+\n     def __init__(self, db: Session):\n         self.db = db\n-    \n+\n     def get_platform_overview(self, platform_id: str) -> Dict[str, Any]:\n         \"\"\"\n         Get comprehensive platform overview with metrics\n         \"\"\"\n         try:\n             # Get platform\n-            platform = self.db.query(Platform).filter(Platform.id == platform_id).first()\n+            platform = (\n+                self.db.query(Platform).filter(Platform.id == platform_id).first()\n+            )\n             if not platform:\n                 raise FynloException(\n                     message=\"Platform not found\",\n                     error_code=ErrorCodes.NOT_FOUND,\n-                    status_code=404\n-                )\n-            \n+                    status_code=404,\n+                )\n+\n             # Get restaurants\n-            restaurants = self.db.query(Restaurant).filter(\n-                Restaurant.platform_id == platform_id\n-            ).all()\n-            \n+            restaurants = (\n+                self.db.query(Restaurant)\n+                .filter(Restaurant.platform_id == platform_id)\n+                .all()\n+            )\n+\n             restaurant_ids = [str(r.id) for r in restaurants]\n-            \n+\n             # Calculate metrics\n             total_restaurants = len(restaurants)\n             active_restaurants = sum(1 for r in restaurants if r.is_active)\n-            \n+\n             # Revenue metrics (last 30 days)\n             end_date = datetime.now()\n             start_date = end_date - timedelta(days=30)\n-            \n-            total_revenue = self.db.query(func.sum(Order.total_amount)).filter(\n-                and_(\n-                    Order.restaurant_id.in_(restaurant_ids),\n-                    Order.created_at >= start_date,\n-                    Order.status == \"completed\"\n-                )\n-            ).scalar() or 0\n-            \n-            total_orders = self.db.query(Order).filter(\n-                and_(\n-                    Order.restaurant_id.in_(restaurant_ids),\n-                    Order.created_at >= start_date\n-                )\n-            ).count()\n-            \n+\n+            total_revenue = (\n+                self.db.query(func.sum(Order.total_amount))\n+                .filter(\n+                    and_(\n+                        Order.restaurant_id.in_(restaurant_ids),\n+                        Order.created_at >= start_date,\n+                        Order.status == \"completed\",\n+                    )\n+                )\n+                .scalar()\n+                or 0\n+            )\n+\n+            total_orders = (\n+                self.db.query(Order)\n+                .filter(\n+                    and_(\n+                        Order.restaurant_id.in_(restaurant_ids),\n+                        Order.created_at >= start_date,\n+                    )\n+                )\n+                .count()\n+            )\n+\n             # Customer metrics\n-            total_customers = self.db.query(Customer).filter(\n-                Customer.restaurant_id.in_(restaurant_ids)\n-            ).count()\n-            \n+            total_customers = (\n+                self.db.query(Customer)\n+                .filter(Customer.restaurant_id.in_(restaurant_ids))\n+                .count()\n+            )\n+\n             return {\n                 \"platform_id\": str(platform.id),\n                 \"platform_name\": platform.name,\n                 \"total_restaurants\": total_restaurants,\n                 \"active_restaurants\": active_restaurants,\n                 \"total_revenue_30d\": float(total_revenue),\n                 \"total_orders_30d\": total_orders,\n                 \"total_customers\": total_customers,\n-                \"average_revenue_per_restaurant\": float(total_revenue / total_restaurants) if total_restaurants > 0 else 0,\n+                \"average_revenue_per_restaurant\": (\n+                    float(total_revenue / total_restaurants)\n+                    if total_restaurants > 0\n+                    else 0\n+                ),\n                 \"restaurants\": [\n                     {\n                         \"id\": str(r.id),\n                         \"name\": r.name,\n                         \"is_active\": r.is_active,\n-                        \"created_at\": r.created_at.isoformat()\n+                        \"created_at\": r.created_at.isoformat(),\n                     }\n                     for r in restaurants\n-                ]\n+                ],\n             }\n-            \n+\n         except Exception as e:\n             raise FynloException(\n                 message=f\"Failed to get platform overview: {str(e)}\",\n                 error_code=ErrorCodes.INTERNAL_ERROR,\n-                status_code=500\n-            )\n-    \n-    def get_restaurant_performance_comparison(self, platform_id: str, period_days: int = 30) -> List[Dict[str, Any]]:\n+                status_code=500,\n+            )\n+\n+    def get_restaurant_performance_comparison(\n+        self, platform_id: str, period_days: int = 30\n+    ) -> List[Dict[str, Any]]:\n         \"\"\"\n         Compare performance across all restaurants in platform\n         \"\"\"\n         try:\n-            restaurants = self.db.query(Restaurant).filter(\n-                Restaurant.platform_id == platform_id\n-            ).all()\n-            \n+            restaurants = (\n+                self.db.query(Restaurant)\n+                .filter(Restaurant.platform_id == platform_id)\n+                .all()\n+            )\n+\n             end_date = datetime.now()\n             start_date = end_date - timedelta(days=period_days)\n-            \n+\n             performance_data = []\n-            \n+\n             for restaurant in restaurants:\n                 # Get restaurant metrics\n-                orders = self.db.query(Order).filter(\n-                    and_(\n-                        Order.restaurant_id == restaurant.id,\n-                        Order.created_at >= start_date\n-                    )\n-                ).all()\n-                \n+                orders = (\n+                    self.db.query(Order)\n+                    .filter(\n+                        and_(\n+                            Order.restaurant_id == restaurant.id,\n+                            Order.created_at >= start_date,\n+                        )\n+                    )\n+                    .all()\n+                )\n+\n                 completed_orders = [o for o in orders if o.status == \"completed\"]\n                 total_revenue = sum(o.total_amount for o in completed_orders)\n-                \n+\n                 # Customer metrics\n-                customers = self.db.query(Customer).filter(\n-                    Customer.restaurant_id == restaurant.id\n-                ).count()\n-                \n+                customers = (\n+                    self.db.query(Customer)\n+                    .filter(Customer.restaurant_id == restaurant.id)\n+                    .count()\n+                )\n+\n                 # Calculate performance indicators\n-                avg_order_value = total_revenue / len(completed_orders) if completed_orders else 0\n-                order_completion_rate = len(completed_orders) / len(orders) * 100 if orders else 0\n-                \n-                performance_data.append({\n-                    \"restaurant_id\": str(restaurant.id),\n-                    \"restaurant_name\": restaurant.name,\n-                    \"is_active\": restaurant.is_active,\n-                    \"total_orders\": len(orders),\n-                    \"completed_orders\": len(completed_orders),\n-                    \"total_revenue\": float(total_revenue),\n-                    \"average_order_value\": float(avg_order_value),\n-                    \"order_completion_rate\": round(order_completion_rate, 2),\n-                    \"total_customers\": customers,\n-                    \"revenue_per_customer\": float(total_revenue / customers) if customers > 0 else 0,\n-                    \"orders_per_day\": round(len(orders) / period_days, 2),\n-                    \"revenue_per_day\": round(float(total_revenue) / period_days, 2)\n-                })\n-            \n+                avg_order_value = (\n+                    total_revenue / len(completed_orders) if completed_orders else 0\n+                )\n+                order_completion_rate = (\n+                    len(completed_orders) / len(orders) * 100 if orders else 0\n+                )\n+\n+                performance_data.append(\n+                    {\n+                        \"restaurant_id\": str(restaurant.id),\n+                        \"restaurant_name\": restaurant.name,\n+                        \"is_active\": restaurant.is_active,\n+                        \"total_orders\": len(orders),\n+                        \"completed_orders\": len(completed_orders),\n+                        \"total_revenue\": float(total_revenue),\n+                        \"average_order_value\": float(avg_order_value),\n+                        \"order_completion_rate\": round(order_completion_rate, 2),\n+                        \"total_customers\": customers,\n+                        \"revenue_per_customer\": (\n+                            float(total_revenue / customers) if customers > 0 else 0\n+                        ),\n+                        \"orders_per_day\": round(len(orders) / period_days, 2),\n+                        \"revenue_per_day\": round(float(total_revenue) / period_days, 2),\n+                    }\n+                )\n+\n             # Sort by revenue (highest first)\n             performance_data.sort(key=lambda x: x[\"total_revenue\"], reverse=True)\n-            \n+\n             return performance_data\n-            \n+\n         except Exception as e:\n             raise FynloException(\n                 message=f\"Failed to get restaurant performance comparison: {str(e)}\",\n                 error_code=ErrorCodes.INTERNAL_ERROR,\n-                status_code=500\n-            )\n-    \n-    def calculate_commission_breakdown(self, platform_id: str, period_days: int = 30) -> Dict[str, Any]:\n+                status_code=500,\n+            )\n+\n+    def calculate_commission_breakdown(\n+        self, platform_id: str, period_days: int = 30\n+    ) -> Dict[str, Any]:\n         \"\"\"\n         Calculate commission breakdown for platform\n         \"\"\"\n         try:\n-            restaurants = self.db.query(Restaurant).filter(\n-                Restaurant.platform_id == platform_id\n-            ).all()\n-            \n+            restaurants = (\n+                self.db.query(Restaurant)\n+                .filter(Restaurant.platform_id == platform_id)\n+                .all()\n+            )\n+\n             end_date = datetime.now()\n             start_date = end_date - timedelta(days=period_days)\n-            \n+\n             commission_data = []\n             total_platform_commission = 0\n             total_gross_revenue = 0\n-            \n+\n             for restaurant in restaurants:\n                 # Get completed orders for period\n-                completed_orders = self.db.query(Order).filter(\n-                    and_(\n-                        Order.restaurant_id == restaurant.id,\n-                        Order.created_at >= start_date,\n-                        Order.status == \"completed\"\n-                    )\n-                ).all()\n-                \n+                completed_orders = (\n+                    self.db.query(Order)\n+                    .filter(\n+                        and_(\n+                            Order.restaurant_id == restaurant.id,\n+                            Order.created_at >= start_date,\n+                            Order.status == \"completed\",\n+                        )\n+                    )\n+                    .all()\n+                )\n+\n                 gross_revenue = sum(o.total_amount for o in completed_orders)\n-                \n+\n                 # Get commission rate (default 5%)\n-                commission_rate = restaurant.settings.get(\"commission_rate\", 0.05) if restaurant.settings else 0.05\n+                commission_rate = (\n+                    restaurant.settings.get(\"commission_rate\", 0.05)\n+                    if restaurant.settings\n+                    else 0.05\n+                )\n                 commission_amount = gross_revenue * commission_rate\n                 net_revenue = gross_revenue - commission_amount\n-                \n-                commission_data.append({\n-                    \"restaurant_id\": str(restaurant.id),\n-                    \"restaurant_name\": restaurant.name,\n-                    \"gross_revenue\": float(gross_revenue),\n-                    \"commission_rate\": float(commission_rate),\n-                    \"commission_amount\": float(commission_amount),\n-                    \"net_revenue\": float(net_revenue),\n-                    \"order_count\": len(completed_orders)\n-                })\n-                \n+\n+                commission_data.append(\n+                    {\n+                        \"restaurant_id\": str(restaurant.id),\n+                        \"restaurant_name\": restaurant.name,\n+                        \"gross_revenue\": float(gross_revenue),\n+                        \"commission_rate\": float(commission_rate),\n+                        \"commission_amount\": float(commission_amount),\n+                        \"net_revenue\": float(net_revenue),\n+                        \"order_count\": len(completed_orders),\n+                    }\n+                )\n+\n                 total_platform_commission += commission_amount\n                 total_gross_revenue += gross_revenue\n-            \n+\n             return {\n                 \"period_days\": period_days,\n                 \"start_date\": start_date.isoformat(),\n                 \"end_date\": end_date.isoformat(),\n                 \"total_gross_revenue\": float(total_gross_revenue),\n                 \"total_platform_commission\": float(total_platform_commission),\n-                \"platform_commission_rate\": float(total_platform_commission / total_gross_revenue * 100) if total_gross_revenue > 0 else 0,\n-                \"restaurant_breakdown\": commission_data\n+                \"platform_commission_rate\": (\n+                    float(total_platform_commission / total_gross_revenue * 100)\n+                    if total_gross_revenue > 0\n+                    else 0\n+                ),\n+                \"restaurant_breakdown\": commission_data,\n             }\n-            \n+\n         except Exception as e:\n             raise FynloException(\n                 message=f\"Failed to calculate commission breakdown: {str(e)}\",\n                 error_code=ErrorCodes.INTERNAL_ERROR,\n-                status_code=500\n-            )\n-    \n+                status_code=500,\n+            )\n+\n     def validate_restaurant_switch(self, platform_id: str, restaurant_id: str) -> bool:\n         \"\"\"\n         Validate that restaurant belongs to platform\n         \"\"\"\n         try:\n-            restaurant = self.db.query(Restaurant).filter(\n-                and_(\n-                    Restaurant.id == restaurant_id,\n-                    Restaurant.platform_id == platform_id\n-                )\n-            ).first()\n-            \n+            restaurant = (\n+                self.db.query(Restaurant)\n+                .filter(\n+                    and_(\n+                        Restaurant.id == restaurant_id,\n+                        Restaurant.platform_id == platform_id,\n+                    )\n+                )\n+                .first()\n+            )\n+\n             return restaurant is not None\n-            \n+\n         except Exception:\n             return False\n-    \n-    def get_platform_activity_feed(self, platform_id: str, limit: int = 20) -> List[Dict[str, Any]]:\n+\n+    def get_platform_activity_feed(\n+        self, platform_id: str, limit: int = 20\n+    ) -> List[Dict[str, Any]]:\n         \"\"\"\n         Get recent activity across all restaurants in platform\n         \"\"\"\n         try:\n-            restaurants = self.db.query(Restaurant).filter(\n-                Restaurant.platform_id == platform_id\n-            ).all()\n-            \n+            restaurants = (\n+                self.db.query(Restaurant)\n+                .filter(Restaurant.platform_id == platform_id)\n+                .all()\n+            )\n+\n             restaurant_ids = [str(r.id) for r in restaurants]\n             restaurant_map = {str(r.id): r.name for r in restaurants}\n-            \n+\n             # Get recent orders\n-            recent_orders = self.db.query(Order).filter(\n-                Order.restaurant_id.in_(restaurant_ids)\n-            ).order_by(desc(Order.created_at)).limit(limit).all()\n-            \n+            recent_orders = (\n+                self.db.query(Order)\n+                .filter(Order.restaurant_id.in_(restaurant_ids))\n+                .order_by(desc(Order.created_at))\n+                .limit(limit)\n+                .all()\n+            )\n+\n             activity_feed = []\n-            \n+\n             for order in recent_orders:\n-                activity_feed.append({\n-                    \"id\": str(order.id),\n-                    \"type\": \"order\",\n-                    \"title\": f\"New order #{order.order_number}\",\n-                    \"description\": f\"Order placed at {restaurant_map.get(str(order.restaurant_id), 'Unknown')}\",\n-                    \"restaurant_id\": str(order.restaurant_id),\n-                    \"restaurant_name\": restaurant_map.get(str(order.restaurant_id), \"Unknown\"),\n-                    \"amount\": float(order.total_amount),\n-                    \"status\": order.status,\n-                    \"created_at\": order.created_at.isoformat(),\n-                    \"metadata\": {\n-                        \"order_number\": order.order_number,\n-                        \"items_count\": len(order.items) if order.items else 0,\n-                        \"table_number\": order.table_number\n+                activity_feed.append(\n+                    {\n+                        \"id\": str(order.id),\n+                        \"type\": \"order\",\n+                        \"title\": f\"New order #{order.order_number}\",\n+                        \"description\": f\"Order placed at {restaurant_map.get(str(order.restaurant_id), 'Unknown')}\",\n+                        \"restaurant_id\": str(order.restaurant_id),\n+                        \"restaurant_name\": restaurant_map.get(\n+                            str(order.restaurant_id), \"Unknown\"\n+                        ),\n+                        \"amount\": float(order.total_amount),\n+                        \"status\": order.status,\n+                        \"created_at\": order.created_at.isoformat(),\n+                        \"metadata\": {\n+                            \"order_number\": order.order_number,\n+                            \"items_count\": len(order.items) if order.items else 0,\n+                            \"table_number\": order.table_number,\n+                        },\n                     }\n-                })\n-            \n+                )\n+\n             return activity_feed\n-            \n+\n         except Exception as e:\n             raise FynloException(\n                 message=f\"Failed to get platform activity feed: {str(e)}\",\n                 error_code=ErrorCodes.INTERNAL_ERROR,\n-                status_code=500\n-            )\n-    \n+                status_code=500,\n+            )\n+\n     def get_restaurant_health_check(self, platform_id: str) -> Dict[str, Any]:\n         \"\"\"\n         Health check for all restaurants in platform\n         \"\"\"\n         try:\n-            restaurants = self.db.query(Restaurant).filter(\n-                Restaurant.platform_id == platform_id\n-            ).all()\n-            \n+            restaurants = (\n+                self.db.query(Restaurant)\n+                .filter(Restaurant.platform_id == platform_id)\n+                .all()\n+            )\n+\n             health_data = []\n-            \n+\n             for restaurant in restaurants:\n                 # Get recent activity (last 24 hours)\n                 yesterday = datetime.now() - timedelta(days=1)\n-                \n-                recent_orders = self.db.query(Order).filter(\n-                    and_(\n-                        Order.restaurant_id == restaurant.id,\n-                        Order.created_at >= yesterday\n-                    )\n-                ).count()\n-                \n+\n+                recent_orders = (\n+                    self.db.query(Order)\n+                    .filter(\n+                        and_(\n+                            Order.restaurant_id == restaurant.id,\n+                            Order.created_at >= yesterday,\n+                        )\n+                    )\n+                    .count()\n+                )\n+\n                 # Determine health status\n                 if not restaurant.is_active:\n                     health_status = \"inactive\"\n                 elif recent_orders == 0:\n                     health_status = \"warning\"  # No orders in 24h\n                 elif recent_orders < 5:\n-                    health_status = \"fair\"     # Low activity\n+                    health_status = \"fair\"  # Low activity\n                 else:\n                     health_status = \"healthy\"  # Good activity\n-                \n-                health_data.append({\n-                    \"restaurant_id\": str(restaurant.id),\n-                    \"restaurant_name\": restaurant.name,\n-                    \"health_status\": health_status,\n-                    \"is_active\": restaurant.is_active,\n-                    \"recent_orders_24h\": recent_orders,\n-                    \"last_updated\": restaurant.updated_at.isoformat() if restaurant.updated_at else restaurant.created_at.isoformat(),\n-                    \"recommendations\": self._get_health_recommendations(health_status, recent_orders)\n-                })\n-            \n+\n+                health_data.append(\n+                    {\n+                        \"restaurant_id\": str(restaurant.id),\n+                        \"restaurant_name\": restaurant.name,\n+                        \"health_status\": health_status,\n+                        \"is_active\": restaurant.is_active,\n+                        \"recent_orders_24h\": recent_orders,\n+                        \"last_updated\": (\n+                            restaurant.updated_at.isoformat()\n+                            if restaurant.updated_at\n+                            else restaurant.created_at.isoformat()\n+                        ),\n+                        \"recommendations\": self._get_health_recommendations(\n+                            health_status, recent_orders\n+                        ),\n+                    }\n+                )\n+\n             # Summary\n             total_restaurants = len(restaurants)\n-            healthy_count = sum(1 for r in health_data if r[\"health_status\"] == \"healthy\")\n-            warning_count = sum(1 for r in health_data if r[\"health_status\"] == \"warning\")\n-            \n+            healthy_count = sum(\n+                1 for r in health_data if r[\"health_status\"] == \"healthy\"\n+            )\n+            warning_count = sum(\n+                1 for r in health_data if r[\"health_status\"] == \"warning\"\n+            )\n+\n             return {\n                 \"platform_id\": platform_id,\n                 \"total_restaurants\": total_restaurants,\n                 \"healthy_restaurants\": healthy_count,\n                 \"warning_restaurants\": warning_count,\n-                \"overall_health_score\": round((healthy_count / total_restaurants * 100), 1) if total_restaurants > 0 else 0,\n+                \"overall_health_score\": (\n+                    round((healthy_count / total_restaurants * 100), 1)\n+                    if total_restaurants > 0\n+                    else 0\n+                ),\n                 \"restaurant_health\": health_data,\n-                \"checked_at\": datetime.now().isoformat()\n+                \"checked_at\": datetime.now().isoformat(),\n             }\n-            \n+\n         except Exception as e:\n             raise FynloException(\n                 message=f\"Failed to perform restaurant health check: {str(e)}\",\n                 error_code=ErrorCodes.INTERNAL_ERROR,\n-                status_code=500\n-            )\n-    \n-    def _get_health_recommendations(self, health_status: str, recent_orders: int) -> List[str]:\n+                status_code=500,\n+            )\n+\n+    def _get_health_recommendations(\n+        self, health_status: str, recent_orders: int\n+    ) -> List[str]:\n         \"\"\"\n         Get health recommendations based on status\n         \"\"\"\n         recommendations = []\n-        \n+\n         if health_status == \"inactive\":\n             recommendations.append(\"Restaurant is inactive - contact to reactivate\")\n         elif health_status == \"warning\":\n-            recommendations.append(\"No orders in 24 hours - check restaurant operations\")\n+            recommendations.append(\n+                \"No orders in 24 hours - check restaurant operations\"\n+            )\n             recommendations.append(\"Consider promotional campaigns\")\n         elif health_status == \"fair\":\n             recommendations.append(\"Low order volume - review menu pricing\")\n             recommendations.append(\"Check customer feedback\")\n-        \n+\n         return recommendations\n+\n \n # Singleton service factory\n def get_platform_service(db: Session) -> PlatformService:\n     \"\"\"Factory function to get platform service instance\"\"\"\n-    return PlatformService(db)\n\\ No newline at end of file\n+    return PlatformService(db)\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/security_monitor.py\t2025-08-02 21:56:58.996930+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/security_monitor.py\t2025-08-02 22:36:03.395074+00:00\n@@ -16,78 +16,77 @@\n logger = logging.getLogger(\"security\")\n \n \n class SecurityEventType(str, Enum):\n     \"\"\"Types of security events to monitor\"\"\"\n+\n     # Authentication events\n     LOGIN_SUCCESS = \"login_success\"\n     LOGIN_FAILED = \"login_failed\"\n     LOGOUT = \"logout\"\n     TOKEN_EXPIRED = \"token_expired\"\n     TOKEN_INVALID = \"token_invalid\"\n-    \n+\n     # Access control events\n     ACCESS_GRANTED = \"access_granted\"\n     ACCESS_DENIED = \"access_denied\"\n     CROSS_TENANT_ATTEMPT = \"cross_tenant_attempt\"\n     PRIVILEGE_ESCALATION_ATTEMPT = \"privilege_escalation_attempt\"\n-    \n+\n     # Rate limiting events\n     RATE_LIMIT_EXCEEDED = \"rate_limit_exceeded\"\n     IP_BANNED = \"ip_banned\"\n     DDOS_ATTEMPT = \"ddos_attempt\"\n-    \n+\n     # WebSocket events\n     WS_CONNECTION_ACCEPTED = \"ws_connection_accepted\"\n     WS_CONNECTION_REJECTED = \"ws_connection_rejected\"\n     WS_CROSS_TENANT_MESSAGE = \"ws_cross_tenant_message\"\n-    \n+\n     # Platform owner events\n     PLATFORM_OWNER_ACCESS = \"platform_owner_access\"\n     PLATFORM_OWNER_CROSS_TENANT = \"platform_owner_cross_tenant\"\n-    \n+\n     # Data modification events\n     SENSITIVE_DATA_ACCESS = \"sensitive_data_access\"\n     BULK_DATA_EXPORT = \"bulk_data_export\"\n     DATA_DELETION = \"data_deletion\"\n \n \n class SecurityMonitor:\n     \"\"\"\n     Central security monitoring and logging system\n     \"\"\"\n-    \n+\n     def __init__(self, redis_client: Optional[RedisClient] = None):\n         self.redis = redis_client\n-        \n+\n         # Configure security logger\n         self.security_logger = logging.getLogger(\"security.audit\")\n         handler = logging.FileHandler(\"security_audit.log\")\n         handler.setFormatter(\n-            logging.Formatter(\n-                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n-            )\n+            logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n         )\n         self.security_logger.addHandler(handler)\n         self.security_logger.setLevel(logging.INFO)\n-        \n+\n         # Alert thresholds\n         self.FAILED_LOGIN_THRESHOLD = 5  # Failed logins before alert\n         self.ACCESS_DENIED_THRESHOLD = 10  # Access denials before alert\n         self.RATE_LIMIT_THRESHOLD = 20  # Rate limit hits before alert\n-    \n+\n     async def log_event(\n         self,\n         event_type: SecurityEventType,\n         user_id: Optional[str] = None,\n         user_email: Optional[str] = None,\n         ip_address: Optional[str] = None,\n         restaurant_id: Optional[str] = None,\n         resource_type: Optional[str] = None,\n         resource_id: Optional[str] = None,\n         details: Optional[Dict[str, Any]] = None,\n-        severity: str = \"INFO\"\n+        severity: str = \"INFO\",\n     ):\n         \"\"\"\n         Log a security event with full context\n         \"\"\"\n         event = {\n@@ -98,64 +97,67 @@\n             \"user_email\": user_email,\n             \"ip_address\": ip_address,\n             \"restaurant_id\": restaurant_id,\n             \"resource_type\": resource_type,\n             \"resource_id\": resource_id,\n-            \"details\": details or {}\n+            \"details\": details or {},\n         }\n-        \n+\n         # Log to file\n-        self.security_logger.log(\n-            getattr(logging, severity),\n-            json.dumps(event)\n-        )\n-        \n+        self.security_logger.log(getattr(logging, severity), json.dumps(event))\n+\n         # Store in Redis for real-time monitoring\n         if self.redis:\n             try:\n                 # Store event\n                 event_key = f\"security:event:{datetime.utcnow().timestamp()}\"\n-                await self.redis.setex(event_key, 86400, json.dumps(event))  # 24 hour retention\n-                \n+                await self.redis.setex(\n+                    event_key, 86400, json.dumps(event)\n+                )  # 24 hour retention\n+\n                 # Update counters for alerting\n                 await self._update_security_counters(event_type, user_id, ip_address)\n-                \n+\n                 # Check for security alerts\n                 await self._check_security_alerts(event_type, user_id, ip_address)\n-                \n+\n             except Exception as e:\n                 logger.error(f\"Failed to store security event in Redis: {e}\")\n-        \n+\n         # Log to standard logger for immediate visibility\n         if severity in [\"WARNING\", \"ERROR\", \"CRITICAL\"]:\n             logger.warning(\n                 f\"SECURITY EVENT: {event_type.value} - \"\n                 f\"User: {user_email or user_id} - IP: {ip_address} - \"\n                 f\"Details: {details}\"\n             )\n-    \n+\n     async def log_access_attempt(\n         self,\n         user: User,\n         resource_type: str,\n         resource_id: str,\n         action: str,\n         granted: bool,\n         ip_address: str,\n-        reason: Optional[str] = None\n+        reason: Optional[str] = None,\n     ):\n         \"\"\"\n         Log an access control decision\n         \"\"\"\n-        event_type = SecurityEventType.ACCESS_GRANTED if granted else SecurityEventType.ACCESS_DENIED\n+        event_type = (\n+            SecurityEventType.ACCESS_GRANTED\n+            if granted\n+            else SecurityEventType.ACCESS_DENIED\n+        )\n         severity = \"INFO\" if granted else \"WARNING\"\n-        \n+\n         # Check if this is a cross-tenant attempt\n         if not granted and reason and \"restaurant\" in reason.lower():\n             event_type = SecurityEventType.CROSS_TENANT_ATTEMPT\n             severity = \"ERROR\"\n-        \n+\n         await self.log_event(\n             event_type=event_type,\n             user_id=str(user.id),\n             user_email=user.email,\n             ip_address=ip_address,\n@@ -164,127 +166,120 @@\n             resource_id=resource_id,\n             details={\n                 \"action\": action,\n                 \"reason\": reason,\n                 \"user_role\": user.role,\n-                \"granted\": granted\n+                \"granted\": granted,\n             },\n-            severity=severity\n-        )\n-    \n+            severity=severity,\n+        )\n+\n     async def log_platform_owner_access(\n         self,\n         user: User,\n         target_restaurant_id: str,\n         action: str,\n         resource_type: Optional[str] = None,\n-        details: Optional[Dict[str, Any]] = None\n+        details: Optional[Dict[str, Any]] = None,\n     ):\n         \"\"\"\n         Special logging for platform owner access to track their activities\n         \"\"\"\n         await self.log_event(\n             event_type=SecurityEventType.PLATFORM_OWNER_ACCESS,\n             user_id=str(user.id),\n             user_email=user.email,\n             restaurant_id=target_restaurant_id,\n             resource_type=resource_type,\n-            details={\n-                \"action\": action,\n-                \"platform_owner\": True,\n-                **(details or {})\n-            },\n-            severity=\"INFO\"\n-        )\n-    \n+            details={\"action\": action, \"platform_owner\": True, **(details or {})},\n+            severity=\"INFO\",\n+        )\n+\n     async def log_rate_limit_violation(\n         self,\n         ip_address: str,\n         user_id: Optional[str] = None,\n         limit_type: str = \"connection\",\n-        details: Optional[Dict[str, Any]] = None\n+        details: Optional[Dict[str, Any]] = None,\n     ):\n         \"\"\"\n         Log rate limiting violations\n         \"\"\"\n         await self.log_event(\n             event_type=SecurityEventType.RATE_LIMIT_EXCEEDED,\n             user_id=user_id,\n             ip_address=ip_address,\n-            details={\n-                \"limit_type\": limit_type,\n-                **(details or {})\n-            },\n-            severity=\"WARNING\"\n-        )\n-    \n+            details={\"limit_type\": limit_type, **(details or {})},\n+            severity=\"WARNING\",\n+        )\n+\n     async def _update_security_counters(\n         self,\n         event_type: SecurityEventType,\n         user_id: Optional[str],\n-        ip_address: Optional[str]\n+        ip_address: Optional[str],\n     ):\n         \"\"\"\n         Update security event counters for alerting\n         \"\"\"\n         if not self.redis:\n             return\n-        \n+\n         try:\n             # Track failed logins\n             if event_type == SecurityEventType.LOGIN_FAILED and ip_address:\n                 key = f\"security:failed_logins:{ip_address}\"\n                 await self.redis.incr(key)\n                 await self.redis.expire(key, 3600)  # Reset after 1 hour\n-            \n+\n             # Track access denials\n             elif event_type == SecurityEventType.ACCESS_DENIED and user_id:\n                 key = f\"security:access_denied:{user_id}\"\n                 await self.redis.incr(key)\n                 await self.redis.expire(key, 3600)\n-            \n+\n             # Track rate limit violations\n             elif event_type == SecurityEventType.RATE_LIMIT_EXCEEDED and ip_address:\n                 key = f\"security:rate_limits:{ip_address}\"\n                 await self.redis.incr(key)\n                 await self.redis.expire(key, 3600)\n-                \n+\n         except Exception as e:\n             logger.error(f\"Failed to update security counters: {e}\")\n-    \n+\n     async def _check_security_alerts(\n         self,\n         event_type: SecurityEventType,\n         user_id: Optional[str],\n-        ip_address: Optional[str]\n+        ip_address: Optional[str],\n     ):\n         \"\"\"\n         Check if security thresholds are exceeded and generate alerts\n         \"\"\"\n         if not self.redis:\n             return\n-        \n+\n         try:\n             # Check failed login threshold\n             if event_type == SecurityEventType.LOGIN_FAILED and ip_address:\n                 key = f\"security:failed_logins:{ip_address}\"\n                 count = await self.redis.get(key)\n                 if count and int(count) >= self.FAILED_LOGIN_THRESHOLD:\n                     logger.critical(\n                         f\"SECURITY ALERT: {count} failed login attempts from IP {ip_address}\"\n                     )\n                     # Could trigger additional actions like temporary IP ban\n-            \n+\n             # Check access denial threshold\n             elif event_type == SecurityEventType.ACCESS_DENIED and user_id:\n                 key = f\"security:access_denied:{user_id}\"\n                 count = await self.redis.get(key)\n                 if count and int(count) >= self.ACCESS_DENIED_THRESHOLD:\n                     logger.critical(\n                         f\"SECURITY ALERT: User {user_id} has {count} access denials\"\n                     )\n-            \n+\n             # Check rate limit threshold\n             elif event_type == SecurityEventType.RATE_LIMIT_EXCEEDED and ip_address:\n                 key = f\"security:rate_limits:{ip_address}\"\n                 count = await self.redis.get(key)\n                 if count and int(count) >= self.RATE_LIMIT_THRESHOLD:\n@@ -293,40 +288,37 @@\n                     )\n                     await self.log_event(\n                         event_type=SecurityEventType.DDOS_ATTEMPT,\n                         ip_address=ip_address,\n                         severity=\"CRITICAL\",\n-                        details={\"rate_limit_hits\": count}\n+                        details={\"rate_limit_hits\": count},\n                     )\n-                    \n+\n         except Exception as e:\n             logger.error(f\"Failed to check security alerts: {e}\")\n-    \n-    async def get_security_summary(\n-        self,\n-        time_window_hours: int = 24\n-    ) -> Dict[str, Any]:\n+\n+    async def get_security_summary(self, time_window_hours: int = 24) -> Dict[str, Any]:\n         \"\"\"\n         Get a summary of security events for monitoring dashboard\n         \"\"\"\n         if not self.redis:\n             return {\"error\": \"Redis not available\"}\n-        \n+\n         try:\n             # This would aggregate security events from Redis\n             # For now, return a placeholder\n             return {\n                 \"time_window_hours\": time_window_hours,\n                 \"total_events\": 0,\n                 \"failed_logins\": 0,\n                 \"access_denials\": 0,\n                 \"rate_limit_violations\": 0,\n                 \"cross_tenant_attempts\": 0,\n-                \"platform_owner_actions\": 0\n+                \"platform_owner_actions\": 0,\n             }\n         except Exception as e:\n             logger.error(f\"Failed to get security summary: {e}\")\n             return {\"error\": str(e)}\n \n \n # Global security monitor instance\n-security_monitor = SecurityMonitor()\n\\ No newline at end of file\n+security_monitor = SecurityMonitor()\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/validators.py\t2025-08-02 20:51:59.759016+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/validators.py\t2025-08-02 22:36:03.408957+00:00\n@@ -1,6 +1,7 @@\n \"\"\"Enhanced input validators for security.\"\"\"\n+\n import re\n from typing import Any, Optional\n from pydantic import validator\n from app.core.security_utils import sanitize_search_term, is_valid_uuid\n \n@@ -13,38 +14,42 @@\n     r\"(cast|convert|concat|substring|char|ascii)\\s*\\(\",  # SQL functions\n     r\"(waitfor|delay|sleep|benchmark)\\s\",  # Time-based attacks\n     r\"(or|and)\\s+\\d+\\s*=\\s*\\d+\",  # Boolean-based attacks like \"or 1=1\"\n ]\n \n-COMPILED_SQL_PATTERNS = [re.compile(pattern, re.IGNORECASE) for pattern in SQL_INJECTION_PATTERNS]\n+COMPILED_SQL_PATTERNS = [\n+    re.compile(pattern, re.IGNORECASE) for pattern in SQL_INJECTION_PATTERNS\n+]\n \n \n def validate_no_sql_injection(value: str, field_name: str = \"input\") -> str:\n     \"\"\"Validate that input doesn't contain SQL injection patterns.\"\"\"\n     if not value:\n         return value\n-    \n+\n     # Check for SQL injection patterns\n     for pattern in COMPILED_SQL_PATTERNS:\n         if pattern.search(value):\n-            raise ValueError(f\"{field_name} contains potentially malicious SQL patterns\")\n-    \n+            raise ValueError(\n+                f\"{field_name} contains potentially malicious SQL patterns\"\n+            )\n+\n     return value\n \n \n def validate_search_input(value: Optional[str]) -> Optional[str]:\n     \"\"\"Validate and sanitize search input.\"\"\"\n     if not value:\n         return value\n-    \n+\n     # Length check\n     if len(value) > 100:\n         raise ValueError(\"Search input too long (max 100 characters)\")\n-    \n+\n     # Check for SQL injection\n     validate_no_sql_injection(value, \"Search input\")\n-    \n+\n     # Sanitize\n     return sanitize_search_term(value)\n \n \n def validate_uuid_format(value: str) -> str:\n@@ -55,89 +60,89 @@\n \n \n def validate_sort_field(value: str, allowed_fields: list[str]) -> str:\n     \"\"\"Validate sort field against whitelist.\"\"\"\n     # Remove any direction suffix (e.g., \"name:asc\" -> \"name\")\n-    field = value.split(':')[0].strip()\n-    \n+    field = value.split(\":\")[0].strip()\n+\n     if field not in allowed_fields:\n-        raise ValueError(f\"Invalid sort field. Allowed fields: {', '.join(allowed_fields)}\")\n-    \n+        raise ValueError(\n+            f\"Invalid sort field. Allowed fields: {', '.join(allowed_fields)}\"\n+        )\n+\n     return value\n \n \n def validate_email_format(email: str) -> str:\n     \"\"\"Enhanced email validation.\"\"\"\n     if not email:\n         raise ValueError(\"Email cannot be empty\")\n-    \n+\n     # Basic email pattern\n-    email_pattern = re.compile(\n-        r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n-    )\n-    \n+    email_pattern = re.compile(r\"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\")\n+\n     if not email_pattern.match(email):\n         raise ValueError(\"Invalid email format\")\n-    \n+\n     # Check for SQL injection in email\n     validate_no_sql_injection(email, \"Email\")\n-    \n+\n     return email.lower()\n \n \n def validate_phone_format(phone: str) -> str:\n     \"\"\"Enhanced phone validation.\"\"\"\n     if not phone:\n         return phone\n-    \n+\n     # Remove common formatting characters\n-    cleaned = re.sub(r'[\\s\\-\\(\\)\\+\\.]', '', phone)\n-    \n+    cleaned = re.sub(r\"[\\s\\-\\(\\)\\+\\.]\", \"\", phone)\n+\n     # Check if it's all digits after cleaning\n     if not cleaned.isdigit():\n         raise ValueError(\"Phone number contains invalid characters\")\n-    \n+\n     # Length check\n     if len(cleaned) < 7 or len(cleaned) > 15:\n         raise ValueError(\"Phone number length invalid (7-15 digits)\")\n-    \n+\n     return phone\n \n \n def validate_name_field(name: str, field_name: str = \"Name\") -> str:\n     \"\"\"Validate name fields (first name, last name, etc).\"\"\"\n     if not name:\n         return name\n-    \n+\n     # Length check\n     if len(name) > 50:\n         raise ValueError(f\"{field_name} too long (max 50 characters)\")\n-    \n+\n     # Allow only letters, spaces, hyphens, and apostrophes\n     name_pattern = re.compile(r\"^[a-zA-Z\\s\\-']+$\")\n     if not name_pattern.match(name):\n         raise ValueError(f\"{field_name} contains invalid characters\")\n-    \n+\n     # Check for SQL injection\n     validate_no_sql_injection(name, field_name)\n-    \n+\n     return name.strip()\n \n \n def validate_alphanumeric(value: str, field_name: str = \"Field\") -> str:\n     \"\"\"Validate alphanumeric input with limited special characters.\"\"\"\n     if not value:\n         return value\n-    \n+\n     # Allow alphanumeric, spaces, and basic punctuation\n-    pattern = re.compile(r'^[a-zA-Z0-9\\s\\-_\\.]+$')\n+    pattern = re.compile(r\"^[a-zA-Z0-9\\s\\-_\\.]+$\")\n     if not pattern.match(value):\n         raise ValueError(f\"{field_name} contains invalid characters\")\n-    \n+\n     # Check for SQL injection\n     validate_no_sql_injection(value, field_name)\n-    \n+\n     return value\n \n \n def validate_numeric_id(value: Any) -> int:\n     \"\"\"Validate numeric ID.\"\"\"\n@@ -162,46 +167,46 @@\n         raise ValueError(\"Invalid amount format\")\n \n \n # Pydantic field validators for common use cases\n class SearchValidator:\n-    @validator('search', 'query', 'q', pre=True, always=True)\n+    @validator(\"search\", \"query\", \"q\", pre=True, always=True)\n     def validate_search(cls, v):\n         return validate_search_input(v)\n \n \n class UUIDValidator:\n-    @validator('id', 'user_id', 'restaurant_id', 'order_id', 'customer_id', pre=True)\n+    @validator(\"id\", \"user_id\", \"restaurant_id\", \"order_id\", \"customer_id\", pre=True)\n     def validate_ids(cls, v):\n         if v:\n             return validate_uuid_format(v)\n         return v\n \n \n class EmailValidator:\n-    @validator('email', pre=True)\n+    @validator(\"email\", pre=True)\n     def validate_email_field(cls, v):\n         if v:\n             return validate_email_format(v)\n         return v\n \n \n class PhoneValidator:\n-    @validator('phone', 'phone_number', pre=True)\n+    @validator(\"phone\", \"phone_number\", pre=True)\n     def validate_phone_field(cls, v):\n         if v:\n             return validate_phone_format(v)\n         return v\n \n \n class NameValidator:\n-    @validator('first_name', pre=True)\n+    @validator(\"first_name\", pre=True)\n     def validate_first_name_field(cls, v):\n         if v:\n             return validate_name_field(v, \"First name\")\n         return v\n-    \n-    @validator('last_name', pre=True)\n+\n+    @validator(\"last_name\", pre=True)\n     def validate_last_name_field(cls, v):\n         if v:\n             return validate_name_field(v, \"Last name\")\n-        return v\n\\ No newline at end of file\n+        return v\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/redis_client.py\t2025-08-02 14:10:21.488956+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/redis_client.py\t2025-08-02 22:36:03.407420+00:00\n@@ -14,22 +14,23 @@\n \n from app.core.config import settings\n \n logger = logging.getLogger(__name__)\n \n+\n class RedisClient:\n     \"\"\"Redis client wrapper with circuit breaker pattern\"\"\"\n \n     def __init__(self):\n         self.pool: Optional[ConnectionPool] = None\n         self.redis: Optional[aioredis.Redis] = None\n-        self._mock_storage = {} # For fallback\n+        self._mock_storage = {}  # For fallback\n         self._is_connected = False  # Track if we've attempted connection\n         self._last_health_check = 0\n         self._health_check_interval = 5  # seconds\n         self._is_healthy = False\n-        \n+\n         # Circuit breaker state\n         self._circuit_state = \"closed\"  # closed, open, half-open\n         self._failure_count = 0\n         self._failure_threshold = 5  # failures before opening circuit\n         self._success_threshold = 2  # successes before closing circuit\n@@ -41,45 +42,48 @@\n         \"\"\"Connect to Redis\"\"\"\n         if not self.redis and not self._is_connected:\n             self._is_connected = True  # Mark that we've attempted connection\n             try:\n                 logger.info(f\"Attempting to connect to Redis at {settings.REDIS_URL}\")\n-                self.pool = ConnectionPool.from_url(settings.REDIS_URL, decode_responses=True, max_connections=20)\n+                self.pool = ConnectionPool.from_url(\n+                    settings.REDIS_URL, decode_responses=True, max_connections=20\n+                )\n                 self.redis = aioredis.Redis(connection_pool=self.pool)\n                 await self.redis.ping()\n                 logger.info(\"\u2705 Redis connected successfully.\")\n                 # Clear mock storage if real connection is successful\n                 self._mock_storage = {}\n                 self._is_healthy = True\n             except Exception as e:\n                 logger.error(f\"\u274c Failed to connect to Redis: {e}\")\n                 self.redis = None  # Ensure redis is None if connection failed\n                 self._is_healthy = False\n-                \n+\n                 # Only allow mock storage in development/testing environments\n                 if settings.ENVIRONMENT in [\"development\", \"testing\", \"local\"]:\n-                    logger.warning(\"\u26a0\ufe0f Redis connection failed. Using in-memory storage (DEV MODE ONLY).\")\n+                    logger.warning(\n+                        \"\u26a0\ufe0f Redis connection failed. Using in-memory storage (DEV MODE ONLY).\"\n+                    )\n                     # _mock_storage is already initialized as {} which indicates mock mode is active\n                 else:\n                     # In production, fail closed - don't allow bypass\n                     raise ServiceUnavailableError(\n                         message=\"Cache service is currently unavailable. Please try again later.\",\n                         service_name=\"Redis\",\n                         retry_after=30,\n-                        details={\"reason\": \"Redis connection failed\", \"error\": str(e)}\n+                        details={\"reason\": \"Redis connection failed\", \"error\": str(e)},\n                     )\n-\n \n     async def disconnect(self):\n         \"\"\"Disconnect from Redis\"\"\"\n-        if self.redis and hasattr(self.redis, 'close'):\n+        if self.redis and hasattr(self.redis, \"close\"):\n             try:\n                 await self.redis.close()\n                 logger.info(\"Redis client closed.\")\n             except Exception as e:\n                 logger.error(f\"Error closing Redis client: {e}\")\n-        if self.pool and hasattr(self.pool, 'disconnect'):\n+        if self.pool and hasattr(self.pool, \"disconnect\"):\n             try:\n                 await self.pool.disconnect()\n                 logger.info(\"Redis connection pool disconnected.\")\n             except Exception as e:\n                 logger.error(f\"Error disconnecting Redis connection pool: {e}\")\n@@ -87,23 +91,25 @@\n         self.pool = None\n         self._is_healthy = False\n \n     async def set(self, key: str, value: Any, expire: Optional[int] = None) -> bool:\n         \"\"\"Set a value in Redis\"\"\"\n-        if not self.redis: # Mock fallback\n-            if isinstance(value, (dict, list, tuple)): # Handle tuples as well\n+        if not self.redis:  # Mock fallback\n+            if isinstance(value, (dict, list, tuple)):  # Handle tuples as well\n                 value = json.dumps(value)\n-            self._mock_storage[key] = str(value) # Store as string for consistency\n+            self._mock_storage[key] = str(value)  # Store as string for consistency\n             # Mock doesn't handle expire well, but log it\n             if expire:\n-                logger.debug(f\"Mock Redis: SET {key} with expire {expire} (not implemented in mock)\")\n+                logger.debug(\n+                    f\"Mock Redis: SET {key} with expire {expire} (not implemented in mock)\"\n+                )\n             return True\n \n         if isinstance(value, (dict, list, tuple)):\n             value_to_set = json.dumps(value)\n         else:\n-            value_to_set = str(value) # Ensure value is string if not complex type\n+            value_to_set = str(value)  # Ensure value is string if not complex type\n \n         try:\n             await self.redis.set(key, value_to_set, ex=expire)\n             self._on_success()\n             return True\n@@ -112,18 +118,18 @@\n             self._on_failure()\n             return False\n \n     async def get(self, key: str) -> Optional[Any]:\n         \"\"\"Get a value from Redis\"\"\"\n-        if not self.redis: # Mock fallback\n+        if not self.redis:  # Mock fallback\n             value = self._mock_storage.get(key)\n             if value is None:\n                 return None\n             try:\n-                return json.loads(value) # Try to parse as JSON\n+                return json.loads(value)  # Try to parse as JSON\n             except (json.JSONDecodeError, TypeError):\n-                return value # Return as is if not JSON or if already primitive\n+                return value  # Return as is if not JSON or if already primitive\n \n         try:\n             value = await self.redis.get(key)\n             self._on_success()\n             if value is None:\n@@ -138,11 +144,11 @@\n             self._on_failure()\n             return None\n \n     async def delete(self, key: str) -> bool:\n         \"\"\"Delete a key from Redis\"\"\"\n-        if not self.redis: # Mock fallback\n+        if not self.redis:  # Mock fallback\n             if key in self._mock_storage:\n                 del self._mock_storage[key]\n                 return True\n             return False\n         try:\n@@ -152,48 +158,59 @@\n             logger.error(f\"Error deleting key {key} from Redis: {e}\")\n             return False\n \n     async def delete_pattern(self, pattern: str) -> int:\n         \"\"\"Delete all keys matching a pattern\"\"\"\n-        if not self.redis: # Mock fallback\n+        if not self.redis:  # Mock fallback\n             import fnmatch\n-            keys_to_delete = [k for k in self._mock_storage.keys() if fnmatch.fnmatch(k, pattern)]\n+\n+            keys_to_delete = [\n+                k for k in self._mock_storage.keys() if fnmatch.fnmatch(k, pattern)\n+            ]\n             for key_to_del in keys_to_delete:\n                 del self._mock_storage[key_to_del]\n-            logger.info(f\"Mock deleted {len(keys_to_delete)} keys matching pattern: {pattern}\")\n+            logger.info(\n+                f\"Mock deleted {len(keys_to_delete)} keys matching pattern: {pattern}\"\n+            )\n             return len(keys_to_delete)\n \n         keys_deleted_count = 0\n         # Use a cursor for potentially large number of keys\n-        async for key_batch in self.redis.scan_iter(match=pattern, count=100): # Process in batches\n-            if key_batch: # redis-py scan_iter might yield empty lists\n-                 # delete can take multiple keys\n-                num = await self.redis.delete(*key_batch if isinstance(key_batch, list) else [key_batch])\n+        async for key_batch in self.redis.scan_iter(\n+            match=pattern, count=100\n+        ):  # Process in batches\n+            if key_batch:  # redis-py scan_iter might yield empty lists\n+                # delete can take multiple keys\n+                num = await self.redis.delete(\n+                    *key_batch if isinstance(key_batch, list) else [key_batch]\n+                )\n                 keys_deleted_count += num\n         logger.info(f\"Deleted {keys_deleted_count} keys matching pattern: {pattern}\")\n         return keys_deleted_count\n \n     async def exists(self, key: str) -> bool:\n         \"\"\"Check if key exists\"\"\"\n-        if not self.redis: # Mock fallback\n-             return key in self._mock_storage\n-        try:\n-            return bool(await self.redis.exists(key)) # Ensure boolean return\n+        if not self.redis:  # Mock fallback\n+            return key in self._mock_storage\n+        try:\n+            return bool(await self.redis.exists(key))  # Ensure boolean return\n         except Exception as e:\n             logger.error(f\"Error checking existence of key {key} in Redis: {e}\")\n             return False\n \n     # --- Methods for specific application logic ---\n     async def set_session(self, session_id: str, data: dict, expire: int = 3600):\n         \"\"\"Set session data - critical operation that must not fail silently\"\"\"\n         self._require_redis(\"session management\")\n         success = await self.set(f\"session:{session_id}\", data, expire)\n-        if not success and settings.ENVIRONMENT not in [\"development\", \"testing\", \"local\"]:\n+        if not success and settings.ENVIRONMENT not in [\n+            \"development\",\n+            \"testing\",\n+            \"local\",\n+        ]:\n             raise ServiceUnavailableError(\n-                message=\"Failed to create session\",\n-                service_name=\"Redis\",\n-                retry_after=30\n+                message=\"Failed to create session\", service_name=\"Redis\", retry_after=30\n             )\n         return success\n \n     async def get_session(self, session_id: str) -> Optional[dict]:\n         \"\"\"Get session data - returns None if not found or Redis unavailable in dev\"\"\"\n@@ -202,12 +219,18 @@\n \n     async def delete_session(self, session_id: str):\n         \"\"\"Delete session - critical for security\"\"\"\n         self._require_redis(\"session deletion\")\n         success = await self.delete(f\"session:{session_id}\")\n-        if not success and settings.ENVIRONMENT not in [\"development\", \"testing\", \"local\"]:\n-            logger.error(f\"Failed to delete session {session_id} - potential security risk\")\n+        if not success and settings.ENVIRONMENT not in [\n+            \"development\",\n+            \"testing\",\n+            \"local\",\n+        ]:\n+            logger.error(\n+                f\"Failed to delete session {session_id} - potential security risk\"\n+            )\n \n     async def cache_menu(self, restaurant_id: str, menu_data: dict, expire: int = 300):\n         await self.set(f\"menu:{restaurant_id}\", menu_data, expire)\n \n     async def get_cached_menu(self, restaurant_id: str) -> Optional[dict]:\n@@ -219,27 +242,33 @@\n     async def get_cached_order(self, order_id: str) -> Optional[dict]:\n         return await self.get(f\"order:{order_id}\")\n \n     async def invalidate_restaurant_cache(self, restaurant_id: str) -> int:\n         patterns = [\n-            f\"products:{restaurant_id}:*\", f\"categories:{restaurant_id}:*\",\n-            f\"menu:{restaurant_id}:*\", f\"orders:{restaurant_id}:*\"\n+            f\"products:{restaurant_id}:*\",\n+            f\"categories:{restaurant_id}:*\",\n+            f\"menu:{restaurant_id}:*\",\n+            f\"orders:{restaurant_id}:*\",\n         ]\n         total_deleted = sum(await self.delete_pattern(p) for p in patterns)\n-        logger.info(f\"Invalidated {total_deleted} cache keys for restaurant {restaurant_id}\")\n+        logger.info(\n+            f\"Invalidated {total_deleted} cache keys for restaurant {restaurant_id}\"\n+        )\n         return total_deleted\n \n     async def invalidate_product_cache(self, restaurant_id: str) -> int:\n         patterns = [f\"products:{restaurant_id}:*\", f\"menu:{restaurant_id}:*\"]\n         total_deleted = sum(await self.delete_pattern(p) for p in patterns)\n-        logger.info(f\"Invalidated {total_deleted} product cache keys for restaurant {restaurant_id}\")\n+        logger.info(\n+            f\"Invalidated {total_deleted} product cache keys for restaurant {restaurant_id}\"\n+        )\n         return total_deleted\n \n     # --- Methods required by fastapi-limiter ---\n     async def incr(self, key: str) -> int:\n         \"\"\"Increment a key in Redis. Required by fastapi-limiter.\"\"\"\n-        if not self.redis: # Mock fallback\n+        if not self.redis:  # Mock fallback\n             if settings.ENVIRONMENT in [\"development\", \"testing\", \"local\"]:\n                 current_value = self._mock_storage.get(key, \"0\")\n                 new_value = int(current_value) + 1\n                 self._mock_storage[key] = str(new_value)\n                 return new_value\n@@ -266,36 +295,38 @@\n                 self._mock_storage[key] = str(new_value)\n                 return new_value\n \n     async def expire(self, key: str, timeout: int):\n         \"\"\"Set an expire on a key. Required by fastapi-limiter.\"\"\"\n-        if not self.redis: # Mock fallback\n-            logger.debug(f\"Mock Redis: EXPIRE {key} {timeout} (not implemented in mock)\")\n+        if not self.redis:  # Mock fallback\n+            logger.debug(\n+                f\"Mock Redis: EXPIRE {key} {timeout} (not implemented in mock)\"\n+            )\n             return\n         try:\n             await self.redis.expire(key, timeout)\n         except Exception as e:\n             logger.error(f\"Error setting expire for key {key} in Redis: {e}\")\n \n     async def is_healthy(self) -> bool:\n         \"\"\"Check if Redis connection is healthy\"\"\"\n         if not self.redis:\n             return False\n-            \n+\n         # Check circuit breaker state\n         if self._circuit_state == \"open\":\n             if time.time() - self._circuit_open_time > self._circuit_timeout:\n                 logger.info(\"Circuit breaker timeout reached, trying half-open state\")\n                 self._circuit_state = \"half-open\"\n             else:\n                 return False\n-            \n+\n         # Rate limit health checks\n         current_time = time.time()\n         if current_time - self._last_health_check < self._health_check_interval:\n             return self._is_healthy\n-            \n+\n         try:\n             await self.redis.ping()\n             self._is_healthy = True\n             self._last_health_check = current_time\n             self._on_success()\n@@ -304,11 +335,11 @@\n             logger.warning(f\"Redis health check failed: {e}\")\n             self._is_healthy = False\n             self._last_health_check = current_time\n             self._on_failure()\n             return False\n-    \n+\n     def _on_success(self):\n         \"\"\"Handle successful Redis operation\"\"\"\n         if self._circuit_state == \"half-open\":\n             self._consecutive_successes += 1\n             if self._consecutive_successes >= self._success_threshold:\n@@ -316,77 +347,104 @@\n                 self._circuit_state = \"closed\"\n                 self._failure_count = 0\n                 self._consecutive_successes = 0\n         elif self._circuit_state == \"closed\":\n             self._failure_count = 0\n-    \n+\n     def _on_failure(self):\n         \"\"\"Handle failed Redis operation\"\"\"\n         self._consecutive_successes = 0\n         self._failure_count += 1\n-        \n+\n         if self._circuit_state == \"half-open\":\n             logger.warning(\"Circuit breaker reopening after failure in half-open state\")\n             self._circuit_state = \"open\"\n             self._circuit_open_time = time.time()\n-        elif self._circuit_state == \"closed\" and self._failure_count >= self._failure_threshold:\n-            logger.error(f\"Circuit breaker opening after {self._failure_count} failures\")\n+        elif (\n+            self._circuit_state == \"closed\"\n+            and self._failure_count >= self._failure_threshold\n+        ):\n+            logger.error(\n+                f\"Circuit breaker opening after {self._failure_count} failures\"\n+            )\n             self._circuit_state = \"open\"\n             self._circuit_open_time = time.time()\n \n     def _require_redis(self, operation: str = \"operation\"):\n         \"\"\"Ensure Redis is available or raise exception in production\"\"\"\n         # Check circuit breaker first\n-        if self._circuit_state == \"open\" and settings.ENVIRONMENT not in [\"development\", \"testing\", \"local\"]:\n-            time_until_retry = int(self._circuit_timeout - (time.time() - self._circuit_open_time))\n+        if self._circuit_state == \"open\" and settings.ENVIRONMENT not in [\n+            \"development\",\n+            \"testing\",\n+            \"local\",\n+        ]:\n+            time_until_retry = int(\n+                self._circuit_timeout - (time.time() - self._circuit_open_time)\n+            )\n             raise ServiceUnavailableError(\n                 message=f\"Service temporarily unavailable due to repeated failures\",\n                 service_name=\"Redis\",\n                 retry_after=max(1, time_until_retry),\n-                details={\"circuit_state\": \"open\", \"operation\": operation}\n-            )\n-            \n-        if not self.redis and settings.ENVIRONMENT not in [\"development\", \"testing\", \"local\"]:\n+                details={\"circuit_state\": \"open\", \"operation\": operation},\n+            )\n+\n+        if not self.redis and settings.ENVIRONMENT not in [\n+            \"development\",\n+            \"testing\",\n+            \"local\",\n+        ]:\n             raise ServiceUnavailableError(\n                 message=f\"Cannot perform {operation}: Cache service unavailable\",\n                 service_name=\"Redis\",\n-                retry_after=30\n+                retry_after=30,\n             )\n \n     def get_client(self) -> Optional[aioredis.Redis]:\n         \"\"\"\n         Returns the raw aioredis.Redis client instance.\n         Useful for fastapi-limiter or other libraries that need direct access.\n         \"\"\"\n-        if not self.redis and settings.ENVIRONMENT in [\"development\", \"testing\", \"local\"]:\n-            logger.warning(\"FastAPI-Limiter might be using a mock RedisClient instance (self).\")\n+        if not self.redis and settings.ENVIRONMENT in [\n+            \"development\",\n+            \"testing\",\n+            \"local\",\n+        ]:\n+            logger.warning(\n+                \"FastAPI-Limiter might be using a mock RedisClient instance (self).\"\n+            )\n             # This is a tricky part for mock compatibility with fastapi-limiter.\n             # fastapi-limiter expects an object with specific async methods (incr, expire).\n             # The mock fallback in this class implements these.\n-            return self # type: ignore\n+            return self  # type: ignore\n         return self.redis\n \n \n # Global Redis client instance\n redis_client = RedisClient()\n+\n \n async def init_redis():\n     \"\"\"Initialize Redis connection and prepare for fastapi-limiter.\"\"\"\n     await redis_client.connect()\n     # No explicit init for fastapi-limiter here; it will call redis_client.get_client()\n \n+\n async def close_redis():\n     \"\"\"Close Redis connection.\"\"\"\n     await redis_client.disconnect()\n+\n \n async def get_redis() -> RedisClient:\n     \"\"\"Get Redis client instance, ensuring it's connected.\"\"\"\n     # If we haven't attempted connection yet\n     if not redis_client._is_connected:\n-        logger.info(\"Redis client accessed before initial connect, attempting to connect.\")\n+        logger.info(\n+            \"Redis client accessed before initial connect, attempting to connect.\"\n+        )\n         await redis_client.connect()\n     return redis_client\n+\n \n async def get_redis_health() -> dict:\n     \"\"\"Get Redis health status for monitoring\"\"\"\n     try:\n         is_healthy = await redis_client.is_healthy()\n@@ -395,15 +453,15 @@\n             \"status\": \"healthy\" if is_healthy else \"unhealthy\",\n             \"connected\": redis_client.redis is not None,\n             \"circuit_state\": redis_client._circuit_state,\n             \"failure_count\": redis_client._failure_count,\n             \"is_mock\": redis_client.redis is None and bool(redis_client._mock_storage),\n-            \"environment\": settings.ENVIRONMENT\n+            \"environment\": settings.ENVIRONMENT,\n         }\n     except Exception as e:\n         logger.error(f\"Error checking Redis health: {e}\")\n         return {\n             \"service\": \"redis\",\n             \"status\": \"error\",\n             \"error\": str(e),\n-            \"environment\": settings.ENVIRONMENT\n-        }\n\\ No newline at end of file\n+            \"environment\": settings.ENVIRONMENT,\n+        }\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/tenant_security.py\t2025-08-02 22:06:47.593664+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/tenant_security.py\t2025-08-02 22:36:03.404190+00:00\n@@ -12,51 +12,55 @@\n from sqlalchemy import select, func\n from app.models import User, Restaurant, UserRestaurant\n from app.core.security_monitor import security_monitor, SecurityEventType\n from app.core.config import settings\n from app.core.validators import validate_uuid_format\n-from app.core.exceptions import FynloException, ValidationException, AuthorizationException\n+from app.core.exceptions import (\n+    FynloException,\n+    ValidationException,\n+    AuthorizationException,\n+)\n \n \n class TenantSecurity:\n     \"\"\"Handles multi-tenant data isolation and access control\"\"\"\n-    \n+\n     @staticmethod\n     def is_platform_owner(user: User) -> bool:\n         \"\"\"\n         Check if user is a platform owner (Ryan or Arnaud)\n         Platform owners have full access to all data\n         \"\"\"\n         if not user:\n             return False\n-            \n+\n         # Check by role AND email for extra security\n         is_owner_role = user.role == \"platform_owner\"\n         is_owner_email = user.email.lower() in settings.platform_owner_emails_list\n-        \n+\n         # Both conditions must be true for platform owner access\n         return is_owner_role and is_owner_email\n-    \n+\n     @staticmethod\n     async def validate_restaurant_access(\n         user: User,\n         restaurant_id: str,\n         operation: str = \"access\",\n         resource_type: Optional[str] = None,\n         resource_id: Optional[str] = None,\n         request: Optional[Request] = None,\n-        db: Optional[Session] = None\n+        db: Optional[Session] = None,\n     ) -> None:\n         \"\"\"\n         Validate if user can access a specific restaurant's data\n-        \n+\n         Args:\n             user: Current user\n             restaurant_id: Restaurant ID to access\n             operation: Type of operation (access, modify, delete)\n             db: Database session (required for multi-restaurant check)\n-            \n+\n         Raises:\n             FynloException: If access is denied\n         \"\"\"\n         # Validate restaurant_id format to prevent SQL injection\n         try:\n@@ -65,38 +69,42 @@\n             raise ValidationException(message=\"Invalid restaurant ID format\")\n         # Get client IP for logging\n         client_ip = None\n         if request:\n             client_ip = request.client.host if request.client else \"unknown\"\n-        \n+\n         # Platform owners (Ryan and Arnaud) can access everything\n         if TenantSecurity.is_platform_owner(user):\n             # Log platform owner access for audit trail\n             await security_monitor.log_platform_owner_access(\n                 user=user,\n                 target_restaurant_id=restaurant_id,\n                 action=operation,\n                 resource_type=resource_type,\n-                details={\"resource_id\": resource_id} if resource_id else None\n+                details={\"resource_id\": resource_id} if resource_id else None,\n             )\n             return  # Full access granted\n-        \n+\n         # Check if user has access to this restaurant (multi-restaurant support)\n         has_access = False\n-        \n+\n         # First check legacy single restaurant assignment\n         if user.restaurant_id and str(user.restaurant_id) == str(restaurant_id):\n             has_access = True\n-        \n+\n         # Then check multi-restaurant access for restaurant owners\n         elif db and user.role == \"restaurant_owner\":\n             # Check if user has access through user_restaurants table\n-            user_restaurant = db.query(UserRestaurant).filter(\n-                UserRestaurant.user_id == user.id,\n-                UserRestaurant.restaurant_id == restaurant_id\n-            ).first()\n-            \n+            user_restaurant = (\n+                db.query(UserRestaurant)\n+                .filter(\n+                    UserRestaurant.user_id == user.id,\n+                    UserRestaurant.restaurant_id == restaurant_id,\n+                )\n+                .first()\n+            )\n+\n             if user_restaurant:\n                 has_access = True\n                 # Update current restaurant context if different\n                 if user.current_restaurant_id != restaurant_id:\n                     try:\n@@ -110,39 +118,40 @@\n                             user=user,\n                             event_type=SecurityEventType.ERROR,\n                             details={\n                                 \"error\": \"Failed to update current restaurant context\",\n                                 \"restaurant_id\": restaurant_id,\n-                                \"exception\": str(e)\n-                            }\n+                                \"exception\": str(e),\n+                            },\n                         )\n-        \n+\n         if not has_access:\n             # Log access denial\n             reason = \"User has no access to this restaurant\"\n             if not user.restaurant_id and (not db or user.role != \"restaurant_owner\"):\n                 reason = \"User has no restaurant assigned\"\n-            \n+\n             await security_monitor.log_access_attempt(\n                 user=user,\n                 resource_type=resource_type or \"restaurant\",\n                 resource_id=restaurant_id,\n                 action=operation,\n                 granted=False,\n                 ip_address=client_ip or \"unknown\",\n-                reason=reason\n-            )\n-            raise AuthorizationException(message=f\"Access denied: You don't have permission to {operation} data from this restaurant\")\n-            \n-    \n+                reason=reason,\n+            )\n+            raise AuthorizationException(\n+                message=f\"Access denied: You don't have permission to {operation} data from this restaurant\"\n+            )\n+\n     @staticmethod\n     def apply_tenant_filter(\n         query: Query,\n         user: User,\n         model_class: type,\n         restaurant_field: str = \"restaurant_id\",\n-        db: Optional[Session] = None\n+        db: Optional[Session] = None,\n     ) -> Query:\n         \"\"\"Execute apply_tenant_filter operation.\"\"\"\n         \"\"\"\n         Apply tenant filtering to a SQLAlchemy query\n         \n@@ -157,67 +166,69 @@\n             Filtered query\n         \"\"\"\n         # Platform owners see everything\n         if TenantSecurity.is_platform_owner(user):\n             return query\n-        \n+\n         # Get accessible restaurant IDs\n         accessible_restaurants = TenantSecurity.get_accessible_restaurant_ids(user, db)\n-        \n+\n         if not accessible_restaurants:\n             # Return empty result for users without restaurant access\n             return query.filter(False)\n-        \n+\n         # Filter by accessible restaurants\n         filter_field = getattr(model_class, restaurant_field)\n-        \n+\n         # If only one restaurant, use simple equality\n         if len(accessible_restaurants) == 1:\n             return query.filter(filter_field == accessible_restaurants[0])\n-        \n+\n         # Multiple restaurants - use IN clause\n         return query.filter(filter_field.in_(accessible_restaurants))\n-    \n-    @staticmethod\n-    def get_accessible_restaurant_ids(user: User, db: Optional[Session] = None) -> List[str]:\n+\n+    @staticmethod\n+    def get_accessible_restaurant_ids(\n+        user: User, db: Optional[Session] = None\n+    ) -> List[str]:\n         \"\"\"\n         Get list of restaurant IDs accessible by user\n-        \n+\n         Returns:\n             List of restaurant IDs user can access\n         \"\"\"\n         # Platform owners can access all restaurants\n         if TenantSecurity.is_platform_owner(user):\n             return []  # Empty list means \"all restaurants\"\n-        \n+\n         # Use a set for efficient deduplication\n         accessible_restaurants = set()\n-        \n+\n         # For restaurant owners, check user_restaurants table\n         if db and user.role == \"restaurant_owner\":\n             # Get all restaurants from user_restaurants table\n-            user_restaurants = db.query(UserRestaurant).filter(\n-                UserRestaurant.user_id == user.id\n-            ).all()\n-            \n+            user_restaurants = (\n+                db.query(UserRestaurant).filter(UserRestaurant.user_id == user.id).all()\n+            )\n+\n             for ur in user_restaurants:\n                 accessible_restaurants.add(str(ur.restaurant_id))\n-        \n+\n         # For non-restaurant owners, only add legacy restaurant_id if it exists\n         # This ensures that if a restaurant owner's access is revoked via user_restaurants,\n         # they don't retain access through the legacy field\n         elif user.restaurant_id:\n             accessible_restaurants.add(str(user.restaurant_id))\n-        \n+\n         return list(accessible_restaurants)\n-    \n+\n     @staticmethod\n     def validate_cross_restaurant_operation(\n         user: User,\n         source_restaurant_id: str,\n         target_restaurant_id: str,\n-        operation: str = \"transfer\"\n+        operation: str = \"transfer\",\n     ) -> None:\n         \"\"\"Execute validate_cross_restaurant_operation operation.\"\"\"\n         \"\"\"\n         Validate operations that involve multiple restaurants\n         \n@@ -230,36 +241,37 @@\n         Raises:\n             FynloException: If operation is not allowed\n         \"\"\"\n         # Only platform owners can perform cross-restaurant operations\n         if not TenantSecurity.is_platform_owner(user):\n-            raise AuthorizationException(message=f\"Access denied: Only platform owners can {operation} data between restaurants\")\n-            \n-    \n+            raise AuthorizationException(\n+                message=f\"Access denied: Only platform owners can {operation} data between restaurants\"\n+            )\n+\n     @staticmethod\n     def sanitize_response_data(data: dict, user: User) -> dict:\n         \"\"\"\n         Remove sensitive data based on user's access level\n-        \n+\n         Args:\n             data: Response data\n             user: Current user\n-            \n+\n         Returns:\n             Sanitized data\n         \"\"\"\n         # Platform owners see everything\n         if TenantSecurity.is_platform_owner(user):\n             return data\n-        \n+\n         # Remove platform-level sensitive data for non-platform owners\n         sensitive_fields = [\n             \"platform_commission\",\n             \"platform_fee\",\n             \"total_platform_revenue\",\n-            \"other_restaurant_data\"\n+            \"other_restaurant_data\",\n         ]\n-        \n+\n         for field in sensitive_fields:\n             data.pop(field, None)\n-        \n-        return data\n\\ No newline at end of file\n+\n+        return data\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/two_factor_auth.py\t2025-08-02 22:05:26.748000+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/two_factor_auth.py\t2025-08-02 22:36:03.412484+00:00\n@@ -11,11 +11,17 @@\n from typing import Optional, Tuple\n \n from app.core.redis_client import RedisClient\n from app.models import User\n from app.core.tenant_security import TenantSecurity\n-from app.core.exceptions import ValidationException, AuthenticationException, FynloException, ResourceNotFoundException, ConflictException\n+from app.core.exceptions import (\n+    ValidationException,\n+    AuthenticationException,\n+    FynloException,\n+    ResourceNotFoundException,\n+    ConflictException,\n+)\n \n # 2FA Configuration\n TOTP_ISSUER = \"Fynlo POS\"\n TOTP_WINDOW = 1  # Allow 1 time window before/after for clock skew\n BACKUP_CODES_COUNT = 10\n@@ -24,243 +30,219 @@\n \n class TwoFactorAuth:\n     \"\"\"\n     Manages 2FA for platform owners\n     \"\"\"\n-    \n+\n     def __init__(self, redis_client: Optional[RedisClient] = None):\n         self.redis = redis_client\n-    \n+\n     def generate_secret(self) -> str:\n         \"\"\"Generate a new TOTP secret\"\"\"\n         return pyotp.random_base32()\n-    \n+\n     def generate_qr_code(self, user: User, secret: str) -> str:\n         \"\"\"\n         Generate QR code for authenticator app setup\n-        \n+\n         Returns:\n             Base64 encoded PNG image\n         \"\"\"\n         # Create provisioning URI\n         totp_uri = pyotp.totp.TOTP(secret).provisioning_uri(\n-            name=user.email,\n-            issuer_name=TOTP_ISSUER\n+            name=user.email, issuer_name=TOTP_ISSUER\n         )\n-        \n+\n         # Generate QR code\n         qr = qrcode.QRCode(version=1, box_size=10, border=5)\n         qr.add_data(totp_uri)\n         qr.make(fit=True)\n-        \n+\n         # Convert to image\n         img = qr.make_image(fill_color=\"black\", back_color=\"white\")\n-        \n+\n         # Convert to base64\n         buffer = io.BytesIO()\n-        img.save(buffer, format='PNG')\n+        img.save(buffer, format=\"PNG\")\n         buffer.seek(0)\n-        \n+\n         return base64.b64encode(buffer.getvalue()).decode()\n-    \n+\n     def generate_backup_codes(self) -> list[str]:\n         \"\"\"Generate backup recovery codes\"\"\"\n         codes = []\n         for _ in range(BACKUP_CODES_COUNT):\n             # Generate cryptographically secure random code\n             code = pyotp.random_base32()[:RECOVERY_CODE_LENGTH]\n             codes.append(f\"{code[:4]}-{code[4:]}\")\n         return codes\n-    \n+\n     async def setup_2fa(self, user: User) -> dict:\n         \"\"\"\n         Set up 2FA for a platform owner\n-        \n+\n         Returns:\n             Dict with secret, QR code, and backup codes\n         \"\"\"\n         # Only platform owners require 2FA\n         if not TenantSecurity.is_platform_owner(user):\n             raise AuthenticationException(\n                 message=\"2FA is only required for platform owners\",\n-                error_code=\"ACCESS_DENIED\"\n+                error_code=\"ACCESS_DENIED\",\n             )\n-        \n+\n         # Generate secret and backup codes\n         secret = self.generate_secret()\n         backup_codes = self.generate_backup_codes()\n         qr_code = self.generate_qr_code(user, secret)\n-        \n+\n         # Store in Redis temporarily (user must confirm setup)\n         if self.redis:\n             setup_key = f\"2fa:setup:{user.id}\"\n             setup_data = {\n                 \"secret\": secret,\n                 \"backup_codes\": \",\".join(backup_codes),\n-                \"created_at\": datetime.utcnow().isoformat()\n+                \"created_at\": datetime.utcnow().isoformat(),\n             }\n             await self.redis.setex(setup_key, 600, setup_data)  # 10 minute expiry\n-        \n+\n         return {\n             \"secret\": secret,\n             \"qr_code\": f\"data:image/png;base64,{qr_code}\",\n             \"backup_codes\": backup_codes,\n-            \"setup_key\": f\"2fa:setup:{user.id}\"\n+            \"setup_key\": f\"2fa:setup:{user.id}\",\n         }\n-    \n-    async def confirm_2fa_setup(\n-        self, \n-        user: User, \n-        token: str,\n-        setup_key: str\n-    ) -> bool:\n+\n+    async def confirm_2fa_setup(self, user: User, token: str, setup_key: str) -> bool:\n         \"\"\"\n         Confirm 2FA setup with a valid token\n         \"\"\"\n         if not self.redis:\n-            raise FynloException(\n-                message=\"2FA service unavailable\", \n-                status_code=503\n-            )\n-        \n+            raise FynloException(message=\"2FA service unavailable\", status_code=503)\n+\n         # Get setup data\n         setup_data = await self.redis.get(setup_key)\n         if not setup_data:\n-            raise ValidationException(\n-                message=\"2FA setup expired or invalid\"\n-            )\n-        \n+            raise ValidationException(message=\"2FA setup expired or invalid\")\n+\n         # Verify token\n         secret = setup_data.get(\"secret\")\n         if not self.verify_totp(secret, token):\n             return False\n-        \n+\n         # Store 2FA data permanently\n         user_2fa_key = f\"2fa:user:{user.id}\"\n         permanent_data = {\n             \"secret\": secret,\n             \"backup_codes\": setup_data.get(\"backup_codes\"),\n             \"enabled\": True,\n-            \"enabled_at\": datetime.utcnow().isoformat()\n+            \"enabled_at\": datetime.utcnow().isoformat(),\n         }\n         await self.redis.set(user_2fa_key, permanent_data)\n-        \n+\n         # Clean up setup data\n         await self.redis.delete(setup_key)\n-        \n+\n         return True\n-    \n+\n     def verify_totp(self, secret: str, token: str) -> bool:\n         \"\"\"Verify a TOTP token\"\"\"\n         totp = pyotp.TOTP(secret)\n         return totp.verify(token, valid_window=TOTP_WINDOW)\n-    \n-    async def verify_2fa(\n-        self, \n-        user: User, \n-        token: str\n-    ) -> Tuple[bool, Optional[str]]:\n+\n+    async def verify_2fa(self, user: User, token: str) -> Tuple[bool, Optional[str]]:\n         \"\"\"\n         Verify 2FA token for user\n-        \n+\n         Returns:\n             Tuple[bool, Optional[str]]: (is_valid, error_message)\n         \"\"\"\n         # Platform owners must have 2FA\n         if TenantSecurity.is_platform_owner(user):\n             if not self.redis:\n                 return False, \"2FA service unavailable\"\n-            \n+\n             # Get user's 2FA data\n             user_2fa_key = f\"2fa:user:{user.id}\"\n             user_2fa_data = await self.redis.get(user_2fa_key)\n-            \n+\n             if not user_2fa_data or not user_2fa_data.get(\"enabled\"):\n                 return False, \"2FA not enabled for platform owner\"\n-            \n+\n             secret = user_2fa_data.get(\"secret\")\n-            \n+\n             # Try TOTP first\n             if self.verify_totp(secret, token):\n                 return True, None\n-            \n+\n             # Try backup codes\n             backup_codes = user_2fa_data.get(\"backup_codes\", \"\").split(\",\")\n             formatted_token = token if \"-\" in token else f\"{token[:4]}-{token[4:]}\"\n-            \n+\n             if formatted_token in backup_codes:\n                 # Remove used backup code\n                 backup_codes.remove(formatted_token)\n                 user_2fa_data[\"backup_codes\"] = \",\".join(backup_codes)\n                 await self.redis.set(user_2fa_key, user_2fa_data)\n-                \n+\n                 return True, None\n-            \n+\n             return False, \"Invalid 2FA token\"\n-        \n+\n         # Non-platform owners don't need 2FA\n         return True, None\n-    \n+\n     async def is_2fa_enabled(self, user: User) -> bool:\n         \"\"\"Check if user has 2FA enabled\"\"\"\n         if not self.redis:\n             return False\n-        \n+\n         user_2fa_key = f\"2fa:user:{user.id}\"\n         user_2fa_data = await self.redis.get(user_2fa_key)\n-        \n+\n         return bool(user_2fa_data and user_2fa_data.get(\"enabled\"))\n-    \n+\n     async def disable_2fa(self, user: User, current_token: str) -> bool:\n         \"\"\"\n         Disable 2FA for user (requires current token)\n         \"\"\"\n         # Verify current token first\n         valid, _ = await self.verify_2fa(user, current_token)\n         if not valid:\n-            raise AuthenticationException(\n-                message=\"Invalid 2FA token\"\n-            )\n-        \n+            raise AuthenticationException(message=\"Invalid 2FA token\")\n+\n         if self.redis:\n             user_2fa_key = f\"2fa:user:{user.id}\"\n             await self.redis.delete(user_2fa_key)\n-        \n+\n         return True\n-    \n+\n     async def generate_new_backup_codes(\n-        self, \n-        user: User, \n-        current_token: str\n+        self, user: User, current_token: str\n     ) -> list[str]:\n         \"\"\"\n         Generate new backup codes (requires current token)\n         \"\"\"\n         # Verify current token\n         valid, _ = await self.verify_2fa(user, current_token)\n         if not valid:\n-            raise AuthenticationException(\n-                message=\"Invalid 2FA token\"\n-            )\n-        \n+            raise AuthenticationException(message=\"Invalid 2FA token\")\n+\n         if not self.redis:\n-            raise FynloException(\n-                message=\"2FA service unavailable\", \n-                status_code=503\n-            )\n-        \n+            raise FynloException(message=\"2FA service unavailable\", status_code=503)\n+\n         # Generate new codes\n         new_codes = self.generate_backup_codes()\n-        \n+\n         # Update stored data\n         user_2fa_key = f\"2fa:user:{user.id}\"\n         user_2fa_data = await self.redis.get(user_2fa_key)\n-        \n+\n         if user_2fa_data:\n             user_2fa_data[\"backup_codes\"] = \",\".join(new_codes)\n             await self.redis.set(user_2fa_key, user_2fa_data)\n-        \n+\n         return new_codes\n \n \n # Global 2FA instance\n-two_factor_auth = TwoFactorAuth()\n\\ No newline at end of file\n+two_factor_auth = TwoFactorAuth()\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/integration/__init__.py\t2025-07-03 16:16:48.236649+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/integration/__init__.py\t2025-08-02 22:36:03.418858+00:00\n@@ -1 +1 @@\n-# Integration package for Fynlo POS\n\\ No newline at end of file\n+# Integration package for Fynlo POS\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/transaction_manager.py\t2025-08-02 22:32:50.869247+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/transaction_manager.py\t2025-08-02 22:36:03.417206+00:00\n@@ -12,305 +12,341 @@\n import asyncio\n from datetime import datetime\n \n logger = logging.getLogger(__name__)\n \n+\n class TransactionError(Exception):\n     \"\"\"Custom exception for transaction failures\"\"\"\n-    pass\n+\n+    pass\n+\n \n class RetryableTransactionError(TransactionError):\n     \"\"\"Exception for transactions that can be retried\"\"\"\n-    pass\n+\n+    pass\n+\n \n class NonRetryableTransactionError(TransactionError):\n     \"\"\"Exception for transactions that should not be retried\"\"\"\n+\n     pass\n \n \n class TransactionManager:\n     \"\"\"\n     Manages database transactions with retry logic, rollback handling,\n     and atomic operation support.\n     \"\"\"\n-    \n+\n     pass\n \n     def __init__(self, max_retries: int = 3, retry_delay: float = 0.1):\n         self.max_retries = max_retries\n         self.retry_delay = retry_delay\n-    \n+\n     @asynccontextmanager\n     async def atomic_transaction(self, db: Session):\n         \"\"\"\n         Context manager for atomic database transactions with automatic rollback.\n-        \n+\n         Usage:\n             async with transaction_manager.atomic_transaction(db) as tx:\n                 # Perform database operations\n                 db.add(object1)\n                 db.add(object2)\n                 # Transaction automatically committed on successful exit\n                 # Automatically rolled back on exception\n         \"\"\"\n         transaction_started = datetime.utcnow()\n-        \n+\n         try:\n             # Begin transaction if not already in one\n             if db.in_transaction():\n                 logger.debug(\"Already in transaction, using existing transaction\")\n                 yield db\n             else:\n                 logger.debug(\"Starting new atomic transaction\")\n                 # SQLAlchemy automatically begins transaction on first operation\n                 yield db\n-                \n+\n                 # Commit if we reach this point without exceptions\n                 db.commit()\n-                \n+\n                 duration = (datetime.utcnow() - transaction_started).total_seconds()\n-                logger.info(f\"\u2705 Transaction committed successfully (duration: {duration:.3f}s)\")\n-                \n+                logger.info(\n+                    f\"\u2705 Transaction committed successfully (duration: {duration:.3f}s)\"\n+                )\n+\n         except IntegrityError as e:\n             # Database constraint violations\n             db.rollback()\n             duration = (datetime.utcnow() - transaction_started).total_seconds()\n-            logger.error(f\"\u274c Transaction rolled back - Integrity constraint violation (duration: {duration:.3f}s): {e}\")\n+            logger.error(\n+                f\"\u274c Transaction rolled back - Integrity constraint violation (duration: {duration:.3f}s): {e}\"\n+            )\n             raise NonRetryableTransactionError(f\"Database constraint violation: {e}\")\n-            \n+\n         except DisconnectionError as e:\n             # Database connection issues - these can be retried\n             db.rollback()\n             duration = (datetime.utcnow() - transaction_started).total_seconds()\n-            logger.error(f\"\u274c Transaction rolled back - Database disconnection (duration: {duration:.3f}s): {e}\")\n+            logger.error(\n+                f\"\u274c Transaction rolled back - Database disconnection (duration: {duration:.3f}s): {e}\"\n+            )\n             raise RetryableTransactionError(f\"Database connection error: {e}\")\n-            \n+\n         except SQLAlchemyError as e:\n             # Other SQLAlchemy errors\n             db.rollback()\n             duration = (datetime.utcnow() - transaction_started).total_seconds()\n-            logger.error(f\"\u274c Transaction rolled back - SQLAlchemy error (duration: {duration:.3f}s): {e}\")\n+            logger.error(\n+                f\"\u274c Transaction rolled back - SQLAlchemy error (duration: {duration:.3f}s): {e}\"\n+            )\n             # Most SQLAlchemy errors are non-retryable\n             raise NonRetryableTransactionError(f\"Database error: {e}\")\n-            \n+\n         except Exception as e:\n             # Any other unexpected error\n             db.rollback()\n             duration = (datetime.utcnow() - transaction_started).total_seconds()\n-            logger.error(f\"\u274c Transaction rolled back - Unexpected error (duration: {duration:.3f}s): {e}\")\n-            raise NonRetryableTransactionError(f\"Unexpected error during transaction: {e}\")\n-    \n+            logger.error(\n+                f\"\u274c Transaction rolled back - Unexpected error (duration: {duration:.3f}s): {e}\"\n+            )\n+            raise NonRetryableTransactionError(\n+                f\"Unexpected error during transaction: {e}\"\n+            )\n+\n     async def execute_with_retry(self, operation: Callable, *args, **kwargs) -> Any:\n         \"\"\"\n         Execute a database operation with retry logic for transient failures.\n-        \n+\n         Args:\n             operation: The function to execute\n             *args: Arguments to pass to the operation\n             **kwargs: Keyword arguments to pass to the operation\n-            \n+\n         Returns:\n             Result of the operation\n-            \n+\n         Raises:\n             NonRetryableTransactionError: For errors that shouldn't be retried\n             TransactionError: If all retries are exhausted\n         \"\"\"\n         last_exception = None\n-        \n+\n         for attempt in range(self.max_retries + 1):\n             try:\n-                logger.debug(f\"Executing operation (attempt {attempt + 1}/{self.max_retries + 1})\")\n+                logger.debug(\n+                    f\"Executing operation (attempt {attempt + 1}/{self.max_retries + 1})\"\n+                )\n                 result = await operation(*args, **kwargs)\n-                \n+\n                 if attempt > 0:\n                     logger.info(f\"\u2705 Operation succeeded on attempt {attempt + 1}\")\n-                \n+\n                 return result\n-                \n+\n             except NonRetryableTransactionError:\n                 # Don't retry these\n                 raise\n-                \n+\n             except RetryableTransactionError as e:\n                 last_exception = e\n                 if attempt < self.max_retries:\n-                    wait_time = self.retry_delay * (2 ** attempt)  # Exponential backoff\n-                    logger.warning(f\"\u26a0\ufe0f Retryable error on attempt {attempt + 1}, waiting {wait_time:.3f}s before retry: {e}\")\n+                    wait_time = self.retry_delay * (2**attempt)  # Exponential backoff\n+                    logger.warning(\n+                        f\"\u26a0\ufe0f Retryable error on attempt {attempt + 1}, waiting {wait_time:.3f}s before retry: {e}\"\n+                    )\n                     await asyncio.sleep(wait_time)\n                     continue\n                 else:\n                     logger.error(f\"\u274c All retry attempts exhausted\")\n                     break\n-                    \n+\n             except Exception as e:\n                 # Treat unknown exceptions as non-retryable\n                 logger.error(f\"\u274c Non-retryable error: {e}\")\n                 raise NonRetryableTransactionError(f\"Unexpected error: {e}\")\n-        \n+\n         # If we get here, all retries were exhausted\n-        raise TransactionError(f\"Operation failed after {self.max_retries + 1} attempts. Last error: {last_exception}\")\n+        raise TransactionError(\n+            f\"Operation failed after {self.max_retries + 1} attempts. Last error: {last_exception}\"\n+        )\n \n \n def transactional(max_retries: int = 3, retry_delay: float = 0.1):\n     \"\"\"\n     Decorator to wrap a function in an atomic transaction with retry logic.\n-    \n+\n     The decorated function should take a 'db' parameter as its first argument.\n-    \n+\n     Args:\n         max_retries: Maximum number of retry attempts for retryable errors\n         retry_delay: Base delay between retries (with exponential backoff)\n-    \n+\n     Usage:\n         @transactional(max_retries=5, retry_delay=0.2)\n         async def create_order_atomically(db: Session, order_data: dict):\n             # All database operations in this function will be atomic\n             order = Order(**order_data)\n             db.add(order)\n             # Update inventory\n             # Send notifications\n             # etc.\n     \"\"\"\n+\n     @functools.wraps(func)\n     async def wrapper(*args, **kwargs):\n         # Extract db session from arguments\n         db = None\n-        if args and hasattr(args[0], 'query'):  # First arg is Session\n+        if args and hasattr(args[0], \"query\"):  # First arg is Session\n             db = args[0]\n-        elif 'db' in kwargs:\n-            db = kwargs['db']\n+        elif \"db\" in kwargs:\n+            db = kwargs[\"db\"]\n         else:\n             raise ValueError(\"No database session found in function arguments\")\n-        \n-        transaction_manager = TransactionManager(max_retries=max_retries, retry_delay=retry_delay)\n-        \n+\n+        transaction_manager = TransactionManager(\n+            max_retries=max_retries, retry_delay=retry_delay\n+        )\n+\n         async def operation():\n             async with transaction_manager.atomic_transaction(db):\n                 return await func(*args, **kwargs)\n-        \n+\n         return await transaction_manager.execute_with_retry(operation)\n-        \n+\n         return wrapper\n+\n     return decorator\n \n \n-def optimistic_lock_retry(version_field: str = 'version', max_retries: int = 5):\n+def optimistic_lock_retry(version_field: str = \"version\", max_retries: int = 5):\n     \"\"\"\n     Decorator for handling optimistic locking with automatic retry.\n-    \n+\n     Args:\n         version_field: Name of the version field used for optimistic locking\n         max_retries: Maximum number of retry attempts for version conflicts\n-    \n+\n     Usage:\n         @optimistic_lock_retry(version_field='version', max_retries=10)\n         async def update_product_stock(db: Session, product_id: str, quantity_change: int):\n             product = db.query(Product).filter(Product.id == product_id).first()\n             original_version = product.version\n             product.stock_quantity += quantity_change\n             product.version += 1\n             # If another process updated the product, this will fail and retry\n     \"\"\"\n+\n     def decorator(func):\n         @functools.wraps(func)\n         async def wrapper(*args, **kwargs):\n             for attempt in range(max_retries + 1):\n                 try:\n                     return await func(*args, **kwargs)\n                 except IntegrityError as e:\n                     if version_field in str(e) and attempt < max_retries:\n-                        logger.warning(f\"\u26a0\ufe0f Optimistic lock conflict (attempt {attempt + 1}), retrying...\")\n-                        await asyncio.sleep(0.05 * (attempt + 1))  # Short delay with backoff\n+                        logger.warning(\n+                            f\"\u26a0\ufe0f Optimistic lock conflict (attempt {attempt + 1}), retrying...\"\n+                        )\n+                        await asyncio.sleep(\n+                            0.05 * (attempt + 1)\n+                        )  # Short delay with backoff\n                         continue\n                     raise\n-            \n-            raise TransactionError(f\"Optimistic lock failed after {max_retries + 1} attempts\")\n-        \n+\n+            raise TransactionError(\n+                f\"Optimistic lock failed after {max_retries + 1} attempts\"\n+            )\n+\n         return wrapper\n+\n     return decorator\n \n \n class BatchTransactionManager:\n     \"\"\"\n     Manages batch operations with transaction boundaries and partial failure handling.\n     \"\"\"\n-    \n+\n     pass\n \n     def __init__(self, batch_size: int = 100, rollback_on_partial_failure: bool = True):\n         self.batch_size = batch_size\n         self.rollback_on_partial_failure = rollback_on_partial_failure\n-    \n-    async def execute_batch(self, db: Session, operations: list, operation_handler: Callable) -> dict:\n+\n+    async def execute_batch(\n+        self, db: Session, operations: list, operation_handler: Callable\n+    ) -> dict:\n         \"\"\"\n         Execute a batch of operations with proper transaction management.\n-        \n+\n         Args:\n             db: Database session\n             operations: List of operations to execute\n             operation_handler: Function to handle each individual operation\n-            \n+\n         Returns:\n             Dictionary with results: {'successful': int, 'failed': int, 'errors': list}\n         \"\"\"\n-        results = {\n-            'successful': 0,\n-            'failed': 0,\n-            'errors': [],\n-            'total': len(operations)\n-        }\n-        \n+        results = {\"successful\": 0, \"failed\": 0, \"errors\": [], \"total\": len(operations)}\n+\n         # Process in batches\n         for i in range(0, len(operations), self.batch_size):\n-            batch = operations[i:i + self.batch_size]\n-            batch_results = await self._execute_batch_chunk(db, batch, operation_handler)\n-            \n+            batch = operations[i : i + self.batch_size]\n+            batch_results = await self._execute_batch_chunk(\n+                db, batch, operation_handler\n+            )\n+\n             # Aggregate results\n-            results['successful'] += batch_results['successful']\n-            results['failed'] += batch_results['failed']\n-            results['errors'].extend(batch_results['errors'])\n-        \n-        logger.info(f\"\u2705 Batch execution completed: {results['successful']}/{results['total']} successful\")\n-        \n+            results[\"successful\"] += batch_results[\"successful\"]\n+            results[\"failed\"] += batch_results[\"failed\"]\n+            results[\"errors\"].extend(batch_results[\"errors\"])\n+\n+        logger.info(\n+            f\"\u2705 Batch execution completed: {results['successful']}/{results['total']} successful\"\n+        )\n+\n         return results\n-        chunk_results = {\n-            'successful': 0,\n-            'failed': 0,\n-            'errors': []\n-        }\n-        \n+        chunk_results = {\"successful\": 0, \"failed\": 0, \"errors\": []}\n+\n         transaction_manager = TransactionManager()\n-        \n+\n         try:\n             async with transaction_manager.atomic_transaction(db):\n                 for operation in batch:\n                     try:\n                         await operation_handler(db, operation)\n-                        chunk_results['successful'] += 1\n+                        chunk_results[\"successful\"] += 1\n                     except Exception as e:\n-                        chunk_results['failed'] += 1\n-                        chunk_results['errors'].append({\n-                            'operation': str(operation),\n-                            'error': str(e)\n-                        })\n-                        \n+                        chunk_results[\"failed\"] += 1\n+                        chunk_results[\"errors\"].append(\n+                            {\"operation\": str(operation), \"error\": str(e)}\n+                        )\n+\n                         if self.rollback_on_partial_failure:\n-                            logger.error(f\"\u274c Batch operation failed, rolling back entire batch: {e}\")\n+                            logger.error(\n+                                f\"\u274c Batch operation failed, rolling back entire batch: {e}\"\n+                            )\n                             raise  # This will trigger rollback of entire batch\n                         else:\n-                            logger.warning(f\"\u26a0\ufe0f Individual operation failed, continuing with batch: {e}\")\n+                            logger.warning(\n+                                f\"\u26a0\ufe0f Individual operation failed, continuing with batch: {e}\"\n+                            )\n                             continue\n-                \n+\n         except Exception as e:\n             # If we're here with rollback_on_partial_failure=True, the entire batch failed\n             if self.rollback_on_partial_failure:\n-                chunk_results['successful'] = 0  # All operations rolled back\n-                chunk_results['failed'] = len(batch)\n-                chunk_results['errors'] = [{'batch_error': str(e)}]\n-        \n+                chunk_results[\"successful\"] = 0  # All operations rolled back\n+                chunk_results[\"failed\"] = len(batch)\n+                chunk_results[\"errors\"] = [{\"batch_error\": str(e)}]\n+\n         return chunk_results\n \n \n # Global instances\n transaction_manager = TransactionManager()\n-batch_transaction_manager = BatchTransactionManager()\n\\ No newline at end of file\n+batch_transaction_manager = BatchTransactionManager()\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/push_notifications.py\t2025-08-02 21:56:58.995946+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/push_notifications.py\t2025-08-02 22:36:03.431036+00:00\n@@ -18,12 +18,14 @@\n # Mock APNs implementation for development\n # In production, this would use aioapns or similar library\n \n logger = logging.getLogger(__name__)\n \n+\n class NotificationType(str, Enum):\n     \"\"\"Push notification types\"\"\"\n+\n     ORDER_CREATED = \"order_created\"\n     ORDER_STATUS_CHANGED = \"order_status_changed\"\n     PAYMENT_COMPLETED = \"payment_completed\"\n     PAYMENT_FAILED = \"payment_failed\"\n     KITCHEN_ALERT = \"kitchen_alert\"\n@@ -31,128 +33,141 @@\n     SHIFT_REMINDER = \"shift_reminder\"\n     SYSTEM_MAINTENANCE = \"system_maintenance\"\n     CUSTOMER_ORDER_READY = \"customer_order_ready\"\n     DELIVERY_UPDATE = \"delivery_update\"\n \n+\n class NotificationPriority(str, Enum):\n     \"\"\"Notification priority levels\"\"\"\n+\n     LOW = \"low\"\n     NORMAL = \"normal\"\n     HIGH = \"high\"\n     CRITICAL = \"critical\"\n \n+\n @dataclass\n class DeviceToken:\n     \"\"\"Device token for push notifications\"\"\"\n+\n     token: str\n     user_id: str\n     restaurant_id: str\n     device_type: str = \"ios\"\n     is_active: bool = True\n     registered_at: datetime = None\n     last_used: datetime = None\n-    \n+\n     def __post_init__(self):\n         if self.registered_at is None:\n             self.registered_at = datetime.now()\n         if self.last_used is None:\n             self.last_used = datetime.now()\n \n+\n @dataclass\n class NotificationPayload:\n     \"\"\"Push notification payload structure\"\"\"\n+\n     title: str\n     body: str\n     notification_type: NotificationType\n     priority: NotificationPriority = NotificationPriority.NORMAL\n     badge_count: Optional[int] = None\n     sound: str = \"default\"\n     custom_data: Dict[str, Any] = None\n     expiration: Optional[datetime] = None\n-    \n+\n     def __post_init__(self):\n         if self.custom_data is None:\n             self.custom_data = {}\n         if self.expiration is None:\n             self.expiration = datetime.now() + timedelta(hours=24)\n \n+\n @dataclass\n class NotificationTemplate:\n     \"\"\"Notification template for different types\"\"\"\n+\n     notification_type: NotificationType\n     title_template: str\n     body_template: str\n     sound: str = \"default\"\n     priority: NotificationPriority = NotificationPriority.NORMAL\n     custom_data_template: Dict[str, Any] = None\n-    \n+\n     def __post_init__(self):\n         if self.custom_data_template is None:\n             self.custom_data_template = {}\n \n+\n @dataclass\n class NotificationResult:\n     \"\"\"Result of sending a push notification\"\"\"\n+\n     device_token: str\n     success: bool\n     message_id: Optional[str] = None\n     error_code: Optional[str] = None\n     error_message: Optional[str] = None\n     sent_at: datetime = None\n-    \n+\n     def __post_init__(self):\n         if self.sent_at is None:\n             self.sent_at = datetime.now()\n \n+\n class NotificationPreferences:\n     \"\"\"User notification preferences\"\"\"\n+\n     def __init__(\n         self,\n         user_id: str,\n         enabled_types: List[NotificationType] = None,\n         quiet_hours_start: Optional[str] = None,\n         quiet_hours_end: Optional[str] = None,\n         sound_enabled: bool = True,\n-        badge_enabled: bool = True\n+        badge_enabled: bool = True,\n     ):\n         self.user_id = user_id\n         self.enabled_types = enabled_types or list(NotificationType)\n         self.quiet_hours_start = quiet_hours_start  # \"22:00\"\n-        self.quiet_hours_end = quiet_hours_end      # \"08:00\"\n+        self.quiet_hours_end = quiet_hours_end  # \"08:00\"\n         self.sound_enabled = sound_enabled\n         self.badge_enabled = badge_enabled\n         self.updated_at = datetime.now()\n \n+\n class PushNotificationService:\n     \"\"\"Push notification service for iOS devices\"\"\"\n-    \n+\n     def __init__(self):\n         # In-memory storage for development\n         # In production, these would be stored in database\n         self.device_tokens: Dict[str, DeviceToken] = {}\n         self.user_preferences: Dict[str, NotificationPreferences] = {}\n         self.notification_history: List[NotificationResult] = []\n-        \n+\n         # APNs configuration (mock for development)\n         self.apns_config = {\n             \"key_id\": \"mock_key_id\",\n             \"team_id\": \"mock_team_id\",\n             \"bundle_id\": \"com.fynlo.pos\",\n-            \"use_sandbox\": True  # Set to False for production\n+            \"use_sandbox\": True,  # Set to False for production\n         }\n-        \n+\n         # Notification templates\n         self.templates = self._initialize_templates()\n-        \n+\n         # Statistics\n         self.stats = {\n             \"total_sent\": 0,\n             \"total_delivered\": 0,\n             \"total_failed\": 0,\n-            \"tokens_registered\": 0\n+            \"tokens_registered\": 0,\n         }\n-    \n+\n     def _initialize_templates(self) -> Dict[NotificationType, NotificationTemplate]:\n         \"\"\"Initialize notification templates\"\"\"\n         return {\n             NotificationType.ORDER_CREATED: NotificationTemplate(\n                 notification_type=NotificationType.ORDER_CREATED,\n@@ -161,23 +176,23 @@\n                 priority=NotificationPriority.HIGH,\n                 sound=\"order_alert.wav\",\n                 custom_data_template={\n                     \"order_id\": \"{order_id}\",\n                     \"restaurant_id\": \"{restaurant_id}\",\n-                    \"action\": \"view_order\"\n-                }\n+                    \"action\": \"view_order\",\n+                },\n             ),\n             NotificationType.ORDER_STATUS_CHANGED: NotificationTemplate(\n                 notification_type=NotificationType.ORDER_STATUS_CHANGED,\n                 title_template=\"Order #{order_number} {status}\",\n                 body_template=\"Order status updated to {status}\",\n                 priority=NotificationPriority.NORMAL,\n                 custom_data_template={\n                     \"order_id\": \"{order_id}\",\n                     \"new_status\": \"{status}\",\n-                    \"action\": \"view_order\"\n-                }\n+                    \"action\": \"view_order\",\n+                },\n             ),\n             NotificationType.PAYMENT_COMPLETED: NotificationTemplate(\n                 notification_type=NotificationType.PAYMENT_COMPLETED,\n                 title_template=\"Payment Received\",\n                 body_template=\"${amount} payment confirmed for order #{order_number}\",\n@@ -185,12 +200,12 @@\n                 sound=\"payment_success.wav\",\n                 custom_data_template={\n                     \"payment_id\": \"{payment_id}\",\n                     \"order_id\": \"{order_id}\",\n                     \"amount\": \"{amount}\",\n-                    \"action\": \"view_payment\"\n-                }\n+                    \"action\": \"view_payment\",\n+                },\n             ),\n             NotificationType.PAYMENT_FAILED: NotificationTemplate(\n                 notification_type=NotificationType.PAYMENT_FAILED,\n                 title_template=\"Payment Failed\",\n                 body_template=\"Payment of ${amount} failed for order #{order_number}\",\n@@ -198,429 +213,437 @@\n                 sound=\"error_alert.wav\",\n                 custom_data_template={\n                     \"payment_id\": \"{payment_id}\",\n                     \"order_id\": \"{order_id}\",\n                     \"error_reason\": \"{error_reason}\",\n-                    \"action\": \"retry_payment\"\n-                }\n+                    \"action\": \"retry_payment\",\n+                },\n             ),\n             NotificationType.KITCHEN_ALERT: NotificationTemplate(\n                 notification_type=NotificationType.KITCHEN_ALERT,\n                 title_template=\"Kitchen Alert\",\n                 body_template=\"{alert_message}\",\n                 priority=NotificationPriority.HIGH,\n                 sound=\"kitchen_alert.wav\",\n                 custom_data_template={\n                     \"alert_type\": \"{alert_type}\",\n                     \"order_id\": \"{order_id}\",\n-                    \"action\": \"view_kitchen\"\n-                }\n+                    \"action\": \"view_kitchen\",\n+                },\n             ),\n             NotificationType.INVENTORY_LOW: NotificationTemplate(\n                 notification_type=NotificationType.INVENTORY_LOW,\n                 title_template=\"Low Stock Alert\",\n                 body_template=\"{product_name} is running low ({current_stock} remaining)\",\n                 priority=NotificationPriority.NORMAL,\n                 custom_data_template={\n                     \"product_id\": \"{product_id}\",\n                     \"current_stock\": \"{current_stock}\",\n-                    \"action\": \"view_inventory\"\n-                }\n+                    \"action\": \"view_inventory\",\n+                },\n             ),\n             NotificationType.SHIFT_REMINDER: NotificationTemplate(\n                 notification_type=NotificationType.SHIFT_REMINDER,\n                 title_template=\"Shift Reminder\",\n                 body_template=\"Your shift starts in {time_until} minutes\",\n                 priority=NotificationPriority.NORMAL,\n                 custom_data_template={\n                     \"shift_id\": \"{shift_id}\",\n                     \"shift_start\": \"{shift_start}\",\n-                    \"action\": \"view_schedule\"\n-                }\n+                    \"action\": \"view_schedule\",\n+                },\n             ),\n             NotificationType.SYSTEM_MAINTENANCE: NotificationTemplate(\n                 notification_type=NotificationType.SYSTEM_MAINTENANCE,\n                 title_template=\"System Maintenance\",\n                 body_template=\"{maintenance_message}\",\n                 priority=NotificationPriority.NORMAL,\n                 custom_data_template={\n                     \"maintenance_type\": \"{maintenance_type}\",\n                     \"estimated_duration\": \"{estimated_duration}\",\n-                    \"action\": \"view_status\"\n-                }\n+                    \"action\": \"view_status\",\n+                },\n             ),\n             NotificationType.CUSTOMER_ORDER_READY: NotificationTemplate(\n                 notification_type=NotificationType.CUSTOMER_ORDER_READY,\n                 title_template=\"Order Ready for Pickup\",\n                 body_template=\"Order #{order_number} is ready for pickup\",\n                 priority=NotificationPriority.HIGH,\n                 sound=\"order_ready.wav\",\n                 custom_data_template={\n                     \"order_id\": \"{order_id}\",\n                     \"pickup_code\": \"{pickup_code}\",\n-                    \"action\": \"pickup_order\"\n-                }\n+                    \"action\": \"pickup_order\",\n+                },\n             ),\n             NotificationType.DELIVERY_UPDATE: NotificationTemplate(\n                 notification_type=NotificationType.DELIVERY_UPDATE,\n                 title_template=\"Delivery Update\",\n                 body_template=\"Your order is {delivery_status}\",\n                 priority=NotificationPriority.NORMAL,\n                 custom_data_template={\n                     \"order_id\": \"{order_id}\",\n                     \"delivery_status\": \"{delivery_status}\",\n                     \"estimated_arrival\": \"{estimated_arrival}\",\n-                    \"action\": \"track_delivery\"\n-                }\n-            )\n+                    \"action\": \"track_delivery\",\n+                },\n+            ),\n         }\n-    \n+\n     async def register_device_token(\n-        self,\n-        token: str,\n-        user_id: str,\n-        restaurant_id: str,\n-        device_type: str = \"ios\"\n+        self, token: str, user_id: str, restaurant_id: str, device_type: str = \"ios\"\n     ) -> bool:\n         \"\"\"Register device token for push notifications\"\"\"\n         try:\n             # Validate token format (APNs tokens are 64 characters hex)\n             if not self._validate_device_token(token):\n                 raise FynloException(\n                     message=\"Invalid device token format\",\n                     error_code=ErrorCodes.VALIDATION_ERROR,\n-                    status_code=400\n+                    status_code=400,\n                 )\n-            \n+\n             # Create or update device token\n             device_token = DeviceToken(\n                 token=token,\n                 user_id=user_id,\n                 restaurant_id=restaurant_id,\n                 device_type=device_type,\n                 is_active=True,\n                 registered_at=datetime.now(),\n-                last_used=datetime.now()\n+                last_used=datetime.now(),\n             )\n-            \n+\n             self.device_tokens[token] = device_token\n             self.stats[\"tokens_registered\"] += 1\n-            \n+\n             logger.info(f\"Device token registered: {token[:8]}... for user {user_id}\")\n             return True\n-            \n+\n         except Exception as e:\n             logger.error(f\"Failed to register device token: {str(e)}\")\n             return False\n-    \n+\n     async def unregister_device_token(self, token: str) -> bool:\n         \"\"\"Unregister device token\"\"\"\n         try:\n             if token in self.device_tokens:\n                 self.device_tokens[token].is_active = False\n                 logger.info(f\"Device token unregistered: {token[:8]}...\")\n                 return True\n             return False\n-            \n+\n         except Exception as e:\n             logger.error(f\"Failed to unregister device token: {str(e)}\")\n             return False\n-    \n+\n     async def send_notification(\n         self,\n         payload: NotificationPayload,\n         target_users: List[str] = None,\n         target_restaurants: List[str] = None,\n-        target_tokens: List[str] = None\n+        target_tokens: List[str] = None,\n     ) -> Dict[str, Any]:\n         \"\"\"Send push notification to specified targets\"\"\"\n         try:\n             results = []\n-            \n+\n             # Collect target device tokens\n             tokens_to_send = set()\n-            \n+\n             if target_tokens:\n                 tokens_to_send.update(target_tokens)\n-            \n+\n             if target_users:\n                 for user_id in target_users:\n                     user_tokens = [\n-                        token for token, device in self.device_tokens.items()\n+                        token\n+                        for token, device in self.device_tokens.items()\n                         if device.user_id == user_id and device.is_active\n                     ]\n                     tokens_to_send.update(user_tokens)\n-            \n+\n             if target_restaurants:\n                 for restaurant_id in target_restaurants:\n                     restaurant_tokens = [\n-                        token for token, device in self.device_tokens.items()\n+                        token\n+                        for token, device in self.device_tokens.items()\n                         if device.restaurant_id == restaurant_id and device.is_active\n                     ]\n                     tokens_to_send.update(restaurant_tokens)\n-            \n+\n             # Send notifications to each token\n             for token in tokens_to_send:\n                 device = self.device_tokens.get(token)\n                 if not device:\n                     continue\n-                \n+\n                 # Check user preferences\n                 if not self._should_send_notification(device.user_id, payload):\n                     continue\n-                \n+\n                 # Send notification\n                 result = await self._send_to_device(token, payload)\n                 results.append(result)\n-                \n+\n                 # Update statistics\n                 if result.success:\n                     self.stats[\"total_delivered\"] += 1\n                 else:\n                     self.stats[\"total_failed\"] += 1\n-                \n+\n                 self.stats[\"total_sent\"] += 1\n                 self.notification_history.append(result)\n-            \n+\n             return {\n                 \"total_sent\": len(results),\n                 \"successful\": len([r for r in results if r.success]),\n                 \"failed\": len([r for r in results if not r.success]),\n-                \"results\": [r.__dict__ for r in results]\n+                \"results\": [r.__dict__ for r in results],\n             }\n-            \n+\n         except Exception as e:\n             raise FynloException(\n                 message=f\"Failed to send notification: {str(e)}\",\n                 error_code=ErrorCodes.INTERNAL_ERROR,\n-                status_code=500\n+                status_code=500,\n             )\n-    \n+\n     async def send_templated_notification(\n         self,\n         notification_type: NotificationType,\n         template_data: Dict[str, Any],\n         target_users: List[str] = None,\n         target_restaurants: List[str] = None,\n-        target_tokens: List[str] = None\n+        target_tokens: List[str] = None,\n     ) -> Dict[str, Any]:\n         \"\"\"Send notification using predefined template\"\"\"\n         try:\n             template = self.templates.get(notification_type)\n             if not template:\n                 raise FynloException(\n                     message=f\"Template not found for type: {notification_type}\",\n                     error_code=ErrorCodes.NOT_FOUND,\n-                    status_code=404\n+                    status_code=404,\n                 )\n-            \n+\n             # Format template with provided data\n             title = template.title_template.format(**template_data)\n             body = template.body_template.format(**template_data)\n-            \n+\n             # Format custom data\n             custom_data = {}\n             for key, value_template in template.custom_data_template.items():\n                 try:\n                     custom_data[key] = value_template.format(**template_data)\n                 except KeyError:\n                     custom_data[key] = value_template  # Use as-is if no template data\n-            \n+\n             # Create payload\n             payload = NotificationPayload(\n                 title=title,\n                 body=body,\n                 notification_type=notification_type,\n                 priority=template.priority,\n                 sound=template.sound,\n-                custom_data=custom_data\n+                custom_data=custom_data,\n             )\n-            \n+\n             return await self.send_notification(\n                 payload=payload,\n                 target_users=target_users,\n                 target_restaurants=target_restaurants,\n-                target_tokens=target_tokens\n+                target_tokens=target_tokens,\n             )\n-            \n+\n         except Exception as e:\n             raise FynloException(\n                 message=f\"Failed to send templated notification: {str(e)}\",\n                 error_code=ErrorCodes.INTERNAL_ERROR,\n-                status_code=500\n+                status_code=500,\n             )\n         \"\"\"Update user notification preferences\"\"\"\n         try:\n             preferences.user_id = user_id\n             preferences.updated_at = datetime.now()\n             self.user_preferences[user_id] = preferences\n-            \n+\n             logger.info(f\"Updated notification preferences for user {user_id}\")\n             return True\n-            \n+\n         except Exception as e:\n             logger.error(f\"Failed to update preferences: {str(e)}\")\n             return False\n-    \n+\n     def get_user_preferences(self, user_id: str) -> Optional[NotificationPreferences]:\n         \"\"\"Get user notification preferences\"\"\"\n         return self.user_preferences.get(user_id)\n         \"\"\"Get notification history\"\"\"\n         history = self.notification_history\n-        \n+\n         if user_id:\n             # Filter by user's device tokens\n             user_tokens = [\n-                token for token, device in self.device_tokens.items()\n+                token\n+                for token, device in self.device_tokens.items()\n                 if device.user_id == user_id\n             ]\n             history = [\n-                result for result in history\n-                if result.device_token in user_tokens\n+                result for result in history if result.device_token in user_tokens\n             ]\n-        \n+\n         return history[-limit:]\n-    \n+\n     def get_service_statistics(self) -> Dict[str, Any]:\n         \"\"\"Get push notification service statistics\"\"\"\n         return {\n             \"stats\": self.stats.copy(),\n-            \"registered_tokens\": len([t for t in self.device_tokens.values() if t.is_active]),\n+            \"registered_tokens\": len(\n+                [t for t in self.device_tokens.values() if t.is_active]\n+            ),\n             \"total_tokens\": len(self.device_tokens),\n             \"templates_available\": len(self.templates),\n-            \"recent_failures\": len([\n-                r for r in self.notification_history[-50:]\n-                if not r.success\n-            ])\n+            \"recent_failures\": len(\n+                [r for r in self.notification_history[-50:] if not r.success]\n+            ),\n         }\n-    \n+\n     async def _send_to_device(\n-        self,\n-        device_token: str,\n-        payload: NotificationPayload\n+        self, device_token: str, payload: NotificationPayload\n     ) -> NotificationResult:\n         \"\"\"Send notification to specific device (mock implementation)\"\"\"\n         try:\n             # Mock APNs sending logic\n             # In production, this would use aioapns or similar library\n-            \n+\n             # Simulate APNs request\n             await asyncio.sleep(0.1)  # Simulate network delay\n-            \n+\n             # Mock success/failure (95% success rate)\n             import random\n+\n             success = random.random() < 0.95\n-            \n+\n             if success:\n                 message_id = str(uuid.uuid4())\n                 return NotificationResult(\n                     device_token=device_token,\n                     success=True,\n                     message_id=message_id,\n-                    sent_at=datetime.now()\n+                    sent_at=datetime.now(),\n                 )\n             else:\n                 return NotificationResult(\n                     device_token=device_token,\n                     success=False,\n                     error_code=\"InvalidToken\",\n                     error_message=\"Device token is invalid or expired\",\n-                    sent_at=datetime.now()\n+                    sent_at=datetime.now(),\n                 )\n-                \n+\n         except Exception as e:\n             return NotificationResult(\n                 device_token=device_token,\n                 success=False,\n                 error_code=\"SendError\",\n                 error_message=str(e),\n-                sent_at=datetime.now()\n+                sent_at=datetime.now(),\n             )\n-    \n+\n     def _validate_device_token(self, token: str) -> bool:\n         \"\"\"Validate APNs device token format\"\"\"\n         # APNs tokens are 64-character hexadecimal strings\n         if len(token) != 64:\n             return False\n-        \n+\n         try:\n             int(token, 16)  # Try to parse as hex\n             return True\n         except ValueError:\n             return False\n-    \n+\n     def _should_send_notification(\n-        self,\n-        user_id: str,\n-        payload: NotificationPayload\n+        self, user_id: str, payload: NotificationPayload\n     ) -> bool:\n         \"\"\"Check if notification should be sent based on user preferences\"\"\"\n         preferences = self.user_preferences.get(user_id)\n         if not preferences:\n             return True  # Default to sending if no preferences set\n-        \n+\n         # Check if notification type is enabled\n         if payload.notification_type not in preferences.enabled_types:\n             return False\n-        \n+\n         # Check quiet hours\n         if preferences.quiet_hours_start and preferences.quiet_hours_end:\n             current_time = datetime.now().time()\n-            start_time = datetime.strptime(preferences.quiet_hours_start, \"%H:%M\").time()\n+            start_time = datetime.strptime(\n+                preferences.quiet_hours_start, \"%H:%M\"\n+            ).time()\n             end_time = datetime.strptime(preferences.quiet_hours_end, \"%H:%M\").time()\n-            \n+\n             if start_time <= end_time:\n                 # Same day quiet hours\n                 if start_time <= current_time <= end_time:\n                     return False\n             else:\n                 # Overnight quiet hours\n                 if current_time >= start_time or current_time <= end_time:\n                     return False\n-        \n+\n         return True\n+\n \n # Global service instance\n push_notification_service = PushNotificationService()\n \n+\n # Helper functions for easy integration\n-async def send_order_notification(order_data: Dict[str, Any], target_users: List[str] = None):\n+async def send_order_notification(\n+    order_data: Dict[str, Any], target_users: List[str] = None\n+):\n     \"\"\"Send order-related notification\"\"\"\n     await push_notification_service.send_templated_notification(\n         notification_type=NotificationType.ORDER_CREATED,\n         template_data=order_data,\n-        target_users=target_users\n+        target_users=target_users,\n     )\n \n-async def send_payment_notification(payment_data: Dict[str, Any], target_users: List[str] = None):\n+\n+async def send_payment_notification(\n+    payment_data: Dict[str, Any], target_users: List[str] = None\n+):\n     \"\"\"Send payment-related notification\"\"\"\n     notification_type = (\n-        NotificationType.PAYMENT_COMPLETED \n-        if payment_data.get(\"status\") == \"completed\" \n+        NotificationType.PAYMENT_COMPLETED\n+        if payment_data.get(\"status\") == \"completed\"\n         else NotificationType.PAYMENT_FAILED\n     )\n-    \n+\n     await push_notification_service.send_templated_notification(\n         notification_type=notification_type,\n         template_data=payment_data,\n-        target_users=target_users\n+        target_users=target_users,\n     )\n+\n \n async def send_kitchen_alert(alert_data: Dict[str, Any], restaurant_id: str):\n     \"\"\"Send kitchen alert notification\"\"\"\n     await push_notification_service.send_templated_notification(\n         notification_type=NotificationType.KITCHEN_ALERT,\n         template_data=alert_data,\n-        target_restaurants=[restaurant_id]\n+        target_restaurants=[restaurant_id],\n     )\n+\n \n async def send_inventory_alert(inventory_data: Dict[str, Any], restaurant_id: str):\n     \"\"\"Send inventory alert notification\"\"\"\n     await push_notification_service.send_templated_notification(\n         notification_type=NotificationType.INVENTORY_LOW,\n         template_data=inventory_data,\n-        target_restaurants=[restaurant_id]\n+        target_restaurants=[restaurant_id],\n     )\n+\n \n def get_push_service() -> PushNotificationService:\n     \"\"\"Get the global push notification service instance\"\"\"\n-    return push_notification_service\n\\ No newline at end of file\n+    return push_notification_service\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/integration/websocket_events.py\t2025-08-02 21:56:58.999031+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/integration/websocket_events.py\t2025-08-02 22:36:03.466917+00:00\n@@ -11,134 +11,181 @@\n     notify_order_created,\n     notify_order_status_changed,\n     notify_payment_completed,\n     notify_inventory_low,\n     notify_kitchen_update,\n-    notify_user_activity\n+    notify_user_activity,\n )\n+\n \n class WebSocketEventService:\n     \"\"\"Service to integrate backend events with WebSocket notifications\"\"\"\n-    \n+\n     @staticmethod\n     async def on_order_created(order_data: Dict[str, Any]):\n         \"\"\"Handle new order creation event\"\"\"\n         try:\n             await notify_order_created(\n                 order_id=str(order_data[\"id\"]),\n                 restaurant_id=str(order_data[\"restaurant_id\"]),\n-                order_data=order_data\n+                order_data=order_data,\n             )\n         except Exception as e:\n             logger.error(f\"Failed to send order created notification: {str(e)}\")\n-    \n+\n     @staticmethod\n-    async def on_order_status_changed(order_id: str, restaurant_id: str, old_status: str, new_status: str, order_data: Dict[str, Any]):\n+    async def on_order_status_changed(\n+        order_id: str,\n+        restaurant_id: str,\n+        old_status: str,\n+        new_status: str,\n+        order_data: Dict[str, Any],\n+    ):\n         \"\"\"Handle order status change event\"\"\"\n         try:\n             await notify_order_status_changed(\n                 order_id=order_id,\n                 restaurant_id=restaurant_id,\n                 old_status=old_status,\n                 new_status=new_status,\n-                order_data=order_data\n+                order_data=order_data,\n             )\n         except Exception as e:\n             logger.error(f\"Failed to send order status change notification: {str(e)}\")\n-    \n+\n     @staticmethod\n     async def on_payment_completed(payment_data: Dict[str, Any]):\n         \"\"\"Handle payment completion event\"\"\"\n         try:\n             await notify_payment_completed(\n                 payment_id=str(payment_data[\"id\"]),\n                 order_id=str(payment_data[\"order_id\"]),\n                 restaurant_id=str(payment_data[\"restaurant_id\"]),\n-                payment_data=payment_data\n+                payment_data=payment_data,\n             )\n         except Exception as e:\n             logger.error(f\"Failed to send payment completed notification: {str(e)}\")\n-    \n+\n     @staticmethod\n-    async def on_inventory_low(product_id: str, restaurant_id: str, product_name: str, current_stock: int, min_stock: int):\n+    async def on_inventory_low(\n+        product_id: str,\n+        restaurant_id: str,\n+        product_name: str,\n+        current_stock: int,\n+        min_stock: int,\n+    ):\n         \"\"\"Handle low inventory event\"\"\"\n         try:\n             await notify_inventory_low(\n                 product_id=product_id,\n                 restaurant_id=restaurant_id,\n                 product_name=product_name,\n                 current_stock=current_stock,\n-                min_stock=min_stock\n+                min_stock=min_stock,\n             )\n         except Exception as e:\n             logger.error(f\"Failed to send inventory low notification: {str(e)}\")\n-    \n+\n     @staticmethod\n-    async def on_kitchen_update(order_id: str, restaurant_id: str, update_type: str, update_data: Dict[str, Any]):\n+    async def on_kitchen_update(\n+        order_id: str, restaurant_id: str, update_type: str, update_data: Dict[str, Any]\n+    ):\n         \"\"\"Handle kitchen update event\"\"\"\n         try:\n             await notify_kitchen_update(\n                 order_id=order_id,\n                 restaurant_id=restaurant_id,\n                 update_type=update_type,\n-                update_data=update_data\n+                update_data=update_data,\n             )\n         except Exception as e:\n             logger.error(f\"Failed to send kitchen update notification: {str(e)}\")\n-    \n+\n     @staticmethod\n-    async def on_user_login(user_id: str, restaurant_id: str, user_data: Dict[str, Any]):\n+    async def on_user_login(\n+        user_id: str, restaurant_id: str, user_data: Dict[str, Any]\n+    ):\n         \"\"\"Handle user login event\"\"\"\n         try:\n             await notify_user_activity(\n                 user_id=user_id,\n                 restaurant_id=restaurant_id,\n                 activity_type=\"login\",\n-                activity_data=user_data\n+                activity_data=user_data,\n             )\n         except Exception as e:\n             logger.error(f\"Failed to send user login notification: {str(e)}\")\n-    \n+\n     @staticmethod\n-    async def on_user_logout(user_id: str, restaurant_id: str, user_data: Dict[str, Any]):\n+    async def on_user_logout(\n+        user_id: str, restaurant_id: str, user_data: Dict[str, Any]\n+    ):\n         \"\"\"Handle user logout event\"\"\"\n         try:\n             await notify_user_activity(\n                 user_id=user_id,\n                 restaurant_id=restaurant_id,\n                 activity_type=\"logout\",\n-                activity_data=user_data\n+                activity_data=user_data,\n             )\n         except Exception as e:\n             logger.error(f\"Failed to send user logout notification: {str(e)}\")\n \n+\n # Global event service instance\n websocket_events = WebSocketEventService()\n+\n \n # Helper functions for easy integration\n async def emit_order_created(order_data: Dict[str, Any]):\n     \"\"\"Emit order created event\"\"\"\n     await websocket_events.on_order_created(order_data)\n \n-async def emit_order_status_changed(order_id: str, restaurant_id: str, old_status: str, new_status: str, order_data: Dict[str, Any]):\n+\n+async def emit_order_status_changed(\n+    order_id: str,\n+    restaurant_id: str,\n+    old_status: str,\n+    new_status: str,\n+    order_data: Dict[str, Any],\n+):\n     \"\"\"Emit order status changed event\"\"\"\n-    await websocket_events.on_order_status_changed(order_id, restaurant_id, old_status, new_status, order_data)\n+    await websocket_events.on_order_status_changed(\n+        order_id, restaurant_id, old_status, new_status, order_data\n+    )\n+\n \n async def emit_payment_completed(payment_data: Dict[str, Any]):\n     \"\"\"Emit payment completed event\"\"\"\n     await websocket_events.on_payment_completed(payment_data)\n \n-async def emit_inventory_low(product_id: str, restaurant_id: str, product_name: str, current_stock: int, min_stock: int):\n+\n+async def emit_inventory_low(\n+    product_id: str,\n+    restaurant_id: str,\n+    product_name: str,\n+    current_stock: int,\n+    min_stock: int,\n+):\n     \"\"\"Emit inventory low event\"\"\"\n-    await websocket_events.on_inventory_low(product_id, restaurant_id, product_name, current_stock, min_stock)\n+    await websocket_events.on_inventory_low(\n+        product_id, restaurant_id, product_name, current_stock, min_stock\n+    )\n \n-async def emit_kitchen_update(order_id: str, restaurant_id: str, update_type: str, update_data: Dict[str, Any]):\n+\n+async def emit_kitchen_update(\n+    order_id: str, restaurant_id: str, update_type: str, update_data: Dict[str, Any]\n+):\n     \"\"\"Emit kitchen update event\"\"\"\n-    await websocket_events.on_kitchen_update(order_id, restaurant_id, update_type, update_data)\n+    await websocket_events.on_kitchen_update(\n+        order_id, restaurant_id, update_type, update_data\n+    )\n+\n \n async def emit_user_login(user_id: str, restaurant_id: str, user_data: Dict[str, Any]):\n     \"\"\"Emit user login event\"\"\"\n     await websocket_events.on_user_login(user_id, restaurant_id, user_data)\n \n+\n async def emit_user_logout(user_id: str, restaurant_id: str, user_data: Dict[str, Any]):\n     \"\"\"Emit user logout event\"\"\"\n-    await websocket_events.on_user_logout(user_id, restaurant_id, user_data)\n\\ No newline at end of file\n+    await websocket_events.on_user_logout(user_id, restaurant_id, user_data)\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/crud/payments.py\t2025-08-02 19:23:36.823234+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/crud/payments.py\t2025-08-02 22:36:03.464217+00:00\n@@ -7,226 +7,230 @@\n from datetime import datetime, timedelta\n from decimal import Decimal\n from typing import List, Dict, Any\n from ..core.database import Payment, Order\n \n+\n async def get_restaurant_monthly_volume(\n-    restaurant_id: str,\n-    db: Session = None\n+    restaurant_id: str, db: Session = None\n ) -> Decimal:\n     \"\"\"Get restaurant's average monthly transaction volume\"\"\"\n     if not db:\n         # Return default for now - this will be properly implemented later\n         return Decimal(\"2000\")\n-    \n+\n     end_date = datetime.utcnow()\n     start_date = end_date - timedelta(days=90)\n-    \n-    result = db.query(\n-        func.sum(Payment.amount)\n-    ).filter(\n-        and_(\n-            Payment.order_id.in_(\n-                db.query(Order.id).filter(Order.restaurant_id == restaurant_id)\n-            ),\n-            Payment.created_at >= start_date,\n-            Payment.created_at <= end_date,\n-            Payment.status == \"completed\"\n-        )\n-    ).scalar()\n-    \n+\n+    result = (\n+        db.query(func.sum(Payment.amount))\n+        .filter(\n+            and_(\n+                Payment.order_id.in_(\n+                    db.query(Order.id).filter(Order.restaurant_id == restaurant_id)\n+                ),\n+                Payment.created_at >= start_date,\n+                Payment.created_at <= end_date,\n+                Payment.status == \"completed\",\n+            )\n+        )\n+        .scalar()\n+    )\n+\n     if result:\n         return Decimal(str(result)) / Decimal(\"3\")  # 3 months average\n     return Decimal(\"0\")\n \n+\n async def get_provider_analytics(\n-    start_date: str,\n-    end_date: str,\n-    db: Session\n+    start_date: str, end_date: str, db: Session\n ) -> Dict[str, Any]:\n     \"\"\"Get payment provider analytics for date range\"\"\"\n     # Parse dates\n     start = datetime.fromisoformat(start_date)\n     end = datetime.fromisoformat(end_date)\n-    \n+\n     # Get payments by provider\n-    provider_stats = db.query(\n-        Payment.provider,\n-        func.count(Payment.id).label(\"count\"),\n-        func.sum(Payment.amount).label(\"volume\"),\n-        func.sum(Payment.provider_fee).label(\"fees\"),\n-        func.avg(Payment.amount).label(\"avg_transaction\")\n-    ).filter(\n-        and_(\n-            Payment.created_at >= start,\n-            Payment.created_at <= end,\n-            Payment.status == \"completed\"\n-        )\n-    ).group_by(Payment.provider).all()\n-    \n+    provider_stats = (\n+        db.query(\n+            Payment.provider,\n+            func.count(Payment.id).label(\"count\"),\n+            func.sum(Payment.amount).label(\"volume\"),\n+            func.sum(Payment.provider_fee).label(\"fees\"),\n+            func.avg(Payment.amount).label(\"avg_transaction\"),\n+        )\n+        .filter(\n+            and_(\n+                Payment.created_at >= start,\n+                Payment.created_at <= end,\n+                Payment.status == \"completed\",\n+            )\n+        )\n+        .group_by(Payment.provider)\n+        .all()\n+    )\n+\n     # Calculate totals\n     total_volume = sum(stat.volume or 0 for stat in provider_stats)\n     total_fees = sum(stat.fees or 0 for stat in provider_stats)\n-    \n+\n     # Build analytics response\n     by_provider = {}\n     for stat in provider_stats:\n         by_provider[stat.provider] = {\n             \"transaction_count\": stat.count,\n             \"total_volume\": float(stat.volume or 0),\n             \"total_fees\": float(stat.fees or 0),\n             \"average_transaction\": float(stat.avg_transaction or 0),\n             \"effective_rate\": (\n-                float(stat.fees / stat.volume * 100) \n-                if stat.volume else 0\n-            )\n+                float(stat.fees / stat.volume * 100) if stat.volume else 0\n+            ),\n         }\n-    \n+\n     # Calculate potential savings\n     optimal_fees = _calculate_optimal_fees(provider_stats)\n     potential_savings = float(total_fees - optimal_fees)\n-    \n+\n     # Generate recommendations\n     recommendations = _generate_recommendations(by_provider, total_volume)\n-    \n+\n     return {\n         \"by_provider\": by_provider,\n         \"total_volume\": float(total_volume),\n         \"total_fees\": float(total_fees),\n         \"potential_savings\": potential_savings,\n-        \"recommendations\": recommendations\n+        \"recommendations\": recommendations,\n     }\n+\n \n def _calculate_optimal_fees(provider_stats) -> Decimal:\n     \"\"\"Calculate what fees would be with optimal provider selection\"\"\"\n     total_optimal = Decimal(\"0\")\n-    \n+\n     for stat in provider_stats:\n         volume = Decimal(str(stat.volume or 0))\n-        \n+\n         # Calculate optimal provider for this volume\n         if volume >= Decimal(\"2714\"):\n             # SumUp Plus rate\n             optimal_fee = volume * Decimal(\"0.0069\") + Decimal(\"19\")\n         else:\n             # Stripe rate for lower volumes\n             optimal_fee = volume * Decimal(\"0.014\") + (stat.count * Decimal(\"0.20\"))\n-        \n+\n         total_optimal += optimal_fee\n-    \n+\n     return total_optimal\n \n+\n def _generate_recommendations(\n-    by_provider: Dict[str, Any],\n-    total_volume: float\n+    by_provider: Dict[str, Any], total_volume: float\n ) -> List[str]:\n     \"\"\"Generate recommendations based on analytics\"\"\"\n     recommendations = []\n-    \n+\n     monthly_volume = total_volume / 3  # Assuming 3 month period\n-    \n+\n     if monthly_volume >= 2714:\n         if \"sumup\" not in by_provider or by_provider[\"sumup\"][\"transaction_count\"] == 0:\n             recommendations.append(\n                 f\"Your monthly volume of \u00a3{monthly_volume:.2f} qualifies for \"\n                 f\"SumUp Payments Plus at 0.69% + \u00a319/month. \"\n                 f\"Potential savings: \u00a3{(monthly_volume * 0.007):.2f}/month\"\n             )\n-    \n+\n     # Check if using expensive providers\n     for provider, stats in by_provider.items():\n         if stats[\"effective_rate\"] > 1.5:\n             recommendations.append(\n                 f\"Consider reducing usage of {provider} \"\n                 f\"(current rate: {stats['effective_rate']:.2f}%)\"\n             )\n-    \n+\n     return recommendations\n \n+\n async def create_payment_analytics_report(\n-    restaurant_id: str,\n-    db: Session\n+    restaurant_id: str, db: Session\n ) -> Dict[str, Any]:\n     \"\"\"Create comprehensive payment analytics report for restaurant\"\"\"\n     # Get last 12 months of data\n     end_date = datetime.utcnow()\n     start_date = end_date - timedelta(days=365)\n-    \n+\n     # Monthly breakdown\n-    monthly_data = db.query(\n-        func.date_trunc('month', Payment.created_at).label('month'),\n-        Payment.provider,\n-        func.count(Payment.id).label('count'),\n-        func.sum(Payment.amount).label('volume'),\n-        func.sum(Payment.provider_fee).label('fees')\n-    ).join(Order, Payment.order_id == Order.id).filter(\n-        and_(\n-            Order.restaurant_id == restaurant_id,\n-            Payment.created_at >= start_date,\n-            Payment.status == \"completed\"\n-        )\n-    ).group_by('month', Payment.provider).all()\n-    \n+    monthly_data = (\n+        db.query(\n+            func.date_trunc(\"month\", Payment.created_at).label(\"month\"),\n+            Payment.provider,\n+            func.count(Payment.id).label(\"count\"),\n+            func.sum(Payment.amount).label(\"volume\"),\n+            func.sum(Payment.provider_fee).label(\"fees\"),\n+        )\n+        .join(Order, Payment.order_id == Order.id)\n+        .filter(\n+            and_(\n+                Order.restaurant_id == restaurant_id,\n+                Payment.created_at >= start_date,\n+                Payment.status == \"completed\",\n+            )\n+        )\n+        .group_by(\"month\", Payment.provider)\n+        .all()\n+    )\n+\n     # Process into report format\n     report = {\n         \"restaurant_id\": restaurant_id,\n-        \"period\": {\n-            \"start\": start_date.isoformat(),\n-            \"end\": end_date.isoformat()\n-        },\n+        \"period\": {\"start\": start_date.isoformat(), \"end\": end_date.isoformat()},\n         \"monthly_breakdown\": [],\n         \"provider_summary\": {},\n         \"cost_optimization\": {\n             \"current_annual_fees\": 0,\n             \"optimal_annual_fees\": 0,\n-            \"potential_annual_savings\": 0\n-        }\n+            \"potential_annual_savings\": 0,\n+        },\n     }\n-    \n+\n     # Process monthly data\n     for row in monthly_data:\n         month_data = {\n             \"month\": row.month.isoformat(),\n             \"provider\": row.provider,\n             \"transactions\": row.count,\n             \"volume\": float(row.volume or 0),\n-            \"fees\": float(row.fees or 0)\n+            \"fees\": float(row.fees or 0),\n         }\n         report[\"monthly_breakdown\"].append(month_data)\n-        \n+\n         # Update provider summary\n         if row.provider not in report[\"provider_summary\"]:\n             report[\"provider_summary\"][row.provider] = {\n                 \"total_transactions\": 0,\n                 \"total_volume\": 0,\n-                \"total_fees\": 0\n+                \"total_fees\": 0,\n             }\n-        \n+\n         report[\"provider_summary\"][row.provider][\"total_transactions\"] += row.count\n-        report[\"provider_summary\"][row.provider][\"total_volume\"] += float(row.volume or 0)\n+        report[\"provider_summary\"][row.provider][\"total_volume\"] += float(\n+            row.volume or 0\n+        )\n         report[\"provider_summary\"][row.provider][\"total_fees\"] += float(row.fees or 0)\n-    \n+\n     # Calculate cost optimization\n-    total_volume = sum(\n-        p[\"total_volume\"] \n-        for p in report[\"provider_summary\"].values()\n-    )\n-    total_fees = sum(\n-        p[\"total_fees\"] \n-        for p in report[\"provider_summary\"].values()\n-    )\n-    \n+    total_volume = sum(p[\"total_volume\"] for p in report[\"provider_summary\"].values())\n+    total_fees = sum(p[\"total_fees\"] for p in report[\"provider_summary\"].values())\n+\n     # Calculate optimal fees\n     monthly_avg_volume = total_volume / 12\n     if monthly_avg_volume >= 2714:\n         optimal_annual_fees = (total_volume * 0.0069) + (12 * 19)\n     else:\n         optimal_annual_fees = total_volume * 0.014\n-    \n+\n     report[\"cost_optimization\"][\"current_annual_fees\"] = total_fees\n     report[\"cost_optimization\"][\"optimal_annual_fees\"] = optimal_annual_fees\n     report[\"cost_optimization\"][\"potential_annual_savings\"] = max(\n-        0, \n-        total_fees - optimal_annual_fees\n-    )\n-    \n-    return report\n\\ No newline at end of file\n+        0, total_fees - optimal_annual_fees\n+    )\n+\n+    return report\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/websocket_rate_limiter.py\t2025-08-02 21:56:58.998668+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/websocket_rate_limiter.py\t2025-08-02 22:36:03.468993+00:00\n@@ -17,70 +17,70 @@\n \n class WebSocketRateLimiter:\n     \"\"\"\n     Comprehensive rate limiting for WebSocket connections and messages\n     \"\"\"\n-    \n+\n     def __init__(self, redis_client: Optional[RedisClient] = None):\n         self.redis = redis_client\n-        \n+\n         # Configuration\n         self.MAX_CONNECTIONS_PER_IP = 50  # per minute\n         self.MAX_CONNECTIONS_PER_USER = 5  # simultaneous connections\n         self.MAX_MESSAGES_PER_CONNECTION = 60  # per minute\n         self.MAX_MESSAGE_SIZE = 10 * 1024  # 10KB\n-        \n+\n         # Rate limit windows\n         self.CONNECTION_WINDOW = 60  # seconds\n         self.MESSAGE_WINDOW = 60  # seconds\n-        \n+\n         # Penalty system\n         self.VIOLATION_PENALTY_MULTIPLIER = 2  # Double the wait time for violations\n         self.MAX_VIOLATIONS = 5  # Before temporary ban\n         self.TEMP_BAN_DURATION = 300  # 5 minutes\n-        \n+\n         # In-memory fallback if Redis not available\n         self.connection_attempts: Dict[str, Dict[str, any]] = defaultdict(\n             lambda: {\"count\": 0, \"window_start\": time.time(), \"violations\": 0}\n         )\n         self.message_counts: Dict[str, Dict[str, any]] = defaultdict(\n             lambda: {\"count\": 0, \"window_start\": time.time()}\n         )\n         self.active_connections: Dict[str, Set[str]] = defaultdict(set)\n         self.banned_ips: Dict[str, float] = {}  # IP -> ban_until timestamp\n-    \n+\n     async def check_connection_limit(\n-        self, \n-        ip_address: str, \n-        user_id: Optional[str] = None\n+        self, ip_address: str, user_id: Optional[str] = None\n     ) -> Tuple[bool, Optional[str]]:\n         \"\"\"\n         Check if a new connection is allowed\n-        \n+\n         Returns:\n             Tuple[bool, Optional[str]]: (is_allowed, error_message)\n         \"\"\"\n         # Check if IP is temporarily banned\n         if ip_address in self.banned_ips:\n             if time.time() < self.banned_ips[ip_address]:\n                 remaining = int(self.banned_ips[ip_address] - time.time())\n                 return False, f\"Temporarily banned. Try again in {remaining} seconds\"\n             else:\n                 del self.banned_ips[ip_address]\n-        \n+\n         # Check IP-based rate limit\n         if self.redis:\n             try:\n                 key = f\"ws:conn:ip:{ip_address}\"\n                 current = await self.redis.get(key)\n                 current_count = int(current) if current else 0\n-                \n+\n                 if current_count >= self.MAX_CONNECTIONS_PER_IP:\n                     await self._record_violation(ip_address)\n                     return False, \"Too many connection attempts from this IP\"\n-                \n-                await self.redis.set(key, current_count + 1, expire=self.CONNECTION_WINDOW)\n+\n+                await self.redis.set(\n+                    key, current_count + 1, expire=self.CONNECTION_WINDOW\n+                )\n             except Exception as e:\n                 logger.error(f\"Redis error in connection rate limit: {e}\")\n                 # In production, fail closed\n                 if settings.ENVIRONMENT not in [\"development\", \"testing\", \"local\"]:\n                     return False, \"Rate limiting service temporarily unavailable\"\n@@ -88,58 +88,62 @@\n         else:\n             # In-memory rate limiting (dev only)\n             if settings.ENVIRONMENT not in [\"development\", \"testing\", \"local\"]:\n                 # Production without Redis - fail closed\n                 return False, \"Rate limiting service unavailable\"\n-                \n+\n             now = time.time()\n             tracker = self.connection_attempts[ip_address]\n-            \n+\n             # Reset window if expired\n             if now - tracker[\"window_start\"] > self.CONNECTION_WINDOW:\n                 tracker[\"count\"] = 0\n                 tracker[\"window_start\"] = now\n-            \n+\n             if tracker[\"count\"] >= self.MAX_CONNECTIONS_PER_IP:\n                 await self._record_violation(ip_address)\n                 return False, \"Too many connection attempts from this IP\"\n-            \n+\n             tracker[\"count\"] += 1\n-        \n+\n         # Check user connection limit if authenticated\n         if user_id:\n             active_count = len(self.active_connections.get(user_id, set()))\n             if active_count >= self.MAX_CONNECTIONS_PER_USER:\n-                return False, f\"Maximum {self.MAX_CONNECTIONS_PER_USER} simultaneous connections allowed\"\n-        \n+                return (\n+                    False,\n+                    f\"Maximum {self.MAX_CONNECTIONS_PER_USER} simultaneous connections allowed\",\n+                )\n+\n         return True, None\n-    \n+\n     async def check_message_rate(\n-        self, \n-        connection_id: str,\n-        message_size: int\n+        self, connection_id: str, message_size: int\n     ) -> Tuple[bool, Optional[str]]:\n         \"\"\"\n         Check if a message is allowed based on rate limits\n-        \n+\n         Returns:\n             Tuple[bool, Optional[str]]: (is_allowed, error_message)\n         \"\"\"\n         # Check message size\n         if message_size > self.MAX_MESSAGE_SIZE:\n-            return False, f\"Message too large. Maximum size: {self.MAX_MESSAGE_SIZE} bytes\"\n-        \n+            return (\n+                False,\n+                f\"Message too large. Maximum size: {self.MAX_MESSAGE_SIZE} bytes\",\n+            )\n+\n         # Check message rate\n         if self.redis:\n             try:\n                 key = f\"ws:msg:conn:{connection_id}\"\n                 current = await self.redis.get(key)\n                 current_count = int(current) if current else 0\n-                \n+\n                 if current_count >= self.MAX_MESSAGES_PER_CONNECTION:\n                     return False, \"Message rate limit exceeded\"\n-                \n+\n                 await self.redis.set(key, current_count + 1, expire=self.MESSAGE_WINDOW)\n             except Exception as e:\n                 logger.error(f\"Redis error in message rate limit: {e}\")\n                 # In production, fail closed\n                 if settings.ENVIRONMENT not in [\"development\", \"testing\", \"local\"]:\n@@ -148,113 +152,115 @@\n         else:\n             # In-memory rate limiting (dev only)\n             if settings.ENVIRONMENT not in [\"development\", \"testing\", \"local\"]:\n                 # Production without Redis - fail closed\n                 return False, \"Rate limiting service unavailable\"\n-                \n+\n             now = time.time()\n             tracker = self.message_counts[connection_id]\n-            \n+\n             # Reset window if expired\n             if now - tracker[\"window_start\"] > self.MESSAGE_WINDOW:\n                 tracker[\"count\"] = 0\n                 tracker[\"window_start\"] = now\n-            \n+\n             if tracker[\"count\"] >= self.MAX_MESSAGES_PER_CONNECTION:\n                 return False, \"Message rate limit exceeded\"\n-            \n+\n             tracker[\"count\"] += 1\n-        \n+\n         return True, None\n-    \n-    async def register_connection(self, connection_id: str, user_id: Optional[str], ip_address: str):\n+\n+    async def register_connection(\n+        self, connection_id: str, user_id: Optional[str], ip_address: str\n+    ):\n         \"\"\"Register a new active connection\"\"\"\n         if user_id:\n             self.active_connections[user_id].add(connection_id)\n-        \n+\n         # Log for security monitoring\n         logger.info(\n             f\"WebSocket connection established - \"\n             f\"ID: {connection_id}, User: {user_id or 'anonymous'}, IP: {ip_address}\"\n         )\n-    \n+\n     async def unregister_connection(self, connection_id: str, user_id: Optional[str]):\n         \"\"\"Remove a closed connection\"\"\"\n         if user_id and user_id in self.active_connections:\n             self.active_connections[user_id].discard(connection_id)\n             if not self.active_connections[user_id]:\n                 del self.active_connections[user_id]\n-        \n+\n         # Clean up message tracking\n         if connection_id in self.message_counts:\n             del self.message_counts[connection_id]\n-        \n+\n         logger.info(f\"WebSocket connection closed - ID: {connection_id}\")\n-    \n+\n     async def _record_violation(self, ip_address: str):\n         \"\"\"Record a rate limit violation and apply penalties\"\"\"\n         if ip_address in self.connection_attempts:\n             self.connection_attempts[ip_address][\"violations\"] += 1\n             violations = self.connection_attempts[ip_address][\"violations\"]\n-            \n-            logger.warning(\n-                f\"Rate limit violation #{violations} from IP: {ip_address}\"\n-            )\n-            \n+\n+            logger.warning(f\"Rate limit violation #{violations} from IP: {ip_address}\")\n+\n             # Apply temporary ban after max violations\n             if violations >= self.MAX_VIOLATIONS:\n                 self.banned_ips[ip_address] = time.time() + self.TEMP_BAN_DURATION\n                 logger.warning(\n                     f\"IP {ip_address} temporarily banned for {self.TEMP_BAN_DURATION} seconds\"\n                 )\n-    \n+\n     async def get_rate_limit_info(self, connection_id: str) -> Dict[str, any]:\n         \"\"\"Get current rate limit status for a connection\"\"\"\n         if connection_id in self.message_counts:\n             tracker = self.message_counts[connection_id]\n             remaining = self.MAX_MESSAGES_PER_CONNECTION - tracker[\"count\"]\n-            reset_in = max(0, self.MESSAGE_WINDOW - (time.time() - tracker[\"window_start\"]))\n-            \n+            reset_in = max(\n+                0, self.MESSAGE_WINDOW - (time.time() - tracker[\"window_start\"])\n+            )\n+\n             return {\n                 \"messages_remaining\": max(0, remaining),\n                 \"reset_in_seconds\": int(reset_in),\n                 \"max_messages\": self.MAX_MESSAGES_PER_CONNECTION,\n-                \"window_seconds\": self.MESSAGE_WINDOW\n+                \"window_seconds\": self.MESSAGE_WINDOW,\n             }\n-        \n+\n         return {\n             \"messages_remaining\": self.MAX_MESSAGES_PER_CONNECTION,\n             \"reset_in_seconds\": self.MESSAGE_WINDOW,\n             \"max_messages\": self.MAX_MESSAGES_PER_CONNECTION,\n-            \"window_seconds\": self.MESSAGE_WINDOW\n+            \"window_seconds\": self.MESSAGE_WINDOW,\n         }\n-    \n+\n     async def cleanup_expired_data(self):\n         \"\"\"Periodic cleanup of expired tracking data\"\"\"\n         now = time.time()\n-        \n+\n         # Clean up connection attempts\n         expired_ips = []\n         for ip, data in self.connection_attempts.items():\n             if now - data[\"window_start\"] > self.CONNECTION_WINDOW * 2:\n                 expired_ips.append(ip)\n-        \n+\n         for ip in expired_ips:\n             del self.connection_attempts[ip]\n-        \n+\n         # Clean up expired bans\n         expired_bans = [ip for ip, until in self.banned_ips.items() if now > until]\n         for ip in expired_bans:\n             del self.banned_ips[ip]\n-        \n+\n         # Clean up message counts for closed connections\n         # This is handled in unregister_connection()\n-        \n+\n         if expired_ips or expired_bans:\n             logger.debug(\n                 f\"Cleaned up {len(expired_ips)} connection trackers \"\n                 f\"and {len(expired_bans)} expired bans\"\n             )\n \n \n # Global rate limiter instance\n-websocket_rate_limiter = WebSocketRateLimiter()\n\\ No newline at end of file\n+websocket_rate_limiter = WebSocketRateLimiter()\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/main_minimal.py\t2025-08-02 21:56:58.999389+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/main_minimal.py\t2025-08-02 22:36:03.472774+00:00\n@@ -8,88 +8,95 @@\n from fastapi.middleware.cors import CORSMiddleware\n from datetime import datetime\n \n # Create minimal FastAPI app\n app = FastAPI(\n-title=\"Fynlo POS Backend\",\n-description=\"Hardware-Free Restaurant Management Platform\",\n-version=\"1.0.0\"\n+    title=\"Fynlo POS Backend\",\n+    description=\"Hardware-Free Restaurant Management Platform\",\n+    version=\"1.0.0\",\n )\n \n # Add CORS middleware\n app.add_middleware(\n-CORSMiddleware,\n-allow_origins=[\"*\"],  # Permissive for now\n-allow_credentials=True,\n-allow_methods=[\"*\"],\n-allow_headers=[\"*\"],\n+    CORSMiddleware,\n+    allow_origins=[\"*\"],  # Permissive for now\n+    allow_credentials=True,\n+    allow_methods=[\"*\"],\n+    allow_headers=[\"*\"],\n )\n+\n \n @app.get(\"/\")\n async def root():\n     \"\"\"Root endpoint\"\"\"\n     return {\n-    \"service\": \"Fynlo POS Backend API\",\n-    \"version\": \"1.0.0\",\n-    \"status\": \"healthy\",\n-    \"timestamp\": datetime.now().isoformat(),\n-    \"message\": \"Fynlo POS API is running\"\n+        \"service\": \"Fynlo POS Backend API\",\n+        \"version\": \"1.0.0\",\n+        \"status\": \"healthy\",\n+        \"timestamp\": datetime.now().isoformat(),\n+        \"message\": \"Fynlo POS API is running\",\n     }\n+\n \n @app.get(\"/health\")\n async def health_check():\n     \"\"\"Health check endpoint for DigitalOcean\"\"\"\n     return {\n         \"status\": \"healthy\",\n         \"service\": \"fynlo-pos-backend\",\n         \"version\": \"1.0.0\",\n         \"timestamp\": datetime.now().isoformat(),\n         \"environment\": os.environ.get(\"ENVIRONMENT\", \"production\"),\n-        \"port\": os.environ.get(\"PORT\", \"8080\")\n+        \"port\": os.environ.get(\"PORT\", \"8080\"),\n     }\n+\n \n @app.get(\"/api/v1/health\")\n async def api_health():\n     \"\"\"API health check\"\"\"\n     return {\n         \"api_version\": \"v1\",\n         \"status\": \"operational\",\n         \"endpoints\": \"available\",\n-        \"timestamp\": datetime.now().isoformat()\n+        \"timestamp\": datetime.now().isoformat(),\n     }\n+\n \n # Authentication removed - use Supabase auth at /api/v1/auth/verify instead\n # See BREAKING_CHANGES.md for migration guide\n+\n \n # Menu endpoints\n @app.get(\"/api/v1/menu/items\")\n async def get_menu_items():\n     \"\"\"Get menu items\"\"\"\n     return {\n         \"success\": True,\n         \"data\": [\n             {\"id\": 1, \"name\": \"Tacos\", \"price\": 8.99, \"category\": \"Main\"},\n             {\"id\": 2, \"name\": \"Burrito\", \"price\": 12.99, \"category\": \"Main\"},\n-            {\"id\": 3, \"name\": \"Nachos\", \"price\": 9.99, \"category\": \"Appetizer\"}\n+            {\"id\": 3, \"name\": \"Nachos\", \"price\": 9.99, \"category\": \"Appetizer\"},\n         ],\n         \"message\": \"Menu items retrieved\",\n-        \"timestamp\": datetime.now().isoformat()\n+        \"timestamp\": datetime.now().isoformat(),\n     }\n+\n \n @app.get(\"/api/v1/menu/categories\")\n async def get_menu_categories():\n     \"\"\"Get menu categories\"\"\"\n     return {\n         \"success\": True,\n         \"data\": [\n             {\"id\": 1, \"name\": \"Main\", \"description\": \"Main courses\"},\n             {\"id\": 2, \"name\": \"Appetizer\", \"description\": \"Appetizers\"},\n-            {\"id\": 3, \"name\": \"Beverage\", \"description\": \"Drinks\"}\n+            {\"id\": 3, \"name\": \"Beverage\", \"description\": \"Drinks\"},\n         ],\n         \"message\": \"Menu categories retrieved\",\n-        \"timestamp\": datetime.now().isoformat()\n+        \"timestamp\": datetime.now().isoformat(),\n     }\n+\n \n # Employee endpoints\n @app.get(\"/api/v1/employees\")\n async def get_employees():\n     \"\"\"Get employees\"\"\"\n@@ -102,26 +109,28 @@\n                 \"email\": \"john@restaurant.com\",\n                 \"role\": \"manager\",\n                 \"hourlyRate\": 25.00,\n                 \"totalSales\": 15420.50,\n                 \"performanceScore\": 9.2,\n-                \"isActive\": True\n+                \"isActive\": True,\n             },\n             {\n                 \"id\": 2,\n                 \"name\": \"Sarah Cashier\",\n                 \"email\": \"sarah@restaurant.com\",\n                 \"role\": \"cashier\",\n                 \"hourlyRate\": 15.50,\n                 \"totalSales\": 8750.25,\n                 \"performanceScore\": 8.8,\n-                \"isActive\": True\n-            }\n+                \"isActive\": True,\n+            },\n         ],\n         \"message\": \"Employees retrieved\",\n-        \"timestamp\": datetime.now().isoformat()\n+        \"timestamp\": datetime.now().isoformat(),\n     }\n+\n \n if __name__ == \"__main__\":\n     import uvicorn\n+\n     port = int(os.environ.get(\"PORT\", 8000))\n-    uvicorn.run(app, host=\"0.0.0.0\", port=port)\n\\ No newline at end of file\n+    uvicorn.run(app, host=\"0.0.0.0\", port=port)\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/main_simple.py\t2025-08-02 10:59:17.995189+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/main_simple.py\t2025-08-02 22:36:03.487583+00:00\n@@ -16,11 +16,11 @@\n # Create FastAPI app with minimal configuration\n app = FastAPI(\n     title=\"Fynlo POS Backend\",\n     description=\"Hardware-Free Restaurant Management Platform\",\n     version=\"1.0.0\",\n-    debug=False\n+    debug=False,\n )\n \n # CORS middleware for React Native frontend\n app.add_middleware(\n     CORSMiddleware,\n@@ -28,46 +28,44 @@\n     allow_credentials=True,\n     allow_methods=[\"*\"],\n     allow_headers=[\"*\"],\n )\n \n+\n @app.get(\"/\")\n async def root():\n     \"\"\"Root endpoint\"\"\"\n     return {\n         \"service\": \"Fynlo POS Backend API\",\n         \"version\": \"1.0.0\",\n         \"status\": \"healthy\",\n-        \"message\": \"Fynlo POS API is running\"\n+        \"message\": \"Fynlo POS API is running\",\n     }\n+\n \n @app.get(\"/health\")\n async def health_check():\n     \"\"\"Health check endpoint for DigitalOcean\"\"\"\n     return {\n         \"status\": \"healthy\",\n         \"service\": \"fynlo-pos-backend\",\n         \"version\": \"1.0.0\",\n-        \"timestamp\": \"2025-01-08\"\n+        \"timestamp\": \"2025-01-08\",\n     }\n+\n \n @app.get(\"/api/v1/health\")\n async def api_health():\n     \"\"\"API health check\"\"\"\n-    return {\n-        \"api_version\": \"v1\",\n-        \"status\": \"operational\",\n-        \"endpoints\": \"available\"\n-    }\n+    return {\"api_version\": \"v1\", \"status\": \"operational\", \"endpoints\": \"available\"}\n+\n \n # Basic auth endpoint for testing\n @app.post(\"/api/v1/auth/login\")\n async def login():\n     \"\"\"Basic login endpoint\"\"\"\n-    return {\n-        \"message\": \"Authentication endpoint available\",\n-        \"status\": \"ready\"\n-    }\n+    return {\"message\": \"Authentication endpoint available\", \"status\": \"ready\"}\n+\n \n if __name__ == \"__main__\":\n     port = int(os.environ.get(\"PORT\", 8000))\n-    uvicorn.run(app, host=\"0.0.0.0\", port=port)\n\\ No newline at end of file\n+    uvicorn.run(app, host=\"0.0.0.0\", port=port)\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/integration/notification_events.py\t2025-08-02 21:56:58.998852+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/integration/notification_events.py\t2025-08-02 22:36:03.491300+00:00\n@@ -11,306 +11,380 @@\n     get_push_service,\n     send_order_notification,\n     send_payment_notification,\n     send_kitchen_alert,\n     send_inventory_alert,\n-    NotificationType\n+    NotificationType,\n )\n+\n \n class NotificationEventService:\n     \"\"\"Service to integrate backend events with push notifications\"\"\"\n-    \n+\n     @staticmethod\n     async def on_order_created(order_data: Dict[str, Any]):\n         \"\"\"Handle new order creation event\"\"\"\n         try:\n             # Prepare notification data\n             notification_data = {\n                 \"order_id\": str(order_data[\"id\"]),\n                 \"order_number\": order_data.get(\"order_number\", \"N/A\"),\n                 \"total_amount\": order_data.get(\"total_amount\", 0),\n                 \"customer_name\": order_data.get(\"customer_name\", \"Guest\"),\n-                \"restaurant_id\": str(order_data[\"restaurant_id\"])\n-            }\n-            \n+                \"restaurant_id\": str(order_data[\"restaurant_id\"]),\n+            }\n+\n             # Send to kitchen staff and managers\n             push_service = get_push_service()\n             await push_service.send_templated_notification(\n                 notification_type=NotificationType.ORDER_CREATED,\n                 template_data=notification_data,\n-                target_restaurants=[str(order_data[\"restaurant_id\"])]\n-            )\n-            \n+                target_restaurants=[str(order_data[\"restaurant_id\"])],\n+            )\n+\n         except Exception as e:\n             logger.error(f\"Failed to send order created notification: {str(e)}\")\n-    \n-    @staticmethod\n-    async def on_order_status_changed(order_id: str, restaurant_id: str, old_status: str, new_status: str, order_data: Dict[str, Any]):\n+\n+    @staticmethod\n+    async def on_order_status_changed(\n+        order_id: str,\n+        restaurant_id: str,\n+        old_status: str,\n+        new_status: str,\n+        order_data: Dict[str, Any],\n+    ):\n         \"\"\"Handle order status change event\"\"\"\n         try:\n             # Prepare notification data\n             notification_data = {\n                 \"order_id\": order_id,\n                 \"order_number\": order_data.get(\"order_number\", \"N/A\"),\n                 \"status\": new_status,\n-                \"restaurant_id\": restaurant_id\n-            }\n-            \n+                \"restaurant_id\": restaurant_id,\n+            }\n+\n             # Send to relevant staff based on status change\n             push_service = get_push_service()\n-            \n+\n             # Different notifications for different status changes\n             if new_status == \"ready\":\n                 # Notify customer if they have the app\n                 customer_data = notification_data.copy()\n                 customer_data[\"pickup_code\"] = order_data.get(\"pickup_code\", \"\")\n-                \n+\n                 await push_service.send_templated_notification(\n                     notification_type=NotificationType.CUSTOMER_ORDER_READY,\n                     template_data=customer_data,\n-                    target_users=[order_data.get(\"customer_id\")] if order_data.get(\"customer_id\") else None\n+                    target_users=(\n+                        [order_data.get(\"customer_id\")]\n+                        if order_data.get(\"customer_id\")\n+                        else None\n+                    ),\n                 )\n-            \n+\n             # Always notify restaurant staff\n             await push_service.send_templated_notification(\n                 notification_type=NotificationType.ORDER_STATUS_CHANGED,\n                 template_data=notification_data,\n-                target_restaurants=[restaurant_id]\n-            )\n-            \n+                target_restaurants=[restaurant_id],\n+            )\n+\n         except Exception as e:\n             logger.error(f\"Failed to send order status change notification: {str(e)}\")\n-    \n+\n     @staticmethod\n     async def on_payment_completed(payment_data: Dict[str, Any]):\n         \"\"\"Handle payment completion event\"\"\"\n         try:\n             # Prepare notification data\n             notification_data = {\n                 \"payment_id\": str(payment_data[\"id\"]),\n                 \"order_id\": str(payment_data[\"order_id\"]),\n                 \"order_number\": payment_data.get(\"order_number\", \"N/A\"),\n                 \"amount\": payment_data.get(\"amount\", 0),\n-                \"restaurant_id\": str(payment_data[\"restaurant_id\"])\n-            }\n-            \n+                \"restaurant_id\": str(payment_data[\"restaurant_id\"]),\n+            }\n+\n             # Send to managers and cashiers\n             push_service = get_push_service()\n             await push_service.send_templated_notification(\n                 notification_type=NotificationType.PAYMENT_COMPLETED,\n                 template_data=notification_data,\n-                target_restaurants=[str(payment_data[\"restaurant_id\"])]\n-            )\n-            \n+                target_restaurants=[str(payment_data[\"restaurant_id\"])],\n+            )\n+\n         except Exception as e:\n             logger.error(f\"Failed to send payment completed notification: {str(e)}\")\n-    \n+\n     @staticmethod\n     async def on_payment_failed(payment_data: Dict[str, Any]):\n         \"\"\"Handle payment failure event\"\"\"\n         try:\n             # Prepare notification data\n             notification_data = {\n                 \"payment_id\": str(payment_data[\"id\"]),\n                 \"order_id\": str(payment_data[\"order_id\"]),\n                 \"order_number\": payment_data.get(\"order_number\", \"N/A\"),\n                 \"amount\": payment_data.get(\"amount\", 0),\n-                \"error_reason\": payment_data.get(\"error_message\", \"Payment processing failed\"),\n-                \"restaurant_id\": str(payment_data[\"restaurant_id\"])\n-            }\n-            \n+                \"error_reason\": payment_data.get(\n+                    \"error_message\", \"Payment processing failed\"\n+                ),\n+                \"restaurant_id\": str(payment_data[\"restaurant_id\"]),\n+            }\n+\n             # Send critical alert to managers\n             push_service = get_push_service()\n             await push_service.send_templated_notification(\n                 notification_type=NotificationType.PAYMENT_FAILED,\n                 template_data=notification_data,\n-                target_restaurants=[str(payment_data[\"restaurant_id\"])]\n-            )\n-            \n+                target_restaurants=[str(payment_data[\"restaurant_id\"])],\n+            )\n+\n         except Exception as e:\n             logger.error(f\"Failed to send payment failed notification: {str(e)}\")\n-    \n-    @staticmethod\n-    async def on_inventory_low(product_id: str, restaurant_id: str, product_name: str, current_stock: int, min_stock: int):\n+\n+    @staticmethod\n+    async def on_inventory_low(\n+        product_id: str,\n+        restaurant_id: str,\n+        product_name: str,\n+        current_stock: int,\n+        min_stock: int,\n+    ):\n         \"\"\"Handle low inventory event\"\"\"\n         try:\n             # Prepare notification data\n             notification_data = {\n                 \"product_id\": product_id,\n                 \"product_name\": product_name,\n                 \"current_stock\": current_stock,\n                 \"min_stock\": min_stock,\n-                \"restaurant_id\": restaurant_id\n-            }\n-            \n+                \"restaurant_id\": restaurant_id,\n+            }\n+\n             # Send to managers and inventory staff\n             push_service = get_push_service()\n             await push_service.send_templated_notification(\n                 notification_type=NotificationType.INVENTORY_LOW,\n                 template_data=notification_data,\n-                target_restaurants=[restaurant_id]\n-            )\n-            \n+                target_restaurants=[restaurant_id],\n+            )\n+\n         except Exception as e:\n             logger.error(f\"Failed to send inventory low notification: {str(e)}\")\n-    \n-    @staticmethod\n-    async def on_kitchen_alert(order_id: str, restaurant_id: str, alert_type: str, alert_message: str):\n+\n+    @staticmethod\n+    async def on_kitchen_alert(\n+        order_id: str, restaurant_id: str, alert_type: str, alert_message: str\n+    ):\n         \"\"\"Handle kitchen alert event\"\"\"\n         try:\n             # Prepare notification data\n             notification_data = {\n                 \"order_id\": order_id,\n                 \"alert_type\": alert_type,\n                 \"alert_message\": alert_message,\n-                \"restaurant_id\": restaurant_id\n-            }\n-            \n+                \"restaurant_id\": restaurant_id,\n+            }\n+\n             # Send to kitchen staff and managers\n             push_service = get_push_service()\n             await push_service.send_templated_notification(\n                 notification_type=NotificationType.KITCHEN_ALERT,\n                 template_data=notification_data,\n-                target_restaurants=[restaurant_id]\n-            )\n-            \n+                target_restaurants=[restaurant_id],\n+            )\n+\n         except Exception as e:\n             logger.error(f\"Failed to send kitchen alert notification: {str(e)}\")\n-    \n-    @staticmethod\n-    async def on_shift_reminder(user_id: str, restaurant_id: str, shift_data: Dict[str, Any]):\n+\n+    @staticmethod\n+    async def on_shift_reminder(\n+        user_id: str, restaurant_id: str, shift_data: Dict[str, Any]\n+    ):\n         \"\"\"Handle shift reminder event\"\"\"\n         try:\n             # Calculate time until shift\n-            shift_start = datetime.fromisoformat(shift_data[\"start_time\"].replace(\"Z\", \"+00:00\"))\n+            shift_start = datetime.fromisoformat(\n+                shift_data[\"start_time\"].replace(\"Z\", \"+00:00\")\n+            )\n             time_until = int((shift_start - datetime.now()).total_seconds() / 60)\n-            \n+\n             # Prepare notification data\n             notification_data = {\n                 \"shift_id\": str(shift_data[\"id\"]),\n                 \"shift_start\": shift_data[\"start_time\"],\n                 \"time_until\": time_until,\n-                \"restaurant_id\": restaurant_id\n-            }\n-            \n+                \"restaurant_id\": restaurant_id,\n+            }\n+\n             # Send to specific user\n             push_service = get_push_service()\n             await push_service.send_templated_notification(\n                 notification_type=NotificationType.SHIFT_REMINDER,\n                 template_data=notification_data,\n-                target_users=[user_id]\n-            )\n-            \n+                target_users=[user_id],\n+            )\n+\n         except Exception as e:\n             logger.error(f\"Failed to send shift reminder notification: {str(e)}\")\n-    \n-    @staticmethod\n-    async def on_system_maintenance(restaurant_ids: List[str], maintenance_data: Dict[str, Any]):\n+\n+    @staticmethod\n+    async def on_system_maintenance(\n+        restaurant_ids: List[str], maintenance_data: Dict[str, Any]\n+    ):\n         \"\"\"Handle system maintenance event\"\"\"\n         try:\n             # Prepare notification data\n             notification_data = {\n                 \"maintenance_type\": maintenance_data.get(\"type\", \"System Update\"),\n-                \"maintenance_message\": maintenance_data.get(\"message\", \"System maintenance in progress\"),\n-                \"estimated_duration\": maintenance_data.get(\"duration\", \"30 minutes\")\n-            }\n-            \n+                \"maintenance_message\": maintenance_data.get(\n+                    \"message\", \"System maintenance in progress\"\n+                ),\n+                \"estimated_duration\": maintenance_data.get(\"duration\", \"30 minutes\"),\n+            }\n+\n             # Send to all affected restaurants\n             push_service = get_push_service()\n             await push_service.send_templated_notification(\n                 notification_type=NotificationType.SYSTEM_MAINTENANCE,\n                 template_data=notification_data,\n-                target_restaurants=restaurant_ids\n-            )\n-            \n+                target_restaurants=restaurant_ids,\n+            )\n+\n         except Exception as e:\n             logger.error(f\"Failed to send system maintenance notification: {str(e)}\")\n-    \n-    @staticmethod\n-    async def on_delivery_update(order_id: str, customer_id: str, delivery_status: str, estimated_arrival: Optional[str] = None):\n+\n+    @staticmethod\n+    async def on_delivery_update(\n+        order_id: str,\n+        customer_id: str,\n+        delivery_status: str,\n+        estimated_arrival: Optional[str] = None,\n+    ):\n         \"\"\"Handle delivery status update event\"\"\"\n         try:\n             # Prepare notification data\n             notification_data = {\n                 \"order_id\": order_id,\n                 \"delivery_status\": delivery_status,\n-                \"estimated_arrival\": estimated_arrival or \"Unknown\"\n-            }\n-            \n+                \"estimated_arrival\": estimated_arrival or \"Unknown\",\n+            }\n+\n             # Send to customer\n             push_service = get_push_service()\n             await push_service.send_templated_notification(\n                 notification_type=NotificationType.DELIVERY_UPDATE,\n                 template_data=notification_data,\n-                target_users=[customer_id]\n-            )\n-            \n+                target_users=[customer_id],\n+            )\n+\n         except Exception as e:\n             logger.error(f\"Failed to send delivery update notification: {str(e)}\")\n-    \n-    @staticmethod\n-    async def schedule_shift_reminders(restaurant_id: str, shifts: List[Dict[str, Any]]):\n+\n+    @staticmethod\n+    async def schedule_shift_reminders(\n+        restaurant_id: str, shifts: List[Dict[str, Any]]\n+    ):\n         \"\"\"Schedule shift reminder notifications\"\"\"\n         try:\n             for shift in shifts:\n                 # Calculate reminder time (30 minutes before shift)\n-                shift_start = datetime.fromisoformat(shift[\"start_time\"].replace(\"Z\", \"+00:00\"))\n+                shift_start = datetime.fromisoformat(\n+                    shift[\"start_time\"].replace(\"Z\", \"+00:00\")\n+                )\n                 reminder_time = shift_start - timedelta(minutes=30)\n-                \n+\n                 if reminder_time > datetime.now():\n                     # Schedule the reminder\n                     delay = (reminder_time - datetime.now()).total_seconds()\n-                    \n+\n                     # In a real implementation, this would use a task queue like Celery\n                     # For now, we'll use asyncio.create_task for demonstration\n                     asyncio.create_task(\n                         NotificationEventService._delayed_shift_reminder(\n                             delay, shift[\"user_id\"], restaurant_id, shift\n                         )\n                     )\n-            \n+\n         except Exception as e:\n             logger.error(f\"Failed to schedule shift reminders: {str(e)}\")\n-    \n-    @staticmethod\n-    async def _delayed_shift_reminder(delay: float, user_id: str, restaurant_id: str, shift_data: Dict[str, Any]):\n+\n+    @staticmethod\n+    async def _delayed_shift_reminder(\n+        delay: float, user_id: str, restaurant_id: str, shift_data: Dict[str, Any]\n+    ):\n         \"\"\"Send delayed shift reminder\"\"\"\n         try:\n             await asyncio.sleep(delay)\n-            await NotificationEventService.on_shift_reminder(user_id, restaurant_id, shift_data)\n+            await NotificationEventService.on_shift_reminder(\n+                user_id, restaurant_id, shift_data\n+            )\n         except Exception as e:\n             logger.error(f\"Failed to send delayed shift reminder: {str(e)}\")\n+\n \n # Global event service instance\n notification_events = NotificationEventService()\n+\n \n # Helper functions for easy integration\n async def emit_order_created_notification(order_data: Dict[str, Any]):\n     \"\"\"Emit order created notification\"\"\"\n     await notification_events.on_order_created(order_data)\n \n-async def emit_order_status_notification(order_id: str, restaurant_id: str, old_status: str, new_status: str, order_data: Dict[str, Any]):\n+\n+async def emit_order_status_notification(\n+    order_id: str,\n+    restaurant_id: str,\n+    old_status: str,\n+    new_status: str,\n+    order_data: Dict[str, Any],\n+):\n     \"\"\"Emit order status change notification\"\"\"\n-    await notification_events.on_order_status_changed(order_id, restaurant_id, old_status, new_status, order_data)\n+    await notification_events.on_order_status_changed(\n+        order_id, restaurant_id, old_status, new_status, order_data\n+    )\n+\n \n async def emit_payment_notification(payment_data: Dict[str, Any], success: bool = True):\n     \"\"\"Emit payment notification\"\"\"\n     if success:\n         await notification_events.on_payment_completed(payment_data)\n     else:\n         await notification_events.on_payment_failed(payment_data)\n \n-async def emit_inventory_notification(product_id: str, restaurant_id: str, product_name: str, current_stock: int, min_stock: int):\n+\n+async def emit_inventory_notification(\n+    product_id: str,\n+    restaurant_id: str,\n+    product_name: str,\n+    current_stock: int,\n+    min_stock: int,\n+):\n     \"\"\"Emit inventory low notification\"\"\"\n-    await notification_events.on_inventory_low(product_id, restaurant_id, product_name, current_stock, min_stock)\n-\n-async def emit_kitchen_alert_notification(order_id: str, restaurant_id: str, alert_type: str, alert_message: str):\n+    await notification_events.on_inventory_low(\n+        product_id, restaurant_id, product_name, current_stock, min_stock\n+    )\n+\n+\n+async def emit_kitchen_alert_notification(\n+    order_id: str, restaurant_id: str, alert_type: str, alert_message: str\n+):\n     \"\"\"Emit kitchen alert notification\"\"\"\n-    await notification_events.on_kitchen_alert(order_id, restaurant_id, alert_type, alert_message)\n-\n-async def emit_system_maintenance_notification(restaurant_ids: List[str], maintenance_data: Dict[str, Any]):\n+    await notification_events.on_kitchen_alert(\n+        order_id, restaurant_id, alert_type, alert_message\n+    )\n+\n+\n+async def emit_system_maintenance_notification(\n+    restaurant_ids: List[str], maintenance_data: Dict[str, Any]\n+):\n     \"\"\"Emit system maintenance notification\"\"\"\n     await notification_events.on_system_maintenance(restaurant_ids, maintenance_data)\n \n-async def schedule_shift_reminder_notifications(restaurant_id: str, shifts: List[Dict[str, Any]]):\n+\n+async def schedule_shift_reminder_notifications(\n+    restaurant_id: str, shifts: List[Dict[str, Any]]\n+):\n     \"\"\"Schedule shift reminder notifications\"\"\"\n-    await notification_events.schedule_shift_reminders(restaurant_id, shifts)\n\\ No newline at end of file\n+    await notification_events.schedule_shift_reminders(restaurant_id, shifts)\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/middleware/rls_middleware.py\t2025-08-02 21:56:59.000072+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/middleware/rls_middleware.py\t2025-08-02 22:36:03.508801+00:00\n@@ -19,40 +19,40 @@\n class RLSMiddleware(BaseHTTPMiddleware):\n     \"\"\"\n     Middleware to automatically set RLS context based on authenticated user.\n     This ensures that all database queries in a request have proper tenant isolation.\n     \"\"\"\n-    \n+\n     async def dispatch(self, request: Request, call_next):\n         # Skip RLS for public endpoints\n         if self._is_public_endpoint(request.url.path):\n             return await call_next(request)\n-        \n+\n         # Try to extract user from request\n         # Note: This is a simplified version. In production, you might want to\n         # extract the token and validate it here, or use a different approach\n         # based on your authentication flow.\n-        \n+\n         try:\n             # For authenticated endpoints, the user will be set by the auth dependency\n             # We'll let the dependency injection handle it, but we can set up\n             # a request state for later use\n             request.state.rls_context = None\n-            \n+\n             response = await call_next(request)\n-            \n+\n             # Clear RLS context after request\n             RLSContext.clear()\n-            \n+\n             return response\n-            \n+\n         except Exception as e:\n             # Always clear RLS context on error\n             RLSContext.clear()\n             logger.error(f\"Error in RLS middleware: {e}\")\n             raise\n-    \n+\n     def _is_public_endpoint(self, path: str) -> bool:\n         \"\"\"Check if endpoint is public and doesn't need RLS\"\"\"\n         public_paths = [\n             \"/docs\",\n             \"/redoc\",\n@@ -62,19 +62,21 @@\n             \"/api/v1/auth/verify\",\n             \"/api/v1/public\",\n             \"/health\",\n             \"/metrics\",\n         ]\n-        \n+\n         return any(path.startswith(p) for p in public_paths)\n \n \n-async def set_rls_context(request: Request, current_user: User = Depends(get_current_user)):\n+async def set_rls_context(\n+    request: Request, current_user: User = Depends(get_current_user)\n+):\n     \"\"\"\n     Dependency to set RLS context for the current request.\n     Use this in your route handlers to ensure RLS is properly configured.\n-    \n+\n     Example:\n         @router.get(\"/orders\")\n         async def get_orders(\n             db: Session = Depends(get_db),\n             _rls: None = Depends(set_rls_context),\n@@ -85,19 +87,23 @@\n     \"\"\"\n     if current_user:\n         # Set RLS context based on user\n         RLSContext.set(\n             user_id=str(current_user.id),\n-            restaurant_id=str(current_user.restaurant_id) if current_user.restaurant_id else None,\n-            role=current_user.role\n+            restaurant_id=(\n+                str(current_user.restaurant_id) if current_user.restaurant_id else None\n+            ),\n+            role=current_user.role,\n         )\n-        \n+\n         # Store in request state for logging/debugging\n         request.state.rls_user_id = str(current_user.id)\n-        request.state.rls_restaurant_id = str(current_user.restaurant_id) if current_user.restaurant_id else None\n+        request.state.rls_restaurant_id = (\n+            str(current_user.restaurant_id) if current_user.restaurant_id else None\n+        )\n         request.state.rls_role = current_user.role\n-        \n+\n         logger.debug(\n             f\"RLS context set - User: {current_user.id}, \"\n             f\"Restaurant: {current_user.restaurant_id}, Role: {current_user.role}\"\n         )\n \n@@ -109,31 +115,35 @@\n     \"\"\"\n     return RLSContext.get()\n \n \n # Helper function for manual RLS context management\n-def with_rls_context(user_id: Optional[str] = None, \n-                    restaurant_id: Optional[str] = None, \n-                    role: Optional[str] = None):\n+def with_rls_context(\n+    user_id: Optional[str] = None,\n+    restaurant_id: Optional[str] = None,\n+    role: Optional[str] = None,\n+):\n     \"\"\"\n     Decorator to set RLS context for a specific function.\n     Useful for background tasks or scripts.\n-    \n+\n     Example:\n         @with_rls_context(restaurant_id=\"123\")\n         async def process_orders():\n             # All database queries will be filtered by restaurant_id\n     \"\"\"\n+\n     def decorator(func):\n         async def wrapper(*args, **kwargs):\n             # Set RLS context\n             RLSContext.set(user_id=user_id, restaurant_id=restaurant_id, role=role)\n-            \n+\n             try:\n                 result = await func(*args, **kwargs)\n                 return result\n             finally:\n                 # Always clear context\n                 RLSContext.clear()\n-        \n+\n         return wrapper\n-    return decorator\n\\ No newline at end of file\n+\n+    return decorator\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/crud/inventory.py\t2025-08-02 22:20:12.995453+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/crud/inventory.py\t2025-08-02 22:36:03.514218+00:00\n@@ -1,8 +1,9 @@\n \"\"\"\n CRUD operations for Inventory, Recipes, and Inventory Ledger\n \"\"\"\n+\n from sqlalchemy.orm import Session\n from sqlalchemy import func, case\n from sqlalchemy.dialects.postgresql import insert as pg_insert\n from typing import List, Optional, Tuple\n from uuid import UUID\n@@ -11,28 +12,42 @@\n from app.models import InventoryItem, Recipe, InventoryLedgerEntry, Product\n from app.schemas import inventory_schemas as schemas\n \n # --- InventoryItem CRUD ---\n \n-def get_inventory_item_by_sku(db: Session, sku: str, restaurant_id: int) -> Optional[InventoryItem]:\n+\n+def get_inventory_item_by_sku(\n+    db: Session, sku: str, restaurant_id: int\n+) -> Optional[InventoryItem]:\n     \"\"\"Get inventory item by SKU and restaurant ID.\"\"\"\n-    return db.query(InventoryItem).filter(\n-        InventoryItem.sku == sku,\n-        InventoryItem.restaurant_id == restaurant_id\n-    ).first()\n-\n-\n-def get_inventory_items(db: Session, restaurant_id: int, skip: int = 0, limit: int = 100) -> List[InventoryItem]:\n+    return (\n+        db.query(InventoryItem)\n+        .filter(InventoryItem.sku == sku, InventoryItem.restaurant_id == restaurant_id)\n+        .first()\n+    )\n+\n+\n+def get_inventory_items(\n+    db: Session, restaurant_id: int, skip: int = 0, limit: int = 100\n+) -> List[InventoryItem]:\n     \"\"\"Get inventory items for a restaurant.\"\"\"\n-    return db.query(InventoryItem).filter(\n-        InventoryItem.restaurant_id == restaurant_id\n-    ).offset(skip).limit(limit).all()\n-\n-\n-def create_inventory_item(db: Session, item: schemas.InventoryItemCreate, restaurant_id: int) -> InventoryItem:\n+    return (\n+        db.query(InventoryItem)\n+        .filter(InventoryItem.restaurant_id == restaurant_id)\n+        .offset(skip)\n+        .limit(limit)\n+        .all()\n+    )\n+\n+\n+def create_inventory_item(\n+    db: Session, item: schemas.InventoryItemCreate, restaurant_id: int\n+) -> InventoryItem:\n     \"\"\"Create a new inventory item.\"\"\"\n-    db_item = InventoryItem(**item.dict(exclude={'restaurant_id'}), restaurant_id=restaurant_id)\n+    db_item = InventoryItem(\n+        **item.dict(exclude={\"restaurant_id\"}), restaurant_id=restaurant_id\n+    )\n     db.add(db_item)\n     db.commit()\n     db.refresh(db_item)\n     return db_item\n     db_item = get_inventory_item(db, sku, restaurant_id)\n@@ -50,11 +65,19 @@\n         # For now, allowing deletion. Add checks if business logic requires.\n         db.delete(db_item)\n         db.commit()\n     return db_item\n \n-def adjust_inventory_item_quantity(db: Session, sku: str, change_qty_g: int, source: str, restaurant_id: UUID, source_id: Optional[str] = None) -> Tuple[Optional[InventoryItem], Optional[InventoryLedgerEntry]]:\n+\n+def adjust_inventory_item_quantity(\n+    db: Session,\n+    sku: str,\n+    change_qty_g: int,\n+    source: str,\n+    restaurant_id: UUID,\n+    source_id: Optional[str] = None,\n+) -> Tuple[Optional[InventoryItem], Optional[InventoryLedgerEntry]]:\n     \"\"\"\n     Adjusts the quantity of an inventory item and logs the change.\n     Ensures quantity does not drop below zero.\n     Returns the updated inventory item and the created ledger entry.\n     \"\"\"\n@@ -64,11 +87,11 @@\n \n     original_qty = db_item.qty_g\n \n     # Calculate new quantity, ensuring it doesn't go below 0\n     if db_item.qty_g + change_qty_g < 0:\n-        actual_change_qty_g = -db_item.qty_g # Deduct only what's available\n+        actual_change_qty_g = -db_item.qty_g  # Deduct only what's available\n         db_item.qty_g = 0\n     else:\n         actual_change_qty_g = change_qty_g\n         db_item.qty_g += change_qty_g\n \n@@ -76,45 +99,59 @@\n \n     # Create ledger entry for the actual change\n     ledger_entry = InventoryLedgerEntry(\n         sku=sku,\n         restaurant_id=restaurant_id,\n-        delta_g=actual_change_qty_g, # Log the actual change that happened\n+        delta_g=actual_change_qty_g,  # Log the actual change that happened\n         source=source,\n-        source_id=source_id\n+        source_id=source_id,\n     )\n     db.add(ledger_entry)\n \n     db.commit()\n     db.refresh(db_item)\n     db.refresh(ledger_entry)\n \n     return db_item, ledger_entry\n \n+\n # --- Recipe CRUD ---\n \n-def get_recipe_by_item_id(db: Session, item_id: UUID, restaurant_id: UUID) -> List[Recipe]:\n+\n+def get_recipe_by_item_id(\n+    db: Session, item_id: UUID, restaurant_id: UUID\n+) -> List[Recipe]:\n     \"\"\"Gets all recipe ingredient entries for a given product (item_id) and restaurant\"\"\"\n-    return db.query(Recipe).filter(\n-        Recipe.item_id == item_id,\n-        Recipe.restaurant_id == restaurant_id\n-    ).all()\n-    return db.query(Recipe).filter(\n-        Recipe.item_id == item_id,\n-        Recipe.ingredient_sku == ingredient_sku,\n-        Recipe.restaurant_id == restaurant_id\n-    ).first()\n-\n-def create_recipe_for_item(db: Session, item_id: UUID, ingredients: List[schemas.RecipeIngredientCreate], restaurant_id: UUID) -> List[Recipe]:\n+    return (\n+        db.query(Recipe)\n+        .filter(Recipe.item_id == item_id, Recipe.restaurant_id == restaurant_id)\n+        .all()\n+    )\n+    return (\n+        db.query(Recipe)\n+        .filter(\n+            Recipe.item_id == item_id,\n+            Recipe.ingredient_sku == ingredient_sku,\n+            Recipe.restaurant_id == restaurant_id,\n+        )\n+        .first()\n+    )\n+\n+\n+def create_recipe_for_item(\n+    db: Session,\n+    item_id: UUID,\n+    ingredients: List[schemas.RecipeIngredientCreate],\n+    restaurant_id: UUID,\n+) -> List[Recipe]:\n     \"\"\"\n     Creates or updates recipe ingredients for a given item_id.\n     This will replace all existing ingredients for the item.\n     \"\"\"\n     # First, delete existing recipe ingredients for this item and restaurant\n     db.query(Recipe).filter(\n-        Recipe.item_id == item_id,\n-        Recipe.restaurant_id == restaurant_id\n+        Recipe.item_id == item_id, Recipe.restaurant_id == restaurant_id\n     ).delete()\n \n     db_recipes = []\n     for ingredient_data in ingredients:\n         # Ensure ingredient exists in inventory for this restaurant\n@@ -125,22 +162,27 @@\n \n         db_recipe_ingredient = Recipe(\n             restaurant_id=restaurant_id,\n             item_id=item_id,\n             ingredient_sku=ingredient_data.ingredient_sku,\n-            qty_g=ingredient_data.qty_g\n+            qty_g=ingredient_data.qty_g,\n         )\n         db.add(db_recipe_ingredient)\n         db_recipes.append(db_recipe_ingredient)\n \n     db.commit()\n-    for rec in db_recipes: # Refresh each object to get DB-generated IDs etc.\n+    for rec in db_recipes:  # Refresh each object to get DB-generated IDs etc.\n         db.refresh(rec)\n     return db_recipes\n \n \n-def create_or_update_recipe_ingredients(db: Session, item_id: UUID, ingredients_data: List[schemas.RecipeIngredientCreate], restaurant_id: UUID) -> List[Recipe]:\n+def create_or_update_recipe_ingredients(\n+    db: Session,\n+    item_id: UUID,\n+    ingredients_data: List[schemas.RecipeIngredientCreate],\n+    restaurant_id: UUID,\n+) -> List[Recipe]:\n     \"\"\"\n     Creates new recipe ingredients or updates existing ones for a product.\n     Uses PostgreSQL's ON CONFLICT DO UPDATE (upsert).\n     \"\"\"\n     if not ingredients_data:\n@@ -150,110 +192,129 @@\n         # db.query(Recipe).filter(Recipe.item_id == item_id).delete()\n         # db.commit()\n         return []\n \n     # Fetch existing ingredients for this item and restaurant to compare and delete if necessary\n-    existing_db_ingredients = db.query(Recipe).filter(\n-        Recipe.item_id == item_id,\n-        Recipe.restaurant_id == restaurant_id\n-    ).all()\n+    existing_db_ingredients = (\n+        db.query(Recipe)\n+        .filter(Recipe.item_id == item_id, Recipe.restaurant_id == restaurant_id)\n+        .all()\n+    )\n     existing_ingredient_skus = {ing.ingredient_sku for ing in existing_db_ingredients}\n \n     input_ingredient_skus = {ing_data.ingredient_sku for ing_data in ingredients_data}\n \n     # Ingredients to delete (present in DB but not in input)\n     skus_to_delete = existing_ingredient_skus - input_ingredient_skus\n     if skus_to_delete:\n         db.query(Recipe).filter(\n             Recipe.item_id == item_id,\n             Recipe.restaurant_id == restaurant_id,\n-            Recipe.ingredient_sku.in_(skus_to_delete)\n+            Recipe.ingredient_sku.in_(skus_to_delete),\n         ).delete(synchronize_session=False)\n \n     # Prepare data for upsert\n     insert_values = []\n     for ingredient_data in ingredients_data:\n         # Optional: Validate ingredient_sku exists in inventory\n         # inv_item = get_inventory_item(db, ingredient_data.ingredient_sku)\n         # if not inv_item:\n         #     raise ValueError(f\"Ingredient SKU {ingredient_data.ingredient_sku} not found in inventory.\")\n \n-        insert_values.append({\n-            \"restaurant_id\": restaurant_id,\n-            \"item_id\": item_id,\n-            \"ingredient_sku\": ingredient_data.ingredient_sku,\n-            \"qty_g\": ingredient_data.qty_g,\n-        })\n-\n-    if not insert_values: # Only deletions happened\n+        insert_values.append(\n+            {\n+                \"restaurant_id\": restaurant_id,\n+                \"item_id\": item_id,\n+                \"ingredient_sku\": ingredient_data.ingredient_sku,\n+                \"qty_g\": ingredient_data.qty_g,\n+            }\n+        )\n+\n+    if not insert_values:  # Only deletions happened\n         db.commit()\n         return []\n \n     # Upsert statement for PostgreSQL\n     stmt = pg_insert(Recipe).values(insert_values)\n     stmt = stmt.on_conflict_do_update(\n-        index_elements=['restaurant_id', 'item_id', 'ingredient_sku'],  # Use the unique constraint name if available and preferred\n+        index_elements=[\n+            \"restaurant_id\",\n+            \"item_id\",\n+            \"ingredient_sku\",\n+        ],  # Use the unique constraint name if available and preferred\n         set_={\n             \"qty_g\": stmt.excluded.qty_g,\n-        }\n+        },\n     )\n     db.execute(stmt)\n     db.commit()\n \n     # Re-fetch the ingredients to return them with current state\n-    return db.query(Recipe).filter(\n-        Recipe.item_id == item_id,\n-        Recipe.restaurant_id == restaurant_id\n-    ).all()\n+    return (\n+        db.query(Recipe)\n+        .filter(Recipe.item_id == item_id, Recipe.restaurant_id == restaurant_id)\n+        .all()\n+    )\n \n \n def delete_recipe_for_item(db: Session, item_id: UUID, restaurant_id: UUID) -> int:\n     \"\"\"Deletes all recipe ingredients for a given item_id and restaurant. Returns count of deleted ingredients.\"\"\"\n-    deleted_count = db.query(Recipe).filter(\n-        Recipe.item_id == item_id,\n-        Recipe.restaurant_id == restaurant_id\n-    ).delete()\n+    deleted_count = (\n+        db.query(Recipe)\n+        .filter(Recipe.item_id == item_id, Recipe.restaurant_id == restaurant_id)\n+        .delete()\n+    )\n     db.commit()\n     return deleted_count\n \n-def delete_specific_ingredient_from_recipe(db: Session, item_id: UUID, ingredient_sku: str, restaurant_id: UUID) -> Optional[Recipe]:\n+\n+def delete_specific_ingredient_from_recipe(\n+    db: Session, item_id: UUID, ingredient_sku: str, restaurant_id: UUID\n+) -> Optional[Recipe]:\n     \"\"\"Deletes a specific ingredient from an item's recipe.\"\"\"\n     db_ingredient = get_recipe_ingredient(db, item_id, ingredient_sku, restaurant_id)\n     if db_ingredient:\n         db.delete(db_ingredient)\n         db.commit()\n-        return db_ingredient # No longer in DB, but was the object before deletion\n+        return db_ingredient  # No longer in DB, but was the object before deletion\n     return None\n \n-# --- InventoryLedgerEntry CRUD ---\n+    # --- InventoryLedgerEntry CRUD ---\n     db_entry = InventoryLedgerEntry(**entry.dict(), restaurant_id=restaurant_id)\n     db.add(db_entry)\n     db.commit()\n     db.refresh(db_entry)\n     return db_entry\n     query = db.query(InventoryLedgerEntry).filter(\n         InventoryLedgerEntry.sku == sku,\n-        InventoryLedgerEntry.restaurant_id == restaurant_id\n+        InventoryLedgerEntry.restaurant_id == restaurant_id,\n     )\n     if start_date:\n         query = query.filter(InventoryLedgerEntry.ts >= start_date)\n     if end_date:\n         query = query.filter(InventoryLedgerEntry.ts <= end_date)\n-    return query.order_by(InventoryLedgerEntry.ts.desc()).offset(skip).limit(limit).all()\n+    return (\n+        query.order_by(InventoryLedgerEntry.ts.desc()).offset(skip).limit(limit).all()\n+    )\n     query = db.query(InventoryLedgerEntry).filter(\n         InventoryLedgerEntry.restaurant_id == restaurant_id\n     )\n     if start_date:\n         query = query.filter(InventoryLedgerEntry.ts >= start_date)\n     if end_date:\n         query = query.filter(InventoryLedgerEntry.ts <= end_date)\n-    return query.order_by(InventoryLedgerEntry.ts.desc()).offset(skip).limit(limit).all()\n+    return (\n+        query.order_by(InventoryLedgerEntry.ts.desc()).offset(skip).limit(limit).all()\n+    )\n \n \n # --- Helper / Service level CRUD-like functions ---\n \n-def get_inventory_status_summary(db: Session, restaurant_id: UUID) -> List[schemas.InventoryStatusResponse]:\n+\n+def get_inventory_status_summary(\n+    db: Session, restaurant_id: UUID\n+) -> List[schemas.InventoryStatusResponse]:\n     \"\"\"\n     Provides a summary of all inventory items including their stock status\n     (e.g., \"In Stock\", \"Low Stock\", \"Out of Stock\").\n     \"\"\"\n     # Case statement for status:\n@@ -263,128 +324,163 @@\n     # Handle par_level_g being NULL or 0 to avoid division by zero or incorrect \"Low Stock\"\n \n     status_expression = case(\n         (InventoryItem.qty_g <= 0, \"Out of Stock\"),\n         (\n-            (InventoryItem.par_level_g.isnot(None)) & (InventoryItem.par_level_g > 0) & (InventoryItem.qty_g <= InventoryItem.par_level_g * 0.1),\n-            \"Low Stock\"\n+            (InventoryItem.par_level_g.isnot(None))\n+            & (InventoryItem.par_level_g > 0)\n+            & (InventoryItem.qty_g <= InventoryItem.par_level_g * 0.1),\n+            \"Low Stock\",\n         ),\n-        else_=\"In Stock\"\n+        else_=\"In Stock\",\n     ).label(\"status\")\n \n-    results = db.query(\n-        InventoryItem.sku,\n-        InventoryItem.name,\n-        InventoryItem.qty_g,\n-        InventoryItem.par_level_g,\n-        InventoryItem.unit,\n-        status_expression\n-    ).filter(\n-        InventoryItem.restaurant_id == restaurant_id\n-    ).all()\n+    results = (\n+        db.query(\n+            InventoryItem.sku,\n+            InventoryItem.name,\n+            InventoryItem.qty_g,\n+            InventoryItem.par_level_g,\n+            InventoryItem.unit,\n+            status_expression,\n+        )\n+        .filter(InventoryItem.restaurant_id == restaurant_id)\n+        .all()\n+    )\n \n     return [\n         schemas.InventoryStatusResponse(\n             sku=r.sku,\n             name=r.name,\n             current_qty_g=r.qty_g,\n             par_level_g=r.par_level_g,\n             status=r.status,\n-            unit=r.unit\n-        ) for r in results\n+            unit=r.unit,\n+        )\n+        for r in results\n     ]\n \n-def get_low_stock_items(db: Session, restaurant_id: UUID, threshold_percentage: float = 0.1) -> List[schemas.LowStockItem]:\n+\n+def get_low_stock_items(\n+    db: Session, restaurant_id: UUID, threshold_percentage: float = 0.1\n+) -> List[schemas.LowStockItem]:\n     \"\"\"\n     Retrieves items that are at or below a certain percentage of their par level.\n     Only considers items where par_level_g is defined and greater than 0.\n     \"\"\"\n     if not (0 < threshold_percentage <= 1):\n-        raise ValueError(\"Threshold percentage must be between 0 (exclusive) and 1 (inclusive).\")\n+        raise ValueError(\n+            \"Threshold percentage must be between 0 (exclusive) and 1 (inclusive).\"\n+        )\n \n     # Filter for items where par_level_g is set and positive, and current quantity is below threshold\n     low_stock_condition = (\n-        (InventoryItem.par_level_g.isnot(None)) &\n-        (InventoryItem.par_level_g > 0) &\n-        (InventoryItem.qty_g <= (InventoryItem.par_level_g * threshold_percentage))\n-    )\n-\n-    results = db.query(\n-        InventoryItem.sku,\n-        InventoryItem.name,\n-        InventoryItem.qty_g,\n-        InventoryItem.par_level_g,\n-        InventoryItem.unit\n-    ).filter(\n-        low_stock_condition,\n-        InventoryItem.restaurant_id == restaurant_id\n-    ).all()\n+        (InventoryItem.par_level_g.isnot(None))\n+        & (InventoryItem.par_level_g > 0)\n+        & (InventoryItem.qty_g <= (InventoryItem.par_level_g * threshold_percentage))\n+    )\n+\n+    results = (\n+        db.query(\n+            InventoryItem.sku,\n+            InventoryItem.name,\n+            InventoryItem.qty_g,\n+            InventoryItem.par_level_g,\n+            InventoryItem.unit,\n+        )\n+        .filter(low_stock_condition, InventoryItem.restaurant_id == restaurant_id)\n+        .all()\n+    )\n \n     response_items = []\n     for r in results:\n-        percentage_remaining = (r.qty_g / r.par_level_g) * 100 if r.par_level_g > 0 else 0\n-        response_items.append(schemas.LowStockItem(\n-            sku=r.sku,\n-            name=r.name,\n-            qty_g=r.qty_g,\n-            par_level_g=r.par_level_g,\n-            percentage_remaining=round(percentage_remaining, 2),\n-            unit=r.unit\n-        ))\n+        percentage_remaining = (\n+            (r.qty_g / r.par_level_g) * 100 if r.par_level_g > 0 else 0\n+        )\n+        response_items.append(\n+            schemas.LowStockItem(\n+                sku=r.sku,\n+                name=r.name,\n+                qty_g=r.qty_g,\n+                par_level_g=r.par_level_g,\n+                percentage_remaining=round(percentage_remaining, 2),\n+                unit=r.unit,\n+            )\n+        )\n     return response_items\n \n-def get_product_details_with_recipe(db: Session, item_id: UUID, restaurant_id: UUID) -> Optional[dict]:\n+\n+def get_product_details_with_recipe(\n+    db: Session, item_id: UUID, restaurant_id: UUID\n+) -> Optional[dict]:\n     \"\"\"\n     Retrieves a product and its associated recipe ingredients, including ingredient names.\n     \"\"\"\n-    product = db.query(Product).filter(\n-        Product.id == item_id,\n-        Product.restaurant_id == restaurant_id\n-    ).first()\n+    product = (\n+        db.query(Product)\n+        .filter(Product.id == item_id, Product.restaurant_id == restaurant_id)\n+        .first()\n+    )\n     if not product:\n         return None\n \n-    recipe_ingredients = db.query(\n-        Recipe.ingredient_sku,\n-        Recipe.qty_g,\n-        InventoryItem.name.label(\"ingredient_name\"),\n-        InventoryItem.unit.label(\"ingredient_unit\")\n-    ).join(InventoryItem, Recipe.ingredient_sku == InventoryItem.sku)\\\n-     .filter(\n-        Recipe.item_id == item_id,\n-        Recipe.restaurant_id == restaurant_id,\n-        InventoryItem.restaurant_id == restaurant_id\n-     ).all()\n+    recipe_ingredients = (\n+        db.query(\n+            Recipe.ingredient_sku,\n+            Recipe.qty_g,\n+            InventoryItem.name.label(\"ingredient_name\"),\n+            InventoryItem.unit.label(\"ingredient_unit\"),\n+        )\n+        .join(InventoryItem, Recipe.ingredient_sku == InventoryItem.sku)\n+        .filter(\n+            Recipe.item_id == item_id,\n+            Recipe.restaurant_id == restaurant_id,\n+            InventoryItem.restaurant_id == restaurant_id,\n+        )\n+        .all()\n+    )\n \n     return {\n         \"item_id\": product.id,\n         \"item_name\": product.name,\n         \"ingredients\": [\n             {\n                 \"ingredient_sku\": ri.ingredient_sku,\n                 \"qty_g\": ri.qty_g,\n                 \"ingredient_name\": ri.ingredient_name,\n                 \"ingredient_unit\": ri.ingredient_unit,\n-            } for ri in recipe_ingredients\n-        ]\n+            }\n+            for ri in recipe_ingredients\n+        ],\n     }\n \n-def get_all_products_with_recipes(db: Session, restaurant_id: UUID, skip: int = 0, limit: int = 100) -> List[dict]:\n+\n+def get_all_products_with_recipes(\n+    db: Session, restaurant_id: UUID, skip: int = 0, limit: int = 100\n+) -> List[dict]:\n     \"\"\"\n     Retrieves all products that have recipes, along with their recipe details.\n     This can be heavy; consider pagination or specific filtering for real-world use.\n     \"\"\"\n     # This is a simplified version. A more optimized query might be needed for performance\n     # on large datasets, possibly using subqueries or window functions if complexity grows.\n \n-    products_with_recipes_query = db.query(Product).filter(\n-        Product.restaurant_id == restaurant_id,\n-        Product.recipes.any(Recipe.restaurant_id == restaurant_id)\n-    ).offset(skip).limit(limit).all()\n+    products_with_recipes_query = (\n+        db.query(Product)\n+        .filter(\n+            Product.restaurant_id == restaurant_id,\n+            Product.recipes.any(Recipe.restaurant_id == restaurant_id),\n+        )\n+        .offset(skip)\n+        .limit(limit)\n+        .all()\n+    )\n \n     result_list = []\n     for product in products_with_recipes_query:\n-        recipe_data = get_product_details_with_recipe(db, product.id, restaurant_id) # Reuse existing function\n-        if recipe_data: # Should always be true due to the filter, but good practice\n-             result_list.append(recipe_data)\n+        recipe_data = get_product_details_with_recipe(\n+            db, product.id, restaurant_id\n+        )  # Reuse existing function\n+        if recipe_data:  # Should always be true due to the filter, but good practice\n+            result_list.append(recipe_data)\n \n     return result_list\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/middleware/security_headers_middleware.py\t2025-08-02 20:32:28.999388+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/middleware/security_headers_middleware.py\t2025-08-02 22:36:03.522915+00:00\n@@ -1,32 +1,43 @@\n from fastapi import Request, Response\n from starlette.middleware.base import BaseHTTPMiddleware\n from typing import Callable\n from app.core.config import settings\n+\n \n class SecurityHeadersMiddleware(BaseHTTPMiddleware):\n     async def dispatch(self, request: Request, call_next: Callable) -> Response:\n         response = await call_next(request)\n \n         # Common headers for all environments\n         response.headers[\"X-Content-Type-Options\"] = \"nosniff\"\n         response.headers[\"X-Frame-Options\"] = \"DENY\"\n-        response.headers[\"X-XSS-Protection\"] = \"1; mode=block\" # Deprecated but still good for older browsers\n+        response.headers[\"X-XSS-Protection\"] = (\n+            \"1; mode=block\"  # Deprecated but still good for older browsers\n+        )\n \n         if settings.ENVIRONMENT == \"production\":\n             # Production specific headers\n-            response.headers[\"Strict-Transport-Security\"] = \"max-age=31536000; includeSubDomains; preload\"\n+            response.headers[\"Strict-Transport-Security\"] = (\n+                \"max-age=31536000; includeSubDomains; preload\"\n+            )\n             response.headers[\"Referrer-Policy\"] = \"strict-origin-when-cross-origin\"\n             # CSP needs careful configuration, will be more complex\n             response.headers[\"Content-Security-Policy\"] = self.get_production_csp()\n             response.headers[\"Permissions-Policy\"] = self.get_permissions_policy()\n         else:\n             # Development/staging specific headers (more permissive)\n-            response.headers[\"Strict-Transport-Security\"] = \"max-age=31536000; includeSubDomains\" # Can be less strict if not preloading\n-            response.headers[\"Referrer-Policy\"] = \"no-referrer-when-downgrade\" # More permissive\n+            response.headers[\"Strict-Transport-Security\"] = (\n+                \"max-age=31536000; includeSubDomains\"  # Can be less strict if not preloading\n+            )\n+            response.headers[\"Referrer-Policy\"] = (\n+                \"no-referrer-when-downgrade\"  # More permissive\n+            )\n             response.headers[\"Content-Security-Policy\"] = self.get_development_csp()\n-            response.headers[\"Permissions-Policy\"] = \"camera=(), microphone=(), geolocation=()\" # Example, adjust as needed\n+            response.headers[\"Permissions-Policy\"] = (\n+                \"camera=(), microphone=(), geolocation=()\"  # Example, adjust as needed\n+            )\n \n         return response\n         # Base policy: restrict to self, allow necessary scripts and styles\n         # This needs to be carefully configured based on actual needs, especially for payment providers\n         # and WebSocket connections.\n@@ -34,75 +45,109 @@\n         # For WebSockets: connect-src 'self' wss://yourdomain.com;\n \n         # Start with a restrictive policy\n         csp_directives = {\n             \"default-src\": [\"'self'\"],\n-            \"script-src\": [\"'self'\", \"https://js.stripe.com\", \"https://checkout.stripe.com\"], # Stripe JS\n-            \"style-src\": [\"'self'\", \"'unsafe-inline'\", \"https://fonts.googleapis.com\"], # Allow inline styles for now, and Google Fonts\n-            \"img-src\": [\"'self'\", \"data:\", \"https://*.stripe.com\"], # Allow data URIs and Stripe images\n-            \"font-src\": [\"'self'\", \"https://fonts.gstatic.com\"], # Google Fonts\n+            \"script-src\": [\n+                \"'self'\",\n+                \"https://js.stripe.com\",\n+                \"https://checkout.stripe.com\",\n+            ],  # Stripe JS\n+            \"style-src\": [\n+                \"'self'\",\n+                \"'unsafe-inline'\",\n+                \"https://fonts.googleapis.com\",\n+            ],  # Allow inline styles for now, and Google Fonts\n+            \"img-src\": [\n+                \"'self'\",\n+                \"data:\",\n+                \"https://*.stripe.com\",\n+            ],  # Allow data URIs and Stripe images\n+            \"font-src\": [\"'self'\", \"https://fonts.gstatic.com\"],  # Google Fonts\n             \"connect-src\": [\n                 \"'self'\",\n                 # \"wss://\" + settings.DOMAIN if hasattr(settings, 'DOMAIN') and settings.DOMAIN else \"\", # WebSocket - Re-evaluate how to best set this\n                 \"https://api.stripe.com\",\n-                \"https://errors.stripe.com\"\n-            ], # Allow self, WebSocket, Stripe API\n-            \"frame-src\": [\"'self'\", \"https://js.stripe.com\", \"https://checkout.stripe.com\"], # Stripe frames\n-            \"object-src\": [\"'none'\"], # Disallow plugins like Flash\n+                \"https://errors.stripe.com\",\n+            ],  # Allow self, WebSocket, Stripe API\n+            \"frame-src\": [\n+                \"'self'\",\n+                \"https://js.stripe.com\",\n+                \"https://checkout.stripe.com\",\n+            ],  # Stripe frames\n+            \"object-src\": [\"'none'\"],  # Disallow plugins like Flash\n             \"base-uri\": [\"'self'\"],\n-            \"form-action\": [\"'self'\"], # Restrict where forms can submit\n-            \"frame-ancestors\": [\"'none'\"], # Equivalent to X-Frame-Options: DENY\n+            \"form-action\": [\"'self'\"],  # Restrict where forms can submit\n+            \"frame-ancestors\": [\"'none'\"],  # Equivalent to X-Frame-Options: DENY\n             # \"report-uri\": [\"/api/v1/csp-reports\"], # Endpoint to report violations (optional) - needs an endpoint\n         }\n \n         # CSP directives for connect-src might need to be adjusted based on settings.DOMAIN availability\n         # For now, WebSocket connections to a different domain than 'self' might be blocked in production.\n         # Consider adding settings.DOMAIN or making CSP more dynamically configurable.\n \n-        return \"; \".join([f\"{key} {' '.join(values)}\" for key, values in csp_directives.items() if values])\n+        return \"; \".join(\n+            [\n+                f\"{key} {' '.join(values)}\"\n+                for key, values in csp_directives.items()\n+                if values\n+            ]\n+        )\n         # More permissive CSP for development to avoid blocking common dev tools\n         # Still, it's good practice to keep it as close to production as possible\n         csp_directives = {\n             \"default-src\": [\"'self'\"],\n-            \"script-src\": [\"'self'\", \"'unsafe-inline'\", \"'unsafe-eval'\", \"https://js.stripe.com\", \"https://checkout.stripe.com\"], # Allow inline scripts and eval for dev\n+            \"script-src\": [\n+                \"'self'\",\n+                \"'unsafe-inline'\",\n+                \"'unsafe-eval'\",\n+                \"https://js.stripe.com\",\n+                \"https://checkout.stripe.com\",\n+            ],  # Allow inline scripts and eval for dev\n             \"style-src\": [\"'self'\", \"'unsafe-inline'\", \"https://fonts.googleapis.com\"],\n             \"img-src\": [\"'self'\", \"data:\", \"https://*.stripe.com\"],\n             \"font-src\": [\"'self'\", \"https://fonts.gstatic.com\"],\n             \"connect-src\": [\n                 \"'self'\",\n-                \"ws://localhost:8000\", # Local WebSocket\n-                \"wss://localhost:8000\", # Local secure WebSocket\n-                \"http://localhost:8000\", # Local HTTP for API calls\n+                \"ws://localhost:8000\",  # Local WebSocket\n+                \"wss://localhost:8000\",  # Local secure WebSocket\n+                \"http://localhost:8000\",  # Local HTTP for API calls\n                 \"https://api.stripe.com\",\n-                \"https://errors.stripe.com\"\n+                \"https://errors.stripe.com\",\n             ],\n-            \"frame-src\": [\"'self'\", \"https://js.stripe.com\", \"https://checkout.stripe.com\"],\n+            \"frame-src\": [\n+                \"'self'\",\n+                \"https://js.stripe.com\",\n+                \"https://checkout.stripe.com\",\n+            ],\n             \"object-src\": [\"'none'\"],\n             \"base-uri\": [\"'self'\"],\n             \"form-action\": [\"'self'\"],\n-            \"frame-ancestors\": [\"'self'\"], # Allow framing from self for dev tools\n+            \"frame-ancestors\": [\"'self'\"],  # Allow framing from self for dev tools\n         }\n-        return \"; \".join([f\"{key} {' '.join(values)}\" for key, values in csp_directives.items()])\n+        return \"; \".join(\n+            [f\"{key} {' '.join(values)}\" for key, values in csp_directives.items()]\n+        )\n         # Define features and their permissions\n         # Example: geolocation=(self \"https://example.com\"), microphone=()\n         # By default, disable most features unless explicitly needed.\n         permissions = [\n             \"accelerometer=()\",\n             \"ambient-light-sensor=()\",\n             \"autoplay=()\",\n-            \"camera=()\", # Example: allow self if app needs camera: \"camera=(self)\"\n+            \"camera=()\",  # Example: allow self if app needs camera: \"camera=(self)\"\n             \"encrypted-media=()\",\n-            \"fullscreen=(self)\", # Example: allow self if app needs fullscreen\n-            \"geolocation=()\", # Example: \"geolocation=(self \\\"https://trusted.third-party.com\\\")\"\n+            \"fullscreen=(self)\",  # Example: allow self if app needs fullscreen\n+            \"geolocation=()\",  # Example: \"geolocation=(self \\\"https://trusted.third-party.com\\\")\"\n             \"gyroscope=()\",\n             \"magnetometer=()\",\n             \"microphone=()\",\n             \"midi=()\",\n-            \"payment=()\", # Example: \"payment=(self \\\"https://stripe.com\\\")\" if Stripe handles payments in an iframe\n+            \"payment=()\",  # Example: \"payment=(self \\\"https://stripe.com\\\")\" if Stripe handles payments in an iframe\n             \"picture-in-picture=()\",\n             \"speaker=()\",\n             \"sync-xhr=(self)\",\n             \"usb=()\",\n             \"vr=()\",\n-            \"screen-wake-lock=()\"\n+            \"screen-wake-lock=()\",\n         ]\n         return \", \".join(permissions)\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/sync_manager.py\t2025-08-02 21:56:58.997129+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/sync_manager.py\t2025-08-02 22:36:03.529739+00:00\n@@ -13,33 +13,41 @@\n \n from app.core.database import get_db, Order, Product, Customer, Payment, User\n from app.core.exceptions import FynloException, ErrorCodes\n from app.core.responses import APIResponseHelper\n \n+\n class SyncAction(str, Enum):\n     \"\"\"Sync action types\"\"\"\n+\n     CREATE = \"create\"\n     UPDATE = \"update\"\n     DELETE = \"delete\"\n \n+\n class SyncStatus(str, Enum):\n     \"\"\"Sync status types\"\"\"\n+\n     PENDING = \"pending\"\n     PROCESSING = \"processing\"\n     COMPLETED = \"completed\"\n     FAILED = \"failed\"\n     CONFLICT = \"conflict\"\n \n+\n class ConflictResolution(str, Enum):\n     \"\"\"Conflict resolution strategies\"\"\"\n+\n     SERVER_WINS = \"server_wins\"\n     CLIENT_WINS = \"client_wins\"\n     MANUAL = \"manual\"\n     MERGE = \"merge\"\n \n+\n class SyncRecord:\n     \"\"\"Sync record data structure\"\"\"\n+\n     def __init__(\n         self,\n         id: str,\n         entity_type: str,\n         entity_id: str,\n@@ -47,11 +55,11 @@\n         data: Dict[str, Any],\n         client_timestamp: datetime,\n         restaurant_id: str,\n         user_id: str,\n         device_id: Optional[str] = None,\n-        version: int = 1\n+        version: int = 1,\n     ):\n         self.id = id\n         self.entity_type = entity_type\n         self.entity_id = entity_id\n         self.action = action\n@@ -77,21 +85,23 @@\n             \"user_id\": self.user_id,\n             \"device_id\": self.device_id,\n             \"version\": self.version,\n             \"status\": self.status.value,\n             \"conflict_details\": self.conflict_details,\n-            \"error_message\": self.error_message\n+            \"error_message\": self.error_message,\n         }\n+\n \n class SyncConflict:\n     \"\"\"Sync conflict representation\"\"\"\n+\n     def __init__(\n         self,\n         sync_record: SyncRecord,\n         server_data: Dict[str, Any],\n         conflict_fields: List[str],\n-        conflict_type: str = \"data_mismatch\"\n+        conflict_type: str = \"data_mismatch\",\n     ):\n         self.sync_record = sync_record\n         self.server_data = server_data\n         self.conflict_fields = conflict_fields\n         self.conflict_type = conflict_type\n@@ -101,16 +111,17 @@\n             \"conflict_type\": self.conflict_type,\n             \"conflict_fields\": self.conflict_fields,\n             \"client_data\": self.sync_record.data,\n             \"server_data\": self.server_data,\n             \"client_timestamp\": self.sync_record.client_timestamp.isoformat(),\n-            \"detected_at\": self.detected_at.isoformat()\n+            \"detected_at\": self.detected_at.isoformat(),\n         }\n+\n \n class OfflineSyncManager:\n     \"\"\"Manager for offline synchronization operations\"\"\"\n-    \n+\n     def __init__(self, db: Session):\n         self.db = db\n         self.sync_queue: List[SyncRecord] = []\n         self.conflicts: List[SyncConflict] = []\n         \"\"\"\n@@ -122,356 +133,387 @@\n                 \"successful\": 0,\n                 \"failed\": 0,\n                 \"conflicts\": 0,\n                 \"processed_actions\": [],\n                 \"conflicts_detected\": [],\n-                \"errors\": []\n-            }\n-            \n+                \"errors\": [],\n+            }\n+\n             # Validate and create sync records\n             sync_records = []\n             for action_data in sync_actions:\n                 try:\n                     sync_record = self._create_sync_record(\n                         action_data, restaurant_id, user_id, device_id\n                     )\n                     sync_records.append(sync_record)\n                 except Exception as e:\n-                    results[\"errors\"].append({\n-                        \"action\": action_data,\n-                        \"error\": str(e)\n-                    })\n+                    results[\"errors\"].append({\"action\": action_data, \"error\": str(e)})\n                     results[\"failed\"] += 1\n-            \n+\n             # Process sync records in order\n             for sync_record in sync_records:\n                 try:\n                     result = self._process_sync_record(sync_record)\n                     results[\"processed_actions\"].append(result)\n-                    \n+\n                     if result[\"status\"] == SyncStatus.COMPLETED.value:\n                         results[\"successful\"] += 1\n                     elif result[\"status\"] == SyncStatus.CONFLICT.value:\n                         results[\"conflicts\"] += 1\n                         results[\"conflicts_detected\"].append(result[\"conflict_details\"])\n                     else:\n                         results[\"failed\"] += 1\n-                        \n+\n                 except Exception as e:\n                     results[\"failed\"] += 1\n-                    results[\"errors\"].append({\n-                        \"sync_record_id\": sync_record.id,\n-                        \"error\": str(e)\n-                    })\n-            \n+                    results[\"errors\"].append(\n+                        {\"sync_record_id\": sync_record.id, \"error\": str(e)}\n+                    )\n+\n             # Commit successful changes\n             if results[\"successful\"] > 0:\n                 self.db.commit()\n-            \n+\n             return results\n-            \n+\n         except Exception as e:\n             self.db.rollback()\n             raise FynloException(\n                 message=f\"Batch upload failed: {str(e)}\",\n                 error_code=ErrorCodes.INTERNAL_ERROR,\n-                status_code=500\n+                status_code=500,\n             )\n         \"\"\"\n         Download server changes since last sync\n         \"\"\"\n         try:\n             if not last_sync_timestamp:\n-                last_sync_timestamp = datetime.now() - timedelta(days=7)  # Default 7 days\n-            \n+                last_sync_timestamp = datetime.now() - timedelta(\n+                    days=7\n+                )  # Default 7 days\n+\n             changes = {\n                 \"sync_timestamp\": datetime.now().isoformat(),\n                 \"last_sync_timestamp\": last_sync_timestamp.isoformat(),\n                 \"changes\": {},\n-                \"total_changes\": 0\n-            }\n-            \n+                \"total_changes\": 0,\n+            }\n+\n             # Define entity handlers\n             entity_handlers = {\n                 \"orders\": self._get_order_changes,\n                 \"products\": self._get_product_changes,\n                 \"customers\": self._get_customer_changes,\n-                \"payments\": self._get_payment_changes\n-            }\n-            \n+                \"payments\": self._get_payment_changes,\n+            }\n+\n             # Get changes for requested entity types\n             requested_types = entity_types or list(entity_handlers.keys())\n-            \n+\n             for entity_type in requested_types:\n                 if entity_type in entity_handlers:\n                     entity_changes = entity_handlers[entity_type](\n                         restaurant_id, last_sync_timestamp\n                     )\n                     changes[\"changes\"][entity_type] = entity_changes\n                     changes[\"total_changes\"] += len(entity_changes)\n-            \n+\n             return changes\n-            \n+\n         except Exception as e:\n             raise FynloException(\n                 message=f\"Failed to download changes: {str(e)}\",\n                 error_code=ErrorCodes.INTERNAL_ERROR,\n-                status_code=500\n+                status_code=500,\n             )\n         \"\"\"\n         Resolve sync conflict with specified strategy\n         \"\"\"\n         try:\n             # Find conflict by ID\n-            conflict = next((c for c in self.conflicts if c.sync_record.id == conflict_id), None)\n+            conflict = next(\n+                (c for c in self.conflicts if c.sync_record.id == conflict_id), None\n+            )\n             if not conflict:\n                 raise FynloException(\n                     message=\"Conflict not found\",\n                     error_code=ErrorCodes.NOT_FOUND,\n-                    status_code=404\n+                    status_code=404,\n                 )\n-            \n+\n             sync_record = conflict.sync_record\n-            \n+\n             if resolution_strategy == ConflictResolution.SERVER_WINS:\n                 # Keep server data, mark sync as completed\n                 sync_record.status = SyncStatus.COMPLETED\n                 final_data = conflict.server_data\n-                \n+\n             elif resolution_strategy == ConflictResolution.CLIENT_WINS:\n                 # Apply client data, overwrite server\n                 final_data = self._apply_client_data(sync_record)\n                 sync_record.status = SyncStatus.COMPLETED\n-                \n+\n             elif resolution_strategy == ConflictResolution.MERGE:\n                 # Use provided merged data\n                 if not merged_data:\n                     raise FynloException(\n                         message=\"Merged data required for merge resolution\",\n                         error_code=ErrorCodes.VALIDATION_ERROR,\n-                        status_code=400\n+                        status_code=400,\n                     )\n                 final_data = self._apply_merged_data(sync_record, merged_data)\n                 sync_record.status = SyncStatus.COMPLETED\n-                \n+\n             else:  # MANUAL\n                 # Leave for manual resolution\n                 sync_record.status = SyncStatus.CONFLICT\n                 final_data = conflict.server_data\n-            \n+\n             # Remove from conflicts list if resolved\n             if sync_record.status == SyncStatus.COMPLETED:\n-                self.conflicts = [c for c in self.conflicts if c.sync_record.id != conflict_id]\n+                self.conflicts = [\n+                    c for c in self.conflicts if c.sync_record.id != conflict_id\n+                ]\n                 self.db.commit()\n-            \n+\n             return {\n                 \"conflict_id\": conflict_id,\n                 \"resolution_strategy\": resolution_strategy.value,\n                 \"status\": sync_record.status.value,\n-                \"final_data\": final_data\n-            }\n-            \n+                \"final_data\": final_data,\n+            }\n+\n         except Exception as e:\n             self.db.rollback()\n             raise FynloException(\n                 message=f\"Failed to resolve conflict: {str(e)}\",\n                 error_code=ErrorCodes.INTERNAL_ERROR,\n-                status_code=500\n+                status_code=500,\n             )\n         \"\"\"\n         Get synchronization status for restaurant/device\n         \"\"\"\n         try:\n             # This would query a sync_records table in a real implementation\n             # For now, return status from in-memory structures\n-            \n-            total_pending = len([r for r in self.sync_queue if r.restaurant_id == restaurant_id])\n-            total_conflicts = len([c for c in self.conflicts if c.sync_record.restaurant_id == restaurant_id])\n-            \n+\n+            total_pending = len(\n+                [r for r in self.sync_queue if r.restaurant_id == restaurant_id]\n+            )\n+            total_conflicts = len(\n+                [\n+                    c\n+                    for c in self.conflicts\n+                    if c.sync_record.restaurant_id == restaurant_id\n+                ]\n+            )\n+\n             return {\n                 \"restaurant_id\": restaurant_id,\n                 \"device_id\": device_id,\n                 \"pending_uploads\": total_pending,\n                 \"active_conflicts\": total_conflicts,\n                 \"last_sync_attempt\": datetime.now().isoformat(),\n-                \"sync_health\": \"healthy\" if total_conflicts == 0 else \"conflicts_detected\"\n-            }\n-            \n+                \"sync_health\": (\n+                    \"healthy\" if total_conflicts == 0 else \"conflicts_detected\"\n+                ),\n+            }\n+\n         except Exception as e:\n             raise FynloException(\n                 message=f\"Failed to get sync status: {str(e)}\",\n                 error_code=ErrorCodes.INTERNAL_ERROR,\n-                status_code=500\n-            )\n-    \n+                status_code=500,\n+            )\n+\n     def _create_sync_record(\n         self,\n         action_data: Dict[str, Any],\n         restaurant_id: str,\n         user_id: str,\n-        device_id: Optional[str]\n+        device_id: Optional[str],\n     ) -> SyncRecord:\n         \"\"\"Create sync record from action data\"\"\"\n-        required_fields = [\"entity_type\", \"entity_id\", \"action\", \"data\", \"client_timestamp\"]\n-        \n+        required_fields = [\n+            \"entity_type\",\n+            \"entity_id\",\n+            \"action\",\n+            \"data\",\n+            \"client_timestamp\",\n+        ]\n+\n         for field in required_fields:\n             if field not in action_data:\n                 raise ValueError(f\"Missing required field: {field}\")\n-        \n+\n         # Parse client timestamp\n         client_timestamp = datetime.fromisoformat(\n             action_data[\"client_timestamp\"].replace(\"Z\", \"+00:00\")\n         )\n-        \n+\n         return SyncRecord(\n             id=action_data.get(\"id\", str(uuid.uuid4())),\n             entity_type=action_data[\"entity_type\"],\n             entity_id=action_data[\"entity_id\"],\n             action=SyncAction(action_data[\"action\"]),\n             data=action_data[\"data\"],\n             client_timestamp=client_timestamp,\n             restaurant_id=restaurant_id,\n             user_id=user_id,\n             device_id=device_id,\n-            version=action_data.get(\"version\", 1)\n+            version=action_data.get(\"version\", 1),\n         )\n-    \n+\n     def _process_sync_record(self, sync_record: SyncRecord) -> Dict[str, Any]:\n         \"\"\"Process individual sync record\"\"\"\n         try:\n             # Check for conflicts\n             conflict = self._detect_conflicts(sync_record)\n             if conflict:\n                 sync_record.status = SyncStatus.CONFLICT\n                 sync_record.conflict_details = conflict.to_dict()\n                 self.conflicts.append(conflict)\n-                \n+\n                 return {\n                     \"sync_record_id\": sync_record.id,\n                     \"status\": SyncStatus.CONFLICT.value,\n-                    \"conflict_details\": conflict.to_dict()\n+                    \"conflict_details\": conflict.to_dict(),\n                 }\n-            \n+\n             # Apply the sync action\n             result = self._apply_sync_action(sync_record)\n             sync_record.status = SyncStatus.COMPLETED\n-            \n+\n             return {\n                 \"sync_record_id\": sync_record.id,\n                 \"status\": SyncStatus.COMPLETED.value,\n                 \"entity_type\": sync_record.entity_type,\n                 \"entity_id\": sync_record.entity_id,\n                 \"action\": sync_record.action.value,\n-                \"result\": result\n-            }\n-            \n+                \"result\": result,\n+            }\n+\n         except Exception as e:\n             sync_record.status = SyncStatus.FAILED\n             sync_record.error_message = str(e)\n-            \n+\n             return {\n                 \"sync_record_id\": sync_record.id,\n                 \"status\": SyncStatus.FAILED.value,\n-                \"error\": str(e)\n-            }\n-    \n+                \"error\": str(e),\n+            }\n+\n     def _detect_conflicts(self, sync_record: SyncRecord) -> Optional[SyncConflict]:\n         \"\"\"Detect conflicts between client and server data\"\"\"\n         try:\n             entity_type = sync_record.entity_type\n             entity_id = sync_record.entity_id\n-            \n+\n             # Get current server data\n             server_data = None\n             if entity_type == \"orders\":\n                 entity = self.db.query(Order).filter(Order.id == entity_id).first()\n                 if entity:\n                     server_data = {\n                         \"id\": str(entity.id),\n                         \"status\": entity.status,\n                         \"total_amount\": float(entity.total_amount),\n-                        \"updated_at\": entity.updated_at.isoformat() if entity.updated_at else None\n+                        \"updated_at\": (\n+                            entity.updated_at.isoformat() if entity.updated_at else None\n+                        ),\n                     }\n             elif entity_type == \"products\":\n                 entity = self.db.query(Product).filter(Product.id == entity_id).first()\n                 if entity:\n                     server_data = {\n                         \"id\": str(entity.id),\n                         \"name\": entity.name,\n                         \"price\": float(entity.price),\n                         \"stock_quantity\": entity.stock_quantity,\n-                        \"updated_at\": entity.updated_at.isoformat() if entity.updated_at else None\n+                        \"updated_at\": (\n+                            entity.updated_at.isoformat() if entity.updated_at else None\n+                        ),\n                     }\n             # Add other entity types as needed\n-            \n+\n             # Check for conflicts based on action type\n             if sync_record.action == SyncAction.UPDATE and server_data:\n                 client_data = sync_record.data\n                 conflict_fields = []\n-                \n+\n                 # Compare timestamps first\n                 if \"updated_at\" in server_data and \"updated_at\" in client_data:\n-                    server_updated = datetime.fromisoformat(server_data[\"updated_at\"].replace(\"Z\", \"+00:00\"))\n-                    client_updated = datetime.fromisoformat(client_data[\"updated_at\"].replace(\"Z\", \"+00:00\"))\n-                    \n+                    server_updated = datetime.fromisoformat(\n+                        server_data[\"updated_at\"].replace(\"Z\", \"+00:00\")\n+                    )\n+                    client_updated = datetime.fromisoformat(\n+                        client_data[\"updated_at\"].replace(\"Z\", \"+00:00\")\n+                    )\n+\n                     if server_updated > client_updated:\n                         # Server has newer data - potential conflict\n                         # Check specific fields for actual differences\n                         for field in client_data:\n-                            if field in server_data and server_data[field] != client_data[field]:\n+                            if (\n+                                field in server_data\n+                                and server_data[field] != client_data[field]\n+                            ):\n                                 conflict_fields.append(field)\n-                        \n+\n                         if conflict_fields:\n                             return SyncConflict(\n                                 sync_record=sync_record,\n                                 server_data=server_data,\n                                 conflict_fields=conflict_fields,\n-                                conflict_type=\"timestamp_conflict\"\n+                                conflict_type=\"timestamp_conflict\",\n                             )\n-            \n+\n             elif sync_record.action == SyncAction.CREATE and server_data:\n                 # Entity already exists - conflict\n                 return SyncConflict(\n                     sync_record=sync_record,\n                     server_data=server_data,\n                     conflict_fields=[\"id\"],\n-                    conflict_type=\"already_exists\"\n+                    conflict_type=\"already_exists\",\n                 )\n-            \n+\n             elif sync_record.action == SyncAction.DELETE and not server_data:\n                 # Entity already deleted - minor conflict\n                 return SyncConflict(\n                     sync_record=sync_record,\n                     server_data={},\n                     conflict_fields=[\"id\"],\n-                    conflict_type=\"already_deleted\"\n+                    conflict_type=\"already_deleted\",\n                 )\n-            \n+\n             return None\n-            \n+\n         except Exception as e:\n             # If conflict detection fails, treat as no conflict\n             return None\n-    \n+\n     def _apply_sync_action(self, sync_record: SyncRecord) -> Dict[str, Any]:\n         \"\"\"Apply sync action to database\"\"\"\n         entity_type = sync_record.entity_type\n         action = sync_record.action\n         data = sync_record.data\n-        \n+\n         if entity_type == \"orders\":\n             return self._apply_order_action(action, data)\n         elif entity_type == \"products\":\n             return self._apply_product_action(action, data)\n         elif entity_type == \"customers\":\n             return self._apply_customer_action(action, data)\n         elif entity_type == \"payments\":\n             return self._apply_payment_action(action, data)\n         else:\n             raise ValueError(f\"Unsupported entity type: {entity_type}\")\n-    \n-    def _apply_order_action(self, action: SyncAction, data: Dict[str, Any]) -> Dict[str, Any]:\n+\n+    def _apply_order_action(\n+        self, action: SyncAction, data: Dict[str, Any]\n+    ) -> Dict[str, Any]:\n         \"\"\"Apply order sync action\"\"\"\n         if action == SyncAction.CREATE:\n             # Create new order (simplified)\n             return {\"message\": \"Order creation applied\", \"entity_id\": data.get(\"id\")}\n         elif action == SyncAction.UPDATE:\n@@ -486,127 +528,164 @@\n             order = self.db.query(Order).filter(Order.id == data[\"id\"]).first()\n             if order:\n                 order.is_deleted = True\n                 order.updated_at = datetime.now()\n                 return {\"message\": \"Order deletion applied\", \"entity_id\": str(order.id)}\n-        \n+\n         return {\"message\": \"No action applied\"}\n-    \n-    def _apply_product_action(self, action: SyncAction, data: Dict[str, Any]) -> Dict[str, Any]:\n+\n+    def _apply_product_action(\n+        self, action: SyncAction, data: Dict[str, Any]\n+    ) -> Dict[str, Any]:\n         \"\"\"Apply product sync action\"\"\"\n         if action == SyncAction.UPDATE:\n             product = self.db.query(Product).filter(Product.id == data[\"id\"]).first()\n             if product:\n-                product.stock_quantity = data.get(\"stock_quantity\", product.stock_quantity)\n+                product.stock_quantity = data.get(\n+                    \"stock_quantity\", product.stock_quantity\n+                )\n                 product.price = data.get(\"price\", product.price)\n                 product.updated_at = datetime.now()\n-                return {\"message\": \"Product update applied\", \"entity_id\": str(product.id)}\n-        \n+                return {\n+                    \"message\": \"Product update applied\",\n+                    \"entity_id\": str(product.id),\n+                }\n+\n         return {\"message\": \"No action applied\"}\n-    \n-    def _apply_customer_action(self, action: SyncAction, data: Dict[str, Any]) -> Dict[str, Any]:\n+\n+    def _apply_customer_action(\n+        self, action: SyncAction, data: Dict[str, Any]\n+    ) -> Dict[str, Any]:\n         \"\"\"Apply customer sync action\"\"\"\n         # Implementation would handle customer-specific actions\n         return {\"message\": \"Customer action applied\", \"entity_id\": data.get(\"id\")}\n-    \n-    def _apply_payment_action(self, action: SyncAction, data: Dict[str, Any]) -> Dict[str, Any]:\n+\n+    def _apply_payment_action(\n+        self, action: SyncAction, data: Dict[str, Any]\n+    ) -> Dict[str, Any]:\n         \"\"\"Apply payment sync action\"\"\"\n         # Implementation would handle payment-specific actions\n         return {\"message\": \"Payment action applied\", \"entity_id\": data.get(\"id\")}\n-    \n+\n     def _apply_client_data(self, sync_record: SyncRecord) -> Dict[str, Any]:\n         \"\"\"Apply client data in client-wins resolution\"\"\"\n         return self._apply_sync_action(sync_record)\n-    \n-    def _apply_merged_data(self, sync_record: SyncRecord, merged_data: Dict[str, Any]) -> Dict[str, Any]:\n+\n+    def _apply_merged_data(\n+        self, sync_record: SyncRecord, merged_data: Dict[str, Any]\n+    ) -> Dict[str, Any]:\n         \"\"\"Apply merged data in merge resolution\"\"\"\n         # Update sync record data with merged data\n         sync_record.data = merged_data\n         return self._apply_sync_action(sync_record)\n-    \n-    def _get_order_changes(self, restaurant_id: str, since: datetime) -> List[Dict[str, Any]]:\n+\n+    def _get_order_changes(\n+        self, restaurant_id: str, since: datetime\n+    ) -> List[Dict[str, Any]]:\n         \"\"\"Get order changes since timestamp\"\"\"\n-        orders = self.db.query(Order).filter(\n-            and_(\n-                Order.restaurant_id == restaurant_id,\n-                Order.updated_at >= since\n-            )\n-        ).order_by(desc(Order.updated_at)).all()\n-        \n+        orders = (\n+            self.db.query(Order)\n+            .filter(\n+                and_(Order.restaurant_id == restaurant_id, Order.updated_at >= since)\n+            )\n+            .order_by(desc(Order.updated_at))\n+            .all()\n+        )\n+\n         return [\n             {\n                 \"id\": str(order.id),\n                 \"status\": order.status,\n                 \"total_amount\": float(order.total_amount),\n                 \"updated_at\": order.updated_at.isoformat(),\n-                \"action\": \"update\"\n+                \"action\": \"update\",\n             }\n             for order in orders\n         ]\n-    \n-    def _get_product_changes(self, restaurant_id: str, since: datetime) -> List[Dict[str, Any]]:\n+\n+    def _get_product_changes(\n+        self, restaurant_id: str, since: datetime\n+    ) -> List[Dict[str, Any]]:\n         \"\"\"Get product changes since timestamp\"\"\"\n-        products = self.db.query(Product).filter(\n-            and_(\n-                Product.restaurant_id == restaurant_id,\n-                Product.updated_at >= since\n-            )\n-        ).order_by(desc(Product.updated_at)).all()\n-        \n+        products = (\n+            self.db.query(Product)\n+            .filter(\n+                and_(\n+                    Product.restaurant_id == restaurant_id, Product.updated_at >= since\n+                )\n+            )\n+            .order_by(desc(Product.updated_at))\n+            .all()\n+        )\n+\n         return [\n             {\n                 \"id\": str(product.id),\n                 \"name\": product.name,\n                 \"price\": float(product.price),\n                 \"stock_quantity\": product.stock_quantity,\n                 \"updated_at\": product.updated_at.isoformat(),\n-                \"action\": \"update\"\n+                \"action\": \"update\",\n             }\n             for product in products\n         ]\n-    \n-    def _get_customer_changes(self, restaurant_id: str, since: datetime) -> List[Dict[str, Any]]:\n+\n+    def _get_customer_changes(\n+        self, restaurant_id: str, since: datetime\n+    ) -> List[Dict[str, Any]]:\n         \"\"\"Get customer changes since timestamp\"\"\"\n-        customers = self.db.query(Customer).filter(\n-            and_(\n-                Customer.restaurant_id == restaurant_id,\n-                Customer.updated_at >= since\n-            )\n-        ).order_by(desc(Customer.updated_at)).all()\n-        \n+        customers = (\n+            self.db.query(Customer)\n+            .filter(\n+                and_(\n+                    Customer.restaurant_id == restaurant_id,\n+                    Customer.updated_at >= since,\n+                )\n+            )\n+            .order_by(desc(Customer.updated_at))\n+            .all()\n+        )\n+\n         return [\n             {\n                 \"id\": str(customer.id),\n                 \"name\": customer.name,\n                 \"email\": customer.email,\n                 \"phone\": customer.phone,\n                 \"updated_at\": customer.updated_at.isoformat(),\n-                \"action\": \"update\"\n+                \"action\": \"update\",\n             }\n             for customer in customers\n         ]\n-    \n-    def _get_payment_changes(self, restaurant_id: str, since: datetime) -> List[Dict[str, Any]]:\n+\n+    def _get_payment_changes(\n+        self, restaurant_id: str, since: datetime\n+    ) -> List[Dict[str, Any]]:\n         \"\"\"Get payment changes since timestamp\"\"\"\n-        payments = self.db.query(Payment).filter(\n-            and_(\n-                Payment.restaurant_id == restaurant_id,\n-                Payment.updated_at >= since\n-            )\n-        ).order_by(desc(Payment.updated_at)).all()\n-        \n+        payments = (\n+            self.db.query(Payment)\n+            .filter(\n+                and_(\n+                    Payment.restaurant_id == restaurant_id, Payment.updated_at >= since\n+                )\n+            )\n+            .order_by(desc(Payment.updated_at))\n+            .all()\n+        )\n+\n         return [\n             {\n                 \"id\": str(payment.id),\n                 \"order_id\": str(payment.order_id),\n                 \"amount\": float(payment.amount),\n                 \"status\": payment.status,\n                 \"updated_at\": payment.updated_at.isoformat(),\n-                \"action\": \"update\"\n+                \"action\": \"update\",\n             }\n             for payment in payments\n         ]\n+\n \n # Factory function\n def get_sync_manager(db: Session) -> OfflineSyncManager:\n     \"\"\"Get sync manager instance\"\"\"\n-    return OfflineSyncManager(db)\n\\ No newline at end of file\n+    return OfflineSyncManager(db)\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/middleware/feature_gate.py\t2025-08-02 21:56:58.999703+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/middleware/feature_gate.py\t2025-08-02 22:36:03.528427+00:00\n@@ -16,259 +16,290 @@\n from app.core.exceptions import FynloException\n \n \n class FeatureGateError(FynloException):\n     \"\"\"Custom exception for feature gate violations\"\"\"\n-    \n-    def __init__(self, feature_name: str, current_plan: str = None, required_plans: List[str] = None):\n+\n+    def __init__(\n+        self,\n+        feature_name: str,\n+        current_plan: str = None,\n+        required_plans: List[str] = None,\n+    ):\n         self.feature_name = feature_name\n         self.current_plan = current_plan\n         self.required_plans = required_plans or []\n-        \n+\n         detail = {\n             \"error\": \"feature_access_denied\",\n             \"message\": f\"Feature '{feature_name}' is not available in your current plan\",\n             \"feature\": feature_name,\n             \"current_plan\": current_plan,\n             \"upgrade_required\": True,\n-            \"required_plans\": required_plans\n+            \"required_plans\": required_plans,\n         }\n-        \n+\n         super().__init__(status_code=403, detail=detail)\n \n \n class UsageLimitError(FynloException):\n     \"\"\"Custom exception for usage limit violations\"\"\"\n-    \n-    def __init__(self, limit_type: str, current_usage: int, limit: int, current_plan: str = None):\n+\n+    def __init__(\n+        self, limit_type: str, current_usage: int, limit: int, current_plan: str = None\n+    ):\n         self.limit_type = limit_type\n         self.current_usage = current_usage\n         self.limit = limit\n         self.current_plan = current_plan\n-        \n+\n         detail = {\n             \"error\": \"usage_limit_exceeded\",\n             \"message\": f\"Usage limit exceeded for {limit_type}: {current_usage}/{limit}\",\n             \"limit_type\": limit_type,\n             \"current_usage\": current_usage,\n             \"limit\": limit,\n             \"current_plan\": current_plan,\n-            \"upgrade_required\": True\n+            \"upgrade_required\": True,\n         }\n-        \n+\n         super().__init__(status_code=429, detail=detail)\n \n \n-def get_restaurant_subscription(restaurant_id: int, db: Session) -> Optional[RestaurantSubscription]:\n+def get_restaurant_subscription(\n+    restaurant_id: int, db: Session\n+) -> Optional[RestaurantSubscription]:\n     \"\"\"Get active subscription for a restaurant\"\"\"\n-    return db.query(RestaurantSubscription).filter(\n-        RestaurantSubscription.restaurant_id == restaurant_id,\n-        RestaurantSubscription.status.in_(['active', 'trial'])\n-    ).first()\n+    return (\n+        db.query(RestaurantSubscription)\n+        .filter(\n+            RestaurantSubscription.restaurant_id == restaurant_id,\n+            RestaurantSubscription.status.in_([\"active\", \"trial\"]),\n+        )\n+        .first()\n+    )\n \n \n def check_feature_access(restaurant_id: int, feature_name: str, db: Session) -> bool:\n     \"\"\"Check if restaurant has access to a specific feature\"\"\"\n     subscription = get_restaurant_subscription(restaurant_id, db)\n-    \n+\n     if not subscription:\n         return False  # No active subscription\n-    \n+\n     return subscription.has_feature(feature_name)\n \n \n-def check_usage_limit(restaurant_id: int, limit_type: str, db: Session) -> Tuple[bool, int, Optional[int]]:\n+def check_usage_limit(\n+    restaurant_id: int, limit_type: str, db: Session\n+) -> Tuple[bool, int, Optional[int]]:\n     \"\"\"\n     Check if restaurant is at usage limit\n-    \n+\n     Returns:\n         tuple: (at_limit, current_usage, limit)\n     \"\"\"\n     subscription = get_restaurant_subscription(restaurant_id, db)\n-    \n+\n     if not subscription:\n         return True, 0, 0  # No subscription = at limit\n-    \n+\n     # Get current month usage\n     current_month = SubscriptionUsage.get_current_month_key()\n-    usage = db.query(SubscriptionUsage).filter(\n-        SubscriptionUsage.restaurant_id == restaurant_id,\n-        SubscriptionUsage.month_year == current_month\n-    ).first()\n-    \n+    usage = (\n+        db.query(SubscriptionUsage)\n+        .filter(\n+            SubscriptionUsage.restaurant_id == restaurant_id,\n+            SubscriptionUsage.month_year == current_month,\n+        )\n+        .first()\n+    )\n+\n     if not usage:\n         current_usage = 0\n     else:\n         usage_map = {\n-            'orders': usage.orders_count,\n-            'staff': usage.staff_count,\n-            'menu_items': usage.menu_items_count\n+            \"orders\": usage.orders_count,\n+            \"staff\": usage.staff_count,\n+            \"menu_items\": usage.menu_items_count,\n         }\n         current_usage = usage_map.get(limit_type, 0)\n-    \n+\n     plan_limit = subscription.get_limit(limit_type)\n-    \n+\n     if plan_limit is None:  # Unlimited\n         return False, current_usage, None\n-    \n+\n     return current_usage >= plan_limit, current_usage, plan_limit\n \n \n def require_feature(feature_name: str):\n     \"\"\"\n     FastAPI-compatible dependency factory for feature gating.\n-    \n+\n     Returns a dependency function that can be used with Depends().\n-    \n+\n     Usage:\n         @router.get(\"/advanced-report\")\n         async def get_advanced_report(\n             restaurant_id: int = Query(...),\n             db: Session = Depends(get_db),\n             _feature_check = Depends(require_feature('advanced_analytics'))\n         ):\n             pass\n     \"\"\"\n     from fastapi import Query\n-    \n+\n     def feature_dependency(\n         restaurant_id: int = Query(..., description=\"Restaurant ID\"),\n-        db: Session = Depends(get_db)\n+        db: Session = Depends(get_db),\n     ):\n         \"\"\"Dependency that checks feature access\"\"\"\n         if not check_feature_access(restaurant_id, feature_name, db):\n             subscription = get_restaurant_subscription(restaurant_id, db)\n-            current_plan = subscription.plan.name if subscription and subscription.plan else \"none\"\n-            \n+            current_plan = (\n+                subscription.plan.name if subscription and subscription.plan else \"none\"\n+            )\n+\n             raise FeatureGateError(\n                 feature_name=feature_name,\n                 current_plan=current_plan,\n-                required_plans=[\"beta\", \"gamma\"]  # Updated to correct plan names\n+                required_plans=[\"beta\", \"gamma\"],  # Updated to correct plan names\n             )\n         return True  # Return something to indicate success\n-    \n+\n     return feature_dependency\n \n \n def require_usage_limit(limit_type: str, increment: int = 1):\n     \"\"\"\n     FastAPI-compatible dependency factory for usage limit checking.\n-    \n+\n     Returns a dependency function that can be used with Depends().\n-    \n+\n     Usage:\n         @router.post(\"/create-order\")\n         async def create_order(\n             restaurant_id: int = Query(...),\n             db: Session = Depends(get_db),\n             _usage_check = Depends(require_usage_limit('orders', increment=1))\n         ):\n             pass\n     \"\"\"\n     from fastapi import Query\n-    \n+\n     def usage_dependency(\n         restaurant_id: int = Query(..., description=\"Restaurant ID\"),\n-        db: Session = Depends(get_db)\n+        db: Session = Depends(get_db),\n     ):\n         \"\"\"Dependency that checks usage limits\"\"\"\n         # Check usage limit\n-        at_limit, current_usage, limit = check_usage_limit(restaurant_id, limit_type, db)\n-        \n+        at_limit, current_usage, limit = check_usage_limit(\n+            restaurant_id, limit_type, db\n+        )\n+\n         if at_limit:\n             subscription = get_restaurant_subscription(restaurant_id, db)\n-            current_plan = subscription.plan.name if subscription and subscription.plan else \"none\"\n-            \n+            current_plan = (\n+                subscription.plan.name if subscription and subscription.plan else \"none\"\n+            )\n+\n             raise UsageLimitError(\n                 limit_type=limit_type,\n                 current_usage=current_usage,\n                 limit=limit or 0,\n-                current_plan=current_plan\n-            )\n-        \n+                current_plan=current_plan,\n+            )\n+\n         # If we would exceed the limit with this action, also block\n         if limit is not None and (current_usage + increment) > limit:\n             subscription = get_restaurant_subscription(restaurant_id, db)\n-            current_plan = subscription.plan.name if subscription and subscription.plan else \"none\"\n-            \n+            current_plan = (\n+                subscription.plan.name if subscription and subscription.plan else \"none\"\n+            )\n+\n             raise UsageLimitError(\n                 limit_type=limit_type,\n                 current_usage=current_usage,\n                 limit=limit,\n-                current_plan=current_plan\n-            )\n-        \n+                current_plan=current_plan,\n+            )\n+\n         return True  # Return something to indicate success\n-    \n+\n     return usage_dependency\n \n \n # Convenience decorators for common features\n-require_advanced_analytics = require_feature('advanced_analytics')\n-require_inventory_management = require_feature('inventory_management')\n-require_multi_location = require_feature('multi_location')\n-require_api_access = require_feature('api_access')\n-require_custom_branding = require_feature('custom_branding')\n+require_advanced_analytics = require_feature(\"advanced_analytics\")\n+require_inventory_management = require_feature(\"inventory_management\")\n+require_multi_location = require_feature(\"multi_location\")\n+require_api_access = require_feature(\"api_access\")\n+require_custom_branding = require_feature(\"custom_branding\")\n \n # Convenience decorators for common limits\n-require_order_limit = require_usage_limit('orders')\n-require_staff_limit = require_usage_limit('staff')\n-require_menu_limit = require_usage_limit('menu_items')\n+require_order_limit = require_usage_limit(\"orders\")\n+require_staff_limit = require_usage_limit(\"staff\")\n+require_menu_limit = require_usage_limit(\"menu_items\")\n \n \n class FeatureGateService:\n     \"\"\"Service class for feature gating operations\"\"\"\n-    \n+\n     def __init__(self, db: Session):\n         self.db = db\n-    \n+\n     def has_feature(self, restaurant_id: int, feature_name: str) -> bool:\n         \"\"\"Check if restaurant has access to a feature\"\"\"\n         return check_feature_access(restaurant_id, feature_name, self.db)\n-    \n+\n     def get_feature_access_map(self, restaurant_id: int) -> dict:\n         \"\"\"Get a map of all features and their access status\"\"\"\n         subscription = get_restaurant_subscription(restaurant_id, self.db)\n-        \n+\n         if not subscription:\n             return {}\n-        \n+\n         return subscription.plan.features\n-    \n+\n     def is_at_limit(self, restaurant_id: int, limit_type: str) -> bool:\n         \"\"\"Check if restaurant is at a usage limit\"\"\"\n         at_limit, _, _ = check_usage_limit(restaurant_id, limit_type, self.db)\n         return at_limit\n-    \n+\n     def get_usage_summary(self, restaurant_id: int) -> dict:\n         \"\"\"Get comprehensive usage summary for a restaurant\"\"\"\n         subscription = get_restaurant_subscription(restaurant_id, self.db)\n-        \n+\n         if not subscription:\n             return {\"error\": \"No active subscription\"}\n-        \n+\n         current_month = SubscriptionUsage.get_current_month_key()\n-        usage = self.db.query(SubscriptionUsage).filter(\n-            SubscriptionUsage.restaurant_id == restaurant_id,\n-            SubscriptionUsage.month_year == current_month\n-        ).first()\n-        \n+        usage = (\n+            self.db.query(SubscriptionUsage)\n+            .filter(\n+                SubscriptionUsage.restaurant_id == restaurant_id,\n+                SubscriptionUsage.month_year == current_month,\n+            )\n+            .first()\n+        )\n+\n         if not usage:\n             usage_data = {\"orders\": 0, \"staff\": 0, \"menu_items\": 0}\n         else:\n             usage_data = {\n                 \"orders\": usage.orders_count,\n                 \"staff\": usage.staff_count,\n-                \"menu_items\": usage.menu_items_count\n+                \"menu_items\": usage.menu_items_count,\n             }\n-        \n+\n         return {\n             \"plan\": subscription.plan.name,\n             \"status\": subscription.status,\n             \"usage\": usage_data,\n             \"limits\": {\n                 \"orders\": subscription.plan.max_orders_per_month,\n                 \"staff\": subscription.plan.max_staff_accounts,\n-                \"menu_items\": subscription.plan.max_menu_items\n+                \"menu_items\": subscription.plan.max_menu_items,\n             },\n-            \"features\": subscription.plan.features\n-        }\n\\ No newline at end of file\n+            \"features\": subscription.plan.features,\n+        }\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/websocket.py\t2025-08-02 21:56:58.998244+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/websocket.py\t2025-08-02 22:36:03.529904+00:00\n@@ -11,12 +11,14 @@\n from enum import Enum\n \n from app.core.exceptions import FynloException, ErrorCodes\n from app.core.responses import APIResponseHelper\n \n+\n class EventType(str, Enum):\n     \"\"\"WebSocket event types\"\"\"\n+\n     ORDER_CREATED = \"order_created\"\n     ORDER_STATUS_CHANGED = \"order_status_changed\"\n     PAYMENT_COMPLETED = \"payment_completed\"\n     PAYMENT_FAILED = \"payment_failed\"\n     INVENTORY_LOW = \"inventory_low\"\n@@ -26,27 +28,31 @@\n     KITCHEN_UPDATE = \"kitchen_update\"\n     TABLE_STATUS_CHANGED = \"table_status_changed\"\n     RESTAURANT_STATUS = \"restaurant_status\"\n     SYSTEM_NOTIFICATION = \"system_notification\"\n \n+\n class ConnectionType(str, Enum):\n     \"\"\"WebSocket connection types\"\"\"\n+\n     POS = \"pos\"\n     KITCHEN = \"kitchen\"\n     MANAGEMENT = \"management\"\n     CUSTOMER = \"customer\"\n     PLATFORM = \"platform\"\n \n+\n class WebSocketMessage:\n     \"\"\"WebSocket message structure\"\"\"\n+\n     def __init__(\n         self,\n         event_type: EventType,\n         data: Dict[str, Any],\n         restaurant_id: str,\n         user_id: Optional[str] = None,\n-        connection_types: List[ConnectionType] = None\n+        connection_types: List[ConnectionType] = None,\n     ):\n         self.id = str(uuid.uuid4())\n         self.event_type = event_type\n         self.data = data\n         self.restaurant_id = restaurant_id\n@@ -57,23 +63,25 @@\n             \"id\": self.id,\n             \"event_type\": self.event_type.value,\n             \"data\": self.data,\n             \"restaurant_id\": self.restaurant_id,\n             \"user_id\": self.user_id,\n-            \"timestamp\": self.timestamp\n+            \"timestamp\": self.timestamp,\n         }\n+\n \n class WebSocketConnection:\n     \"\"\"WebSocket connection info\"\"\"\n+\n     def __init__(\n         self,\n         websocket: WebSocket,\n         connection_id: str,\n         restaurant_id: str,\n         user_id: Optional[str] = None,\n         connection_type: ConnectionType = ConnectionType.POS,\n-        roles: List[str] = None\n+        roles: List[str] = None,\n     ):\n         self.websocket = websocket\n         self.connection_id = connection_id\n         self.restaurant_id = restaurant_id\n         self.user_id = user_id\n@@ -81,287 +89,294 @@\n         self.roles = roles or []\n         self.connected_at = datetime.now()\n         self.last_ping = datetime.now()\n         self.is_active = True\n \n+\n class WebSocketManager:\n     \"\"\"WebSocket connection manager\"\"\"\n-    \n+\n     def __init__(self):\n         # Store active connections: {connection_id: WebSocketConnection}\n         self.active_connections: Dict[str, WebSocketConnection] = {}\n-        \n+\n         # Store connections by restaurant: {restaurant_id: List[connection_id]}\n         self.restaurant_connections: Dict[str, List[str]] = {}\n-        \n+\n         # Store connections by user: {user_id: List[connection_id]}\n         self.user_connections: Dict[str, List[str]] = {}\n-        \n+\n         # Store connections by type: {connection_type: List[connection_id]}\n         self.type_connections: Dict[str, List[str]] = {}\n-        \n+\n         # Message queue for offline connections\n         self.message_queue: Dict[str, List[WebSocketMessage]] = {}\n-        \n+\n         # Connection statistics\n         self.stats = {\n             \"total_connections\": 0,\n             \"active_connections\": 0,\n             \"messages_sent\": 0,\n-            \"messages_failed\": 0\n+            \"messages_failed\": 0,\n         }\n-    \n+\n     async def connect(\n         self,\n         websocket: WebSocket,\n         restaurant_id: str,\n         user_id: Optional[str] = None,\n         connection_type: ConnectionType = ConnectionType.POS,\n-        roles: List[str] = None\n+        roles: List[str] = None,\n     ) -> str:\n         \"\"\"Accept new WebSocket connection\"\"\"\n         try:\n             await websocket.accept()\n-            \n+\n             connection_id = str(uuid.uuid4())\n             connection = WebSocketConnection(\n                 websocket=websocket,\n                 connection_id=connection_id,\n                 restaurant_id=restaurant_id,\n                 user_id=user_id,\n                 connection_type=connection_type,\n-                roles=roles or []\n+                roles=roles or [],\n             )\n-            \n+\n             # Store connection\n             self.active_connections[connection_id] = connection\n-            \n+\n             # Index by restaurant\n             if restaurant_id not in self.restaurant_connections:\n                 self.restaurant_connections[restaurant_id] = []\n             self.restaurant_connections[restaurant_id].append(connection_id)\n-            \n+\n             # Index by user\n             if user_id:\n                 if user_id not in self.user_connections:\n                     self.user_connections[user_id] = []\n                 self.user_connections[user_id].append(connection_id)\n-            \n+\n             # Index by type\n             type_key = connection_type.value\n             if type_key not in self.type_connections:\n                 self.type_connections[type_key] = []\n             self.type_connections[type_key].append(connection_id)\n-            \n+\n             # Update stats\n             self.stats[\"total_connections\"] += 1\n             self.stats[\"active_connections\"] = len(self.active_connections)\n-            \n+\n             # Send connection confirmation\n             await self.send_to_connection(\n                 connection_id,\n                 WebSocketMessage(\n                     event_type=EventType.SYSTEM_NOTIFICATION,\n                     data={\n                         \"type\": \"connection_established\",\n                         \"connection_id\": connection_id,\n-                        \"message\": \"WebSocket connection established successfully\"\n+                        \"message\": \"WebSocket connection established successfully\",\n                     },\n                     restaurant_id=restaurant_id,\n-                    user_id=user_id\n-                )\n+                    user_id=user_id,\n+                ),\n             )\n-            \n+\n             # Send queued messages if any\n             await self._send_queued_messages(user_id, restaurant_id)\n-            \n+\n             return connection_id\n-            \n+\n         except Exception as e:\n             raise FynloException(\n                 message=f\"Failed to establish WebSocket connection: {str(e)}\",\n                 error_code=ErrorCodes.INTERNAL_ERROR,\n-                status_code=500\n+                status_code=500,\n             )\n-    \n+\n     async def disconnect(self, connection_id: str):\n         \"\"\"Disconnect WebSocket connection\"\"\"\n         try:\n             if connection_id not in self.active_connections:\n                 return\n-            \n+\n             connection = self.active_connections[connection_id]\n-            \n+\n             # Remove from restaurant index\n             if connection.restaurant_id in self.restaurant_connections:\n-                if connection_id in self.restaurant_connections[connection.restaurant_id]:\n-                    self.restaurant_connections[connection.restaurant_id].remove(connection_id)\n+                if (\n+                    connection_id\n+                    in self.restaurant_connections[connection.restaurant_id]\n+                ):\n+                    self.restaurant_connections[connection.restaurant_id].remove(\n+                        connection_id\n+                    )\n                     if not self.restaurant_connections[connection.restaurant_id]:\n                         del self.restaurant_connections[connection.restaurant_id]\n-            \n+\n             # Remove from user index\n             if connection.user_id and connection.user_id in self.user_connections:\n                 if connection_id in self.user_connections[connection.user_id]:\n                     self.user_connections[connection.user_id].remove(connection_id)\n                     if not self.user_connections[connection.user_id]:\n                         del self.user_connections[connection.user_id]\n-            \n+\n             # Remove from type index\n             type_key = connection.connection_type.value\n             if type_key in self.type_connections:\n                 if connection_id in self.type_connections[type_key]:\n                     self.type_connections[type_key].remove(connection_id)\n                     if not self.type_connections[type_key]:\n                         del self.type_connections[type_key]\n-            \n+\n             # Remove from active connections\n             del self.active_connections[connection_id]\n-            \n+\n             # Update stats\n             self.stats[\"active_connections\"] = len(self.active_connections)\n-            \n+\n         except Exception as e:\n             # Log error but don't raise to prevent cascade failures\n             logger.error(f\"Error disconnecting WebSocket {connection_id}: {str(e)}\")\n-    \n+\n     async def send_to_connection(self, connection_id: str, message: WebSocketMessage):\n         \"\"\"Send message to specific connection\"\"\"\n         try:\n             if connection_id not in self.active_connections:\n                 return False\n-            \n+\n             connection = self.active_connections[connection_id]\n-            \n+\n             if not connection.is_active:\n                 return False\n-            \n+\n             message_data = message.to_dict()\n             await connection.websocket.send_text(json.dumps(message_data))\n-            \n+\n             self.stats[\"messages_sent\"] += 1\n             return True\n-            \n+\n         except WebSocketDisconnect:\n             await self.disconnect(connection_id)\n             return False\n         except Exception as e:\n             self.stats[\"messages_failed\"] += 1\n-            logger.error(f\"Failed to send message to connection {connection_id}: {str(e)}\")\n+            logger.error(\n+                f\"Failed to send message to connection {connection_id}: {str(e)}\"\n+            )\n             return False\n-    \n+\n     async def send_to_restaurant(self, restaurant_id: str, message: WebSocketMessage):\n         \"\"\"Send message to all connections in a restaurant\"\"\"\n         if restaurant_id not in self.restaurant_connections:\n             return\n-        \n+\n         connection_ids = self.restaurant_connections[restaurant_id].copy()\n-        \n+\n         for connection_id in connection_ids:\n             await self.send_to_connection(connection_id, message)\n-    \n+\n     async def send_to_user(self, user_id: str, message: WebSocketMessage):\n         \"\"\"Send message to all user connections\"\"\"\n         if user_id not in self.user_connections:\n             # Queue message for when user connects\n             self._queue_message(user_id, message)\n             return\n-        \n+\n         connection_ids = self.user_connections[user_id].copy()\n-        \n+\n         for connection_id in connection_ids:\n             await self.send_to_connection(connection_id, message)\n-    \n-    async def send_to_connection_type(self, connection_type: ConnectionType, message: WebSocketMessage):\n+\n+    async def send_to_connection_type(\n+        self, connection_type: ConnectionType, message: WebSocketMessage\n+    ):\n         \"\"\"Send message to all connections of specific type\"\"\"\n         type_key = connection_type.value\n-        \n+\n         if type_key not in self.type_connections:\n             return\n-        \n+\n         connection_ids = self.type_connections[type_key].copy()\n-        \n+\n         for connection_id in connection_ids:\n             connection = self.active_connections.get(connection_id)\n             if connection and connection.restaurant_id == message.restaurant_id:\n                 await self.send_to_connection(connection_id, message)\n-    \n+\n     async def broadcast_to_restaurant(\n         self,\n         restaurant_id: str,\n         message: WebSocketMessage,\n         connection_types: List[ConnectionType] = None,\n-        exclude_user_id: Optional[str] = None\n+        exclude_user_id: Optional[str] = None,\n     ):\n         \"\"\"Broadcast message to restaurant with filtering\"\"\"\n         if restaurant_id not in self.restaurant_connections:\n             return\n-        \n+\n         connection_ids = self.restaurant_connections[restaurant_id].copy()\n-        \n+\n         for connection_id in connection_ids:\n             connection = self.active_connections.get(connection_id)\n             if not connection:\n                 continue\n-            \n+\n             # Filter by connection type\n             if connection_types and connection.connection_type not in connection_types:\n                 continue\n-            \n+\n             # Exclude specific user\n             if exclude_user_id and connection.user_id == exclude_user_id:\n                 continue\n-            \n+\n             await self.send_to_connection(connection_id, message)\n-    \n+\n     def _queue_message(self, user_id: str, message: WebSocketMessage):\n         \"\"\"Queue message for offline user\"\"\"\n         if user_id not in self.message_queue:\n             self.message_queue[user_id] = []\n-        \n+\n         self.message_queue[user_id].append(message)\n-        \n+\n         # Limit queue size to prevent memory issues\n         if len(self.message_queue[user_id]) > 100:\n             self.message_queue[user_id] = self.message_queue[user_id][-100:]\n-    \n+\n     async def _send_queued_messages(self, user_id: Optional[str], restaurant_id: str):\n         \"\"\"Send queued messages to newly connected user\"\"\"\n         if not user_id or user_id not in self.message_queue:\n             return\n-        \n+\n         queued_messages = self.message_queue[user_id].copy()\n         del self.message_queue[user_id]\n-        \n+\n         for message in queued_messages:\n             # Only send messages for the current restaurant\n             if message.restaurant_id == restaurant_id:\n                 await self.send_to_user(user_id, message)\n-    \n+\n     async def ping_connections(self):\n         \"\"\"Send ping to all connections to check health\"\"\"\n         current_time = datetime.now()\n         disconnected_connections = []\n-        \n+\n         for connection_id, connection in self.active_connections.items():\n             try:\n                 # Send ping\n-                ping_message = {\n-                    \"type\": \"ping\",\n-                    \"timestamp\": current_time.isoformat()\n-                }\n+                ping_message = {\"type\": \"ping\", \"timestamp\": current_time.isoformat()}\n                 await connection.websocket.send_text(json.dumps(ping_message))\n                 connection.last_ping = current_time\n-                \n+\n             except WebSocketDisconnect:\n                 disconnected_connections.append(connection_id)\n             except Exception:\n                 disconnected_connections.append(connection_id)\n-        \n+\n         # Clean up disconnected connections\n         for connection_id in disconnected_connections:\n             await self.disconnect(connection_id)\n-    \n+\n     def get_connection_stats(self) -> Dict[str, Any]:\n         \"\"\"Get connection statistics\"\"\"\n         return {\n             **self.stats,\n             \"connections_by_restaurant\": {\n@@ -370,105 +385,143 @@\n             },\n             \"connections_by_type\": {\n                 conn_type: len(connections)\n                 for conn_type, connections in self.type_connections.items()\n             },\n-            \"queued_messages\": sum(len(messages) for messages in self.message_queue.values())\n+            \"queued_messages\": sum(\n+                len(messages) for messages in self.message_queue.values()\n+            ),\n         }\n+\n \n # Global WebSocket manager instance\n websocket_manager = WebSocketManager()\n \n+\n # Event helper functions\n-async def notify_order_created(order_id: str, restaurant_id: str, order_data: Dict[str, Any]):\n+async def notify_order_created(\n+    order_id: str, restaurant_id: str, order_data: Dict[str, Any]\n+):\n     \"\"\"Notify all connections about new order\"\"\"\n     message = WebSocketMessage(\n         event_type=EventType.ORDER_CREATED,\n         data={\n             \"order_id\": order_id,\n             \"order_number\": order_data.get(\"order_number\"),\n             \"total_amount\": order_data.get(\"total_amount\"),\n             \"items_count\": len(order_data.get(\"items\", [])),\n             \"table_number\": order_data.get(\"table_number\"),\n             \"customer_name\": order_data.get(\"customer_name\"),\n-            \"order_type\": order_data.get(\"order_type\", \"dine_in\")\n+            \"order_type\": order_data.get(\"order_type\", \"dine_in\"),\n         },\n         restaurant_id=restaurant_id,\n-        connection_types=[ConnectionType.POS, ConnectionType.KITCHEN, ConnectionType.MANAGEMENT]\n-    )\n-    \n+        connection_types=[\n+            ConnectionType.POS,\n+            ConnectionType.KITCHEN,\n+            ConnectionType.MANAGEMENT,\n+        ],\n+    )\n+\n     await websocket_manager.broadcast_to_restaurant(\n         restaurant_id,\n         message,\n-        connection_types=[ConnectionType.POS, ConnectionType.KITCHEN, ConnectionType.MANAGEMENT]\n-    )\n-\n-async def notify_order_status_changed(order_id: str, restaurant_id: str, old_status: str, new_status: str, order_data: Dict[str, Any]):\n+        connection_types=[\n+            ConnectionType.POS,\n+            ConnectionType.KITCHEN,\n+            ConnectionType.MANAGEMENT,\n+        ],\n+    )\n+\n+\n+async def notify_order_status_changed(\n+    order_id: str,\n+    restaurant_id: str,\n+    old_status: str,\n+    new_status: str,\n+    order_data: Dict[str, Any],\n+):\n     \"\"\"Notify about order status change\"\"\"\n     message = WebSocketMessage(\n         event_type=EventType.ORDER_STATUS_CHANGED,\n         data={\n             \"order_id\": order_id,\n             \"order_number\": order_data.get(\"order_number\"),\n             \"old_status\": old_status,\n             \"new_status\": new_status,\n             \"total_amount\": order_data.get(\"total_amount\"),\n             \"table_number\": order_data.get(\"table_number\"),\n-            \"updated_at\": datetime.now().isoformat()\n+            \"updated_at\": datetime.now().isoformat(),\n         },\n         restaurant_id=restaurant_id,\n-        connection_types=[ConnectionType.POS, ConnectionType.KITCHEN, ConnectionType.MANAGEMENT]\n-    )\n-    \n+        connection_types=[\n+            ConnectionType.POS,\n+            ConnectionType.KITCHEN,\n+            ConnectionType.MANAGEMENT,\n+        ],\n+    )\n+\n     await websocket_manager.broadcast_to_restaurant(restaurant_id, message)\n \n-async def notify_payment_completed(payment_id: str, order_id: str, restaurant_id: str, payment_data: Dict[str, Any]):\n+\n+async def notify_payment_completed(\n+    payment_id: str, order_id: str, restaurant_id: str, payment_data: Dict[str, Any]\n+):\n     \"\"\"Notify about successful payment\"\"\"\n     message = WebSocketMessage(\n         event_type=EventType.PAYMENT_COMPLETED,\n         data={\n             \"payment_id\": payment_id,\n             \"order_id\": order_id,\n             \"order_number\": payment_data.get(\"order_number\"),\n             \"amount\": payment_data.get(\"amount\"),\n             \"payment_method\": payment_data.get(\"payment_method\"),\n             \"transaction_id\": payment_data.get(\"transaction_id\"),\n-            \"completed_at\": datetime.now().isoformat()\n+            \"completed_at\": datetime.now().isoformat(),\n         },\n         restaurant_id=restaurant_id,\n-        connection_types=[ConnectionType.POS, ConnectionType.MANAGEMENT]\n-    )\n-    \n+        connection_types=[ConnectionType.POS, ConnectionType.MANAGEMENT],\n+    )\n+\n     await websocket_manager.broadcast_to_restaurant(\n         restaurant_id,\n         message,\n-        connection_types=[ConnectionType.POS, ConnectionType.MANAGEMENT]\n-    )\n-\n-async def notify_inventory_low(product_id: str, restaurant_id: str, product_name: str, current_stock: int, min_stock: int):\n+        connection_types=[ConnectionType.POS, ConnectionType.MANAGEMENT],\n+    )\n+\n+\n+async def notify_inventory_low(\n+    product_id: str,\n+    restaurant_id: str,\n+    product_name: str,\n+    current_stock: int,\n+    min_stock: int,\n+):\n     \"\"\"Notify about low inventory\"\"\"\n     message = WebSocketMessage(\n         event_type=EventType.INVENTORY_LOW,\n         data={\n             \"product_id\": product_id,\n             \"product_name\": product_name,\n             \"current_stock\": current_stock,\n             \"minimum_stock\": min_stock,\n             \"severity\": \"warning\" if current_stock > 0 else \"critical\",\n-            \"message\": f\"{product_name} is running low (only {current_stock} left)\"\n+            \"message\": f\"{product_name} is running low (only {current_stock} left)\",\n         },\n         restaurant_id=restaurant_id,\n-        connection_types=[ConnectionType.POS, ConnectionType.MANAGEMENT]\n-    )\n-    \n+        connection_types=[ConnectionType.POS, ConnectionType.MANAGEMENT],\n+    )\n+\n     await websocket_manager.broadcast_to_restaurant(\n         restaurant_id,\n         message,\n-        connection_types=[ConnectionType.POS, ConnectionType.MANAGEMENT]\n-    )\n-\n-async def notify_kitchen_update(order_id: str, restaurant_id: str, update_type: str, update_data: Dict[str, Any]):\n+        connection_types=[ConnectionType.POS, ConnectionType.MANAGEMENT],\n+    )\n+\n+\n+async def notify_kitchen_update(\n+    order_id: str, restaurant_id: str, update_type: str, update_data: Dict[str, Any]\n+):\n     \"\"\"Notify kitchen about order updates\"\"\"\n     message = WebSocketMessage(\n         event_type=EventType.KITCHEN_UPDATE,\n         data={\n             \"order_id\": order_id,\n@@ -476,56 +529,63 @@\n             \"update_type\": update_type,  # \"item_ready\", \"order_ready\", \"special_request\"\n             \"item_id\": update_data.get(\"item_id\"),\n             \"item_name\": update_data.get(\"item_name\"),\n             \"special_instructions\": update_data.get(\"special_instructions\"),\n             \"estimated_time\": update_data.get(\"estimated_time\"),\n-            \"updated_at\": datetime.now().isoformat()\n+            \"updated_at\": datetime.now().isoformat(),\n         },\n         restaurant_id=restaurant_id,\n-        connection_types=[ConnectionType.KITCHEN, ConnectionType.POS]\n-    )\n-    \n+        connection_types=[ConnectionType.KITCHEN, ConnectionType.POS],\n+    )\n+\n     await websocket_manager.broadcast_to_restaurant(\n         restaurant_id,\n         message,\n-        connection_types=[ConnectionType.KITCHEN, ConnectionType.POS]\n-    )\n-\n-async def notify_user_activity(user_id: str, restaurant_id: str, activity_type: str, activity_data: Dict[str, Any]):\n+        connection_types=[ConnectionType.KITCHEN, ConnectionType.POS],\n+    )\n+\n+\n+async def notify_user_activity(\n+    user_id: str, restaurant_id: str, activity_type: str, activity_data: Dict[str, Any]\n+):\n     \"\"\"Notify about user login/logout\"\"\"\n-    event_type = EventType.USER_LOGIN if activity_type == \"login\" else EventType.USER_LOGOUT\n-    \n+    event_type = (\n+        EventType.USER_LOGIN if activity_type == \"login\" else EventType.USER_LOGOUT\n+    )\n+\n     message = WebSocketMessage(\n         event_type=event_type,\n         data={\n             \"user_id\": user_id,\n             \"username\": activity_data.get(\"username\"),\n             \"role\": activity_data.get(\"role\"),\n             \"activity_type\": activity_type,\n-            \"timestamp\": datetime.now().isoformat()\n+            \"timestamp\": datetime.now().isoformat(),\n         },\n         restaurant_id=restaurant_id,\n         user_id=user_id,\n-        connection_types=[ConnectionType.MANAGEMENT]\n-    )\n-    \n+        connection_types=[ConnectionType.MANAGEMENT],\n+    )\n+\n     await websocket_manager.broadcast_to_restaurant(\n         restaurant_id,\n         message,\n         connection_types=[ConnectionType.MANAGEMENT],\n-        exclude_user_id=user_id\n-    )\n-\n-    async def broadcast_order_update(self, restaurant_id: str, order_data: Dict[str, Any]):\n+        exclude_user_id=user_id,\n+    )\n+\n+    async def broadcast_order_update(\n+        self, restaurant_id: str, order_data: Dict[str, Any]\n+    ):\n         \"\"\"Broadcast order update to all relevant connections\"\"\"\n         action = order_data.get(\"action\", \"updated\")\n-        \n+\n         if action == \"created\":\n             await notify_order_created(\n                 order_id=order_data[\"id\"],\n                 restaurant_id=restaurant_id,\n-                order_data=order_data\n+                order_data=order_data,\n             )\n         else:\n             message = WebSocketMessage(\n                 event_type=EventType.ORDER_STATUS_CHANGED,\n                 data={\n@@ -535,23 +595,33 @@\n                     \"action\": action,\n                     \"total_amount\": order_data.get(\"total_amount\"),\n                     \"table_number\": order_data.get(\"table_number\"),\n                     \"items\": order_data.get(\"items\"),\n                     \"reason\": order_data.get(\"reason\"),\n-                    \"updated_at\": datetime.now().isoformat()\n+                    \"updated_at\": datetime.now().isoformat(),\n                 },\n                 restaurant_id=restaurant_id,\n-                connection_types=[ConnectionType.POS, ConnectionType.KITCHEN, ConnectionType.MANAGEMENT]\n+                connection_types=[\n+                    ConnectionType.POS,\n+                    ConnectionType.KITCHEN,\n+                    ConnectionType.MANAGEMENT,\n+                ],\n             )\n-            \n+\n             await self.broadcast_to_restaurant(\n                 restaurant_id,\n                 message,\n-                connection_types=[ConnectionType.POS, ConnectionType.KITCHEN, ConnectionType.MANAGEMENT]\n+                connection_types=[\n+                    ConnectionType.POS,\n+                    ConnectionType.KITCHEN,\n+                    ConnectionType.MANAGEMENT,\n+                ],\n             )\n-    \n-    async def broadcast_kitchen_update(self, restaurant_id: str, kitchen_data: Dict[str, Any]):\n+\n+    async def broadcast_kitchen_update(\n+        self, restaurant_id: str, kitchen_data: Dict[str, Any]\n+    ):\n         \"\"\"Broadcast kitchen update to kitchen displays and POS\"\"\"\n         message = WebSocketMessage(\n             event_type=EventType.KITCHEN_UPDATE,\n             data={\n                 \"order_id\": kitchen_data.get(\"order_id\"),\n@@ -559,24 +629,26 @@\n                 \"status\": kitchen_data.get(\"status\"),\n                 \"action\": kitchen_data.get(\"action\", \"new_order\"),\n                 \"items\": kitchen_data.get(\"items\"),\n                 \"table_number\": kitchen_data.get(\"table_number\"),\n                 \"special_instructions\": kitchen_data.get(\"special_instructions\"),\n-                \"updated_at\": datetime.now().isoformat()\n+                \"updated_at\": datetime.now().isoformat(),\n             },\n             restaurant_id=restaurant_id,\n-            connection_types=[ConnectionType.KITCHEN, ConnectionType.POS]\n+            connection_types=[ConnectionType.KITCHEN, ConnectionType.POS],\n         )\n-        \n+\n         await self.broadcast_to_restaurant(\n             restaurant_id,\n             message,\n-            connection_types=[ConnectionType.KITCHEN, ConnectionType.POS]\n+            connection_types=[ConnectionType.KITCHEN, ConnectionType.POS],\n         )\n+\n \n # Global WebSocket manager instance\n websocket_manager = WebSocketManager()\n \n-# Utility functions  \n+\n+# Utility functions\n def get_websocket_manager() -> WebSocketManager:\n     \"\"\"Get the global WebSocket manager instance\"\"\"\n-    return websocket_manager\n\\ No newline at end of file\n+    return websocket_manager\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/middleware/tenant_isolation_middleware.py\t2025-08-02 19:52:26.972224+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/middleware/tenant_isolation_middleware.py\t2025-08-02 22:36:03.535276+00:00\n@@ -18,104 +18,104 @@\n \n class TenantIsolationMiddleware(BaseHTTPMiddleware):\n     \"\"\"\n     Middleware to enforce tenant isolation across all API endpoints\n     \"\"\"\n-    \n+\n     def __init__(self, app: ASGIApp):\n         super().__init__(app)\n-        \n+\n     async def dispatch(self, request: Request, call_next: Callable) -> Response:\n         \"\"\"\n         Process each request to ensure tenant isolation\n         \"\"\"\n         # Skip middleware for non-API routes\n         if not request.url.path.startswith(\"/api/\"):\n             return await call_next(request)\n-        \n+\n         # Skip for public endpoints\n         public_endpoints = [\n             \"/api/v1/auth/login\",\n             \"/api/v1/auth/register\",\n             \"/api/v1/auth/verify\",\n             \"/api/v1/health\",\n             \"/api/docs\",\n-            \"/api/openapi.json\"\n+            \"/api/openapi.json\",\n         ]\n-        \n+\n         if any(request.url.path.startswith(endpoint) for endpoint in public_endpoints):\n             return await call_next(request)\n-        \n+\n         try:\n             # Log the request for security audit\n             if hasattr(request.state, \"user\") and request.state.user:\n                 user = request.state.user\n                 is_platform_owner = TenantSecurity.is_platform_owner(user)\n-                \n+\n                 logger.info(\n                     f\"API Request: {request.method} {request.url.path} | \"\n                     f\"User: {user.email} | \"\n                     f\"Role: {user.role} | \"\n                     f\"Restaurant: {user.restaurant_id} | \"\n                     f\"Platform Owner: {is_platform_owner}\"\n                 )\n-                \n+\n                 # Add security headers to response\n                 response = await call_next(request)\n                 response.headers[\"X-Tenant-Isolated\"] = \"true\"\n                 response.headers[\"X-Platform-Owner\"] = str(is_platform_owner)\n-                \n+\n                 return response\n             else:\n                 # No user context, proceed normally\n                 return await call_next(request)\n-                \n+\n         except Exception as e:\n             logger.error(f\"Tenant isolation middleware error: {str(e)}\")\n             # Don't break the request, just log the error\n             return await call_next(request)\n \n \n class TenantValidationMiddleware:\n     \"\"\"\n     Additional middleware to validate tenant access in request payloads\n     \"\"\"\n-    \n+\n     @staticmethod\n     async def validate_request_body(request: Request) -> None:\n         \"\"\"\n         Validate that request body doesn't contain cross-tenant data\n         \"\"\"\n         # Only check POST, PUT, PATCH requests\n         if request.method not in [\"POST\", \"PUT\", \"PATCH\"]:\n             return\n-        \n+\n         # Get request body\n         body = await request.body()\n         if not body:\n             return\n-        \n+\n         try:\n             data = json.loads(body)\n-            \n+\n             # Check if restaurant_id is in the payload\n             if \"restaurant_id\" in data and hasattr(request.state, \"user\"):\n                 user = request.state.user\n-                \n+\n                 # Platform owners can specify any restaurant_id\n                 if TenantSecurity.is_platform_owner(user):\n                     return\n-                \n+\n                 # Other users cannot specify a different restaurant_id\n                 if data[\"restaurant_id\"] != str(user.restaurant_id):\n                     logger.warning(\n                         f\"Tenant violation attempt: User {user.email} tried to access \"\n                         f\"restaurant {data['restaurant_id']} but belongs to {user.restaurant_id}\"\n                     )\n                     # The actual validation will happen in the endpoint\n                     # This is just for logging/monitoring\n-                    \n+\n         except json.JSONDecodeError:\n             # Not JSON, skip validation\n             pass\n         except Exception as e:\n-            logger.error(f\"Error validating request body: {str(e)}\")\n\\ No newline at end of file\n+            logger.error(f\"Error validating request body: {str(e)}\")\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models/activity_log.py\t2025-08-02 10:59:17.995614+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models/activity_log.py\t2025-08-02 22:36:03.586385+00:00\n@@ -8,47 +8,52 @@\n import uuid\n from datetime import datetime\n \n from app.core.database import Base\n \n+\n class PortalActivityLog(Base):\n     \"\"\"Model for tracking portal user activities\"\"\"\n-    \n+\n     __tablename__ = \"portal_activity_logs\"\n-    \n+\n     id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n     user_id = Column(UUID(as_uuid=True), ForeignKey(\"users.id\"), nullable=False)\n-    restaurant_id = Column(UUID(as_uuid=True), ForeignKey(\"restaurants.id\"), nullable=True)\n+    restaurant_id = Column(\n+        UUID(as_uuid=True), ForeignKey(\"restaurants.id\"), nullable=True\n+    )\n     action = Column(String(255), nullable=False)\n     details = Column(JSONB, nullable=True, default={})\n     ip_address = Column(String(45), nullable=True)  # Supports IPv4 and IPv6\n     user_agent = Column(Text, nullable=True)\n     created_at = Column(DateTime, nullable=False, default=datetime.utcnow)\n-    \n+\n     # Relationships\n     user = relationship(\"User\", backref=\"activity_logs\")\n     restaurant = relationship(\"Restaurant\", backref=\"activity_logs\")\n-    \n+\n     # Indexes for performance\n     __table_args__ = (\n-        Index('idx_activity_log_user_id', 'user_id'),\n-        Index('idx_activity_log_restaurant_id', 'restaurant_id'),\n-        Index('idx_activity_log_action', 'action'),\n-        Index('idx_activity_log_created_at', 'created_at'),\n-        Index('idx_activity_log_user_restaurant', 'user_id', 'restaurant_id'),\n+        Index(\"idx_activity_log_user_id\", \"user_id\"),\n+        Index(\"idx_activity_log_restaurant_id\", \"restaurant_id\"),\n+        Index(\"idx_activity_log_action\", \"action\"),\n+        Index(\"idx_activity_log_created_at\", \"created_at\"),\n+        Index(\"idx_activity_log_user_restaurant\", \"user_id\", \"restaurant_id\"),\n     )\n-    \n+\n     def __repr__(self):\n-        return f\"<PortalActivityLog {self.action} by {self.user_id} at {self.created_at}>\"\n-    \n+        return (\n+            f\"<PortalActivityLog {self.action} by {self.user_id} at {self.created_at}>\"\n+        )\n+\n     def to_dict(self):\n         \"\"\"Convert to dictionary for API responses\"\"\"\n         return {\n             \"id\": str(self.id),\n             \"user_id\": str(self.user_id),\n             \"restaurant_id\": str(self.restaurant_id) if self.restaurant_id else None,\n             \"action\": self.action,\n             \"details\": self.details,\n             \"ip_address\": self.ip_address,\n             \"user_agent\": self.user_agent,\n-            \"created_at\": self.created_at.isoformat() if self.created_at else None\n-        }\n\\ No newline at end of file\n+            \"created_at\": self.created_at.isoformat() if self.created_at else None,\n+        }\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/validation.py\t2025-08-02 21:56:58.998039+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/validation.py\t2025-08-02 22:36:03.593284+00:00\n@@ -9,376 +9,400 @@\n import re\n from pydantic import BaseModel\n \n from app.core.exceptions import FynloException, ErrorCodes\n \n+\n class ValidationError(BaseModel):\n     \"\"\"Individual validation error\"\"\"\n+\n     field: str\n     message: str\n     code: str\n     value: Any = None\n \n+\n class ValidationResult(BaseModel):\n     \"\"\"Validation result with multiple errors\"\"\"\n+\n     is_valid: bool\n     errors: List[ValidationError] = []\n-    \n+\n     def add_error(self, field: str, message: str, code: str, value: Any = None):\n         \"\"\"Add a validation error\"\"\"\n-        self.errors.append(ValidationError(\n-            field=field,\n-            message=message,\n-            code=code,\n-            value=value\n-        ))\n+        self.errors.append(\n+            ValidationError(field=field, message=message, code=code, value=value)\n+        )\n         self.is_valid = False\n+\n \n class BusinessValidator:\n     \"\"\"Business logic validation for Fynlo POS operations\"\"\"\n-    \n+\n     @staticmethod\n-    def validate_order_creation(order_data: dict, products: List[dict]) -> ValidationResult:\n+    def validate_order_creation(\n+        order_data: dict, products: List[dict]\n+    ) -> ValidationResult:\n         \"\"\"Validate order creation with comprehensive checks\"\"\"\n         result = ValidationResult(is_valid=True)\n-        \n+\n         # Validate items exist\n-        if not order_data.get('items') or len(order_data['items']) == 0:\n+        if not order_data.get(\"items\") or len(order_data[\"items\"]) == 0:\n             result.add_error(\n                 field=\"items\",\n                 message=\"Order must contain at least one item\",\n-                code=\"EMPTY_ORDER\"\n-            )\n-        \n+                code=\"EMPTY_ORDER\",\n+            )\n+\n         # Validate product availability and quantities\n-        product_map = {str(p['id']): p for p in products}\n-        \n-        for i, item in enumerate(order_data.get('items', [])):\n+        product_map = {str(p[\"id\"]): p for p in products}\n+\n+        for i, item in enumerate(order_data.get(\"items\", [])):\n             item_field = f\"items[{i}]\"\n-            \n+\n             # Check product exists\n-            product_id = str(item.get('product_id', ''))\n+            product_id = str(item.get(\"product_id\", \"\"))\n             if product_id not in product_map:\n                 result.add_error(\n                     field=f\"{item_field}.product_id\",\n                     message=f\"Product {product_id} not found or unavailable\",\n                     code=\"PRODUCT_NOT_FOUND\",\n-                    value=product_id\n+                    value=product_id,\n                 )\n                 continue\n-            \n+\n             product = product_map[product_id]\n-            \n+\n             # Check quantity is valid\n-            quantity = item.get('quantity', 0)\n+            quantity = item.get(\"quantity\", 0)\n             if not isinstance(quantity, int) or quantity <= 0:\n                 result.add_error(\n                     field=f\"{item_field}.quantity\",\n                     message=\"Quantity must be a positive integer\",\n                     code=\"INVALID_QUANTITY\",\n-                    value=quantity\n+                    value=quantity,\n                 )\n-            \n+\n             # Check stock if tracking enabled\n-            if product.get('stock_tracking', False):\n-                available_stock = product.get('stock_quantity', 0)\n+            if product.get(\"stock_tracking\", False):\n+                available_stock = product.get(\"stock_quantity\", 0)\n                 if quantity > available_stock:\n                     result.add_error(\n                         field=f\"{item_field}.quantity\",\n                         message=f\"Insufficient stock. Available: {available_stock}, Requested: {quantity}\",\n                         code=\"INSUFFICIENT_STOCK\",\n-                        value={\"requested\": quantity, \"available\": available_stock}\n+                        value={\"requested\": quantity, \"available\": available_stock},\n                     )\n-            \n+\n             # Validate price consistency\n-            expected_price = float(product.get('price', 0))\n-            item_price = float(item.get('unit_price', 0))\n+            expected_price = float(product.get(\"price\", 0))\n+            item_price = float(item.get(\"unit_price\", 0))\n             if abs(expected_price - item_price) > 0.01:  # Allow 1 cent tolerance\n                 result.add_error(\n                     field=f\"{item_field}.unit_price\",\n                     message=f\"Price mismatch. Expected: \u00a3{expected_price:.2f}, Provided: \u00a3{item_price:.2f}\",\n                     code=\"PRICE_MISMATCH\",\n-                    value={\"expected\": expected_price, \"provided\": item_price}\n+                    value={\"expected\": expected_price, \"provided\": item_price},\n                 )\n-        \n+\n         # Validate order type\n         valid_order_types = [\"dine_in\", \"takeaway\", \"delivery\"]\n-        order_type = order_data.get('order_type', '')\n+        order_type = order_data.get(\"order_type\", \"\")\n         if order_type not in valid_order_types:\n             result.add_error(\n                 field=\"order_type\",\n                 message=f\"Invalid order type. Must be one of: {', '.join(valid_order_types)}\",\n                 code=\"INVALID_ORDER_TYPE\",\n-                value=order_type\n-            )\n-        \n+                value=order_type,\n+            )\n+\n         # Validate table number for dine-in orders\n         if order_type == \"dine_in\":\n-            table_number = order_data.get('table_number')\n+            table_number = order_data.get(\"table_number\")\n             if not table_number or not str(table_number).strip():\n                 result.add_error(\n                     field=\"table_number\",\n                     message=\"Table number is required for dine-in orders\",\n-                    code=\"MISSING_TABLE_NUMBER\"\n+                    code=\"MISSING_TABLE_NUMBER\",\n                 )\n-        \n+\n         return result\n-    \n+\n     @staticmethod\n-    def validate_order_status_transition(current_status: str, new_status: str) -> ValidationResult:\n+    def validate_order_status_transition(\n+        current_status: str, new_status: str\n+    ) -> ValidationResult:\n         \"\"\"Validate order status transitions\"\"\"\n         result = ValidationResult(is_valid=True)\n-        \n+\n         # Define valid status transitions\n         valid_transitions = {\n             \"pending\": [\"confirmed\", \"cancelled\"],\n             \"confirmed\": [\"preparing\", \"cancelled\"],\n             \"preparing\": [\"ready\", \"cancelled\"],\n             \"ready\": [\"completed\", \"cancelled\"],\n             \"completed\": [],  # Final state\n-            \"cancelled\": []   # Final state\n+            \"cancelled\": [],  # Final state\n         }\n-        \n+\n         valid_statuses = list(valid_transitions.keys())\n-        \n+\n         # Check if statuses are valid\n         if current_status not in valid_statuses:\n             result.add_error(\n                 field=\"current_status\",\n                 message=f\"Invalid current status: {current_status}\",\n                 code=\"INVALID_STATUS\",\n-                value=current_status\n-            )\n-        \n+                value=current_status,\n+            )\n+\n         if new_status not in valid_statuses:\n             result.add_error(\n                 field=\"new_status\",\n                 message=f\"Invalid new status: {new_status}\",\n                 code=\"INVALID_STATUS\",\n-                value=new_status\n-            )\n-        \n+                value=new_status,\n+            )\n+\n         # Check if transition is allowed\n         if result.is_valid and new_status not in valid_transitions[current_status]:\n             result.add_error(\n                 field=\"status_transition\",\n                 message=f\"Cannot transition from '{current_status}' to '{new_status}'. Valid transitions: {', '.join(valid_transitions[current_status]) or 'None (final state)'}\",\n                 code=\"INVALID_STATUS_TRANSITION\",\n-                value={\"from\": current_status, \"to\": new_status}\n-            )\n-        \n+                value={\"from\": current_status, \"to\": new_status},\n+            )\n+\n         return result\n-    \n+\n     @staticmethod\n-    def validate_payment_amount(order_total: float, payment_amount: float, payment_method: str) -> ValidationResult:\n+    def validate_payment_amount(\n+        order_total: float, payment_amount: float, payment_method: str\n+    ) -> ValidationResult:\n         \"\"\"Validate payment amounts and methods\"\"\"\n         result = ValidationResult(is_valid=True)\n-        \n+\n         # Check amount is positive\n         if payment_amount <= 0:\n             result.add_error(\n                 field=\"amount\",\n                 message=\"Payment amount must be positive\",\n                 code=\"INVALID_AMOUNT\",\n-                value=payment_amount\n-            )\n-        \n+                value=payment_amount,\n+            )\n+\n         # Check amount matches order total (allow small tolerance for floating point)\n         tolerance = 0.01\n         if abs(payment_amount - order_total) > tolerance:\n             result.add_error(\n                 field=\"amount\",\n                 message=f\"Payment amount (\u00a3{payment_amount:.2f}) does not match order total (\u00a3{order_total:.2f})\",\n                 code=\"AMOUNT_MISMATCH\",\n-                value={\"payment\": payment_amount, \"order_total\": order_total}\n-            )\n-        \n+                value={\"payment\": payment_amount, \"order_total\": order_total},\n+            )\n+\n         # Validate payment method\n         valid_methods = [\"qr_code\", \"stripe\", \"apple_pay\", \"cash\"]\n         if payment_method not in valid_methods:\n             result.add_error(\n                 field=\"payment_method\",\n                 message=f\"Invalid payment method. Must be one of: {', '.join(valid_methods)}\",\n                 code=\"INVALID_PAYMENT_METHOD\",\n-                value=payment_method\n-            )\n-        \n+                value=payment_method,\n+            )\n+\n         return result\n-    \n+\n     @staticmethod\n-    def validate_business_hours(operation_time: datetime, business_hours: dict) -> ValidationResult:\n+    def validate_business_hours(\n+        operation_time: datetime, business_hours: dict\n+    ) -> ValidationResult:\n         \"\"\"Validate operation against business hours\"\"\"\n         result = ValidationResult(is_valid=True)\n-        \n+\n         if not business_hours:\n             # No restrictions if business hours not configured\n             return result\n-        \n-        day_name = operation_time.strftime('%A').lower()  # monday, tuesday, etc.\n+\n+        day_name = operation_time.strftime(\"%A\").lower()  # monday, tuesday, etc.\n         day_hours = business_hours.get(day_name)\n-        \n+\n         if not day_hours:\n             result.add_error(\n                 field=\"operation_time\",\n                 message=f\"Restaurant is closed on {day_name.title()}\",\n                 code=\"CLOSED_DAY\",\n-                value=day_name\n+                value=day_name,\n             )\n             return result\n-        \n+\n         # Check if within operating hours\n         current_time = operation_time.time()\n-        open_time = time.fromisoformat(day_hours.get('open', '00:00'))\n-        close_time = time.fromisoformat(day_hours.get('close', '23:59'))\n-        \n+        open_time = time.fromisoformat(day_hours.get(\"open\", \"00:00\"))\n+        close_time = time.fromisoformat(day_hours.get(\"close\", \"23:59\"))\n+\n         if not (open_time <= current_time <= close_time):\n             result.add_error(\n                 field=\"operation_time\",\n                 message=f\"Restaurant is closed. Operating hours: {open_time.strftime('%H:%M')} - {close_time.strftime('%H:%M')}\",\n                 code=\"OUTSIDE_BUSINESS_HOURS\",\n                 value={\n-                    \"current\": current_time.strftime('%H:%M'),\n-                    \"open\": open_time.strftime('%H:%M'),\n-                    \"close\": close_time.strftime('%H:%M')\n-                }\n-            )\n-        \n+                    \"current\": current_time.strftime(\"%H:%M\"),\n+                    \"open\": open_time.strftime(\"%H:%M\"),\n+                    \"close\": close_time.strftime(\"%H:%M\"),\n+                },\n+            )\n+\n         return result\n-    \n+\n     @staticmethod\n     def validate_customer_data(customer_data: dict) -> ValidationResult:\n         \"\"\"Validate customer information\"\"\"\n         result = ValidationResult(is_valid=True)\n-        \n+\n         # Validate required fields\n-        if not customer_data.get('first_name', '').strip():\n+        if not customer_data.get(\"first_name\", \"\").strip():\n             result.add_error(\n                 field=\"first_name\",\n                 message=\"First name is required\",\n-                code=\"MISSING_REQUIRED_FIELD\"\n-            )\n-        \n-        if not customer_data.get('last_name', '').strip():\n+                code=\"MISSING_REQUIRED_FIELD\",\n+            )\n+\n+        if not customer_data.get(\"last_name\", \"\").strip():\n             result.add_error(\n                 field=\"last_name\",\n                 message=\"Last name is required\",\n-                code=\"MISSING_REQUIRED_FIELD\"\n-            )\n-        \n+                code=\"MISSING_REQUIRED_FIELD\",\n+            )\n+\n         # Validate email format if provided\n-        email = customer_data.get('email', '').strip()\n+        email = customer_data.get(\"email\", \"\").strip()\n         if email:\n-            email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n+            email_pattern = r\"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\"\n             if not re.match(email_pattern, email):\n                 result.add_error(\n                     field=\"email\",\n                     message=\"Invalid email format\",\n                     code=\"INVALID_EMAIL_FORMAT\",\n-                    value=email\n+                    value=email,\n                 )\n-        \n+\n         # Validate phone format if provided (UK format)\n-        phone = customer_data.get('phone', '').strip()\n+        phone = customer_data.get(\"phone\", \"\").strip()\n         if phone:\n             # Remove common separators\n-            clean_phone = re.sub(r'[\\s\\-\\(\\)]', '', phone)\n-            uk_phone_pattern = r'^(\\+44|0)[1-9]\\d{8,9}$'\n+            clean_phone = re.sub(r\"[\\s\\-\\(\\)]\", \"\", phone)\n+            uk_phone_pattern = r\"^(\\+44|0)[1-9]\\d{8,9}$\"\n             if not re.match(uk_phone_pattern, clean_phone):\n                 result.add_error(\n                     field=\"phone\",\n                     message=\"Invalid UK phone number format\",\n                     code=\"INVALID_PHONE_FORMAT\",\n-                    value=phone\n+                    value=phone,\n                 )\n-        \n+\n         # At least one contact method required\n         if not email and not phone:\n             result.add_error(\n                 field=\"contact\",\n                 message=\"Either email or phone number is required\",\n-                code=\"MISSING_CONTACT_INFO\"\n-            )\n-        \n+                code=\"MISSING_CONTACT_INFO\",\n+            )\n+\n         return result\n-    \n+\n     @staticmethod\n     def validate_image_upload(file_data: dict) -> ValidationResult:\n         \"\"\"Validate image upload data\"\"\"\n         result = ValidationResult(is_valid=True)\n-        \n+\n         # Check file size (already validated in file_upload.py, but double-check)\n         max_size = 10 * 1024 * 1024  # 10MB\n-        file_size = file_data.get('size', 0)\n-        \n+        file_size = file_data.get(\"size\", 0)\n+\n         if file_size > max_size:\n             result.add_error(\n                 field=\"file_size\",\n                 message=f\"File too large. Maximum size: {max_size // (1024*1024)}MB\",\n                 code=\"FILE_TOO_LARGE\",\n-                value={\"size\": file_size, \"max_size\": max_size}\n-            )\n-        \n+                value={\"size\": file_size, \"max_size\": max_size},\n+            )\n+\n         # Validate file type\n-        allowed_types = ['image/jpeg', 'image/png', 'image/webp', 'image/gif']\n-        file_type = file_data.get('mime_type', '')\n-        \n+        allowed_types = [\"image/jpeg\", \"image/png\", \"image/webp\", \"image/gif\"]\n+        file_type = file_data.get(\"mime_type\", \"\")\n+\n         if file_type not in allowed_types:\n             result.add_error(\n                 field=\"file_type\",\n                 message=f\"Unsupported file type. Allowed: {', '.join(allowed_types)}\",\n                 code=\"UNSUPPORTED_FILE_TYPE\",\n-                value=file_type\n-            )\n-        \n+                value=file_type,\n+            )\n+\n         return result\n \n-def raise_validation_exception(validation_result: ValidationResult, message: str = \"Validation failed\"):\n+\n+def raise_validation_exception(\n+    validation_result: ValidationResult, message: str = \"Validation failed\"\n+):\n     \"\"\"Convert validation result to FynloException\"\"\"\n     if not validation_result.is_valid:\n         error_details = {\n             \"validation_errors\": [error.dict() for error in validation_result.errors],\n-            \"error_count\": len(validation_result.errors)\n+            \"error_count\": len(validation_result.errors),\n         }\n-        \n+\n         # Create user-friendly message\n         if len(validation_result.errors) == 1:\n             user_message = validation_result.errors[0].message\n         else:\n             user_message = f\"{message} ({len(validation_result.errors)} errors found)\"\n-        \n+\n         raise FynloException(\n             message=user_message,\n             error_code=ErrorCodes.VALIDATION_ERROR,\n             details=error_details,\n-            status_code=400\n+            status_code=400,\n         )\n+\n \n # Convenience functions for common validations\n def validate_order_or_raise(order_data: dict, products: List[dict]):\n     \"\"\"Validate order creation and raise exception if invalid\"\"\"\n     result = BusinessValidator.validate_order_creation(order_data, products)\n     if not result.is_valid:\n         raise_validation_exception(result, \"Order validation failed\")\n \n+\n def validate_status_transition_or_raise(current_status: str, new_status: str):\n     \"\"\"Validate status transition and raise exception if invalid\"\"\"\n-    result = BusinessValidator.validate_order_status_transition(current_status, new_status)\n+    result = BusinessValidator.validate_order_status_transition(\n+        current_status, new_status\n+    )\n     if not result.is_valid:\n         raise_validation_exception(result, \"Invalid status transition\")\n \n-def validate_payment_or_raise(order_total: float, payment_amount: float, payment_method: str):\n+\n+def validate_payment_or_raise(\n+    order_total: float, payment_amount: float, payment_method: str\n+):\n     \"\"\"Validate payment and raise exception if invalid\"\"\"\n-    result = BusinessValidator.validate_payment_amount(order_total, payment_amount, payment_method)\n+    result = BusinessValidator.validate_payment_amount(\n+        order_total, payment_amount, payment_method\n+    )\n     if not result.is_valid:\n         raise_validation_exception(result, \"Payment validation failed\")\n+\n \n def validate_customer_or_raise(customer_data: dict):\n     \"\"\"Validate customer data and raise exception if invalid\"\"\"\n     result = BusinessValidator.validate_customer_data(customer_data)\n     if not result.is_valid:\n         raise_validation_exception(result, \"Customer validation failed\")\n \n+\n \"\"\"\n Input validation schemas and helpers for Fynlo POS\n Provides JSON schema validation for all JSONB fields in database models\n \"\"\"\n \n@@ -388,117 +412,126 @@\n from jsonschema import validate, ValidationError as JSONSchemaError\n \n \n class AddressSchema(BaseModel):\n     \"\"\"Validation schema for restaurant address\"\"\"\n+\n     street: str\n     city: str\n     state: str\n     postal_code: str\n     country: str = \"GB\"\n-    \n-    @validator('postal_code')\n+\n+    @validator(\"postal_code\")\n     def validate_postal_code(cls, v):\n         \"\"\"Validate UK postal code format\"\"\"\n-        if not re.match(r'^[A-Z]{1,2}[0-9R][0-9A-Z]? [0-9][A-Z]{2}$', v.upper()):\n-            raise ValueError('Invalid UK postal code format')\n+        if not re.match(r\"^[A-Z]{1,2}[0-9R][0-9A-Z]? [0-9][A-Z]{2}$\", v.upper()):\n+            raise ValueError(\"Invalid UK postal code format\")\n         return v.upper()\n \n \n class BusinessHoursSchema(BaseModel):\n     \"\"\"Validation schema for business hours\"\"\"\n+\n     monday: Optional[Dict[str, str]] = None\n     tuesday: Optional[Dict[str, str]] = None\n     wednesday: Optional[Dict[str, str]] = None\n     thursday: Optional[Dict[str, str]] = None\n     friday: Optional[Dict[str, str]] = None\n     saturday: Optional[Dict[str, str]] = None\n     sunday: Optional[Dict[str, str]] = None\n-    \n-    @validator('*', pre=True)\n+\n+    @validator(\"*\", pre=True)\n     def validate_day_hours(cls, v):\n         \"\"\"Validate day hours format\"\"\"\n         if v is None:\n             return None\n         if not isinstance(v, dict):\n-            raise ValueError('Day hours must be a dictionary')\n-        if 'open' not in v or 'close' not in v:\n+            raise ValueError(\"Day hours must be a dictionary\")\n+        if \"open\" not in v or \"close\" not in v:\n             raise ValueError('Day hours must have \"open\" and \"close\" times')\n-        \n+\n         # Validate time format (HH:MM)\n-        time_pattern = r'^([01]?[0-9]|2[0-3]):[0-5][0-9]$'\n-        if not re.match(time_pattern, v['open']) or not re.match(time_pattern, v['close']):\n-            raise ValueError('Time must be in HH:MM format')\n-        \n+        time_pattern = r\"^([01]?[0-9]|2[0-3]):[0-5][0-9]$\"\n+        if not re.match(time_pattern, v[\"open\"]) or not re.match(\n+            time_pattern, v[\"close\"]\n+        ):\n+            raise ValueError(\"Time must be in HH:MM format\")\n+\n         return v\n \n \n class TaxConfigurationSchema(BaseModel):\n     \"\"\"Validation schema for tax configuration\"\"\"\n+\n     vatEnabled: bool\n     vatRate: float\n     serviceTaxEnabled: bool\n     serviceTaxRate: float\n-    \n-    @validator('vatRate', 'serviceTaxRate')\n+\n+    @validator(\"vatRate\", \"serviceTaxRate\")\n     def validate_tax_rates(cls, v):\n         \"\"\"Validate tax rates are reasonable\"\"\"\n         if v < 0 or v > 100:\n-            raise ValueError('Tax rate must be between 0 and 100')\n+            raise ValueError(\"Tax rate must be between 0 and 100\")\n         return v\n \n \n class PaymentMethodSchema(BaseModel):\n     \"\"\"Validation schema for individual payment method\"\"\"\n+\n     enabled: bool\n     feePercentage: Optional[float] = 0.0\n     requiresAuth: Optional[bool] = False\n-    \n-    @validator('feePercentage')\n+\n+    @validator(\"feePercentage\")\n     def validate_fee_percentage(cls, v):\n         \"\"\"Validate fee percentage is reasonable\"\"\"\n         if v is not None and (v < 0 or v > 10):\n-            raise ValueError('Fee percentage must be between 0 and 10')\n+            raise ValueError(\"Fee percentage must be between 0 and 10\")\n         return v\n \n \n class PaymentMethodsSchema(BaseModel):\n     \"\"\"Validation schema for payment methods configuration\"\"\"\n+\n     qrCode: Optional[PaymentMethodSchema] = None\n     cash: Optional[PaymentMethodSchema] = None\n     card: Optional[PaymentMethodSchema] = None\n     applePay: Optional[PaymentMethodSchema] = None\n     giftCard: Optional[PaymentMethodSchema] = None\n \n \n class RestaurantSettingsSchema(BaseModel):\n     \"\"\"Validation schema for restaurant settings\"\"\"\n+\n     currency: str = \"GBP\"\n     autoAcceptOrders: bool = True\n     orderTimeout: int = 30  # minutes\n     requireTableNumber: bool = True\n     enableLoyaltyProgram: bool = True\n     loyaltyPointsPerPound: float = 1.0\n-    \n-    @validator('currency')\n+\n+    @validator(\"currency\")\n     def validate_currency(cls, v):\n         \"\"\"Validate currency code\"\"\"\n-        valid_currencies = ['GBP', 'EUR', 'USD']\n+        valid_currencies = [\"GBP\", \"EUR\", \"USD\"]\n         if v not in valid_currencies:\n-            raise ValueError(f'Currency must be one of: {valid_currencies}')\n-        return v\n-    \n-    @validator('orderTimeout')\n+            raise ValueError(f\"Currency must be one of: {valid_currencies}\")\n+        return v\n+\n+    @validator(\"orderTimeout\")\n     def validate_order_timeout(cls, v):\n         \"\"\"Validate order timeout is reasonable\"\"\"\n         if v < 5 or v > 120:\n-            raise ValueError('Order timeout must be between 5 and 120 minutes')\n+            raise ValueError(\"Order timeout must be between 5 and 120 minutes\")\n         return v\n \n \n class UserPermissionsSchema(BaseModel):\n     \"\"\"Validation schema for user permissions\"\"\"\n+\n     canManageUsers: bool = False\n     canManageMenu: bool = False\n     canViewReports: bool = False\n     canProcessPayments: bool = False\n     canManageOrders: bool = False\n@@ -506,107 +539,117 @@\n     canManageSettings: bool = False\n \n \n class CustomerPreferencesSchema(BaseModel):\n     \"\"\"Validation schema for customer preferences\"\"\"\n+\n     dietaryRestrictions: Optional[List[str]] = []\n     favoriteItems: Optional[List[str]] = []\n     preferredTable: Optional[str] = None\n     communicationPreferences: Optional[Dict[str, bool]] = {}\n-    \n-    @validator('dietaryRestrictions')\n+\n+    @validator(\"dietaryRestrictions\")\n     def validate_dietary_restrictions(cls, v):\n         \"\"\"Validate dietary restrictions\"\"\"\n         valid_restrictions = [\n-            'vegetarian', 'vegan', 'gluten-free', 'dairy-free', \n-            'nut-free', 'halal', 'kosher', 'low-sodium'\n+            \"vegetarian\",\n+            \"vegan\",\n+            \"gluten-free\",\n+            \"dairy-free\",\n+            \"nut-free\",\n+            \"halal\",\n+            \"kosher\",\n+            \"low-sodium\",\n         ]\n         if v:\n             for restriction in v:\n                 if restriction not in valid_restrictions:\n-                    raise ValueError(f'Invalid dietary restriction: {restriction}')\n+                    raise ValueError(f\"Invalid dietary restriction: {restriction}\")\n         return v\n \n \n class ProductModifierSchema(BaseModel):\n     \"\"\"Validation schema for product modifiers\"\"\"\n+\n     name: str\n     type: str  # 'single', 'multiple', 'quantity'\n     required: bool = False\n     options: List[Dict[str, Union[str, float]]]\n-    \n-    @validator('type')\n+\n+    @validator(\"type\")\n     def validate_modifier_type(cls, v):\n         \"\"\"Validate modifier type\"\"\"\n-        valid_types = ['single', 'multiple', 'quantity']\n+        valid_types = [\"single\", \"multiple\", \"quantity\"]\n         if v not in valid_types:\n-            raise ValueError(f'Modifier type must be one of: {valid_types}')\n-        return v\n-    \n-    @validator('options')\n+            raise ValueError(f\"Modifier type must be one of: {valid_types}\")\n+        return v\n+\n+    @validator(\"options\")\n     def validate_options(cls, v):\n         \"\"\"Validate modifier options\"\"\"\n         for option in v:\n-            if 'name' not in option or 'price' not in option:\n+            if \"name\" not in option or \"price\" not in option:\n                 raise ValueError('Each option must have \"name\" and \"price\"')\n-            if not isinstance(option['price'], (int, float)):\n-                raise ValueError('Option price must be a number')\n+            if not isinstance(option[\"price\"], (int, float)):\n+                raise ValueError(\"Option price must be a number\")\n         return v\n \n \n class OrderItemSchema(BaseModel):\n     \"\"\"Validation schema for order items\"\"\"\n+\n     productId: str\n     name: str\n     price: float\n     quantity: int\n     modifiers: Optional[List[Dict[str, Any]]] = []\n     specialInstructions: Optional[str] = None\n-    \n-    @validator('price')\n+\n+    @validator(\"price\")\n     def validate_price(cls, v):\n         \"\"\"Validate price is positive\"\"\"\n         if v < 0:\n-            raise ValueError('Price must be positive')\n-        return v\n-    \n-    @validator('quantity')\n+            raise ValueError(\"Price must be positive\")\n+        return v\n+\n+    @validator(\"quantity\")\n     def validate_quantity(cls, v):\n         \"\"\"Validate quantity is positive\"\"\"\n         if v <= 0:\n-            raise ValueError('Quantity must be positive')\n+            raise ValueError(\"Quantity must be positive\")\n         return v\n \n \n class PaymentMetadataSchema(BaseModel):\n     \"\"\"Validation schema for payment metadata\"\"\"\n+\n     stripePaymentId: Optional[str] = None\n     cashReceived: Optional[float] = None\n     changeGiven: Optional[float] = None\n     cardLast4: Optional[str] = None\n     approvalCode: Optional[str] = None\n-    \n-    @validator('cardLast4')\n+\n+    @validator(\"cardLast4\")\n     def validate_card_last4(cls, v):\n         \"\"\"Validate card last 4 digits\"\"\"\n-        if v is not None and not re.match(r'^\\d{4}$', v):\n-            raise ValueError('Card last 4 must be 4 digits')\n+        if v is not None and not re.match(r\"^\\d{4}$\", v):\n+            raise ValueError(\"Card last 4 must be 4 digits\")\n         return v\n \n \n # Validation helper functions\n def validate_jsonb_field(data: Any, schema_class: BaseModel) -> Dict[str, Any]:\n     \"\"\"\n     Validate JSONB field data against a schema\n-    \n+\n     Args:\n         data: The data to validate\n         schema_class: The Pydantic schema class\n-        \n+\n     Returns:\n         Validated and cleaned data\n-        \n+\n     Raises:\n         ValidationError: If validation fails\n     \"\"\"\n     try:\n         validated = schema_class.parse_obj(data)\n@@ -615,96 +658,118 @@\n         raise ValidationError(f\"JSONB validation failed: {e}\")\n \n \n def validate_email(email: str) -> bool:\n     \"\"\"Validate email format\"\"\"\n-    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n+    pattern = r\"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\"\n     return bool(re.match(pattern, email))\n \n \n def validate_phone(phone: str) -> bool:\n     \"\"\"Validate UK phone number format\"\"\"\n     # UK phone number patterns\n     patterns = [\n-        r'^(\\+44|0)[1-9]\\d{8,9}$',  # Standard UK numbers\n-        r'^(\\+44|0)7\\d{9}$',        # Mobile numbers\n+        r\"^(\\+44|0)[1-9]\\d{8,9}$\",  # Standard UK numbers\n+        r\"^(\\+44|0)7\\d{9}$\",  # Mobile numbers\n     ]\n-    return any(re.match(pattern, phone.replace(' ', '').replace('-', '')) for pattern in patterns)\n+    return any(\n+        re.match(pattern, phone.replace(\" \", \"\").replace(\"-\", \"\"))\n+        for pattern in patterns\n+    )\n \n \n def validate_file_size(file_size: int, max_size_mb: int = 5) -> bool:\n     \"\"\"Validate file size\"\"\"\n     max_size_bytes = max_size_mb * 1024 * 1024\n     return file_size <= max_size_bytes\n \n \n def validate_image_format(filename: str) -> bool:\n     \"\"\"Validate image file format\"\"\"\n-    valid_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.webp']\n+    valid_extensions = [\".jpg\", \".jpeg\", \".png\", \".gif\", \".webp\"]\n     return any(filename.lower().endswith(ext) for ext in valid_extensions)\n \n \n def sanitize_string(text: str, max_length: int = 255) -> str:\n     \"\"\"Sanitize string input\"\"\"\n     if not text:\n         return \"\"\n-    \n+\n     # Remove potentially dangerous characters - comprehensive list\n-    # Includes: HTML/XML tags, quotes, parentheses, semicolons, ampersands, \n+    # Includes: HTML/XML tags, quotes, parentheses, semicolons, ampersands,\n     # plus signs, backticks, pipes, backslashes, asterisks, equals, dollar signs\n-    cleaned = re.sub(r'[<>\"\\';()&+`|\\\\*=$]', '', text)\n-    \n+    cleaned = re.sub(r'[<>\"\\';()&+`|\\\\*=$]', \"\", text)\n+\n     # Remove SQL keywords (case insensitive)\n-    sql_keywords = ['SELECT', 'INSERT', 'UPDATE', 'DELETE', 'DROP', 'CREATE', \n-                    'ALTER', 'EXEC', 'EXECUTE', 'UNION', 'FROM', 'WHERE',\n-                    'JOIN', 'SCRIPT', 'JAVASCRIPT', 'VBSCRIPT']\n+    sql_keywords = [\n+        \"SELECT\",\n+        \"INSERT\",\n+        \"UPDATE\",\n+        \"DELETE\",\n+        \"DROP\",\n+        \"CREATE\",\n+        \"ALTER\",\n+        \"EXEC\",\n+        \"EXECUTE\",\n+        \"UNION\",\n+        \"FROM\",\n+        \"WHERE\",\n+        \"JOIN\",\n+        \"SCRIPT\",\n+        \"JAVASCRIPT\",\n+        \"VBSCRIPT\",\n+    ]\n     for keyword in sql_keywords:\n-        cleaned = re.sub(rf'\\b{keyword}\\b', '', cleaned, flags=re.IGNORECASE)\n-    \n+        cleaned = re.sub(rf\"\\b{keyword}\\b\", \"\", cleaned, flags=re.IGNORECASE)\n+\n     # Trim whitespace and limit length\n     cleaned = cleaned.strip()[:max_length]\n-    \n+\n     return cleaned\n \n \n # Schema mapping for database fields\n VALIDATION_SCHEMAS = {\n-    'restaurant.address': AddressSchema,\n-    'restaurant.business_hours': BusinessHoursSchema,\n-    'restaurant.settings': RestaurantSettingsSchema,\n-    'restaurant.tax_configuration': TaxConfigurationSchema,\n-    'restaurant.payment_methods': PaymentMethodsSchema,\n-    'user.permissions': UserPermissionsSchema,\n-    'customer.preferences': CustomerPreferencesSchema,\n-    'product.dietary_info': lambda x: x if isinstance(x, list) else [],\n-    'product.modifiers': lambda x: [ProductModifierSchema.parse_obj(m).dict() for m in x] if x else [],\n-    'order.items': lambda x: [OrderItemSchema.parse_obj(item).dict() for item in x] if x else [],\n-    'payment.payment_metadata': PaymentMetadataSchema,\n+    \"restaurant.address\": AddressSchema,\n+    \"restaurant.business_hours\": BusinessHoursSchema,\n+    \"restaurant.settings\": RestaurantSettingsSchema,\n+    \"restaurant.tax_configuration\": TaxConfigurationSchema,\n+    \"restaurant.payment_methods\": PaymentMethodsSchema,\n+    \"user.permissions\": UserPermissionsSchema,\n+    \"customer.preferences\": CustomerPreferencesSchema,\n+    \"product.dietary_info\": lambda x: x if isinstance(x, list) else [],\n+    \"product.modifiers\": lambda x: (\n+        [ProductModifierSchema.parse_obj(m).dict() for m in x] if x else []\n+    ),\n+    \"order.items\": lambda x: (\n+        [OrderItemSchema.parse_obj(item).dict() for item in x] if x else []\n+    ),\n+    \"payment.payment_metadata\": PaymentMetadataSchema,\n }\n \n \n def validate_model_jsonb_fields(model_name: str, field_name: str, data: Any) -> Any:\n     \"\"\"\n     Validate JSONB field for a specific model\n-    \n+\n     Args:\n         model_name: Name of the database model (e.g., 'restaurant')\n         field_name: Name of the JSONB field (e.g., 'address')\n         data: Data to validate\n-        \n+\n     Returns:\n         Validated data\n     \"\"\"\n     schema_key = f\"{model_name}.{field_name}\"\n-    \n+\n     if schema_key in VALIDATION_SCHEMAS:\n         schema = VALIDATION_SCHEMAS[schema_key]\n-        \n+\n         if callable(schema) and not issubclass(schema, BaseModel):\n             # Custom validation function\n             return schema(data)\n         else:\n             # Pydantic schema class\n             return validate_jsonb_field(data, schema)\n-    \n+\n     # No specific validation, return as-is\n-    return data\n\\ No newline at end of file\n+    return data\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/middleware/version_middleware.py\t2025-08-02 21:56:59.000242+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/middleware/version_middleware.py\t2025-08-02 22:36:03.596344+00:00\n@@ -9,178 +9,181 @@\n from typing import Optional\n import logging\n \n logger = logging.getLogger(__name__)\n \n+\n class APIVersionMiddleware:\n     \"\"\"\n     Middleware to handle API versioning and provide backward compatibility\n-    \n+\n     Features:\n     - Automatic /api/ to /api/v1/ routing\n     - WebSocket path normalization\n     - Version header detection\n     - Graceful fallback mechanisms\n     \"\"\"\n-    \n+\n     def __init__(self, app):\n         self.app = app\n-        \n+\n     async def __call__(self, scope, receive, send):\n         if scope[\"type\"] == \"http\":\n             # Handle HTTP requests\n             request = Request(scope, receive)\n             path = request.url.path\n-            \n+\n             # Check if path needs version routing\n             rewritten_path = self.rewrite_api_path(path)\n-            \n+\n             if rewritten_path != path:\n                 # Log the rewrite for debugging\n                 logger.info(f\"API version rewrite: {path} -> {rewritten_path}\")\n-                \n+\n                 # Update the scope with new path\n                 scope[\"path\"] = rewritten_path\n                 scope[\"raw_path\"] = rewritten_path.encode()\n-                \n+\n         elif scope[\"type\"] == \"websocket\":\n             # Handle WebSocket connections\n             path = scope[\"path\"]\n             rewritten_path = self.rewrite_websocket_path(path)\n-            \n+\n             if rewritten_path != path:\n                 logger.info(f\"WebSocket path rewrite: {path} -> {rewritten_path}\")\n                 scope[\"path\"] = rewritten_path\n                 scope[\"raw_path\"] = rewritten_path.encode()\n-        \n+\n         # Continue with the request\n         await self.app(scope, receive, send)\n-    \n+\n     def rewrite_api_path(self, path: str) -> str:\n         \"\"\"\n         Rewrite API paths to ensure version consistency\n-        \n+\n         Examples:\n         /api/products -> /api/v1/products\n         /api/v1/products -> /api/v1/products (unchanged)\n         /health -> /health (unchanged)\n         \"\"\"\n-        \n+\n         # Pattern for unversioned API calls\n-        unversioned_pattern = r'^/api/(?!v\\d+/)(.+)$'\n+        unversioned_pattern = r\"^/api/(?!v\\d+/)(.+)$\"\n         match = re.match(unversioned_pattern, path)\n-        \n+\n         if match:\n             # Extract the resource path\n             resource_path = match.group(1)\n             # Add v1 version\n             return f\"/api/v1/{resource_path}\"\n-        \n+\n         return path\n-    \n+\n     def rewrite_websocket_path(self, path: str) -> str:\n         \"\"\"\n         Rewrite WebSocket paths for consistency\n-        \n+\n         Examples:\n         /ws/{restaurant_id} -> /api/v1/websocket/ws/{restaurant_id}\n         /websocket/{restaurant_id} -> /api/v1/websocket/ws/{restaurant_id}\n         \"\"\"\n-        \n+\n         # Pattern for direct WebSocket paths\n         ws_patterns = [\n-            (r'^/ws/(.+)$', r'/api/v1/websocket/ws/\\1'),\n-            (r'^/websocket/(.+)$', r'/api/v1/websocket/ws/\\1'),\n+            (r\"^/ws/(.+)$\", r\"/api/v1/websocket/ws/\\1\"),\n+            (r\"^/websocket/(.+)$\", r\"/api/v1/websocket/ws/\\1\"),\n         ]\n-        \n+\n         for pattern, replacement in ws_patterns:\n             if re.match(pattern, path):\n                 return re.sub(pattern, replacement, path)\n-        \n+\n         return path\n-    \n+\n     def extract_version_from_headers(self, request: Request) -> Optional[str]:\n         \"\"\"\n         Extract API version from request headers\n-        \n+\n         Checks for:\n         - X-API-Version header\n         - Accept header with version\n         \"\"\"\n-        \n+\n         # Check X-API-Version header\n         api_version = request.headers.get(\"x-api-version\")\n         if api_version:\n             return f\"v{api_version}\" if not api_version.startswith(\"v\") else api_version\n-        \n+\n         # Check Accept header for version\n         accept_header = request.headers.get(\"accept\", \"\")\n-        version_match = re.search(r'application/json;version=(\\d+)', accept_header)\n+        version_match = re.search(r\"application/json;version=(\\d+)\", accept_header)\n         if version_match:\n             return f\"v{version_match.group(1)}\"\n-        \n+\n         return None\n \n \n def add_version_headers_to_response(request: Request, response: Response) -> Response:\n     \"\"\"\n     Add version information to response headers\n     \"\"\"\n-    \n+\n     # Add current API version to response\n     response.headers[\"X-API-Version\"] = \"1\"\n     response.headers[\"X-API-Version-Supported\"] = \"1\"\n-    \n+\n     # Add compatibility information\n     response.headers[\"X-API-Backward-Compatible\"] = \"true\"\n-    \n+\n     return response\n \n \n class WebSocketPathNormalizer:\n     \"\"\"\n     Utility class for WebSocket path normalization\n     \"\"\"\n-    \n+\n     @staticmethod\n-    def normalize_ws_path(path: str, restaurant_id: str, connection_type: str = \"general\") -> str:\n+    def normalize_ws_path(\n+        path: str, restaurant_id: str, connection_type: str = \"general\"\n+    ) -> str:\n         \"\"\"\n         Normalize WebSocket path to standard format\n-        \n+\n         Args:\n             path: Original path\n             restaurant_id: Restaurant ID\n             connection_type: Type of connection (general, kitchen, pos, management)\n-            \n+\n         Returns:\n             Normalized path\n         \"\"\"\n-        \n+\n         base_path = f\"/api/v1/websocket/ws\"\n-        \n+\n         if connection_type == \"general\":\n             return f\"{base_path}/{restaurant_id}\"\n         else:\n             return f\"{base_path}/{connection_type}/{restaurant_id}\"\n-    \n+\n     @staticmethod\n     def extract_restaurant_id_from_path(path: str) -> Optional[str]:\n         \"\"\"\n         Extract restaurant ID from WebSocket path\n         \"\"\"\n-        \n+\n         patterns = [\n-            r'/ws/([^/]+)',\n-            r'/websocket/([^/]+)',\n-            r'/api/v1/websocket/ws/([^/]+)',\n+            r\"/ws/([^/]+)\",\n+            r\"/websocket/([^/]+)\",\n+            r\"/api/v1/websocket/ws/([^/]+)\",\n         ]\n-        \n+\n         for pattern in patterns:\n             match = re.search(pattern, path)\n             if match:\n                 return match.group(1)\n-        \n+\n         return None\n \n \n # Configuration constants\n API_VERSION_CONFIG = {\n@@ -188,6 +191,6 @@\n     \"supported_versions\": [\"v1\"],\n     \"default_version_for_unversioned\": \"v1\",\n     \"enable_backward_compatibility\": True,\n     \"enable_websocket_normalization\": True,\n     \"log_version_rewrites\": True,\n-} \n\\ No newline at end of file\n+}\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/middleware/sql_injection_waf.py\t2025-08-02 19:23:36.824973+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/middleware/sql_injection_waf.py\t2025-08-02 22:36:03.602180+00:00\n@@ -1,9 +1,10 @@\n \"\"\"\n SQL Injection Web Application Firewall (WAF) Middleware\n Provides an additional layer of protection against SQL injection attacks\n \"\"\"\n+\n import re\n import json\n import logging\n from typing import Dict, List, Any, Optional\n from fastapi import Request\n@@ -22,55 +23,47 @@\n class SQLInjectionWAFMiddleware(BaseHTTPMiddleware):\n     \"\"\"\n     Web Application Firewall middleware to detect and block SQL injection attempts.\n     This provides defense-in-depth security in addition to parameterized queries.\n     \"\"\"\n-    \n+\n     # SQL injection patterns to detect\n     SQL_INJECTION_PATTERNS = [\n         # SQL Keywords and commands\n         r\"\\b(union|select|insert|update|delete|drop|create|alter|exec|execute)\\b.*\\b(from|where|table|into)\\b\",\n         r\"\\b(exec|execute)\\s*\\(\",\n         r\"\\b(xp_|sp_)\\w+\",  # Extended stored procedures\n-        \n         # SQL comments\n         r\"(-{2}|/\\*|\\*/|#)\",\n-        \n         # SQL operators and special characters\n         r\"(\\s|^)'(\\s|;|$)\",  # Lone quotes\n         r\";\\s*(drop|delete|truncate|update|insert|create|alter)\",\n-        \n         # Boolean-based patterns\n         r\"(\\'|\\\")\\s*(or|and)\\s*(\\d+\\s*=\\s*\\d+|\\'?\\w+\\'?\\s*=\\s*\\'?\\w+\\'?)\",\n         r\"\\b(or|and)\\s+\\d+\\s*=\\s*\\d+\",\n-        \n         # Time-based blind SQL injection\n         r\"\\b(sleep|waitfor|delay|benchmark|pg_sleep)\\s*\\(\",\n-        \n         # Stacked queries\n         r\";\\s*\\b(select|insert|update|delete|drop|create)\\b\",\n-        \n         # Common injection endings\n         r\"(\\'|\\\")\\s*;?\\s*(-{2}|#|/\\*)\",\n-        \n         # Hex injection\n         r\"0x[0-9a-fA-F]+\",\n-        \n         # Function-based patterns\n         r\"\\b(ascii|char|concat|substring|length|substr|instr|cast|convert)\\s*\\(\",\n-        \n         # Information schema queries\n         r\"\\b(information_schema|sysobjects|syscolumns|sysusers)\\b\",\n-        \n         # Out-of-band attacks\n         r\"\\b(load_file|into\\s+(out|dump)file)\\b\",\n     ]\n-    \n+\n     # Compile patterns for efficiency\n-    COMPILED_PATTERNS = [re.compile(pattern, re.IGNORECASE | re.DOTALL) \n-                        for pattern in SQL_INJECTION_PATTERNS]\n-    \n+    COMPILED_PATTERNS = [\n+        re.compile(pattern, re.IGNORECASE | re.DOTALL)\n+        for pattern in SQL_INJECTION_PATTERNS\n+    ]\n+\n     # Suspicious character sequences\n     SUSPICIOUS_SEQUENCES = [\n         \"' or '\",\n         \"' and '\",\n         \"1=1\",\n@@ -82,190 +75,192 @@\n         \"'; drop\",\n         \"'; delete\",\n         \"'; update\",\n         \"'; insert\",\n     ]\n-    \n+\n     # Whitelist of allowed endpoints that might have special requirements\n     ENDPOINT_WHITELIST = [\n         \"/docs\",\n         \"/redoc\",\n         \"/openapi.json\",\n         \"/health\",\n         \"/metrics\",\n     ]\n-    \n+\n     def __init__(self, app, enabled: bool = True, log_attacks: bool = True):\n         super().__init__(app)\n         self.enabled = enabled\n         self.log_attacks = log_attacks\n         self.attack_counter = 0\n-    \n+\n     async def dispatch(self, request: Request, call_next):\n         \"\"\"Process each request through the WAF\"\"\"\n         if not self.enabled:\n             return await call_next(request)\n-        \n+\n         # Skip whitelisted endpoints\n-        if any(request.url.path.startswith(endpoint) for endpoint in self.ENDPOINT_WHITELIST):\n+        if any(\n+            request.url.path.startswith(endpoint)\n+            for endpoint in self.ENDPOINT_WHITELIST\n+        ):\n             return await call_next(request)\n-        \n+\n         # Check various parts of the request\n         attack_detected = False\n         attack_details = []\n-        \n+\n         # Check URL path\n         path_check = self._check_string(request.url.path, \"URL path\")\n         if path_check:\n             attack_detected = True\n             attack_details.append(path_check)\n-        \n+\n         # Check query parameters\n         if request.url.query:\n             query_params = QueryParams(request.url.query)\n             for key, value in query_params.items():\n                 # Check parameter name\n                 key_check = self._check_string(key, f\"Query param name '{key}'\")\n                 if key_check:\n                     attack_detected = True\n                     attack_details.append(key_check)\n-                \n+\n                 # Check parameter value\n                 value_check = self._check_string(value, f\"Query param '{key}'\")\n                 if value_check:\n                     attack_detected = True\n                     attack_details.append(value_check)\n-        \n+\n         # Check request body for POST/PUT/PATCH requests\n         if request.method in [\"POST\", \"PUT\", \"PATCH\"]:\n             # Clone the request body\n             body = await request.body()\n-            \n+\n             # Check raw body first\n-            body_text = body.decode('utf-8', errors='ignore')\n+            body_text = body.decode(\"utf-8\", errors=\"ignore\")\n             body_check = self._check_string(body_text, \"Request body\")\n             if body_check:\n                 attack_detected = True\n                 attack_details.append(body_check)\n-            \n+\n             # Check JSON body if applicable\n             if request.headers.get(\"content-type\") == \"application/json\":\n                 try:\n                     json_body = json.loads(body_text)\n                     json_check = self._check_json_recursive(json_body, \"JSON body\")\n                     if json_check:\n                         attack_detected = True\n                         attack_details.extend(json_check)\n                 except json.JSONDecodeError:\n                     pass\n-            \n+\n             # Reconstruct request with body\n             async def receive():\n                 return {\"type\": \"http.request\", \"body\": body}\n-            \n+\n             request = Request(request.scope, receive)\n-        \n+\n         # Check headers\n         for header_name, header_value in request.headers.items():\n             # Skip binary headers\n-            if header_name.lower() in ['authorization', 'cookie']:\n+            if header_name.lower() in [\"authorization\", \"cookie\"]:\n                 continue\n-            \n+\n             header_check = self._check_string(header_value, f\"Header '{header_name}'\")\n             if header_check:\n                 attack_detected = True\n                 attack_details.append(header_check)\n-        \n+\n         # If attack detected, block the request\n         if attack_detected:\n             self.attack_counter += 1\n-            \n+\n             if self.log_attacks:\n                 logger.warning(\n                     f\"SQL Injection attempt blocked: {request.method} {request.url.path}\\n\"\n                     f\"Client: {request.client.host if request.client else 'Unknown'}\\n\"\n                     f\"Details: {attack_details}\\n\"\n                     f\"Total attacks blocked: {self.attack_counter}\"\n                 )\n-            \n+\n             # Return a generic error to avoid information disclosure\n             return JSONResponse(\n                 status_code=400,\n                 content=APIResponseHelper.error(\n-                    \"Invalid request parameters\",\n-                    status_code=400\n-                )\n+                    \"Invalid request parameters\", status_code=400\n+                ),\n             )\n-        \n+\n         # Process the request normally\n         start_time = time.time()\n         response = await call_next(request)\n         process_time = time.time() - start_time\n-        \n+\n         # Add security headers\n         response.headers[\"X-Content-Type-Options\"] = \"nosniff\"\n         response.headers[\"X-Frame-Options\"] = \"DENY\"\n         response.headers[\"X-XSS-Protection\"] = \"1; mode=block\"\n         response.headers[\"X-Process-Time\"] = str(process_time)\n-        \n+\n         return response\n-    \n+\n     def _check_string(self, text: str, context: str) -> Optional[str]:\n         \"\"\"Check a string for SQL injection patterns\"\"\"\n         if not text:\n             return None\n-        \n+\n         # Decode URL encoding\n         decoded_text = unquote(text)\n-        \n+\n         # Check against compiled regex patterns\n         for pattern in self.COMPILED_PATTERNS:\n             if pattern.search(decoded_text):\n                 return f\"{context} matches SQL injection pattern\"\n-        \n+\n         # Check for suspicious sequences\n         decoded_lower = decoded_text.lower()\n         for sequence in self.SUSPICIOUS_SEQUENCES:\n             if sequence.lower() in decoded_lower:\n                 return f\"{context} contains suspicious sequence: {sequence}\"\n-        \n+\n         # Check for null bytes\n-        if '\\x00' in decoded_text or '%00' in decoded_text:\n+        if \"\\x00\" in decoded_text or \"%00\" in decoded_text:\n             return f\"{context} contains null byte\"\n-        \n+\n         return None\n-    \n+\n     def _check_json_recursive(self, obj: Any, path: str = \"\") -> List[str]:\n         \"\"\"Recursively check JSON objects for SQL injection\"\"\"\n         findings = []\n-        \n+\n         if isinstance(obj, str):\n             check = self._check_string(obj, path)\n             if check:\n                 findings.append(check)\n-        \n+\n         elif isinstance(obj, dict):\n             for key, value in obj.items():\n                 # Check the key itself\n                 key_check = self._check_string(str(key), f\"{path}.{key} (key)\")\n                 if key_check:\n                     findings.append(key_check)\n-                \n+\n                 # Check the value\n                 findings.extend(self._check_json_recursive(value, f\"{path}.{key}\"))\n-        \n+\n         elif isinstance(obj, list):\n             for i, item in enumerate(obj):\n                 findings.extend(self._check_json_recursive(item, f\"{path}[{i}]\"))\n-        \n+\n         return findings\n-    \n+\n     def get_stats(self) -> Dict[str, Any]:\n         \"\"\"Get WAF statistics\"\"\"\n         return {\n             \"enabled\": self.enabled,\n             \"attacks_blocked\": self.attack_counter,\n         }\n-    \n+\n     def reset_stats(self):\n         \"\"\"Reset WAF statistics\"\"\"\n-        self.attack_counter = 0\n\\ No newline at end of file\n+        self.attack_counter = 0\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models/audit_log.py\t2025-08-02 19:23:36.825688+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models/audit_log.py\t2025-08-02 22:36:03.611302+00:00\n@@ -1,6 +1,14 @@\n-from sqlalchemy import Column, String, DateTime, ForeignKey, Enum as SQLAlchemyEnum, Integer, Index\n+from sqlalchemy import (\n+    Column,\n+    String,\n+    DateTime,\n+    ForeignKey,\n+    Enum as SQLAlchemyEnum,\n+    Integer,\n+    Index,\n+)\n from sqlalchemy.dialects.postgresql import UUID, INET, JSONB\n from sqlalchemy.sql import func\n from sqlalchemy.sql.elements import quoted_name\n from sqlalchemy.orm import relationship  # Added for potential future use\n import uuid\n@@ -55,26 +63,42 @@\n     SECURITY_SETTING_CHANGED = \"SECURITY_SETTING_CHANGED\"\n \n     # General Security Events\n     SUSPICIOUS_ACTIVITY_DETECTED = \"SUSPICIOUS_ACTIVITY_DETECTED\"\n \n+\n # Enum for Event Status\n class AuditEventStatus(str, enum.Enum):\n     SUCCESS = \"SUCCESS\"\n     FAILURE = \"FAILURE\"\n     PENDING = \"PENDING\"\n     INFO = \"INFO\"\n \n+\n class AuditLog(Base):\n     __tablename__ = \"audit_logs\"\n \n     id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n-    timestamp = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)\n-    event_type = Column(SQLAlchemyEnum(AuditEventType, name=\"audit_event_type_enum\", create_type=True), nullable=False)\n-    event_status = Column(SQLAlchemyEnum(AuditEventStatus, name=\"audit_event_status_enum\", create_type=True), nullable=False)\n+    timestamp = Column(\n+        DateTime(timezone=True), server_default=func.now(), nullable=False\n+    )\n+    event_type = Column(\n+        SQLAlchemyEnum(AuditEventType, name=\"audit_event_type_enum\", create_type=True),\n+        nullable=False,\n+    )\n+    event_status = Column(\n+        SQLAlchemyEnum(\n+            AuditEventStatus, name=\"audit_event_status_enum\", create_type=True\n+        ),\n+        nullable=False,\n+    )\n \n-    user_id = Column(UUID(as_uuid=True), ForeignKey(\"users.id\", name=\"fk_audit_log_user_id\"), nullable=True)\n+    user_id = Column(\n+        UUID(as_uuid=True),\n+        ForeignKey(\"users.id\", name=\"fk_audit_log_user_id\"),\n+        nullable=True,\n+    )\n     username_or_email = Column(String(255), nullable=True)\n \n     ip_address = Column(INET, nullable=True)\n     user_agent = Column(String(512), nullable=True)\n \n@@ -92,12 +116,18 @@\n         Index(\"ix_audit_logs_timestamp\", \"timestamp\"),\n         Index(\"ix_audit_logs_event_type\", \"event_type\"),\n         Index(\"ix_audit_logs_event_status\", \"event_status\"),\n         Index(\"ix_audit_logs_user_id\", \"user_id\"),\n         Index(\"ix_audit_logs_ip_address\", \"ip_address\"),\n-        Index(\"ix_audit_logs_resource_type_resource_id\", \"resource_type\", \"resource_id\"),\n+        Index(\n+            \"ix_audit_logs_resource_type_resource_id\", \"resource_type\", \"resource_id\"\n+        ),\n         # For JSONB, a GIN index is often useful if querying specific keys within the details\n-        Index('ix_audit_logs_details_gin', quoted_name('details', quote=False), postgresql_using='gin'),\n+        Index(\n+            \"ix_audit_logs_details_gin\",\n+            quoted_name(\"details\", quote=False),\n+            postgresql_using=\"gin\",\n+        ),\n     )\n \n     def __repr__(self):\n         return f\"<AuditLog(id={self.id}, event_type='{self.event_type.value}', user_id='{self.user_id}')>\"\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models/financial_records.py\t2025-08-02 21:56:59.000382+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models/financial_records.py\t2025-08-02 22:36:03.613138+00:00\n@@ -1,28 +1,38 @@\n from sqlalchemy import Column, String, Boolean, Integer, DateTime, Numeric, Index\n from sqlalchemy.dialects.postgresql import UUID\n-from sqlalchemy.sql import func # For server-side default timestamps\n+from sqlalchemy.sql import func  # For server-side default timestamps\n \n-from app.core.database import Base # Assuming Base is correctly defined\n+from app.core.database import Base  # Assuming Base is correctly defined\n+\n # from app.schemas.fee_schemas import PaymentMethodEnum # Not strictly needed for model def, but for context\n+\n \n class PlatformFeeRecord(Base):\n     __tablename__ = \"platform_fees\"\n \n-    id = Column(Integer, primary_key=True, index=True) # Auto-incrementing integer PK\n+    id = Column(Integer, primary_key=True, index=True)  # Auto-incrementing integer PK\n \n     # Assuming order_id from Odoo might be a string (e.g., 'Order 00001-001-0001') or an integer/UUID if synced differently.\n     # Using String for flexibility, but this needs to match how Odoo order identifiers are referenced.\n     order_reference = Column(String, nullable=False, index=True)\n \n-    platform_fee_amount = Column(Numeric(10, 2), nullable=False) # Store as Numeric for precision\n+    platform_fee_amount = Column(\n+        Numeric(10, 2), nullable=False\n+    )  # Store as Numeric for precision\n     processor_fee_amount = Column(Numeric(10, 2), nullable=False)\n-    customer_paid_processor_fee = Column(Boolean, nullable=False) # Clarified name from schema\n+    customer_paid_processor_fee = Column(\n+        Boolean, nullable=False\n+    )  # Clarified name from schema\n \n-    payment_method = Column(String, nullable=False) # Stores PaymentMethodEnum.value, e.g., \"stripe\"\n+    payment_method = Column(\n+        String, nullable=False\n+    )  # Stores PaymentMethodEnum.value, e.g., \"stripe\"\n \n-    transaction_timestamp = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)\n+    transaction_timestamp = Column(\n+        DateTime(timezone=True), server_default=func.now(), nullable=False\n+    )\n     # If you want client-settable timestamp, then nullable=False, default=None, and set it in service.\n     # server_default=func.now() is generally good for record creation time.\n \n     # Additional fields that might be useful:\n     # restaurant_id = Column(String, index=True)\n@@ -32,34 +42,41 @@\n         return (\n             f\"<PlatformFeeRecord(id={self.id}, order_reference='{self.order_reference}', \"\n             f\"platform_fee={self.platform_fee_amount}, processor_fee={self.processor_fee_amount})>\"\n         )\n \n+\n class StaffTipDistributionRecord(Base):\n     __tablename__ = \"staff_tip_distributions\"\n \n     id = Column(Integer, primary_key=True, index=True)\n \n-    order_reference = Column(String, nullable=False, index=True) # Links to Odoo pos.order\n+    order_reference = Column(\n+        String, nullable=False, index=True\n+    )  # Links to Odoo pos.order\n \n     # staff_id would ideally link to a users or hr_employee table if those are synced/available.\n     # Using String for now.\n     staff_id = Column(String, nullable=False, index=True)\n \n     tip_amount_gross = Column(Numeric(10, 2), nullable=False)\n     service_charge_deduction = Column(Numeric(10, 2), nullable=False, default=0.0)\n-    transaction_fee_impact_on_tip = Column(Numeric(10, 2), nullable=False, default=0.0) # Renamed from schema for clarity\n-    tip_amount_net = Column(Numeric(10, 2), nullable=False) # Gross - deductions\n+    transaction_fee_impact_on_tip = Column(\n+        Numeric(10, 2), nullable=False, default=0.0\n+    )  # Renamed from schema for clarity\n+    tip_amount_net = Column(Numeric(10, 2), nullable=False)  # Gross - deductions\n \n-    distribution_timestamp = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)\n+    distribution_timestamp = Column(\n+        DateTime(timezone=True), server_default=func.now(), nullable=False\n+    )\n \n     # Additional fields:\n     # payment_id_external = Column(String) # If tips are paid out via a system that provides IDs\n     # week_number = Column(Integer, index=True) # For easier weekly reporting\n \n     __table_args__ = (\n-        Index('idx_staff_tip_order_staff', 'order_reference', 'staff_id'),\n+        Index(\"idx_staff_tip_order_staff\", \"order_reference\", \"staff_id\"),\n     )\n \n     def __repr__(self):\n         return (\n             f\"<StaffTipDistributionRecord(id={self.id}, order_reference='{self.order_reference}', \"\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models/payment_config.py\t2025-08-02 21:56:59.000562+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models/payment_config.py\t2025-08-02 22:36:03.615395+00:00\n@@ -1,11 +1,14 @@\n from sqlalchemy import Column, String, Boolean, Integer, UniqueConstraint, Index\n from sqlalchemy.orm import relationship\n from sqlalchemy.dialects.postgresql import UUID\n \n-from app.core.database import Base # Assuming Base is correctly defined in app.core.database\n+from app.core.database import (\n+    Base,\n+)  # Assuming Base is correctly defined in app.core.database\n from app.schemas.fee_schemas import PaymentMethodEnum  # Reusing the enum\n+\n \n class PaymentMethodSetting(Base):\n     __tablename__ = \"payment_method_settings\"\n \n     id = Column(Integer, primary_key=True, index=True)\n@@ -17,41 +20,60 @@\n     # However, the issue schema implies restaurant_id is part of PK with payment_method,\n     # suggesting settings are always per restaurant or per payment_method at platform level.\n     # Let's adjust: a composite unique constraint for (restaurant_id, payment_method)\n     # and another for (payment_method) where restaurant_id is NULL for platform defaults.\n \n-    restaurant_id = Column(String, index=True, nullable=True) # Assuming restaurant_id is a string. Adjust if it's UUID.\n+    restaurant_id = Column(\n+        String, index=True, nullable=True\n+    )  # Assuming restaurant_id is a string. Adjust if it's UUID.\n     # If restaurant_id links to an actual restaurants table:\n     # restaurant_id = Column(UUID(as_uuid=True), ForeignKey('restaurants.id'), nullable=True, index=True)\n \n-    payment_method = Column(String, nullable=False, index=True) # Store enum value e.g., \"stripe\"\n+    payment_method = Column(\n+        String, nullable=False, index=True\n+    )  # Store enum value e.g., \"stripe\"\n \n     # Defines if, by default, the customer pays the processor fee for this payment_method.\n     customer_pays_default = Column(Boolean, default=True, nullable=False)\n \n     # Defines if the merchant is allowed to toggle who pays the fee at the POS.\n     allow_toggle_by_merchant = Column(Boolean, default=True, nullable=False)\n \n     # Defines if the processor fee (when paid by customer) should be part of the service charge amount.\n-    include_processor_fee_in_service_charge = Column(Boolean, default=True, nullable=False)\n+    include_processor_fee_in_service_charge = Column(\n+        Boolean, default=True, nullable=False\n+    )\n \n     # Unique constraints and indexes\n     __table_args__ = (\n         # Unique constraint for restaurant-specific settings\n-        UniqueConstraint('restaurant_id', 'payment_method', name='uq_restaurant_payment_method_setting'),\n+        UniqueConstraint(\n+            \"restaurant_id\",\n+            \"payment_method\",\n+            name=\"uq_restaurant_payment_method_setting\",\n+        ),\n         # Partial unique index for platform-level settings (restaurant_id is NULL)\n-        Index('idx_platform_payment_method_unique', 'payment_method', \n-              unique=True, postgresql_where=restaurant_id.is_(None)),\n+        Index(\n+            \"idx_platform_payment_method_unique\",\n+            \"payment_method\",\n+            unique=True,\n+            postgresql_where=restaurant_id.is_(None),\n+        ),\n         # Regular index for performance\n-        Index('idx_payment_method_settings_restaurant_method', 'restaurant_id', 'payment_method'),\n+        Index(\n+            \"idx_payment_method_settings_restaurant_method\",\n+            \"restaurant_id\",\n+            \"payment_method\",\n+        ),\n     )\n \n     def __repr__(self):\n         return (\n             f\"<PaymentMethodSetting(id={self.id}, restaurant_id='{self.restaurant_id}', \"\n             f\"payment_method='{self.payment_method}', customer_pays_default={self.customer_pays_default})>\"\n         )\n+\n \n # Example of how PlatformSettingsService might be extended or a new service created:\n # class PaymentConfigurationService:\n #     def __init__(self, db: Session):\n #         self.db = db\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models/refund.py\t2025-08-02 19:23:36.826609+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models/refund.py\t2025-08-02 22:36:03.643543+00:00\n@@ -2,48 +2,69 @@\n from sqlalchemy import Column, String, Numeric, Text, DateTime, ForeignKey, func\n from sqlalchemy.orm import relationship\n from sqlalchemy.dialects.postgresql import UUID\n from ..core.database import Base\n \n+\n class Refund(Base):\n     __tablename__ = \"refunds\"\n \n     id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n     # Corrected ForeignKey to \"orders.id\" and ensured order_id is String to match UUID type\n-    order_id = Column(UUID(as_uuid=True), ForeignKey(\"orders.id\", ondelete=\"CASCADE\"), nullable=False, index=True)\n+    order_id = Column(\n+        UUID(as_uuid=True),\n+        ForeignKey(\"orders.id\", ondelete=\"CASCADE\"),\n+        nullable=False,\n+        index=True,\n+    )\n     amount = Column(Numeric(10, 2), nullable=False)\n     reason = Column(Text)\n     state = Column(String(50), nullable=False, default=\"done\", index=True)\n     created_at = Column(DateTime(timezone=True), server_default=func.now())\n-    updated_at = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now())\n+    updated_at = Column(\n+        DateTime(timezone=True), server_default=func.now(), onupdate=func.now()\n+    )\n \n-    ledger_entries = relationship(\"RefundLedger\", back_populates=\"refund\", cascade=\"all, delete-orphan\")\n+    ledger_entries = relationship(\n+        \"RefundLedger\", back_populates=\"refund\", cascade=\"all, delete-orphan\"\n+    )\n     # If 'Order' is also a SQLAlchemy model in this context and a relationship is desired:\n     # order = relationship(\"Order\", backref=\"refund_entries\")\n+\n \n class RefundLedger(Base):\n     __tablename__ = \"refunds_ledger\"\n \n     id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n-    refund_id = Column(UUID(as_uuid=True), ForeignKey(\"refunds.id\", ondelete=\"CASCADE\"), nullable=False, index=True)\n+    refund_id = Column(\n+        UUID(as_uuid=True),\n+        ForeignKey(\"refunds.id\", ondelete=\"CASCADE\"),\n+        nullable=False,\n+        index=True,\n+    )\n     # Assuming res_users.id is also a UUID string in your FastAPI context, if not, adjust type.\n     # If res_users.id is Integer (Odoo default), then this should be Integer.\n     # For consistency with other UUIDs, let's assume it's String(36) if it's a FastAPI managed user table.\n     # However, 'res_users' implies an Odoo table. Odoo 'res_users.id' is Integer.\n     # This highlights a potential type mismatch if FastAPI user IDs are UUIDs and Odoo's are Integers.\n     # For now, assuming the FK is to an Odoo res_users table, so Integer is more appropriate for user_id.\n-    user_id = Column(UUID(as_uuid=True), ForeignKey(\"users.id\"), nullable=True, index=True)\n+    user_id = Column(\n+        UUID(as_uuid=True), ForeignKey(\"users.id\"), nullable=True, index=True\n+    )\n     device_id = Column(Text)\n-    action = Column(Text, nullable=False) # E.g., \"created\", \"processed_gateway\", \"failed_gateway\"\n+    action = Column(\n+        Text, nullable=False\n+    )  # E.g., \"created\", \"processed_gateway\", \"failed_gateway\"\n     timestamp = Column(DateTime(timezone=True), server_default=func.now())\n \n     # Relationships\n     refund = relationship(\"Refund\", back_populates=\"ledger_entries\")\n     # user = relationship(\"ResUsers\") # Assuming a ResUsers model exists and is mapped in SQLAlchemy\n     # If ResUsers is an Odoo model, this direct SQLAlchemy relationship might not be straightforward\n     # unless there's a corresponding SQLAlchemy model for res_users.\n-    user = relationship(\"User\") # Reference to User model\n+    user = relationship(\"User\")  # Reference to User model\n+\n \n # In your PosOrder model (e.g., addons/point_of_sale/models/pos_order.py), you would add:\n # refunds = relationship(\"Refund\", back_populates=\"order\")\n \n # In your ResUsers model (e.g., addons/base/models/res_users.py or a custom user model), you might add:\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/middleware/rate_limit_middleware.py\t2025-08-02 21:56:58.999898+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/middleware/rate_limit_middleware.py\t2025-08-02 22:36:03.681657+00:00\n@@ -1,8 +1,9 @@\n \"\"\"\n Rate limiting middleware using fastapi-limiter.\n \"\"\"\n+\n import logging\n from typing import Optional\n \n from fastapi import Request, Depends\n from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials\n@@ -11,60 +12,69 @@\n from slowapi.errors import RateLimitExceeded\n from slowapi.middleware import SlowAPIMiddleware\n from jose import JWTError, jwt\n \n from app.core.config import settings\n-from app.core.redis_client import redis_client # Import global instance\n+from app.core.redis_client import redis_client  # Import global instance\n \n logger = logging.getLogger(__name__)\n \n # --- User Identification ---\n security = HTTPBearer(auto_error=False)\n \n+\n async def get_current_user_id(\n-    request: Request,\n-    token: Optional[HTTPAuthorizationCredentials] = Depends(security)\n+    request: Request, token: Optional[HTTPAuthorizationCredentials] = Depends(security)\n ) -> Optional[str]:\n     \"\"\"\n     Extracts user ID from JWT token if present.\n     Returns None if no token or token is invalid.\n     \"\"\"\n     if token is None:\n         return None\n     try:\n-        payload = jwt.decode(token.credentials, settings.SECRET_KEY, algorithms=[settings.ALGORITHM])\n-        user_id: Optional[str] = payload.get(\"sub\") # Assuming 'sub' contains the user ID\n+        payload = jwt.decode(\n+            token.credentials, settings.SECRET_KEY, algorithms=[settings.ALGORITHM]\n+        )\n+        user_id: Optional[str] = payload.get(\n+            \"sub\"\n+        )  # Assuming 'sub' contains the user ID\n         if user_id is None:\n             return None\n-        return str(user_id) # Ensure it's a string\n+        return str(user_id)  # Ensure it's a string\n     except JWTError:\n-        return None # Invalid token\n+        return None  # Invalid token\n+\n \n # --- Limiter Configuration ---\n+\n \n # This function determines the key for rate limiting.\n # It prioritizes user ID if available, otherwise falls back to IP address.\n async def identify_client(request: Request) -> str:\n     user_id = await get_current_user_id(request)\n     client_type = request.headers.get(\"X-Client-Type\", \"unknown\")\n-    \n+\n     if user_id:\n         return f\"user:{user_id}:{client_type}\"\n     return f\"ip:{get_remote_address(request)}:{client_type}\"\n+\n \n # Specialized key functions for different client types\n async def identify_mobile_client(request: Request) -> str:\n     user_id = await get_current_user_id(request)\n     if user_id:\n         return f\"mobile:user:{user_id}\"\n     return f\"mobile:ip:{get_remote_address(request)}\"\n \n+\n async def identify_portal_client(request: Request) -> str:\n     user_id = await get_current_user_id(request)\n     if user_id:\n         return f\"portal:user:{user_id}\"\n     return f\"portal:ip:{get_remote_address(request)}\"\n+\n \n # Initialize the Limiter with our identifier function\n # The redis_client.get_client() will provide the actual aioredis.Redis instance\n # or a compatible mock if Redis connection fails in dev/test.\n limiter = Limiter(key_func=identify_client, strategy=\"moving-window\")\n@@ -79,33 +89,40 @@\n \n # The limiter instance needs to be aware of the Redis client.\n # fastapi-limiter's global limiter state can be tricky.\n # We'll ensure it's configured when the app starts.\n \n+\n async def init_fastapi_limiter():\n     \"\"\"\n     Initializes the fastapi-limiter with the Redis client.\n     This should be called during application startup after Redis is connected.\n     \"\"\"\n     try:\n         # Try to ping Redis to check connectivity\n-        if redis_client and hasattr(redis_client, 'ping'):\n+        if redis_client and hasattr(redis_client, \"ping\"):\n             await redis_client.ping()\n             logger.info(\"\u2705 Redis is available for rate limiting\")\n         else:\n             # Check if we're in mock mode\n-            if settings.ENVIRONMENT in [\"development\", \"testing\", \"local\"] and hasattr(redis_client, '_mock_storage'):\n+            if settings.ENVIRONMENT in [\"development\", \"testing\", \"local\"] and hasattr(\n+                redis_client, \"_mock_storage\"\n+            ):\n                 logger.info(\"\u2705 Rate limiter using mock storage in development mode\")\n             else:\n-                logger.warning(\"Rate limiter cannot be initialized: Redis is not available and not in mock mode.\")\n+                logger.warning(\n+                    \"Rate limiter cannot be initialized: Redis is not available and not in mock mode.\"\n+                )\n                 return\n     except Exception as e:\n         # Redis connection failed\n         if settings.ENVIRONMENT in [\"development\", \"testing\", \"local\"]:\n             logger.warning(f\"Redis connection failed, using mock storage: {e}\")\n         else:\n-            logger.error(f\"Rate limiter cannot be initialized in production: Redis connection failed: {e}\")\n+            logger.error(\n+                f\"Rate limiter cannot be initialized in production: Redis connection failed: {e}\"\n+            )\n             return\n \n     # The `limiter` object we created earlier will be used by route decorators.\n     # We need to ensure that the `RateLimiter` state is configured with our Redis client.\n     # This is a bit of a workaround for how `fastapi-limiter` handles its global state\n@@ -156,20 +173,22 @@\n # Define default limits (can be overridden by decorators)\n DEFAULT_RATE = \"60/minute\"\n \n # Define specific limits for endpoint categories\n AUTH_RATE = \"5/minute\"\n-PAYMENT_RATE = \"15/minute\" # As per requirement \"10-20\", using 15\n+PAYMENT_RATE = \"15/minute\"  # As per requirement \"10-20\", using 15\n \n # Portal vs Mobile specific limits\n MOBILE_APP_RATE = \"100/minute\"\n PORTAL_DASHBOARD_RATE = \"300/minute\"  # Higher for analytics\n-PORTAL_EXPORT_RATE = \"10/minute\"     # Lower for resource-intensive operations\n+PORTAL_EXPORT_RATE = \"10/minute\"  # Lower for resource-intensive operations\n \n # API-specific limits\n-ANALYTICS_RATE = \"200/minute\"        # High for dashboard queries\n-WEBSOCKET_RATE = \"500/minute\"        # Very high for real-time updates\n-SYNC_RATE = \"200/minute\"             # High for synchronization\n+ANALYTICS_RATE = \"200/minute\"  # High for dashboard queries\n+WEBSOCKET_RATE = \"500/minute\"  # Very high for real-time updates\n+SYNC_RATE = \"200/minute\"  # High for synchronization\n \n-logger.info(f\"Rate Limiter Configured: DEFAULT_RATE={DEFAULT_RATE}, AUTH_RATE={AUTH_RATE}, PAYMENT_RATE={PAYMENT_RATE}\")\n+logger.info(\n+    f\"Rate Limiter Configured: DEFAULT_RATE={DEFAULT_RATE}, AUTH_RATE={AUTH_RATE}, PAYMENT_RATE={PAYMENT_RATE}\"\n+)\n logger.info(\"Rate limiting strategy: User ID if authenticated, otherwise IP address.\")\n logger.info(\"Rate limits will be applied via decorators on specific routes.\")\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models.py\t2025-08-02 14:10:21.490278+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models.py\t2025-08-02 22:36:03.698689+00:00\n@@ -16,27 +16,27 @@\n     Section,\n     InventoryItem,\n     Recipe,\n     InventoryLedgerEntry,\n     Table,\n-    PosSession\n+    PosSession,\n )\n \n # Re-export all models\n __all__ = [\n-    'Platform',\n-    'Restaurant',\n-    'User',\n-    'UserRestaurant',\n-    'Customer',\n-    'Category',\n-    'Product',\n-    'Order',\n-    'Payment',\n-    'QRPayment',\n-    'Section',\n-    'InventoryItem',\n-    'Recipe',\n-    'InventoryLedgerEntry',\n-    'Table',\n-    'PosSession'\n-]\n\\ No newline at end of file\n+    \"Platform\",\n+    \"Restaurant\",\n+    \"User\",\n+    \"UserRestaurant\",\n+    \"Customer\",\n+    \"Category\",\n+    \"Product\",\n+    \"Order\",\n+    \"Payment\",\n+    \"QRPayment\",\n+    \"Section\",\n+    \"InventoryItem\",\n+    \"Recipe\",\n+    \"InventoryLedgerEntry\",\n+    \"Table\",\n+    \"PosSession\",\n+]\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models/__init__.py\t2025-08-02 14:10:21.490400+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models/__init__.py\t2025-08-02 22:36:03.704887+00:00\n@@ -14,39 +14,29 @@\n     Section,\n     Table,\n     PosSession,\n     InventoryItem,\n     Recipe,\n-    InventoryLedgerEntry\n+    InventoryLedgerEntry,\n )\n \n # Import models from audit_log.py\n-from .audit_log import (\n-    AuditLog,\n-    AuditEventType,\n-    AuditEventStatus\n-)\n+from .audit_log import AuditLog, AuditEventType, AuditEventStatus\n \n # Import models from refund.py\n from .refund import Refund, RefundLedger\n \n # Import models from employee.py\n-from .employee import (\n-    EmployeeProfile,\n-    Schedule,\n-    Shift,\n-    TimeEntry,\n-    PerformanceMetric\n-)\n+from .employee import EmployeeProfile, Schedule, Shift, TimeEntry, PerformanceMetric\n \n # Import models from reports.py\n from .reports import (\n     DailyReport,\n     HourlyMetric,\n     ProductPerformance,\n     EmployeePerformance,\n-    FinancialSummary\n+    FinancialSummary,\n )\n \n # Import models from stock_movement.py\n from .stock_movement import (\n     MovementType,\n@@ -54,19 +44,15 @@\n     PurchaseOrder,\n     PurchaseOrderItem,\n     StockMovement,\n     StockAlert,\n     InventoryCount,\n-    InventoryCountItem\n+    InventoryCountItem,\n )\n \n # Import models from subscription.py (singular)\n-from .subscription import (\n-    SubscriptionPlan,\n-    RestaurantSubscription,\n-    SubscriptionUsage\n-)\n+from .subscription import SubscriptionPlan, RestaurantSubscription, SubscriptionUsage\n \n __all__ = [\n     \"Base\",\n     \"Platform\",\n     \"Restaurant\",\n@@ -111,7 +97,7 @@\n     \"InventoryCount\",\n     \"InventoryCountItem\",\n     # Subscription models\n     \"SubscriptionPlan\",\n     \"RestaurantSubscription\",\n-    \"SubscriptionUsage\"\n+    \"SubscriptionUsage\",\n ]\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/schemas/auth.py\t2025-08-02 19:52:26.972541+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/schemas/auth.py\t2025-08-02 22:36:03.718079+00:00\n@@ -6,17 +6,19 @@\n from typing import Optional, List\n \n \n class RegisterRestaurantRequest(BaseModel):\n     \"\"\"Request model for registering a new restaurant\"\"\"\n+\n     restaurant_name: str\n     phone: Optional[str] = None\n     address: Optional[str] = None\n \n \n class UserInfo(BaseModel):\n     \"\"\"User information returned in auth responses\"\"\"\n+\n     id: str\n     email: str\n     name: str\n     is_platform_owner: bool\n     role: str\n@@ -27,6 +29,7 @@\n     enabled_features: Optional[List[str]] = []\n \n \n class AuthVerifyResponse(BaseModel):\n     \"\"\"Response model for auth verification\"\"\"\n-    user: UserInfo\n\\ No newline at end of file\n+\n+    user: UserInfo\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/main.py\t2025-08-02 21:56:58.999236+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/main.py\t2025-08-02 22:36:03.745069+00:00\n@@ -24,11 +24,11 @@\n from slowapi.errors import RateLimitExceeded\n from slowapi.middleware import SlowAPIMiddleware\n from app.core.responses import APIResponseHelper\n from app.core.mobile_middleware import (\n     MobileCompatibilityMiddleware,\n-    MobileDataOptimizationMiddleware\n+    MobileDataOptimizationMiddleware,\n )\n from app.middleware.version_middleware import APIVersionMiddleware\n from app.middleware.security_headers_middleware import SecurityHeadersMiddleware\n from app.middleware.sql_injection_waf import SQLInjectionWAFMiddleware\n from app.core.auth import get_current_user\n@@ -43,107 +43,117 @@\n # This should be done after basic logging config but before the app starts handling requests.\n # Note: Uvicorn sets up its own handlers. This filter will apply to log records\n # processed by the application's loggers. For Uvicorn's access logs,\n # different configuration might be needed if they also contain sensitive data.\n from app.core.logging_filters import setup_logging_filters\n+\n if settings.ENVIRONMENT == \"production\" or not settings.ERROR_DETAIL_ENABLED:\n     # We call this early, but it depends on `settings` being initialized.\n     # Logging needs to be configured before this call if it relies on basicConfig.\n     # If Uvicorn manages basicConfig, this should be fine.\n     setup_logging_filters()\n \n \n security = HTTPBearer()\n \n+\n @asynccontextmanager\n async def lifespan(app: FastAPI):\n     \"\"\"Initialize application on startup\"\"\"\n     logger.info(f\"\ud83d\ude80 Fynlo POS Backend starting in {settings.ENVIRONMENT} mode...\")\n-    \n+\n     # Initialize database and Redis\n     try:\n         from app.core.database import init_db\n         from app.core.redis_client import init_redis\n-        \n+\n         logger.info(\"Initializing database...\")\n         await init_db()\n-        \n+\n         logger.info(\"Initializing Redis...\")\n         await init_redis()\n-        \n+\n         logger.info(\"Initializing rate limiter...\")\n         await init_fastapi_limiter()\n-        \n+\n         # Set the limiter on app.state for SlowAPI middleware\n         from app.middleware.rate_limit_middleware import limiter\n+\n         app.state.limiter = limiter\n         logger.info(\"\u2705 SlowAPI limiter attached to app.state\")\n-        \n+\n         logger.info(\"Initializing WebSocket services...\")\n-        from app.api.v1.endpoints.websocket_enhanced import init_websocket_services, start_health_monitor\n+        from app.api.v1.endpoints.websocket_enhanced import (\n+            init_websocket_services,\n+            start_health_monitor,\n+        )\n+\n         await init_websocket_services()\n         await start_health_monitor()\n-        \n+\n         logger.info(\"Initializing instance tracker...\")\n         from app.services.instance_tracker import init_instance_tracker\n         from app.core.redis_client import redis_client\n+\n         await init_instance_tracker(redis_client)\n-        \n+\n         # Initialize cache warming\n         logger.info(\"Initializing cache warming...\")\n         from app.core.cache_warmer import warm_cache_on_startup, warm_cache_task\n         from app.core.database import SessionLocal\n         import asyncio\n-        \n+\n         # Use SessionLocal directly for non-dependency-injection contexts\n         db = SessionLocal()\n         try:\n             await warm_cache_on_startup(db)\n         finally:\n             db.close()\n-        \n+\n         # Start background cache warming task\n         asyncio.create_task(warm_cache_task())\n         logger.info(\"\u2705 Cache warming initialized\")\n-        \n+\n         logger.info(\"\u2705 Core services initialized successfully\")\n     except Exception as e:\n         logger.error(f\"Core services initialization failed: {e}\")\n         # Continue startup even if initialization fails\n-    \n+\n     yield\n-    \n+\n     # Cleanup\n     logger.info(\"Stopping instance tracker...\")\n     from app.services.instance_tracker import stop_instance_tracker\n+\n     await stop_instance_tracker()\n-    \n+\n     logger.info(\"Closing Redis connection...\")\n     await close_redis()\n-    \n+\n     logger.info(\"\u2705 Cleanup complete\")\n+\n \n app = FastAPI(\n     title=settings.APP_NAME,\n     description=\"Hardware-Free Restaurant Management Platform\",\n     version=\"1.0.0\",\n     lifespan=lifespan,\n-    debug=settings.DEBUG and settings.ENVIRONMENT != \"production\"  # Ensure debug is disabled in production\n+    debug=settings.DEBUG\n+    and settings.ENVIRONMENT != \"production\",  # Ensure debug is disabled in production\n )\n \n # CORS middleware for React Native frontend and Supabase\n if settings.ENVIRONMENT == \"production\":\n     allowed_origins = settings.PRODUCTION_ALLOWED_ORIGINS\n else:\n     # Use CORS_ORIGINS from settings for development, fallback to permissive\n-    allowed_origins = settings.cors_origins_list if settings.cors_origins_list else [\"*\"]\n+    allowed_origins = (\n+        settings.cors_origins_list if settings.cors_origins_list else [\"*\"]\n+    )\n \n # Add Supabase domains to allowed origins\n-supabase_origins = [\n-    \"https://*.supabase.co\",\n-    \"https://*.supabase.io\"\n-]\n+supabase_origins = [\"https://*.supabase.co\", \"https://*.supabase.io\"]\n \n # Add specific Supabase URL if configured\n if settings.SUPABASE_URL:\n     supabase_origins.append(settings.SUPABASE_URL)\n \n@@ -162,21 +172,28 @@\n async def add_security_headers(request: Request, call_next):\n     response = await call_next(request)\n     response.headers[\"X-Content-Type-Options\"] = \"nosniff\"\n     response.headers[\"X-Frame-Options\"] = \"DENY\"\n     response.headers[\"X-XSS-Protection\"] = \"1; mode=block\"\n-    response.headers[\"Strict-Transport-Security\"] = \"max-age=31536000; includeSubDomains\"\n+    response.headers[\"Strict-Transport-Security\"] = (\n+        \"max-age=31536000; includeSubDomains\"\n+    )\n     response.headers[\"Referrer-Policy\"] = \"strict-origin-when-cross-origin\"\n     return response\n+\n \n app.add_middleware(\n     CORSMiddleware,\n     allow_origins=allowed_origins,\n     allow_credentials=True,\n     allow_methods=[\"*\"],\n     allow_headers=[\"*\"],\n-    allow_origin_regex=r\"^https://fynlo-[a-zA-Z0-9\\-]+\\.vercel\\.app$\" if settings.ENVIRONMENT != \"production\" else None\n+    allow_origin_regex=(\n+        r\"^https://fynlo-[a-zA-Z0-9\\-]+\\.vercel\\.app$\"\n+        if settings.ENVIRONMENT != \"production\"\n+        else None\n+    ),\n )\n \n # TEMPORARY: Disable complex middleware for deployment\n # Add API version middleware for backward compatibility (FIRST in middleware stack)\n # app.add_middleware(APIVersionMiddleware)\n@@ -184,10 +201,11 @@\n # Add Security Headers Middleware (after CORS and Versioning, before others)\n # app.add_middleware(SecurityHeadersMiddleware)\n \n # Add RLS middleware for session variable isolation\n from app.middleware.rls_middleware import RLSMiddleware\n+\n app.add_middleware(RLSMiddleware)\n \n # Add SQL Injection WAF middleware for additional protection\n app.add_middleware(SQLInjectionWAFMiddleware, enabled=True, log_attacks=True)\n \n@@ -208,40 +226,45 @@\n # Include API routes\n app.include_router(api_router, prefix=\"/api/v1\")\n \n # Include mobile-optimized routes (both prefixed and Odoo-style)\n app.include_router(mobile_router, prefix=\"/api/mobile\", tags=[\"mobile\"])\n-app.include_router(mobile_router, prefix=\"\", tags=[\"mobile-compatibility\"])  # For Odoo-style endpoints\n+app.include_router(\n+    mobile_router, prefix=\"\", tags=[\"mobile-compatibility\"]\n+)  # For Odoo-style endpoints\n \n # WebSocket routes are handled through the websocket router in api.py\n+\n \n @app.get(\"/\")\n async def root():\n     \"\"\"Health check endpoint with standardized response\"\"\"\n     return APIResponseHelper.success(\n         data={\n             \"service\": \"Fynlo POS Backend API\",\n             \"version\": \"1.0.0\",\n             \"status\": \"healthy\",\n             \"api_version\": \"v1\",\n-            \"backward_compatible\": True\n-        },\n-        message=\"Fynlo POS API is running\"\n-    )\n+            \"backward_compatible\": True,\n+        },\n+        message=\"Fynlo POS API is running\",\n+    )\n+\n \n @app.get(\"/health\")\n async def health_check():\n     \"\"\"Ultra-fast health check for DigitalOcean deployment - NO EXTERNAL CHECKS\"\"\"\n-    \n+\n     # CRITICAL FIX: Return immediately without any DB/Redis checks to avoid Error 524 timeouts\n     # This endpoint is called every 10 seconds by DigitalOcean - it MUST be instant\n     return {\n         \"status\": \"healthy\",\n         \"service\": \"fynlo-pos-backend\",\n         \"version\": \"1.0.0\",\n-        \"timestamp\": datetime.now().isoformat()\n+        \"timestamp\": datetime.now().isoformat(),\n     }\n+\n \n @app.get(\"/api/version\")\n async def api_version_info():\n     \"\"\"API version information endpoint\"\"\"\n     return APIResponseHelper.success(\n@@ -254,68 +277,81 @@\n             \"documentation\": {\n                 \"versioned_endpoints\": \"/api/v1/{resource}\",\n                 \"unversioned_fallback\": \"/api/{resource} \u2192 /api/v1/{resource}\",\n                 \"websocket_paths\": {\n                     \"/ws/{id}\": \"/api/v1/websocket/ws/{id}\",\n-                    \"/websocket/{id}\": \"/api/v1/websocket/ws/{id}\"\n-                }\n-            }\n-        },\n-        message=\"API version information\"\n+                    \"/websocket/{id}\": \"/api/v1/websocket/ws/{id}\",\n+                },\n+            },\n+        },\n+        message=\"API version information\",\n     )\n \n \n # Hardcoded menu endpoints removed - now using proper router at /api/v1/menu/\n # See app/api/v1/endpoints/menu.py for database-driven menu endpoints\n+\n \n def format_employee_response(employee):\n     \"\"\"Format employee with all required fields\"\"\"\n     from datetime import datetime\n-    \n+\n     return {\n         \"id\": employee.id,\n-        \"name\": f\"{getattr(employee, 'first_name', '')} {getattr(employee, 'last_name', '')}\".strip() or employee.email,\n+        \"name\": f\"{getattr(employee, 'first_name', '')} {getattr(employee, 'last_name', '')}\".strip()\n+        or employee.email,\n         \"email\": employee.email,\n         \"role\": employee.role,\n-        \"hourlyRate\": float(getattr(employee, 'hourly_rate', 0) or 0),\n-        \"totalSales\": float(getattr(employee, 'total_sales', 0) or 0),\n-        \"performanceScore\": float(getattr(employee, 'performance_score', 0) or 0),\n-        \"isActive\": getattr(employee, 'is_active', True),\n-        \"hireDate\": employee.hire_date.isoformat() if hasattr(employee, 'hire_date') and employee.hire_date else datetime.now().isoformat(),\n-        \"startDate\": employee.start_date.isoformat() if hasattr(employee, 'start_date') and employee.start_date else datetime.now().isoformat(),\n-        \"phone\": getattr(employee, 'phone', '') or '',\n-        \"totalOrders\": int(getattr(employee, 'total_orders', 0) or 0),\n-        \"avgOrderValue\": float(getattr(employee, 'avg_order_value', 0) or 0),\n-        \"hoursWorked\": float(getattr(employee, 'hours_worked', 0) or 0)\n+        \"hourlyRate\": float(getattr(employee, \"hourly_rate\", 0) or 0),\n+        \"totalSales\": float(getattr(employee, \"total_sales\", 0) or 0),\n+        \"performanceScore\": float(getattr(employee, \"performance_score\", 0) or 0),\n+        \"isActive\": getattr(employee, \"is_active\", True),\n+        \"hireDate\": (\n+            employee.hire_date.isoformat()\n+            if hasattr(employee, \"hire_date\") and employee.hire_date\n+            else datetime.now().isoformat()\n+        ),\n+        \"startDate\": (\n+            employee.start_date.isoformat()\n+            if hasattr(employee, \"start_date\") and employee.start_date\n+            else datetime.now().isoformat()\n+        ),\n+        \"phone\": getattr(employee, \"phone\", \"\") or \"\",\n+        \"totalOrders\": int(getattr(employee, \"total_orders\", 0) or 0),\n+        \"avgOrderValue\": float(getattr(employee, \"avg_order_value\", 0) or 0),\n+        \"hoursWorked\": float(getattr(employee, \"hours_worked\", 0) or 0),\n     }\n+\n \n @app.get(\"/api/v1/employees\")\n async def get_employees(\n-    db: Session = Depends(get_db),\n-    current_user: User = Depends(get_current_user)\n+    db: Session = Depends(get_db), current_user: User = Depends(get_current_user)\n ):\n     \"\"\"Get employees\"\"\"\n     from datetime import datetime, timedelta\n-    \n+\n     # Try to get real employees from database\n     try:\n-        employees = db.query(User).filter(\n-            User.restaurant_id == current_user.restaurant_id,\n-            User.is_active == True\n-        ).all()\n-        \n+        employees = (\n+            db.query(User)\n+            .filter(\n+                User.restaurant_id == current_user.restaurant_id, User.is_active == True\n+            )\n+            .all()\n+        )\n+\n         if employees:\n             return APIResponseHelper.success(\n                 data=[format_employee_response(emp) for emp in employees],\n-                message=f\"Retrieved {len(employees)} employees\"\n+                message=f\"Retrieved {len(employees)} employees\",\n             )\n     except Exception as e:\n         logger.error(f\"Error fetching employees: {str(e)}\")\n-    \n+\n     # Fallback to mock data if no real data\n     base_date = datetime.now() - timedelta(days=365)\n-    \n+\n     return APIResponseHelper.success(\n         data=[\n             {\n                 \"id\": 1,\n                 \"name\": \"John Manager\",\n@@ -323,20 +359,22 @@\n                 \"role\": \"manager\",\n                 \"hourlyRate\": 25.00,\n                 \"totalSales\": 15420.50,\n                 \"performanceScore\": 9.2,\n                 \"isActive\": True,\n-                \"hireDate\": (base_date - timedelta(days=730)).isoformat(),  # 2 years ago\n+                \"hireDate\": (\n+                    base_date - timedelta(days=730)\n+                ).isoformat(),  # 2 years ago\n                 \"startDate\": (base_date - timedelta(days=730)).isoformat(),\n                 \"phone\": \"+44 7700 900100\",\n                 \"totalOrders\": 342,\n                 \"avgOrderValue\": 45.03,\n-                \"hoursWorked\": 1680\n+                \"hoursWorked\": 1680,\n             },\n             {\n                 \"id\": 2,\n-                \"name\": \"Sarah Cashier\", \n+                \"name\": \"Sarah Cashier\",\n                 \"email\": \"sarah@restaurant.com\",\n                 \"role\": \"cashier\",\n                 \"hourlyRate\": 15.50,\n                 \"totalSales\": 8750.25,\n                 \"performanceScore\": 8.8,\n@@ -344,75 +382,83 @@\n                 \"hireDate\": (base_date - timedelta(days=365)).isoformat(),  # 1 year ago\n                 \"startDate\": (base_date - timedelta(days=365)).isoformat(),\n                 \"phone\": \"+44 7700 900101\",\n                 \"totalOrders\": 256,\n                 \"avgOrderValue\": 34.18,\n-                \"hoursWorked\": 1120\n+                \"hoursWorked\": 1120,\n             },\n             {\n                 \"id\": 3,\n                 \"name\": \"Mike Server\",\n                 \"email\": \"mike@restaurant.com\",\n                 \"role\": \"server\",\n                 \"hourlyRate\": 12.50,\n                 \"totalSales\": 6230.15,\n                 \"performanceScore\": 8.5,\n                 \"isActive\": True,\n-                \"hireDate\": (base_date - timedelta(days=180)).isoformat(),  # 6 months ago\n+                \"hireDate\": (\n+                    base_date - timedelta(days=180)\n+                ).isoformat(),  # 6 months ago\n                 \"startDate\": (base_date - timedelta(days=180)).isoformat(),\n                 \"phone\": \"+44 7700 900102\",\n                 \"totalOrders\": 198,\n                 \"avgOrderValue\": 31.47,\n-                \"hoursWorked\": 560\n-            }\n+                \"hoursWorked\": 560,\n+            },\n         ],\n-        message=\"Employees retrieved\"\n-    )\n+        message=\"Employees retrieved\",\n+    )\n+\n \n @app.get(\"/api/v1/platform/settings/service-charge\")\n async def get_service_charge():\n     \"\"\"Get platform service charge settings\"\"\"\n     return APIResponseHelper.success(\n         data={\n             \"enabled\": True,\n             \"rate\": 0.125,  # 12.5%\n             \"description\": \"Platform service charge\",\n-            \"lastUpdated\": \"2025-01-08T16:30:00Z\"\n-        },\n-        message=\"Service charge settings retrieved\"\n-    )\n+            \"lastUpdated\": \"2025-01-08T16:30:00Z\",\n+        },\n+        message=\"Service charge settings retrieved\",\n+    )\n+\n \n @app.get(\"/api/v1/orders\")\n async def get_orders():\n     \"\"\"Get recent orders\"\"\"\n     from datetime import datetime, timedelta\n     import random\n-    \n+\n     # Generate mock orders\n     orders = []\n     statuses = [\"completed\", \"in_progress\", \"pending\"]\n-    \n+\n     for i in range(20):\n         order_time = datetime.now() - timedelta(minutes=random.randint(0, 1440))\n-        orders.append({\n-            \"id\": f\"ORD{1000 + i}\",\n-            \"orderNumber\": 1000 + i,\n-            \"customerName\": f\"Customer {i + 1}\",\n-            \"items\": [\n-                {\"name\": \"Nachos\", \"quantity\": 1, \"price\": 5.00},\n-                {\"name\": \"Tacos\", \"quantity\": 2, \"price\": 3.50}\n-            ],\n-            \"total\": 12.00 + (i * 2.5),\n-            \"status\": random.choice(statuses),\n-            \"createdAt\": order_time.isoformat(),\n-            \"completedAt\": (order_time + timedelta(minutes=15)).isoformat() if random.choice(statuses) == \"completed\" else None\n-        })\n-    \n-    return APIResponseHelper.success(\n-        data=orders,\n-        message=\"Orders retrieved\"\n-    )\n+        orders.append(\n+            {\n+                \"id\": f\"ORD{1000 + i}\",\n+                \"orderNumber\": 1000 + i,\n+                \"customerName\": f\"Customer {i + 1}\",\n+                \"items\": [\n+                    {\"name\": \"Nachos\", \"quantity\": 1, \"price\": 5.00},\n+                    {\"name\": \"Tacos\", \"quantity\": 2, \"price\": 3.50},\n+                ],\n+                \"total\": 12.00 + (i * 2.5),\n+                \"status\": random.choice(statuses),\n+                \"createdAt\": order_time.isoformat(),\n+                \"completedAt\": (\n+                    (order_time + timedelta(minutes=15)).isoformat()\n+                    if random.choice(statuses) == \"completed\"\n+                    else None\n+                ),\n+            }\n+        )\n+\n+    return APIResponseHelper.success(data=orders, message=\"Orders retrieved\")\n+\n \n @app.get(\"/api/v1/customers\")\n async def get_customers():\n     \"\"\"Get customers\"\"\"\n     customers = [\n@@ -421,27 +467,25 @@\n             \"name\": \"John Smith\",\n             \"email\": \"john@example.com\",\n             \"phone\": \"+44 7700 900001\",\n             \"totalOrders\": 25,\n             \"totalSpent\": 312.50,\n-            \"lastVisit\": \"2025-01-08\"\n+            \"lastVisit\": \"2025-01-08\",\n         },\n         {\n             \"id\": \"CUST002\",\n             \"name\": \"Sarah Johnson\",\n             \"email\": \"sarah@example.com\",\n             \"phone\": \"+44 7700 900002\",\n             \"totalOrders\": 18,\n             \"totalSpent\": 245.00,\n-            \"lastVisit\": \"2025-01-07\"\n-        }\n+            \"lastVisit\": \"2025-01-07\",\n+        },\n     ]\n-    \n-    return APIResponseHelper.success(\n-        data=customers,\n-        message=\"Customers retrieved\"\n-    )\n+\n+    return APIResponseHelper.success(data=customers, message=\"Customers retrieved\")\n+\n \n @app.get(\"/api/v1/inventory\")\n async def get_inventory():\n     \"\"\"Get inventory items\"\"\"\n     inventory = [\n@@ -450,71 +494,75 @@\n             \"name\": \"Tortilla Chips\",\n             \"category\": \"Dry Goods\",\n             \"currentStock\": 50,\n             \"unit\": \"bags\",\n             \"reorderLevel\": 20,\n-            \"lastRestocked\": \"2025-01-05\"\n+            \"lastRestocked\": \"2025-01-05\",\n         },\n         {\n             \"id\": \"INV002\",\n             \"name\": \"Black Beans\",\n             \"category\": \"Canned Goods\",\n             \"currentStock\": 30,\n             \"unit\": \"cans\",\n             \"reorderLevel\": 15,\n-            \"lastRestocked\": \"2025-01-03\"\n-        }\n+            \"lastRestocked\": \"2025-01-03\",\n+        },\n     ]\n-    \n-    return APIResponseHelper.success(\n-        data=inventory,\n-        message=\"Inventory retrieved\"\n-    )\n+\n+    return APIResponseHelper.success(data=inventory, message=\"Inventory retrieved\")\n+\n \n @app.get(\"/api/v1/test/supabase-config\")\n async def test_supabase_config():\n     \"\"\"Test endpoint to verify Supabase configuration\"\"\"\n     import os\n-    \n+\n     # Check all possible sources\n     env_checks = {\n-        \"settings_url\": bool(getattr(settings, 'SUPABASE_URL', None)),\n-        \"settings_key\": bool(getattr(settings, 'SUPABASE_SERVICE_ROLE_KEY', None)),\n+        \"settings_url\": bool(getattr(settings, \"SUPABASE_URL\", None)),\n+        \"settings_key\": bool(getattr(settings, \"SUPABASE_SERVICE_ROLE_KEY\", None)),\n         \"env_url\": bool(os.getenv(\"SUPABASE_URL\")),\n         \"env_key\": bool(os.getenv(\"SUPABASE_SERVICE_ROLE_KEY\")),\n         \"env_alt_key\": bool(os.getenv(\"supabase_secret_key\")),\n     }\n-    \n+\n     # List all env vars containing SUPA or SECRET (names only)\n     all_env_vars = list(os.environ.keys())\n-    relevant_vars = [var for var in all_env_vars if 'SUPA' in var.upper() or ('SECRET' in var.upper() and 'KEY' in var.upper())]\n-    \n+    relevant_vars = [\n+        var\n+        for var in all_env_vars\n+        if \"SUPA\" in var.upper() or (\"SECRET\" in var.upper() and \"KEY\" in var.upper())\n+    ]\n+\n     try:\n         from app.core.supabase import get_admin_client\n+\n         client = get_admin_client()\n-        \n+\n         return APIResponseHelper.success(\n             data={\n                 \"status\": \"success\",\n                 \"checks\": env_checks,\n                 \"client_initialized\": client is not None,\n                 \"environment\": settings.ENVIRONMENT,\n-                \"relevant_env_vars\": relevant_vars\n-            },\n-            message=\"Supabase configuration verified\"\n+                \"relevant_env_vars\": relevant_vars,\n+            },\n+            message=\"Supabase configuration verified\",\n         )\n     except Exception as e:\n         return APIResponseHelper.success(\n             data={\n                 \"status\": \"error\",\n                 \"error\": str(e),\n                 \"checks\": env_checks,\n                 \"environment\": settings.ENVIRONMENT,\n-                \"relevant_env_vars\": relevant_vars\n-            },\n-            message=\"Supabase configuration check failed\"\n+                \"relevant_env_vars\": relevant_vars,\n+            },\n+            message=\"Supabase configuration check failed\",\n         )\n+\n \n @app.get(\"/api/v1/analytics/dashboard/mobile\")\n async def get_analytics_dashboard():\n     \"\"\"Get analytics dashboard for mobile\"\"\"\n     return APIResponseHelper.success(\n@@ -523,83 +571,95 @@\n                 \"today\": 2847.50,\n                 \"yesterday\": 3156.80,\n                 \"thisWeek\": 18432.75,\n                 \"lastWeek\": 19875.20,\n                 \"thisMonth\": 67890.50,\n-                \"lastMonth\": 71234.80\n+                \"lastMonth\": 71234.80,\n             },\n             \"orders\": {\n                 \"today\": 42,\n                 \"yesterday\": 48,\n                 \"thisWeek\": 287,\n                 \"lastWeek\": 312,\n-                \"averageOrderValue\": 67.80\n+                \"averageOrderValue\": 67.80,\n             },\n             \"topItems\": [\n                 {\"name\": \"Nachos\", \"quantity\": 156, \"revenue\": 780.00},\n                 {\"name\": \"Carnitas Tacos\", \"quantity\": 134, \"revenue\": 469.00},\n-                {\"name\": \"Quesadillas\", \"quantity\": 98, \"revenue\": 539.00}\n+                {\"name\": \"Quesadillas\", \"quantity\": 98, \"revenue\": 539.00},\n             ],\n             \"hourlyBreakdown\": [],\n             \"paymentMethods\": {\n                 \"card\": {\"count\": 178, \"percentage\": 62},\n                 \"cash\": {\"count\": 65, \"percentage\": 23},\n-                \"applePay\": {\"count\": 44, \"percentage\": 15}\n+                \"applePay\": {\"count\": 44, \"percentage\": 15},\n             },\n             \"staffPerformance\": [\n                 {\"name\": \"John Manager\", \"orders\": 89, \"revenue\": 5234.50},\n-                {\"name\": \"Sarah Cashier\", \"orders\": 76, \"revenue\": 4567.80}\n-            ]\n-        },\n-        message=\"Analytics dashboard data retrieved\"\n-    )\n+                {\"name\": \"Sarah Cashier\", \"orders\": 76, \"revenue\": 4567.80},\n+            ],\n+        },\n+        message=\"Analytics dashboard data retrieved\",\n+    )\n+\n \n @app.get(\"/api/v1/schedule/week\")\n async def get_week_schedule():\n     \"\"\"Get weekly schedule\"\"\"\n     from datetime import datetime, timedelta\n-    \n+\n     # Generate a mock weekly schedule\n     today = datetime.now()\n     week_start = today - timedelta(days=today.weekday())\n-    \n+\n     schedule_data = []\n-    days = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n-    \n+    days = [\n+        \"Monday\",\n+        \"Tuesday\",\n+        \"Wednesday\",\n+        \"Thursday\",\n+        \"Friday\",\n+        \"Saturday\",\n+        \"Sunday\",\n+    ]\n+\n     for i, day in enumerate(days):\n         date = week_start + timedelta(days=i)\n-        schedule_data.append({\n-            \"date\": date.strftime(\"%Y-%m-%d\"),\n-            \"day\": day,\n-            \"shifts\": [\n-                {\n-                    \"employeeId\": 1,\n-                    \"employeeName\": \"John Manager\",\n-                    \"startTime\": \"09:00\",\n-                    \"endTime\": \"17:00\",\n-                    \"role\": \"manager\"\n-                },\n-                {\n-                    \"employeeId\": 2,\n-                    \"employeeName\": \"Sarah Cashier\",\n-                    \"startTime\": \"10:00\",\n-                    \"endTime\": \"18:00\",\n-                    \"role\": \"cashier\"\n-                }\n-            ]\n-        })\n-    \n+        schedule_data.append(\n+            {\n+                \"date\": date.strftime(\"%Y-%m-%d\"),\n+                \"day\": day,\n+                \"shifts\": [\n+                    {\n+                        \"employeeId\": 1,\n+                        \"employeeName\": \"John Manager\",\n+                        \"startTime\": \"09:00\",\n+                        \"endTime\": \"17:00\",\n+                        \"role\": \"manager\",\n+                    },\n+                    {\n+                        \"employeeId\": 2,\n+                        \"employeeName\": \"Sarah Cashier\",\n+                        \"startTime\": \"10:00\",\n+                        \"endTime\": \"18:00\",\n+                        \"role\": \"cashier\",\n+                    },\n+                ],\n+            }\n+        )\n+\n     return APIResponseHelper.success(\n-        data=schedule_data,\n-        message=\"Weekly schedule retrieved\"\n-    )\n+        data=schedule_data, message=\"Weekly schedule retrieved\"\n+    )\n+\n \n if __name__ == \"__main__\":\n     import os\n+\n     port = int(os.environ.get(\"PORT\", 8000))  # Use DigitalOcean's PORT env var\n     uvicorn.run(\n         \"app.main:app\",\n         host=\"0.0.0.0\",\n         port=port,\n         reload=settings.ENVIRONMENT == \"development\",\n-        log_level=settings.LOG_LEVEL.lower()\n-    )\n\\ No newline at end of file\n+        log_level=settings.LOG_LEVEL.lower(),\n+    )\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/schemas/fee_schemas.py\t2025-08-02 19:23:36.827314+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/schemas/fee_schemas.py\t2025-08-02 22:36:03.748540+00:00\n@@ -1,76 +1,96 @@\n from typing import Optional\n from typing_extensions import TypedDict\n from enum import Enum\n+\n \n class PaymentMethodEnum(str, Enum):\n     STRIPE = \"stripe\"\n     SUMUP = \"sumup\"\n     CASH = \"cash\"\n-    CARD_MANUAL = \"card_manual\" # A generic card payment\n+    CARD_MANUAL = \"card_manual\"  # A generic card payment\n     OTHER = \"other\"\n+\n \n class CustomerTotalBreakdown(TypedDict):\n     subtotal: float\n-    vat_amount: float # Assuming VAT might be needed explicitly\n+    vat_amount: float  # Assuming VAT might be needed explicitly\n     service_charge_calculated: float\n     platform_fee: float\n     processor_fee: float\n     customer_pays_processor_fees: bool\n     final_total: float\n     notes: Optional[str]\n \n+\n class ServiceChargeBreakdown(TypedDict):\n     original_service_charge_on_subtotal: float\n-    processor_fee_added_to_service_charge: float # This is the portion of processor fee covered by SC\n+    processor_fee_added_to_service_charge: (\n+        float  # This is the portion of processor fee covered by SC\n+    )\n     final_service_charge_amount: float\n-    service_charge_rate_applied: float # The rate used (e.g. 0.10 for 10%)\n+    service_charge_rate_applied: float  # The rate used (e.g. 0.10 for 10%)\n     include_transaction_fees_in_service_charge: bool\n+\n \n # For StaffTipService later\n class StaffMember(TypedDict):\n-    id: str # Staff ID, likely from Odoo user or hr.employee\n+    id: str  # Staff ID, likely from Odoo user or hr.employee\n     name: str\n+\n \n class StaffTipDistribution(TypedDict):\n     staff_member: StaffMember\n     tip_amount_allocated: float\n     notes: Optional[str]\n \n+\n # For payment_method_fee_settings table later\n class PaymentMethodFeeSettingSchema(TypedDict):\n-    id: Optional[int] # Primary key\n-    restaurant_id: Optional[str] # For restaurant-specific overrides, null for platform default\n+    id: Optional[int]  # Primary key\n+    restaurant_id: Optional[\n+        str\n+    ]  # For restaurant-specific overrides, null for platform default\n     payment_method: PaymentMethodEnum\n     customer_pays_default: bool\n-    allow_toggle_by_merchant: bool # If merchant can switch who pays on POS\n-    include_processor_fee_in_service_charge: bool # If this payment method's fee contributes to SC\n+    allow_toggle_by_merchant: bool  # If merchant can switch who pays on POS\n+    include_processor_fee_in_service_charge: (\n+        bool  # If this payment method's fee contributes to SC\n+    )\n \n     class Config:\n-        from_attributes = True # If using Pydantic models with SQLAlchemy\n+        from_attributes = True  # If using Pydantic models with SQLAlchemy\n+\n \n # For platform_fees table later\n class PlatformFeeRecordSchema(TypedDict):\n     id: Optional[int]\n-    order_id: str # Link to Odoo pos.order name or ID\n+    order_id: str  # Link to Odoo pos.order name or ID\n     platform_fee_amount: float\n     processor_fee_amount: float\n     customer_paid_processor: bool\n     payment_method: PaymentMethodEnum\n-    transaction_timestamp: str # ISO format\n+    transaction_timestamp: str  # ISO format\n \n     class Config:\n         from_attributes = True\n \n+\n # For staff_tip_distributions table later\n class StaffTipDistributionRecordSchema(TypedDict):\n     id: Optional[int]\n-    order_id: str # Link to Odoo pos.order name or ID\n-    staff_id: str # Link to StaffMember ID\n-    tip_amount_gross: float # Tip amount collected for this staff member before any deductions\n-    service_charge_deduction: float # Portion of tip reduced due to service charge policy\n-    transaction_fee_impact_on_tip: float # Portion of tip reduced due to transaction fees in SC\n-    tip_amount_net: float # Actual tip paid to staff\n-    distribution_timestamp: str # ISO format\n+    order_id: str  # Link to Odoo pos.order name or ID\n+    staff_id: str  # Link to StaffMember ID\n+    tip_amount_gross: (\n+        float  # Tip amount collected for this staff member before any deductions\n+    )\n+    service_charge_deduction: (\n+        float  # Portion of tip reduced due to service charge policy\n+    )\n+    transaction_fee_impact_on_tip: (\n+        float  # Portion of tip reduced due to transaction fees in SC\n+    )\n+    tip_amount_net: float  # Actual tip paid to staff\n+    distribution_timestamp: str  # ISO format\n \n     class Config:\n         from_attributes = True\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/schemas/inventory_schemas.py\t2025-08-02 19:23:36.827478+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/schemas/inventory_schemas.py\t2025-08-02 22:36:03.762321+00:00\n@@ -1,68 +1,101 @@\n \"\"\"\n Pydantic Schemas for Inventory, Recipes, and Ledger\n \"\"\"\n+\n from pydantic import BaseModel, Field\n from typing import List, Optional\n from uuid import UUID\n from datetime import datetime\n \n+\n # Schema for InventoryItem\n class InventoryItemBase(BaseModel):\n-    sku: str = Field(..., description=\"Stock Keeping Unit - unique identifier for the inventory item\")\n-    restaurant_id: Optional[UUID] = Field(None, description=\"Restaurant ID - will be set automatically from user context\")\n+    sku: str = Field(\n+        ..., description=\"Stock Keeping Unit - unique identifier for the inventory item\"\n+    )\n+    restaurant_id: Optional[UUID] = Field(\n+        None, description=\"Restaurant ID - will be set automatically from user context\"\n+    )\n     name: str = Field(..., description=\"Name of the inventory item\")\n     description: Optional[str] = None\n-    qty_g: int = Field(default=0, description=\"Current quantity in grams (or ml or units)\")\n-    par_level_g: Optional[int] = Field(default=0, description=\"Desired stock level (par level)\")\n-    unit: Optional[str] = Field(default=\"grams\", description=\"Unit of measurement (e.g., grams, ml, units)\")\n-    cost_per_unit: Optional[float] = Field(None, description=\"Cost per unit (e.g., cost per gram)\")\n+    qty_g: int = Field(\n+        default=0, description=\"Current quantity in grams (or ml or units)\"\n+    )\n+    par_level_g: Optional[int] = Field(\n+        default=0, description=\"Desired stock level (par level)\"\n+    )\n+    unit: Optional[str] = Field(\n+        default=\"grams\", description=\"Unit of measurement (e.g., grams, ml, units)\"\n+    )\n+    cost_per_unit: Optional[float] = Field(\n+        None, description=\"Cost per unit (e.g., cost per gram)\"\n+    )\n     supplier: Optional[str] = None\n+\n \n class InventoryItemCreate(InventoryItemBase):\n     pass\n+\n \n class InventoryItemUpdate(BaseModel):\n     name: Optional[str] = None\n     description: Optional[str] = None\n     qty_g: Optional[int] = None\n     par_level_g: Optional[int] = None\n     unit: Optional[str] = None\n     cost_per_unit: Optional[float] = None\n     supplier: Optional[str] = None\n \n+\n class InventoryItemInDBBase(InventoryItemBase):\n     last_updated: datetime\n \n     class Config:\n         from_attributes = True\n+\n \n class InventoryItem(InventoryItemInDBBase):\n     pass\n \n \n # Schema for RecipeIngredient\n class RecipeIngredientBase(BaseModel):\n-    ingredient_sku: str = Field(..., description=\"SKU of the ingredient, maps to InventoryItem.sku\")\n-    qty_g: int = Field(..., gt=0, le=1000, description=\"Quantity of this ingredient in grams (or ml/units) per portion of the menu item. Must be > 0 and <= 1000.\")\n+    ingredient_sku: str = Field(\n+        ..., description=\"SKU of the ingredient, maps to InventoryItem.sku\"\n+    )\n+    qty_g: int = Field(\n+        ...,\n+        gt=0,\n+        le=1000,\n+        description=\"Quantity of this ingredient in grams (or ml/units) per portion of the menu item. Must be > 0 and <= 1000.\",\n+    )\n+\n \n class RecipeIngredientCreate(RecipeIngredientBase):\n     pass\n+\n \n class RecipeIngredient(RecipeIngredientBase):\n     # Optional: Add fields from InventoryItem if you want to return them nested\n     # ingredient_name: Optional[str] = None\n     pass\n \n \n # Schema for Recipe\n class RecipeBase(BaseModel):\n-    item_id: UUID = Field(..., description=\"ID of the menu item (Product) this recipe is for\")\n-    ingredients: List[RecipeIngredientCreate] = Field(..., description=\"List of ingredients and their quantities\")\n+    item_id: UUID = Field(\n+        ..., description=\"ID of the menu item (Product) this recipe is for\"\n+    )\n+    ingredients: List[RecipeIngredientCreate] = Field(\n+        ..., description=\"List of ingredients and their quantities\"\n+    )\n+\n \n class RecipeCreate(RecipeBase):\n     pass\n+\n \n class RecipeUpdate(BaseModel):\n     item_id: Optional[UUID] = None\n     ingredients: Optional[List[RecipeIngredientCreate]] = None\n \n@@ -76,10 +109,11 @@\n     # Alternatively, a more complex schema can be defined here if needed.\n \n     class Config:\n         from_attributes = True\n \n+\n class Recipe(RecipeInDBBase):\n     # This schema is for individual recipe ingredient entries as stored in DB\n     # The API will likely want to return a list of these grouped by item_id\n     ingredient_sku: str\n     qty_g: int\n@@ -88,52 +122,67 @@\n     # ingredient: Optional[InventoryItem]\n \n \n class RecipeResponse(BaseModel):\n     item_id: UUID\n-    item_name: Optional[str] # Product name, to be joined\n+    item_name: Optional[str]  # Product name, to be joined\n     ingredients: List[RecipeIngredient]\n \n \n # Schema for InventoryLedgerEntry\n class InventoryLedgerEntryBase(BaseModel):\n     sku: str\n-    delta_g: int = Field(..., description=\"Change in quantity. Positive for additions, negative for deductions.\")\n-    source: str = Field(..., description=\"Source of the inventory change (e.g., 'order_fulfillment', 'manual_stock_add')\")\n-    source_id: Optional[str] = Field(None, description=\"Identifier for the source (e.g., Order ID, User ID)\")\n+    delta_g: int = Field(\n+        ...,\n+        description=\"Change in quantity. Positive for additions, negative for deductions.\",\n+    )\n+    source: str = Field(\n+        ...,\n+        description=\"Source of the inventory change (e.g., 'order_fulfillment', 'manual_stock_add')\",\n+    )\n+    source_id: Optional[str] = Field(\n+        None, description=\"Identifier for the source (e.g., Order ID, User ID)\"\n+    )\n+\n \n class InventoryLedgerEntryCreate(InventoryLedgerEntryBase):\n     pass\n+\n \n class InventoryLedgerEntryInDBBase(InventoryLedgerEntryBase):\n     id: int\n     ts: datetime\n \n     class Config:\n         from_attributes = True\n \n+\n class InventoryLedgerEntry(InventoryLedgerEntryInDBBase):\n     pass\n+\n \n # Schemas for bulk operations or specific use cases\n class StockAdjustment(BaseModel):\n     sku: str\n-    change_qty_g: int # Positive to add stock, negative to remove (e.g. for spoilage)\n-    reason: Optional[str] = \"manual_adjustment\" # Default reason\n+    change_qty_g: int  # Positive to add stock, negative to remove (e.g. for spoilage)\n+    reason: Optional[str] = \"manual_adjustment\"  # Default reason\n+\n \n class StockAdjustmentResult(BaseModel):\n     sku: str\n     new_qty_g: int\n     message: str\n \n+\n class InventoryStatusResponse(BaseModel):\n     sku: str\n     name: str\n     current_qty_g: int\n     par_level_g: Optional[int]\n-    status: str # e.g. \"In Stock\", \"Low Stock\", \"Out of Stock\"\n+    status: str  # e.g. \"In Stock\", \"Low Stock\", \"Out of Stock\"\n     unit: Optional[str]\n+\n \n class LowStockItem(BaseModel):\n     sku: str\n     name: str\n     qty_g: int\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models/employee.py\t2025-08-02 19:23:36.825897+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models/employee.py\t2025-08-02 22:36:03.767490+00:00\n@@ -1,230 +1,296 @@\n \"\"\"\n Employee Management Models\n Extends the User model with employee-specific features like schedules, shifts, and performance tracking\n \"\"\"\n-from sqlalchemy import Column, String, Integer, Boolean, DateTime, Date, Time, DECIMAL, ForeignKey, UniqueConstraint\n+\n+from sqlalchemy import (\n+    Column,\n+    String,\n+    Integer,\n+    Boolean,\n+    DateTime,\n+    Date,\n+    Time,\n+    DECIMAL,\n+    ForeignKey,\n+    UniqueConstraint,\n+)\n from sqlalchemy.dialects.postgresql import UUID, JSONB\n from sqlalchemy.sql import func\n from sqlalchemy.orm import relationship\n import uuid\n from app.core.database import Base\n \n \n class EmployeeProfile(Base):\n     \"\"\"Extended employee information linked to User model\"\"\"\n+\n     __tablename__ = \"employee_profiles\"\n-    \n-    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n-    user_id = Column(UUID(as_uuid=True), ForeignKey(\"users.id\"), unique=True, nullable=False)\n-    restaurant_id = Column(UUID(as_uuid=True), ForeignKey(\"restaurants.id\"), nullable=False)\n-    \n+\n+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n+    user_id = Column(\n+        UUID(as_uuid=True), ForeignKey(\"users.id\"), unique=True, nullable=False\n+    )\n+    restaurant_id = Column(\n+        UUID(as_uuid=True), ForeignKey(\"restaurants.id\"), nullable=False\n+    )\n+\n     # Employment Information\n     employee_id = Column(String(50), unique=True)  # Internal employee ID\n     hire_date = Column(Date, nullable=False)\n-    employment_type = Column(String(50), default=\"full_time\")  # full_time, part_time, seasonal\n+    employment_type = Column(\n+        String(50), default=\"full_time\"\n+    )  # full_time, part_time, seasonal\n     hourly_rate = Column(DECIMAL(10, 2), nullable=False)\n-    \n+\n     # Contact & Emergency\n     phone = Column(String(20), nullable=False)\n     emergency_contact = Column(JSONB, default={})  # {name, phone, relationship}\n-    \n+\n     # Scheduling Preferences\n     max_hours_per_week = Column(Integer, default=40)\n     min_hours_per_week = Column(Integer, default=0)\n-    availability = Column(JSONB, default={})  # {monday: {start: \"09:00\", end: \"17:00\"}, ...}\n-    \n+    availability = Column(\n+        JSONB, default={}\n+    )  # {monday: {start: \"09:00\", end: \"17:00\"}, ...}\n+\n     # Performance Metrics\n     performance_rating = Column(DECIMAL(3, 2), default=0.0)  # 0.00 to 5.00\n     total_sales = Column(DECIMAL(12, 2), default=0.0)\n     orders_served = Column(Integer, default=0)\n     average_order_time = Column(Integer, default=0)  # minutes\n-    \n+\n     # Status\n     is_active = Column(Boolean, default=True)\n     termination_date = Column(Date, nullable=True)\n     notes = Column(JSONB, default=[])  # [{date, note, author_id}]\n-    \n-    created_at = Column(DateTime(timezone=True), server_default=func.now())\n-    updated_at = Column(DateTime(timezone=True), onupdate=func.now())\n-    \n+\n+    created_at = Column(DateTime(timezone=True), server_default=func.now())\n+    updated_at = Column(DateTime(timezone=True), onupdate=func.now())\n+\n     # Relationships\n     user = relationship(\"User\", backref=\"employee_profile\")\n     restaurant = relationship(\"Restaurant\", backref=\"employees\")\n-    schedules = relationship(\"Schedule\", back_populates=\"employee\", cascade=\"all, delete-orphan\", foreign_keys=\"Schedule.employee_id\")\n-    shifts = relationship(\"Shift\", back_populates=\"employee\", cascade=\"all, delete-orphan\")\n-    time_entries = relationship(\"TimeEntry\", back_populates=\"employee\", cascade=\"all, delete-orphan\")\n+    schedules = relationship(\n+        \"Schedule\",\n+        back_populates=\"employee\",\n+        cascade=\"all, delete-orphan\",\n+        foreign_keys=\"Schedule.employee_id\",\n+    )\n+    shifts = relationship(\n+        \"Shift\", back_populates=\"employee\", cascade=\"all, delete-orphan\"\n+    )\n+    time_entries = relationship(\n+        \"TimeEntry\", back_populates=\"employee\", cascade=\"all, delete-orphan\"\n+    )\n \n \n class Schedule(Base):\n     \"\"\"Employee work schedules\"\"\"\n+\n     __tablename__ = \"schedules\"\n-    \n-    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n-    employee_id = Column(UUID(as_uuid=True), ForeignKey(\"employee_profiles.id\"), nullable=False)\n-    restaurant_id = Column(UUID(as_uuid=True), ForeignKey(\"restaurants.id\"), nullable=False)\n-    \n+\n+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n+    employee_id = Column(\n+        UUID(as_uuid=True), ForeignKey(\"employee_profiles.id\"), nullable=False\n+    )\n+    restaurant_id = Column(\n+        UUID(as_uuid=True), ForeignKey(\"restaurants.id\"), nullable=False\n+    )\n+\n     # Schedule Details\n     date = Column(Date, nullable=False)\n     start_time = Column(Time, nullable=False)\n     end_time = Column(Time, nullable=False)\n     break_minutes = Column(Integer, default=0)\n-    \n+\n     # Role for this shift\n     role = Column(String(50), nullable=False)  # server, kitchen, cashier, manager\n-    section_id = Column(UUID(as_uuid=True), ForeignKey(\"sections.id\"), nullable=True)  # For servers\n-    \n+    section_id = Column(\n+        UUID(as_uuid=True), ForeignKey(\"sections.id\"), nullable=True\n+    )  # For servers\n+\n     # Status\n-    status = Column(String(20), default=\"scheduled\")  # scheduled, confirmed, completed, cancelled\n+    status = Column(\n+        String(20), default=\"scheduled\"\n+    )  # scheduled, confirmed, completed, cancelled\n     is_published = Column(Boolean, default=False)\n-    \n+\n     # Swap/Cover requests\n     swap_requested = Column(Boolean, default=False)\n-    swap_with_employee_id = Column(UUID(as_uuid=True), ForeignKey(\"employee_profiles.id\"), nullable=True)\n-    \n+    swap_with_employee_id = Column(\n+        UUID(as_uuid=True), ForeignKey(\"employee_profiles.id\"), nullable=True\n+    )\n+\n     notes = Column(String(500), nullable=True)\n     created_by = Column(UUID(as_uuid=True), ForeignKey(\"users.id\"), nullable=False)\n     created_at = Column(DateTime(timezone=True), server_default=func.now())\n     updated_at = Column(DateTime(timezone=True), onupdate=func.now())\n-    \n-    # Relationships\n-    employee = relationship(\"EmployeeProfile\", back_populates=\"schedules\", foreign_keys=[employee_id])\n+\n+    # Relationships\n+    employee = relationship(\n+        \"EmployeeProfile\", back_populates=\"schedules\", foreign_keys=[employee_id]\n+    )\n     restaurant = relationship(\"Restaurant\")\n     section = relationship(\"Section\")\n     creator = relationship(\"User\", foreign_keys=[created_by])\n-    swap_with_employee = relationship(\"EmployeeProfile\", foreign_keys=[swap_with_employee_id])\n-    \n+    swap_with_employee = relationship(\n+        \"EmployeeProfile\", foreign_keys=[swap_with_employee_id]\n+    )\n+\n     # Ensure no duplicate schedules for same employee on same date/time\n     __table_args__ = (\n-        UniqueConstraint('employee_id', 'date', 'start_time', name='uq_employee_schedule'),\n+        UniqueConstraint(\n+            \"employee_id\", \"date\", \"start_time\", name=\"uq_employee_schedule\"\n+        ),\n     )\n \n \n class Shift(Base):\n     \"\"\"Actual worked shifts (clock in/out records)\"\"\"\n+\n     __tablename__ = \"shifts\"\n-    \n-    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n-    employee_id = Column(UUID(as_uuid=True), ForeignKey(\"employee_profiles.id\"), nullable=False)\n-    restaurant_id = Column(UUID(as_uuid=True), ForeignKey(\"restaurants.id\"), nullable=False)\n+\n+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n+    employee_id = Column(\n+        UUID(as_uuid=True), ForeignKey(\"employee_profiles.id\"), nullable=False\n+    )\n+    restaurant_id = Column(\n+        UUID(as_uuid=True), ForeignKey(\"restaurants.id\"), nullable=False\n+    )\n     schedule_id = Column(UUID(as_uuid=True), ForeignKey(\"schedules.id\"), nullable=True)\n-    \n+\n     # Clock In/Out\n     clock_in = Column(DateTime(timezone=True), nullable=False)\n     clock_out = Column(DateTime(timezone=True), nullable=True)\n-    \n+\n     # Break tracking\n     break_start = Column(DateTime(timezone=True), nullable=True)\n     break_end = Column(DateTime(timezone=True), nullable=True)\n     total_break_minutes = Column(Integer, default=0)\n-    \n+\n     # Shift Details\n     role = Column(String(50), nullable=False)\n     hourly_rate = Column(DECIMAL(10, 2), nullable=False)  # Rate at time of shift\n-    \n+\n     # Calculated Fields\n     total_hours = Column(DECIMAL(5, 2), default=0.0)\n     regular_hours = Column(DECIMAL(5, 2), default=0.0)\n     overtime_hours = Column(DECIMAL(5, 2), default=0.0)\n-    \n+\n     # Earnings\n     tips_cash = Column(DECIMAL(10, 2), default=0.0)\n     tips_card = Column(DECIMAL(10, 2), default=0.0)\n     total_sales = Column(DECIMAL(12, 2), default=0.0)\n     total_earnings = Column(DECIMAL(10, 2), default=0.0)  # wages + tips\n-    \n+\n     # Status\n     status = Column(String(20), default=\"active\")  # active, completed, void\n-    approval_status = Column(String(20), default=\"pending\")  # pending, approved, rejected\n+    approval_status = Column(\n+        String(20), default=\"pending\"\n+    )  # pending, approved, rejected\n     approved_by = Column(UUID(as_uuid=True), ForeignKey(\"users.id\"), nullable=True)\n     approved_at = Column(DateTime(timezone=True), nullable=True)\n-    \n+\n     notes = Column(String(500), nullable=True)\n     created_at = Column(DateTime(timezone=True), server_default=func.now())\n     updated_at = Column(DateTime(timezone=True), onupdate=func.now())\n-    \n+\n     # Relationships\n     employee = relationship(\"EmployeeProfile\", back_populates=\"shifts\")\n     restaurant = relationship(\"Restaurant\")\n     schedule = relationship(\"Schedule\")\n     approver = relationship(\"User\")\n \n \n class TimeEntry(Base):\n     \"\"\"Time clock entries for tracking all clock events\"\"\"\n+\n     __tablename__ = \"time_entries\"\n-    \n-    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n-    employee_id = Column(UUID(as_uuid=True), ForeignKey(\"employee_profiles.id\"), nullable=False)\n+\n+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n+    employee_id = Column(\n+        UUID(as_uuid=True), ForeignKey(\"employee_profiles.id\"), nullable=False\n+    )\n     shift_id = Column(UUID(as_uuid=True), ForeignKey(\"shifts.id\"), nullable=True)\n-    \n+\n     # Entry Details\n-    entry_type = Column(String(20), nullable=False)  # clock_in, clock_out, break_start, break_end\n+    entry_type = Column(\n+        String(20), nullable=False\n+    )  # clock_in, clock_out, break_start, break_end\n     timestamp = Column(DateTime(timezone=True), nullable=False)\n-    \n+\n     # Location/Device\n     device_id = Column(String(100), nullable=True)\n     ip_address = Column(String(45), nullable=True)\n     location = Column(JSONB, nullable=True)  # {lat, lng, accuracy}\n-    \n+\n     # Verification\n     pin_verified = Column(Boolean, default=True)\n     biometric_verified = Column(Boolean, default=False)\n     manager_override = Column(Boolean, default=False)\n     override_by = Column(UUID(as_uuid=True), ForeignKey(\"users.id\"), nullable=True)\n     override_reason = Column(String(255), nullable=True)\n-    \n-    created_at = Column(DateTime(timezone=True), server_default=func.now())\n-    \n+\n+    created_at = Column(DateTime(timezone=True), server_default=func.now())\n+\n     # Relationships\n     employee = relationship(\"EmployeeProfile\", back_populates=\"time_entries\")\n     shift = relationship(\"Shift\")\n     override_manager = relationship(\"User\")\n \n \n class PerformanceMetric(Base):\n     \"\"\"Employee performance tracking\"\"\"\n+\n     __tablename__ = \"performance_metrics\"\n-    \n-    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n-    employee_id = Column(UUID(as_uuid=True), ForeignKey(\"employee_profiles.id\"), nullable=False)\n-    restaurant_id = Column(UUID(as_uuid=True), ForeignKey(\"restaurants.id\"), nullable=False)\n-    \n+\n+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n+    employee_id = Column(\n+        UUID(as_uuid=True), ForeignKey(\"employee_profiles.id\"), nullable=False\n+    )\n+    restaurant_id = Column(\n+        UUID(as_uuid=True), ForeignKey(\"restaurants.id\"), nullable=False\n+    )\n+\n     # Period\n     metric_date = Column(Date, nullable=False)\n     metric_type = Column(String(50), nullable=False)  # daily, weekly, monthly\n-    \n+\n     # Sales Metrics\n     total_sales = Column(DECIMAL(12, 2), default=0.0)\n     transaction_count = Column(Integer, default=0)\n     average_transaction = Column(DECIMAL(10, 2), default=0.0)\n-    \n+\n     # Service Metrics\n     tables_served = Column(Integer, default=0)\n     average_table_time = Column(Integer, default=0)  # minutes\n-    \n+\n     # Quality Metrics\n     customer_rating = Column(DECIMAL(3, 2), default=0.0)  # 0.00 to 5.00\n     compliments = Column(Integer, default=0)\n     complaints = Column(Integer, default=0)\n-    \n+\n     # Efficiency\n     items_per_hour = Column(DECIMAL(10, 2), default=0.0)\n     waste_percentage = Column(DECIMAL(5, 2), default=0.0)\n-    \n+\n     # Attendance\n     scheduled_hours = Column(DECIMAL(5, 2), default=0.0)\n     worked_hours = Column(DECIMAL(5, 2), default=0.0)\n     late_arrivals = Column(Integer, default=0)\n     no_shows = Column(Integer, default=0)\n-    \n-    created_at = Column(DateTime(timezone=True), server_default=func.now())\n-    updated_at = Column(DateTime(timezone=True), onupdate=func.now())\n-    \n+\n+    created_at = Column(DateTime(timezone=True), server_default=func.now())\n+    updated_at = Column(DateTime(timezone=True), onupdate=func.now())\n+\n     # Relationships\n     employee = relationship(\"EmployeeProfile\")\n     restaurant = relationship(\"Restaurant\")\n-    \n+\n     # Ensure one metric per employee per date per type\n     __table_args__ = (\n-        UniqueConstraint('employee_id', 'metric_date', 'metric_type', name='uq_employee_metric'),\n-    )\n\\ No newline at end of file\n+        UniqueConstraint(\n+            \"employee_id\", \"metric_date\", \"metric_type\", name=\"uq_employee_metric\"\n+        ),\n+    )\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/middleware/websocket_rate_limit.py\t2025-08-02 19:23:36.825495+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/middleware/websocket_rate_limit.py\t2025-08-02 22:36:03.767176+00:00\n@@ -17,169 +17,213 @@\n logger = logging.getLogger(__name__)\n \n \n class RateLimitAction(str, Enum):\n     \"\"\"Actions to take when rate limit is exceeded\"\"\"\n+\n     BLOCK = \"block\"\n     THROTTLE = \"throttle\"\n     WARN = \"warn\"\n \n \n class WebSocketRateLimiter:\n     \"\"\"\n     Rate limiter for WebSocket connections and messages\n     Uses Redis for distributed rate limiting across multiple servers\n     \"\"\"\n-    \n+\n     def __init__(self):\n         # Connection limits\n-        self.MAX_CONNECTIONS_PER_IP = settings.get(\"WEBSOCKET_MAX_CONNECTIONS_PER_IP\", 10)\n-        self.MAX_CONNECTIONS_PER_USER = settings.get(\"WEBSOCKET_MAX_CONNECTIONS_PER_USER\", 5)\n-        self.CONNECTION_WINDOW_MINUTES = settings.get(\"WEBSOCKET_CONNECTION_WINDOW_MINUTES\", 1)\n-        \n+        self.MAX_CONNECTIONS_PER_IP = settings.get(\n+            \"WEBSOCKET_MAX_CONNECTIONS_PER_IP\", 10\n+        )\n+        self.MAX_CONNECTIONS_PER_USER = settings.get(\n+            \"WEBSOCKET_MAX_CONNECTIONS_PER_USER\", 5\n+        )\n+        self.CONNECTION_WINDOW_MINUTES = settings.get(\n+            \"WEBSOCKET_CONNECTION_WINDOW_MINUTES\", 1\n+        )\n+\n         # Message limits\n-        self.MAX_MESSAGES_PER_CONNECTION = settings.get(\"WEBSOCKET_MAX_MESSAGES_PER_CONNECTION\", 60)\n-        self.MESSAGE_WINDOW_SECONDS = settings.get(\"WEBSOCKET_MESSAGE_WINDOW_SECONDS\", 60)\n-        \n+        self.MAX_MESSAGES_PER_CONNECTION = settings.get(\n+            \"WEBSOCKET_MAX_MESSAGES_PER_CONNECTION\", 60\n+        )\n+        self.MESSAGE_WINDOW_SECONDS = settings.get(\n+            \"WEBSOCKET_MESSAGE_WINDOW_SECONDS\", 60\n+        )\n+\n         # Violation tracking for exponential backoff\n-        self.VIOLATION_EXPIRY_HOURS = settings.get(\"WEBSOCKET_VIOLATION_EXPIRY_HOURS\", 24)\n-        self.MAX_VIOLATIONS_BEFORE_BAN = settings.get(\"WEBSOCKET_MAX_VIOLATIONS_BEFORE_BAN\", 10)\n-        \n+        self.VIOLATION_EXPIRY_HOURS = settings.get(\n+            \"WEBSOCKET_VIOLATION_EXPIRY_HOURS\", 24\n+        )\n+        self.MAX_VIOLATIONS_BEFORE_BAN = settings.get(\n+            \"WEBSOCKET_MAX_VIOLATIONS_BEFORE_BAN\", 10\n+        )\n+\n         # In-memory fallback for when Redis is unavailable\n         self._fallback_storage: Dict[str, Dict[str, Any]] = defaultdict(dict)\n         self._fallback_lock = asyncio.Lock()\n-        \n+\n         # Metrics\n         self.metrics = {\n             \"connections_allowed\": 0,\n             \"connections_blocked\": 0,\n             \"messages_allowed\": 0,\n             \"messages_blocked\": 0,\n             \"violations_recorded\": 0,\n-            \"bans_applied\": 0\n+            \"bans_applied\": 0,\n         }\n-    \n+\n     async def check_connection_limit(\n-        self, \n-        ip_address: str, \n-        user_id: Optional[str] = None\n+        self, ip_address: str, user_id: Optional[str] = None\n     ) -> Tuple[bool, Optional[str], Optional[int]]:\n         \"\"\"\n         Check if a new WebSocket connection is allowed\n-        \n+\n         Returns:\n             - allowed: Whether the connection is allowed\n             - reason: Reason for blocking (if blocked)\n             - retry_after: Seconds until retry is allowed (for exponential backoff)\n         \"\"\"\n         try:\n             # Check if IP is banned\n             is_banned, ban_duration = await self._check_ban_status(ip_address)\n             if is_banned:\n                 self.metrics[\"connections_blocked\"] += 1\n-                return False, f\"IP banned for {ban_duration} seconds due to repeated violations\", ban_duration\n-            \n+                return (\n+                    False,\n+                    f\"IP banned for {ban_duration} seconds due to repeated violations\",\n+                    ban_duration,\n+                )\n+\n             # Check IP connection rate\n             ip_key = f\"ws:conn:ip:{ip_address}\"\n-            ip_count = await self._increment_counter(ip_key, self.CONNECTION_WINDOW_MINUTES * 60)\n-            \n+            ip_count = await self._increment_counter(\n+                ip_key, self.CONNECTION_WINDOW_MINUTES * 60\n+            )\n+\n             if ip_count > self.MAX_CONNECTIONS_PER_IP:\n                 await self._record_violation(ip_address, \"connection_limit_exceeded\")\n                 self.metrics[\"connections_blocked\"] += 1\n-                return False, f\"Too many connections from IP (limit: {self.MAX_CONNECTIONS_PER_IP}/min)\", 60\n-            \n+                return (\n+                    False,\n+                    f\"Too many connections from IP (limit: {self.MAX_CONNECTIONS_PER_IP}/min)\",\n+                    60,\n+                )\n+\n             # Check user connection rate if user_id provided\n             if user_id:\n                 user_key = f\"ws:conn:user:{user_id}\"\n-                user_count = await self._increment_counter(user_key, self.CONNECTION_WINDOW_MINUTES * 60)\n-                \n+                user_count = await self._increment_counter(\n+                    user_key, self.CONNECTION_WINDOW_MINUTES * 60\n+                )\n+\n                 if user_count > self.MAX_CONNECTIONS_PER_USER:\n-                    await self._record_violation(f\"user:{user_id}\", \"user_connection_limit_exceeded\")\n+                    await self._record_violation(\n+                        f\"user:{user_id}\", \"user_connection_limit_exceeded\"\n+                    )\n                     self.metrics[\"connections_blocked\"] += 1\n-                    return False, f\"Too many connections for user (limit: {self.MAX_CONNECTIONS_PER_USER}/min)\", 60\n-            \n+                    return (\n+                        False,\n+                        f\"Too many connections for user (limit: {self.MAX_CONNECTIONS_PER_USER}/min)\",\n+                        60,\n+                    )\n+\n             # Check active connections (not rate, but total active)\n             active_key = f\"ws:active:ip:{ip_address}\"\n             active_count = await self._get_active_count(active_key)\n-            \n+\n             if active_count >= self.MAX_CONNECTIONS_PER_IP:\n                 self.metrics[\"connections_blocked\"] += 1\n                 return False, f\"Maximum active connections reached for IP\", 60\n-            \n+\n             self.metrics[\"connections_allowed\"] += 1\n             return True, None, None\n-            \n+\n         except Exception as e:\n             logger.error(f\"Error checking connection limit: {str(e)}\")\n             # Fail open in case of Redis issues, but log it\n             logger.warning(\"Rate limiting failed, allowing connection (fail-open)\")\n             return True, None, None\n-    \n+\n     async def check_message_limit(\n-        self, \n-        connection_id: str,\n-        ip_address: str,\n-        user_id: Optional[str] = None\n+        self, connection_id: str, ip_address: str, user_id: Optional[str] = None\n     ) -> Tuple[bool, Optional[str]]:\n         \"\"\"\n         Check if a message is allowed on a WebSocket connection\n-        \n+\n         Returns:\n             - allowed: Whether the message is allowed\n             - reason: Reason for blocking (if blocked)\n         \"\"\"\n         try:\n             # Check message rate for connection\n             conn_key = f\"ws:msg:conn:{connection_id}\"\n-            msg_count = await self._increment_counter(conn_key, self.MESSAGE_WINDOW_SECONDS)\n-            \n+            msg_count = await self._increment_counter(\n+                conn_key, self.MESSAGE_WINDOW_SECONDS\n+            )\n+\n             if msg_count > self.MAX_MESSAGES_PER_CONNECTION:\n                 await self._record_violation(ip_address, \"message_limit_exceeded\")\n                 self.metrics[\"messages_blocked\"] += 1\n-                \n+\n                 # Check if we should escalate to connection termination\n                 violation_count = await self._get_violation_count(ip_address)\n-                if violation_count >= 5:  # Terminate connection after 5 message violations\n-                    return False, \"Message rate limit exceeded - connection will be terminated\"\n-                \n-                return False, f\"Too many messages (limit: {self.MAX_MESSAGES_PER_CONNECTION}/min)\"\n-            \n+                if (\n+                    violation_count >= 5\n+                ):  # Terminate connection after 5 message violations\n+                    return (\n+                        False,\n+                        \"Message rate limit exceeded - connection will be terminated\",\n+                    )\n+\n+                return (\n+                    False,\n+                    f\"Too many messages (limit: {self.MAX_MESSAGES_PER_CONNECTION}/min)\",\n+                )\n+\n             # Additional per-user message limiting\n             if user_id:\n                 user_msg_key = f\"ws:msg:user:{user_id}\"\n-                user_msg_count = await self._increment_counter(user_msg_key, self.MESSAGE_WINDOW_SECONDS)\n-                \n+                user_msg_count = await self._increment_counter(\n+                    user_msg_key, self.MESSAGE_WINDOW_SECONDS\n+                )\n+\n                 # User gets higher limit (3x connection limit)\n                 if user_msg_count > self.MAX_MESSAGES_PER_CONNECTION * 3:\n-                    await self._record_violation(f\"user:{user_id}\", \"user_message_limit_exceeded\")\n+                    await self._record_violation(\n+                        f\"user:{user_id}\", \"user_message_limit_exceeded\"\n+                    )\n                     self.metrics[\"messages_blocked\"] += 1\n                     return False, \"User message rate limit exceeded\"\n-            \n+\n             self.metrics[\"messages_allowed\"] += 1\n             return True, None\n-            \n+\n         except Exception as e:\n             logger.error(f\"Error checking message limit: {str(e)}\")\n             # Fail open for messages too\n             return True, None\n-    \n+\n     async def register_connection(self, ip_address: str, connection_id: str):\n         \"\"\"Register a new active connection\"\"\"\n         try:\n             active_key = f\"ws:active:ip:{ip_address}\"\n-            await self._add_to_set(active_key, connection_id, expire=3600)  # 1 hour expiry\n+            await self._add_to_set(\n+                active_key, connection_id, expire=3600\n+            )  # 1 hour expiry\n         except Exception as e:\n             logger.error(f\"Error registering connection: {str(e)}\")\n-    \n+\n     async def unregister_connection(self, ip_address: str, connection_id: str):\n         \"\"\"Unregister a closed connection\"\"\"\n         try:\n             active_key = f\"ws:active:ip:{ip_address}\"\n             await self._remove_from_set(active_key, connection_id)\n         except Exception as e:\n             logger.error(f\"Error unregistering connection: {str(e)}\")\n-    \n+\n     async def _increment_counter(self, key: str, window_seconds: int) -> int:\n         \"\"\"Increment a rate limit counter with expiry\"\"\"\n         if redis_client.redis:\n             try:\n                 # Use Redis INCR with expiry\n@@ -188,255 +232,257 @@\n                     # First increment, set expiry\n                     await redis_client.expire(key, window_seconds)\n                 return count\n             except Exception as e:\n                 logger.error(f\"Redis error in increment_counter: {str(e)}\")\n-        \n+\n         # Fallback to in-memory\n         async with self._fallback_lock:\n             current_time = time.time()\n-            \n+\n             if key not in self._fallback_storage:\n-                self._fallback_storage[key] = {\n-                    \"count\": 0,\n-                    \"window_start\": current_time\n-                }\n-            \n+                self._fallback_storage[key] = {\"count\": 0, \"window_start\": current_time}\n+\n             entry = self._fallback_storage[key]\n-            \n+\n             # Check if window has expired\n             if current_time - entry[\"window_start\"] > window_seconds:\n                 entry[\"count\"] = 1\n                 entry[\"window_start\"] = current_time\n             else:\n                 entry[\"count\"] += 1\n-            \n+\n             return entry[\"count\"]\n-    \n+\n     async def _get_active_count(self, key: str) -> int:\n         \"\"\"Get count of active connections\"\"\"\n         if redis_client.redis:\n             try:\n                 count = await redis_client.redis.scard(key)\n                 return count\n             except Exception as e:\n                 logger.error(f\"Redis error in get_active_count: {str(e)}\")\n-        \n+\n         # Fallback\n         async with self._fallback_lock:\n             return len(self._fallback_storage.get(key, {}).get(\"members\", set()))\n-    \n+\n     async def _add_to_set(self, key: str, value: str, expire: int):\n         \"\"\"Add value to a set with expiry\"\"\"\n         if redis_client.redis:\n             try:\n                 await redis_client.redis.sadd(key, value)\n                 await redis_client.expire(key, expire)\n                 return\n             except Exception as e:\n                 logger.error(f\"Redis error in add_to_set: {str(e)}\")\n-        \n+\n         # Fallback\n         async with self._fallback_lock:\n             if key not in self._fallback_storage:\n                 self._fallback_storage[key] = {\"members\": set()}\n             self._fallback_storage[key][\"members\"].add(value)\n-    \n+\n     async def _remove_from_set(self, key: str, value: str):\n         \"\"\"Remove value from a set\"\"\"\n         if redis_client.redis:\n             try:\n                 await redis_client.redis.srem(key, value)\n                 return\n             except Exception as e:\n                 logger.error(f\"Redis error in remove_from_set: {str(e)}\")\n-        \n+\n         # Fallback\n         async with self._fallback_lock:\n-            if key in self._fallback_storage and \"members\" in self._fallback_storage[key]:\n+            if (\n+                key in self._fallback_storage\n+                and \"members\" in self._fallback_storage[key]\n+            ):\n                 self._fallback_storage[key][\"members\"].discard(value)\n-    \n+\n     async def _record_violation(self, identifier: str, violation_type: str):\n         \"\"\"Record a rate limit violation\"\"\"\n         try:\n             self.metrics[\"violations_recorded\"] += 1\n-            \n+\n             violation_key = f\"ws:violations:{identifier}\"\n             violation_count = await self._increment_counter(\n-                violation_key, \n-                self.VIOLATION_EXPIRY_HOURS * 3600\n-            )\n-            \n+                violation_key, self.VIOLATION_EXPIRY_HOURS * 3600\n+            )\n+\n             # Log violation\n             logger.warning(\n                 f\"Rate limit violation recorded - \"\n                 f\"Identifier: {identifier}, \"\n                 f\"Type: {violation_type}, \"\n                 f\"Count: {violation_count}\"\n             )\n-            \n+\n             # Check if we should ban\n             if violation_count >= self.MAX_VIOLATIONS_BEFORE_BAN:\n                 await self._apply_ban(identifier)\n-            \n+\n         except Exception as e:\n             logger.error(f\"Error recording violation: {str(e)}\")\n-    \n+\n     async def _apply_ban(self, identifier: str):\n         \"\"\"Apply a temporary ban with exponential backoff\"\"\"\n         try:\n             violation_count = await self._get_violation_count(identifier)\n-            \n+\n             # Exponential backoff: 2^(violations-threshold) minutes\n-            ban_minutes = 2 ** max(0, violation_count - self.MAX_VIOLATIONS_BEFORE_BAN + 1)\n+            ban_minutes = 2 ** max(\n+                0, violation_count - self.MAX_VIOLATIONS_BEFORE_BAN + 1\n+            )\n             ban_seconds = min(ban_minutes * 60, 86400)  # Max 24 hours\n-            \n+\n             ban_key = f\"ws:ban:{identifier}\"\n-            await redis_client.set(ban_key, {\n-                \"banned_at\": datetime.now().isoformat(),\n-                \"ban_duration\": ban_seconds,\n-                \"violation_count\": violation_count\n-            }, expire=ban_seconds)\n-            \n+            await redis_client.set(\n+                ban_key,\n+                {\n+                    \"banned_at\": datetime.now().isoformat(),\n+                    \"ban_duration\": ban_seconds,\n+                    \"violation_count\": violation_count,\n+                },\n+                expire=ban_seconds,\n+            )\n+\n             self.metrics[\"bans_applied\"] += 1\n-            \n+\n             logger.warning(\n                 f\"Ban applied - \"\n                 f\"Identifier: {identifier}, \"\n                 f\"Duration: {ban_seconds}s, \"\n                 f\"Violations: {violation_count}\"\n             )\n-            \n+\n         except Exception as e:\n             logger.error(f\"Error applying ban: {str(e)}\")\n-    \n+\n     async def _check_ban_status(self, identifier: str) -> Tuple[bool, Optional[int]]:\n         \"\"\"Check if an identifier is banned\"\"\"\n         try:\n             ban_key = f\"ws:ban:{identifier}\"\n             ban_data = await redis_client.get(ban_key)\n-            \n+\n             if ban_data:\n                 # Calculate remaining ban time\n                 banned_at = datetime.fromisoformat(ban_data[\"banned_at\"])\n                 ban_duration = ban_data[\"ban_duration\"]\n                 elapsed = (datetime.now() - banned_at).total_seconds()\n                 remaining = int(ban_duration - elapsed)\n-                \n+\n                 if remaining > 0:\n                     return True, remaining\n-            \n+\n             return False, None\n-            \n+\n         except Exception as e:\n             logger.error(f\"Error checking ban status: {str(e)}\")\n             return False, None\n-    \n+\n     async def _get_violation_count(self, identifier: str) -> int:\n         \"\"\"Get current violation count\"\"\"\n         try:\n             violation_key = f\"ws:violations:{identifier}\"\n             count = await redis_client.get(violation_key)\n             return int(count) if count else 0\n         except Exception:\n             return 0\n-    \n+\n     def get_metrics(self) -> Dict[str, Any]:\n         \"\"\"Get rate limiting metrics\"\"\"\n         return {\n             **self.metrics,\n             \"limits\": {\n                 \"max_connections_per_ip\": self.MAX_CONNECTIONS_PER_IP,\n                 \"max_connections_per_user\": self.MAX_CONNECTIONS_PER_USER,\n                 \"max_messages_per_connection\": self.MAX_MESSAGES_PER_CONNECTION,\n                 \"connection_window_minutes\": self.CONNECTION_WINDOW_MINUTES,\n-                \"message_window_seconds\": self.MESSAGE_WINDOW_SECONDS\n-            }\n+                \"message_window_seconds\": self.MESSAGE_WINDOW_SECONDS,\n+            },\n         }\n-    \n+\n     async def cleanup_expired_data(self):\n         \"\"\"Periodic cleanup of expired rate limit data\"\"\"\n         try:\n             # Clean up old violations\n             pattern = \"ws:violations:*\"\n             await self._cleanup_pattern(pattern, self.VIOLATION_EXPIRY_HOURS * 3600)\n-            \n+\n             # Clean up expired bans\n             pattern = \"ws:ban:*\"\n             await self._cleanup_pattern(pattern, 86400)  # 24 hours max\n-            \n+\n             # Clean up in-memory fallback storage\n             async with self._fallback_lock:\n                 current_time = time.time()\n                 keys_to_delete = []\n-                \n+\n                 for key, data in self._fallback_storage.items():\n                     if \"window_start\" in data:\n                         # Check if window has expired\n                         window_seconds = 3600  # Default 1 hour\n                         if key.startswith(\"ws:msg:\"):\n                             window_seconds = self.MESSAGE_WINDOW_SECONDS\n                         elif key.startswith(\"ws:conn:\"):\n                             window_seconds = self.CONNECTION_WINDOW_MINUTES * 60\n-                        \n+\n                         if current_time - data[\"window_start\"] > window_seconds * 2:\n                             keys_to_delete.append(key)\n-                \n+\n                 for key in keys_to_delete:\n                     del self._fallback_storage[key]\n-                \n+\n         except Exception as e:\n             logger.error(f\"Error during cleanup: {str(e)}\")\n-    \n+\n     async def _cleanup_pattern(self, pattern: str, max_age_seconds: int):\n         \"\"\"Clean up keys matching pattern older than max_age\"\"\"\n         if not redis_client.redis:\n             return\n-        \n+\n         try:\n             # Use SCAN to avoid blocking\n             cursor = 0\n             while True:\n                 cursor, keys = await redis_client.redis.scan(\n-                    cursor, \n-                    match=pattern, \n-                    count=100\n+                    cursor, match=pattern, count=100\n                 )\n-                \n+\n                 for key in keys:\n                     # Check TTL\n                     ttl = await redis_client.redis.ttl(key)\n                     if ttl == -1:  # No expiry set\n                         await redis_client.expire(key, max_age_seconds)\n-                \n+\n                 if cursor == 0:\n                     break\n-                    \n+\n         except Exception as e:\n             logger.error(f\"Error in cleanup_pattern: {str(e)}\")\n \n \n # Global rate limiter instance\n websocket_rate_limiter = WebSocketRateLimiter()\n \n \n # Utility functions for easy integration\n async def check_websocket_connection_allowed(\n-    ip_address: str,\n-    user_id: Optional[str] = None\n+    ip_address: str, user_id: Optional[str] = None\n ) -> Tuple[bool, Optional[str], Optional[int]]:\n     \"\"\"Check if a WebSocket connection is allowed\"\"\"\n     return await websocket_rate_limiter.check_connection_limit(ip_address, user_id)\n \n \n async def check_websocket_message_allowed(\n-    connection_id: str,\n-    ip_address: str,\n-    user_id: Optional[str] = None\n+    connection_id: str, ip_address: str, user_id: Optional[str] = None\n ) -> Tuple[bool, Optional[str]]:\n     \"\"\"Check if a WebSocket message is allowed\"\"\"\n-    return await websocket_rate_limiter.check_message_limit(connection_id, ip_address, user_id)\n+    return await websocket_rate_limiter.check_message_limit(\n+        connection_id, ip_address, user_id\n+    )\n \n \n async def register_websocket_connection(ip_address: str, connection_id: str):\n     \"\"\"Register a new WebSocket connection\"\"\"\n     await websocket_rate_limiter.register_connection(ip_address, connection_id)\n@@ -459,6 +505,6 @@\n         try:\n             await asyncio.sleep(3600)  # Run every hour\n             await websocket_rate_limiter.cleanup_expired_data()\n             logger.info(\"WebSocket rate limit cleanup completed\")\n         except Exception as e:\n-            logger.error(f\"Error in rate limit cleanup task: {str(e)}\")\n\\ No newline at end of file\n+            logger.error(f\"Error in rate limit cleanup task: {str(e)}\")\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/schemas/refund_schemas.py\t2025-07-08 09:23:50.342692+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/schemas/refund_schemas.py\t2025-08-02 22:36:03.768880+00:00\n@@ -1,40 +1,46 @@\n from typing import List, Optional\n from pydantic import BaseModel, UUID4\n from decimal import Decimal\n \n+\n class RefundItemSchema(BaseModel):\n-    line_id: str # Assuming line_id is a string, adjust if it's an int or other type\n+    line_id: str  # Assuming line_id is a string, adjust if it's an int or other type\n     qty: int\n \n+\n class RefundRequestSchema(BaseModel):\n-    items: Optional[List[RefundItemSchema]] = None # Null or empty for full order refund\n+    items: Optional[List[RefundItemSchema]] = (\n+        None  # Null or empty for full order refund\n+    )\n     reason: Optional[str] = None\n     # For full order refund, amount might be passed or calculated based on order total\n-    amount: Optional[Decimal] = None # Explicit amount for full refund, if provided\n+    amount: Optional[Decimal] = None  # Explicit amount for full refund, if provided\n+\n \n class RefundResponseSchema(BaseModel):\n     id: UUID4\n-    order_id: str # Assuming order_id is a string from POS\n+    order_id: str  # Assuming order_id is a string from POS\n     amount: Decimal\n     reason: Optional[str] = None\n-    status: str # e.g., \"processed\", \"pending\", \"failed\"\n+    status: str  # e.g., \"processed\", \"pending\", \"failed\"\n     gateway_refund_id: Optional[str] = None\n-    created_at: str # ISO format datetime string\n+    created_at: str  # ISO format datetime string\n \n     class Config:\n-        from_attributes = True # Pydantic V1 style, or from_attributes = True for V2\n+        from_attributes = True  # Pydantic V1 style, or from_attributes = True for V2\n         # For Pydantic V2, ensure orm_mode is correctly handled.\n         # If using Pydantic V2, it would be:\n         # model_config = {\"from_attributes\": True}\n \n+\n class RefundLedgerEntrySchema(BaseModel):\n     id: UUID4\n     refund_id: UUID4\n-    user_id: Optional[str] = None # Assuming user_id is a string\n+    user_id: Optional[str] = None  # Assuming user_id is a string\n     device_id: Optional[str] = None\n     action: str\n-    timestamp: str # ISO format datetime string\n+    timestamp: str  # ISO format datetime string\n \n     class Config:\n         from_attributes = True\n         # model_config = {\"from_attributes\": True} # For Pydantic V2\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models/platform_audit.py\t2025-08-02 22:17:16.360657+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models/platform_audit.py\t2025-08-02 22:36:03.771393+00:00\n@@ -12,36 +12,39 @@\n from app.core.database import Base\n \n \n class PlatformAuditLog(Base):\n     \"\"\"Audit log for platform administrator actions\"\"\"\n+\n     __tablename__ = \"platform_audit_logs\"\n-    \n+\n     id = Column(Integer, primary_key=True, index=True)\n-    \n+\n     # Who performed the action\n     user_id = Column(String, ForeignKey(\"users.id\"), nullable=False, index=True)\n     user_email = Column(String, nullable=False)  # Denormalized for history\n-    \n+\n     # What action was performed\n     action = Column(String, nullable=False, index=True)\n     resource_type = Column(String, nullable=False, index=True)\n     resource_id = Column(String, nullable=True, index=True)\n-    \n+\n     # Additional details\n     details = Column(JSONB, default={})\n     ip_address = Column(String, nullable=True)\n     user_agent = Column(Text, nullable=True)\n-    \n+\n     # Request tracking\n     request_id = Column(String, nullable=True, index=True)\n     http_method = Column(String, nullable=True)\n     endpoint = Column(String, nullable=True)\n-    \n+\n     # Timestamps\n-    created_at = Column(TIMESTAMP, server_default=func.now(), nullable=False, index=True)\n-    \n+    created_at = Column(\n+        TIMESTAMP, server_default=func.now(), nullable=False, index=True\n+    )\n+\n     # Relationships\n     user = relationship(\"User\", backref=\"platform_audit_logs\")\n \n \n def create_audit_log(\n@@ -53,15 +56,15 @@\n     details: Optional[dict] = None,\n     ip_address: Optional[str] = None,\n     user_agent: Optional[str] = None,\n     request_id: Optional[str] = None,\n     http_method: Optional[str] = None,\n-    endpoint: Optional[str] = None\n+    endpoint: Optional[str] = None,\n ) -> PlatformAuditLog:\n     \"\"\"\n     Create an audit log entry.\n-    \n+\n     Args:\n         db: Database session\n         user_id: ID of the user performing the action\n         action: Action being performed (e.g., 'update_subscription', 'delete_user')\n         resource_type: Type of resource being acted upon (e.g., 'restaurant', 'user')\n@@ -70,20 +73,20 @@\n         ip_address: Client IP address\n         user_agent: Client user agent string\n         request_id: Unique request ID for tracking\n         http_method: HTTP method used\n         endpoint: API endpoint called\n-    \n+\n     Returns:\n         Created audit log entry\n     \"\"\"\n     from app.core.database import User\n-    \n+\n     # Get user email for denormalization\n     user = db.query(User).filter(User.id == user_id).first()\n     user_email = user.email if user else \"unknown\"\n-    \n+\n     audit_log = PlatformAuditLog(\n         user_id=user_id,\n         user_email=user_email,\n         action=action,\n         resource_type=resource_type,\n@@ -91,17 +94,17 @@\n         details=details or {},\n         ip_address=ip_address,\n         user_agent=user_agent,\n         request_id=request_id,\n         http_method=http_method,\n-        endpoint=endpoint\n-    )\n-    \n+        endpoint=endpoint,\n+    )\n+\n     db.add(audit_log)\n     db.commit()\n     db.refresh(audit_log)\n-    \n+\n     return audit_log\n \n \n # Common audit log actions\n AUDIT_ACTIONS = {\n@@ -109,29 +112,25 @@\n     \"create_restaurant\": \"Created new restaurant\",\n     \"update_restaurant\": \"Updated restaurant details\",\n     \"delete_restaurant\": \"Deleted restaurant\",\n     \"toggle_restaurant_status\": \"Changed restaurant status\",\n     \"update_subscription\": \"Updated restaurant subscription\",\n-    \n     # User management\n     \"create_user\": \"Created new user\",\n     \"update_user\": \"Updated user details\",\n     \"delete_user\": \"Deleted user\",\n     \"toggle_user_status\": \"Changed user status\",\n     \"reset_user_password\": \"Reset user password\",\n-    \n     # Financial actions\n     \"process_refund\": \"Processed refund\",\n     \"adjust_billing\": \"Adjusted billing\",\n     \"generate_invoice\": \"Generated invoice\",\n-    \n     # System actions\n     \"export_data\": \"Exported data\",\n     \"import_data\": \"Imported data\",\n     \"clear_cache\": \"Cleared cache\",\n     \"run_report\": \"Generated report\",\n-    \n     # Subscription management\n     \"batch_update_subscriptions\": \"Batch updated subscriptions\",\n     \"cancel_subscription\": \"Cancelled subscription\",\n     \"reactivate_subscription\": \"Reactivated subscription\",\n }\n@@ -144,50 +143,55 @@\n     resource_type: Optional[str] = None,\n     resource_id: Optional[str] = None,\n     start_date: Optional[datetime] = None,\n     end_date: Optional[datetime] = None,\n     limit: int = 100,\n-    offset: int = 0\n+    offset: int = 0,\n ) -> list[PlatformAuditLog]:\n     \"\"\"\n     Query audit logs with filters.\n-    \n+\n     Args:\n         db: Database session\n         user_id: Filter by user ID\n         action: Filter by action\n         resource_type: Filter by resource type\n         resource_id: Filter by resource ID\n         start_date: Filter by start date\n         end_date: Filter by end date\n         limit: Maximum number of results\n         offset: Offset for pagination\n-    \n+\n     Returns:\n         List of audit log entries\n     \"\"\"\n     query = db.query(PlatformAuditLog)\n-    \n+\n     if user_id:\n         query = query.filter(PlatformAuditLog.user_id == user_id)\n-    \n+\n     if action:\n         query = query.filter(PlatformAuditLog.action == action)\n-    \n+\n     if resource_type:\n         query = query.filter(PlatformAuditLog.resource_type == resource_type)\n-    \n+\n     if resource_id:\n         query = query.filter(PlatformAuditLog.resource_id == resource_id)\n-    \n+\n     if start_date:\n         query = query.filter(PlatformAuditLog.created_at >= start_date)\n-    \n+\n     if end_date:\n         query = query.filter(PlatformAuditLog.created_at <= end_date)\n-    \n-    return query.order_by(PlatformAuditLog.created_at.desc()).limit(limit).offset(offset).all()\n+\n+    return (\n+        query.order_by(PlatformAuditLog.created_at.desc())\n+        .limit(limit)\n+        .offset(offset)\n+        .all()\n+    )\n     \"\"\"\n     Get summary of audit logs for dashboard.\n     \n     Args:\n         db: Database session\n@@ -196,52 +200,54 @@\n     Returns:\n         Summary statistics\n     \"\"\"\n     from datetime import timedelta\n     from sqlalchemy import func\n-    \n+\n     cutoff_date = datetime.now() - timedelta(days=days)\n-    \n+\n     # Actions by type\n-    actions_by_type = db.query(\n-        PlatformAuditLog.action,\n-        func.count(PlatformAuditLog.id).label('count')\n-    ).filter(\n-        PlatformAuditLog.created_at >= cutoff_date\n-    ).group_by(\n-        PlatformAuditLog.action\n-    ).all()\n-    \n+    actions_by_type = (\n+        db.query(\n+            PlatformAuditLog.action, func.count(PlatformAuditLog.id).label(\"count\")\n+        )\n+        .filter(PlatformAuditLog.created_at >= cutoff_date)\n+        .group_by(PlatformAuditLog.action)\n+        .all()\n+    )\n+\n     # Actions by user\n-    actions_by_user = db.query(\n-        PlatformAuditLog.user_email,\n-        func.count(PlatformAuditLog.id).label('count')\n-    ).filter(\n-        PlatformAuditLog.created_at >= cutoff_date\n-    ).group_by(\n-        PlatformAuditLog.user_email\n-    ).order_by(\n-        func.count(PlatformAuditLog.id).desc()\n-    ).limit(10).all()\n-    \n+    actions_by_user = (\n+        db.query(\n+            PlatformAuditLog.user_email, func.count(PlatformAuditLog.id).label(\"count\")\n+        )\n+        .filter(PlatformAuditLog.created_at >= cutoff_date)\n+        .group_by(PlatformAuditLog.user_email)\n+        .order_by(func.count(PlatformAuditLog.id).desc())\n+        .limit(10)\n+        .all()\n+    )\n+\n     # Actions by resource type\n-    actions_by_resource = db.query(\n-        PlatformAuditLog.resource_type,\n-        func.count(PlatformAuditLog.id).label('count')\n-    ).filter(\n-        PlatformAuditLog.created_at >= cutoff_date\n-    ).group_by(\n-        PlatformAuditLog.resource_type\n-    ).all()\n-    \n+    actions_by_resource = (\n+        db.query(\n+            PlatformAuditLog.resource_type,\n+            func.count(PlatformAuditLog.id).label(\"count\"),\n+        )\n+        .filter(PlatformAuditLog.created_at >= cutoff_date)\n+        .group_by(PlatformAuditLog.resource_type)\n+        .all()\n+    )\n+\n     return {\n         \"period_days\": days,\n-        \"total_actions\": db.query(PlatformAuditLog).filter(\n-            PlatformAuditLog.created_at >= cutoff_date\n-        ).count(),\n+        \"total_actions\": db.query(PlatformAuditLog)\n+        .filter(PlatformAuditLog.created_at >= cutoff_date)\n+        .count(),\n         \"actions_by_type\": {action: count for action, count in actions_by_type},\n         \"top_users\": [\n-            {\"email\": email, \"action_count\": count}\n-            for email, count in actions_by_user\n+            {\"email\": email, \"action_count\": count} for email, count in actions_by_user\n         ],\n-        \"actions_by_resource\": {resource: count for resource, count in actions_by_resource}\n-    }\n\\ No newline at end of file\n+        \"actions_by_resource\": {\n+            resource: count for resource, count in actions_by_resource\n+        },\n+    }\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/schemas/restaurant.py\t2025-08-02 21:56:59.000712+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/schemas/restaurant.py\t2025-08-02 22:36:03.776448+00:00\n@@ -7,10 +7,11 @@\n from pydantic import BaseModel, EmailStr\n \n \n class RestaurantBase(BaseModel):\n     \"\"\"Base restaurant schema\"\"\"\n+\n     name: str\n     address: dict\n     phone: Optional[str] = None\n     email: Optional[EmailStr] = None\n     timezone: str = \"UTC\"\n@@ -18,15 +19,17 @@\n     settings: dict = {}\n \n \n class RestaurantCreate(RestaurantBase):\n     \"\"\"Schema for creating a restaurant\"\"\"\n+\n     pass\n \n \n class RestaurantOnboardingCreate(BaseModel):\n     \"\"\"Extended schema for restaurant onboarding with additional fields\"\"\"\n+\n     name: str\n     display_name: str\n     business_type: str\n     description: Optional[str] = None\n     phone: str\n@@ -39,10 +42,11 @@\n     bank_details: Optional[dict] = None\n \n \n class RestaurantUpdate(BaseModel):\n     \"\"\"Schema for updating a restaurant\"\"\"\n+\n     name: Optional[str] = None\n     address: Optional[dict] = None\n     phone: Optional[str] = None\n     email: Optional[EmailStr] = None\n     timezone: Optional[str] = None\n@@ -53,10 +57,11 @@\n     is_active: Optional[bool] = None\n \n \n class RestaurantResponse(RestaurantBase):\n     \"\"\"Schema for restaurant responses\"\"\"\n+\n     id: str\n     platform_id: Optional[str]\n     tax_configuration: dict\n     payment_methods: dict\n     is_active: bool\n@@ -67,10 +72,11 @@\n         from_attributes = True\n \n \n class RestaurantStats(BaseModel):\n     \"\"\"Restaurant statistics schema\"\"\"\n+\n     restaurant_id: str\n     name: str\n     daily_revenue: float\n     monthly_revenue: float\n     total_orders: int\n@@ -79,11 +85,12 @@\n     payment_method_breakdown: dict\n \n \n class PlatformStats(BaseModel):\n     \"\"\"Platform statistics schema\"\"\"\n+\n     total_restaurants: int\n     active_restaurants: int\n     total_revenue: float\n     total_orders: int\n     total_customers: int\n-    top_performing_restaurants: List[RestaurantStats]\n\\ No newline at end of file\n+    top_performing_restaurants: List[RestaurantStats]\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/schemas/websocket.py\t2025-08-02 19:23:36.828344+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/schemas/websocket.py\t2025-08-02 22:36:03.788857+00:00\n@@ -8,76 +8,80 @@\n from enum import Enum\n \n \n class WebSocketEventType(str, Enum):\n     \"\"\"WebSocket event types matching shared TypeScript definitions\"\"\"\n+\n     # Connection\n-    CONNECT = 'connect'\n-    DISCONNECT = 'disconnect'\n-    AUTHENTICATE = 'authenticate'\n-    AUTHENTICATED = 'authenticated'\n-    AUTH_ERROR = 'auth_error'\n-    \n+    CONNECT = \"connect\"\n+    DISCONNECT = \"disconnect\"\n+    AUTHENTICATE = \"authenticate\"\n+    AUTHENTICATED = \"authenticated\"\n+    AUTH_ERROR = \"auth_error\"\n+\n     # System\n-    PING = 'ping'\n-    PONG = 'pong'\n-    ERROR = 'error'\n-    HEARTBEAT = 'heartbeat'\n-    RECONNECT = 'reconnect'\n-    \n+    PING = \"ping\"\n+    PONG = \"pong\"\n+    ERROR = \"error\"\n+    HEARTBEAT = \"heartbeat\"\n+    RECONNECT = \"reconnect\"\n+\n     # Orders\n-    ORDER_CREATED = 'order.created'\n-    ORDER_UPDATED = 'order.updated'\n-    ORDER_STATUS_CHANGED = 'order.status_changed'\n-    ORDER_ITEM_STATUS_CHANGED = 'order.item_status_changed'\n-    ORDER_CANCELLED = 'order.cancelled'\n-    ORDER_COMPLETED = 'order.completed'\n-    \n+    ORDER_CREATED = \"order.created\"\n+    ORDER_UPDATED = \"order.updated\"\n+    ORDER_STATUS_CHANGED = \"order.status_changed\"\n+    ORDER_ITEM_STATUS_CHANGED = \"order.item_status_changed\"\n+    ORDER_CANCELLED = \"order.cancelled\"\n+    ORDER_COMPLETED = \"order.completed\"\n+\n     # Payments\n-    PAYMENT_INITIATED = 'payment.initiated'\n-    PAYMENT_PROCESSING = 'payment.processing'\n-    PAYMENT_COMPLETED = 'payment.completed'\n-    PAYMENT_FAILED = 'payment.failed'\n-    PAYMENT_REFUNDED = 'payment.refunded'\n-    \n+    PAYMENT_INITIATED = \"payment.initiated\"\n+    PAYMENT_PROCESSING = \"payment.processing\"\n+    PAYMENT_COMPLETED = \"payment.completed\"\n+    PAYMENT_FAILED = \"payment.failed\"\n+    PAYMENT_REFUNDED = \"payment.refunded\"\n+\n     # Kitchen\n-    KITCHEN_ORDER_RECEIVED = 'kitchen.order_received'\n-    KITCHEN_ITEM_STARTED = 'kitchen.item_started'\n-    KITCHEN_ITEM_READY = 'kitchen.item_ready'\n-    KITCHEN_ORDER_READY = 'kitchen.order_ready'\n-    \n+    KITCHEN_ORDER_RECEIVED = \"kitchen.order_received\"\n+    KITCHEN_ITEM_STARTED = \"kitchen.item_started\"\n+    KITCHEN_ITEM_READY = \"kitchen.item_ready\"\n+    KITCHEN_ORDER_READY = \"kitchen.order_ready\"\n+\n     # Inventory\n-    INVENTORY_LOW_STOCK = 'inventory.low_stock'\n-    INVENTORY_OUT_OF_STOCK = 'inventory.out_of_stock'\n-    INVENTORY_UPDATED = 'inventory.updated'\n-    \n+    INVENTORY_LOW_STOCK = \"inventory.low_stock\"\n+    INVENTORY_OUT_OF_STOCK = \"inventory.out_of_stock\"\n+    INVENTORY_UPDATED = \"inventory.updated\"\n+\n     # Staff\n-    STAFF_CLOCKED_IN = 'staff.clocked_in'\n-    STAFF_CLOCKED_OUT = 'staff.clocked_out'\n-    STAFF_BREAK_STARTED = 'staff.break_started'\n-    STAFF_BREAK_ENDED = 'staff.break_ended'\n-    \n+    STAFF_CLOCKED_IN = \"staff.clocked_in\"\n+    STAFF_CLOCKED_OUT = \"staff.clocked_out\"\n+    STAFF_BREAK_STARTED = \"staff.break_started\"\n+    STAFF_BREAK_ENDED = \"staff.break_ended\"\n+\n     # Tables\n-    TABLE_OCCUPIED = 'table.occupied'\n-    TABLE_AVAILABLE = 'table.available'\n-    TABLE_RESERVED = 'table.reserved'\n-    TABLE_CLEANED = 'table.cleaned'\n-    \n+    TABLE_OCCUPIED = \"table.occupied\"\n+    TABLE_AVAILABLE = \"table.available\"\n+    TABLE_RESERVED = \"table.reserved\"\n+    TABLE_CLEANED = \"table.cleaned\"\n+\n     # Sync\n-    SYNC_STARTED = 'sync.started'\n-    SYNC_COMPLETED = 'sync.completed'\n-    SYNC_FAILED = 'sync.failed'\n-    DATA_UPDATED = 'data.updated'\n+    SYNC_STARTED = \"sync.started\"\n+    SYNC_COMPLETED = \"sync.completed\"\n+    SYNC_FAILED = \"sync.failed\"\n+    DATA_UPDATED = \"data.updated\"\n \n \n class WebSocketMessage(BaseModel):\n     \"\"\"WebSocket message structure matching shared TypeScript definition\"\"\"\n+\n     id: str = Field(..., description=\"Unique message ID\")\n     type: WebSocketEventType = Field(..., description=\"Event type\")\n     data: Optional[Dict[str, Any]] = Field(default=None, description=\"Message payload\")\n     restaurant_id: str = Field(..., description=\"Restaurant ID\")\n     timestamp: str = Field(default_factory=lambda: datetime.utcnow().isoformat())\n     user_id: Optional[str] = Field(default=None, description=\"User ID if applicable\")\n-    token: Optional[str] = Field(default=None, description=\"Auth token for authentication messages\")\n+    token: Optional[str] = Field(\n+        default=None, description=\"Auth token for authentication messages\"\n+    )\n \n     class Config:\n-        use_enum_values = True\n\\ No newline at end of file\n+        use_enum_values = True\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/audit_logger.py\t2025-08-02 19:23:36.829276+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/audit_logger.py\t2025-08-02 22:36:03.800083+00:00\n@@ -4,14 +4,17 @@\n \n from sqlalchemy.orm import Session\n from sqlalchemy.exc import SQLAlchemyError\n \n from app.models.audit_log import AuditLog, AuditEventType, AuditEventStatus\n-from app.core.database import get_db  # To be used as a dependency if service is injected\n+from app.core.database import (\n+    get_db,\n+)  # To be used as a dependency if service is injected\n \n # Standard logger for issues within the audit logger itself\n logger = logging.getLogger(__name__)\n+\n \n class AuditLoggerService:\n     def __init__(self, db: Session):\n         self.db = db\n \n@@ -26,11 +29,11 @@\n         user_agent: Optional[str] = None,\n         resource_type: Optional[str] = None,\n         resource_id: Optional[str] = None,\n         details: Optional[Dict[str, Any]] = None,\n         risk_score: Optional[int] = None,\n-        commit: bool = True  # Option to control commit, useful if called within a larger transaction\n+        commit: bool = True,  # Option to control commit, useful if called within a larger transaction\n     ) -> Optional[AuditLog]:\n         \"\"\"\n         Creates and saves an audit log entry.\n \n         Args:\n@@ -56,16 +59,16 @@\n                 event_type=event_type,\n                 event_status=event_status,\n                 action_performed=action_performed,\n                 user_id=user_id,\n                 username_or_email=username_or_email,\n-                ip_address=ip_address, # SQLAlchemy handles INET conversion\n+                ip_address=ip_address,  # SQLAlchemy handles INET conversion\n                 user_agent=user_agent,\n                 resource_type=resource_type,\n                 resource_id=resource_id,\n                 details=details,\n-                risk_score=risk_score\n+                risk_score=risk_score,\n             )\n             self.db.add(audit_log_entry)\n \n             if commit:\n                 self.db.commit()\n@@ -76,24 +79,31 @@\n                 self.db.flush()\n                 # Note: refresh might not work as expected without commit in some scenarios,\n                 # but for defaults like UUID and server_default timestamp, flush is often enough.\n                 # If refresh is critical, the caller must handle it post-commit.\n \n-            logger.debug(f\"Audit log created: {event_type.value} for user {user_id or username_or_email}\")\n+            logger.debug(\n+                f\"Audit log created: {event_type.value} for user {user_id or username_or_email}\"\n+            )\n             return audit_log_entry\n         except SQLAlchemyError as e:\n             logger.error(f\"Failed to save audit log: {e}\", exc_info=True)\n             try:\n-                self.db.rollback() # Rollback on error if we were supposed to commit\n+                self.db.rollback()  # Rollback on error if we were supposed to commit\n             except Exception as rb_exc:\n-                logger.error(f\"Failed to rollback audit log session: {rb_exc}\", exc_info=True)\n+                logger.error(\n+                    f\"Failed to rollback audit log session: {rb_exc}\", exc_info=True\n+                )\n             return None\n         except Exception as e:\n             # Catch any other unexpected errors\n-            logger.error(f\"Unexpected error during audit log creation: {e}\", exc_info=True)\n+            logger.error(\n+                f\"Unexpected error during audit log creation: {e}\", exc_info=True\n+            )\n             # We don't rollback here as the state of db session is unknown for non-SQLAlchemy errors\n             return None\n+\n \n # --- Helper function to get the service with a DB session ---\n # This is a common pattern in FastAPI for dependency injection.\n # However, since this service might be called from various places,\n # direct instantiation with a passed DB session is also fine.\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models/subscription.py\t2025-08-01 19:20:39.075951+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models/subscription.py\t2025-08-02 22:36:03.800308+00:00\n@@ -3,11 +3,20 @@\n \n This module contains SQLAlchemy models for managing subscription plans,\n restaurant subscriptions, and usage tracking.\n \"\"\"\n \n-from sqlalchemy import Column, Integer, String, DECIMAL, Boolean, TIMESTAMP, ForeignKey, UniqueConstraint\n+from sqlalchemy import (\n+    Column,\n+    Integer,\n+    String,\n+    DECIMAL,\n+    Boolean,\n+    TIMESTAMP,\n+    ForeignKey,\n+    UniqueConstraint,\n+)\n from sqlalchemy.dialects.postgresql import JSONB\n from sqlalchemy.orm import relationship\n from sqlalchemy.sql import func\n from datetime import datetime\n \n@@ -15,31 +24,36 @@\n \n \n class SubscriptionPlan(Base):\n     \"\"\"\n     Subscription plans available to restaurants\n-    \n+\n     Defines the different pricing tiers with their features and limits.\n     \"\"\"\n+\n     __tablename__ = \"subscription_plans\"\n \n     id = Column(Integer, primary_key=True, autoincrement=True)\n     name = Column(String(50), unique=True, nullable=False, index=True)\n     display_name = Column(String(100), nullable=False)\n     price_monthly = Column(DECIMAL(10, 2), nullable=False)\n     price_yearly = Column(DECIMAL(10, 2), nullable=False)\n-    transaction_fee_percentage = Column(DECIMAL(5, 2), nullable=False, default=1.0)  # Transaction fee %\n+    transaction_fee_percentage = Column(\n+        DECIMAL(5, 2), nullable=False, default=1.0\n+    )  # Transaction fee %\n     max_orders_per_month = Column(Integer, nullable=True)  # None = unlimited\n-    max_staff_accounts = Column(Integer, nullable=True)    # None = unlimited\n-    max_menu_items = Column(Integer, nullable=True)        # None = unlimited\n+    max_staff_accounts = Column(Integer, nullable=True)  # None = unlimited\n+    max_menu_items = Column(Integer, nullable=True)  # None = unlimited\n     features = Column(JSONB, nullable=False)  # Feature flags and capabilities\n     is_active = Column(Boolean, default=True)\n     created_at = Column(TIMESTAMP, server_default=func.now())\n     updated_at = Column(TIMESTAMP, server_default=func.now(), onupdate=func.now())\n \n     # Relationships\n-    restaurant_subscriptions = relationship(\"RestaurantSubscription\", back_populates=\"plan\")\n+    restaurant_subscriptions = relationship(\n+        \"RestaurantSubscription\", back_populates=\"plan\"\n+    )\n \n     def __repr__(self):\n         return f\"<SubscriptionPlan(name='{self.name}', display_name='{self.display_name}')>\"\n \n     def has_feature(self, feature_name: str) -> bool:\n@@ -47,13 +61,13 @@\n         return self.features.get(feature_name, False)\n \n     def is_unlimited(self, limit_type: str) -> bool:\n         \"\"\"Check if a limit is unlimited (None) for this plan\"\"\"\n         limit_map = {\n-            'orders': self.max_orders_per_month,\n-            'staff': self.max_staff_accounts,\n-            'menu_items': self.max_menu_items\n+            \"orders\": self.max_orders_per_month,\n+            \"staff\": self.max_staff_accounts,\n+            \"menu_items\": self.max_menu_items,\n         }\n         return limit_map.get(limit_type) is None\n \n     def get_yearly_savings(self) -> float:\n         \"\"\"Calculate yearly savings compared to monthly billing\"\"\"\n@@ -71,20 +85,29 @@\n \n \n class RestaurantSubscription(Base):\n     \"\"\"\n     Individual restaurant subscriptions\n-    \n+\n     Links restaurants to their current subscription plans and tracks\n     billing information and subscription status.\n     \"\"\"\n+\n     __tablename__ = \"restaurant_subscriptions\"\n \n     id = Column(Integer, primary_key=True, autoincrement=True)\n-    restaurant_id = Column(Integer, nullable=False, index=True)  # FK to restaurants table\n-    plan_id = Column(Integer, ForeignKey(\"subscription_plans.id\", ondelete=\"RESTRICT\"), nullable=False)\n-    status = Column(String(20), nullable=False, index=True)  # active, trial, suspended, cancelled\n+    restaurant_id = Column(\n+        Integer, nullable=False, index=True\n+    )  # FK to restaurants table\n+    plan_id = Column(\n+        Integer,\n+        ForeignKey(\"subscription_plans.id\", ondelete=\"RESTRICT\"),\n+        nullable=False,\n+    )\n+    status = Column(\n+        String(20), nullable=False, index=True\n+    )  # active, trial, suspended, cancelled\n     trial_end_date = Column(TIMESTAMP, nullable=True)\n     current_period_start = Column(TIMESTAMP, nullable=False)\n     current_period_end = Column(TIMESTAMP, nullable=False)\n     stripe_subscription_id = Column(String(255), nullable=True, unique=True)\n     stripe_customer_id = Column(String(255), nullable=True)\n@@ -98,16 +121,16 @@\n         return f\"<RestaurantSubscription(restaurant_id={self.restaurant_id}, plan='{self.plan.name}', status='{self.status}')>\"\n \n     @property\n     def is_active(self) -> bool:\n         \"\"\"Check if subscription is currently active\"\"\"\n-        return self.status in ['active', 'trial']\n+        return self.status in [\"active\", \"trial\"]\n \n     @property\n     def is_trial(self) -> bool:\n         \"\"\"Check if subscription is in trial period\"\"\"\n-        return self.status == 'trial'\n+        return self.status == \"trial\"\n \n     @property\n     def is_expired(self) -> bool:\n         \"\"\"Check if subscription period has expired\"\"\"\n         return datetime.utcnow() > self.current_period_end\n@@ -126,15 +149,15 @@\n \n     def get_limit(self, limit_type: str) -> int | None:\n         \"\"\"Get the limit for a specific resource type\"\"\"\n         if not self.is_active:\n             return 0\n-            \n+\n         limit_map = {\n-            'orders': self.plan.max_orders_per_month,\n-            'staff': self.plan.max_staff_accounts,\n-            'menu_items': self.plan.max_menu_items\n+            \"orders\": self.plan.max_orders_per_month,\n+            \"staff\": self.plan.max_staff_accounts,\n+            \"menu_items\": self.plan.max_menu_items,\n         }\n         return limit_map.get(limit_type)\n \n     def is_at_limit(self, limit_type: str, current_usage: int) -> bool:\n         \"\"\"Check if current usage has reached the plan limit\"\"\"\n@@ -145,17 +168,18 @@\n \n \n class SubscriptionUsage(Base):\n     \"\"\"\n     Monthly usage tracking for restaurants\n-    \n+\n     Tracks resource usage (orders, staff, menu items) by month\n     to enforce subscription limits and provide analytics.\n     \"\"\"\n+\n     __tablename__ = \"subscription_usage\"\n     __table_args__ = (\n-        UniqueConstraint('restaurant_id', 'month_year', name='unique_restaurant_month'),\n+        UniqueConstraint(\"restaurant_id\", \"month_year\", name=\"unique_restaurant_month\"),\n     )\n \n     id = Column(Integer, primary_key=True, autoincrement=True)\n     restaurant_id = Column(Integer, nullable=False)  # FK to restaurants table\n     month_year = Column(String(7), nullable=False)  # Format: \"2025-01\"\n@@ -175,39 +199,39 @@\n \n     def get_usage_percentage(self, limit_type: str, plan_limit: int | None) -> float:\n         \"\"\"Calculate usage percentage for a specific limit\"\"\"\n         if plan_limit is None:  # Unlimited\n             return 0.0\n-            \n+\n         usage_map = {\n-            'orders': self.orders_count,\n-            'staff': self.staff_count,\n-            'menu_items': self.menu_items_count\n-        }\n-        \n+            \"orders\": self.orders_count,\n+            \"staff\": self.staff_count,\n+            \"menu_items\": self.menu_items_count,\n+        }\n+\n         current_usage = usage_map.get(limit_type, 0)\n         if plan_limit > 0:\n             return min(100.0, (current_usage / plan_limit) * 100)\n         return 0.0\n \n     def is_over_limit(self, limit_type: str, plan_limit: int | None) -> bool:\n         \"\"\"Check if usage exceeds the plan limit\"\"\"\n         if plan_limit is None:  # Unlimited\n             return False\n-            \n+\n         usage_map = {\n-            'orders': self.orders_count,\n-            'staff': self.staff_count,\n-            'menu_items': self.menu_items_count\n-        }\n-        \n+            \"orders\": self.orders_count,\n+            \"staff\": self.staff_count,\n+            \"menu_items\": self.menu_items_count,\n+        }\n+\n         current_usage = usage_map.get(limit_type, 0)\n         return current_usage > plan_limit\n \n     def increment_usage(self, usage_type: str, amount: int = 1) -> None:\n         \"\"\"Increment usage for a specific type\"\"\"\n-        if usage_type == 'orders':\n+        if usage_type == \"orders\":\n             self.orders_count += amount\n-        elif usage_type == 'staff':\n+        elif usage_type == \"staff\":\n             self.staff_count += amount\n-        elif usage_type == 'menu_items':\n-            self.menu_items_count += amount\n\\ No newline at end of file\n+        elif usage_type == \"menu_items\":\n+            self.menu_items_count += amount\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/cache_service.py\t2025-08-02 21:56:59.002299+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/cache_service.py\t2025-08-02 22:36:03.808723+00:00\n@@ -1,80 +1,80 @@\n \"\"\"\n Cache Service for Platform Settings\n Provides fast access to frequently requested configuration\n \"\"\"\n+\n import json\n import logging\n from typing import Dict, Any, Optional\n from datetime import datetime, timedelta\n \n from app.core.redis_client import get_redis\n from app.core.config import settings\n \n logger = logging.getLogger(__name__)\n \n+\n class PlatformCacheService:\n     \"\"\"Service for caching platform configuration\"\"\"\n-    \n+\n     CACHE_PREFIX = \"platform:config:\"\n     DEFAULT_TTL = 300  # 5 minutes\n-    \n+\n     @staticmethod\n     def get_cache_key(key: str) -> str:\n         \"\"\"Generate cache key with prefix\"\"\"\n         return f\"{PlatformCacheService.CACHE_PREFIX}{key}\"\n-    \n+\n     @staticmethod\n     async def get_service_charge_config() -> Optional[Dict[str, Any]]:\n         \"\"\"Get service charge configuration from cache\"\"\"\n         try:\n             redis = await get_redis()\n             if not redis:\n                 return None\n-                \n+\n             cache_key = PlatformCacheService.get_cache_key(\"service_charge\")\n             cached_data = await redis.get(cache_key)\n-            \n+\n             if cached_data:\n                 return json.loads(cached_data)\n-                \n+\n             return None\n-            \n+\n         except Exception as e:\n             logger.warning(f\"Cache read failed: {e}\")\n             return None\n-    \n+\n     @staticmethod\n-    async def set_service_charge_config(config: Dict[str, Any], ttl: int = DEFAULT_TTL) -> bool:\n+    async def set_service_charge_config(\n+        config: Dict[str, Any], ttl: int = DEFAULT_TTL\n+    ) -> bool:\n         \"\"\"Set service charge configuration in cache\"\"\"\n         try:\n             redis = await get_redis()\n             if not redis:\n                 return False\n-                \n+\n             cache_key = PlatformCacheService.get_cache_key(\"service_charge\")\n-            await redis.setex(\n-                cache_key,\n-                ttl,\n-                json.dumps(config)\n-            )\n+            await redis.setex(cache_key, ttl, json.dumps(config))\n             return True\n-            \n+\n         except Exception as e:\n             logger.warning(f\"Cache write failed: {e}\")\n             return False\n-    \n+\n     @staticmethod\n     async def invalidate_service_charge_config() -> bool:\n         \"\"\"Invalidate service charge configuration cache\"\"\"\n         try:\n             redis = await get_redis()\n             if not redis:\n                 return False\n-                \n+\n             cache_key = PlatformCacheService.get_cache_key(\"service_charge\")\n             await redis.delete(cache_key)\n             return True\n-            \n+\n         except Exception as e:\n             logger.warning(f\"Cache invalidation failed: {e}\")\n-            return False\n\\ No newline at end of file\n+            return False\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models/platform_config.py\t2025-08-01 23:08:38.310608+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models/platform_config.py\t2025-08-02 22:36:03.810884+00:00\n@@ -7,15 +7,17 @@\n from sqlalchemy.dialects.postgresql import UUID\n from sqlalchemy.sql import func\n import uuid\n from app.core.database import Base\n \n+\n class PlatformConfiguration(Base):\n     \"\"\"\n     Platform-wide configuration settings controlled by Fynlo\n     These settings are read-only for restaurants\n     \"\"\"\n+\n     __tablename__ = \"platform_configurations\"\n \n     id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n     config_key = Column(String(255), unique=True, nullable=False, index=True)\n     config_value = Column(JSON, nullable=False)\n@@ -23,27 +25,31 @@\n     description = Column(Text)\n     is_sensitive = Column(Boolean, default=False)\n     validation_schema = Column(JSON)  # JSON schema for validation\n     is_active = Column(Boolean, default=True)\n     created_at = Column(DateTime(timezone=True), server_default=func.now())\n-    updated_at = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now())\n+    updated_at = Column(\n+        DateTime(timezone=True), server_default=func.now(), onupdate=func.now()\n+    )\n     updated_by = Column(UUID(as_uuid=True))  # Admin user who made the change\n \n     # Create indexes for performance\n     __table_args__ = (\n-        Index('idx_platform_config_category_active', 'category', 'is_active'),\n-        Index('idx_platform_config_key_active', 'config_key', 'is_active'),\n+        Index(\"idx_platform_config_category_active\", \"category\", \"is_active\"),\n+        Index(\"idx_platform_config_key_active\", \"config_key\", \"is_active\"),\n     )\n \n     def __repr__(self):\n         return f\"<PlatformConfiguration(key='{self.config_key}', category='{self.category}')>\"\n \n+\n class RestaurantOverride(Base):\n     \"\"\"\n     Restaurant-specific overrides of platform settings (where allowed)\n     These must comply with platform limits and validation rules\n     \"\"\"\n+\n     __tablename__ = \"restaurant_overrides\"\n \n     id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n     restaurant_id = Column(UUID(as_uuid=True), nullable=False, index=True)\n     config_key = Column(String(255), nullable=False)\n@@ -51,27 +57,33 @@\n     platform_limit = Column(JSON)  # The platform-defined limits for this override\n     is_approved = Column(Boolean, default=True)  # For overrides requiring approval\n     approved_by = Column(UUID(as_uuid=True))  # Admin who approved\n     approved_at = Column(DateTime(timezone=True))\n     created_at = Column(DateTime(timezone=True), server_default=func.now())\n-    updated_at = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now())\n+    updated_at = Column(\n+        DateTime(timezone=True), server_default=func.now(), onupdate=func.now()\n+    )\n     created_by = Column(UUID(as_uuid=True))  # Restaurant user who created override\n \n     # Ensure unique overrides per restaurant per setting\n     __table_args__ = (\n-        Index('idx_restaurant_override_unique', 'restaurant_id', 'config_key', unique=True),\n-        Index('idx_restaurant_override_approval', 'is_approved', 'approved_at'),\n+        Index(\n+            \"idx_restaurant_override_unique\", \"restaurant_id\", \"config_key\", unique=True\n+        ),\n+        Index(\"idx_restaurant_override_approval\", \"is_approved\", \"approved_at\"),\n     )\n \n     def __repr__(self):\n         return f\"<RestaurantOverride(restaurant_id='{self.restaurant_id}', key='{self.config_key}')>\"\n \n+\n class ConfigurationAudit(Base):\n     \"\"\"\n     Audit trail for all configuration changes\n     Tracks who changed what and when for compliance\n     \"\"\"\n+\n     __tablename__ = \"configuration_audit\"\n \n     id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n     config_type = Column(String(50), nullable=False)  # 'platform' or 'restaurant'\n     config_key = Column(String(255), nullable=False)\n@@ -85,242 +97,264 @@\n     ip_address = Column(String(45))  # IPv4 or IPv6\n     user_agent = Column(Text)\n \n     # Indexes for audit queries\n     __table_args__ = (\n-        Index('idx_config_audit_type_key', 'config_type', 'config_key'),\n-        Index('idx_config_audit_entity', 'entity_id', 'changed_at'),\n-        Index('idx_config_audit_user_time', 'changed_by', 'changed_at'),\n+        Index(\"idx_config_audit_type_key\", \"config_type\", \"config_key\"),\n+        Index(\"idx_config_audit_entity\", \"entity_id\", \"changed_at\"),\n+        Index(\"idx_config_audit_user_time\", \"changed_by\", \"changed_at\"),\n     )\n \n     def __repr__(self):\n         return f\"<ConfigurationAudit(type='{self.config_type}', key='{self.config_key}', at='{self.changed_at}')>\"\n \n+\n class PlatformFeatureFlag(Base):\n     \"\"\"\n     Feature flags controlled at platform level\n     Allows enabling/disabling features across restaurants\n     \"\"\"\n+\n     __tablename__ = \"platform_feature_flags\"\n \n     id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n     feature_key = Column(String(255), unique=True, nullable=False, index=True)\n     is_enabled = Column(Boolean, default=False)\n     rollout_percentage = Column(Numeric(5, 2), default=0.0)  # 0.00 to 100.00\n     target_restaurants = Column(JSON)  # Array of restaurant IDs for targeted rollout\n     description = Column(Text)\n     feature_category = Column(String(100))  # 'payment', 'analytics', 'ui', etc.\n     created_at = Column(DateTime(timezone=True), server_default=func.now())\n-    updated_at = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now())\n+    updated_at = Column(\n+        DateTime(timezone=True), server_default=func.now(), onupdate=func.now()\n+    )\n     created_by = Column(UUID(as_uuid=True))\n \n     def __repr__(self):\n         return f\"<PlatformFeatureFlag(feature='{self.feature_key}', enabled={self.is_enabled})>\"\n+\n \n # Default platform configurations\n DEFAULT_PLATFORM_CONFIGS = [\n     # Payment Processing Fees\n     {\n-        'config_key': 'payment.fees.qr_code',\n-        'config_value': {'percentage': 1.2, 'fixed_fee': 0.0, 'currency': 'GBP'},\n-        'category': 'payment_fees',\n-        'description': 'QR code payment processing fee - Fynlo competitive advantage',\n-        'is_sensitive': False,\n-        'validation_schema': {\n-            'type': 'object',\n-            'properties': {\n-                'percentage': {'type': 'number', 'minimum': 0, 'maximum': 10},\n-                'fixed_fee': {'type': 'number', 'minimum': 0},\n-                'currency': {'type': 'string', 'enum': ['GBP', 'EUR', 'USD']}\n+        \"config_key\": \"payment.fees.qr_code\",\n+        \"config_value\": {\"percentage\": 1.2, \"fixed_fee\": 0.0, \"currency\": \"GBP\"},\n+        \"category\": \"payment_fees\",\n+        \"description\": \"QR code payment processing fee - Fynlo competitive advantage\",\n+        \"is_sensitive\": False,\n+        \"validation_schema\": {\n+            \"type\": \"object\",\n+            \"properties\": {\n+                \"percentage\": {\"type\": \"number\", \"minimum\": 0, \"maximum\": 10},\n+                \"fixed_fee\": {\"type\": \"number\", \"minimum\": 0},\n+                \"currency\": {\"type\": \"string\", \"enum\": [\"GBP\", \"EUR\", \"USD\"]},\n             },\n-            'required': ['percentage', 'fixed_fee', 'currency']\n-        }\n-    },\n-    {\n-        'config_key': 'payment.fees.stripe',\n-        'config_value': {'percentage': 1.4, 'fixed_fee': 0.20, 'currency': 'GBP'},\n-        'category': 'payment_fees',\n-        'description': 'Stripe payment processing fee',\n-        'is_sensitive': False,\n-        'validation_schema': {\n-            'type': 'object',\n-            'properties': {\n-                'percentage': {'type': 'number', 'minimum': 0, 'maximum': 10},\n-                'fixed_fee': {'type': 'number', 'minimum': 0},\n-                'currency': {'type': 'string', 'enum': ['GBP', 'EUR', 'USD']}\n+            \"required\": [\"percentage\", \"fixed_fee\", \"currency\"],\n+        },\n+    },\n+    {\n+        \"config_key\": \"payment.fees.stripe\",\n+        \"config_value\": {\"percentage\": 1.4, \"fixed_fee\": 0.20, \"currency\": \"GBP\"},\n+        \"category\": \"payment_fees\",\n+        \"description\": \"Stripe payment processing fee\",\n+        \"is_sensitive\": False,\n+        \"validation_schema\": {\n+            \"type\": \"object\",\n+            \"properties\": {\n+                \"percentage\": {\"type\": \"number\", \"minimum\": 0, \"maximum\": 10},\n+                \"fixed_fee\": {\"type\": \"number\", \"minimum\": 0},\n+                \"currency\": {\"type\": \"string\", \"enum\": [\"GBP\", \"EUR\", \"USD\"]},\n             },\n-            'required': ['percentage', 'fixed_fee', 'currency']\n-        }\n-    },\n-    {\n-        'config_key': 'payment.fees.square',\n-        'config_value': {'percentage': 1.75, 'fixed_fee': 0.0, 'currency': 'GBP'},\n-        'category': 'payment_fees',\n-        'description': 'Square payment processing fee',\n-        'is_sensitive': False,\n-    },\n-    {\n-        'config_key': 'payment.fees.sumup',\n-        'config_value': {\n-            'high_volume': {'percentage': 0.69, 'monthly_fee': 19.0, 'threshold': 2714.0},\n-            'standard': {'percentage': 1.69, 'monthly_fee': 0.0},\n-            'currency': 'GBP'\n-        },\n-        'category': 'payment_fees',\n-        'description': 'SumUp payment processing fees with volume tiers',\n-        'is_sensitive': False,\n-    },\n-    {\n-        'config_key': 'payment.fees.cash',\n-        'config_value': {'percentage': 0.0, 'fixed_fee': 0.0, 'currency': 'GBP'},\n-        'category': 'payment_fees',\n-        'description': 'Cash payment processing (no fees)',\n-        'is_sensitive': False,\n-    },\n-    \n+            \"required\": [\"percentage\", \"fixed_fee\", \"currency\"],\n+        },\n+    },\n+    {\n+        \"config_key\": \"payment.fees.square\",\n+        \"config_value\": {\"percentage\": 1.75, \"fixed_fee\": 0.0, \"currency\": \"GBP\"},\n+        \"category\": \"payment_fees\",\n+        \"description\": \"Square payment processing fee\",\n+        \"is_sensitive\": False,\n+    },\n+    {\n+        \"config_key\": \"payment.fees.sumup\",\n+        \"config_value\": {\n+            \"high_volume\": {\n+                \"percentage\": 0.69,\n+                \"monthly_fee\": 19.0,\n+                \"threshold\": 2714.0,\n+            },\n+            \"standard\": {\"percentage\": 1.69, \"monthly_fee\": 0.0},\n+            \"currency\": \"GBP\",\n+        },\n+        \"category\": \"payment_fees\",\n+        \"description\": \"SumUp payment processing fees with volume tiers\",\n+        \"is_sensitive\": False,\n+    },\n+    {\n+        \"config_key\": \"payment.fees.cash\",\n+        \"config_value\": {\"percentage\": 0.0, \"fixed_fee\": 0.0, \"currency\": \"GBP\"},\n+        \"category\": \"payment_fees\",\n+        \"description\": \"Cash payment processing (no fees)\",\n+        \"is_sensitive\": False,\n+    },\n     # Transaction Limits\n     {\n-        'config_key': 'payment.limits.minimum_transaction',\n-        'config_value': {'amount': 0.01, 'currency': 'GBP'},\n-        'category': 'payment_limits',\n-        'description': 'Minimum transaction amount across all payment methods',\n-    },\n-    {\n-        'config_key': 'payment.limits.maximum_transaction',\n-        'config_value': {'amount': 50000.0, 'currency': 'GBP'},\n-        'category': 'payment_limits',\n-        'description': 'Maximum transaction amount across all payment methods',\n-    },\n-    {\n-        'config_key': 'payment.limits.daily_limit',\n-        'config_value': {'amount': 100000.0, 'currency': 'GBP'},\n-        'category': 'payment_limits',\n-        'description': 'Daily transaction limit per restaurant',\n-    },\n-\n+        \"config_key\": \"payment.limits.minimum_transaction\",\n+        \"config_value\": {\"amount\": 0.01, \"currency\": \"GBP\"},\n+        \"category\": \"payment_limits\",\n+        \"description\": \"Minimum transaction amount across all payment methods\",\n+    },\n+    {\n+        \"config_key\": \"payment.limits.maximum_transaction\",\n+        \"config_value\": {\"amount\": 50000.0, \"currency\": \"GBP\"},\n+        \"category\": \"payment_limits\",\n+        \"description\": \"Maximum transaction amount across all payment methods\",\n+    },\n+    {\n+        \"config_key\": \"payment.limits.daily_limit\",\n+        \"config_value\": {\"amount\": 100000.0, \"currency\": \"GBP\"},\n+        \"category\": \"payment_limits\",\n+        \"description\": \"Daily transaction limit per restaurant\",\n+    },\n     # Security Settings\n     {\n-        'config_key': 'security.session_timeout',\n-        'config_value': {'minutes': 30},\n-        'category': 'security',\n-        'description': 'Session timeout for POS applications',\n-    },\n-    {\n-        'config_key': 'security.api_rate_limit',\n-        'config_value': {'requests_per_minute': 100, 'burst_limit': 200},\n-        'category': 'security',\n-        'description': 'API rate limiting configuration',\n-    },\n-    {\n-        'config_key': 'security.data_retention_days',\n-        'config_value': {'payment_logs': 2555, 'audit_logs': 2555, 'user_sessions': 90},  # 7 years\n-        'category': 'security',\n-        'description': 'Data retention periods for compliance',\n-    },\n-\n+        \"config_key\": \"security.session_timeout\",\n+        \"config_value\": {\"minutes\": 30},\n+        \"category\": \"security\",\n+        \"description\": \"Session timeout for POS applications\",\n+    },\n+    {\n+        \"config_key\": \"security.api_rate_limit\",\n+        \"config_value\": {\"requests_per_minute\": 100, \"burst_limit\": 200},\n+        \"category\": \"security\",\n+        \"description\": \"API rate limiting configuration\",\n+    },\n+    {\n+        \"config_key\": \"security.data_retention_days\",\n+        \"config_value\": {\n+            \"payment_logs\": 2555,\n+            \"audit_logs\": 2555,\n+            \"user_sessions\": 90,\n+        },  # 7 years\n+        \"category\": \"security\",\n+        \"description\": \"Data retention periods for compliance\",\n+    },\n     # Feature Flags\n     {\n-        'config_key': 'features.smart_routing_enabled',\n-        'config_value': {'enabled': True},\n-        'category': 'features',\n-        'description': 'Enable smart payment routing algorithms',\n-    },\n-    {\n-        'config_key': 'features.analytics_enabled',\n-        'config_value': {'enabled': True},\n-        'category': 'features',\n-        'description': 'Enable analytics and reporting features',\n-    },\n-    {\n-        'config_key': 'features.qr_payments_enabled',\n-        'config_value': {'enabled': True},\n-        'category': 'features',\n-        'description': 'Enable QR code payment functionality',\n-    },\n-\n+        \"config_key\": \"features.smart_routing_enabled\",\n+        \"config_value\": {\"enabled\": True},\n+        \"category\": \"features\",\n+        \"description\": \"Enable smart payment routing algorithms\",\n+    },\n+    {\n+        \"config_key\": \"features.analytics_enabled\",\n+        \"config_value\": {\"enabled\": True},\n+        \"category\": \"features\",\n+        \"description\": \"Enable analytics and reporting features\",\n+    },\n+    {\n+        \"config_key\": \"features.qr_payments_enabled\",\n+        \"config_value\": {\"enabled\": True},\n+        \"category\": \"features\",\n+        \"description\": \"Enable QR code payment functionality\",\n+    },\n     # Business Rules\n     {\n-        'config_key': 'business.restaurant_limits.max_discount_percentage',\n-        'config_value': {'percentage': 50.0},\n-        'category': 'business_rules',\n-        'description': 'Maximum discount percentage restaurants can offer',\n-    },\n-    {\n-        'config_key': 'business.restaurant_limits.max_service_charge',\n-        'config_value': {'percentage': 20.0},\n-        'category': 'business_rules',\n-        'description': 'Maximum service charge restaurants can apply',\n-    },\n-\n+        \"config_key\": \"business.restaurant_limits.max_discount_percentage\",\n+        \"config_value\": {\"percentage\": 50.0},\n+        \"category\": \"business_rules\",\n+        \"description\": \"Maximum discount percentage restaurants can offer\",\n+    },\n+    {\n+        \"config_key\": \"business.restaurant_limits.max_service_charge\",\n+        \"config_value\": {\"percentage\": 20.0},\n+        \"category\": \"business_rules\",\n+        \"description\": \"Maximum service charge restaurants can apply\",\n+    },\n     # Service Charge Configuration\n     {\n-        'config_key': 'platform.service_charge.enabled',\n-        'config_value': {'value': True}, # Storing as a dict to match other config_value structures\n-        'category': 'service_charge',\n-        'description': 'Enable or disable platform-wide service charge.',\n-        'is_sensitive': False,\n-        'validation_schema': {'type': 'object', 'properties': {'value': {'type': 'boolean'}}}\n-    },\n-    {\n-        'config_key': 'platform.service_charge.rate',\n-        'config_value': {'value': 12.5}, # Storing as a dict\n-        'category': 'service_charge',\n-        'description': 'Service charge rate as a percentage (e.g., 12.5 for 12.5%).',\n-        'is_sensitive': False,\n-        'validation_schema': {'type': 'object', 'properties': {'value': {'type': 'number', 'minimum': 0, 'maximum': 100}}}\n-    },\n-    {\n-        'config_key': 'platform.service_charge.description',\n-        'config_value': {'value': 'Platform service charge'}, # Storing as a dict\n-        'category': 'service_charge',\n-        'description': 'Description for the service charge (e.g., for display on receipts).',\n-        'is_sensitive': False,\n-        'validation_schema': {'type': 'object', 'properties': {'value': {'type': 'string', 'maxLength': 255}}}\n-    },\n-    {\n-        'config_key': 'platform.service_charge.currency',\n-        'config_value': {'value': 'GBP'}, # Storing as a dict\n-        'category': 'service_charge',\n-        'description': 'Currency for the service charge.',\n-        'is_sensitive': False,\n-        'validation_schema': {'type': 'object', 'properties': {'value': {'type': 'string', 'enum': ['GBP', 'USD', 'EUR']}}}\n+        \"config_key\": \"platform.service_charge.enabled\",\n+        \"config_value\": {\n+            \"value\": True\n+        },  # Storing as a dict to match other config_value structures\n+        \"category\": \"service_charge\",\n+        \"description\": \"Enable or disable platform-wide service charge.\",\n+        \"is_sensitive\": False,\n+        \"validation_schema\": {\n+            \"type\": \"object\",\n+            \"properties\": {\"value\": {\"type\": \"boolean\"}},\n+        },\n+    },\n+    {\n+        \"config_key\": \"platform.service_charge.rate\",\n+        \"config_value\": {\"value\": 12.5},  # Storing as a dict\n+        \"category\": \"service_charge\",\n+        \"description\": \"Service charge rate as a percentage (e.g., 12.5 for 12.5%).\",\n+        \"is_sensitive\": False,\n+        \"validation_schema\": {\n+            \"type\": \"object\",\n+            \"properties\": {\"value\": {\"type\": \"number\", \"minimum\": 0, \"maximum\": 100}},\n+        },\n+    },\n+    {\n+        \"config_key\": \"platform.service_charge.description\",\n+        \"config_value\": {\"value\": \"Platform service charge\"},  # Storing as a dict\n+        \"category\": \"service_charge\",\n+        \"description\": \"Description for the service charge (e.g., for display on receipts).\",\n+        \"is_sensitive\": False,\n+        \"validation_schema\": {\n+            \"type\": \"object\",\n+            \"properties\": {\"value\": {\"type\": \"string\", \"maxLength\": 255}},\n+        },\n+    },\n+    {\n+        \"config_key\": \"platform.service_charge.currency\",\n+        \"config_value\": {\"value\": \"GBP\"},  # Storing as a dict\n+        \"category\": \"service_charge\",\n+        \"description\": \"Currency for the service charge.\",\n+        \"is_sensitive\": False,\n+        \"validation_schema\": {\n+            \"type\": \"object\",\n+            \"properties\": {\"value\": {\"type\": \"string\", \"enum\": [\"GBP\", \"USD\", \"EUR\"]}},\n+        },\n     },\n ]\n \n # Default feature flags\n DEFAULT_FEATURE_FLAGS = [\n     {\n-        'feature_key': 'payment_smart_routing',\n-        'is_enabled': True,\n-        'rollout_percentage': 100.0,\n-        'description': 'Smart payment provider routing',\n-        'feature_category': 'payment',\n-    },\n-    {\n-        'feature_key': 'analytics_dashboard',\n-        'is_enabled': True,\n-        'rollout_percentage': 100.0,\n-        'description': 'Analytics and reporting dashboard',\n-        'feature_category': 'analytics',\n-    },\n-    {\n-        'feature_key': 'qr_code_payments',\n-        'is_enabled': True,\n-        'rollout_percentage': 100.0,\n-        'description': 'QR code payment processing',\n-        'feature_category': 'payment',\n-    },\n-    {\n-        'feature_key': 'cash_payments',\n-        'is_enabled': True,\n-        'rollout_percentage': 100.0,\n-        'description': 'Cash payment handling',\n-        'feature_category': 'payment',\n-    },\n-    {\n-        'feature_key': 'demo_mode',\n-        'is_enabled': True,\n-        'rollout_percentage': 100.0,\n-        'description': 'Demo mode for investor presentations',\n-        'feature_category': 'system',\n-    },\n-]\n\\ No newline at end of file\n+        \"feature_key\": \"payment_smart_routing\",\n+        \"is_enabled\": True,\n+        \"rollout_percentage\": 100.0,\n+        \"description\": \"Smart payment provider routing\",\n+        \"feature_category\": \"payment\",\n+    },\n+    {\n+        \"feature_key\": \"analytics_dashboard\",\n+        \"is_enabled\": True,\n+        \"rollout_percentage\": 100.0,\n+        \"description\": \"Analytics and reporting dashboard\",\n+        \"feature_category\": \"analytics\",\n+    },\n+    {\n+        \"feature_key\": \"qr_code_payments\",\n+        \"is_enabled\": True,\n+        \"rollout_percentage\": 100.0,\n+        \"description\": \"QR code payment processing\",\n+        \"feature_category\": \"payment\",\n+    },\n+    {\n+        \"feature_key\": \"cash_payments\",\n+        \"is_enabled\": True,\n+        \"rollout_percentage\": 100.0,\n+        \"description\": \"Cash payment handling\",\n+        \"feature_category\": \"payment\",\n+    },\n+    {\n+        \"feature_key\": \"demo_mode\",\n+        \"is_enabled\": True,\n+        \"rollout_percentage\": 100.0,\n+        \"description\": \"Demo mode for investor presentations\",\n+        \"feature_category\": \"system\",\n+    },\n+]\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/scripts/initialize_platform_defaults.py\t2025-08-02 22:11:56.420022+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/scripts/initialize_platform_defaults.py\t2025-08-02 22:36:03.814565+00:00\n@@ -14,153 +14,171 @@\n # Add parent directory to path to import app modules\n sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n \n from app.core.database import SessionLocal\n from app.models.platform_config import (\n-    PlatformConfiguration, \n+    PlatformConfiguration,\n     PlatformFeatureFlag,\n     DEFAULT_PLATFORM_CONFIGS,\n-    DEFAULT_FEATURE_FLAGS\n+    DEFAULT_FEATURE_FLAGS,\n )\n \n # Configure logging\n logging.basicConfig(\n-    level=logging.INFO,\n-    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n+    level=logging.INFO, format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n )\n \n logger = logging.getLogger(__name__)\n+\n \n class PlatformDefaultsInitializer:\n     \"\"\"Initializes platform with production-ready default configurations\"\"\"\n-    \n+\n     def __init__(self, update_existing: bool = False):\n         self.update_existing = update_existing\n         self.db = SessionLocal()\n         self.stats = {\n-            'configs_added': 0,\n-            'configs_updated': 0,\n-            'configs_skipped': 0,\n-            'flags_added': 0,\n-            'flags_updated': 0,\n-            'flags_skipped': 0,\n-            'errors': 0\n+            \"configs_added\": 0,\n+            \"configs_updated\": 0,\n+            \"configs_skipped\": 0,\n+            \"flags_added\": 0,\n+            \"flags_updated\": 0,\n+            \"flags_skipped\": 0,\n+            \"errors\": 0,\n         }\n-    \n+\n     def __enter__(self):\n         return self\n-    \n+\n     def __exit__(self, exc_type, exc_val, exc_tb):\n         if exc_type is None:\n             self.db.commit()\n             logger.info(\"Platform initialization completed successfully\")\n         else:\n             self.db.rollback()\n             logger.error(\"Platform initialization failed - changes rolled back\")\n         self.db.close()\n-    \n+\n     def initialize(self) -> bool:\n         \"\"\"Initialize platform with all default configurations\"\"\"\n-        \n+\n         logger.info(\"Starting platform defaults initialization...\")\n-        \n+\n         try:\n             # Initialize platform configurations\n             logger.info(\"Initializing platform configurations...\")\n             self.initialize_platform_configs()\n-            \n+\n             # Initialize feature flags\n             logger.info(\"Initializing feature flags...\")\n             self.initialize_feature_flags()\n-            \n+\n             # Generate initialization report\n             self.generate_report()\n-            \n-            if self.stats['errors'] == 0:\n+\n+            if self.stats[\"errors\"] == 0:\n                 logger.info(\"\u2705 Platform initialization completed successfully!\")\n                 return True\n             else:\n-                logger.warning(f\"\u26a0\ufe0f Platform initialization completed with {self.stats['errors']} errors\")\n+                logger.warning(\n+                    f\"\u26a0\ufe0f Platform initialization completed with {self.stats['errors']} errors\"\n+                )\n                 return False\n-                \n+\n         except Exception as e:\n             logger.error(f\"Platform initialization failed: {e}\", exc_info=True)\n-            self.stats['errors'] += 1\n+            self.stats[\"errors\"] += 1\n             return False\n-    \n+\n     def initialize_platform_configs(self) -> None:\n         \"\"\"Initialize all platform configurations\"\"\"\n-        \n+\n         for config_data in DEFAULT_PLATFORM_CONFIGS:\n             try:\n-                existing = self.db.query(PlatformConfiguration).filter(\n-                    PlatformConfiguration.config_key == config_data['config_key']\n-                ).first()\n-                \n+                existing = (\n+                    self.db.query(PlatformConfiguration)\n+                    .filter(\n+                        PlatformConfiguration.config_key == config_data[\"config_key\"]\n+                    )\n+                    .first()\n+                )\n+\n                 if existing:\n                     if self.update_existing:\n                         # Update existing configuration\n                         for key, value in config_data.items():\n-                            if key != 'id':\n+                            if key != \"id\":\n                                 setattr(existing, key, value)\n                         existing.updated_at = datetime.utcnow()\n-                        existing.updated_by = 'initialization_script'\n-                        \n-                        self.stats['configs_updated'] += 1\n-                        logger.info(f\"Updated platform config: {config_data['config_key']}\")\n+                        existing.updated_by = \"initialization_script\"\n+\n+                        self.stats[\"configs_updated\"] += 1\n+                        logger.info(\n+                            f\"Updated platform config: {config_data['config_key']}\"\n+                        )\n                     else:\n-                        self.stats['configs_skipped'] += 1\n-                        logger.info(f\"Skipped existing config: {config_data['config_key']}\")\n+                        self.stats[\"configs_skipped\"] += 1\n+                        logger.info(\n+                            f\"Skipped existing config: {config_data['config_key']}\"\n+                        )\n                 else:\n                     # Add new configuration\n                     config = PlatformConfiguration(**config_data)\n                     self.db.add(config)\n-                    \n-                    self.stats['configs_added'] += 1\n+\n+                    self.stats[\"configs_added\"] += 1\n                     logger.info(f\"Added platform config: {config_data['config_key']}\")\n-                    \n+\n             except Exception as e:\n-                logger.error(f\"Failed to initialize config {config_data['config_key']}: {e}\")\n-                self.stats['errors'] += 1\n-    \n+                logger.error(\n+                    f\"Failed to initialize config {config_data['config_key']}: {e}\"\n+                )\n+                self.stats[\"errors\"] += 1\n+\n     def initialize_feature_flags(self) -> None:\n         \"\"\"Initialize all feature flags\"\"\"\n-        \n+\n         for flag_data in DEFAULT_FEATURE_FLAGS:\n             try:\n-                existing = self.db.query(PlatformFeatureFlag).filter(\n-                    PlatformFeatureFlag.feature_key == flag_data['feature_key']\n-                ).first()\n-                \n+                existing = (\n+                    self.db.query(PlatformFeatureFlag)\n+                    .filter(PlatformFeatureFlag.feature_key == flag_data[\"feature_key\"])\n+                    .first()\n+                )\n+\n                 if existing:\n                     if self.update_existing:\n                         # Update existing feature flag\n                         for key, value in flag_data.items():\n-                            if key != 'id':\n+                            if key != \"id\":\n                                 setattr(existing, key, value)\n                         existing.updated_at = datetime.utcnow()\n-                        \n-                        self.stats['flags_updated'] += 1\n+\n+                        self.stats[\"flags_updated\"] += 1\n                         logger.info(f\"Updated feature flag: {flag_data['feature_key']}\")\n                     else:\n-                        self.stats['flags_skipped'] += 1\n-                        logger.info(f\"Skipped existing flag: {flag_data['feature_key']}\")\n+                        self.stats[\"flags_skipped\"] += 1\n+                        logger.info(\n+                            f\"Skipped existing flag: {flag_data['feature_key']}\"\n+                        )\n                 else:\n                     # Add new feature flag\n                     flag = PlatformFeatureFlag(**flag_data)\n                     self.db.add(flag)\n-                    \n-                    self.stats['flags_added'] += 1\n+\n+                    self.stats[\"flags_added\"] += 1\n                     logger.info(f\"Added feature flag: {flag_data['feature_key']}\")\n-                    \n+\n             except Exception as e:\n-                logger.error(f\"Failed to initialize flag {flag_data['feature_key']}: {e}\")\n-                self.stats['errors'] += 1\n-    \n+                logger.error(\n+                    f\"Failed to initialize flag {flag_data['feature_key']}: {e}\"\n+                )\n+                self.stats[\"errors\"] += 1\n+\n     def generate_report(self) -> None:\n         \"\"\"Generate initialization report\"\"\"\n-        \n+\n         report = f\"\"\"\n PLATFORM DEFAULTS INITIALIZATION REPORT\n ========================================\n Date: {datetime.now().isoformat()}\n Update Existing: {self.update_existing}\n@@ -181,37 +199,46 @@\n - Total Platform Configs: {self.db.query(PlatformConfiguration).count()}\n - Total Feature Flags: {self.db.query(PlatformFeatureFlag).count()}\n \n STATUS: {'SUCCESS' if self.stats['errors'] == 0 else 'COMPLETED WITH ERRORS'}\n \"\"\"\n-        \n+\n         logger.info(\"Platform initialization report generated\")\n \n \n def main():\n     \"\"\"Main function to run the initialization\"\"\"\n-    \n+\n     import argparse\n-    \n-    parser = argparse.ArgumentParser(description='Initialize platform with default configurations')\n-    parser.add_argument('--update-existing', action='store_true',\n-                       help='Update existing configurations instead of skipping them')\n-    \n+\n+    parser = argparse.ArgumentParser(\n+        description=\"Initialize platform with default configurations\"\n+    )\n+    parser.add_argument(\n+        \"--update-existing\",\n+        action=\"store_true\",\n+        help=\"Update existing configurations instead of skipping them\",\n+    )\n+\n     args = parser.parse_args()\n-    \n+\n     if args.update_existing:\n-        confirmation = input(\"Are you sure you want to update existing configs? (yes/no): \")\n-        if confirmation.lower() != 'yes':\n+        confirmation = input(\n+            \"Are you sure you want to update existing configs? (yes/no): \"\n+        )\n+        if confirmation.lower() != \"yes\":\n             return\n-    \n-    with PlatformDefaultsInitializer(update_existing=args.update_existing) as initializer:\n+\n+    with PlatformDefaultsInitializer(\n+        update_existing=args.update_existing\n+    ) as initializer:\n         success = initializer.initialize()\n-        \n+\n         if success:\n             print(\"\\n\u2705 Platform initialization completed successfully!\")\n         else:\n             print(\"\\n\u274c Platform initialization failed\")\n             sys.exit(1)\n \n \n if __name__ == \"__main__\":\n-    main()\n\\ No newline at end of file\n+    main()\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models/reports.py\t2025-08-02 19:23:36.826798+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models/reports.py\t2025-08-02 22:36:03.814919+00:00\n@@ -1,261 +1,311 @@\n \"\"\"\n Reports and Analytics Models\n Cached aggregations for performance and historical reporting\n \"\"\"\n-from sqlalchemy import Column, String, Integer, Boolean, DateTime, Date, DECIMAL, ForeignKey, UniqueConstraint\n+\n+from sqlalchemy import (\n+    Column,\n+    String,\n+    Integer,\n+    Boolean,\n+    DateTime,\n+    Date,\n+    DECIMAL,\n+    ForeignKey,\n+    UniqueConstraint,\n+)\n from sqlalchemy.dialects.postgresql import UUID, JSONB\n from sqlalchemy.sql import func\n from sqlalchemy.orm import relationship\n import uuid\n from app.core.database import Base\n \n \n class DailyReport(Base):\n     \"\"\"Daily aggregated reports for quick access\"\"\"\n+\n     __tablename__ = \"daily_reports\"\n-    \n-    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n-    restaurant_id = Column(UUID(as_uuid=True), ForeignKey(\"restaurants.id\"), nullable=False)\n+\n+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n+    restaurant_id = Column(\n+        UUID(as_uuid=True), ForeignKey(\"restaurants.id\"), nullable=False\n+    )\n     report_date = Column(Date, nullable=False)\n-    \n+\n     # Sales Summary\n     total_revenue = Column(DECIMAL(12, 2), default=0.0)\n     total_orders = Column(Integer, default=0)\n     average_order_value = Column(DECIMAL(10, 2), default=0.0)\n-    \n+\n     # Payment Breakdown\n     cash_sales = Column(DECIMAL(12, 2), default=0.0)\n     card_sales = Column(DECIMAL(12, 2), default=0.0)\n     qr_sales = Column(DECIMAL(12, 2), default=0.0)\n     other_sales = Column(DECIMAL(12, 2), default=0.0)\n-    \n+\n     # Order Types\n     dine_in_orders = Column(Integer, default=0)\n     takeaway_orders = Column(Integer, default=0)\n     delivery_orders = Column(Integer, default=0)\n-    \n+\n     # Fees & Charges\n     total_tax = Column(DECIMAL(10, 2), default=0.0)\n     total_service_charge = Column(DECIMAL(10, 2), default=0.0)\n     total_discounts = Column(DECIMAL(10, 2), default=0.0)\n     payment_processing_fees = Column(DECIMAL(10, 2), default=0.0)\n-    \n+\n     # Labor Summary\n     total_labor_hours = Column(DECIMAL(10, 2), default=0.0)\n     total_labor_cost = Column(DECIMAL(12, 2), default=0.0)\n     employees_worked = Column(Integer, default=0)\n-    \n+\n     # Inventory Impact\n     cogs = Column(DECIMAL(12, 2), default=0.0)  # Cost of Goods Sold\n     waste_cost = Column(DECIMAL(10, 2), default=0.0)\n-    \n+\n     # Customer Metrics\n     unique_customers = Column(Integer, default=0)\n     new_customers = Column(Integer, default=0)\n     returning_customers = Column(Integer, default=0)\n-    \n+\n     # Hourly Breakdown (stored as JSONB for flexibility)\n     hourly_sales = Column(JSONB, default={})  # {\"09\": 150.00, \"10\": 280.00, ...}\n     hourly_orders = Column(JSONB, default={})  # {\"09\": 5, \"10\": 12, ...}\n-    \n+\n     # Top Items\n     top_items = Column(JSONB, default=[])  # [{item_id, name, quantity, revenue}, ...]\n-    top_categories = Column(JSONB, default=[])  # [{category_id, name, quantity, revenue}, ...]\n-    \n+    top_categories = Column(\n+        JSONB, default=[]\n+    )  # [{category_id, name, quantity, revenue}, ...]\n+\n     # Status\n     is_complete = Column(Boolean, default=False)\n     generated_at = Column(DateTime(timezone=True), server_default=func.now())\n     updated_at = Column(DateTime(timezone=True), onupdate=func.now())\n-    \n-    # Relationships\n-    restaurant = relationship(\"Restaurant\")\n-    \n+\n+    # Relationships\n+    restaurant = relationship(\"Restaurant\")\n+\n     # Unique constraint to ensure one report per restaurant per day\n     __table_args__ = (\n-        UniqueConstraint('restaurant_id', 'report_date', name='uq_restaurant_daily_report'),\n+        UniqueConstraint(\n+            \"restaurant_id\", \"report_date\", name=\"uq_restaurant_daily_report\"\n+        ),\n     )\n \n \n class HourlyMetric(Base):\n     \"\"\"Hourly metrics for real-time monitoring\"\"\"\n+\n     __tablename__ = \"hourly_metrics\"\n-    \n-    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n-    restaurant_id = Column(UUID(as_uuid=True), ForeignKey(\"restaurants.id\"), nullable=False)\n+\n+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n+    restaurant_id = Column(\n+        UUID(as_uuid=True), ForeignKey(\"restaurants.id\"), nullable=False\n+    )\n     metric_datetime = Column(DateTime(timezone=True), nullable=False)\n     hour = Column(Integer, nullable=False)  # 0-23\n-    \n+\n     # Sales Metrics\n     revenue = Column(DECIMAL(10, 2), default=0.0)\n     order_count = Column(Integer, default=0)\n     item_count = Column(Integer, default=0)\n     average_order_value = Column(DECIMAL(10, 2), default=0.0)\n-    \n+\n     # Service Metrics\n     average_prep_time = Column(Integer, default=0)  # minutes\n     average_service_time = Column(Integer, default=0)  # minutes\n     tables_turned = Column(Integer, default=0)\n-    \n+\n     # Labor Metrics\n     staff_count = Column(Integer, default=0)\n     labor_cost = Column(DECIMAL(10, 2), default=0.0)\n     revenue_per_labor_hour = Column(DECIMAL(10, 2), default=0.0)\n-    \n+\n     created_at = Column(DateTime(timezone=True), server_default=func.now())\n-    \n-    # Relationships\n-    restaurant = relationship(\"Restaurant\")\n-    \n+\n+    # Relationships\n+    restaurant = relationship(\"Restaurant\")\n+\n     # Unique constraint\n     __table_args__ = (\n-        UniqueConstraint('restaurant_id', 'metric_datetime', 'hour', name='uq_restaurant_hourly_metric'),\n+        UniqueConstraint(\n+            \"restaurant_id\",\n+            \"metric_datetime\",\n+            \"hour\",\n+            name=\"uq_restaurant_hourly_metric\",\n+        ),\n     )\n \n \n class ProductPerformance(Base):\n     \"\"\"Product performance analytics\"\"\"\n+\n     __tablename__ = \"product_performance\"\n-    \n-    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n-    restaurant_id = Column(UUID(as_uuid=True), ForeignKey(\"restaurants.id\"), nullable=False)\n+\n+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n+    restaurant_id = Column(\n+        UUID(as_uuid=True), ForeignKey(\"restaurants.id\"), nullable=False\n+    )\n     product_id = Column(UUID(as_uuid=True), ForeignKey(\"products.id\"), nullable=False)\n     report_date = Column(Date, nullable=False)\n-    \n+\n     # Sales Metrics\n     quantity_sold = Column(Integer, default=0)\n     total_revenue = Column(DECIMAL(10, 2), default=0.0)\n     total_cost = Column(DECIMAL(10, 2), default=0.0)\n     gross_profit = Column(DECIMAL(10, 2), default=0.0)\n     profit_margin = Column(DECIMAL(5, 2), default=0.0)  # percentage\n-    \n+\n     # Time Distribution\n     lunch_sales = Column(Integer, default=0)  # 11am-2pm\n     dinner_sales = Column(Integer, default=0)  # 5pm-9pm\n     other_sales = Column(Integer, default=0)\n-    \n+\n     # Combo/Modifier Analysis\n     sold_as_combo = Column(Integer, default=0)\n     popular_modifiers = Column(JSONB, default=[])  # [{modifier, count}, ...]\n-    \n+\n     # Rankings\n     revenue_rank = Column(Integer, nullable=True)\n     quantity_rank = Column(Integer, nullable=True)\n     profit_rank = Column(Integer, nullable=True)\n-    \n+\n     created_at = Column(DateTime(timezone=True), server_default=func.now())\n-    \n+\n     # Relationships\n     restaurant = relationship(\"Restaurant\")\n     product = relationship(\"Product\")\n-    \n+\n     # Unique constraint\n     __table_args__ = (\n-        UniqueConstraint('restaurant_id', 'product_id', 'report_date', name='uq_product_performance'),\n+        UniqueConstraint(\n+            \"restaurant_id\", \"product_id\", \"report_date\", name=\"uq_product_performance\"\n+        ),\n     )\n \n \n class EmployeePerformance(Base):\n     \"\"\"Employee performance summary for reports\"\"\"\n+\n     __tablename__ = \"employee_performance\"\n-    \n-    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n-    restaurant_id = Column(UUID(as_uuid=True), ForeignKey(\"restaurants.id\"), nullable=False)\n-    employee_id = Column(UUID(as_uuid=True), ForeignKey(\"employee_profiles.id\"), nullable=False)\n+\n+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n+    restaurant_id = Column(\n+        UUID(as_uuid=True), ForeignKey(\"restaurants.id\"), nullable=False\n+    )\n+    employee_id = Column(\n+        UUID(as_uuid=True), ForeignKey(\"employee_profiles.id\"), nullable=False\n+    )\n     report_date = Column(Date, nullable=False)\n-    \n+\n     # Work Summary\n     hours_worked = Column(DECIMAL(5, 2), default=0.0)\n     shifts_worked = Column(Integer, default=0)\n-    \n+\n     # Sales Performance (for servers/cashiers)\n     total_sales = Column(DECIMAL(12, 2), default=0.0)\n     transaction_count = Column(Integer, default=0)\n     average_transaction = Column(DECIMAL(10, 2), default=0.0)\n     sales_per_hour = Column(DECIMAL(10, 2), default=0.0)\n-    \n+\n     # Service Metrics\n     tables_served = Column(Integer, default=0)\n     items_sold = Column(Integer, default=0)\n     average_service_time = Column(Integer, default=0)  # minutes\n-    \n+\n     # Tips\n     tips_earned = Column(DECIMAL(10, 2), default=0.0)\n     tip_percentage = Column(DECIMAL(5, 2), default=0.0)\n-    \n+\n     # Labor Cost\n     wages_earned = Column(DECIMAL(10, 2), default=0.0)\n     total_compensation = Column(DECIMAL(10, 2), default=0.0)  # wages + tips\n-    \n+\n     # Rankings (within restaurant for the day)\n     sales_rank = Column(Integer, nullable=True)\n     efficiency_rank = Column(Integer, nullable=True)\n-    \n+\n     created_at = Column(DateTime(timezone=True), server_default=func.now())\n-    \n+\n     # Relationships\n     restaurant = relationship(\"Restaurant\")\n     employee = relationship(\"EmployeeProfile\")\n-    \n+\n     # Unique constraint\n     __table_args__ = (\n-        UniqueConstraint('restaurant_id', 'employee_id', 'report_date', name='uq_employee_performance'),\n+        UniqueConstraint(\n+            \"restaurant_id\",\n+            \"employee_id\",\n+            \"report_date\",\n+            name=\"uq_employee_performance\",\n+        ),\n     )\n \n \n class FinancialSummary(Base):\n     \"\"\"Weekly/Monthly financial summaries\"\"\"\n+\n     __tablename__ = \"financial_summaries\"\n-    \n-    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n-    restaurant_id = Column(UUID(as_uuid=True), ForeignKey(\"restaurants.id\"), nullable=False)\n+\n+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n+    restaurant_id = Column(\n+        UUID(as_uuid=True), ForeignKey(\"restaurants.id\"), nullable=False\n+    )\n     platform_id = Column(UUID(as_uuid=True), ForeignKey(\"platforms.id\"), nullable=False)\n-    \n+\n     # Period\n-    period_type = Column(String(20), nullable=False)  # weekly, monthly, quarterly, yearly\n+    period_type = Column(\n+        String(20), nullable=False\n+    )  # weekly, monthly, quarterly, yearly\n     period_start = Column(Date, nullable=False)\n     period_end = Column(Date, nullable=False)\n-    \n+\n     # Revenue\n     gross_revenue = Column(DECIMAL(12, 2), default=0.0)\n     net_revenue = Column(DECIMAL(12, 2), default=0.0)\n-    \n+\n     # Costs\n     total_cogs = Column(DECIMAL(12, 2), default=0.0)\n     total_labor = Column(DECIMAL(12, 2), default=0.0)\n     total_overhead = Column(DECIMAL(12, 2), default=0.0)\n-    \n+\n     # Fees & Commissions\n     payment_processing_fees = Column(DECIMAL(10, 2), default=0.0)\n     platform_commission = Column(DECIMAL(10, 2), default=0.0)\n     service_charges_collected = Column(DECIMAL(10, 2), default=0.0)\n-    \n+\n     # Profit\n     gross_profit = Column(DECIMAL(12, 2), default=0.0)\n     operating_profit = Column(DECIMAL(12, 2), default=0.0)\n     profit_margin = Column(DECIMAL(5, 2), default=0.0)  # percentage\n-    \n+\n     # Operational Metrics\n     total_orders = Column(Integer, default=0)\n     average_order_value = Column(DECIMAL(10, 2), default=0.0)\n     customer_count = Column(Integer, default=0)\n-    \n+\n     # Comparisons (stored as percentages)\n     revenue_vs_last_period = Column(DECIMAL(5, 2), default=0.0)\n     profit_vs_last_period = Column(DECIMAL(5, 2), default=0.0)\n-    \n+\n     # Breakdown by category\n-    category_breakdown = Column(JSONB, default={})  # {category_id: {revenue, quantity, profit}}\n-    \n+    category_breakdown = Column(\n+        JSONB, default={}\n+    )  # {category_id: {revenue, quantity, profit}}\n+\n     # Status\n     is_finalized = Column(Boolean, default=False)\n     generated_at = Column(DateTime(timezone=True), server_default=func.now())\n     updated_at = Column(DateTime(timezone=True), onupdate=func.now())\n-    \n+\n     # Relationships\n     restaurant = relationship(\"Restaurant\")\n     platform = relationship(\"Platform\")\n-    \n+\n     # Unique constraint\n     __table_args__ = (\n-        UniqueConstraint('restaurant_id', 'period_type', 'period_start', name='uq_financial_summary'),\n-    )\n\\ No newline at end of file\n+        UniqueConstraint(\n+            \"restaurant_id\", \"period_type\", \"period_start\", name=\"uq_financial_summary\"\n+        ),\n+    )\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models/stock_movement.py\t2025-08-02 19:52:26.972387+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models/stock_movement.py\t2025-08-02 22:36:03.833046+00:00\n@@ -1,189 +1,221 @@\n \"\"\"\n Stock Movement and Supplier Management Models\n Track all inventory movements and supplier relationships\n \"\"\"\n-from sqlalchemy import Column, String, Integer, Boolean, DateTime, Date, DECIMAL, ForeignKey, Enum as SqlEnum\n+\n+from sqlalchemy import (\n+    Column,\n+    String,\n+    Integer,\n+    Boolean,\n+    DateTime,\n+    Date,\n+    DECIMAL,\n+    ForeignKey,\n+    Enum as SqlEnum,\n+)\n from sqlalchemy.dialects.postgresql import UUID, JSONB\n from sqlalchemy.sql import func\n from sqlalchemy.orm import relationship\n import uuid\n import enum\n from app.core.database import Base\n \n \n class MovementType(enum.Enum):\n     \"\"\"Types of stock movements\"\"\"\n-    PURCHASE = \"purchase\"          # Stock received from supplier\n-    SALE = \"sale\"                  # Stock used in orders\n-    ADJUSTMENT = \"adjustment\"      # Manual adjustment\n-    TRANSFER = \"transfer\"          # Transfer between locations\n-    WASTE = \"waste\"                # Spoilage/damage\n-    RETURN = \"return\"              # Return to supplier\n-    PRODUCTION = \"production\"      # Used in production/prep\n-    COUNT = \"count\"                # Physical count adjustment\n+\n+    PURCHASE = \"purchase\"  # Stock received from supplier\n+    SALE = \"sale\"  # Stock used in orders\n+    ADJUSTMENT = \"adjustment\"  # Manual adjustment\n+    TRANSFER = \"transfer\"  # Transfer between locations\n+    WASTE = \"waste\"  # Spoilage/damage\n+    RETURN = \"return\"  # Return to supplier\n+    PRODUCTION = \"production\"  # Used in production/prep\n+    COUNT = \"count\"  # Physical count adjustment\n \n \n class Supplier(Base):\n     \"\"\"Supplier management\"\"\"\n+\n     __tablename__ = \"suppliers\"\n-    \n-    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n-    restaurant_id = Column(UUID(as_uuid=True), ForeignKey(\"restaurants.id\"), nullable=False)\n-    \n+\n+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n+    restaurant_id = Column(\n+        UUID(as_uuid=True), ForeignKey(\"restaurants.id\"), nullable=False\n+    )\n+\n     # Supplier Information\n     name = Column(String(255), nullable=False)\n     code = Column(String(50), unique=True)\n     contact_name = Column(String(100))\n     email = Column(String(255))\n     phone = Column(String(20))\n     website = Column(String(255))\n-    \n+\n     # Address\n     address = Column(JSONB, default={})  # {line1, line2, city, postcode, country}\n-    \n+\n     # Business Details\n     tax_number = Column(String(50))\n     payment_terms = Column(String(50), default=\"net30\")  # net30, net60, cod, etc\n     minimum_order = Column(DECIMAL(10, 2), default=0.0)\n     delivery_days = Column(JSONB, default=[])  # [\"monday\", \"thursday\"]\n     lead_time_days = Column(Integer, default=1)\n-    \n+\n     # Categories this supplier provides\n     categories = Column(JSONB, default=[])  # [\"produce\", \"meat\", \"dairy\"]\n-    \n+\n     # Performance Metrics\n     on_time_delivery_rate = Column(DECIMAL(5, 2), default=100.0)  # percentage\n     quality_rating = Column(DECIMAL(3, 2), default=5.0)  # 0.00 to 5.00\n     total_purchases = Column(DECIMAL(12, 2), default=0.0)\n-    \n+\n     # Status\n     is_active = Column(Boolean, default=True)\n     is_preferred = Column(Boolean, default=False)\n     notes = Column(JSONB, default=[])  # [{date, note, author_id}]\n-    \n+\n     created_at = Column(DateTime(timezone=True), server_default=func.now())\n     updated_at = Column(DateTime(timezone=True), onupdate=func.now())\n-    \n+\n     # Relationships\n     restaurant = relationship(\"Restaurant\")\n     purchase_orders = relationship(\"PurchaseOrder\", back_populates=\"supplier\")\n     stock_movements = relationship(\"StockMovement\", back_populates=\"supplier\")\n \n \n class PurchaseOrder(Base):\n     \"\"\"Purchase orders to suppliers\"\"\"\n+\n     __tablename__ = \"purchase_orders\"\n-    \n-    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n-    restaurant_id = Column(UUID(as_uuid=True), ForeignKey(\"restaurants.id\"), nullable=False)\n+\n+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n+    restaurant_id = Column(\n+        UUID(as_uuid=True), ForeignKey(\"restaurants.id\"), nullable=False\n+    )\n     supplier_id = Column(UUID(as_uuid=True), ForeignKey(\"suppliers.id\"), nullable=False)\n-    \n+\n     # Order Details\n     order_number = Column(String(50), unique=True, nullable=False)\n     order_date = Column(Date, nullable=False)\n     expected_delivery = Column(Date, nullable=False)\n     actual_delivery = Column(Date, nullable=True)\n-    \n+\n     # Financial\n     subtotal = Column(DECIMAL(12, 2), default=0.0)\n     tax_amount = Column(DECIMAL(10, 2), default=0.0)\n     delivery_fee = Column(DECIMAL(10, 2), default=0.0)\n     total_amount = Column(DECIMAL(12, 2), default=0.0)\n-    \n-    # Status\n-    status = Column(String(20), default=\"draft\")  # draft, sent, confirmed, delivered, cancelled\n+\n+    # Status\n+    status = Column(\n+        String(20), default=\"draft\"\n+    )  # draft, sent, confirmed, delivered, cancelled\n     payment_status = Column(String(20), default=\"pending\")  # pending, partial, paid\n-    \n+\n     # Delivery\n     delivery_notes = Column(String(500))\n     invoice_number = Column(String(50))\n-    \n+\n     # User tracking\n     created_by = Column(UUID(as_uuid=True), ForeignKey(\"users.id\"), nullable=False)\n     approved_by = Column(UUID(as_uuid=True), ForeignKey(\"users.id\"), nullable=True)\n     received_by = Column(UUID(as_uuid=True), ForeignKey(\"users.id\"), nullable=True)\n-    \n+\n     created_at = Column(DateTime(timezone=True), server_default=func.now())\n     updated_at = Column(DateTime(timezone=True), onupdate=func.now())\n-    \n+\n     # Relationships\n     restaurant = relationship(\"Restaurant\")\n     supplier = relationship(\"Supplier\", back_populates=\"purchase_orders\")\n-    items = relationship(\"PurchaseOrderItem\", back_populates=\"purchase_order\", cascade=\"all, delete-orphan\")\n+    items = relationship(\n+        \"PurchaseOrderItem\",\n+        back_populates=\"purchase_order\",\n+        cascade=\"all, delete-orphan\",\n+    )\n     creator = relationship(\"User\", foreign_keys=[created_by])\n     approver = relationship(\"User\", foreign_keys=[approved_by])\n     receiver = relationship(\"User\", foreign_keys=[received_by])\n \n \n class PurchaseOrderItem(Base):\n     \"\"\"Items in a purchase order\"\"\"\n+\n     __tablename__ = \"purchase_order_items\"\n-    \n-    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n-    purchase_order_id = Column(UUID(as_uuid=True), ForeignKey(\"purchase_orders.id\"), nullable=False)\n+\n+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n+    purchase_order_id = Column(\n+        UUID(as_uuid=True), ForeignKey(\"purchase_orders.id\"), nullable=False\n+    )\n     inventory_sku = Column(String(100), ForeignKey(\"inventory.sku\"), nullable=False)\n-    \n+\n     # Order Details\n     quantity_ordered = Column(DECIMAL(10, 2), nullable=False)\n     unit = Column(String(20), nullable=False)  # kg, g, l, ml, units\n     unit_price = Column(DECIMAL(10, 2), nullable=False)\n     total_price = Column(DECIMAL(10, 2), nullable=False)\n-    \n+\n     # Delivery\n     quantity_received = Column(DECIMAL(10, 2), default=0.0)\n     quantity_rejected = Column(DECIMAL(10, 2), default=0.0)\n     rejection_reason = Column(String(255))\n-    \n-    created_at = Column(DateTime(timezone=True), server_default=func.now())\n-    \n+\n+    created_at = Column(DateTime(timezone=True), server_default=func.now())\n+\n     # Relationships\n     purchase_order = relationship(\"PurchaseOrder\", back_populates=\"items\")\n     inventory_item = relationship(\"InventoryItem\")\n \n \n class StockMovement(Base):\n     \"\"\"Track all inventory movements\"\"\"\n+\n     __tablename__ = \"stock_movements\"\n-    \n-    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n-    restaurant_id = Column(UUID(as_uuid=True), ForeignKey(\"restaurants.id\"), nullable=False)\n+\n+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n+    restaurant_id = Column(\n+        UUID(as_uuid=True), ForeignKey(\"restaurants.id\"), nullable=False\n+    )\n     inventory_sku = Column(String(100), ForeignKey(\"inventory.sku\"), nullable=False)\n-    \n+\n     # Movement Details\n     movement_type = Column(SqlEnum(MovementType), nullable=False)\n-    quantity = Column(DECIMAL(10, 2), nullable=False)  # Positive for IN, Negative for OUT\n+    quantity = Column(\n+        DECIMAL(10, 2), nullable=False\n+    )  # Positive for IN, Negative for OUT\n     unit = Column(String(20), nullable=False)\n-    \n+\n     # Stock Levels (snapshot at time of movement)\n     stock_before = Column(DECIMAL(10, 2), nullable=False)\n     stock_after = Column(DECIMAL(10, 2), nullable=False)\n-    \n+\n     # Cost Information\n     unit_cost = Column(DECIMAL(10, 2), default=0.0)\n     total_cost = Column(DECIMAL(10, 2), default=0.0)\n-    \n+\n     # Reference Information\n     reference_type = Column(String(50))  # order, purchase_order, adjustment, etc\n     reference_id = Column(String(255))  # ID of the related record\n-    \n+\n     # Additional Details based on movement type\n     supplier_id = Column(UUID(as_uuid=True), ForeignKey(\"suppliers.id\"), nullable=True)\n     order_id = Column(UUID(as_uuid=True), ForeignKey(\"orders.id\"), nullable=True)\n-    \n+\n     # Reason/Notes\n     reason = Column(String(255))\n     notes = Column(String(500))\n-    \n+\n     # User tracking\n     performed_by = Column(UUID(as_uuid=True), ForeignKey(\"users.id\"), nullable=False)\n     approved_by = Column(UUID(as_uuid=True), ForeignKey(\"users.id\"), nullable=True)\n-    \n+\n     # Timestamps\n     movement_date = Column(DateTime(timezone=True), nullable=False, default=func.now())\n     created_at = Column(DateTime(timezone=True), server_default=func.now())\n-    \n+\n     # Relationships\n     restaurant = relationship(\"Restaurant\")\n     inventory_item = relationship(\"InventoryItem\")\n     supplier = relationship(\"Supplier\", back_populates=\"stock_movements\")\n     order = relationship(\"Order\")\n@@ -191,108 +223,127 @@\n     approver = relationship(\"User\", foreign_keys=[approved_by])\n \n \n class StockAlert(Base):\n     \"\"\"Inventory alerts and notifications\"\"\"\n+\n     __tablename__ = \"stock_alerts\"\n-    \n-    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n-    restaurant_id = Column(UUID(as_uuid=True), ForeignKey(\"restaurants.id\"), nullable=False)\n+\n+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n+    restaurant_id = Column(\n+        UUID(as_uuid=True), ForeignKey(\"restaurants.id\"), nullable=False\n+    )\n     inventory_sku = Column(String(100), ForeignKey(\"inventory.sku\"), nullable=False)\n-    \n+\n     # Alert Details\n-    alert_type = Column(String(50), nullable=False)  # low_stock, out_of_stock, expiring_soon\n+    alert_type = Column(\n+        String(50), nullable=False\n+    )  # low_stock, out_of_stock, expiring_soon\n     threshold_value = Column(DECIMAL(10, 2))  # The value that triggered the alert\n     current_value = Column(DECIMAL(10, 2))  # Current stock level or days to expiry\n-    \n+\n     # Status\n     is_active = Column(Boolean, default=True)\n     is_acknowledged = Column(Boolean, default=False)\n     acknowledged_by = Column(UUID(as_uuid=True), ForeignKey(\"users.id\"), nullable=True)\n     acknowledged_at = Column(DateTime(timezone=True), nullable=True)\n-    \n+\n     # Resolution\n     is_resolved = Column(Boolean, default=False)\n     resolved_at = Column(DateTime(timezone=True), nullable=True)\n     resolution_notes = Column(String(255))\n-    \n+\n     # Notification\n     notification_sent = Column(Boolean, default=False)\n     notification_channels = Column(JSONB, default=[])  # [\"email\", \"sms\", \"app\"]\n-    \n+\n     created_at = Column(DateTime(timezone=True), server_default=func.now())\n     updated_at = Column(DateTime(timezone=True), onupdate=func.now())\n-    \n+\n     # Relationships\n     restaurant = relationship(\"Restaurant\")\n     inventory_item = relationship(\"InventoryItem\")\n     acknowledger = relationship(\"User\")\n \n \n class InventoryCount(Base):\n     \"\"\"Physical inventory counts\"\"\"\n+\n     __tablename__ = \"inventory_counts\"\n-    \n-    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n-    restaurant_id = Column(UUID(as_uuid=True), ForeignKey(\"restaurants.id\"), nullable=False)\n-    \n+\n+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n+    restaurant_id = Column(\n+        UUID(as_uuid=True), ForeignKey(\"restaurants.id\"), nullable=False\n+    )\n+\n     # Count Details\n     count_date = Column(Date, nullable=False)\n     count_type = Column(String(50), default=\"full\")  # full, cycle, spot\n-    \n-    # Status\n-    status = Column(String(20), default=\"in_progress\")  # in_progress, completed, approved\n-    \n+\n+    # Status\n+    status = Column(\n+        String(20), default=\"in_progress\"\n+    )  # in_progress, completed, approved\n+\n     # Summary\n     items_counted = Column(Integer, default=0)\n     total_items = Column(Integer, default=0)\n     variance_value = Column(DECIMAL(10, 2), default=0.0)  # Total $ variance\n-    \n+\n     # User tracking\n     initiated_by = Column(UUID(as_uuid=True), ForeignKey(\"users.id\"), nullable=False)\n     completed_by = Column(UUID(as_uuid=True), ForeignKey(\"users.id\"), nullable=True)\n     approved_by = Column(UUID(as_uuid=True), ForeignKey(\"users.id\"), nullable=True)\n-    \n+\n     # Timestamps\n     started_at = Column(DateTime(timezone=True), server_default=func.now())\n     completed_at = Column(DateTime(timezone=True), nullable=True)\n     approved_at = Column(DateTime(timezone=True), nullable=True)\n-    \n+\n     notes = Column(String(500))\n     created_at = Column(DateTime(timezone=True), server_default=func.now())\n-    \n-    # Relationships\n-    restaurant = relationship(\"Restaurant\")\n-    items = relationship(\"InventoryCountItem\", back_populates=\"count\", cascade=\"all, delete-orphan\")\n+\n+    # Relationships\n+    restaurant = relationship(\"Restaurant\")\n+    items = relationship(\n+        \"InventoryCountItem\", back_populates=\"count\", cascade=\"all, delete-orphan\"\n+    )\n     initiator = relationship(\"User\", foreign_keys=[initiated_by])\n     completer = relationship(\"User\", foreign_keys=[completed_by])\n     approver = relationship(\"User\", foreign_keys=[approved_by])\n \n \n class InventoryCountItem(Base):\n     \"\"\"Individual items in an inventory count\"\"\"\n+\n     __tablename__ = \"inventory_count_items\"\n-    \n-    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n-    count_id = Column(UUID(as_uuid=True), ForeignKey(\"inventory_counts.id\"), nullable=False)\n+\n+    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n+    count_id = Column(\n+        UUID(as_uuid=True), ForeignKey(\"inventory_counts.id\"), nullable=False\n+    )\n     inventory_sku = Column(String(100), ForeignKey(\"inventory.sku\"), nullable=False)\n-    \n+\n     # Count Details\n     system_quantity = Column(DECIMAL(10, 2), nullable=False)  # What system shows\n-    counted_quantity = Column(DECIMAL(10, 2), nullable=False)  # What was physically counted\n+    counted_quantity = Column(\n+        DECIMAL(10, 2), nullable=False\n+    )  # What was physically counted\n     variance_quantity = Column(DECIMAL(10, 2), nullable=False)  # Difference\n-    \n+\n     # Financial Impact\n     unit_cost = Column(DECIMAL(10, 2), nullable=False)\n-    variance_value = Column(DECIMAL(10, 2), nullable=False)  # variance_quantity * unit_cost\n-    \n+    variance_value = Column(\n+        DECIMAL(10, 2), nullable=False\n+    )  # variance_quantity * unit_cost\n+\n     # Status\n     is_verified = Column(Boolean, default=False)\n     verified_by = Column(UUID(as_uuid=True), ForeignKey(\"users.id\"), nullable=True)\n-    \n+\n     notes = Column(String(255))\n     counted_at = Column(DateTime(timezone=True), server_default=func.now())\n-    \n+\n     # Relationships\n     count = relationship(\"InventoryCount\", back_populates=\"items\")\n     inventory_item = relationship(\"InventoryItem\")\n-    verifier = relationship(\"User\")\n\\ No newline at end of file\n+    verifier = relationship(\"User\")\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/financial_records_service.py\t2025-08-02 21:56:59.003135+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/financial_records_service.py\t2025-08-02 22:36:03.840507+00:00\n@@ -2,82 +2,114 @@\n from typing import List, Optional\n from sqlalchemy.orm import Session\n from decimal import Decimal\n \n from app.models.financial_records import PlatformFeeRecord, StaffTipDistributionRecord\n-from app.schemas.fee_schemas import PlatformFeeRecordSchema, StaffTipDistributionRecordSchema, PaymentMethodEnum\n+from app.schemas.fee_schemas import (\n+    PlatformFeeRecordSchema,\n+    StaffTipDistributionRecordSchema,\n+    PaymentMethodEnum,\n+)\n \n logger = logging.getLogger(__name__)\n+\n \n class FinancialRecordsService:\n     \"\"\"\n     Service for managing financial records like platform fees and staff tip distributions.\n     \"\"\"\n \n     def __init__(self, db: Session):\n         self.db = db\n \n-    def create_platform_fee_record(self, fee_data: PlatformFeeRecordSchema) -> PlatformFeeRecord:\n+    def create_platform_fee_record(\n+        self, fee_data: PlatformFeeRecordSchema\n+    ) -> PlatformFeeRecord:\n         \"\"\"\n         Creates and saves a platform fee record.\n         \"\"\"\n-        logger.info(f\"Creating platform fee record for order: {fee_data.get('order_id')}\")\n+        logger.info(\n+            f\"Creating platform fee record for order: {fee_data.get('order_id')}\"\n+        )\n \n         db_record = PlatformFeeRecord(\n-            order_reference=fee_data['order_id'], # order_id from schema maps to order_reference in model\n-            platform_fee_amount=Decimal(str(fee_data['platform_fee_amount'])),\n-            processor_fee_amount=Decimal(str(fee_data['processor_fee_amount'])),\n-            customer_paid_processor_fee=fee_data['customer_paid_processor'],\n-            payment_method=fee_data['payment_method'].value, # Store enum's value\n+            order_reference=fee_data[\n+                \"order_id\"\n+            ],  # order_id from schema maps to order_reference in model\n+            platform_fee_amount=Decimal(str(fee_data[\"platform_fee_amount\"])),\n+            processor_fee_amount=Decimal(str(fee_data[\"processor_fee_amount\"])),\n+            customer_paid_processor_fee=fee_data[\"customer_paid_processor\"],\n+            payment_method=fee_data[\"payment_method\"].value,  # Store enum's value\n             # transaction_timestamp is server_default in model, or can be passed in fee_data\n         )\n-        if 'transaction_timestamp' in fee_data and fee_data['transaction_timestamp']:\n+        if \"transaction_timestamp\" in fee_data and fee_data[\"transaction_timestamp\"]:\n             # If client provides it, use it. Ensure it's in correct format or parse.\n             # For now, assuming it's already a valid datetime string if provided.\n             # db_record.transaction_timestamp = parse_datetime_string(fee_data['transaction_timestamp'])\n             # Simpler: let server_default handle it if not passed or passed as None.\n             # Or, if model doesn't have server_default and it's mandatory from client:\n             # from dateutil import parser\n             # db_record.transaction_timestamp = parser.isoparse(fee_data['transaction_timestamp'])\n-            pass # Relying on server_default for now if not explicitly handled.\n+            pass  # Relying on server_default for now if not explicitly handled.\n \n         try:\n             self.db.add(db_record)\n             self.db.commit()\n             self.db.refresh(db_record)\n-            logger.info(f\"Platform fee record created with ID: {db_record.id} for order {db_record.order_reference}\")\n+            logger.info(\n+                f\"Platform fee record created with ID: {db_record.id} for order {db_record.order_reference}\"\n+            )\n             return db_record\n         except Exception as e:\n             self.db.rollback()\n-            logger.error(f\"Error creating platform fee record for order {fee_data.get('order_id')}: {e}\", exc_info=True)\n+            logger.error(\n+                f\"Error creating platform fee record for order {fee_data.get('order_id')}: {e}\",\n+                exc_info=True,\n+            )\n             raise\n \n-    def get_platform_fees_for_order(self, order_reference: str) -> List[PlatformFeeRecord]:\n+    def get_platform_fees_for_order(\n+        self, order_reference: str\n+    ) -> List[PlatformFeeRecord]:\n         \"\"\"\n         Retrieves all platform fee records for a given order reference.\n         \"\"\"\n-        return self.db.query(PlatformFeeRecord).filter(\n-            PlatformFeeRecord.order_reference == order_reference\n-        ).all()\n+        return (\n+            self.db.query(PlatformFeeRecord)\n+            .filter(PlatformFeeRecord.order_reference == order_reference)\n+            .all()\n+        )\n \n     # StaffTipDistributionRecord methods will be used by StaffTipService or related endpoints\n     # StaffTipService already handles creation of StaffTipDistributionRecord.\n     # This service could provide query methods if needed outside StaffTipService.\n \n-    def get_staff_tip_distributions_for_order(self, order_reference: str) -> List[StaffTipDistributionRecord]:\n+    def get_staff_tip_distributions_for_order(\n+        self, order_reference: str\n+    ) -> List[StaffTipDistributionRecord]:\n         \"\"\"\n         Retrieves staff tip distribution records for a specific order.\n         (This functionality might also live in StaffTipService)\n         \"\"\"\n-        return self.db.query(StaffTipDistributionRecord).filter(\n-            StaffTipDistributionRecord.order_reference == order_reference\n-        ).all()\n+        return (\n+            self.db.query(StaffTipDistributionRecord)\n+            .filter(StaffTipDistributionRecord.order_reference == order_reference)\n+            .all()\n+        )\n         \"\"\"\n         Retrieves staff tip distribution records for a specific staff member.\n         (This functionality might also live in StaffTipService)\n         \"\"\"\n-        query = self.db.query(StaffTipDistributionRecord).filter(StaffTipDistributionRecord.staff_id == staff_id)\n+        query = self.db.query(StaffTipDistributionRecord).filter(\n+            StaffTipDistributionRecord.staff_id == staff_id\n+        )\n         if start_date:\n-            query = query.filter(StaffTipDistributionRecord.distribution_timestamp >= start_date)\n+            query = query.filter(\n+                StaffTipDistributionRecord.distribution_timestamp >= start_date\n+            )\n         if end_date:\n-            query = query.filter(StaffTipDistributionRecord.distribution_timestamp <= end_date)\n-        return query.order_by(StaffTipDistributionRecord.distribution_timestamp.desc()).all()\n+            query = query.filter(\n+                StaffTipDistributionRecord.distribution_timestamp <= end_date\n+            )\n+        return query.order_by(\n+            StaffTipDistributionRecord.distribution_timestamp.desc()\n+        ).all()\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/email_service.py\t2025-08-02 21:56:59.002703+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/email_service.py\t2025-08-02 22:36:03.849966+00:00\n@@ -14,106 +14,125 @@\n logger = logging.getLogger(__name__)\n \n # Define TYPES for backward compatibility\n TYPES = Literal[\"sale\", \"refund\"]\n \n+\n class EmailService:\n     \"\"\"Email service using Resend API for transactional emails\"\"\"\n-    \n+\n     def __init__(self):\n         \"\"\"Initialize Resend email service\"\"\"\n         try:\n             # Get configuration from settings\n             self.api_key = settings.RESEND_API_KEY\n             self.from_addr = settings.RESEND_FROM_EMAIL\n             self.from_name = settings.RESEND_FROM_NAME\n-            \n+\n             if not self.api_key:\n                 logger.error(\"RESEND_API_KEY not configured\")\n                 self.sg = None  # Keep for backward compatibility\n                 self.env = None\n                 return\n-            \n+\n             # Configure Resend\n             resend.api_key = self.api_key\n-            \n+\n             # Setup Jinja2 for email templates - same path structure as before\n-            templates_dir = Path(__file__).resolve().parent.parent / \"templates\" / \"email\"\n+            templates_dir = (\n+                Path(__file__).resolve().parent.parent / \"templates\" / \"email\"\n+            )\n             if not templates_dir.exists():\n-                logger.info(f\"Templates directory {templates_dir} does not exist. Creating it.\")\n+                logger.info(\n+                    f\"Templates directory {templates_dir} does not exist. Creating it.\"\n+                )\n                 templates_dir.mkdir(parents=True, exist_ok=True)\n \n             self.env = Environment(\n                 loader=FileSystemLoader(str(templates_dir)),\n-                autoescape=select_autoescape([\"html\", \"xml\"])\n-            )\n-            \n+                autoescape=select_autoescape([\"html\", \"xml\"]),\n+            )\n+\n             # Set sg to True for backward compatibility checks\n             self.sg = True\n-            \n-            logger.info(f\"EmailService initialized with Resend - From: {self.from_addr}\")\n-            \n+\n+            logger.info(\n+                f\"EmailService initialized with Resend - From: {self.from_addr}\"\n+            )\n+\n         except Exception as e:\n             logger.exception(f\"Error initializing EmailService: {e}\")\n             self.sg = None\n             self.env = None\n-    \n+\n     def send_receipt(self, *, order: Any, type_: TYPES, amount: float) -> bool:\n         \"\"\"\n         Send receipt email for sale or refund\n-        \n+\n         Args:\n             order: Order object with order details\n             type_: Email type (\"sale\" or \"refund\")\n             amount: Transaction amount\n-            \n+\n         Returns:\n             bool: True if email sent successfully, False otherwise\n         \"\"\"\n         if not self.sg or not self.env:\n-            logger.error(\"EmailService not properly initialized (Resend client or Jinja env missing). Cannot send email.\")\n-            return False\n-\n-        if not hasattr(order, 'customer_email') or not order.customer_email:\n-            logger.info(f\"Order #{getattr(order, 'order_number', getattr(order, 'number', 'N/A'))} has no customer_email. Skipping receipt sending.\")\n+            logger.error(\n+                \"EmailService not properly initialized (Resend client or Jinja env missing). Cannot send email.\"\n+            )\n+            return False\n+\n+        if not hasattr(order, \"customer_email\") or not order.customer_email:\n+            logger.info(\n+                f\"Order #{getattr(order, 'order_number', getattr(order, 'number', 'N/A'))} has no customer_email. Skipping receipt sending.\"\n+            )\n             return False\n \n         try:\n             # Generate email content from template\n             template_name = \"receipt.html\"\n             tmpl = self.env.get_template(template_name)\n             html_content = tmpl.render(order=order, type=type_, amount=amount)\n-            \n+\n             # Determine email subject\n-            order_number = getattr(order, 'order_number', getattr(order, 'number', 'N/A'))\n+            order_number = getattr(\n+                order, \"order_number\", getattr(order, \"number\", \"N/A\")\n+            )\n             subject = f\"Fynlo \u2013 {'Refund' if type_=='refund' else 'Receipt'} for #{order_number}\"\n-            \n+\n             # Send email using Resend\n             params = {\n                 \"from\": f\"{self.from_name} <{self.from_addr}>\",\n                 \"to\": [order.customer_email],\n                 \"subject\": subject,\n                 \"html\": html_content,\n                 \"tags\": [\n                     {\"name\": \"category\", \"value\": \"receipt\"},\n                     {\"name\": \"type\", \"value\": type_},\n-                    {\"name\": \"order_id\", \"value\": str(getattr(order, 'id', 'unknown'))}\n-                ]\n+                    {\"name\": \"order_id\", \"value\": str(getattr(order, \"id\", \"unknown\"))},\n+                ],\n             }\n-            \n+\n             response = resend.Emails.send(params)\n-            \n+\n             # Check response\n-            if response and hasattr(response, 'get') and response.get('id'):\n-                logger.info(f\"Receipt email sent for order #{order_number} to {order.customer_email}. Type: {type_}. Resend ID: {response['id']}\")\n+            if response and hasattr(response, \"get\") and response.get(\"id\"):\n+                logger.info(\n+                    f\"Receipt email sent for order #{order_number} to {order.customer_email}. Type: {type_}. Resend ID: {response['id']}\"\n+                )\n                 return True\n             else:\n-                logger.error(f\"Failed to send receipt email - Invalid response: {response}\")\n-                return False\n-                \n-        except Exception as e:\n-            logger.exception(f\"Error sending receipt email for order #{getattr(order, 'order_number', 'N/A')}: {e}\")\n+                logger.error(\n+                    f\"Failed to send receipt email - Invalid response: {response}\"\n+                )\n+                return False\n+\n+        except Exception as e:\n+            logger.exception(\n+                f\"Error sending receipt email for order #{getattr(order, 'order_number', 'N/A')}: {e}\"\n+            )\n             return False\n         \"\"\"\n         Send custom email with HTML content\n         \n         Args:\n@@ -126,60 +145,67 @@\n             bool: True if sent successfully, False otherwise\n         \"\"\"\n         if not self.sg:\n             logger.error(\"EmailService not properly initialized. Cannot send email.\")\n             return False\n-            \n+\n         try:\n             params = {\n                 \"from\": f\"{self.from_name} <{self.from_addr}>\",\n                 \"to\": [to_email],\n                 \"subject\": subject,\n-                \"html\": html_content\n+                \"html\": html_content,\n             }\n-            \n+\n             # Add tags if provided\n             if tags:\n                 params[\"tags\"] = [{\"name\": k, \"value\": v} for k, v in tags.items()]\n-            \n+\n             response = resend.Emails.send(params)\n-            \n-            if response and hasattr(response, 'get') and response.get('id'):\n-                logger.info(f\"Custom email sent successfully to {to_email} - ID: {response['id']}\")\n+\n+            if response and hasattr(response, \"get\") and response.get(\"id\"):\n+                logger.info(\n+                    f\"Custom email sent successfully to {to_email} - ID: {response['id']}\"\n+                )\n                 return True\n             else:\n-                logger.error(f\"Failed to send custom email - Invalid response: {response}\")\n-                return False\n-                \n+                logger.error(\n+                    f\"Failed to send custom email - Invalid response: {response}\"\n+                )\n+                return False\n+\n         except Exception as e:\n             logger.error(f\"Error sending custom email: {str(e)}\")\n             return False\n-    \n+\n     def test_connection(self) -> bool:\n         \"\"\"Test Resend API connection\"\"\"\n         try:\n             if not self.sg:\n                 logger.error(\"Resend not properly initialized\")\n                 return False\n-                \n+\n             # Send a test email to verify configuration\n-            response = resend.Emails.send({\n-                \"from\": f\"{self.from_name} <{self.from_addr}>\",\n-                \"to\": [self.from_addr],  # Send to ourselves\n-                \"subject\": \"Resend Configuration Test\",\n-                \"html\": \"<p>This is a test email to verify Resend configuration.</p>\"\n-            })\n-            \n-            if response and hasattr(response, 'get') and response.get('id'):\n+            response = resend.Emails.send(\n+                {\n+                    \"from\": f\"{self.from_name} <{self.from_addr}>\",\n+                    \"to\": [self.from_addr],  # Send to ourselves\n+                    \"subject\": \"Resend Configuration Test\",\n+                    \"html\": \"<p>This is a test email to verify Resend configuration.</p>\",\n+                }\n+            )\n+\n+            if response and hasattr(response, \"get\") and response.get(\"id\"):\n                 logger.info(\"Resend connection test successful\")\n                 return True\n             else:\n                 logger.error(\"Resend connection test failed\")\n                 return False\n-                \n+\n         except Exception as e:\n             logger.error(f\"Resend connection test error: {str(e)}\")\n             return False\n \n+\n # Example Usage (for testing or if run directly, though typically not)\n-if __name__ == '__main__':\n-    logger.info(\"EmailService module loaded. Now using Resend instead of SendGrid.\")\n\\ No newline at end of file\n+if __name__ == \"__main__\":\n+    logger.info(\"EmailService module loaded. Now using Resend instead of SendGrid.\")\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/inventory_service.py\t2025-08-02 19:23:36.830494+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/inventory_service.py\t2025-08-02 22:36:03.863953+00:00\n@@ -1,27 +1,37 @@\n \"\"\"\n Service layer for advanced inventory operations, including recipe deductions.\n \"\"\"\n+\n from sqlalchemy.orm import Session\n from sqlalchemy import func\n from typing import List, Optional, Dict, Tuple\n from uuid import UUID\n from app.core.exceptions import InventoryException\n-import logging # For logging stock_overdrawn events\n-\n-from app.models import Order as OrderModel, Recipe as RecipeModel, InventoryItem as InventoryItemModel, InventoryLedgerEntry as InventoryLedgerModel\n+import logging  # For logging stock_overdrawn events\n+\n+from app.models import (\n+    Order as OrderModel,\n+    Recipe as RecipeModel,\n+    InventoryItem as InventoryItemModel,\n+    InventoryLedgerEntry as InventoryLedgerModel,\n+)\n from app.crud import inventory as crud_inventory\n from app.core.websocket import WebSocketManager\n+\n # from app.services.audit_logger import AuditLoggerService # Assuming an audit logger service\n \n logger = logging.getLogger(__name__)\n # audit_logger = AuditLoggerService() # Initialize if you have a dedicated audit logger\n+\n \n async def apply_recipe_deductions_for_order(\n     db: Session,\n     order_id: UUID,\n-    websocket_manager: Optional[WebSocketManager] = None  # Optional: for real-time updates\n+    websocket_manager: Optional[\n+        WebSocketManager\n+    ] = None,  # Optional: for real-time updates\n ) -> List[Tuple[InventoryItemModel, InventoryLedgerModel]]:\n     \"\"\"\n     Applies recipe deductions for all items in a confirmed order.\n     Logs stock_overdrawn events if an item's quantity drops to zero due to deduction.\n     Emits WebSocket events for inventory updates.\n@@ -41,78 +51,118 @@\n     order = db.query(OrderModel).filter(OrderModel.id == order_id).first()\n     if not order:\n         logger.warning(f\"Order ID {order_id} not found for recipe deduction.\")\n         return []\n \n-    if order.status != \"confirmed\" and order.status != \"completed\": # Or whatever status indicates it's ready for deduction\n-        logger.info(f\"Order ID {order_id} is not in a state for inventory deduction (status: {order.status}). Skipping.\")\n+    if (\n+        order.status != \"confirmed\" and order.status != \"completed\"\n+    ):  # Or whatever status indicates it's ready for deduction\n+        logger.info(\n+            f\"Order ID {order_id} is not in a state for inventory deduction (status: {order.status}). Skipping.\"\n+        )\n         return []\n \n-    updated_inventory_and_ledger_entries: List[Tuple[InventoryItemModel, InventoryLedgerModel]] = []\n+    updated_inventory_and_ledger_entries: List[\n+        Tuple[InventoryItemModel, InventoryLedgerModel]\n+    ] = []\n \n     # Order.items is expected to be a JSONB field like:\n     # [{\"product_id\": \"uuid\", \"quantity\": 2, \"price_at_sale\": 10.99}, ...]\n     # We need to ensure 'product_id' and 'quantity' are present.\n \n     if not order.items or not isinstance(order.items, list):\n-        logger.warning(f\"Order ID {order_id} has no items or items are malformed. Skipping deduction.\")\n+        logger.warning(\n+            f\"Order ID {order_id} has no items or items are malformed. Skipping deduction.\"\n+        )\n         return []\n \n     # Aggregate deductions per SKU to make fewer DB calls if an ingredient is in multiple recipes\n-    aggregated_deductions: Dict[str, int] = {} # sku: total_quantity_to_deduct\n+    aggregated_deductions: Dict[str, int] = {}  # sku: total_quantity_to_deduct\n \n     for order_item_data in order.items:\n-        if not isinstance(order_item_data, dict) or \"product_id\" not in order_item_data or \"quantity\" not in order_item_data:\n-            logger.error(f\"Malformed order item in order {order_id}: {order_item_data}. Skipping this item.\")\n+        if (\n+            not isinstance(order_item_data, dict)\n+            or \"product_id\" not in order_item_data\n+            or \"quantity\" not in order_item_data\n+        ):\n+            logger.error(\n+                f\"Malformed order item in order {order_id}: {order_item_data}. Skipping this item.\"\n+            )\n             continue\n \n         product_id_str = order_item_data.get(\"product_id\")\n         quantity_ordered = order_item_data.get(\"quantity\")\n \n-        if not product_id_str or not isinstance(quantity_ordered, (int, float)) or quantity_ordered <= 0:\n-            logger.warning(f\"Invalid product_id or quantity for item in order {order_id}. Skipping item.\")\n+        if (\n+            not product_id_str\n+            or not isinstance(quantity_ordered, (int, float))\n+            or quantity_ordered <= 0\n+        ):\n+            logger.warning(\n+                f\"Invalid product_id or quantity for item in order {order_id}. Skipping item.\"\n+            )\n             continue\n \n         try:\n             product_id = UUID(product_id_str)\n         except ValueError:\n-            logger.error(f\"Invalid UUID format for product_id '{product_id_str}' in order {order_id}. Skipping item.\")\n+            logger.error(\n+                f\"Invalid UUID format for product_id '{product_id_str}' in order {order_id}. Skipping item.\"\n+            )\n             continue\n \n         # Fetch the recipe for this product\n-        recipe_ingredients = db.query(RecipeModel).filter(RecipeModel.item_id == product_id).all()\n+        recipe_ingredients = (\n+            db.query(RecipeModel).filter(RecipeModel.item_id == product_id).all()\n+        )\n \n         if not recipe_ingredients:\n             # Product might not have a recipe, which is fine. Log for info if needed.\n             # logger.info(f\"Product ID {product_id} in order {order_id} has no recipe. No deductions for this item.\")\n             continue\n \n         for recipe_ingredient in recipe_ingredients:\n-            total_deduction_for_ingredient = recipe_ingredient.qty_g * int(quantity_ordered)\n-\n-            current_total = aggregated_deductions.get(recipe_ingredient.ingredient_sku, 0)\n-            aggregated_deductions[recipe_ingredient.ingredient_sku] = current_total + total_deduction_for_ingredient\n+            total_deduction_for_ingredient = recipe_ingredient.qty_g * int(\n+                quantity_ordered\n+            )\n+\n+            current_total = aggregated_deductions.get(\n+                recipe_ingredient.ingredient_sku, 0\n+            )\n+            aggregated_deductions[recipe_ingredient.ingredient_sku] = (\n+                current_total + total_deduction_for_ingredient\n+            )\n \n     # Apply aggregated deductions\n     skus_updated = []\n     for sku, total_qty_to_deduct in aggregated_deductions.items():\n-        if total_qty_to_deduct == 0: # Should not happen if qty_g > 0 and quantity_ordered > 0\n-            continue\n-\n-        inventory_item = db.query(InventoryItemModel).filter(InventoryItemModel.sku == sku).first()\n+        if (\n+            total_qty_to_deduct == 0\n+        ):  # Should not happen if qty_g > 0 and quantity_ordered > 0\n+            continue\n+\n+        inventory_item = (\n+            db.query(InventoryItemModel).filter(InventoryItemModel.sku == sku).first()\n+        )\n         if not inventory_item:\n-            logger.error(f\"Inventory item with SKU {sku} not found for recipe deduction in order {order_id}. Deduction skipped for this SKU.\")\n+            logger.error(\n+                f\"Inventory item with SKU {sku} not found for recipe deduction in order {order_id}. Deduction skipped for this SKU.\"\n+            )\n             continue\n \n         original_qty = inventory_item.qty_g\n \n         # Calculate actual change, ensuring quantity doesn't go below 0\n         if inventory_item.qty_g - total_qty_to_deduct < 0:\n-            actual_deducted_amount = inventory_item.qty_g # Deduct only what's available\n+            actual_deducted_amount = (\n+                inventory_item.qty_g\n+            )  # Deduct only what's available\n             inventory_item.qty_g = 0\n             # Log stock_overdrawn event\n-            logger.warning(f\"Stock overdrawn for SKU {sku} (Order ID: {order_id}). Original: {original_qty}, Requested: {total_qty_to_deduct}, Deducted: {actual_deducted_amount}, New Qty: 0.\")\n+            logger.warning(\n+                f\"Stock overdrawn for SKU {sku} (Order ID: {order_id}). Original: {original_qty}, Requested: {total_qty_to_deduct}, Deducted: {actual_deducted_amount}, New Qty: 0.\"\n+            )\n             # audit_logger.log_event(\n             #     event_type=\"stock_overdrawn\",\n             #     details={\n             #         \"sku\": sku,\n             #         \"order_id\": str(order_id),\n@@ -133,11 +183,11 @@\n         # Note: delta_g is negative for deductions\n         ledger_entry = InventoryLedgerModel(\n             sku=sku,\n             delta_g=-actual_deducted_amount,\n             source=\"order_fulfillment\",\n-            source_id=str(order_id)\n+            source_id=str(order_id),\n         )\n         db.add(ledger_entry)\n         updated_inventory_and_ledger_entries.append((inventory_item, ledger_entry))\n         skus_updated.append(sku)\n \n@@ -151,31 +201,38 @@\n             # Emit WebSocket event for updated SKUs\n             if websocket_manager and skus_updated:\n                 # Fetch the latest state of updated items for the payload\n                 updated_items_payload = []\n                 for sku_val in skus_updated:\n-                    item = crud_inventory.get_inventory_item(db, sku_val) # Re-fetch to get committed state\n+                    item = crud_inventory.get_inventory_item(\n+                        db, sku_val\n+                    )  # Re-fetch to get committed state\n                     if item:\n-                         updated_items_payload.append({\n-                            \"sku\": item.sku,\n-                            \"name\": item.name,\n-                            \"qty_g\": item.qty_g,\n-                            \"par_level_g\": item.par_level_g,\n-                            \"unit\": item.unit,\n-                            \"last_updated\": item.last_updated.isoformat()\n-                        })\n+                        updated_items_payload.append(\n+                            {\n+                                \"sku\": item.sku,\n+                                \"name\": item.name,\n+                                \"qty_g\": item.qty_g,\n+                                \"par_level_g\": item.par_level_g,\n+                                \"unit\": item.unit,\n+                                \"last_updated\": item.last_updated.isoformat(),\n+                            }\n+                        )\n                 if updated_items_payload:\n                     # Consider rate limiting or batching if many items are updated frequently\n-                    await websocket_manager.broadcast_json({\n-                        \"event\": \"inventory.updated\",\n-                        \"data\": updated_items_payload\n-                    })\n-                    logger.info(f\"Broadcasted inventory.updated event for {len(updated_items_payload)} items from order {order_id}.\")\n+                    await websocket_manager.broadcast_json(\n+                        {\"event\": \"inventory.updated\", \"data\": updated_items_payload}\n+                    )\n+                    logger.info(\n+                        f\"Broadcasted inventory.updated event for {len(updated_items_payload)} items from order {order_id}.\"\n+                    )\n \n         except Exception as e:\n             db.rollback()\n-            logger.error(f\"Error committing recipe deductions for order {order_id}: {e}\")\n+            logger.error(\n+                f\"Error committing recipe deductions for order {order_id}: {e}\"\n+            )\n             # Potentially re-raise or handle more gracefully\n             raise\n \n     return updated_inventory_and_ledger_entries\n \n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/ocr_service.py\t2025-08-02 22:09:30.519032+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/ocr_service.py\t2025-08-02 22:36:03.868057+00:00\n@@ -1,10 +1,11 @@\n from typing import List, Dict, Any\n \n # Placeholder for ScannedItemResponse if not centrally defined\n # from app.api.v1.endpoints.inventory import ScannedItemResponse\n # For now, let's define a similar structure here or assume it's passed appropriately.\n+\n \n class OCRService:\n     def __init__(self, ocr_provider_config: Dict[str, Any] = None):\n         \"\"\"\n         Initializes the OCR service.\n@@ -47,24 +48,60 @@\n \n         # Mock response based on some characteristic of the image_bytes if possible,\n         # or just return a fixed mock response.\n         # This is a very naive check just for basic mock differentiation.\n         try:\n-            decoded_string_for_check = image_bytes.decode('utf-8', errors='ignore')\n+            decoded_string_for_check = image_bytes.decode(\"utf-8\", errors=\"ignore\")\n             if \"milk\" in decoded_string_for_check.lower():\n-                 return [\n-                    {\"raw_text_name\": \"Milk 1L\", \"raw_text_quantity\": \"2\", \"raw_text_price\": \"1.50\", \"parsed_quantity\": 2.0, \"parsed_price\": 1.50},\n-                    {\"raw_text_name\": \"Bread Loaf\", \"raw_text_quantity\": \"1\", \"raw_text_price\": \"2.20\", \"parsed_quantity\": 1.0, \"parsed_price\": 2.20},\n-                    {\"raw_text_name\": \"Organic Eggs\", \"raw_text_quantity\": \"1 dz\", \"raw_text_price\": \"4.99\", \"parsed_quantity\": 1.0, \"parsed_price\": 4.99},\n+                return [\n+                    {\n+                        \"raw_text_name\": \"Milk 1L\",\n+                        \"raw_text_quantity\": \"2\",\n+                        \"raw_text_price\": \"1.50\",\n+                        \"parsed_quantity\": 2.0,\n+                        \"parsed_price\": 1.50,\n+                    },\n+                    {\n+                        \"raw_text_name\": \"Bread Loaf\",\n+                        \"raw_text_quantity\": \"1\",\n+                        \"raw_text_price\": \"2.20\",\n+                        \"parsed_quantity\": 1.0,\n+                        \"parsed_price\": 2.20,\n+                    },\n+                    {\n+                        \"raw_text_name\": \"Organic Eggs\",\n+                        \"raw_text_quantity\": \"1 dz\",\n+                        \"raw_text_price\": \"4.99\",\n+                        \"parsed_quantity\": 1.0,\n+                        \"parsed_price\": 4.99,\n+                    },\n                 ]\n         except Exception:\n-            pass # Ignore if it's not easily decodable for a simple check\n+            pass  # Ignore if it's not easily decodable for a simple check\n \n         return [\n-            {\"raw_text_name\": \"Generic Item A\", \"raw_text_quantity\": \"1\", \"raw_text_price\": \"10.00\", \"parsed_quantity\": 1.0, \"parsed_price\": 10.00},\n-            {\"raw_text_name\": \"Another Item B\", \"raw_text_quantity\": \"3 units\", \"raw_text_price\": \"7.50\", \"parsed_quantity\": 3.0, \"parsed_price\": 7.50},\n-            {\"raw_text_name\": \"Service Charge\", \"raw_text_quantity\": \"\", \"raw_text_price\": \"1.20\", \"parsed_quantity\": None, \"parsed_price\": 1.20}, # Example of non-item\n+            {\n+                \"raw_text_name\": \"Generic Item A\",\n+                \"raw_text_quantity\": \"1\",\n+                \"raw_text_price\": \"10.00\",\n+                \"parsed_quantity\": 1.0,\n+                \"parsed_price\": 10.00,\n+            },\n+            {\n+                \"raw_text_name\": \"Another Item B\",\n+                \"raw_text_quantity\": \"3 units\",\n+                \"raw_text_price\": \"7.50\",\n+                \"parsed_quantity\": 3.0,\n+                \"parsed_price\": 7.50,\n+            },\n+            {\n+                \"raw_text_name\": \"Service Charge\",\n+                \"raw_text_quantity\": \"\",\n+                \"raw_text_price\": \"1.20\",\n+                \"parsed_quantity\": None,\n+                \"parsed_price\": 1.20,\n+            },  # Example of non-item\n         ]\n \n     def _extract_text_from_ocr_response(self, ocr_response: Any) -> str:\n         \"\"\"\n         Helper to extract raw text from actual OCR provider's response.\n@@ -73,11 +110,13 @@\n         # Example for Google Vision:\n         # texts = ocr_response.text_annotations\n         # if texts:\n         #     return texts[0].description\n         # return \"\"\n-        raise NotImplementedError(\"Actual OCR response parsing not implemented in mock.\")\n+        raise NotImplementedError(\n+            \"Actual OCR response parsing not implemented in mock.\"\n+        )\n \n     def _parse_line_items_from_text(self, raw_text: str) -> List[Dict[str, Any]]:\n         \"\"\"\n         Parses raw text (presumably lines from a receipt) into structured line items.\n         This involves regex and string manipulation.\n@@ -85,11 +124,14 @@\n         # Complex logic with regex to find item names, quantities, prices\n         # Example patterns:\n         # - Quantity: \\d+\\s*(pcs?|kg|g|ltr|ml|dozen|dz)?\n         # - Price: \\\u00a3?\\d+\\.\\d{2}\n         # - Item name: usually the text before quantity and price on a line\n-        raise NotImplementedError(\"Actual line item parsing from text not implemented in mock.\")\n+        raise NotImplementedError(\n+            \"Actual line item parsing from text not implemented in mock.\"\n+        )\n+\n \n # Example of how this service might be instantiated and used:\n # ocr_service_instance = OCRService(ocr_provider_config={\"provider\": \"mock\"})\n # image_content = b\"some image data\"\n # parsed_data = await ocr_service_instance.parse_receipt_image(image_content)\n@@ -106,10 +148,11 @@\n #         # Find the SKU for the matched name\n #         matched_product = next((p for p in product_list if p[\"name\"] == match[0]), None)\n #         return matched_product[\"sku\"] if matched_product else None\n #     return None\n \n+\n def get_ocr_service():\n     \"\"\"Execute get_ocr_service operation.\"\"\"\n     # This function can be used for dependency injection in FastAPI\n     # It can load configuration for the OCR provider from environment variables or a config file\n     # For now, returns a mock instance\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/scripts/migrate_to_platform_settings.py\t2025-08-02 22:11:31.089281+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/scripts/migrate_to_platform_settings.py\t2025-08-02 22:36:03.874586+00:00\n@@ -17,47 +17,50 @@\n # Add parent directory to path to import app modules\n sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n \n from app.core.database import SessionLocal, Restaurant, Platform\n from app.models.platform_config import (\n-    PlatformConfiguration, \n-    RestaurantOverride, \n+    PlatformConfiguration,\n+    RestaurantOverride,\n     ConfigurationAudit,\n     PlatformFeatureFlag,\n     DEFAULT_PLATFORM_CONFIGS,\n-    DEFAULT_FEATURE_FLAGS\n+    DEFAULT_FEATURE_FLAGS,\n )\n \n # Configure logging\n logging.basicConfig(\n     level=logging.INFO,\n-    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n+    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n     handlers=[\n-        logging.FileHandler(f'migration_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log'),\n-        logging.StreamHandler()\n-    ]\n+        logging.FileHandler(\n+            f'migration_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log'\n+        ),\n+        logging.StreamHandler(),\n+    ],\n )\n \n logger = logging.getLogger(__name__)\n+\n \n class PlatformSettingsMigration:\n     \"\"\"Main migration class for converting restaurant settings to platform architecture\"\"\"\n-    \n+\n     def __init__(self, dry_run: bool = True):\n         self.dry_run = dry_run\n         self.db: Session = SessionLocal()\n         self.migration_stats = {\n-            'restaurants_processed': 0,\n-            'settings_migrated': 0,\n-            'overrides_created': 0,\n-            'errors': 0,\n-            'warnings': 0\n+            \"restaurants_processed\": 0,\n+            \"settings_migrated\": 0,\n+            \"overrides_created\": 0,\n+            \"errors\": 0,\n+            \"warnings\": 0,\n         }\n-        \n+\n     def __enter__(self):\n         return self\n-        \n+\n     def __exit__(self, exc_type, exc_val, exc_tb):\n         if not self.dry_run:\n             if exc_type is None:\n                 self.db.commit()\n                 logger.info(\"Migration completed successfully - changes committed\")\n@@ -65,370 +68,435 @@\n                 self.db.rollback()\n                 logger.error(\"Migration failed - changes rolled back\")\n         else:\n             self.db.rollback()\n             logger.info(\"DRY RUN - No changes committed to database\")\n-        \n+\n         self.db.close()\n-        \n+\n     def run_migration(self) -> bool:\n         \"\"\"Execute the complete migration process\"\"\"\n         logger.info(f\"Starting platform settings migration (DRY RUN: {self.dry_run})\")\n-        \n+\n         try:\n             # Step 1: Initialize platform configurations\n             logger.info(\"Step 1: Initializing platform configurations...\")\n             self.initialize_platform_configs()\n-            \n+\n             # Step 2: Identify restaurants with payment settings\n             logger.info(\"Step 2: Analyzing existing restaurant settings...\")\n             restaurants_to_migrate = self.identify_restaurants_to_migrate()\n-            logger.info(f\"Found {len(restaurants_to_migrate)} restaurants requiring migration\")\n-            \n+            logger.info(\n+                f\"Found {len(restaurants_to_migrate)} restaurants requiring migration\"\n+            )\n+\n             # Step 3: Create backup of current settings\n             logger.info(\"Step 3: Creating backup of current settings...\")\n             self.create_settings_backup()\n-            \n+\n             # Step 4: Migrate restaurant payment settings\n             logger.info(\"Step 4: Migrating restaurant payment settings...\")\n             for restaurant in restaurants_to_migrate:\n                 self.migrate_restaurant_settings(restaurant)\n-            \n+\n             # Step 5: Validate migration results\n             logger.info(\"Step 5: Validating migration results...\")\n             validation_result = self.validate_migration()\n-            \n+\n             # Step 6: Generate migration report\n             logger.info(\"Step 6: Generating migration report...\")\n             self.generate_migration_report()\n-            \n+\n             if validation_result:\n                 logger.info(\"Migration completed successfully!\")\n                 return True\n             else:\n                 logger.error(\"Migration validation failed!\")\n                 return False\n-                \n+\n         except Exception as e:\n             logger.error(f\"Migration failed with error: {e}\", exc_info=True)\n-            self.migration_stats['errors'] += 1\n+            self.migration_stats[\"errors\"] += 1\n             return False\n-    \n+\n     def initialize_platform_configs(self) -> None:\n         \"\"\"Initialize platform with default configurations\"\"\"\n-        \n+\n         # Add default platform configurations\n         for config_data in DEFAULT_PLATFORM_CONFIGS:\n-            existing = self.db.query(PlatformConfiguration).filter(\n-                PlatformConfiguration.config_key == config_data['config_key']\n-            ).first()\n-            \n+            existing = (\n+                self.db.query(PlatformConfiguration)\n+                .filter(PlatformConfiguration.config_key == config_data[\"config_key\"])\n+                .first()\n+            )\n+\n             if not existing:\n                 config = PlatformConfiguration(**config_data)\n                 self.db.add(config)\n                 logger.info(f\"Added platform config: {config_data['config_key']}\")\n-        \n+\n         # Add default feature flags\n         for flag_data in DEFAULT_FEATURE_FLAGS:\n-            existing = self.db.query(PlatformFeatureFlag).filter(\n-                PlatformFeatureFlag.feature_key == flag_data['feature_key']\n-            ).first()\n-            \n+            existing = (\n+                self.db.query(PlatformFeatureFlag)\n+                .filter(PlatformFeatureFlag.feature_key == flag_data[\"feature_key\"])\n+                .first()\n+            )\n+\n             if not existing:\n                 flag = PlatformFeatureFlag(**flag_data)\n                 self.db.add(flag)\n                 logger.info(f\"Added feature flag: {flag_data['feature_key']}\")\n-        \n+\n         if not self.dry_run:\n             self.db.flush()  # Make configs available for subsequent operations\n-    \n+\n     def identify_restaurants_to_migrate(self) -> List[Restaurant]:\n         \"\"\"Identify restaurants that have payment settings requiring migration\"\"\"\n-        \n+\n         restaurants_with_payment_settings = []\n-        \n+\n         # Query all restaurants\n         restaurants = self.db.query(Restaurant).all()\n-        \n+\n         for restaurant in restaurants:\n             if self.has_payment_settings(restaurant):\n                 restaurants_with_payment_settings.append(restaurant)\n-                \n+\n         return restaurants_with_payment_settings\n-    \n+\n     def has_payment_settings(self, restaurant: Restaurant) -> bool:\n         \"\"\"Check if restaurant has payment-related settings that need migration\"\"\"\n-        \n+\n         if not restaurant.settings:\n             return False\n-            \n+\n         # Look for payment-related settings in restaurant.settings JSON\n         payment_related_keys = [\n-            'paymentMethods',\n-            'paymentFees', \n-            'stripeConfig',\n-            'squareConfig',\n-            'sumupConfig',\n-            'paymentProcessing',\n-            'feeStructure'\n+            \"paymentMethods\",\n+            \"paymentFees\",\n+            \"stripeConfig\",\n+            \"squareConfig\",\n+            \"sumupConfig\",\n+            \"paymentProcessing\",\n+            \"feeStructure\",\n         ]\n-        \n+\n         settings_data = restaurant.settings\n         for key in payment_related_keys:\n             if key in settings_data:\n                 logger.info(f\"Restaurant {restaurant.name} has payment setting: {key}\")\n                 return True\n-                \n+\n         return False\n-    \n+\n     def create_settings_backup(self) -> None:\n         \"\"\"Create a backup of all current restaurant settings\"\"\"\n-        \n+\n         backup_filename = f\"restaurant_settings_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n-        \n+\n         try:\n             restaurants = self.db.query(Restaurant).all()\n             backup_data = {\n-                'timestamp': datetime.now().isoformat(),\n-                'migration_type': 'platform_settings',\n-                'restaurants': []\n+                \"timestamp\": datetime.now().isoformat(),\n+                \"migration_type\": \"platform_settings\",\n+                \"restaurants\": [],\n             }\n-            \n+\n             for restaurant in restaurants:\n                 restaurant_data = {\n-                    'id': str(restaurant.id),\n-                    'name': restaurant.name,\n-                    'platform_id': str(restaurant.platform_id) if restaurant.platform_id else None,\n-                    'settings': restaurant.settings,\n-                    'tax_configuration': restaurant.tax_configuration\n+                    \"id\": str(restaurant.id),\n+                    \"name\": restaurant.name,\n+                    \"platform_id\": (\n+                        str(restaurant.platform_id) if restaurant.platform_id else None\n+                    ),\n+                    \"settings\": restaurant.settings,\n+                    \"tax_configuration\": restaurant.tax_configuration,\n                 }\n-                backup_data['restaurants'].append(restaurant_data)\n-            \n-            with open(backup_filename, 'w') as f:\n+                backup_data[\"restaurants\"].append(restaurant_data)\n+\n+            with open(backup_filename, \"w\") as f:\n                 json.dump(backup_data, f, indent=2, default=str)\n-                \n+\n             logger.info(f\"Settings backup created: {backup_filename}\")\n-            \n+\n         except Exception as e:\n             logger.error(f\"Failed to create backup: {e}\")\n             raise\n-    \n+\n     def migrate_restaurant_settings(self, restaurant: Restaurant) -> None:\n         \"\"\"Migrate settings for a single restaurant\"\"\"\n-        \n+\n         try:\n-            logger.info(f\"Migrating settings for restaurant: {restaurant.name} ({restaurant.id})\")\n-            \n+            logger.info(\n+                f\"Migrating settings for restaurant: {restaurant.name} ({restaurant.id})\"\n+            )\n+\n             if not restaurant.settings:\n                 logger.warning(f\"No settings found for restaurant {restaurant.name}\")\n                 return\n-            \n+\n             settings_data = restaurant.settings\n             migrated_settings = {}\n-            \n+\n             # Migrate payment method configurations\n-            if 'paymentMethods' in settings_data:\n-                self.migrate_payment_methods(restaurant, settings_data['paymentMethods'])\n-                migrated_settings['paymentMethods'] = settings_data['paymentMethods']\n-            \n+            if \"paymentMethods\" in settings_data:\n+                self.migrate_payment_methods(\n+                    restaurant, settings_data[\"paymentMethods\"]\n+                )\n+                migrated_settings[\"paymentMethods\"] = settings_data[\"paymentMethods\"]\n+\n             # Migrate payment fees (convert to restaurant overrides if they differ from platform defaults)\n-            if 'paymentFees' in settings_data:\n-                self.migrate_payment_fees(restaurant, settings_data['paymentFees'])\n-                migrated_settings['paymentFees'] = settings_data['paymentFees']\n-            \n+            if \"paymentFees\" in settings_data:\n+                self.migrate_payment_fees(restaurant, settings_data[\"paymentFees\"])\n+                migrated_settings[\"paymentFees\"] = settings_data[\"paymentFees\"]\n+\n             # Migrate provider configurations\n-            for provider in ['stripeConfig', 'squareConfig', 'sumupConfig']:\n+            for provider in [\"stripeConfig\", \"squareConfig\", \"sumupConfig\"]:\n                 if provider in settings_data:\n-                    self.migrate_provider_config(restaurant, provider, settings_data[provider])\n+                    self.migrate_provider_config(\n+                        restaurant, provider, settings_data[provider]\n+                    )\n                     migrated_settings[provider] = settings_data[provider]\n-            \n+\n             # Remove migrated payment settings from restaurant.settings\n-            new_settings = {k: v for k, v in settings_data.items() if k not in migrated_settings}\n-            \n+            new_settings = {\n+                k: v for k, v in settings_data.items() if k not in migrated_settings\n+            }\n+\n             # Update restaurant settings (remove migrated items)\n             if not self.dry_run:\n                 restaurant.settings = new_settings\n                 self.db.flush()\n-            \n+\n             # Create audit record for this migration\n             self.create_migration_audit_record(restaurant, migrated_settings)\n-            \n-            self.migration_stats['restaurants_processed'] += 1\n-            logger.info(f\"Successfully migrated {len(migrated_settings)} settings for {restaurant.name}\")\n-            \n+\n+            self.migration_stats[\"restaurants_processed\"] += 1\n+            logger.info(\n+                f\"Successfully migrated {len(migrated_settings)} settings for {restaurant.name}\"\n+            )\n+\n         except Exception as e:\n             logger.error(f\"Failed to migrate restaurant {restaurant.name}: {e}\")\n-            self.migration_stats['errors'] += 1\n-    \n-    def migrate_payment_methods(self, restaurant: Restaurant, payment_methods: Dict[str, Any]) -> None:\n+            self.migration_stats[\"errors\"] += 1\n+\n+    def migrate_payment_methods(\n+        self, restaurant: Restaurant, payment_methods: Dict[str, Any]\n+    ) -> None:\n         \"\"\"Migrate payment method enablement settings\"\"\"\n-        \n+\n         # Payment method enablement is typically restaurant-specific, so we keep this\n         # but ensure it aligns with platform capabilities\n         logger.info(f\"Payment methods configuration preserved for {restaurant.name}\")\n-        self.migration_stats['settings_migrated'] += 1\n-    \n-    def migrate_payment_fees(self, restaurant: Restaurant, payment_fees: Dict[str, Any]) -> None:\n+        self.migration_stats[\"settings_migrated\"] += 1\n+\n+    def migrate_payment_fees(\n+        self, restaurant: Restaurant, payment_fees: Dict[str, Any]\n+    ) -> None:\n         \"\"\"Migrate payment fee settings - convert custom fees to restaurant overrides\"\"\"\n-        \n+\n         # Get platform default fees for comparison\n         platform_fees = self.get_platform_default_fees()\n-        \n+\n         for payment_method, fee_config in payment_fees.items():\n-            platform_default = platform_fees.get(f'payment.fees.{payment_method}')\n-            \n-            if platform_default and self.fees_differ_from_platform(fee_config, platform_default):\n+            platform_default = platform_fees.get(f\"payment.fees.{payment_method}\")\n+\n+            if platform_default and self.fees_differ_from_platform(\n+                fee_config, platform_default\n+            ):\n                 # Create restaurant override for custom fee\n-                self.create_fee_override(restaurant, payment_method, fee_config, platform_default)\n-            \n-        self.migration_stats['settings_migrated'] += 1\n-    \n-    def migrate_provider_config(self, restaurant: Restaurant, provider: str, config: Dict[str, Any]) -> None:\n+                self.create_fee_override(\n+                    restaurant, payment_method, fee_config, platform_default\n+                )\n+\n+        self.migration_stats[\"settings_migrated\"] += 1\n+\n+    def migrate_provider_config(\n+        self, restaurant: Restaurant, provider: str, config: Dict[str, Any]\n+    ) -> None:\n         \"\"\"Migrate payment provider configurations\"\"\"\n-        \n+\n         # Provider configurations (API keys, etc.) remain restaurant-specific\n         # but we audit the migration\n-        logger.info(f\"Provider {provider} configuration preserved for {restaurant.name}\")\n-        self.migration_stats['settings_migrated'] += 1\n-    \n+        logger.info(\n+            f\"Provider {provider} configuration preserved for {restaurant.name}\"\n+        )\n+        self.migration_stats[\"settings_migrated\"] += 1\n+\n     def get_platform_default_fees(self) -> Dict[str, Any]:\n         \"\"\"Get platform default fee configurations\"\"\"\n-        \n+\n         default_fees = {}\n-        \n+\n         # Query platform configurations for payment fees\n-        fee_configs = self.db.query(PlatformConfiguration).filter(\n-            and_(\n-                PlatformConfiguration.category == 'payment_fees',\n-                PlatformConfiguration.is_active == True\n-            )\n-        ).all()\n-        \n+        fee_configs = (\n+            self.db.query(PlatformConfiguration)\n+            .filter(\n+                and_(\n+                    PlatformConfiguration.category == \"payment_fees\",\n+                    PlatformConfiguration.is_active == True,\n+                )\n+            )\n+            .all()\n+        )\n+\n         for config in fee_configs:\n             default_fees[config.config_key] = config.config_value\n-            \n+\n         return default_fees\n-    \n+\n     def fees_differ_from_platform(self, restaurant_fee: Any, platform_fee: Any) -> bool:\n         \"\"\"Check if restaurant fee differs significantly from platform default\"\"\"\n-        \n+\n         # Simple comparison - in production this would be more sophisticated\n         try:\n             if isinstance(restaurant_fee, dict) and isinstance(platform_fee, dict):\n                 # Compare percentage fees\n-                restaurant_pct = restaurant_fee.get('percentage', 0)\n-                platform_pct = platform_fee.get('percentage', 0)\n-                \n+                restaurant_pct = restaurant_fee.get(\"percentage\", 0)\n+                platform_pct = platform_fee.get(\"percentage\", 0)\n+\n                 # If difference is more than 0.1%, consider it a custom fee\n                 return abs(restaurant_pct - platform_pct) > 0.1\n-                \n+\n         except Exception as e:\n             logger.warning(f\"Error comparing fees: {e}\")\n-            \n+\n         return False\n-    \n-    def create_fee_override(self, restaurant: Restaurant, payment_method: str, \n-                          restaurant_fee: Any, platform_fee: Any) -> None:\n+\n+    def create_fee_override(\n+        self,\n+        restaurant: Restaurant,\n+        payment_method: str,\n+        restaurant_fee: Any,\n+        platform_fee: Any,\n+    ) -> None:\n         \"\"\"Create a restaurant override for custom payment fees\"\"\"\n-        \n+\n         try:\n-            config_key = f'payment.markup.{payment_method}'\n-            \n+            config_key = f\"payment.markup.{payment_method}\"\n+\n             # Calculate markup percentage\n-            restaurant_pct = restaurant_fee.get('percentage', 0) if isinstance(restaurant_fee, dict) else 0\n-            platform_pct = platform_fee.get('percentage', 0) if isinstance(platform_fee, dict) else 0\n+            restaurant_pct = (\n+                restaurant_fee.get(\"percentage\", 0)\n+                if isinstance(restaurant_fee, dict)\n+                else 0\n+            )\n+            platform_pct = (\n+                platform_fee.get(\"percentage\", 0)\n+                if isinstance(platform_fee, dict)\n+                else 0\n+            )\n             markup_pct = restaurant_pct - platform_pct\n-            \n+\n             if markup_pct > 0:\n                 override_value = {\n-                    'percentage': markup_pct,\n-                    'migrated_from': restaurant_fee,\n-                    'migration_date': datetime.now().isoformat()\n+                    \"percentage\": markup_pct,\n+                    \"migrated_from\": restaurant_fee,\n+                    \"migration_date\": datetime.now().isoformat(),\n                 }\n-                \n+\n                 override = RestaurantOverride(\n                     restaurant_id=str(restaurant.id),\n                     config_key=config_key,\n                     override_value=override_value,\n-                    platform_limit={'max_percentage': 2.0},\n+                    platform_limit={\"max_percentage\": 2.0},\n                     is_approved=True,  # Auto-approve migrated settings\n-                    created_by='migration_script'\n-                )\n-                \n+                    created_by=\"migration_script\",\n+                )\n+\n                 self.db.add(override)\n-                self.migration_stats['overrides_created'] += 1\n-                \n-                logger.info(f\"Created fee override for {restaurant.name} - {payment_method}: +{markup_pct}%\")\n-                \n+                self.migration_stats[\"overrides_created\"] += 1\n+\n+                logger.info(\n+                    f\"Created fee override for {restaurant.name} - {payment_method}: +{markup_pct}%\"\n+                )\n+\n         except Exception as e:\n             logger.error(f\"Failed to create fee override: {e}\")\n-            self.migration_stats['errors'] += 1\n-    \n-    def create_migration_audit_record(self, restaurant: Restaurant, migrated_settings: Dict[str, Any]) -> None:\n+            self.migration_stats[\"errors\"] += 1\n+\n+    def create_migration_audit_record(\n+        self, restaurant: Restaurant, migrated_settings: Dict[str, Any]\n+    ) -> None:\n         \"\"\"Create audit record for the migration\"\"\"\n-        \n+\n         audit = ConfigurationAudit(\n-            config_type='migration',\n-            config_key='platform_settings_migration',\n+            config_type=\"migration\",\n+            config_key=\"platform_settings_migration\",\n             entity_id=str(restaurant.id),\n             old_value=migrated_settings,\n-            new_value={'migrated_to': 'platform_controlled'},\n-            change_reason='Automated migration to platform-controlled settings architecture',\n-            change_source='migration_script',\n-            changed_by='system'\n+            new_value={\"migrated_to\": \"platform_controlled\"},\n+            change_reason=\"Automated migration to platform-controlled settings architecture\",\n+            change_source=\"migration_script\",\n+            changed_by=\"system\",\n         )\n-        \n+\n         self.db.add(audit)\n-    \n+\n     def validate_migration(self) -> bool:\n         \"\"\"Validate that the migration completed successfully\"\"\"\n-        \n+\n         validation_passed = True\n-        \n+\n         try:\n             # Check that platform configurations exist\n             platform_config_count = self.db.query(PlatformConfiguration).count()\n             if platform_config_count < len(DEFAULT_PLATFORM_CONFIGS):\n-                logger.error(f\"Missing platform configurations. Expected {len(DEFAULT_PLATFORM_CONFIGS)}, found {platform_config_count}\")\n+                logger.error(\n+                    f\"Missing platform configurations. Expected {len(DEFAULT_PLATFORM_CONFIGS)}, found {platform_config_count}\"\n+                )\n                 validation_passed = False\n-            \n+\n             # Check that feature flags exist\n             feature_flag_count = self.db.query(PlatformFeatureFlag).count()\n             if feature_flag_count < len(DEFAULT_FEATURE_FLAGS):\n-                logger.error(f\"Missing feature flags. Expected {len(DEFAULT_FEATURE_FLAGS)}, found {feature_flag_count}\")\n+                logger.error(\n+                    f\"Missing feature flags. Expected {len(DEFAULT_FEATURE_FLAGS)}, found {feature_flag_count}\"\n+                )\n                 validation_passed = False\n-            \n+\n             # Validate restaurant overrides\n             override_count = self.db.query(RestaurantOverride).count()\n-            logger.info(f\"Created {override_count} restaurant overrides during migration\")\n-            \n+            logger.info(\n+                f\"Created {override_count} restaurant overrides during migration\"\n+            )\n+\n             # Check for orphaned settings\n             restaurants_with_payment_settings = 0\n             restaurants = self.db.query(Restaurant).all()\n-            \n+\n             for restaurant in restaurants:\n                 if self.has_payment_settings(restaurant):\n                     restaurants_with_payment_settings += 1\n-                    logger.warning(f\"Restaurant {restaurant.name} still has payment settings after migration\")\n+                    logger.warning(\n+                        f\"Restaurant {restaurant.name} still has payment settings after migration\"\n+                    )\n                     validation_passed = False\n-            \n+\n             if restaurants_with_payment_settings == 0:\n-                logger.info(\"\u2705 No payment settings remaining in restaurant configurations\")\n-            \n-            logger.info(f\"Migration validation: {'PASSED' if validation_passed else 'FAILED'}\")\n-            \n+                logger.info(\n+                    \"\u2705 No payment settings remaining in restaurant configurations\"\n+                )\n+\n+            logger.info(\n+                f\"Migration validation: {'PASSED' if validation_passed else 'FAILED'}\"\n+            )\n+\n         except Exception as e:\n             logger.error(f\"Migration validation failed: {e}\")\n             validation_passed = False\n-        \n+\n         return validation_passed\n-    \n+\n     def generate_migration_report(self) -> None:\n         \"\"\"Generate a detailed migration report\"\"\"\n-        \n-        report_filename = f\"migration_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n-        \n+\n+        report_filename = (\n+            f\"migration_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n+        )\n+\n         report_content = f\"\"\"\n PLATFORM SETTINGS MIGRATION REPORT\n ===================================\n Date: {datetime.now().isoformat()}\n Dry Run: {self.dry_run}\n@@ -455,50 +523,63 @@\n 4. Monitor system performance after migration\n 5. Update restaurant owners about new platform-controlled settings\n \n For support, contact the development team with this report.\n \"\"\"\n-        \n-        with open(report_filename, 'w') as f:\n+\n+        with open(report_filename, \"w\") as f:\n             f.write(report_content)\n-            \n+\n         logger.info(f\"Migration report generated: {report_filename}\")\n \n \n def main():\n     \"\"\"Main function to run the migration\"\"\"\n-    \n+\n     import argparse\n-    \n-    parser = argparse.ArgumentParser(description='Migrate restaurant settings to platform architecture')\n-    parser.add_argument('--dry-run', action='store_true', default=True, \n-                       help='Run migration without making changes (default: True)')\n-    parser.add_argument('--execute', action='store_true', \n-                       help='Execute the actual migration (overrides --dry-run)')\n-    \n+\n+    parser = argparse.ArgumentParser(\n+        description=\"Migrate restaurant settings to platform architecture\"\n+    )\n+    parser.add_argument(\n+        \"--dry-run\",\n+        action=\"store_true\",\n+        default=True,\n+        help=\"Run migration without making changes (default: True)\",\n+    )\n+    parser.add_argument(\n+        \"--execute\",\n+        action=\"store_true\",\n+        help=\"Execute the actual migration (overrides --dry-run)\",\n+    )\n+\n     args = parser.parse_args()\n-    \n+\n     # Determine if this is a dry run\n     dry_run = not args.execute\n-    \n+\n     if not dry_run:\n-        confirmation = input(\"Are you sure you want to execute the migration? (yes/no): \")\n-        if confirmation.lower() != 'yes':\n+        confirmation = input(\n+            \"Are you sure you want to execute the migration? (yes/no): \"\n+        )\n+        if confirmation.lower() != \"yes\":\n             return\n-    \n+\n     print(f\"Starting migration (DRY RUN: {dry_run})...\")\n-    \n+\n     with PlatformSettingsMigration(dry_run=dry_run) as migration:\n         success = migration.run_migration()\n-        \n+\n         if success:\n             if dry_run:\n-                print(\"DRY RUN completed successfully. Run with --execute to apply changes.\")\n+                print(\n+                    \"DRY RUN completed successfully. Run with --execute to apply changes.\"\n+                )\n             else:\n                 print(\"Migration completed successfully!\")\n         else:\n             print(\"Migration failed. Check logs for details.\")\n             sys.exit(1)\n \n \n if __name__ == \"__main__\":\n-    main()\n\\ No newline at end of file\n+    main()\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/scripts/validate_migration.py\t2025-08-02 21:56:59.001797+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/scripts/validate_migration.py\t2025-08-02 22:36:03.881839+00:00\n@@ -18,494 +18,525 @@\n # Add parent directory to path to import app modules\n sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n \n from app.core.database import SessionLocal, Restaurant, Platform\n from app.models.platform_config import (\n-    PlatformConfiguration, \n-    RestaurantOverride, \n+    PlatformConfiguration,\n+    RestaurantOverride,\n     ConfigurationAudit,\n-    PlatformFeatureFlag\n+    PlatformFeatureFlag,\n )\n from app.services.platform_service import PlatformSettingsService\n \n # Configure logging\n logging.basicConfig(\n-    level=logging.INFO,\n-    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n+    level=logging.INFO, format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n )\n \n logger = logging.getLogger(__name__)\n+\n \n class MigrationValidator:\n     \"\"\"Comprehensive validation of platform settings migration\"\"\"\n-    \n+\n     def __init__(self):\n         self.db: Session = SessionLocal()\n         self.validation_results = {\n-            'tests_run': 0,\n-            'tests_passed': 0,\n-            'tests_failed': 0,\n-            'warnings': 0,\n-            'errors': [],\n-            'warnings_list': []\n+            \"tests_run\": 0,\n+            \"tests_passed\": 0,\n+            \"tests_failed\": 0,\n+            \"warnings\": 0,\n+            \"errors\": [],\n+            \"warnings_list\": [],\n         }\n-    \n+\n     def __enter__(self):\n         return self\n-    \n+\n     def __exit__(self, exc_type, exc_val, exc_tb):\n         self.db.close()\n-    \n+\n     def run_validation(self) -> bool:\n         \"\"\"Run comprehensive validation of the migration\"\"\"\n-        \n+\n         logger.info(\"Starting migration validation...\")\n-        \n+\n         try:\n             # Database structure validation\n             logger.info(\"Validating database structure...\")\n             self.validate_database_structure()\n-            \n+\n             # Platform configurations validation\n             logger.info(\"Validating platform configurations...\")\n             self.validate_platform_configurations()\n-            \n+\n             # Feature flags validation\n             logger.info(\"Validating feature flags...\")\n             self.validate_feature_flags()\n-            \n+\n             # Restaurant overrides validation\n             logger.info(\"Validating restaurant overrides...\")\n             self.validate_restaurant_overrides()\n-            \n+\n             # Data integrity validation\n             logger.info(\"Validating data integrity...\")\n             self.validate_data_integrity()\n-            \n+\n             # API functionality validation\n             logger.info(\"Validating API functionality...\")\n             self.validate_api_functionality()\n-            \n+\n             # Payment processing validation\n             logger.info(\"Validating payment processing...\")\n             self.validate_payment_processing()\n-            \n+\n             # Audit trail validation\n             logger.info(\"Validating audit trail...\")\n             self.validate_audit_trail()\n-            \n+\n             # Generate validation report\n             self.generate_validation_report()\n-            \n-            success = self.validation_results['tests_failed'] == 0\n-            \n+\n+            success = self.validation_results[\"tests_failed\"] == 0\n+\n             if success:\n                 logger.info(\"\u2705 Migration validation passed!\")\n             else:\n-                logger.error(f\"\u274c Migration validation failed! {self.validation_results['tests_failed']} tests failed\")\n-            \n+                logger.error(\n+                    f\"\u274c Migration validation failed! {self.validation_results['tests_failed']} tests failed\"\n+                )\n+\n             return success\n-            \n+\n         except Exception as e:\n             logger.error(f\"Validation failed with exception: {e}\", exc_info=True)\n             self.record_error(f\"Validation exception: {e}\")\n             return False\n-    \n+\n     def validate_database_structure(self) -> None:\n         \"\"\"Validate that all required tables and indices exist\"\"\"\n-        \n+\n         required_tables = [\n-            'platform_configurations',\n-            'restaurant_overrides', \n-            'configuration_audit',\n-            'platform_feature_flags'\n+            \"platform_configurations\",\n+            \"restaurant_overrides\",\n+            \"configuration_audit\",\n+            \"platform_feature_flags\",\n         ]\n-        \n+\n         for table in required_tables:\n             self.run_test(\n                 f\"Table {table} exists\",\n                 lambda t=table: self.table_exists(t),\n-                f\"Required table {table} is missing\"\n-            )\n-        \n+                f\"Required table {table} is missing\",\n+            )\n+\n         # Validate key indices\n         self.run_test(\n             \"Platform config indices exist\",\n             self.validate_platform_config_indices,\n-            \"Platform configuration indices are missing\"\n-        )\n-        \n-        self.run_test(\n-            \"Restaurant override indices exist\", \n+            \"Platform configuration indices are missing\",\n+        )\n+\n+        self.run_test(\n+            \"Restaurant override indices exist\",\n             self.validate_restaurant_override_indices,\n-            \"Restaurant override indices are missing\"\n-        )\n-    \n+            \"Restaurant override indices are missing\",\n+        )\n+\n     def validate_platform_configurations(self) -> None:\n         \"\"\"Validate platform configurations are properly set up\"\"\"\n-        \n+\n         # Check that essential configurations exist\n         essential_configs = [\n-            'payment.fees.qr_code',\n-            'payment.fees.stripe', \n-            'payment.fees.square',\n-            'payment.fees.sumup',\n-            'security.max_login_attempts',\n-            'business.max_discount_percentage'\n+            \"payment.fees.qr_code\",\n+            \"payment.fees.stripe\",\n+            \"payment.fees.square\",\n+            \"payment.fees.sumup\",\n+            \"security.max_login_attempts\",\n+            \"business.max_discount_percentage\",\n         ]\n-        \n+\n         for config_key in essential_configs:\n             self.run_test(\n                 f\"Platform config {config_key} exists\",\n                 lambda key=config_key: self.platform_config_exists(key),\n-                f\"Essential platform config {config_key} is missing\"\n-            )\n-        \n+                f\"Essential platform config {config_key} is missing\",\n+            )\n+\n         # Validate configuration values\n         self.run_test(\n             \"Payment fees are reasonable\",\n             self.validate_payment_fee_values,\n-            \"Payment fee values are unreasonable\"\n-        )\n-        \n+            \"Payment fee values are unreasonable\",\n+        )\n+\n         self.run_test(\n             \"Security settings are appropriate\",\n             self.validate_security_settings,\n-            \"Security settings are inappropriate\"\n-        )\n-    \n+            \"Security settings are inappropriate\",\n+        )\n+\n     def validate_feature_flags(self) -> None:\n         \"\"\"Validate feature flags are properly configured\"\"\"\n-        \n+\n         feature_flags = self.db.query(PlatformFeatureFlag).all()\n-        \n+\n         self.run_test(\n             \"Feature flags exist\",\n             lambda: len(feature_flags) > 0,\n-            \"No feature flags found\"\n-        )\n-        \n+            \"No feature flags found\",\n+        )\n+\n         for flag in feature_flags:\n             # Validate rollout percentage\n             self.run_test(\n                 f\"Feature flag {flag.feature_key} has valid rollout percentage\",\n                 lambda f=flag: 0 <= f.rollout_percentage <= 100,\n-                f\"Feature flag {flag.feature_key} has invalid rollout percentage\"\n-            )\n-    \n+                f\"Feature flag {flag.feature_key} has invalid rollout percentage\",\n+            )\n+\n     def validate_restaurant_overrides(self) -> None:\n         \"\"\"Validate restaurant overrides are within platform limits\"\"\"\n-        \n+\n         overrides = self.db.query(RestaurantOverride).all()\n-        \n+\n         for override in overrides:\n             # Validate payment markup overrides\n-            if 'payment.markup' in override.config_key:\n+            if \"payment.markup\" in override.config_key:\n                 self.run_test(\n                     f\"Payment markup override {override.config_key} is within limits\",\n                     lambda o=override: self.validate_payment_markup(o),\n-                    f\"Payment markup override {override.config_key} exceeds platform limits\"\n+                    f\"Payment markup override {override.config_key} exceeds platform limits\",\n                 )\n-            \n+\n             # Validate discount overrides\n-            if 'discount' in override.config_key:\n+            if \"discount\" in override.config_key:\n                 self.run_test(\n                     f\"Discount override {override.config_key} is within limits\",\n                     lambda o=override: self.validate_discount_override(o),\n-                    f\"Discount override {override.config_key} exceeds platform limits\"\n+                    f\"Discount override {override.config_key} exceeds platform limits\",\n                 )\n-    \n+\n     def validate_data_integrity(self) -> None:\n         \"\"\"Validate data integrity and consistency\"\"\"\n-        \n+\n         # Check for orphaned restaurant overrides\n         self.run_test(\n             \"No orphaned restaurant overrides\",\n             self.check_orphaned_overrides,\n-            \"Found orphaned restaurant overrides\"\n-        )\n-        \n+            \"Found orphaned restaurant overrides\",\n+        )\n+\n         # Check for duplicate configurations\n         self.run_test(\n             \"No duplicate platform configurations\",\n             self.check_duplicate_configurations,\n-            \"Found duplicate platform configurations\"\n-        )\n-        \n+            \"Found duplicate platform configurations\",\n+        )\n+\n         # Check configuration audit trail integrity\n         self.run_test(\n             \"Audit trail integrity\",\n             self.check_audit_trail_integrity,\n-            \"Audit trail has integrity issues\"\n-        )\n-        \n+            \"Audit trail has integrity issues\",\n+        )\n+\n         # Check that restaurants no longer have payment settings in their settings JSON\n         self.run_test(\n             \"Restaurants have clean settings\",\n             self.check_restaurant_settings_cleaned,\n-            \"Some restaurants still have payment settings in their configuration\"\n-        )\n-    \n+            \"Some restaurants still have payment settings in their configuration\",\n+        )\n+\n     def validate_api_functionality(self) -> None:\n         \"\"\"Validate that platform settings API is functional\"\"\"\n-        \n+\n         try:\n             # Test platform service functionality\n             service = PlatformSettingsService(self.db)\n-            \n+\n             # Test getting platform settings\n             self.run_test(\n                 \"Platform settings API - get settings\",\n                 lambda: self.test_get_platform_settings(service),\n-                \"Failed to retrieve platform settings via API\"\n-            )\n-            \n+                \"Failed to retrieve platform settings via API\",\n+            )\n+\n             # Test payment fee calculation\n             self.run_test(\n                 \"Platform settings API - calculate fees\",\n                 lambda: self.test_calculate_payment_fees(service),\n-                \"Failed to calculate payment fees via API\"\n-            )\n-            \n+                \"Failed to calculate payment fees via API\",\n+            )\n+\n             # Test feature flags\n             self.run_test(\n-                \"Platform settings API - get feature flags\", \n+                \"Platform settings API - get feature flags\",\n                 lambda: self.test_get_feature_flags(service),\n-                \"Failed to retrieve feature flags via API\"\n-            )\n-            \n+                \"Failed to retrieve feature flags via API\",\n+            )\n+\n         except Exception as e:\n             self.record_error(f\"API functionality validation failed: {e}\")\n-    \n+\n     def validate_payment_processing(self) -> None:\n         \"\"\"Validate that payment processing is not affected by migration\"\"\"\n-        \n+\n         # Test that payment methods are still available\n         restaurants_with_issues = []\n         restaurants = self.db.query(Restaurant).limit(10).all()  # Sample check\n-        \n+\n         for restaurant in restaurants:\n-            if restaurant.settings and 'paymentMethods' not in restaurant.settings:\n+            if restaurant.settings and \"paymentMethods\" not in restaurant.settings:\n                 restaurants_with_issues.append(restaurant.name)\n-        \n+\n         if restaurants_with_issues:\n-            self.record_warning(f\"Restaurants missing payment methods config: {', '.join(restaurants_with_issues)}\")\n-        \n+            self.record_warning(\n+                f\"Restaurants missing payment methods config: {', '.join(restaurants_with_issues)}\"\n+            )\n+\n         # Validate that all payment providers have fee configurations\n-        payment_providers = ['qr_code', 'stripe', 'square', 'sumup']\n+        payment_providers = [\"qr_code\", \"stripe\", \"square\", \"sumup\"]\n         for provider in payment_providers:\n-            config_key = f'payment.fees.{provider}'\n+            config_key = f\"payment.fees.{provider}\"\n             self.run_test(\n                 f\"Payment provider {provider} has fee configuration\",\n                 lambda key=config_key: self.platform_config_exists(key),\n-                f\"Payment provider {provider} missing fee configuration\"\n-            )\n-    \n+                f\"Payment provider {provider} missing fee configuration\",\n+            )\n+\n     def validate_audit_trail(self) -> None:\n         \"\"\"Validate audit trail completeness\"\"\"\n-        \n+\n         # Check that migration created audit records\n-        migration_audits = self.db.query(ConfigurationAudit).filter(\n-            ConfigurationAudit.config_key == 'platform_settings_migration'\n-        ).all()\n-        \n+        migration_audits = (\n+            self.db.query(ConfigurationAudit)\n+            .filter(ConfigurationAudit.config_key == \"platform_settings_migration\")\n+            .all()\n+        )\n+\n         self.run_test(\n             \"Migration audit records exist\",\n             lambda: len(migration_audits) > 0,\n-            \"No migration audit records found\"\n-        )\n-        \n+            \"No migration audit records found\",\n+        )\n+\n         # Check recent audit activity\n-        recent_audits = self.db.query(ConfigurationAudit).filter(\n-            ConfigurationAudit.changed_at >= datetime.now() - timedelta(hours=24)\n-        ).count()\n-        \n+        recent_audits = (\n+            self.db.query(ConfigurationAudit)\n+            .filter(\n+                ConfigurationAudit.changed_at >= datetime.now() - timedelta(hours=24)\n+            )\n+            .count()\n+        )\n+\n         if recent_audits == 0:\n             self.record_warning(\"No recent audit activity found\")\n-    \n+\n     # Helper methods for validation tests\n-    \n+\n     def run_test(self, test_name: str, test_func, error_message: str) -> bool:\n         \"\"\"Run a validation test and record results\"\"\"\n-        \n-        self.validation_results['tests_run'] += 1\n-        \n+\n+        self.validation_results[\"tests_run\"] += 1\n+\n         try:\n             result = test_func()\n             if result:\n-                self.validation_results['tests_passed'] += 1\n+                self.validation_results[\"tests_passed\"] += 1\n                 logger.debug(f\"\u2705 {test_name}\")\n                 return True\n             else:\n-                self.validation_results['tests_failed'] += 1\n+                self.validation_results[\"tests_failed\"] += 1\n                 self.record_error(f\"{test_name}: {error_message}\")\n                 logger.error(f\"\u274c {test_name}: {error_message}\")\n                 return False\n         except Exception as e:\n-            self.validation_results['tests_failed'] += 1\n+            self.validation_results[\"tests_failed\"] += 1\n             error_msg = f\"{test_name}: {error_message} - {e}\"\n             self.record_error(error_msg)\n             logger.error(f\"\u274c {error_msg}\")\n             return False\n-    \n+\n     def table_exists(self, table_name: str) -> bool:\n         \"\"\"Check if a table exists\"\"\"\n-        result = self.db.execute(text(\n-            \"SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = :table_name);\"\n-        ), {\"table_name\": table_name})\n+        result = self.db.execute(\n+            text(\n+                \"SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = :table_name);\"\n+            ),\n+            {\"table_name\": table_name},\n+        )\n         return result.scalar()\n-    \n+\n     def platform_config_exists(self, config_key: str) -> bool:\n         \"\"\"Check if a platform configuration exists\"\"\"\n-        config = self.db.query(PlatformConfiguration).filter(\n-            PlatformConfiguration.config_key == config_key\n-        ).first()\n+        config = (\n+            self.db.query(PlatformConfiguration)\n+            .filter(PlatformConfiguration.config_key == config_key)\n+            .first()\n+        )\n         return config is not None\n-    \n+\n     def validate_platform_config_indices(self) -> bool:\n         \"\"\"Validate platform configuration indices\"\"\"\n         # This is a simplified check - in production you'd check specific indices\n         return True\n-    \n+\n     def validate_restaurant_override_indices(self) -> bool:\n         \"\"\"Validate restaurant override indices\"\"\"\n         # This is a simplified check - in production you'd check specific indices\n         return True\n-    \n+\n     def validate_payment_fee_values(self) -> bool:\n         \"\"\"Validate that payment fee values are reasonable\"\"\"\n-        fee_configs = self.db.query(PlatformConfiguration).filter(\n-            and_(\n-                PlatformConfiguration.category == 'payment_fees',\n-                PlatformConfiguration.config_key.like('payment.fees.%')\n-            )\n-        ).all()\n-        \n+        fee_configs = (\n+            self.db.query(PlatformConfiguration)\n+            .filter(\n+                and_(\n+                    PlatformConfiguration.category == \"payment_fees\",\n+                    PlatformConfiguration.config_key.like(\"payment.fees.%\"),\n+                )\n+            )\n+            .all()\n+        )\n+\n         for config in fee_configs:\n             fee_data = config.config_value\n             if isinstance(fee_data, dict):\n-                percentage = fee_data.get('percentage', 0)\n+                percentage = fee_data.get(\"percentage\", 0)\n                 if percentage < 0 or percentage > 10:  # Fees should be 0-10%\n                     return False\n-        \n+\n         return True\n-    \n+\n     def validate_security_settings(self) -> bool:\n         \"\"\"Validate security settings\"\"\"\n-        max_login_config = self.db.query(PlatformConfiguration).filter(\n-            PlatformConfiguration.config_key == 'security.max_login_attempts'\n-        ).first()\n-        \n+        max_login_config = (\n+            self.db.query(PlatformConfiguration)\n+            .filter(PlatformConfiguration.config_key == \"security.max_login_attempts\")\n+            .first()\n+        )\n+\n         if max_login_config:\n             max_attempts = max_login_config.config_value\n             return isinstance(max_attempts, int) and 3 <= max_attempts <= 10\n-        \n+\n         return False\n-    \n+\n     def validate_payment_markup(self, override: RestaurantOverride) -> bool:\n         \"\"\"Validate payment markup override\"\"\"\n         if isinstance(override.override_value, dict):\n-            percentage = override.override_value.get('percentage', 0)\n+            percentage = override.override_value.get(\"percentage\", 0)\n             return 0 <= percentage <= 2.0  # Max 2% markup\n         return False\n-    \n+\n     def validate_discount_override(self, override: RestaurantOverride) -> bool:\n         \"\"\"Validate discount override\"\"\"\n         if isinstance(override.override_value, dict):\n-            percentage = override.override_value.get('percentage', 0)\n+            percentage = override.override_value.get(\"percentage\", 0)\n             return 0 <= percentage <= 100  # Max 100% discount\n         return False\n-    \n+\n     def check_orphaned_overrides(self) -> bool:\n         \"\"\"Check for orphaned restaurant overrides\"\"\"\n-        orphaned = self.db.execute(text(\"\"\"\n+        orphaned = self.db.execute(\n+            text(\n+                \"\"\"\n             SELECT COUNT(*) FROM restaurant_overrides ro\n             WHERE NOT EXISTS (\n                 SELECT 1 FROM restaurants r WHERE r.id::text = ro.restaurant_id\n             )\n-        \"\"\")).scalar()\n-        \n+        \"\"\"\n+            )\n+        ).scalar()\n+\n         return orphaned == 0\n-    \n+\n     def check_duplicate_configurations(self) -> bool:\n         \"\"\"Check for duplicate platform configurations\"\"\"\n-        duplicates = self.db.execute(text(\"\"\"\n+        duplicates = self.db.execute(\n+            text(\n+                \"\"\"\n             SELECT config_key, COUNT(*) \n             FROM platform_configurations \n             GROUP BY config_key \n             HAVING COUNT(*) > 1\n-        \"\"\")).fetchall()\n-        \n+        \"\"\"\n+            )\n+        ).fetchall()\n+\n         return len(duplicates) == 0\n-    \n+\n     def check_audit_trail_integrity(self) -> bool:\n         \"\"\"Check audit trail integrity\"\"\"\n         # Check that all configuration changes have corresponding audit records\n         return True  # Simplified check\n-    \n+\n     def check_restaurant_settings_cleaned(self) -> bool:\n         \"\"\"Check that restaurants no longer have payment settings\"\"\"\n         restaurants = self.db.query(Restaurant).all()\n-        \n-        payment_keys = ['paymentFees', 'stripeConfig', 'squareConfig', 'sumupConfig']\n-        \n+\n+        payment_keys = [\"paymentFees\", \"stripeConfig\", \"squareConfig\", \"sumupConfig\"]\n+\n         for restaurant in restaurants:\n             if restaurant.settings:\n                 for key in payment_keys:\n                     if key in restaurant.settings:\n                         return False\n-        \n+\n         return True\n-    \n+\n     def test_get_platform_settings(self, service: PlatformSettingsService) -> bool:\n         \"\"\"Test getting platform settings via service\"\"\"\n         try:\n             settings = asyncio.run(service.get_platform_settings())\n             return len(settings) > 0\n         except Exception:\n             return False\n-    \n+\n     def test_calculate_payment_fees(self, service: PlatformSettingsService) -> bool:\n         \"\"\"Test payment fee calculation\"\"\"\n         try:\n-            fee_calc = asyncio.run(service.calculate_effective_fee('qr_code', 100.0))\n-            return fee_calc is not None and 'effective_fee' in fee_calc\n+            fee_calc = asyncio.run(service.calculate_effective_fee(\"qr_code\", 100.0))\n+            return fee_calc is not None and \"effective_fee\" in fee_calc\n         except Exception:\n             return False\n-    \n+\n     def test_get_feature_flags(self, service: PlatformSettingsService) -> bool:\n         \"\"\"Test getting feature flags\"\"\"\n         try:\n             flags = asyncio.run(service.get_feature_flags())\n             return isinstance(flags, dict)\n         except Exception:\n             return False\n-    \n+\n     def record_error(self, error_message: str) -> None:\n         \"\"\"Record an error\"\"\"\n-        self.validation_results['errors'].append(error_message)\n-    \n+        self.validation_results[\"errors\"].append(error_message)\n+\n     def record_warning(self, warning_message: str) -> None:\n         \"\"\"Record a warning\"\"\"\n-        self.validation_results['warnings'] += 1\n-        self.validation_results['warnings_list'].append(warning_message)\n+        self.validation_results[\"warnings\"] += 1\n+        self.validation_results[\"warnings_list\"].append(warning_message)\n         logger.warning(warning_message)\n-    \n+\n     def generate_validation_report(self) -> None:\n         \"\"\"Generate comprehensive validation report\"\"\"\n-        \n-        report_filename = f\"validation_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n-        \n+\n+        report_filename = (\n+            f\"validation_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n+        )\n+\n         # Database statistics\n         db_stats = {\n-            'platform_configs': self.db.query(PlatformConfiguration).count(),\n-            'feature_flags': self.db.query(PlatformFeatureFlag).count(),\n-            'restaurant_overrides': self.db.query(RestaurantOverride).count(),\n-            'audit_records': self.db.query(ConfigurationAudit).count(),\n-            'restaurants': self.db.query(Restaurant).count()\n+            \"platform_configs\": self.db.query(PlatformConfiguration).count(),\n+            \"feature_flags\": self.db.query(PlatformFeatureFlag).count(),\n+            \"restaurant_overrides\": self.db.query(RestaurantOverride).count(),\n+            \"audit_records\": self.db.query(ConfigurationAudit).count(),\n+            \"restaurants\": self.db.query(Restaurant).count(),\n         }\n-        \n+\n         report_content = f\"\"\"\n MIGRATION VALIDATION REPORT\n ===========================\n Date: {datetime.now().isoformat()}\n \n@@ -523,21 +554,21 @@\n - Total Restaurants: {db_stats['restaurants']}\n \n VALIDATION STATUS: {'PASSED' if self.validation_results['tests_failed'] == 0 else 'FAILED'}\n \n \"\"\"\n-        \n-        if self.validation_results['errors']:\n+\n+        if self.validation_results[\"errors\"]:\n             report_content += \"\\nERRORS:\\n\"\n-            for i, error in enumerate(self.validation_results['errors'], 1):\n+            for i, error in enumerate(self.validation_results[\"errors\"], 1):\n                 report_content += f\"{i}. {error}\\n\"\n-        \n-        if self.validation_results['warnings_list']:\n+\n+        if self.validation_results[\"warnings_list\"]:\n             report_content += \"\\nWARNINGS:\\n\"\n-            for i, warning in enumerate(self.validation_results['warnings_list'], 1):\n+            for i, warning in enumerate(self.validation_results[\"warnings_list\"], 1):\n                 report_content += f\"{i}. {warning}\\n\"\n-        \n+\n         report_content += f\"\"\"\n RECOMMENDATIONS:\n {'\u2705 Migration validation passed. System is ready for production.' if self.validation_results['tests_failed'] == 0 else '\u274c Migration validation failed. Review errors before proceeding.'}\n \n Next Steps:\n@@ -547,26 +578,26 @@\n 4. Monitor system performance\n 5. Update documentation with new platform settings\n \n For support, contact the development team with this report.\n \"\"\"\n-        \n-        with open(report_filename, 'w') as f:\n+\n+        with open(report_filename, \"w\") as f:\n             f.write(report_content)\n-        \n+\n         logger.info(f\"Validation report generated: {report_filename}\")\n \n \n def main():\n     \"\"\"Main function to run the validation\"\"\"\n-    \n+\n     with MigrationValidator() as validator:\n         success = validator.run_validation()\n-        \n+\n         if success:\n             sys.exit(0)\n         else:\n             sys.exit(1)\n \n \n if __name__ == \"__main__\":\n-    main()\n\\ No newline at end of file\n+    main()\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/instance_tracker.py\t2025-08-02 19:52:26.972967+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/instance_tracker.py\t2025-08-02 22:36:03.887397+00:00\n@@ -19,78 +19,78 @@\n \n \n class InstanceTracker:\n     \"\"\"\n     Tracks active instances of the backend service.\n-    \n+\n     Each instance registers itself with Redis and maintains a heartbeat.\n     Stale instances are automatically cleaned up based on TTL.\n     \"\"\"\n-    \n+\n     def __init__(self, redis_client: RedisClient):\n         self.redis = redis_client\n         self.instance_id = self._generate_instance_id()\n         self.instance_key_prefix = \"fynlo:instances:\"\n         self.instance_key = f\"{self.instance_key_prefix}{self.instance_id}\"\n         self.heartbeat_interval = 10  # seconds\n         self.ttl = 30  # seconds - instance considered dead after this\n         self.heartbeat_task: Optional[asyncio.Task] = None\n         self._running = False\n-        \n+\n     def _generate_instance_id(self) -> str:\n         \"\"\"Generate a unique instance ID with random suffix for security.\"\"\"\n         hostname = socket.gethostname()\n         pod_name = os.environ.get(\"POD_NAME\", \"\")\n         do_app_id = os.environ.get(\"DO_APP_ID\", \"\")\n-        \n+\n         # Generate 8-character random suffix for security\n         random_suffix = secrets.token_hex(4)\n-        \n+\n         # Use pod name if available (Kubernetes/DigitalOcean)\n         if pod_name:\n             return f\"{pod_name}-{random_suffix}\"\n         # Otherwise use app ID + hostname\n         elif do_app_id and hostname:\n             return f\"{do_app_id}-{hostname}-{random_suffix}\"\n         # Fallback to just hostname\n         else:\n             return f\"{hostname}-{random_suffix}\"\n-    \n+\n     async def start(self):\n         \"\"\"Start instance tracking - register and begin heartbeat.\"\"\"\n         if self._running:\n             logger.warning(f\"Instance tracker already running for {self.instance_id}\")\n             return\n-            \n+\n         self._running = True\n         logger.info(f\"Starting instance tracker for {self.instance_id}\")\n-        \n+\n         # Register instance\n         await self._register_instance()\n-        \n+\n         # Start heartbeat loop\n         self.heartbeat_task = asyncio.create_task(self._heartbeat_loop())\n-        \n+\n     async def stop(self):\n         \"\"\"Stop instance tracking and unregister.\"\"\"\n         if not self._running:\n             return\n-            \n+\n         self._running = False\n         logger.info(f\"Stopping instance tracker for {self.instance_id}\")\n-        \n+\n         # Cancel heartbeat task\n         if self.heartbeat_task:\n             self.heartbeat_task.cancel()\n             try:\n                 await self.heartbeat_task\n             except asyncio.CancelledError:\n                 pass\n-        \n+\n         # Unregister instance\n         await self._unregister_instance()\n-    \n+\n     async def _register_instance(self):\n         \"\"\"Register this instance in Redis.\"\"\"\n         try:\n             instance_data = {\n                 \"instance_id\": self.instance_id,\n@@ -100,72 +100,80 @@\n                 \"pod_name\": os.environ.get(\"POD_NAME\", \"not_set\"),\n                 \"node_name\": os.environ.get(\"NODE_NAME\", \"not_set\"),\n                 \"deployment_id\": os.environ.get(\"DO_DEPLOYMENT_ID\", \"not_set\"),\n                 \"app_version\": os.environ.get(\"APP_VERSION\", \"unknown\"),\n                 \"environment\": settings.ENVIRONMENT,\n-                \"digitalocean\": json.dumps({\n-                    \"app_id\": os.environ.get(\"DO_APP_ID\", \"not_set\"),\n-                    \"app_name\": os.environ.get(\"DO_APP_NAME\", \"not_set\"),\n-                    \"region\": os.environ.get(\"DO_REGION\", \"not_set\"),\n-                    \"component_name\": os.environ.get(\"DO_COMPONENT_NAME\", \"backend\")\n-                })\n+                \"digitalocean\": json.dumps(\n+                    {\n+                        \"app_id\": os.environ.get(\"DO_APP_ID\", \"not_set\"),\n+                        \"app_name\": os.environ.get(\"DO_APP_NAME\", \"not_set\"),\n+                        \"region\": os.environ.get(\"DO_REGION\", \"not_set\"),\n+                        \"component_name\": os.environ.get(\n+                            \"DO_COMPONENT_NAME\", \"backend\"\n+                        ),\n+                    }\n+                ),\n             }\n-            \n+\n             # Store instance data as hash\n             if self.redis.redis:  # Real Redis\n                 await self.redis.redis.hset(self.instance_key, mapping=instance_data)\n                 await self.redis.redis.expire(self.instance_key, self.ttl)\n             else:\n                 # Mock Redis fallback\n                 await self.redis.set(self.instance_key, instance_data, expire=self.ttl)\n-                \n+\n             logger.info(f\"Instance {self.instance_id} registered successfully\")\n-            \n+\n         except Exception as e:\n             logger.error(f\"Failed to register instance {self.instance_id}: {e}\")\n-    \n+\n     async def _unregister_instance(self):\n         \"\"\"Remove this instance from Redis.\"\"\"\n         try:\n             await self.redis.delete(self.instance_key)\n             logger.info(f\"Instance {self.instance_id} unregistered\")\n         except Exception as e:\n             logger.error(f\"Failed to unregister instance {self.instance_id}: {e}\")\n-    \n+\n     async def _heartbeat_loop(self):\n         \"\"\"Continuously update instance heartbeat.\"\"\"\n         while self._running:\n             try:\n                 # Update heartbeat timestamp\n                 heartbeat_data = {\n                     \"last_heartbeat\": datetime.now(timezone.utc).isoformat(),\n-                    \"status\": \"healthy\"\n+                    \"status\": \"healthy\",\n                 }\n-                \n+\n                 if self.redis.redis:  # Real Redis\n-                    await self.redis.redis.hset(self.instance_key, mapping=heartbeat_data)\n+                    await self.redis.redis.hset(\n+                        self.instance_key, mapping=heartbeat_data\n+                    )\n                     await self.redis.redis.expire(self.instance_key, self.ttl)\n                 else:\n                     # Mock Redis - update the stored data\n                     existing = await self.redis.get(self.instance_key)\n                     if existing and isinstance(existing, dict):\n                         existing.update(heartbeat_data)\n-                        await self.redis.set(self.instance_key, existing, expire=self.ttl)\n-                \n+                        await self.redis.set(\n+                            self.instance_key, existing, expire=self.ttl\n+                        )\n+\n                 logger.debug(f\"Heartbeat updated for instance {self.instance_id}\")\n-                \n+\n             except Exception as e:\n                 logger.error(f\"Heartbeat error for instance {self.instance_id}: {e}\")\n-            \n+\n             # Wait for next heartbeat\n             await asyncio.sleep(self.heartbeat_interval)\n-    \n+\n     async def get_active_instances(self) -> List[Dict[str, Any]]:\n         \"\"\"Get all active instances from Redis.\"\"\"\n         instances = []\n         pattern = f\"{self.instance_key_prefix}*\"\n-        \n+\n         try:\n             if self.redis.redis:  # Real Redis\n                 # Scan for all instance keys\n                 async for key in self.redis.redis.scan_iter(match=pattern):\n                     instance_data = await self.redis.redis.hgetall(key)\n@@ -173,79 +181,77 @@\n                         # Convert bytes to strings and parse JSON fields\n                         instance_info = {}\n                         for k, v in instance_data.items():\n                             key_str = k.decode() if isinstance(k, bytes) else k\n                             val_str = v.decode() if isinstance(v, bytes) else v\n-                            \n+\n                             # Parse JSON fields\n                             if key_str == \"digitalocean\":\n                                 try:\n                                     instance_info[key_str] = json.loads(val_str)\n                                 except json.JSONDecodeError:\n                                     instance_info[key_str] = val_str\n                             else:\n                                 instance_info[key_str] = val_str\n-                        \n+\n                         instances.append(instance_info)\n             else:\n                 # Mock Redis fallback\n                 logger.warning(\"Using mock Redis for instance tracking\")\n-                \n+\n         except Exception as e:\n             logger.error(f\"Error fetching active instances: {e}\")\n-        \n+\n         return instances\n-    \n+\n     async def cleanup_stale_instances(self, max_age_seconds: int = 60):\n         \"\"\"\n         Clean up instances that haven't sent a heartbeat recently.\n-        \n+\n         This is a safety mechanism in case TTL doesn't work properly.\n         \"\"\"\n         try:\n             instances = await self.get_active_instances()\n             current_time = datetime.now(timezone.utc)\n-            \n+\n             for instance in instances:\n-                last_heartbeat_str = instance.get('last_heartbeat')\n+                last_heartbeat_str = instance.get(\"last_heartbeat\")\n                 if last_heartbeat_str:\n                     last_heartbeat = datetime.fromisoformat(last_heartbeat_str)\n                     age_seconds = (current_time - last_heartbeat).total_seconds()\n-                    \n+\n                     if age_seconds > max_age_seconds:\n-                        instance_id = instance.get('instance_id', 'unknown')\n+                        instance_id = instance.get(\"instance_id\", \"unknown\")\n                         stale_key = f\"{self.instance_key_prefix}{instance_id}\"\n                         await self.redis.delete(stale_key)\n-                        logger.warning(f\"Cleaned up stale instance: {instance_id} (age: {age_seconds}s)\")\n-                        \n+                        logger.warning(\n+                            f\"Cleaned up stale instance: {instance_id} (age: {age_seconds}s)\"\n+                        )\n+\n         except Exception as e:\n             logger.error(f\"Error cleaning up stale instances: {e}\")\n-    \n+\n     async def get_instance_count(self) -> Dict[str, int]:\n         \"\"\"Get count of active and total instances.\"\"\"\n         instances = await self.get_active_instances()\n         current_time = datetime.now(timezone.utc)\n-        \n+\n         active_count = 0\n         stale_count = 0\n-        \n+\n         for instance in instances:\n-            last_heartbeat_str = instance.get('last_heartbeat')\n+            last_heartbeat_str = instance.get(\"last_heartbeat\")\n             if last_heartbeat_str:\n                 last_heartbeat = datetime.fromisoformat(last_heartbeat_str)\n                 age_seconds = (current_time - last_heartbeat).total_seconds()\n-                \n+\n                 if age_seconds <= 60:  # Consider active if heartbeat within 60s\n                     active_count += 1\n                 else:\n                     stale_count += 1\n-        \n-        return {\n-            \"active\": active_count,\n-            \"stale\": stale_count,\n-            \"total\": len(instances)\n-        }\n+\n+        return {\"active\": active_count, \"stale\": stale_count, \"total\": len(instances)}\n \n \n # Global instance tracker (will be initialized in app startup)\n instance_tracker: Optional[InstanceTracker] = None\n \n@@ -261,6 +267,6 @@\n async def stop_instance_tracker():\n     \"\"\"Stop the global instance tracker.\"\"\"\n     global instance_tracker\n     if instance_tracker:\n         await instance_tracker.stop()\n-        logger.info(\"Instance tracker stopped\")\n\\ No newline at end of file\n+        logger.info(\"Instance tracker stopped\")\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_providers/__init__.py\t2025-08-02 10:59:17.997836+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_providers/__init__.py\t2025-08-02 22:36:03.898836+00:00\n@@ -7,12 +7,12 @@\n from .square_provider import SquareProvider\n from .sumup_provider import SumUpProvider\n from .payment_factory import PaymentProviderFactory\n \n __all__ = [\n-    'PaymentProvider',\n-    'PaymentStatus',\n-    'StripeProvider',\n-    'SquareProvider',\n-    'SumUpProvider',\n-    'PaymentProviderFactory'\n-]\n\\ No newline at end of file\n+    \"PaymentProvider\",\n+    \"PaymentStatus\",\n+    \"StripeProvider\",\n+    \"SquareProvider\",\n+    \"SumUpProvider\",\n+    \"PaymentProviderFactory\",\n+]\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_fee_calculator.py\t2025-08-02 21:56:59.004261+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_fee_calculator.py\t2025-08-02 22:36:03.904679+00:00\n@@ -4,10 +4,11 @@\n \n from app.services.platform_service import PlatformSettingsService\n from app.schemas.fee_schemas import PaymentMethodEnum\n \n logger = logging.getLogger(__name__)\n+\n \n class PaymentFeeCalculator:\n     \"\"\"\n     Calculates the actual payment processor fees.\n     This fee is what the platform itself is charged by the payment provider (e.g., Stripe, SumUp).\n@@ -20,11 +21,11 @@\n         self,\n         transaction_amount: float,\n         payment_method: PaymentMethodEnum,\n         restaurant_id: Optional[str] = None,\n         # monthly_volume could be passed if available and relevant for specific providers like SumUp\n-        monthly_volume_for_restaurant: Optional[float] = None\n+        monthly_volume_for_restaurant: Optional[float] = None,\n     ) -> float:\n         \"\"\"\n         Calculates the actual fee charged by the payment processor to the platform.\n \n         Args:\n@@ -50,16 +51,16 @@\n \n             fee_details = await self.platform_settings_service.calculate_effective_fee(\n                 payment_method=payment_method_str,\n                 amount=transaction_amount,\n                 restaurant_id=restaurant_id,\n-                monthly_volume=monthly_volume_for_restaurant\n+                monthly_volume=monthly_volume_for_restaurant,\n             )\n \n             # 'platform_fee' in fee_details dict is the actual processor fee before restaurant markup.\n             # This was a bit confusingly named in the original PlatformSettingsService.\n-            processor_fee_value = fee_details.get('platform_fee', 0.0)\n+            processor_fee_value = fee_details.get(\"platform_fee\", 0.0)\n \n             # Ensure the fee is positive\n             if processor_fee_value < 0:\n                 logger.warning(\n                     f\"Calculated processor fee for {payment_method_str} was negative ({processor_fee_value}). Clamping to 0.\"\n@@ -68,60 +69,74 @@\n \n             # Standard rounding for currency (e.g., to 2 decimal places)\n             # Assuming GBP or USD-like currency, typically 2 decimal places.\n             # Using Decimal for precision in financial calculations.\n             quantizer = Decimal(\"0.01\")\n-            rounded_fee = Decimal(str(processor_fee_value)).quantize(quantizer, rounding=ROUND_HALF_UP)\n+            rounded_fee = Decimal(str(processor_fee_value)).quantize(\n+                quantizer, rounding=ROUND_HALF_UP\n+            )\n \n             return float(rounded_fee)\n \n         except ValueError as ve:\n             # This can happen if PlatformSettingsService raises ValueError (e.g., no fee config for payment method)\n-            logger.error(f\"ValueError in PaymentFeeCalculator for {payment_method.value}: {ve}\")\n+            logger.error(\n+                f\"ValueError in PaymentFeeCalculator for {payment_method.value}: {ve}\"\n+            )\n             # Depending on policy, could re-raise, or return a default/error indicator.\n             # For now, let's assume if a fee cannot be calculated, it's 0, but this might need adjustment.\n             # Or, more safely, raise an exception to signal a configuration problem.\n-            raise ve # Re-raise to make it explicit that fee calculation failed\n+            raise ve  # Re-raise to make it explicit that fee calculation failed\n         except Exception as e:\n             logger.error(\n                 f\"Error calculating processor fee for {payment_method.value} on amount {transaction_amount}: {e}\",\n-                exc_info=True\n+                exc_info=True,\n             )\n             # Fallback or re-raise, based on business requirements for error handling.\n             # Raising an exception is often safer for financial calculations to prevent silent errors.\n-            raise Exception(f\"Failed to calculate processor fee for {payment_method.value}: {e}\")\n+            raise Exception(\n+                f\"Failed to calculate processor fee for {payment_method.value}: {e}\"\n+            )\n \n     async def get_payment_method_fee_config(\n-        self,\n-        payment_method: PaymentMethodEnum,\n-        restaurant_id: Optional[str] = None\n+        self, payment_method: PaymentMethodEnum, restaurant_id: Optional[str] = None\n     ) -> Optional[Dict[str, Any]]:\n         \"\"\"\n         Retrieves the fee configuration details for a specific payment method.\n         This might include percentage rates, fixed fees, currency, etc.\n         It primarily relies on `PlatformSettingsService` to get these details.\n         \"\"\"\n         try:\n             payment_method_str = payment_method.value\n             # The fee config is stored under keys like 'payment.fees.stripe'\n-            fee_config_key = f'payment.fees.{payment_method_str}'\n+            fee_config_key = f\"payment.fees.{payment_method_str}\"\n \n             # Use PlatformSettingsService to get the setting\n             # If restaurant_id is provided, it might fetch an override, but raw fee configs are usually platform-level.\n             # For now, let's assume direct fetch of platform setting for the fee structure.\n             # If restaurant-specific fee structures (not just markups) exist, this needs more complex logic.\n \n-            raw_config = await self.platform_settings_service.get_platform_setting(config_key=fee_config_key)\n+            raw_config = await self.platform_settings_service.get_platform_setting(\n+                config_key=fee_config_key\n+            )\n \n-            if raw_config and 'value' in raw_config:\n-                return raw_config['value'] # This should be the dict like {'percentage': 1.4, 'fixed_fee': 0.20, 'currency': 'GBP'}\n+            if raw_config and \"value\" in raw_config:\n+                return raw_config[\n+                    \"value\"\n+                ]  # This should be the dict like {'percentage': 1.4, 'fixed_fee': 0.20, 'currency': 'GBP'}\n             else:\n-                logger.warning(f\"No fee configuration found for payment method '{payment_method_str}' using key '{fee_config_key}'.\")\n+                logger.warning(\n+                    f\"No fee configuration found for payment method '{payment_method_str}' using key '{fee_config_key}'.\"\n+                )\n                 return None\n         except Exception as e:\n-            logger.error(f\"Error retrieving fee configuration for {payment_method.value}: {e}\", exc_info=True)\n+            logger.error(\n+                f\"Error retrieving fee configuration for {payment_method.value}: {e}\",\n+                exc_info=True,\n+            )\n             return None\n+\n \n # Example Usage (conceptual, would be part of another service or API endpoint)\n # async def main():\n #     from app.core.database import SessionLocal\n #     db = SessionLocal()\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/digitalocean_monitor.py\t2025-08-02 21:56:59.002460+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/digitalocean_monitor.py\t2025-08-02 22:36:03.904413+00:00\n@@ -20,79 +20,84 @@\n # Circuit breaker for DigitalOcean API calls\n do_circuit_breaker = CircuitBreaker(\n     fail_max=5,\n     reset_timeout=60,\n     exclude=[httpx.HTTPStatusError],  # Don't trip on 4xx errors\n-    name=\"DigitalOceanAPI\"\n+    name=\"DigitalOceanAPI\",\n )\n \n \n class DigitalOceanMonitorError(Exception):\n     \"\"\"Base exception for DigitalOcean monitoring errors.\"\"\"\n+\n     pass\n \n \n class DigitalOceanAPIError(DigitalOceanMonitorError):\n     \"\"\"Raised when DigitalOcean API returns an error.\"\"\"\n+\n     def __init__(self, status_code: int, message: str):\n         self.status_code = status_code\n         super().__init__(f\"DO API error {status_code}: {message}\")\n \n \n class DigitalOceanConfigError(DigitalOceanMonitorError):\n     \"\"\"Raised when DigitalOcean monitoring is not properly configured.\"\"\"\n+\n     pass\n \n \n class DigitalOceanMonitor:\n     \"\"\"\n     Monitor DigitalOcean App Platform instances and deployments.\n-    \n+\n     Uses the DigitalOcean API to get accurate information about:\n     - Current app configuration\n     - Deployment status\n     - Actual vs desired replica counts\n-    \n+\n     Enhanced with:\n     - Secure token storage\n     - Circuit breaker pattern\n     - Input validation\n     - Proper error handling\n     \"\"\"\n-    \n+\n     def __init__(self):\n         # Load and decrypt API token securely\n         self._api_token = self._load_api_token()\n         self.app_id = self._load_app_id()\n         self.base_url = \"https://api.digitalocean.com/v2\"\n-        \n+\n         # Configure timeouts based on environment\n         timeout_seconds = 30.0 if settings.ENVIRONMENT == \"production\" else 10.0\n         self.timeout = httpx.Timeout(timeout_seconds)\n-        \n+\n         # Cache configuration\n         self._cache_ttl = 60 if settings.ENVIRONMENT == \"production\" else 30\n         self._cache: Dict[str, Tuple[Any, datetime]] = {}\n-        \n+\n         # HTTP client pool for connection reuse\n         self._client: Optional[httpx.AsyncClient] = None\n-        \n+\n     def _load_api_token(self) -> Optional[str]:\n         \"\"\"Load and decrypt the DigitalOcean API token.\"\"\"\n         encrypted_token = os.environ.get(\"DO_API_TOKEN_ENCRYPTED\")\n         if encrypted_token:\n             try:\n                 token_encryption = TokenEncryption()\n                 return token_encryption.decrypt_token(encrypted_token)\n             except Exception as e:\n                 logger.error(f\"Failed to decrypt DO API token: {type(e).__name__}\")\n                 return None\n-        \n+\n         # No fallback to plain token - must use encrypted token\n-        logger.error(\"DO_API_TOKEN_ENCRYPTED not configured - token encryption is required\")\n+        logger.error(\n+            \"DO_API_TOKEN_ENCRYPTED not configured - token encryption is required\"\n+        )\n         return None\n-    \n+\n     def _load_app_id(self) -> Optional[str]:\n         \"\"\"Load and validate the DigitalOcean app ID.\"\"\"\n         app_id = os.environ.get(\"DO_APP_ID\")\n         if app_id:\n             try:\n@@ -101,164 +106,164 @@\n                     raise ValueError(\"Invalid app ID format\")\n                 return app_id\n             except ValueError as e:\n                 logger.error(f\"Invalid DO_APP_ID format: {e}\")\n         return None\n-    \n+\n     def _is_configured(self) -> bool:\n         \"\"\"Check if DO monitoring is properly configured.\"\"\"\n         return bool(self._api_token and self.app_id)\n-    \n+\n     def _get_headers(self) -> Dict[str, str]:\n         \"\"\"Get headers for DO API requests.\"\"\"\n         if not self._api_token:\n             raise DigitalOceanConfigError(\"API token not configured\")\n-        \n+\n         return {\n             \"Authorization\": f\"Bearer {self._api_token}\",\n             \"Content-Type\": \"application/json\",\n-            \"User-Agent\": f\"Fynlo-Monitoring/{settings.APP_VERSION}\"\n+            \"User-Agent\": f\"Fynlo-Monitoring/{settings.APP_VERSION}\",\n         }\n-    \n+\n     async def _get_client(self) -> httpx.AsyncClient:\n         \"\"\"Get or create HTTP client with connection pooling.\"\"\"\n         if not self._client:\n             self._client = httpx.AsyncClient(\n                 timeout=self.timeout,\n                 limits=httpx.Limits(\n                     max_keepalive_connections=5,\n                     max_connections=10,\n-                    keepalive_expiry=30.0\n+                    keepalive_expiry=30.0,\n                 ),\n-                headers=self._get_headers()\n+                headers=self._get_headers(),\n             )\n         return self._client\n-    \n+\n     def _get_from_cache(self, key: str) -> Optional[Any]:\n         \"\"\"Get value from cache if not expired.\"\"\"\n         if key in self._cache:\n             value, timestamp = self._cache[key]\n             age_seconds = (datetime.now(timezone.utc) - timestamp).total_seconds()\n             if age_seconds < self._cache_ttl:\n                 logger.debug(f\"Cache hit for {key} (age: {age_seconds:.1f}s)\")\n                 return value\n         return None\n-    \n+\n     def _set_cache(self, key: str, value: Any):\n         \"\"\"Store value in cache with timestamp.\"\"\"\n         self._cache[key] = (value, datetime.now(timezone.utc))\n-    \n+\n     def _clear_cache(self):\n         \"\"\"Clear all cached data.\"\"\"\n         self._cache.clear()\n-    \n+\n     @do_circuit_breaker\n     async def get_app_info(self, force_refresh: bool = False) -> Dict[str, Any]:\n         \"\"\"\n         Get current app configuration from DigitalOcean API.\n-        \n+\n         Args:\n             force_refresh: Bypass cache and fetch fresh data\n-            \n+\n         Returns:\n             App configuration including services and replica counts\n-            \n+\n         Raises:\n             DigitalOceanConfigError: If not properly configured\n             DigitalOceanAPIError: If API request fails\n         \"\"\"\n         if not self._is_configured():\n             raise DigitalOceanConfigError(\"DigitalOcean API not configured\")\n-        \n+\n         # Check cache unless force refresh\n         cache_key = f\"app_info_{self.app_id}\"\n         if not force_refresh:\n             cached = self._get_from_cache(cache_key)\n             if cached:\n                 return cached\n-        \n+\n         try:\n             client = await self._get_client()\n             response = await client.get(f\"{self.base_url}/apps/{self.app_id}\")\n-            \n+\n             if response.status_code == 200:\n                 data = response.json()\n                 # Validate response structure\n                 if \"app\" not in data:\n                     raise DigitalOceanAPIError(200, \"Invalid response structure\")\n-                \n+\n                 self._set_cache(cache_key, data)\n                 return data\n             elif response.status_code == 404:\n                 raise DigitalOceanAPIError(404, f\"App {self.app_id} not found\")\n             else:\n                 error_msg = response.json().get(\"message\", response.text)\n                 raise DigitalOceanAPIError(response.status_code, error_msg)\n-                \n+\n         except httpx.TimeoutException:\n             logger.error(\"DigitalOcean API request timed out\")\n             raise DigitalOceanAPIError(0, \"Request timed out\")\n         except httpx.RequestError as e:\n             logger.error(f\"Request error: {type(e).__name__}: {e}\")\n             raise DigitalOceanAPIError(0, f\"Request failed: {type(e).__name__}\")\n         except CircuitBreakerError:\n             logger.warning(\"Circuit breaker is open for DigitalOcean API\")\n             raise DigitalOceanAPIError(0, \"Service temporarily unavailable\")\n-    \n+\n     @do_circuit_breaker\n     async def get_deployments(self, limit: int = 10) -> List[Dict[str, Any]]:\n         \"\"\"\n         Get recent deployment history.\n-        \n+\n         Args:\n             limit: Number of recent deployments to fetch (max 200)\n-            \n+\n         Returns:\n             List of deployment records\n-            \n+\n         Raises:\n             DigitalOceanConfigError: If not properly configured\n             DigitalOceanAPIError: If API request fails\n         \"\"\"\n         if not self._is_configured():\n             raise DigitalOceanConfigError(\"DigitalOcean API not configured\")\n-        \n+\n         # Validate limit\n         limit = min(max(1, limit), 200)\n-        \n+\n         cache_key = f\"deployments_{self.app_id}_{limit}\"\n         cached = self._get_from_cache(cache_key)\n         if cached:\n             return cached\n-        \n+\n         try:\n             client = await self._get_client()\n             response = await client.get(\n                 f\"{self.base_url}/apps/{self.app_id}/deployments\",\n-                params={\"per_page\": limit}\n+                params={\"per_page\": limit},\n             )\n-            \n+\n             if response.status_code == 200:\n                 data = response.json()\n                 deployments = data.get(\"deployments\", [])\n                 self._set_cache(cache_key, deployments)\n                 return deployments\n             else:\n                 logger.error(f\"Failed to fetch deployments: {response.status_code}\")\n                 return []\n-                \n+\n         except Exception as e:\n             logger.error(f\"Error fetching deployments: {type(e).__name__}: {e}\")\n             return []\n-    \n+\n     async def get_actual_replicas(self) -> Dict[str, Any]:\n         \"\"\"\n         Get actual replica count and status for the backend service.\n-        \n+\n         Returns:\n             Dictionary with replica information and status\n-            \n+\n         Raises:\n             DigitalOceanConfigError: If not properly configured\n             DigitalOceanAPIError: If API request fails\n         \"\"\"\n         try:\n@@ -266,212 +271,221 @@\n         except DigitalOceanMonitorError:\n             raise\n         except Exception as e:\n             logger.error(f\"Unexpected error getting app info: {type(e).__name__}: {e}\")\n             raise DigitalOceanAPIError(0, f\"Unexpected error: {type(e).__name__}\")\n-        \n+\n         app = app_info.get(\"app\", {})\n-        \n+\n         # Find backend service in the app configuration\n         backend_info = None\n         for service in app.get(\"spec\", {}).get(\"services\", []):\n             if service.get(\"name\") == \"backend\":\n                 backend_info = service\n                 break\n-        \n+\n         if not backend_info:\n             raise DigitalOceanAPIError(404, \"Backend service not found in app spec\")\n-        \n+\n         # Get deployment status\n         deployment_id = app.get(\"active_deployment\", {}).get(\"id\")\n         deployment_phase = app.get(\"active_deployment\", {}).get(\"phase\")\n-        \n+\n         # Extract replica information\n         result = {\n             \"service_name\": \"backend\",\n             \"desired_replicas\": backend_info.get(\"instance_count\", 0),\n             \"instance_size\": backend_info.get(\"instance_size_slug\", \"unknown\"),\n             \"deployment\": {\n                 \"id\": deployment_id,\n                 \"phase\": deployment_phase,\n                 \"updated_at\": app.get(\"updated_at\"),\n-                \"created_at\": app.get(\"created_at\")\n+                \"created_at\": app.get(\"created_at\"),\n             },\n             \"status\": {\n                 \"phase\": deployment_phase,\n                 \"tier_slug\": app.get(\"tier_slug\"),\n-                \"pending_deployment\": app.get(\"pending_deployment\") is not None\n+                \"pending_deployment\": app.get(\"pending_deployment\") is not None,\n             },\n             \"region\": app.get(\"region\", {}).get(\"slug\", \"unknown\"),\n             \"app_id\": self.app_id,\n-            \"app_name\": app.get(\"spec\", {}).get(\"name\", \"unknown\")\n+            \"app_name\": app.get(\"spec\", {}).get(\"name\", \"unknown\"),\n         }\n-        \n+\n         # Check live URLs to see if they're responding\n         if app.get(\"live_url\"):\n             result[\"live_url\"] = app.get(\"live_url\")\n-        \n+\n         return result\n-    \n+\n     @do_circuit_breaker\n-    async def get_deployment_logs(self, deployment_id: Optional[str] = None) -> List[str]:\n+    async def get_deployment_logs(\n+        self, deployment_id: Optional[str] = None\n+    ) -> List[str]:\n         \"\"\"\n         Get logs for a specific deployment.\n-        \n+\n         Args:\n             deployment_id: Specific deployment ID, or None for active deployment\n-            \n+\n         Returns:\n             List of log URLs\n-            \n+\n         Raises:\n             DigitalOceanConfigError: If not properly configured\n         \"\"\"\n         if not self._is_configured():\n             raise DigitalOceanConfigError(\"DigitalOcean API not configured\")\n-        \n+\n         # If no deployment ID provided, get the active one\n         if not deployment_id:\n             try:\n                 app_info = await self.get_app_info()\n-                deployment_id = app_info.get(\"app\", {}).get(\"active_deployment\", {}).get(\"id\")\n+                deployment_id = (\n+                    app_info.get(\"app\", {}).get(\"active_deployment\", {}).get(\"id\")\n+                )\n             except Exception as e:\n                 logger.error(f\"Failed to get active deployment: {e}\")\n                 return [\"Failed to get active deployment ID\"]\n-            \n+\n         if not deployment_id:\n             return [\"No active deployment found\"]\n-        \n+\n         try:\n             # Validate deployment ID format\n             InputValidator.validate_instance_id(deployment_id)\n-            \n+\n             client = await self._get_client()\n             response = await client.get(\n                 f\"{self.base_url}/apps/{self.app_id}/deployments/{deployment_id}/logs\",\n-                params={\n-                    \"type\": \"BUILD\",  # or \"DEPLOY\" or \"RUN\"\n-                    \"follow\": False\n-                }\n+                params={\"type\": \"BUILD\", \"follow\": False},  # or \"DEPLOY\" or \"RUN\"\n             )\n-            \n+\n             if response.status_code == 200:\n                 data = response.json()\n                 return data.get(\"historic_urls\", [])\n             else:\n                 return [f\"Failed to fetch logs: HTTP {response.status_code}\"]\n-                \n+\n         except ValueError as e:\n             return [f\"Invalid deployment ID: {e}\"]\n         except Exception as e:\n             logger.error(f\"Error fetching deployment logs: {type(e).__name__}: {e}\")\n             return [f\"Error: {type(e).__name__}\"]\n-    \n-    async def force_deployment_refresh(self, force_rebuild: bool = False) -> Dict[str, Any]:\n+\n+    async def force_deployment_refresh(\n+        self, force_rebuild: bool = False\n+    ) -> Dict[str, Any]:\n         \"\"\"\n         Trigger a new deployment to refresh metrics.\n-        \n+\n         WARNING: This will cause a brief downtime during deployment.\n         Should only be used when absolutely necessary.\n-        \n+\n         Args:\n             force_rebuild: Whether to force rebuild containers\n-            \n+\n         Returns:\n             Deployment response or error\n-            \n+\n         Raises:\n             DigitalOceanConfigError: If not properly configured\n             DigitalOceanAPIError: If deployment fails\n         \"\"\"\n         if not self._is_configured():\n             raise DigitalOceanConfigError(\"DigitalOcean API not configured\")\n-        \n+\n         if settings.ENVIRONMENT == \"production\":\n             logger.warning(\"Attempting to force deployment refresh in production!\")\n-        \n+\n         # This operation should not be cached\n         self._clear_cache()\n-        \n+\n         try:\n             client = await self._get_client()\n             response = await client.post(\n                 f\"{self.base_url}/apps/{self.app_id}/deployments\",\n-                json={\n-                    \"force_rebuild\": force_rebuild\n-                }\n+                json={\"force_rebuild\": force_rebuild},\n             )\n-            \n+\n             if response.status_code in [200, 201]:\n                 data = response.json()\n                 deployment = data.get(\"deployment\", {})\n                 logger.info(f\"Deployment triggered: {deployment.get('id')}\")\n                 return data\n             else:\n                 error_msg = response.json().get(\"message\", response.text)\n                 raise DigitalOceanAPIError(response.status_code, error_msg)\n-                \n+\n         except httpx.RequestError as e:\n-            logger.error(f\"Request error triggering deployment: {type(e).__name__}: {e}\")\n+            logger.error(\n+                f\"Request error triggering deployment: {type(e).__name__}: {e}\"\n+            )\n             raise DigitalOceanAPIError(0, f\"Request failed: {type(e).__name__}\")\n-    \n+\n     async def get_metrics_summary(self) -> Dict[str, Any]:\n         \"\"\"\n         Get a summary of app metrics and status.\n-        \n+\n         Returns:\n             Summary of current app state and metrics\n         \"\"\"\n         summary = {\n             \"configured\": self._is_configured(),\n             \"circuit_breaker_state\": do_circuit_breaker.state.name,\n             \"cache_size\": len(self._cache),\n-            \"last_check\": datetime.now(timezone.utc).isoformat()\n+            \"last_check\": datetime.now(timezone.utc).isoformat(),\n         }\n-        \n+\n         if not self._is_configured():\n             summary[\"error\"] = \"DigitalOcean monitoring not configured\"\n             return summary\n-        \n+\n         try:\n             # Get app info\n             app_info = await self.get_app_info()\n-            \n+\n             # Get actual replicas\n             replica_info = await self.get_actual_replicas()\n-            \n+\n             # Get recent deployments\n             deployments = await self.get_deployments(limit=5)\n-            \n+\n             # Build summary\n-            summary.update({\n-                \"app\": {\n-                    \"id\": self.app_id,\n-                    \"name\": app_info.get(\"app\", {}).get(\"spec\", {}).get(\"name\", \"unknown\"),\n-                    \"region\": app_info.get(\"app\", {}).get(\"region\", {}).get(\"slug\", \"unknown\"),\n-                    \"created_at\": app_info.get(\"app\", {}).get(\"created_at\"),\n-                    \"updated_at\": app_info.get(\"app\", {}).get(\"updated_at\")\n-                },\n-                \"replicas\": replica_info,\n-                \"recent_deployments\": [\n-                    {\n-                        \"id\": d.get(\"id\"),\n-                        \"phase\": d.get(\"phase\"),\n-                        \"created_at\": d.get(\"created_at\"),\n-                        \"cause\": d.get(\"cause\")\n-                    }\n-                    for d in deployments[:3]  # Just show last 3\n-                ]\n-            })\n+            summary.update(\n+                {\n+                    \"app\": {\n+                        \"id\": self.app_id,\n+                        \"name\": app_info.get(\"app\", {})\n+                        .get(\"spec\", {})\n+                        .get(\"name\", \"unknown\"),\n+                        \"region\": app_info.get(\"app\", {})\n+                        .get(\"region\", {})\n+                        .get(\"slug\", \"unknown\"),\n+                        \"created_at\": app_info.get(\"app\", {}).get(\"created_at\"),\n+                        \"updated_at\": app_info.get(\"app\", {}).get(\"updated_at\"),\n+                    },\n+                    \"replicas\": replica_info,\n+                    \"recent_deployments\": [\n+                        {\n+                            \"id\": d.get(\"id\"),\n+                            \"phase\": d.get(\"phase\"),\n+                            \"created_at\": d.get(\"created_at\"),\n+                            \"cause\": d.get(\"cause\"),\n+                        }\n+                        for d in deployments[:3]  # Just show last 3\n+                    ],\n+                }\n+            )\n         except DigitalOceanMonitorError as e:\n             summary[\"error\"] = str(e)\n         except Exception as e:\n             summary[\"error\"] = f\"Unexpected error: {type(e).__name__}\"\n             logger.error(f\"Error getting metrics summary: {type(e).__name__}: {e}\")\n-        \n+\n         return summary\n-    \n+\n     async def close(self):\n         \"\"\"Close HTTP client connections.\"\"\"\n         if self._client:\n             await self._client.aclose()\n             self._client = None\n@@ -492,6 +506,6 @@\n async def close_do_monitor():\n     \"\"\"Close the global DigitalOcean monitor instance.\"\"\"\n     global _do_monitor\n     if _do_monitor:\n         await _do_monitor.close()\n-        _do_monitor = None\n\\ No newline at end of file\n+        _do_monitor = None\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/config_manager.py\t2025-08-02 10:59:17.996857+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/config_manager.py\t2025-08-02 22:36:03.904597+00:00\n@@ -12,384 +12,431 @@\n import json\n from pathlib import Path\n \n logger = logging.getLogger(__name__)\n \n+\n class Environment(Enum):\n     \"\"\"Supported environments\"\"\"\n+\n     DEVELOPMENT = \"development\"\n     STAGING = \"staging\"\n     PRODUCTION = \"production\"\n     TEST = \"test\"\n \n+\n @dataclass\n class ProviderConfig:\n     \"\"\"Configuration for a payment provider\"\"\"\n+\n     name: str\n     enabled: bool = True\n     api_key: Optional[str] = None\n     secret_key: Optional[str] = None\n     environment: str = \"production\"\n     webhook_url: Optional[str] = None\n     timeout_seconds: int = 30\n     retry_attempts: int = 3\n     custom_settings: Dict[str, Any] = field(default_factory=dict)\n \n+\n @dataclass\n class RoutingConfig:\n     \"\"\"Smart routing configuration\"\"\"\n+\n     enabled: bool = True\n     default_strategy: str = \"balanced\"\n-    volume_thresholds: Dict[str, Decimal] = field(default_factory=lambda: {\n-        \"sumup_optimal\": Decimal(\"2714\"),\n-        \"volume_discount\": Decimal(\"10000\"),\n-        \"enterprise\": Decimal(\"50000\")\n-    })\n+    volume_thresholds: Dict[str, Decimal] = field(\n+        default_factory=lambda: {\n+            \"sumup_optimal\": Decimal(\"2714\"),\n+            \"volume_discount\": Decimal(\"10000\"),\n+            \"enterprise\": Decimal(\"50000\"),\n+        }\n+    )\n     provider_weights: Dict[str, Dict[str, float]] = field(default_factory=dict)\n     fallback_provider: str = \"stripe\"\n+\n \n @dataclass\n class FeatureFlags:\n     \"\"\"Feature flags for payment system\"\"\"\n+\n     smart_routing_enabled: bool = True\n     analytics_enabled: bool = True\n     volume_tracking_enabled: bool = True\n     qr_payments_enabled: bool = True\n     cash_payments_enabled: bool = True\n     auto_refunds_enabled: bool = False\n     webhook_retries_enabled: bool = True\n     cost_optimization_alerts: bool = True\n \n+\n @dataclass\n class SecurityConfig:\n     \"\"\"Security configuration\"\"\"\n+\n     encrypt_api_keys: bool = True\n     webhook_signature_validation: bool = True\n     rate_limiting_enabled: bool = True\n     max_requests_per_minute: int = 100\n     allowed_origins: List[str] = field(default_factory=list)\n     ssl_required: bool = True\n \n+\n class ConfigurationManager:\n     \"\"\"Central configuration manager for payment system\"\"\"\n-    \n+\n     def __init__(self, environment: Optional[Environment] = None):\n         self.environment = environment or self._detect_environment()\n         self.config_dir = Path(__file__).parent.parent.parent / \"config\"\n         self.config_dir.mkdir(exist_ok=True)\n-        \n+\n         # Initialize configurations\n         self.providers: Dict[str, ProviderConfig] = {}\n         self.routing: RoutingConfig = RoutingConfig()\n         self.features: FeatureFlags = FeatureFlags()\n         self.security: SecurityConfig = SecurityConfig()\n-        \n+\n         # Load configurations\n         self._load_configurations()\n-    \n+\n     def _detect_environment(self) -> Environment:\n         \"\"\"Detect current environment from environment variables\"\"\"\n         env_name = os.getenv(\"FYNLO_ENV\", \"development\").lower()\n         try:\n             return Environment(env_name)\n         except ValueError:\n-            logger.warning(f\"Unknown environment '{env_name}', defaulting to development\")\n+            logger.warning(\n+                f\"Unknown environment '{env_name}', defaulting to development\"\n+            )\n             return Environment.DEVELOPMENT\n-    \n+\n     def _load_configurations(self):\n         \"\"\"Load configurations from files and environment variables\"\"\"\n         # Load from JSON config files\n         self._load_from_files()\n-        \n+\n         # Override with environment variables\n         self._load_from_environment()\n-        \n+\n         # Validate configurations\n         self._validate_configurations()\n-    \n+\n     def _load_from_files(self):\n         \"\"\"Load configurations from JSON files\"\"\"\n         config_file = self.config_dir / f\"payment_config_{self.environment.value}.json\"\n-        \n+\n         if config_file.exists():\n             try:\n-                with open(config_file, 'r') as f:\n+                with open(config_file, \"r\") as f:\n                     config_data = json.load(f)\n-                \n+\n                 # Load provider configurations\n                 if \"providers\" in config_data:\n                     for name, provider_data in config_data[\"providers\"].items():\n                         self.providers[name] = ProviderConfig(\n-                            name=name,\n-                            **provider_data\n+                            name=name, **provider_data\n                         )\n-                \n+\n                 # Load routing configuration\n                 if \"routing\" in config_data:\n                     routing_data = config_data[\"routing\"]\n                     self.routing = RoutingConfig(\n                         enabled=routing_data.get(\"enabled\", True),\n-                        default_strategy=routing_data.get(\"default_strategy\", \"balanced\"),\n+                        default_strategy=routing_data.get(\n+                            \"default_strategy\", \"balanced\"\n+                        ),\n                         volume_thresholds={\n-                            k: Decimal(str(v)) \n-                            for k, v in routing_data.get(\"volume_thresholds\", {}).items()\n+                            k: Decimal(str(v))\n+                            for k, v in routing_data.get(\n+                                \"volume_thresholds\", {}\n+                            ).items()\n                         },\n                         provider_weights=routing_data.get(\"provider_weights\", {}),\n-                        fallback_provider=routing_data.get(\"fallback_provider\", \"stripe\")\n+                        fallback_provider=routing_data.get(\n+                            \"fallback_provider\", \"stripe\"\n+                        ),\n                     )\n-                \n+\n                 # Load feature flags\n                 if \"features\" in config_data:\n                     feature_data = config_data[\"features\"]\n                     self.features = FeatureFlags(**feature_data)\n-                \n+\n                 # Load security configuration\n                 if \"security\" in config_data:\n                     security_data = config_data[\"security\"]\n                     self.security = SecurityConfig(**security_data)\n-                \n+\n                 logger.info(f\"Loaded configuration from {config_file}\")\n-                \n+\n             except Exception as e:\n                 logger.error(f\"Failed to load config from {config_file}: {e}\")\n         else:\n             logger.info(f\"No config file found at {config_file}, using defaults\")\n-    \n+\n     def _load_from_environment(self):\n         \"\"\"Load and override configurations from environment variables\"\"\"\n-        \n+\n         # Provider configurations\n         for provider_name in [\"stripe\", \"square\", \"sumup\"]:\n             env_prefix = f\"FYNLO_{provider_name.upper()}_\"\n-            \n+\n             # Check if provider is configured\n             api_key = os.getenv(f\"{env_prefix}API_KEY\")\n             if api_key:\n                 if provider_name not in self.providers:\n                     self.providers[provider_name] = ProviderConfig(name=provider_name)\n-                \n+\n                 provider = self.providers[provider_name]\n                 provider.api_key = api_key\n                 provider.secret_key = os.getenv(f\"{env_prefix}SECRET_KEY\")\n-                provider.environment = os.getenv(f\"{env_prefix}ENVIRONMENT\", \"production\")\n+                provider.environment = os.getenv(\n+                    f\"{env_prefix}ENVIRONMENT\", \"production\"\n+                )\n                 provider.webhook_url = os.getenv(f\"{env_prefix}WEBHOOK_URL\")\n-                \n+\n                 # Provider-specific settings\n                 if provider_name == \"square\":\n-                    provider.custom_settings[\"location_id\"] = os.getenv(f\"{env_prefix}LOCATION_ID\")\n+                    provider.custom_settings[\"location_id\"] = os.getenv(\n+                        f\"{env_prefix}LOCATION_ID\"\n+                    )\n                 elif provider_name == \"sumup\":\n-                    provider.custom_settings[\"merchant_code\"] = os.getenv(f\"{env_prefix}MERCHANT_CODE\")\n-        \n+                    provider.custom_settings[\"merchant_code\"] = os.getenv(\n+                        f\"{env_prefix}MERCHANT_CODE\"\n+                    )\n+\n         # Routing configuration overrides\n         if os.getenv(\"FYNLO_ROUTING_ENABLED\"):\n             self.routing.enabled = os.getenv(\"FYNLO_ROUTING_ENABLED\").lower() == \"true\"\n-        \n+\n         if os.getenv(\"FYNLO_ROUTING_STRATEGY\"):\n             self.routing.default_strategy = os.getenv(\"FYNLO_ROUTING_STRATEGY\")\n-        \n+\n         if os.getenv(\"FYNLO_FALLBACK_PROVIDER\"):\n             self.routing.fallback_provider = os.getenv(\"FYNLO_FALLBACK_PROVIDER\")\n-        \n+\n         # Feature flag overrides\n         feature_mapping = {\n             \"FYNLO_SMART_ROUTING\": \"smart_routing_enabled\",\n             \"FYNLO_ANALYTICS\": \"analytics_enabled\",\n             \"FYNLO_VOLUME_TRACKING\": \"volume_tracking_enabled\",\n             \"FYNLO_QR_PAYMENTS\": \"qr_payments_enabled\",\n             \"FYNLO_CASH_PAYMENTS\": \"cash_payments_enabled\",\n             \"FYNLO_AUTO_REFUNDS\": \"auto_refunds_enabled\",\n             \"FYNLO_WEBHOOK_RETRIES\": \"webhook_retries_enabled\",\n-            \"FYNLO_COST_OPTIMIZATION_ALERTS\": \"cost_optimization_alerts\"\n+            \"FYNLO_COST_OPTIMIZATION_ALERTS\": \"cost_optimization_alerts\",\n         }\n-        \n+\n         for env_var, feature_attr in feature_mapping.items():\n             env_value = os.getenv(env_var)\n             if env_value is not None:\n                 setattr(self.features, feature_attr, env_value.lower() == \"true\")\n-        \n+\n         # Security configuration overrides\n         security_mapping = {\n             \"FYNLO_ENCRYPT_API_KEYS\": \"encrypt_api_keys\",\n             \"FYNLO_WEBHOOK_SIGNATURE_VALIDATION\": \"webhook_signature_validation\",\n             \"FYNLO_RATE_LIMITING\": \"rate_limiting_enabled\",\n-            \"FYNLO_SSL_REQUIRED\": \"ssl_required\"\n+            \"FYNLO_SSL_REQUIRED\": \"ssl_required\",\n         }\n-        \n+\n         for env_var, security_attr in security_mapping.items():\n             env_value = os.getenv(env_var)\n             if env_value is not None:\n                 setattr(self.security, security_attr, env_value.lower() == \"true\")\n-        \n+\n         if os.getenv(\"FYNLO_MAX_REQUESTS_PER_MINUTE\"):\n-            self.security.max_requests_per_minute = int(os.getenv(\"FYNLO_MAX_REQUESTS_PER_MINUTE\"))\n-        \n+            self.security.max_requests_per_minute = int(\n+                os.getenv(\"FYNLO_MAX_REQUESTS_PER_MINUTE\")\n+            )\n+\n         if os.getenv(\"FYNLO_ALLOWED_ORIGINS\"):\n-            self.security.allowed_origins = os.getenv(\"FYNLO_ALLOWED_ORIGINS\").split(\",\")\n-    \n+            self.security.allowed_origins = os.getenv(\"FYNLO_ALLOWED_ORIGINS\").split(\n+                \",\"\n+            )\n+\n     def _validate_configurations(self):\n         \"\"\"Validate all configurations and log warnings for issues\"\"\"\n         issues = []\n-        \n+\n         # Validate providers\n         if not self.providers:\n             issues.append(\"No payment providers configured\")\n         else:\n             for name, provider in self.providers.items():\n                 if provider.enabled and not provider.api_key:\n                     issues.append(f\"Provider {name} is enabled but missing API key\")\n-                \n-                if provider.name == \"square\" and not provider.custom_settings.get(\"location_id\"):\n+\n+                if provider.name == \"square\" and not provider.custom_settings.get(\n+                    \"location_id\"\n+                ):\n                     issues.append(f\"Square provider missing location_id\")\n-                \n-                if provider.name == \"sumup\" and not provider.custom_settings.get(\"merchant_code\"):\n+\n+                if provider.name == \"sumup\" and not provider.custom_settings.get(\n+                    \"merchant_code\"\n+                ):\n                     issues.append(f\"SumUp provider missing merchant_code\")\n-        \n+\n         # Validate routing\n-        if self.routing.enabled and self.routing.fallback_provider not in self.providers:\n-            issues.append(f\"Fallback provider '{self.routing.fallback_provider}' not configured\")\n-        \n+        if (\n+            self.routing.enabled\n+            and self.routing.fallback_provider not in self.providers\n+        ):\n+            issues.append(\n+                f\"Fallback provider '{self.routing.fallback_provider}' not configured\"\n+            )\n+\n         # Validate feature dependencies\n         if self.features.smart_routing_enabled and not self.routing.enabled:\n             issues.append(\"Smart routing feature enabled but routing is disabled\")\n-        \n-        if self.features.analytics_enabled and not self.features.volume_tracking_enabled:\n-            logger.warning(\"Analytics enabled without volume tracking may have limited functionality\")\n-        \n+\n+        if (\n+            self.features.analytics_enabled\n+            and not self.features.volume_tracking_enabled\n+        ):\n+            logger.warning(\n+                \"Analytics enabled without volume tracking may have limited functionality\"\n+            )\n+\n         # Log validation results\n         if issues:\n             for issue in issues:\n                 logger.warning(f\"Configuration issue: {issue}\")\n         else:\n             logger.info(\"All configurations validated successfully\")\n-    \n+\n     def get_provider_config(self, provider_name: str) -> Optional[ProviderConfig]:\n         \"\"\"Get configuration for a specific provider\"\"\"\n         return self.providers.get(provider_name.lower())\n-    \n+\n     def get_enabled_providers(self) -> List[str]:\n         \"\"\"Get list of enabled providers\"\"\"\n         return [name for name, config in self.providers.items() if config.enabled]\n-    \n+\n     def is_feature_enabled(self, feature_name: str) -> bool:\n         \"\"\"Check if a feature is enabled\"\"\"\n         return getattr(self.features, feature_name, False)\n-    \n+\n     def get_routing_config(self) -> RoutingConfig:\n         \"\"\"Get routing configuration\"\"\"\n         return self.routing\n-    \n+\n     def get_security_config(self) -> SecurityConfig:\n         \"\"\"Get security configuration\"\"\"\n         return self.security\n-    \n+\n     def save_configuration(self, config_type: str = \"all\"):\n         \"\"\"Save current configuration to file\"\"\"\n         config_file = self.config_dir / f\"payment_config_{self.environment.value}.json\"\n-        \n+\n         config_data = {}\n-        \n+\n         if config_type in [\"all\", \"providers\"]:\n             config_data[\"providers\"] = {\n                 name: {\n                     \"enabled\": provider.enabled,\n                     \"environment\": provider.environment,\n                     \"webhook_url\": provider.webhook_url,\n                     \"timeout_seconds\": provider.timeout_seconds,\n                     \"retry_attempts\": provider.retry_attempts,\n-                    \"custom_settings\": provider.custom_settings\n+                    \"custom_settings\": provider.custom_settings,\n                 }\n                 for name, provider in self.providers.items()\n             }\n-        \n+\n         if config_type in [\"all\", \"routing\"]:\n             config_data[\"routing\"] = {\n                 \"enabled\": self.routing.enabled,\n                 \"default_strategy\": self.routing.default_strategy,\n-                \"volume_thresholds\": {k: str(v) for k, v in self.routing.volume_thresholds.items()},\n+                \"volume_thresholds\": {\n+                    k: str(v) for k, v in self.routing.volume_thresholds.items()\n+                },\n                 \"provider_weights\": self.routing.provider_weights,\n-                \"fallback_provider\": self.routing.fallback_provider\n+                \"fallback_provider\": self.routing.fallback_provider,\n             }\n-        \n+\n         if config_type in [\"all\", \"features\"]:\n             config_data[\"features\"] = {\n                 \"smart_routing_enabled\": self.features.smart_routing_enabled,\n                 \"analytics_enabled\": self.features.analytics_enabled,\n                 \"volume_tracking_enabled\": self.features.volume_tracking_enabled,\n                 \"qr_payments_enabled\": self.features.qr_payments_enabled,\n                 \"cash_payments_enabled\": self.features.cash_payments_enabled,\n                 \"auto_refunds_enabled\": self.features.auto_refunds_enabled,\n                 \"webhook_retries_enabled\": self.features.webhook_retries_enabled,\n-                \"cost_optimization_alerts\": self.features.cost_optimization_alerts\n+                \"cost_optimization_alerts\": self.features.cost_optimization_alerts,\n             }\n-        \n+\n         if config_type in [\"all\", \"security\"]:\n             config_data[\"security\"] = {\n                 \"encrypt_api_keys\": self.security.encrypt_api_keys,\n                 \"webhook_signature_validation\": self.security.webhook_signature_validation,\n                 \"rate_limiting_enabled\": self.security.rate_limiting_enabled,\n                 \"max_requests_per_minute\": self.security.max_requests_per_minute,\n                 \"allowed_origins\": self.security.allowed_origins,\n-                \"ssl_required\": self.security.ssl_required\n+                \"ssl_required\": self.security.ssl_required,\n             }\n-        \n+\n         try:\n-            with open(config_file, 'w') as f:\n+            with open(config_file, \"w\") as f:\n                 json.dump(config_data, f, indent=2, default=str)\n             logger.info(f\"Configuration saved to {config_file}\")\n         except Exception as e:\n             logger.error(f\"Failed to save configuration: {e}\")\n             raise\n-    \n+\n     def update_provider_config(self, provider_name: str, **kwargs):\n         \"\"\"Update provider configuration\"\"\"\n         if provider_name not in self.providers:\n             self.providers[provider_name] = ProviderConfig(name=provider_name)\n-        \n+\n         provider = self.providers[provider_name]\n         for key, value in kwargs.items():\n             if hasattr(provider, key):\n                 setattr(provider, key, value)\n             else:\n                 provider.custom_settings[key] = value\n-        \n+\n         logger.info(f\"Updated configuration for provider {provider_name}\")\n-    \n+\n     def update_feature_flag(self, feature_name: str, enabled: bool):\n         \"\"\"Update a feature flag\"\"\"\n         if hasattr(self.features, feature_name):\n             setattr(self.features, feature_name, enabled)\n             logger.info(f\"Updated feature flag {feature_name} to {enabled}\")\n         else:\n             logger.warning(f\"Unknown feature flag: {feature_name}\")\n-    \n+\n     def get_configuration_summary(self) -> Dict[str, Any]:\n         \"\"\"Get a summary of current configuration\"\"\"\n         return {\n             \"environment\": self.environment.value,\n             \"providers\": {\n                 name: {\n                     \"enabled\": config.enabled,\n                     \"configured\": bool(config.api_key),\n-                    \"environment\": config.environment\n+                    \"environment\": config.environment,\n                 }\n                 for name, config in self.providers.items()\n             },\n             \"routing\": {\n                 \"enabled\": self.routing.enabled,\n                 \"strategy\": self.routing.default_strategy,\n-                \"fallback\": self.routing.fallback_provider\n+                \"fallback\": self.routing.fallback_provider,\n             },\n             \"features\": {\n                 \"smart_routing\": self.features.smart_routing_enabled,\n                 \"analytics\": self.features.analytics_enabled,\n                 \"qr_payments\": self.features.qr_payments_enabled,\n-                \"cash_payments\": self.features.cash_payments_enabled\n+                \"cash_payments\": self.features.cash_payments_enabled,\n             },\n             \"security\": {\n                 \"ssl_required\": self.security.ssl_required,\n                 \"rate_limiting\": self.security.rate_limiting_enabled,\n-                \"webhook_validation\": self.security.webhook_signature_validation\n-            }\n+                \"webhook_validation\": self.security.webhook_signature_validation,\n+            },\n         }\n \n+\n # Global configuration manager instance\n-config_manager = ConfigurationManager()\n\\ No newline at end of file\n+config_manager = ConfigurationManager()\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_providers/base_provider.py\t2025-08-02 21:56:59.004789+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_providers/base_provider.py\t2025-08-02 22:36:03.922364+00:00\n@@ -1,32 +1,39 @@\n from abc import ABC, abstractmethod\n from decimal import Decimal\n from typing import List, Dict, Any, Optional\n from enum import Enum\n+\n \n class PaymentStatus(Enum):\n     SUCCESS = \"success\"\n     PENDING = \"pending\"\n     FAILED = \"failed\"\n     CANCELLED = \"cancelled\"\n     REFUNDED = \"refunded\"\n \n+\n class RefundItemDetail(Dict[str, Any]):\n     line_id: str\n     quantity: int\n-    amount: Optional[Decimal] # Optional: some gateways might take item amount for partial item refund\n+    amount: Optional[\n+        Decimal\n+    ]  # Optional: some gateways might take item amount for partial item refund\n+\n \n class IGatewayRefund(ABC):\n     @abstractmethod\n     async def refund_payment(\n         self,\n-        transaction_id: str, # The original payment transaction ID from the gateway\n+        transaction_id: str,  # The original payment transaction ID from the gateway\n         amount_to_refund: Decimal,\n         reason: Optional[str] = None,\n         items_to_refund: Optional[List[RefundItemDetail]] = None,\n-        order_id: Optional[str] = None, # Fynlo's internal order ID, for logging/reference\n-        **kwargs: Any\n+        order_id: Optional[\n+            str\n+        ] = None,  # Fynlo's internal order ID, for logging/reference\n+        **kwargs: Any,\n     ) -> Dict[str, Any]:\n         \"\"\"\n         Processes a refund through the payment gateway.\n \n         Args:\n@@ -42,18 +49,26 @@\n             including at least 'success' (bool), 'refund_id' (str, gateway's refund ID),\n             'status' (str, e.g., 'succeeded', 'pending', 'failed'), and optionally 'error' (str).\n         \"\"\"\n         pass\n \n-class BasePaymentProvider(IGatewayRefund, ABC): # Make it inherit IGatewayRefund\n-    def __init__(self, api_key: str, api_secret: Optional[str] = None, config: Optional[Dict[str, Any]] = None):\n+\n+class BasePaymentProvider(IGatewayRefund, ABC):  # Make it inherit IGatewayRefund\n+    def __init__(\n+        self,\n+        api_key: str,\n+        api_secret: Optional[str] = None,\n+        config: Optional[Dict[str, Any]] = None,\n+    ):\n         self.api_key = api_key\n         self.api_secret = api_secret\n         self.config = config or {}\n \n     @abstractmethod\n-    async def process_payment(self, amount: Decimal, currency: str, **kwargs) -> Dict[str, Any]:\n+    async def process_payment(\n+        self, amount: Decimal, currency: str, **kwargs\n+    ) -> Dict[str, Any]:\n         pass\n \n     # Other common payment methods (charge, authorize, etc.) would go here.\n     # For now, focusing on refund.\n     async def refund_payment(\n@@ -61,20 +76,24 @@\n         transaction_id: str,\n         amount_to_refund: Decimal,\n         reason: Optional[str] = None,\n         items_to_refund: Optional[List[RefundItemDetail]] = None,\n         order_id: Optional[str] = None,\n-        **kwargs: Any\n+        **kwargs: Any,\n     ) -> Dict[str, Any]:\n         # Default implementation or raise NotImplementedError if all providers must implement it fully\n-        raise NotImplementedError(\"Refund functionality is not implemented for this provider.\")\n+        raise NotImplementedError(\n+            \"Refund functionality is not implemented for this provider.\"\n+        )\n \n     async def get_transaction_details(self, transaction_id: str) -> Dict[str, Any]:\n-        raise NotImplementedError(\"Get transaction details is not implemented for this provider.\")\n+        raise NotImplementedError(\n+            \"Get transaction details is not implemented for this provider.\"\n+        )\n \n     async def void_payment(self, transaction_id: str, **kwargs) -> Dict[str, Any]:\n         raise NotImplementedError(\"Void payment is not implemented for this provider.\")\n \n     # Add other common interface methods as needed\n     async def check_credentials(self) -> bool:\n         \"\"\"Checks if the provided credentials are valid.\"\"\"\n-        return True # Placeholder\n+        return True  # Placeholder\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_config_service.py\t2025-08-02 20:32:29.208039+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_config_service.py\t2025-08-02 22:36:03.924115+00:00\n@@ -2,13 +2,17 @@\n from typing import Optional, List, Dict, Any\n from sqlalchemy.orm import Session\n from sqlalchemy.exc import IntegrityError\n \n from app.models.payment_config import PaymentMethodSetting\n-from app.schemas.fee_schemas import PaymentMethodEnum, PaymentMethodFeeSettingSchema # Reusing for input/output validation\n+from app.schemas.fee_schemas import (\n+    PaymentMethodEnum,\n+    PaymentMethodFeeSettingSchema,\n+)  # Reusing for input/output validation\n \n logger = logging.getLogger(__name__)\n+\n \n class PaymentConfigService:\n     \"\"\"\n     Service for managing payment method fee configurations.\n     These settings determine how processor fees are handled (e.g., who pays, toggling).\n@@ -22,171 +26,277 @@\n         \"\"\"\n         payment_method_value = payment_method.value\n \n         # Try to get restaurant-specific setting\n         if restaurant_id:\n-            setting = self.db.query(PaymentMethodSetting).filter(\n-                PaymentMethodSetting.restaurant_id == restaurant_id,\n-                PaymentMethodSetting.payment_method == payment_method_value\n-            ).first()\n+            setting = (\n+                self.db.query(PaymentMethodSetting)\n+                .filter(\n+                    PaymentMethodSetting.restaurant_id == restaurant_id,\n+                    PaymentMethodSetting.payment_method == payment_method_value,\n+                )\n+                .first()\n+            )\n             if setting:\n-                logger.debug(f\"Found restaurant-specific setting for {payment_method_value} at {restaurant_id}\")\n+                logger.debug(\n+                    f\"Found restaurant-specific setting for {payment_method_value} at {restaurant_id}\"\n+                )\n                 return setting\n \n         # If no restaurant-specific setting or no restaurant_id provided, get platform default\n-        platform_setting = self.db.query(PaymentMethodSetting).filter(\n-            PaymentMethodSetting.restaurant_id.is_(None), # Platform default has NULL restaurant_id\n-            PaymentMethodSetting.payment_method == payment_method_value\n-        ).first()\n+        platform_setting = (\n+            self.db.query(PaymentMethodSetting)\n+            .filter(\n+                PaymentMethodSetting.restaurant_id.is_(\n+                    None\n+                ),  # Platform default has NULL restaurant_id\n+                PaymentMethodSetting.payment_method == payment_method_value,\n+            )\n+            .first()\n+        )\n \n         if platform_setting:\n             logger.debug(f\"Found platform default setting for {payment_method_value}\")\n         else:\n-            logger.warning(f\"No platform default setting found for payment_method: {payment_method_value}\")\n+            logger.warning(\n+                f\"No platform default setting found for payment_method: {payment_method_value}\"\n+            )\n         return platform_setting\n \n     def get_all_platform_default_settings(self) -> List[PaymentMethodSetting]:\n         \"\"\"Retrieves all platform-level default payment method settings.\"\"\"\n-        return self.db.query(PaymentMethodSetting).filter(\n-            PaymentMethodSetting.restaurant_id.is_(None)\n-        ).order_by(PaymentMethodSetting.payment_method).all()\n-\n-    def get_all_settings_for_restaurant(self, restaurant_id: str) -> List[PaymentMethodSetting]:\n+        return (\n+            self.db.query(PaymentMethodSetting)\n+            .filter(PaymentMethodSetting.restaurant_id.is_(None))\n+            .order_by(PaymentMethodSetting.payment_method)\n+            .all()\n+        )\n+\n+    def get_all_settings_for_restaurant(\n+        self, restaurant_id: str\n+    ) -> List[PaymentMethodSetting]:\n         \"\"\"Retrieves all specific settings for a given restaurant.\"\"\"\n-        return self.db.query(PaymentMethodSetting).filter(\n-            PaymentMethodSetting.restaurant_id == restaurant_id\n-        ).order_by(PaymentMethodSetting.payment_method).all()\n-\n-    def create_platform_default_setting(self, setting_data: PaymentMethodFeeSettingSchema) -> Optional[PaymentMethodSetting]:\n+        return (\n+            self.db.query(PaymentMethodSetting)\n+            .filter(PaymentMethodSetting.restaurant_id == restaurant_id)\n+            .order_by(PaymentMethodSetting.payment_method)\n+            .all()\n+        )\n+\n+    def create_platform_default_setting(\n+        self, setting_data: PaymentMethodFeeSettingSchema\n+    ) -> Optional[PaymentMethodSetting]:\n         \"\"\"\n         Creates a new platform-default payment method setting.\n         `restaurant_id` in `setting_data` should be None or not provided.\n         \"\"\"\n-        logger.info(f\"Attempting to create platform default setting for: {setting_data.get('payment_method')}\")\n-        if setting_data.get('restaurant_id') is not None:\n+        logger.info(\n+            f\"Attempting to create platform default setting for: {setting_data.get('payment_method')}\"\n+        )\n+        if setting_data.get(\"restaurant_id\") is not None:\n             logger.error(\"Cannot create platform default with a restaurant_id.\")\n             raise ValueError(\"Platform default settings must not have a restaurant_id.\")\n \n-        existing_default = self.db.query(PaymentMethodSetting).filter(\n-            PaymentMethodSetting.restaurant_id.is_(None),\n-            PaymentMethodSetting.payment_method == setting_data['payment_method'].value\n-        ).first()\n+        existing_default = (\n+            self.db.query(PaymentMethodSetting)\n+            .filter(\n+                PaymentMethodSetting.restaurant_id.is_(None),\n+                PaymentMethodSetting.payment_method\n+                == setting_data[\"payment_method\"].value,\n+            )\n+            .first()\n+        )\n \n         if existing_default:\n-            logger.warning(f\"Platform default for {setting_data['payment_method'].value} already exists. Use update.\")\n-            raise IntegrityError(f\"Platform default for {setting_data['payment_method'].value} already exists.\", params={}, orig=None)\n+            logger.warning(\n+                f\"Platform default for {setting_data['payment_method'].value} already exists. Use update.\"\n+            )\n+            raise IntegrityError(\n+                f\"Platform default for {setting_data['payment_method'].value} already exists.\",\n+                params={},\n+                orig=None,\n+            )\n \n         db_setting = PaymentMethodSetting(\n-            payment_method=setting_data['payment_method'].value,\n-            customer_pays_default=setting_data.get('customer_pays_default', True),\n-            allow_toggle_by_merchant=setting_data.get('allow_toggle_by_merchant', True),\n-            include_processor_fee_in_service_charge=setting_data.get('include_processor_fee_in_service_charge', True),\n-            restaurant_id=None\n+            payment_method=setting_data[\"payment_method\"].value,\n+            customer_pays_default=setting_data.get(\"customer_pays_default\", True),\n+            allow_toggle_by_merchant=setting_data.get(\"allow_toggle_by_merchant\", True),\n+            include_processor_fee_in_service_charge=setting_data.get(\n+                \"include_processor_fee_in_service_charge\", True\n+            ),\n+            restaurant_id=None,\n         )\n         try:\n             self.db.add(db_setting)\n             self.db.commit()\n             self.db.refresh(db_setting)\n-            logger.info(f\"Created platform default setting for {db_setting.payment_method}, ID: {db_setting.id}\")\n+            logger.info(\n+                f\"Created platform default setting for {db_setting.payment_method}, ID: {db_setting.id}\"\n+            )\n             return db_setting\n         except IntegrityError as e:\n             self.db.rollback()\n-            logger.error(f\"Integrity error creating platform default setting for {setting_data['payment_method'].value}: {e}\")\n+            logger.error(\n+                f\"Integrity error creating platform default setting for {setting_data['payment_method'].value}: {e}\"\n+            )\n             raise\n         except Exception as e:\n             self.db.rollback()\n-            logger.error(f\"Unexpected error creating platform default setting: {e}\", exc_info=True)\n-            raise\n-\n-    def update_platform_default_setting(self, payment_method: PaymentMethodEnum, updates: Dict[str, Any]) -> Optional[PaymentMethodSetting]:\n+            logger.error(\n+                f\"Unexpected error creating platform default setting: {e}\",\n+                exc_info=True,\n+            )\n+            raise\n+\n+    def update_platform_default_setting(\n+        self, payment_method: PaymentMethodEnum, updates: Dict[str, Any]\n+    ) -> Optional[PaymentMethodSetting]:\n         \"\"\"Updates an existing platform-default payment method setting.\"\"\"\n-        logger.info(f\"Attempting to update platform default setting for: {payment_method.value} with data: {updates}\")\n-        db_setting = self.db.query(PaymentMethodSetting).filter(\n-            PaymentMethodSetting.restaurant_id.is_(None),\n-            PaymentMethodSetting.payment_method == payment_method.value\n-        ).first()\n+        logger.info(\n+            f\"Attempting to update platform default setting for: {payment_method.value} with data: {updates}\"\n+        )\n+        db_setting = (\n+            self.db.query(PaymentMethodSetting)\n+            .filter(\n+                PaymentMethodSetting.restaurant_id.is_(None),\n+                PaymentMethodSetting.payment_method == payment_method.value,\n+            )\n+            .first()\n+        )\n \n         if not db_setting:\n-            logger.warning(f\"No platform default setting found for {payment_method.value} to update.\")\n+            logger.warning(\n+                f\"No platform default setting found for {payment_method.value} to update.\"\n+            )\n             return None\n \n         for key, value in updates.items():\n-            if hasattr(db_setting, key) and key not in ['id', 'payment_method', 'restaurant_id']:\n+            if hasattr(db_setting, key) and key not in [\n+                \"id\",\n+                \"payment_method\",\n+                \"restaurant_id\",\n+            ]:\n                 setattr(db_setting, key, value)\n \n         try:\n             self.db.commit()\n             self.db.refresh(db_setting)\n-            logger.info(f\"Updated platform default setting for {db_setting.payment_method}\")\n+            logger.info(\n+                f\"Updated platform default setting for {db_setting.payment_method}\"\n+            )\n             return db_setting\n         except Exception as e:\n             self.db.rollback()\n-            logger.error(f\"Error updating platform default setting for {payment_method.value}: {e}\", exc_info=True)\n-            raise\n-\n-    def create_or_update_restaurant_setting(self, restaurant_id: str, setting_data: PaymentMethodFeeSettingSchema) -> Optional[PaymentMethodSetting]:\n+            logger.error(\n+                f\"Error updating platform default setting for {payment_method.value}: {e}\",\n+                exc_info=True,\n+            )\n+            raise\n+\n+    def create_or_update_restaurant_setting(\n+        self, restaurant_id: str, setting_data: PaymentMethodFeeSettingSchema\n+    ) -> Optional[PaymentMethodSetting]:\n         \"\"\"\n         Creates or updates a restaurant-specific payment method setting.\n         \"\"\"\n-        logger.info(f\"Attempting to create/update restaurant setting for: {restaurant_id}, method: {setting_data.get('payment_method')}\")\n+        logger.info(\n+            f\"Attempting to create/update restaurant setting for: {restaurant_id}, method: {setting_data.get('payment_method')}\"\n+        )\n         if not restaurant_id:\n-            raise ValueError(\"restaurant_id is required for restaurant-specific settings.\")\n-\n-        payment_method_value = setting_data['payment_method'].value\n-\n-        db_setting = self.db.query(PaymentMethodSetting).filter(\n-            PaymentMethodSetting.restaurant_id == restaurant_id,\n-            PaymentMethodSetting.payment_method == payment_method_value\n-        ).first()\n-\n-        if db_setting: # Update existing\n-            logger.debug(f\"Updating existing setting for {restaurant_id}, method {payment_method_value}\")\n-            if 'customer_pays_default' in setting_data:\n-                db_setting.customer_pays_default = setting_data['customer_pays_default']\n-            if 'allow_toggle_by_merchant' in setting_data:\n-                db_setting.allow_toggle_by_merchant = setting_data['allow_toggle_by_merchant']\n-            if 'include_processor_fee_in_service_charge' in setting_data:\n-                db_setting.include_processor_fee_in_service_charge = setting_data['include_processor_fee_in_service_charge']\n-        else: # Create new\n-            logger.debug(f\"Creating new setting for {restaurant_id}, method {payment_method_value}\")\n+            raise ValueError(\n+                \"restaurant_id is required for restaurant-specific settings.\"\n+            )\n+\n+        payment_method_value = setting_data[\"payment_method\"].value\n+\n+        db_setting = (\n+            self.db.query(PaymentMethodSetting)\n+            .filter(\n+                PaymentMethodSetting.restaurant_id == restaurant_id,\n+                PaymentMethodSetting.payment_method == payment_method_value,\n+            )\n+            .first()\n+        )\n+\n+        if db_setting:  # Update existing\n+            logger.debug(\n+                f\"Updating existing setting for {restaurant_id}, method {payment_method_value}\"\n+            )\n+            if \"customer_pays_default\" in setting_data:\n+                db_setting.customer_pays_default = setting_data[\"customer_pays_default\"]\n+            if \"allow_toggle_by_merchant\" in setting_data:\n+                db_setting.allow_toggle_by_merchant = setting_data[\n+                    \"allow_toggle_by_merchant\"\n+                ]\n+            if \"include_processor_fee_in_service_charge\" in setting_data:\n+                db_setting.include_processor_fee_in_service_charge = setting_data[\n+                    \"include_processor_fee_in_service_charge\"\n+                ]\n+        else:  # Create new\n+            logger.debug(\n+                f\"Creating new setting for {restaurant_id}, method {payment_method_value}\"\n+            )\n             db_setting = PaymentMethodSetting(\n                 restaurant_id=restaurant_id,\n                 payment_method=payment_method_value,\n-                customer_pays_default=setting_data.get('customer_pays_default', True),\n-                allow_toggle_by_merchant=setting_data.get('allow_toggle_by_merchant', True),\n-                include_processor_fee_in_service_charge=setting_data.get('include_processor_fee_in_service_charge', True)\n+                customer_pays_default=setting_data.get(\"customer_pays_default\", True),\n+                allow_toggle_by_merchant=setting_data.get(\n+                    \"allow_toggle_by_merchant\", True\n+                ),\n+                include_processor_fee_in_service_charge=setting_data.get(\n+                    \"include_processor_fee_in_service_charge\", True\n+                ),\n             )\n             self.db.add(db_setting)\n \n         try:\n             self.db.commit()\n             self.db.refresh(db_setting)\n-            logger.info(f\"Saved restaurant setting for {restaurant_id}, method {payment_method_value}, ID: {db_setting.id}\")\n+            logger.info(\n+                f\"Saved restaurant setting for {restaurant_id}, method {payment_method_value}, ID: {db_setting.id}\"\n+            )\n             return db_setting\n         except IntegrityError as e:\n             self.db.rollback()\n-            logger.error(f\"Integrity error for restaurant {restaurant_id}, method {payment_method_value}: {e}\")\n+            logger.error(\n+                f\"Integrity error for restaurant {restaurant_id}, method {payment_method_value}: {e}\"\n+            )\n             raise\n         except Exception as e:\n             self.db.rollback()\n-            logger.error(f\"Unexpected error for restaurant {restaurant_id}, method {payment_method_value}: {e}\", exc_info=True)\n-            raise\n-\n-    def delete_restaurant_setting(self, restaurant_id: str, payment_method: PaymentMethodEnum) -> bool:\n+            logger.error(\n+                f\"Unexpected error for restaurant {restaurant_id}, method {payment_method_value}: {e}\",\n+                exc_info=True,\n+            )\n+            raise\n+\n+    def delete_restaurant_setting(\n+        self, restaurant_id: str, payment_method: PaymentMethodEnum\n+    ) -> bool:\n         \"\"\"Deletes a restaurant-specific setting. Platform defaults cannot be deleted via this method.\"\"\"\n-        logger.info(f\"Attempting to delete restaurant setting for: {restaurant_id}, method: {payment_method.value}\")\n+        logger.info(\n+            f\"Attempting to delete restaurant setting for: {restaurant_id}, method: {payment_method.value}\"\n+        )\n         if not restaurant_id:\n             logger.error(\"Cannot delete setting: restaurant_id is required.\")\n-            return False # Or raise error\n-\n-        db_setting = self.db.query(PaymentMethodSetting).filter(\n-            PaymentMethodSetting.restaurant_id == restaurant_id,\n-            PaymentMethodSetting.payment_method == payment_method.value\n-        ).first()\n+            return False  # Or raise error\n+\n+        db_setting = (\n+            self.db.query(PaymentMethodSetting)\n+            .filter(\n+                PaymentMethodSetting.restaurant_id == restaurant_id,\n+                PaymentMethodSetting.payment_method == payment_method.value,\n+            )\n+            .first()\n+        )\n \n         if db_setting:\n             self.db.delete(db_setting)\n             self.db.commit()\n-            logger.info(f\"Deleted restaurant setting for {restaurant_id}, method {payment_method.value}\")\n+            logger.info(\n+                f\"Deleted restaurant setting for {restaurant_id}, method {payment_method.value}\"\n+            )\n             return True\n-        logger.warning(f\"No setting found to delete for restaurant {restaurant_id}, method {payment_method.value}\")\n+        logger.warning(\n+            f\"No setting found to delete for restaurant {restaurant_id}, method {payment_method.value}\"\n+        )\n         return False\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_factory.py\t2025-08-02 21:56:59.004058+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_factory.py\t2025-08-02 22:36:03.928358+00:00\n@@ -11,79 +11,92 @@\n from ..core.database import get_db\n import logging\n \n logger = logging.getLogger(__name__)\n \n+\n class PaymentProviderFactory:\n     \"\"\"Factory for creating and managing payment providers with smart routing\"\"\"\n-    \n+\n     def __init__(self):\n-        self.providers: Dict[str, BasePaymentProvider] = {} # Changed type hint\n+        self.providers: Dict[str, BasePaymentProvider] = {}  # Changed type hint\n         self.smart_router = None\n         self.analytics_service = None\n         self._initialize_providers()\n \n     def _initialize_smart_routing(self, db_session):\n         \"\"\"Initialize smart routing service with database session\"\"\"\n         if not self.analytics_service:\n             self.analytics_service = PaymentAnalyticsService(db_session)\n         if not self.smart_router:\n             self.smart_router = SmartRoutingService(self.analytics_service)\n-    \n+\n     def _initialize_providers(self):\n         \"\"\"Initialize all configured payment providers\"\"\"\n         # Initialize Stripe\n-        if hasattr(settings, 'STRIPE_API_KEY') and settings.STRIPE_API_KEY:\n-            self.providers[\"stripe\"] = StripeProvider({\n-                \"api_key\": settings.STRIPE_API_KEY\n-            })\n-        \n+        if hasattr(settings, \"STRIPE_API_KEY\") and settings.STRIPE_API_KEY:\n+            self.providers[\"stripe\"] = StripeProvider(\n+                {\"api_key\": settings.STRIPE_API_KEY}\n+            )\n+\n         # Initialize Square (temporarily disabled for testing)\n         # if (hasattr(settings, 'SQUARE_ACCESS_TOKEN') and settings.SQUARE_ACCESS_TOKEN and\n         #     hasattr(settings, 'SQUARE_LOCATION_ID') and settings.SQUARE_LOCATION_ID):\n         #     self.providers[\"square\"] = SquareProvider({\n         #         \"access_token\": settings.SQUARE_ACCESS_TOKEN,\n         #         \"location_id\": settings.SQUARE_LOCATION_ID,\n         #         \"environment\": getattr(settings, 'SQUARE_ENVIRONMENT', 'production')\n         #     })\n-        \n+\n         # Initialize SumUp\n-        if (hasattr(settings, 'SUMUP_API_KEY') and settings.SUMUP_API_KEY and\n-            hasattr(settings, 'SUMUP_MERCHANT_CODE') and settings.SUMUP_MERCHANT_CODE):\n-            self.providers[\"sumup\"] = SumUpProvider({\n-                \"api_key\": settings.SUMUP_API_KEY,\n-                \"merchant_code\": settings.SUMUP_MERCHANT_CODE\n-            })\n+        if (\n+            hasattr(settings, \"SUMUP_API_KEY\")\n+            and settings.SUMUP_API_KEY\n+            and hasattr(settings, \"SUMUP_MERCHANT_CODE\")\n+            and settings.SUMUP_MERCHANT_CODE\n+        ):\n+            self.providers[\"sumup\"] = SumUpProvider(\n+                {\n+                    \"api_key\": settings.SUMUP_API_KEY,\n+                    \"merchant_code\": settings.SUMUP_MERCHANT_CODE,\n+                }\n+            )\n \n         # Initialize CashProvider (does not require settings typically)\n         self.providers[\"cash\"] = CashProvider()\n         logger.info(\"Cash provider initialized.\")\n \n-    def get_provider(self, provider_name: str) -> Optional[BasePaymentProvider]: # Changed return type hint\n+    def get_provider(\n+        self, provider_name: str\n+    ) -> Optional[BasePaymentProvider]:  # Changed return type hint\n         \"\"\"Get a specific payment provider by name\"\"\"\n         provider = self.providers.get(provider_name.lower())\n         if not provider:\n-            logger.warning(f\"Payment provider '{provider_name}' not found or not configured.\")\n+            logger.warning(\n+                f\"Payment provider '{provider_name}' not found or not configured.\"\n+            )\n         return provider\n \n     def get_refund_provider(self, provider_name: str) -> Optional[IGatewayRefund]:\n         \"\"\"Get a specific payment provider that implements IGatewayRefund.\"\"\"\n         provider = self.get_provider(provider_name)\n         if isinstance(provider, IGatewayRefund):\n             return provider\n-        logger.warning(f\"Provider '{provider_name}' does not support refunds or is not correctly configured.\")\n+        logger.warning(\n+            f\"Provider '{provider_name}' does not support refunds or is not correctly configured.\"\n+        )\n         return None\n \n     async def select_optimal_provider(\n         self,\n         amount: Decimal,\n         restaurant_id: str,\n         monthly_volume: Optional[Decimal] = None,\n         force_provider: Optional[str] = None,\n         strategy: RoutingStrategy = RoutingStrategy.BALANCED,\n-        db_session = None\n-    ) -> BasePaymentProvider: # Changed return type hint\n+        db_session=None,\n+    ) -> BasePaymentProvider:  # Changed return type hint\n         \"\"\"\n         Select the optimal payment provider using smart routing based on:\n         - Transaction amount and restaurant volume\n         - Provider performance and reliability\n         - Cost optimization and routing strategy\n@@ -93,174 +106,174 @@\n         if force_provider:\n             provider = self.get_provider(force_provider)\n             if provider:\n                 logger.info(f\"Using forced provider: {force_provider}\")\n                 return provider\n-        \n+\n         # Initialize smart routing if database session is available\n         if db_session and not self.smart_router:\n             self._initialize_smart_routing(db_session)\n-        \n+\n         # Use smart routing if available\n         if self.smart_router:\n             try:\n                 routing_decision = await self.smart_router.route_payment(\n                     amount=amount,\n                     restaurant_id=restaurant_id,\n                     strategy=strategy,\n-                    force_provider=force_provider\n+                    force_provider=force_provider,\n                 )\n-                \n+\n                 provider = self.get_provider(routing_decision.selected_provider)\n                 if provider:\n                     logger.info(\n                         f\"Smart routing selected {routing_decision.selected_provider} \"\n                         f\"(confidence: {routing_decision.confidence:.2f}, \"\n                         f\"reasoning: {', '.join(routing_decision.reasoning)})\"\n                     )\n                     return provider\n             except Exception as e:\n-                logger.warning(f\"Smart routing failed, falling back to simple selection: {e}\")\n-        \n+                logger.warning(\n+                    f\"Smart routing failed, falling back to simple selection: {e}\"\n+                )\n+\n         # Fallback to simple cost-based selection\n         return await self._select_provider_simple(amount, restaurant_id, monthly_volume)\n-    \n+\n     async def _select_provider_simple(\n         self,\n         amount: Decimal,\n         restaurant_id: str,\n-        monthly_volume: Optional[Decimal] = None\n+        monthly_volume: Optional[Decimal] = None,\n     ) -> BasePaymentProvider:\n         \"\"\"Simple cost-based provider selection (fallback)\"\"\"\n-        \n+\n         # Get restaurant's monthly volume from database if not provided\n         if monthly_volume is None:\n             monthly_volume = await self._get_restaurant_monthly_volume(restaurant_id)\n-        \n+\n         # Calculate costs for each provider\n         provider_costs = self._calculate_provider_costs(amount, monthly_volume)\n-        \n+\n         # Sort by cost and select the cheapest available provider\n         sorted_providers = sorted(provider_costs.items(), key=lambda x: x[1])\n-        \n+\n         for provider_name, cost in sorted_providers:\n             if provider_name in self.providers:\n                 logger.info(\n                     f\"Selected {provider_name} for \u00a3{amount} transaction \"\n                     f\"(monthly volume: \u00a3{monthly_volume}, cost: \u00a3{cost:.2f})\"\n                 )\n                 return self.providers[provider_name]\n-        \n+\n         # Fallback to Stripe if no providers available\n         if \"stripe\" in self.providers:\n             return self.providers[\"stripe\"]\n-        \n+\n         raise ValueError(\"No payment providers available\")\n-    \n+\n     def _calculate_provider_costs(\n-        self,\n-        amount: Decimal,\n-        monthly_volume: Decimal\n+        self, amount: Decimal, monthly_volume: Decimal\n     ) -> Dict[str, Decimal]:\n         \"\"\"Calculate the cost of processing with each provider\"\"\"\n         costs = {}\n-        \n+\n         # Stripe: 1.4% + 20p\n         if \"stripe\" in self.providers:\n             costs[\"stripe\"] = (amount * Decimal(\"0.014\")) + Decimal(\"0.20\")\n-        \n+\n         # Square: 1.75%\n         if \"square\" in self.providers:\n             costs[\"square\"] = amount * Decimal(\"0.0175\")\n-        \n+\n         # SumUp: 0.69% if volume > \u00a32,714/month, else 1.69%\n         if \"sumup\" in self.providers:\n             if monthly_volume >= Decimal(\"2714\"):\n                 # Include amortized monthly fee\n-                transactions_per_month = monthly_volume / Decimal(\"50\")  # Assume avg \u00a350/transaction\n+                transactions_per_month = monthly_volume / Decimal(\n+                    \"50\"\n+                )  # Assume avg \u00a350/transaction\n                 monthly_fee_per_transaction = Decimal(\"19\") / transactions_per_month\n-                costs[\"sumup\"] = (amount * Decimal(\"0.0069\")) + monthly_fee_per_transaction\n+                costs[\"sumup\"] = (\n+                    amount * Decimal(\"0.0069\")\n+                ) + monthly_fee_per_transaction\n             else:\n                 costs[\"sumup\"] = amount * Decimal(\"0.0169\")\n-        \n+\n         return costs\n-    \n+\n     async def _get_restaurant_monthly_volume(self, restaurant_id: str) -> Decimal:\n         \"\"\"Get restaurant's average monthly transaction volume\"\"\"\n         # This would query the database for the restaurant's monthly volume\n         # For now, return a default value\n         from ..crud.payments import get_restaurant_monthly_volume\n+\n         try:\n             return await get_restaurant_monthly_volume(restaurant_id)\n         except Exception as e:\n             # Fallback to default volume\n             return Decimal(\"2000\")  # Default \u00a32,000/month\n-    \n+\n     def get_available_providers(self) -> List[str]:\n         \"\"\"Get list of all available payment providers\"\"\"\n         return list(self.providers.keys())\n-    \n+\n     async def get_routing_recommendations(\n-        self,\n-        restaurant_id: str,\n-        db_session = None\n+        self, restaurant_id: str, db_session=None\n     ) -> Dict:\n         \"\"\"Get smart routing recommendations for a restaurant\"\"\"\n         if db_session:\n             self._initialize_smart_routing(db_session)\n-        \n+\n         if self.smart_router:\n             return await self.smart_router.get_routing_recommendations(restaurant_id)\n         else:\n             return {\"error\": \"Smart routing not available\"}\n-    \n+\n     async def simulate_routing_impact(\n-        self,\n-        restaurant_id: str,\n-        strategy: RoutingStrategy,\n-        db_session = None\n+        self, restaurant_id: str, strategy: RoutingStrategy, db_session=None\n     ) -> Dict:\n         \"\"\"Simulate the impact of changing routing strategy\"\"\"\n         if db_session:\n             self._initialize_smart_routing(db_session)\n-        \n+\n         if self.smart_router:\n             return await self.smart_router.simulate_routing_impact(\n                 restaurant_id, strategy\n             )\n         else:\n             return {\"error\": \"Smart routing not available\"}\n-    \n-    async def get_provider_analytics(\n-        self,\n-        restaurant_id: str,\n-        db_session = None\n-    ) -> Dict:\n+\n+    async def get_provider_analytics(self, restaurant_id: str, db_session=None) -> Dict:\n         \"\"\"Get comprehensive provider analytics\"\"\"\n         if db_session:\n             self._initialize_smart_routing(db_session)\n-        \n+\n         if self.analytics_service:\n-            return await self.analytics_service.get_provider_performance_summary(restaurant_id)\n+            return await self.analytics_service.get_provider_performance_summary(\n+                restaurant_id\n+            )\n         else:\n             return {\"error\": \"Analytics service not available\"}\n-    \n+\n     def calculate_savings(\n         self,\n         amount: Decimal,\n         monthly_volume: Decimal,\n         current_provider: str,\n-        optimal_provider: str\n+        optimal_provider: str,\n     ) -> Decimal:\n         \"\"\"Calculate potential savings by switching providers\"\"\"\n         costs = self._calculate_provider_costs(amount, monthly_volume)\n         current_cost = costs.get(current_provider, Decimal(\"0\"))\n         optimal_cost = costs.get(optimal_provider, Decimal(\"0\"))\n         return current_cost - optimal_cost\n \n+\n # Global factory instance\n payment_factory = PaymentProviderFactory()\n+\n \n # Convenience function for backwards compatibility\n def get_payment_provider(provider_name: str):\n     \"\"\"Get payment provider by name\"\"\"\n-    return payment_factory.get_provider(provider_name)\n\\ No newline at end of file\n+    return payment_factory.get_provider(provider_name)\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_providers/base.py\t2025-08-02 21:56:59.004652+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_providers/base.py\t2025-08-02 22:36:03.931004+00:00\n@@ -12,10 +12,11 @@\n logger = logging.getLogger(__name__)\n \n \n class PaymentStatus(Enum):\n     \"\"\"Payment status enum\"\"\"\n+\n     PENDING = \"pending\"\n     PROCESSING = \"processing\"\n     COMPLETED = \"completed\"\n     FAILED = \"failed\"\n     CANCELLED = \"cancelled\"\n@@ -23,238 +24,228 @@\n     PARTIAL_REFUND = \"partial_refund\"\n \n \n class PaymentProvider(ABC):\n     \"\"\"Abstract base class for payment providers\"\"\"\n-    \n+\n     def __init__(self, config: Dict[str, Any]):\n         \"\"\"\n         Initialize payment provider with configuration\n-        \n+\n         Args:\n             config: Provider-specific configuration including credentials\n         \"\"\"\n         self.config = config\n-        self.provider_name = self.__class__.__name__.replace('Provider', '').lower()\n+        self.provider_name = self.__class__.__name__.replace(\"Provider\", \"\").lower()\n         self.logger = logging.getLogger(f\"{__name__}.{self.provider_name}\")\n-    \n+\n     @abstractmethod\n     async def initialize(self) -> bool:\n         \"\"\"\n         Initialize the payment provider connection\n-        \n+\n         Returns:\n             bool: True if initialization successful\n         \"\"\"\n         pass\n-    \n+\n     @abstractmethod\n     async def create_payment(\n-        self, \n-        amount: Decimal, \n+        self,\n+        amount: Decimal,\n         currency: str,\n         order_id: str,\n         customer_info: Dict[str, Any],\n         payment_method: Dict[str, Any],\n-        metadata: Optional[Dict[str, Any]] = None\n+        metadata: Optional[Dict[str, Any]] = None,\n     ) -> Dict[str, Any]:\n         \"\"\"\n         Create a payment with the provider\n-        \n+\n         Args:\n             amount: Payment amount\n             currency: Currency code (e.g., 'GBP')\n             order_id: Internal order reference\n             customer_info: Customer details\n             payment_method: Payment method details\n             metadata: Additional metadata\n-            \n+\n         Returns:\n             Dict containing:\n                 - transaction_id: Provider's transaction ID\n                 - status: Payment status\n                 - fee: Provider fee\n                 - net_amount: Amount after fees\n                 - raw_response: Full provider response\n         \"\"\"\n         pass\n-    \n+\n     @abstractmethod\n     async def capture_payment(\n-        self, \n-        transaction_id: str,\n-        amount: Optional[Decimal] = None\n+        self, transaction_id: str, amount: Optional[Decimal] = None\n     ) -> Dict[str, Any]:\n         \"\"\"\n         Capture a previously authorized payment\n-        \n+\n         Args:\n             transaction_id: Provider's transaction ID\n             amount: Amount to capture (None for full amount)\n-            \n+\n         Returns:\n             Dict with capture details\n         \"\"\"\n         pass\n-    \n+\n     @abstractmethod\n     async def refund_payment(\n         self,\n         transaction_id: str,\n         amount: Optional[Decimal] = None,\n-        reason: Optional[str] = None\n+        reason: Optional[str] = None,\n     ) -> Dict[str, Any]:\n         \"\"\"\n         Refund a payment\n-        \n+\n         Args:\n             transaction_id: Provider's transaction ID\n             amount: Amount to refund (None for full refund)\n             reason: Refund reason\n-            \n+\n         Returns:\n             Dict with refund details\n         \"\"\"\n         pass\n-    \n-    @abstractmethod\n-    async def get_transaction_status(\n-        self,\n-        transaction_id: str\n-    ) -> Dict[str, Any]:\n+\n+    @abstractmethod\n+    async def get_transaction_status(self, transaction_id: str) -> Dict[str, Any]:\n         \"\"\"\n         Get current status of a transaction\n-        \n+\n         Args:\n             transaction_id: Provider's transaction ID\n-            \n+\n         Returns:\n             Dict with transaction status and details\n         \"\"\"\n         pass\n-    \n-    @abstractmethod\n-    async def validate_webhook(\n-        self,\n-        payload: bytes,\n-        headers: Dict[str, str]\n-    ) -> bool:\n+\n+    @abstractmethod\n+    async def validate_webhook(self, payload: bytes, headers: Dict[str, str]) -> bool:\n         \"\"\"\n         Validate a webhook from the provider\n-        \n+\n         Args:\n             payload: Raw webhook payload\n             headers: Webhook headers\n-            \n+\n         Returns:\n             bool: True if webhook is valid\n         \"\"\"\n         pass\n-    \n-    @abstractmethod\n-    async def parse_webhook(\n-        self,\n-        payload: bytes\n-    ) -> Dict[str, Any]:\n+\n+    @abstractmethod\n+    async def parse_webhook(self, payload: bytes) -> Dict[str, Any]:\n         \"\"\"\n         Parse webhook payload\n-        \n+\n         Args:\n             payload: Raw webhook payload\n-            \n+\n         Returns:\n             Dict with parsed webhook data\n         \"\"\"\n         pass\n-    \n+\n     def calculate_fee(self, amount: Decimal) -> Decimal:\n         \"\"\"\n         Calculate provider fee for amount\n-        \n+\n         Args:\n             amount: Transaction amount\n-            \n+\n         Returns:\n             Fee amount\n         \"\"\"\n-        fee_rate = Decimal(str(self.config.get('fee_rate', 0.029)))\n-        fixed_fee = Decimal(str(self.config.get('fixed_fee', 0.30)))\n-        return (amount * fee_rate + fixed_fee).quantize(Decimal('0.01'))\n-    \n+        fee_rate = Decimal(str(self.config.get(\"fee_rate\", 0.029)))\n+        fixed_fee = Decimal(str(self.config.get(\"fixed_fee\", 0.30)))\n+        return (amount * fee_rate + fixed_fee).quantize(Decimal(\"0.01\"))\n+\n     def get_supported_currencies(self) -> List[str]:\n         \"\"\"Get list of supported currencies\"\"\"\n-        return self.config.get('supported_currencies', ['GBP', 'EUR', 'USD'])\n-    \n+        return self.config.get(\"supported_currencies\", [\"GBP\", \"EUR\", \"USD\"])\n+\n     def get_supported_payment_methods(self) -> List[str]:\n         \"\"\"Get list of supported payment methods\"\"\"\n-        return self.config.get('supported_methods', ['card'])\n-    \n+        return self.config.get(\"supported_methods\", [\"card\"])\n+\n     def is_available(self) -> bool:\n         \"\"\"Check if provider is currently available\"\"\"\n-        return self.config.get('enabled', True)\n-    \n+        return self.config.get(\"enabled\", True)\n+\n     def supports_recurring(self) -> bool:\n         \"\"\"Check if provider supports recurring payments\"\"\"\n-        return self.config.get('supports_recurring', False)\n-    \n+        return self.config.get(\"supports_recurring\", False)\n+\n     def supports_refunds(self) -> bool:\n         \"\"\"Check if provider supports refunds\"\"\"\n-        return self.config.get('supports_refunds', True)\n-    \n+        return self.config.get(\"supports_refunds\", True)\n+\n     def get_minimum_amount(self) -> Decimal:\n         \"\"\"Get minimum transaction amount\"\"\"\n-        return Decimal(str(self.config.get('minimum_amount', 0.50)))\n-    \n+        return Decimal(str(self.config.get(\"minimum_amount\", 0.50)))\n+\n     def get_maximum_amount(self) -> Decimal:\n         \"\"\"Get maximum transaction amount\"\"\"\n-        return Decimal(str(self.config.get('maximum_amount', 999999.99)))\n-    \n+        return Decimal(str(self.config.get(\"maximum_amount\", 999999.99)))\n+\n     def format_amount(self, amount: Decimal, currency: str) -> int:\n         \"\"\"\n         Format amount for provider API (usually in smallest currency unit)\n-        \n+\n         Args:\n             amount: Decimal amount\n             currency: Currency code\n-            \n+\n         Returns:\n             Amount in smallest unit (e.g., pence for GBP)\n         \"\"\"\n         # Most providers expect amounts in smallest currency unit\n         return int(amount * 100)\n-    \n+\n     def parse_amount(self, amount: int, currency: str) -> Decimal:\n         \"\"\"\n         Parse amount from provider format to Decimal\n-        \n+\n         Args:\n             amount: Amount in smallest unit\n             currency: Currency code\n-            \n+\n         Returns:\n             Decimal amount\n         \"\"\"\n         return Decimal(amount) / 100\n-    \n+\n     async def test_connection(self) -> Dict[str, Any]:\n         \"\"\"\n         Test provider connection and credentials\n-        \n+\n         Returns:\n             Dict with test results\n         \"\"\"\n         try:\n             initialized = await self.initialize()\n             return {\n-                'success': initialized,\n-                'provider': self.provider_name,\n-                'timestamp': datetime.utcnow().isoformat(),\n-                'message': 'Connection successful' if initialized else 'Connection failed'\n+                \"success\": initialized,\n+                \"provider\": self.provider_name,\n+                \"timestamp\": datetime.utcnow().isoformat(),\n+                \"message\": (\n+                    \"Connection successful\" if initialized else \"Connection failed\"\n+                ),\n             }\n         except Exception as e:\n             self.logger.error(f\"Connection test failed: {str(e)}\")\n             return {\n-                'success': False,\n-                'provider': self.provider_name,\n-                'timestamp': datetime.utcnow().isoformat(),\n-                'message': str(e)\n-            }\n\\ No newline at end of file\n+                \"success\": False,\n+                \"provider\": self.provider_name,\n+                \"timestamp\": datetime.utcnow().isoformat(),\n+                \"message\": str(e),\n+            }\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_providers/cash_provider.py\t2025-08-02 20:32:29.226921+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_providers/cash_provider.py\t2025-08-02 22:36:03.941307+00:00\n@@ -2,22 +2,25 @@\n from typing import Dict, Any, Optional, List\n import uuid\n from datetime import datetime\n import logging\n \n-from .base_provider import BasePaymentProvider, RefundItemDetail # Import new base\n+from .base_provider import BasePaymentProvider, RefundItemDetail  # Import new base\n+\n # Assuming PaymentStatus is a shared enum, if not, define or import appropriately\n # from ..payment_providers import PaymentStatus # Or your enum location\n \n logger = logging.getLogger(__name__)\n \n-class PaymentStatus: # Placeholder if not imported\n+\n+class PaymentStatus:  # Placeholder if not imported\n     SUCCESS = \"success\"\n     FAILED = \"failed\"\n     PENDING = \"pending\"\n     REFUNDED = \"refunded\"\n     PARTIALLY_REFUNDED = \"partially_refunded\"\n+\n \n class CashProvider(BasePaymentProvider):\n     \"\"\"Provider for cash transactions and refunds.\"\"\"\n \n     def __init__(self, config: Optional[Dict[str, Any]] = None):\n@@ -31,67 +34,81 @@\n         self,\n         amount: Decimal,\n         currency: str = \"GBP\",\n         order_id: Optional[str] = None,\n         cash_received: Optional[Decimal] = None,\n-        **kwargs: Any\n+        **kwargs: Any,\n     ) -> Dict[str, Any]:\n         \"\"\"\n         Processes a cash payment.\n         For cash, this typically means recording the transaction.\n         \"\"\"\n         if amount <= 0:\n             logger.error(\"Cash payment error: Amount must be positive.\")\n-            return {\"success\": False, \"error\": \"Amount must be positive.\", \"status\": PaymentStatus.FAILED}\n+            return {\n+                \"success\": False,\n+                \"error\": \"Amount must be positive.\",\n+                \"status\": PaymentStatus.FAILED,\n+            }\n \n         transaction_id = f\"CASH_TXN_{uuid.uuid4()}\"\n         timestamp = datetime.utcnow().isoformat() + \"Z\"\n \n         change_due = Decimal(0)\n         if cash_received is not None:\n             if cash_received < amount:\n-                logger.error(f\"Cash payment error for order {order_id}: Insufficient cash received. Amount: {amount}, Received: {cash_received}\")\n+                logger.error(\n+                    f\"Cash payment error for order {order_id}: Insufficient cash received. Amount: {amount}, Received: {cash_received}\"\n+                )\n                 return {\n                     \"success\": False,\n                     \"error\": \"Insufficient cash received.\",\n                     \"status\": PaymentStatus.FAILED,\n                     \"transaction_id\": transaction_id,\n                     \"amount\": float(amount),\n                     \"currency\": currency,\n-                    \"timestamp\": timestamp\n+                    \"timestamp\": timestamp,\n                 }\n             change_due = cash_received - amount\n \n-        logger.info(f\"Cash payment processed for order {order_id}: Amount: {amount} {currency}, Transaction ID: {transaction_id}\")\n+        logger.info(\n+            f\"Cash payment processed for order {order_id}: Amount: {amount} {currency}, Transaction ID: {transaction_id}\"\n+        )\n         return {\n             \"success\": True,\n             \"transaction_id\": transaction_id,\n-            \"gateway_transaction_id\": transaction_id, # For cash, internal ID is the gateway ID\n-            \"status\": PaymentStatus.SUCCESS, # Cash payments are typically successful immediately\n+            \"gateway_transaction_id\": transaction_id,  # For cash, internal ID is the gateway ID\n+            \"status\": PaymentStatus.SUCCESS,  # Cash payments are typically successful immediately\n             \"amount_processed\": float(amount),\n             \"currency\": currency,\n             \"payment_method_type\": \"cash\",\n             \"created_at\": timestamp,\n             \"change_due\": float(change_due),\n-            \"raw_response\": {\"message\": \"Cash payment recorded.\"}\n+            \"raw_response\": {\"message\": \"Cash payment recorded.\"},\n         }\n \n     async def refund_payment(\n         self,\n-        transaction_id: str, # Original Fynlo transaction_id (or a cash specific one)\n+        transaction_id: str,  # Original Fynlo transaction_id (or a cash specific one)\n         amount_to_refund: Decimal,\n         reason: Optional[str] = None,\n         items_to_refund: Optional[List[RefundItemDetail]] = None,\n-        order_id: Optional[str] = None, # Fynlo's internal order ID\n-        **kwargs: Any\n+        order_id: Optional[str] = None,  # Fynlo's internal order ID\n+        **kwargs: Any,\n     ) -> Dict[str, Any]:\n         \"\"\"\n         Processes a cash refund. This is an internal ledger operation.\n         \"\"\"\n         if amount_to_refund <= 0:\n-            logger.error(f\"Cash refund error for order {order_id}: Refund amount must be positive. Received: {amount_to_refund}\")\n-            return {\"success\": False, \"error\": \"Refund amount must be positive.\", \"status\": \"failed\"}\n+            logger.error(\n+                f\"Cash refund error for order {order_id}: Refund amount must be positive. Received: {amount_to_refund}\"\n+            )\n+            return {\n+                \"success\": False,\n+                \"error\": \"Refund amount must be positive.\",\n+                \"status\": \"failed\",\n+            }\n \n         refund_id = f\"CASH_REFUND_{uuid.uuid4()}\"\n         timestamp = datetime.utcnow().isoformat() + \"Z\"\n \n         logger.info(\n@@ -102,28 +119,35 @@\n         # For cash refunds, there's no external gateway call.\n         # The success indicates it's been logged internally.\n         return {\n             \"success\": True,\n             \"refund_id\": refund_id,\n-            \"gateway_transaction_id\": transaction_id, # Reference to original transaction\n-            \"status\": PaymentStatus.REFUNDED, # Or a more specific \"processed_internally\"\n+            \"gateway_transaction_id\": transaction_id,  # Reference to original transaction\n+            \"status\": PaymentStatus.REFUNDED,  # Or a more specific \"processed_internally\"\n             \"amount_refunded\": float(amount_to_refund),\n             # \"currency\" would typically come from the original transaction context if needed\n             \"reason\": reason,\n             \"created_at\": timestamp,\n-            \"raw_response\": {\"message\": \"Cash refund recorded internally.\"}\n+            \"raw_response\": {\"message\": \"Cash refund recorded internally.\"},\n         }\n \n     async def get_transaction_details(self, transaction_id: str) -> Dict[str, Any]:\n-        logger.warning(\"CashProvider: get_transaction_details is not typically applicable for cash.\")\n-        return {\"status\": \"not_applicable\", \"message\": \"Cash transactions are typically not queried via gateway.\"}\n+        logger.warning(\n+            \"CashProvider: get_transaction_details is not typically applicable for cash.\"\n+        )\n+        return {\n+            \"status\": \"not_applicable\",\n+            \"message\": \"Cash transactions are typically not queried via gateway.\",\n+        }\n \n     async def void_payment(self, transaction_id: str, **kwargs) -> Dict[str, Any]:\n-        logger.warning(\"CashProvider: void_payment is not typically applicable for cash in the same way as card payments.\")\n+        logger.warning(\n+            \"CashProvider: void_payment is not typically applicable for cash in the same way as card payments.\"\n+        )\n         # A \"void\" for cash might mean cancelling an order before cash is exchanged or immediately after.\n         # This could be logged as a specific type of refund or cancellation.\n         return {\n-            \"success\": True, # Or False if voiding is not a concept here\n-            \"status\": \"void_not_applicable_or_manual\", # Or PaymentStatus.CANCELLED if that's how it's handled\n-            \"message\": \"Cash transaction voiding is a manual process or handled as cancellation/refund.\"\n+            \"success\": True,  # Or False if voiding is not a concept here\n+            \"status\": \"void_not_applicable_or_manual\",  # Or PaymentStatus.CANCELLED if that's how it's handled\n+            \"message\": \"Cash transaction voiding is a manual process or handled as cancellation/refund.\",\n         }\n-        return Decimal(0) # No processing fees for cash\n+        return Decimal(0)  # No processing fees for cash\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_providers.py\t2025-08-02 21:56:59.004450+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_providers.py\t2025-08-02 22:36:03.951826+00:00\n@@ -6,38 +6,41 @@\n \n # Import all provider implementations to make them available\n from .payment_providers.stripe_provider import StripeProvider\n from .payment_providers.square_provider import SquareProvider\n from .payment_providers.sumup_provider import SumUpProvider\n+\n # Note: PaymentProviderFactory should be imported directly from payment_factory to avoid circular imports\n+\n \n class PaymentStatus(Enum):\n     SUCCESS = \"success\"\n     PENDING = \"pending\"\n     FAILED = \"failed\"\n     CANCELLED = \"cancelled\"\n     REFUNDED = \"refunded\"\n \n+\n class PaymentProvider(ABC):\n     \"\"\"Abstract base class for all payment providers\"\"\"\n-    \n+\n     def __init__(self, config: Dict[str, Any]):\n         self.config = config\n-        self.provider_name = self.__class__.__name__.replace('Provider', '')\n-    \n+        self.provider_name = self.__class__.__name__.replace(\"Provider\", \"\")\n+\n     @abstractmethod\n     async def process_payment(\n         self,\n         amount: Decimal,\n         currency: str = \"GBP\",\n         customer_id: Optional[str] = None,\n         payment_method_id: Optional[str] = None,\n-        metadata: Optional[Dict[str, Any]] = None\n+        metadata: Optional[Dict[str, Any]] = None,\n     ) -> Dict[str, Any]:\n         \"\"\"\n         Process a payment through the provider\n-        \n+\n         Returns standardized response:\n         {\n             \"provider\": \"Stripe\",\n             \"transaction_id\": \"pi_1234567890\",\n             \"status\": \"success\",\n@@ -48,33 +51,33 @@\n             \"created_at\": \"2024-01-20T10:30:00Z\",\n             \"metadata\": {...}\n         }\n         \"\"\"\n         pass\n-    \n+\n     @abstractmethod\n     async def refund_payment(\n         self,\n         transaction_id: str,\n         amount: Optional[Decimal] = None,\n-        reason: Optional[str] = None\n+        reason: Optional[str] = None,\n     ) -> Dict[str, Any]:\n         \"\"\"Process a refund for a previous payment\"\"\"\n         pass\n-    \n+\n     @abstractmethod\n     async def create_checkout(\n         self,\n         amount: Decimal,\n         currency: str = \"GBP\",\n         return_url: str = None,\n         cancel_url: str = None,\n-        metadata: Optional[Dict[str, Any]] = None\n+        metadata: Optional[Dict[str, Any]] = None,\n     ) -> Dict[str, Any]:\n         \"\"\"Create a checkout session for web/mobile payments\"\"\"\n         pass\n-    \n+\n     @abstractmethod\n     def calculate_fee(self, amount: Decimal) -> Decimal:\n         \"\"\"Calculate the provider fee for a given amount\"\"\"\n         pass\n         \"\"\"Convert provider-specific response to standard format\"\"\"\n@@ -87,16 +90,17 @@\n             \"currency\": \"GBP\",\n             \"fee\": int(fee * 100),\n             \"net_amount\": int((amount - fee) * 100),\n             \"created_at\": datetime.utcnow().isoformat() + \"Z\",\n             \"raw_response\": provider_response,\n-            \"metadata\": provider_response.get(\"metadata\", {})\n+            \"metadata\": provider_response.get(\"metadata\", {}),\n         }\n+\n \n # Export all classes for backwards compatibility\n __all__ = [\n-    'PaymentStatus',\n-    'PaymentProvider',\n-    'StripeProvider',\n-    'SquareProvider',\n-    'SumUpProvider'\n-]\n\\ No newline at end of file\n+    \"PaymentStatus\",\n+    \"PaymentProvider\",\n+    \"StripeProvider\",\n+    \"SquareProvider\",\n+    \"SumUpProvider\",\n+]\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/platform_fee_service.py\t2025-08-02 21:56:59.004980+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/platform_fee_service.py\t2025-08-02 22:36:03.964766+00:00\n@@ -5,10 +5,11 @@\n from app.services.platform_service import PlatformSettingsService\n from app.services.payment_fee_calculator import PaymentFeeCalculator\n from app.schemas.fee_schemas import PaymentMethodEnum, CustomerTotalBreakdown\n \n logger = logging.getLogger(__name__)\n+\n \n class PlatformFeeService:\n     \"\"\"\n     Calculates the platform's transaction fee and the final customer total.\n     \"\"\"\n@@ -18,22 +19,24 @@\n     PLATFORM_FEE_RATE = Decimal(\"0.01\")  # 1%\n \n     def __init__(\n         self,\n         payment_fee_calculator: PaymentFeeCalculator,\n-        platform_settings_service: PlatformSettingsService, # Potentially to fetch PLATFORM_FEE_RATE\n+        platform_settings_service: PlatformSettingsService,  # Potentially to fetch PLATFORM_FEE_RATE\n     ):\n         self.payment_fee_calculator = payment_fee_calculator\n         self.platform_settings_service = platform_settings_service\n         # In the future, self.PLATFORM_FEE_RATE could be initialized by fetching from platform_settings_service\n \n     def _round_currency(self, amount: Decimal) -> float:\n         \"\"\"Rounds a Decimal amount to 2 decimal places for currency representation.\"\"\"\n         quantizer = Decimal(\"0.01\")\n         return float(amount.quantize(quantizer, rounding=ROUND_HALF_UP))\n \n-    def calculate_platform_fee(self, amount_subject_to_platform_fee: Decimal) -> Decimal:\n+    def calculate_platform_fee(\n+        self, amount_subject_to_platform_fee: Decimal\n+    ) -> Decimal:\n         \"\"\"\n         Calculates the 1% platform fee on the given amount.\n \n         Args:\n             amount_subject_to_platform_fee: The amount on which the platform fee is calculated.\n@@ -41,11 +44,13 @@\n         Returns:\n             The calculated platform fee as a Decimal.\n         \"\"\"\n         if amount_subject_to_platform_fee < Decimal(\"0\"):\n             # Or handle as an error, fees typically not on negative amounts unless it's a refund scenario with specific rules\n-            logger.warning(\"amount_subject_to_platform_fee is negative, platform fee will be 0.\")\n+            logger.warning(\n+                \"amount_subject_to_platform_fee is negative, platform fee will be 0.\"\n+            )\n             return Decimal(\"0.00\")\n \n         # fee_rate = await self.platform_settings_service.get_platform_setting(\"platform.transaction_fee.rate\") # Example\n         # current_platform_fee_rate = Decimal(str(fee_rate['value']['value'])) if fee_rate else self.PLATFORM_FEE_RATE\n         current_platform_fee_rate = self.PLATFORM_FEE_RATE\n@@ -54,12 +59,12 @@\n         return platform_fee\n \n     async def calculate_customer_total(\n         self,\n         subtotal: float,\n-        vat_amount: float, # Explicit VAT amount\n-        service_charge_final_amount: float, # Final service charge (could already include processor fee)\n+        vat_amount: float,  # Explicit VAT amount\n+        service_charge_final_amount: float,  # Final service charge (could already include processor fee)\n         payment_method: PaymentMethodEnum,\n         customer_pays_processor_fees: bool,\n         restaurant_id: Optional[str] = None,\n         monthly_volume_for_restaurant: Optional[float] = None,\n     ) -> CustomerTotalBreakdown:\n@@ -90,44 +95,62 @@\n         # but the payment for the service charge part *is* part of the transaction amount.\n         # The processor fee is calculated on the total amount processed by the payment gateway.\n \n         # Tentative amount that the processor will handle, before processor fee itself and platform fee.\n         # This is Subtotal + VAT + Service Charge.\n-        amount_before_processor_and_platform_fees = dec_subtotal + dec_vat_amount + dec_service_charge_final_amount\n+        amount_before_processor_and_platform_fees = (\n+            dec_subtotal + dec_vat_amount + dec_service_charge_final_amount\n+        )\n \n-        if payment_method != PaymentMethodEnum.CASH: # No processor fees for cash\n-            raw_processor_fee = await self.payment_fee_calculator.calculate_processor_fee(\n-                transaction_amount=float(amount_before_processor_and_platform_fees), # pass as float\n-                payment_method=payment_method,\n-                restaurant_id=restaurant_id,\n-                monthly_volume_for_restaurant=monthly_volume_for_restaurant,\n+        if payment_method != PaymentMethodEnum.CASH:  # No processor fees for cash\n+            raw_processor_fee = (\n+                await self.payment_fee_calculator.calculate_processor_fee(\n+                    transaction_amount=float(\n+                        amount_before_processor_and_platform_fees\n+                    ),  # pass as float\n+                    payment_method=payment_method,\n+                    restaurant_id=restaurant_id,\n+                    monthly_volume_for_restaurant=monthly_volume_for_restaurant,\n+                )\n             )\n             calculated_processor_fee = Decimal(str(raw_processor_fee))\n \n         actual_processor_fee_paid_by_customer = Decimal(\"0.00\")\n         if customer_pays_processor_fees and payment_method != PaymentMethodEnum.CASH:\n             actual_processor_fee_paid_by_customer = calculated_processor_fee\n \n         # Amount on which platform fee is calculated:\n         # Subtotal + VAT + Service Charge + Processor Fee (if customer pays it directly)\n-        amount_subject_to_platform_fee = dec_subtotal + dec_vat_amount + dec_service_charge_final_amount + actual_processor_fee_paid_by_customer\n+        amount_subject_to_platform_fee = (\n+            dec_subtotal\n+            + dec_vat_amount\n+            + dec_service_charge_final_amount\n+            + actual_processor_fee_paid_by_customer\n+        )\n \n-        calculated_platform_fee = self.calculate_platform_fee(amount_subject_to_platform_fee)\n+        calculated_platform_fee = self.calculate_platform_fee(\n+            amount_subject_to_platform_fee\n+        )\n \n         # Final total for the customer\n         dec_final_total = amount_subject_to_platform_fee + calculated_platform_fee\n \n         return CustomerTotalBreakdown(\n             subtotal=self._round_currency(dec_subtotal),\n             vat_amount=self._round_currency(dec_vat_amount),\n-            service_charge_calculated=self._round_currency(dec_service_charge_final_amount),\n+            service_charge_calculated=self._round_currency(\n+                dec_service_charge_final_amount\n+            ),\n             platform_fee=self._round_currency(calculated_platform_fee),\n-            processor_fee=self._round_currency(calculated_processor_fee), # This is the actual processor fee value\n+            processor_fee=self._round_currency(\n+                calculated_processor_fee\n+            ),  # This is the actual processor fee value\n             customer_pays_processor_fees=customer_pays_processor_fees,\n             final_total=self._round_currency(dec_final_total),\n-            notes=None\n+            notes=None,\n         )\n+\n \n # Example Usage (conceptual)\n # async def main_pf_example():\n #     from app.core.database import SessionLocal\n #     db = SessionLocal()\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/monitoring.py\t2025-08-02 22:08:16.223628+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/monitoring.py\t2025-08-02 22:36:03.971410+00:00\n@@ -20,29 +20,35 @@\n from app.services.volume_tracker import VolumeTracker\n from app.services.config_manager import config_manager\n \n logger = logging.getLogger(__name__)\n \n+\n class AlertSeverity(Enum):\n     \"\"\"Alert severity levels\"\"\"\n+\n     LOW = \"low\"\n     MEDIUM = \"medium\"\n     HIGH = \"high\"\n     CRITICAL = \"critical\"\n \n+\n class MetricType(Enum):\n     \"\"\"Types of metrics to track\"\"\"\n+\n     PAYMENT_SUCCESS_RATE = \"payment_success_rate\"\n     PAYMENT_VOLUME = \"payment_volume\"\n     PROVIDER_HEALTH = \"provider_health\"\n     COST_EFFICIENCY = \"cost_efficiency\"\n     RESPONSE_TIME = \"response_time\"\n     ERROR_RATE = \"error_rate\"\n \n+\n @dataclass\n class Alert:\n     \"\"\"Alert data structure\"\"\"\n+\n     id: str\n     type: str\n     severity: AlertSeverity\n     title: str\n     description: str\n@@ -51,484 +57,483 @@\n     provider: Optional[str] = None\n     value: Optional[float] = None\n     threshold: Optional[float] = None\n     metadata: Dict[str, Any] = field(default_factory=dict)\n \n+\n @dataclass\n class Metric:\n     \"\"\"Metric data structure\"\"\"\n+\n     name: str\n     type: MetricType\n     value: float\n     timestamp: datetime\n     restaurant_id: Optional[str] = None\n     provider: Optional[str] = None\n     labels: Dict[str, str] = field(default_factory=dict)\n \n+\n class MonitoringService:\n     \"\"\"Service for monitoring payment system health and performance\"\"\"\n-    \n+\n     def __init__(self, db: Session):\n         self.db = db\n         self.analytics = PaymentAnalyticsService(db)\n         self.volume_tracker = VolumeTracker(db)\n-        \n+\n         # Alert thresholds\n         self.thresholds = {\n-            'payment_success_rate_min': 95.0,  # 95% minimum success rate\n-            'provider_health_min': 80.0,       # 80% minimum health score\n-            'response_time_max': 5000.0,       # 5 seconds max response time\n-            'cost_increase_max': 20.0,         # 20% cost increase threshold\n-            'volume_drop_max': 30.0,           # 30% volume drop threshold\n-            'error_rate_max': 5.0,             # 5% maximum error rate\n+            \"payment_success_rate_min\": 95.0,  # 95% minimum success rate\n+            \"provider_health_min\": 80.0,  # 80% minimum health score\n+            \"response_time_max\": 5000.0,  # 5 seconds max response time\n+            \"cost_increase_max\": 20.0,  # 20% cost increase threshold\n+            \"volume_drop_max\": 30.0,  # 30% volume drop threshold\n+            \"error_rate_max\": 5.0,  # 5% maximum error rate\n         }\n-        \n+\n         # Alert destinations\n         self.alert_webhooks = [\n-            config_manager.get_provider_config('monitoring').custom_settings.get('webhook_url')\n-            if config_manager.get_provider_config('monitoring') else None\n+            (\n+                config_manager.get_provider_config(\"monitoring\").custom_settings.get(\n+                    \"webhook_url\"\n+                )\n+                if config_manager.get_provider_config(\"monitoring\")\n+                else None\n+            )\n         ]\n-        \n+\n         # Metrics storage (in production, use external time series DB)\n         self.metrics_buffer: List[Metric] = []\n         self.alerts_sent: Dict[str, datetime] = {}  # Track sent alerts to avoid spam\n-    \n+\n     async def check_system_health(self) -> Dict[str, Any]:\n         \"\"\"Perform comprehensive system health check\"\"\"\n         health_status = {\n-            'overall_status': 'healthy',\n-            'timestamp': datetime.utcnow().isoformat(),\n-            'checks': {},\n-            'alerts': []\n+            \"overall_status\": \"healthy\",\n+            \"timestamp\": datetime.utcnow().isoformat(),\n+            \"checks\": {},\n+            \"alerts\": [],\n         }\n-        \n+\n         try:\n             # Check payment success rates\n             success_rate_status = await self._check_payment_success_rates()\n-            health_status['checks']['payment_success_rate'] = success_rate_status\n-            \n+            health_status[\"checks\"][\"payment_success_rate\"] = success_rate_status\n+\n             # Check provider health\n             provider_health_status = await self._check_provider_health()\n-            health_status['checks']['provider_health'] = provider_health_status\n-            \n+            health_status[\"checks\"][\"provider_health\"] = provider_health_status\n+\n             # Check volume anomalies\n             volume_status = await self._check_volume_anomalies()\n-            health_status['checks']['volume_tracking'] = volume_status\n-            \n+            health_status[\"checks\"][\"volume_tracking\"] = volume_status\n+\n             # Check cost efficiency\n             cost_status = await self._check_cost_efficiency()\n-            health_status['checks']['cost_efficiency'] = cost_status\n-            \n+            health_status[\"checks\"][\"cost_efficiency\"] = cost_status\n+\n             # Check response times\n             response_time_status = await self._check_response_times()\n-            health_status['checks']['response_times'] = response_time_status\n-            \n+            health_status[\"checks\"][\"response_times\"] = response_time_status\n+\n             # Determine overall status\n             all_checks = [\n-                success_rate_status, provider_health_status, \n-                volume_status, cost_status, response_time_status\n+                success_rate_status,\n+                provider_health_status,\n+                volume_status,\n+                cost_status,\n+                response_time_status,\n             ]\n-            \n-            if any(check['status'] == 'critical' for check in all_checks):\n-                health_status['overall_status'] = 'critical'\n-            elif any(check['status'] == 'warning' for check in all_checks):\n-                health_status['overall_status'] = 'warning'\n-            \n+\n+            if any(check[\"status\"] == \"critical\" for check in all_checks):\n+                health_status[\"overall_status\"] = \"critical\"\n+            elif any(check[\"status\"] == \"warning\" for check in all_checks):\n+                health_status[\"overall_status\"] = \"warning\"\n+\n             # Collect alerts\n             for check in all_checks:\n-                if 'alerts' in check:\n-                    health_status['alerts'].extend(check['alerts'])\n-            \n+                if \"alerts\" in check:\n+                    health_status[\"alerts\"].extend(check[\"alerts\"])\n+\n         except Exception as e:\n             logger.error(f\"Health check failed: {e}\")\n-            health_status['overall_status'] = 'error'\n-            health_status['error'] = str(e)\n-        \n+            health_status[\"overall_status\"] = \"error\"\n+            health_status[\"error\"] = str(e)\n+\n         return health_status\n-    \n+\n     async def _check_payment_success_rates(self) -> Dict[str, Any]:\n         \"\"\"Check payment success rates across providers\"\"\"\n         end_date = datetime.utcnow()\n         start_date = end_date - timedelta(hours=24)  # Last 24 hours\n-        \n+\n         try:\n             performance_data = await self.analytics.get_provider_performance_summary(\n-                start_date=start_date,\n-                end_date=end_date\n+                start_date=start_date, end_date=end_date\n             )\n-            \n-            status = {\n-                'status': 'healthy',\n-                'metrics': {},\n-                'alerts': []\n-            }\n-            \n+\n+            status = {\"status\": \"healthy\", \"metrics\": {}, \"alerts\": []}\n+\n             # Check each provider's success rate\n-            for provider, data in performance_data['provider_performance'].items():\n-                if data['transaction_count'] > 0:\n+            for provider, data in performance_data[\"provider_performance\"].items():\n+                if data[\"transaction_count\"] > 0:\n                     # Calculate success rate (assuming completed = successful)\n                     # In a real implementation, you'd track failed vs successful separately\n                     success_rate = 100.0  # Placeholder - calculate from actual data\n-                    \n-                    status['metrics'][f'{provider}_success_rate'] = success_rate\n-                    \n-                    if success_rate < self.thresholds['payment_success_rate_min']:\n+\n+                    status[\"metrics\"][f\"{provider}_success_rate\"] = success_rate\n+\n+                    if success_rate < self.thresholds[\"payment_success_rate_min\"]:\n                         alert = Alert(\n                             id=f\"success_rate_{provider}_{int(time.time())}\",\n                             type=\"success_rate_low\",\n                             severity=AlertSeverity.HIGH,\n                             title=f\"Low Success Rate: {provider}\",\n                             description=f\"Success rate for {provider} is {success_rate:.1f}%, below threshold of {self.thresholds['payment_success_rate_min']}%\",\n                             timestamp=datetime.utcnow(),\n                             provider=provider,\n                             value=success_rate,\n-                            threshold=self.thresholds['payment_success_rate_min']\n+                            threshold=self.thresholds[\"payment_success_rate_min\"],\n                         )\n-                        \n-                        status['alerts'].append(alert)\n-                        status['status'] = 'warning'\n-                        \n+\n+                        status[\"alerts\"].append(alert)\n+                        status[\"status\"] = \"warning\"\n+\n                         await self._send_alert(alert)\n-            \n+\n             return status\n-            \n+\n         except Exception as e:\n             logger.error(f\"Success rate check failed: {e}\")\n-            return {\n-                'status': 'error',\n-                'error': str(e)\n-            }\n-    \n+            return {\"status\": \"error\", \"error\": str(e)}\n+\n     async def _check_provider_health(self) -> Dict[str, Any]:\n         \"\"\"Check provider health scores\"\"\"\n         try:\n             health_scores = await self.analytics.get_provider_health_scores()\n-            \n-            status = {\n-                'status': 'healthy',\n-                'metrics': {},\n-                'alerts': []\n-            }\n-            \n-            for provider, health_data in health_scores['health_scores'].items():\n-                overall_score = health_data['overall_score']\n-                status['metrics'][f'{provider}_health_score'] = overall_score\n-                \n-                if overall_score < self.thresholds['provider_health_min']:\n-                    severity = AlertSeverity.CRITICAL if overall_score < 60 else AlertSeverity.HIGH\n-                    \n+\n+            status = {\"status\": \"healthy\", \"metrics\": {}, \"alerts\": []}\n+\n+            for provider, health_data in health_scores[\"health_scores\"].items():\n+                overall_score = health_data[\"overall_score\"]\n+                status[\"metrics\"][f\"{provider}_health_score\"] = overall_score\n+\n+                if overall_score < self.thresholds[\"provider_health_min\"]:\n+                    severity = (\n+                        AlertSeverity.CRITICAL\n+                        if overall_score < 60\n+                        else AlertSeverity.HIGH\n+                    )\n+\n                     alert = Alert(\n                         id=f\"health_{provider}_{int(time.time())}\",\n                         type=\"provider_health_low\",\n                         severity=severity,\n                         title=f\"Provider Health Issue: {provider}\",\n                         description=f\"Health score for {provider} is {overall_score:.1f}, below threshold of {self.thresholds['provider_health_min']}\",\n                         timestamp=datetime.utcnow(),\n                         provider=provider,\n                         value=overall_score,\n-                        threshold=self.thresholds['provider_health_min'],\n-                        metadata={'health_factors': health_data['factors']}\n+                        threshold=self.thresholds[\"provider_health_min\"],\n+                        metadata={\"health_factors\": health_data[\"factors\"]},\n                     )\n-                    \n-                    status['alerts'].append(alert)\n-                    status['status'] = 'critical' if severity == AlertSeverity.CRITICAL else 'warning'\n-                    \n+\n+                    status[\"alerts\"].append(alert)\n+                    status[\"status\"] = (\n+                        \"critical\" if severity == AlertSeverity.CRITICAL else \"warning\"\n+                    )\n+\n                     await self._send_alert(alert)\n-            \n+\n             return status\n-            \n+\n         except Exception as e:\n             logger.error(f\"Provider health check failed: {e}\")\n-            return {\n-                'status': 'error',\n-                'error': str(e)\n-            }\n-    \n+            return {\"status\": \"error\", \"error\": str(e)}\n+\n     async def _check_volume_anomalies(self) -> Dict[str, Any]:\n         \"\"\"Check for volume anomalies and drops\"\"\"\n         try:\n             # Get volume data for multiple restaurants\n-            restaurants = self.db.query(Restaurant.id).limit(50).all()  # Check top 50 restaurants\n-            \n-            status = {\n-                'status': 'healthy',\n-                'metrics': {},\n-                'alerts': []\n-            }\n-            \n+            restaurants = (\n+                self.db.query(Restaurant.id).limit(50).all()\n+            )  # Check top 50 restaurants\n+\n+            status = {\"status\": \"healthy\", \"metrics\": {}, \"alerts\": []}\n+\n             for restaurant in restaurants:\n                 restaurant_id = str(restaurant.id)\n-                \n+\n                 # Get current and previous period volumes\n                 current_metrics = await self.volume_tracker.track_restaurant_volume(\n                     restaurant_id, period_days=7\n                 )\n-                \n+\n                 volume_alerts = await self.volume_tracker.check_volume_thresholds(\n                     restaurant_id, current_metrics\n                 )\n-                \n+\n                 # Check for significant volume drops\n-                if current_metrics.growth_rate < -self.thresholds['volume_drop_max']:\n+                if current_metrics.growth_rate < -self.thresholds[\"volume_drop_max\"]:\n                     alert = Alert(\n                         id=f\"volume_drop_{restaurant_id}_{int(time.time())}\",\n                         type=\"volume_drop\",\n                         severity=AlertSeverity.MEDIUM,\n                         title=f\"Volume Drop Alert\",\n                         description=f\"Restaurant {restaurant_id} volume dropped by {abs(current_metrics.growth_rate):.1f}%\",\n                         timestamp=datetime.utcnow(),\n                         restaurant_id=restaurant_id,\n                         value=current_metrics.growth_rate,\n-                        threshold=-self.thresholds['volume_drop_max']\n+                        threshold=-self.thresholds[\"volume_drop_max\"],\n                     )\n-                    \n-                    status['alerts'].append(alert)\n-                    status['status'] = 'warning'\n-                    \n+\n+                    status[\"alerts\"].append(alert)\n+                    status[\"status\"] = \"warning\"\n+\n                     await self._send_alert(alert)\n-                \n+\n                 # Convert volume alerts to monitoring alerts\n                 for vol_alert in volume_alerts:\n-                    if vol_alert.alert_type == 'threshold_exceeded':\n+                    if vol_alert.alert_type == \"threshold_exceeded\":\n                         alert = Alert(\n                             id=f\"volume_threshold_{restaurant_id}_{vol_alert.threshold_name}_{int(time.time())}\",\n                             type=\"volume_threshold\",\n                             severity=AlertSeverity.LOW,\n                             title=\"Volume Threshold Reached\",\n                             description=vol_alert.recommendation,\n                             timestamp=datetime.utcnow(),\n                             restaurant_id=restaurant_id,\n                             value=float(vol_alert.current_volume),\n                             threshold=float(vol_alert.threshold_volume),\n-                            metadata={'threshold_name': vol_alert.threshold_name}\n+                            metadata={\"threshold_name\": vol_alert.threshold_name},\n                         )\n-                        \n-                        status['alerts'].append(alert)\n+\n+                        status[\"alerts\"].append(alert)\n                         await self._send_alert(alert)\n-            \n+\n             return status\n-            \n+\n         except Exception as e:\n             logger.error(f\"Volume anomaly check failed: {e}\")\n-            return {\n-                'status': 'error',\n-                'error': str(e)\n-            }\n-    \n+            return {\"status\": \"error\", \"error\": str(e)}\n+\n     async def _check_cost_efficiency(self) -> Dict[str, Any]:\n         \"\"\"Check cost efficiency and potential savings\"\"\"\n         try:\n             end_date = datetime.utcnow()\n             start_date = end_date - timedelta(days=30)\n-            \n+\n             cost_report = await self.analytics.get_cost_optimization_report(\n-                start_date=start_date,\n-                end_date=end_date\n+                start_date=start_date, end_date=end_date\n             )\n-            \n+\n             status = {\n-                'status': 'healthy',\n-                'metrics': {\n-                    'savings_percentage': cost_report['savings_opportunity']['savings_percentage'],\n-                    'potential_savings': cost_report['savings_opportunity']['potential_savings']\n+                \"status\": \"healthy\",\n+                \"metrics\": {\n+                    \"savings_percentage\": cost_report[\"savings_opportunity\"][\n+                        \"savings_percentage\"\n+                    ],\n+                    \"potential_savings\": cost_report[\"savings_opportunity\"][\n+                        \"potential_savings\"\n+                    ],\n                 },\n-                'alerts': []\n+                \"alerts\": [],\n             }\n-            \n+\n             # Alert if significant savings are available\n-            if cost_report['savings_opportunity']['savings_percentage'] > self.thresholds['cost_increase_max']:\n+            if (\n+                cost_report[\"savings_opportunity\"][\"savings_percentage\"]\n+                > self.thresholds[\"cost_increase_max\"]\n+            ):\n                 alert = Alert(\n                     id=f\"cost_optimization_{int(time.time())}\",\n                     type=\"cost_optimization\",\n                     severity=AlertSeverity.MEDIUM,\n                     title=\"Cost Optimization Opportunity\",\n                     description=f\"Potential savings of {cost_report['savings_opportunity']['savings_percentage']:.1f}% (\u00a3{cost_report['savings_opportunity']['potential_savings']:.2f}) available\",\n                     timestamp=datetime.utcnow(),\n-                    value=cost_report['savings_opportunity']['savings_percentage'],\n-                    threshold=self.thresholds['cost_increase_max'],\n-                    metadata={\n-                        'recommendations': cost_report['recommendations']\n-                    }\n+                    value=cost_report[\"savings_opportunity\"][\"savings_percentage\"],\n+                    threshold=self.thresholds[\"cost_increase_max\"],\n+                    metadata={\"recommendations\": cost_report[\"recommendations\"]},\n                 )\n-                \n-                status['alerts'].append(alert)\n+\n+                status[\"alerts\"].append(alert)\n                 await self._send_alert(alert)\n-            \n+\n             return status\n-            \n+\n         except Exception as e:\n             logger.error(f\"Cost efficiency check failed: {e}\")\n-            return {\n-                'status': 'error',\n-                'error': str(e)\n-            }\n-    \n+            return {\"status\": \"error\", \"error\": str(e)}\n+\n     async def _check_response_times(self) -> Dict[str, Any]:\n         \"\"\"Check API response times\"\"\"\n         try:\n             # In a real implementation, you'd track response times from your metrics system\n             # For now, we'll return a placeholder\n-            \n+\n             status = {\n-                'status': 'healthy',\n-                'metrics': {\n-                    'avg_response_time': 1500.0,  # milliseconds\n-                    'p95_response_time': 3000.0,\n-                    'p99_response_time': 5000.0\n+                \"status\": \"healthy\",\n+                \"metrics\": {\n+                    \"avg_response_time\": 1500.0,  # milliseconds\n+                    \"p95_response_time\": 3000.0,\n+                    \"p99_response_time\": 5000.0,\n                 },\n-                'alerts': []\n+                \"alerts\": [],\n             }\n-            \n+\n             # Check if response times are too high\n-            avg_response_time = status['metrics']['avg_response_time']\n-            if avg_response_time > self.thresholds['response_time_max']:\n+            avg_response_time = status[\"metrics\"][\"avg_response_time\"]\n+            if avg_response_time > self.thresholds[\"response_time_max\"]:\n                 alert = Alert(\n                     id=f\"response_time_{int(time.time())}\",\n                     type=\"high_response_time\",\n                     severity=AlertSeverity.HIGH,\n                     title=\"High Response Times\",\n                     description=f\"Average response time is {avg_response_time:.0f}ms, above threshold of {self.thresholds['response_time_max']:.0f}ms\",\n                     timestamp=datetime.utcnow(),\n                     value=avg_response_time,\n-                    threshold=self.thresholds['response_time_max']\n+                    threshold=self.thresholds[\"response_time_max\"],\n                 )\n-                \n-                status['alerts'].append(alert)\n-                status['status'] = 'warning'\n-                \n+\n+                status[\"alerts\"].append(alert)\n+                status[\"status\"] = \"warning\"\n+\n                 await self._send_alert(alert)\n-            \n+\n             return status\n-            \n+\n         except Exception as e:\n             logger.error(f\"Response time check failed: {e}\")\n-            return {\n-                'status': 'error',\n-                'error': str(e)\n-            }\n-    \n+            return {\"status\": \"error\", \"error\": str(e)}\n+\n     async def _send_alert(self, alert: Alert):\n         \"\"\"Send alert to configured destinations\"\"\"\n         alert_key = f\"{alert.type}_{alert.provider or 'system'}_{alert.restaurant_id or 'global'}\"\n-        \n+\n         # Rate limiting: don't send same alert more than once per hour\n         if alert_key in self.alerts_sent:\n             last_sent = self.alerts_sent[alert_key]\n             if datetime.utcnow() - last_sent < timedelta(hours=1):\n                 return\n-        \n+\n         self.alerts_sent[alert_key] = datetime.utcnow()\n-        \n+\n         # Prepare alert payload\n         payload = {\n-            'alert_id': alert.id,\n-            'type': alert.type,\n-            'severity': alert.severity.value,\n-            'title': alert.title,\n-            'description': alert.description,\n-            'timestamp': alert.timestamp.isoformat(),\n-            'restaurant_id': alert.restaurant_id,\n-            'provider': alert.provider,\n-            'value': alert.value,\n-            'threshold': alert.threshold,\n-            'metadata': alert.metadata\n+            \"alert_id\": alert.id,\n+            \"type\": alert.type,\n+            \"severity\": alert.severity.value,\n+            \"title\": alert.title,\n+            \"description\": alert.description,\n+            \"timestamp\": alert.timestamp.isoformat(),\n+            \"restaurant_id\": alert.restaurant_id,\n+            \"provider\": alert.provider,\n+            \"value\": alert.value,\n+            \"threshold\": alert.threshold,\n+            \"metadata\": alert.metadata,\n         }\n-        \n+\n         # Send to webhook endpoints\n         for webhook_url in self.alert_webhooks:\n             if webhook_url:\n                 try:\n                     async with httpx.AsyncClient() as client:\n                         response = await client.post(\n                             webhook_url,\n                             json=payload,\n-                            headers={'Content-Type': 'application/json'},\n-                            timeout=10.0\n+                            headers={\"Content-Type\": \"application/json\"},\n+                            timeout=10.0,\n                         )\n                         response.raise_for_status()\n                         logger.info(f\"Alert sent to webhook: {alert.id}\")\n-                \n+\n                 except Exception as e:\n                     logger.error(f\"Failed to send alert to webhook {webhook_url}: {e}\")\n-        \n+\n         # Log alert\n-        logger.warning(f\"ALERT [{alert.severity.value.upper()}] {alert.title}: {alert.description}\")\n-    \n+        logger.warning(\n+            f\"ALERT [{alert.severity.value.upper()}] {alert.title}: {alert.description}\"\n+        )\n+\n     async def record_metric(self, metric: Metric):\n         \"\"\"Record a metric for monitoring\"\"\"\n         self.metrics_buffer.append(metric)\n-        \n+\n         # In production, send to time series database\n-        logger.debug(f\"Metric recorded: {metric.name}={metric.value} at {metric.timestamp}\")\n-        \n+        logger.debug(\n+            f\"Metric recorded: {metric.name}={metric.value} at {metric.timestamp}\"\n+        )\n+\n         # Flush buffer if it gets too large\n         if len(self.metrics_buffer) > 1000:\n             await self._flush_metrics()\n-    \n+\n     async def _flush_metrics(self):\n         \"\"\"Flush metrics buffer to storage\"\"\"\n         if not self.metrics_buffer:\n             return\n-        \n+\n         # In production, batch send to Prometheus, InfluxDB, etc.\n         logger.info(f\"Flushing {len(self.metrics_buffer)} metrics\")\n         self.metrics_buffer.clear()\n-    \n+\n     async def get_system_metrics(self, hours: int = 24) -> Dict[str, Any]:\n         \"\"\"Get system metrics for the specified time period\"\"\"\n         try:\n             end_date = datetime.utcnow()\n             start_date = end_date - timedelta(hours=hours)\n-            \n+\n             # Get payment metrics\n             payment_performance = await self.analytics.get_provider_performance_summary(\n-                start_date=start_date,\n-                end_date=end_date\n+                start_date=start_date, end_date=end_date\n             )\n-            \n+\n             # Get volume trends\n-            volume_trends = await self.analytics.get_transaction_volume_trends(days=hours//24 or 1)\n-            \n+            volume_trends = await self.analytics.get_transaction_volume_trends(\n+                days=hours // 24 or 1\n+            )\n+\n             # Get provider health\n             provider_health = await self.analytics.get_provider_health_scores()\n-            \n+\n             return {\n-                'period': {\n-                    'start': start_date.isoformat(),\n-                    'end': end_date.isoformat(),\n-                    'hours': hours\n+                \"period\": {\n+                    \"start\": start_date.isoformat(),\n+                    \"end\": end_date.isoformat(),\n+                    \"hours\": hours,\n                 },\n-                'payment_performance': payment_performance,\n-                'volume_trends': volume_trends,\n-                'provider_health': provider_health,\n-                'system_status': await self.check_system_health()\n+                \"payment_performance\": payment_performance,\n+                \"volume_trends\": volume_trends,\n+                \"provider_health\": provider_health,\n+                \"system_status\": await self.check_system_health(),\n             }\n-            \n+\n         except Exception as e:\n             logger.error(f\"Failed to get system metrics: {e}\")\n-            return {\n-                'error': str(e),\n-                'timestamp': datetime.utcnow().isoformat()\n-            }\n-    \n+            return {\"error\": str(e), \"timestamp\": datetime.utcnow().isoformat()}\n+\n     async def update_thresholds(self, new_thresholds: Dict[str, float]):\n         \"\"\"Update monitoring thresholds\"\"\"\n         for key, value in new_thresholds.items():\n             if key in self.thresholds:\n                 old_value = self.thresholds[key]\n                 self.thresholds[key] = value\n                 logger.info(f\"Updated threshold {key}: {old_value} -> {value}\")\n-        \n+\n         # Save to configuration\n-        config_manager.providers.setdefault('monitoring', type('obj', (object,), {\n-            'custom_settings': {}\n-        })()).custom_settings.update({'thresholds': self.thresholds})\n+        config_manager.providers.setdefault(\n+            \"monitoring\", type(\"obj\", (object,), {\"custom_settings\": {}})()\n+        ).custom_settings.update({\"thresholds\": self.thresholds})\n+\n \n # Global monitoring service instance (initialized with database session)\n _monitoring_service: Optional[MonitoringService] = None\n+\n \n def get_monitoring_service(db: Session) -> MonitoringService:\n     \"\"\"Get or create monitoring service instance\"\"\"\n     global _monitoring_service\n     if _monitoring_service is None:\n         _monitoring_service = MonitoringService(db)\n-    return _monitoring_service\n\\ No newline at end of file\n+    return _monitoring_service\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_providers/payment_factory.py\t2025-08-02 19:23:36.832065+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_providers/payment_factory.py\t2025-08-02 22:36:03.975519+00:00\n@@ -17,239 +17,243 @@\n logger = logging.getLogger(__name__)\n \n \n class PaymentProviderFactory:\n     \"\"\"Factory for creating and managing payment providers with smart routing\"\"\"\n-    \n+\n     def __init__(self):\n         self.providers: Dict[str, PaymentProvider] = {}\n         self.config_service = SecurePaymentConfig()\n         self._initialized = False\n-    \n+\n     async def initialize(self, restaurant_id: str):\n         \"\"\"Initialize all configured payment providers for a restaurant\"\"\"\n         if self._initialized:\n             return\n-        \n+\n         try:\n             # Get all provider configurations for the restaurant\n             configs = await self._get_provider_configs(restaurant_id)\n-            \n+\n             for config in configs:\n                 if config.is_active:\n                     provider = await self._create_provider(\n-                        config.provider_name,\n-                        config.config_data,\n-                        restaurant_id\n+                        config.provider_name, config.config_data, restaurant_id\n                     )\n                     if provider:\n                         self.providers[config.provider_name] = provider\n-            \n+\n             self._initialized = True\n-            logger.info(f\"Initialized {len(self.providers)} payment providers for restaurant {restaurant_id}\")\n-            \n+            logger.info(\n+                f\"Initialized {len(self.providers)} payment providers for restaurant {restaurant_id}\"\n+            )\n+\n         except Exception as e:\n             logger.error(f\"Failed to initialize payment providers: {str(e)}\")\n             raise\n-    \n+\n     async def get_provider(self, provider_name: str) -> Optional[PaymentProvider]:\n         \"\"\"Get a specific payment provider\"\"\"\n         return self.providers.get(provider_name)\n-    \n+\n     async def get_best_provider(\n-        self,\n-        amount: Decimal,\n-        payment_method: str,\n-        currency: str = 'GBP'\n+        self, amount: Decimal, payment_method: str, currency: str = \"GBP\"\n     ) -> Optional[PaymentProvider]:\n         \"\"\"\n         Get the best provider based on fees, availability, and performance\n-        \n+\n         Selection criteria:\n         1. Provider must be available and support the payment method\n         2. Lowest fee for the transaction amount\n         3. Best performance metrics (success rate, response time)\n         \"\"\"\n         available_providers = []\n-        \n+\n         for name, provider in self.providers.items():\n-            if (provider.is_available() and \n-                payment_method in provider.get_supported_payment_methods() and\n-                currency in provider.get_supported_currencies()):\n-                \n+            if (\n+                provider.is_available()\n+                and payment_method in provider.get_supported_payment_methods()\n+                and currency in provider.get_supported_currencies()\n+            ):\n+\n                 # Calculate fee for this provider\n                 fee = provider.calculate_fee(amount)\n-                \n+\n                 # Get performance metrics\n                 metrics = await self._get_provider_metrics(name)\n-                \n-                available_providers.append({\n-                    'provider': provider,\n-                    'name': name,\n-                    'fee': fee,\n-                    'success_rate': metrics.get('success_rate', 0.95),\n-                    'avg_response_time': metrics.get('avg_response_time', 1.0)\n-                })\n-        \n+\n+                available_providers.append(\n+                    {\n+                        \"provider\": provider,\n+                        \"name\": name,\n+                        \"fee\": fee,\n+                        \"success_rate\": metrics.get(\"success_rate\", 0.95),\n+                        \"avg_response_time\": metrics.get(\"avg_response_time\", 1.0),\n+                    }\n+                )\n+\n         if not available_providers:\n             logger.warning(\"No available providers found\")\n             return None\n-        \n+\n         # Sort by fee (ascending) and success rate (descending)\n         available_providers.sort(\n-            key=lambda x: (x['fee'], -x['success_rate'], x['avg_response_time'])\n+            key=lambda x: (x[\"fee\"], -x[\"success_rate\"], x[\"avg_response_time\"])\n         )\n-        \n+\n         best = available_providers[0]\n-        logger.info(f\"Selected {best['name']} provider with fee {best['fee']} for amount {amount}\")\n-        \n-        return best['provider']\n-    \n+        logger.info(\n+            f\"Selected {best['name']} provider with fee {best['fee']} for amount {amount}\"\n+        )\n+\n+        return best[\"provider\"]\n+\n     async def get_providers_for_fallback(\n-        self,\n-        amount: Decimal,\n-        payment_method: str,\n-        currency: str = 'GBP'\n+        self, amount: Decimal, payment_method: str, currency: str = \"GBP\"\n     ) -> List[PaymentProvider]:\n         \"\"\"\n         Get ordered list of providers for fallback processing\n-        \n+\n         Returns providers ordered by preference for automatic fallback\n         \"\"\"\n         available_providers = []\n-        \n+\n         for name, provider in self.providers.items():\n-            if (provider.is_available() and \n-                payment_method in provider.get_supported_payment_methods() and\n-                currency in provider.get_supported_currencies()):\n-                \n+            if (\n+                provider.is_available()\n+                and payment_method in provider.get_supported_payment_methods()\n+                and currency in provider.get_supported_currencies()\n+            ):\n+\n                 fee = provider.calculate_fee(amount)\n                 metrics = await self._get_provider_metrics(name)\n-                \n-                available_providers.append({\n-                    'provider': provider,\n-                    'name': name,\n-                    'fee': fee,\n-                    'success_rate': metrics.get('success_rate', 0.95),\n-                    'avg_response_time': metrics.get('avg_response_time', 1.0)\n-                })\n-        \n+\n+                available_providers.append(\n+                    {\n+                        \"provider\": provider,\n+                        \"name\": name,\n+                        \"fee\": fee,\n+                        \"success_rate\": metrics.get(\"success_rate\", 0.95),\n+                        \"avg_response_time\": metrics.get(\"avg_response_time\", 1.0),\n+                    }\n+                )\n+\n         # Sort by fee and performance\n         available_providers.sort(\n-            key=lambda x: (x['fee'], -x['success_rate'], x['avg_response_time'])\n+            key=lambda x: (x[\"fee\"], -x[\"success_rate\"], x[\"avg_response_time\"])\n         )\n-        \n-        return [p['provider'] for p in available_providers]\n-    \n+\n+        return [p[\"provider\"] for p in available_providers]\n+\n     async def _create_provider(\n-        self,\n-        provider_name: str,\n-        encrypted_config: str,\n-        restaurant_id: str\n+        self, provider_name: str, encrypted_config: str, restaurant_id: str\n     ) -> Optional[PaymentProvider]:\n         \"\"\"Create a payment provider instance\"\"\"\n         try:\n             # Decrypt configuration\n             decrypted_config = self.config_service.get_provider_config(\n-                provider_name,\n-                restaurant_id\n-            )\n-            \n+                provider_name, restaurant_id\n+            )\n+\n             if not decrypted_config:\n                 logger.warning(f\"No configuration found for {provider_name}\")\n                 return None\n-            \n+\n             # Create provider instance\n             provider_class = {\n-                'stripe': StripeProvider,\n-                'square': SquareProvider,\n-                'sumup': SumUpProvider\n+                \"stripe\": StripeProvider,\n+                \"square\": SquareProvider,\n+                \"sumup\": SumUpProvider,\n             }.get(provider_name.lower())\n-            \n+\n             if not provider_class:\n                 logger.error(f\"Unknown provider: {provider_name}\")\n                 return None\n-            \n+\n             provider = provider_class(decrypted_config)\n-            \n+\n             # Initialize the provider\n             if await provider.initialize():\n                 logger.info(f\"Successfully initialized {provider_name} provider\")\n                 return provider\n             else:\n                 logger.error(f\"Failed to initialize {provider_name} provider\")\n                 return None\n-                \n+\n         except Exception as e:\n             logger.error(f\"Failed to create {provider_name} provider: {str(e)}\")\n             return None\n-    \n-    async def _get_provider_configs(self, restaurant_id: str) -> List[PaymentProviderConfig]:\n+\n+    async def _get_provider_configs(\n+        self, restaurant_id: str\n+    ) -> List[PaymentProviderConfig]:\n         \"\"\"Get all provider configurations for a restaurant\"\"\"\n         from sqlalchemy import select\n-        \n+\n         async with get_db() as db:\n             result = await db.execute(\n-                select(PaymentProviderConfig)\n-                .filter(\n+                select(PaymentProviderConfig).filter(\n                     PaymentProviderConfig.restaurant_id == restaurant_id,\n-                    PaymentProviderConfig.is_active == True\n+                    PaymentProviderConfig.is_active == True,\n                 )\n             )\n             return result.scalars().all()\n-    \n+\n     async def _get_provider_metrics(self, provider_name: str) -> Dict[str, Any]:\n         \"\"\"Get performance metrics for a provider\"\"\"\n         from sqlalchemy import select, func\n-        \n+\n         # Calculate metrics for last 30 days\n         cutoff_date = datetime.utcnow() - timedelta(days=30)\n-        \n+\n         async with get_db() as db:\n             # Get success rate\n             result = await db.execute(\n                 select(\n-                    func.count(PaymentTransaction.id).label('total'),\n+                    func.count(PaymentTransaction.id).label(\"total\"),\n                     func.sum(\n                         func.case(\n-                            (PaymentTransaction.status == PaymentStatus.COMPLETED.value, 1),\n-                            else_=0\n+                            (\n+                                PaymentTransaction.status\n+                                == PaymentStatus.COMPLETED.value,\n+                                1,\n+                            ),\n+                            else_=0,\n                         )\n-                    ).label('successful')\n-                )\n-                .filter(\n+                    ).label(\"successful\"),\n+                ).filter(\n                     PaymentTransaction.provider == provider_name,\n-                    PaymentTransaction.created_at >= cutoff_date\n-                )\n-            )\n-            \n+                    PaymentTransaction.created_at >= cutoff_date,\n+                )\n+            )\n+\n             metrics = result.first()\n-            \n+\n             if metrics and metrics.total > 0:\n                 success_rate = float(metrics.successful or 0) / float(metrics.total)\n             else:\n                 success_rate = 0.95  # Default success rate for new providers\n-            \n+\n             # Get average response time (if tracked)\n             # For now, return default values\n             return {\n-                'success_rate': success_rate,\n-                'avg_response_time': 1.0,  # seconds\n-                'total_transactions': metrics.total if metrics else 0\n+                \"success_rate\": success_rate,\n+                \"avg_response_time\": 1.0,  # seconds\n+                \"total_transactions\": metrics.total if metrics else 0,\n             }\n-    \n+\n     def get_provider_info(self) -> Dict[str, Any]:\n         \"\"\"Get information about all configured providers\"\"\"\n         info = {}\n-        \n+\n         for name, provider in self.providers.items():\n             info[name] = {\n-                'available': provider.is_available(),\n-                'supported_currencies': provider.get_supported_currencies(),\n-                'supported_methods': provider.get_supported_payment_methods(),\n-                'supports_recurring': provider.supports_recurring(),\n-                'supports_refunds': provider.supports_refunds(),\n-                'minimum_amount': str(provider.get_minimum_amount()),\n-                'maximum_amount': str(provider.get_maximum_amount())\n+                \"available\": provider.is_available(),\n+                \"supported_currencies\": provider.get_supported_currencies(),\n+                \"supported_methods\": provider.get_supported_payment_methods(),\n+                \"supports_recurring\": provider.supports_recurring(),\n+                \"supports_refunds\": provider.supports_refunds(),\n+                \"minimum_amount\": str(provider.get_minimum_amount()),\n+                \"maximum_amount\": str(provider.get_maximum_amount()),\n             }\n-        \n-        return info\n\\ No newline at end of file\n+\n+        return info\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_providers/stripe_provider.py\t2025-08-02 10:59:17.998490+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_providers/stripe_provider.py\t2025-08-02 22:36:03.988866+00:00\n@@ -13,271 +13,250 @@\n logger = logging.getLogger(__name__)\n \n \n class StripeProvider(PaymentProvider):\n     \"\"\"Stripe payment provider implementation\"\"\"\n-    \n+\n     async def initialize(self) -> bool:\n         \"\"\"Initialize Stripe with API key\"\"\"\n         try:\n-            stripe.api_key = self.config.get('secret_key')\n-            stripe.api_version = '2023-10-16'\n-            \n+            stripe.api_key = self.config.get(\"secret_key\")\n+            stripe.api_version = \"2023-10-16\"\n+\n             # Test the connection\n             stripe.Account.retrieve()\n-            \n+\n             self.logger.info(\"Stripe provider initialized successfully\")\n             return True\n         except Exception as e:\n             self.logger.error(f\"Failed to initialize Stripe: {str(e)}\")\n             return False\n-    \n+\n     async def create_payment(\n-        self, \n-        amount: Decimal, \n+        self,\n+        amount: Decimal,\n         currency: str,\n         order_id: str,\n         customer_info: Dict[str, Any],\n         payment_method: Dict[str, Any],\n-        metadata: Optional[Dict[str, Any]] = None\n+        metadata: Optional[Dict[str, Any]] = None,\n     ) -> Dict[str, Any]:\n         \"\"\"Create a payment intent with Stripe\"\"\"\n         try:\n             # Format amount for Stripe (in smallest currency unit)\n             stripe_amount = self.format_amount(amount, currency)\n-            \n+\n             # Prepare payment intent data\n             intent_data = {\n-                'amount': stripe_amount,\n-                'currency': currency.lower(),\n-                'metadata': {\n-                    'order_id': order_id,\n-                    'platform': 'fynlo_pos',\n-                    **(metadata or {})\n+                \"amount\": stripe_amount,\n+                \"currency\": currency.lower(),\n+                \"metadata\": {\n+                    \"order_id\": order_id,\n+                    \"platform\": \"fynlo_pos\",\n+                    **(metadata or {}),\n                 },\n-                'description': f\"Order {order_id}\",\n-                'capture_method': 'automatic'\n-            }\n-            \n+                \"description\": f\"Order {order_id}\",\n+                \"capture_method\": \"automatic\",\n+            }\n+\n             # Add customer if provided\n-            if customer_info.get('email'):\n-                intent_data['receipt_email'] = customer_info['email']\n-            \n+            if customer_info.get(\"email\"):\n+                intent_data[\"receipt_email\"] = customer_info[\"email\"]\n+\n             # Handle payment method\n-            if payment_method.get('token'):\n-                intent_data['payment_method'] = payment_method['token']\n-                intent_data['confirm'] = True\n-            elif payment_method.get('payment_method_id'):\n-                intent_data['payment_method'] = payment_method['payment_method_id']\n-                intent_data['confirm'] = True\n-            \n+            if payment_method.get(\"token\"):\n+                intent_data[\"payment_method\"] = payment_method[\"token\"]\n+                intent_data[\"confirm\"] = True\n+            elif payment_method.get(\"payment_method_id\"):\n+                intent_data[\"payment_method\"] = payment_method[\"payment_method_id\"]\n+                intent_data[\"confirm\"] = True\n+\n             # Create payment intent\n             intent = stripe.PaymentIntent.create(**intent_data)\n-            \n+\n             # Calculate fees\n             fee = self.calculate_fee(amount)\n             net_amount = amount - fee\n-            \n-            return {\n-                'transaction_id': intent.id,\n-                'status': self._map_stripe_status(intent.status),\n-                'fee': fee,\n-                'net_amount': net_amount,\n-                'client_secret': intent.client_secret,\n-                'raw_response': intent\n-            }\n-            \n+\n+            return {\n+                \"transaction_id\": intent.id,\n+                \"status\": self._map_stripe_status(intent.status),\n+                \"fee\": fee,\n+                \"net_amount\": net_amount,\n+                \"client_secret\": intent.client_secret,\n+                \"raw_response\": intent,\n+            }\n+\n         except stripe.error.CardError as e:\n             self.logger.error(f\"Card error: {str(e)}\")\n             return {\n-                'transaction_id': None,\n-                'status': PaymentStatus.FAILED,\n-                'error': str(e.user_message),\n-                'error_code': e.code,\n-                'raw_response': e.json_body\n+                \"transaction_id\": None,\n+                \"status\": PaymentStatus.FAILED,\n+                \"error\": str(e.user_message),\n+                \"error_code\": e.code,\n+                \"raw_response\": e.json_body,\n             }\n         except Exception as e:\n             self.logger.error(f\"Payment creation failed: {str(e)}\")\n             return {\n-                'transaction_id': None,\n-                'status': PaymentStatus.FAILED,\n-                'error': str(e),\n-                'raw_response': None\n-            }\n-    \n+                \"transaction_id\": None,\n+                \"status\": PaymentStatus.FAILED,\n+                \"error\": str(e),\n+                \"raw_response\": None,\n+            }\n+\n     async def capture_payment(\n-        self, \n-        transaction_id: str,\n-        amount: Optional[Decimal] = None\n+        self, transaction_id: str, amount: Optional[Decimal] = None\n     ) -> Dict[str, Any]:\n         \"\"\"Capture a previously authorized payment\"\"\"\n         try:\n             capture_data = {}\n             if amount:\n-                capture_data['amount_to_capture'] = self.format_amount(amount, 'gbp')\n-            \n+                capture_data[\"amount_to_capture\"] = self.format_amount(amount, \"gbp\")\n+\n             intent = stripe.PaymentIntent.capture(transaction_id, **capture_data)\n-            \n-            return {\n-                'success': True,\n-                'transaction_id': intent.id,\n-                'status': self._map_stripe_status(intent.status),\n-                'captured_amount': self.parse_amount(intent.amount_received, intent.currency),\n-                'raw_response': intent\n-            }\n-            \n+\n+            return {\n+                \"success\": True,\n+                \"transaction_id\": intent.id,\n+                \"status\": self._map_stripe_status(intent.status),\n+                \"captured_amount\": self.parse_amount(\n+                    intent.amount_received, intent.currency\n+                ),\n+                \"raw_response\": intent,\n+            }\n+\n         except Exception as e:\n             self.logger.error(f\"Payment capture failed: {str(e)}\")\n-            return {\n-                'success': False,\n-                'error': str(e),\n-                'raw_response': None\n-            }\n-    \n+            return {\"success\": False, \"error\": str(e), \"raw_response\": None}\n+\n     async def refund_payment(\n         self,\n         transaction_id: str,\n         amount: Optional[Decimal] = None,\n-        reason: Optional[str] = None\n+        reason: Optional[str] = None,\n     ) -> Dict[str, Any]:\n         \"\"\"Refund a payment\"\"\"\n         try:\n             refund_data = {\n-                'payment_intent': transaction_id,\n-                'metadata': {\n-                    'refund_reason': reason or 'customer_request',\n-                    'refunded_at': datetime.utcnow().isoformat()\n-                }\n-            }\n-            \n+                \"payment_intent\": transaction_id,\n+                \"metadata\": {\n+                    \"refund_reason\": reason or \"customer_request\",\n+                    \"refunded_at\": datetime.utcnow().isoformat(),\n+                },\n+            }\n+\n             if amount:\n                 # Get the payment intent to know the currency\n                 intent = stripe.PaymentIntent.retrieve(transaction_id)\n-                refund_data['amount'] = self.format_amount(amount, intent.currency)\n-            \n+                refund_data[\"amount\"] = self.format_amount(amount, intent.currency)\n+\n             if reason:\n                 # Map reason to Stripe's expected values\n                 reason_map = {\n-                    'duplicate': 'duplicate',\n-                    'fraudulent': 'fraudulent',\n-                    'customer_request': 'requested_by_customer'\n+                    \"duplicate\": \"duplicate\",\n+                    \"fraudulent\": \"fraudulent\",\n+                    \"customer_request\": \"requested_by_customer\",\n                 }\n-                refund_data['reason'] = reason_map.get(reason, 'requested_by_customer')\n-            \n+                refund_data[\"reason\"] = reason_map.get(reason, \"requested_by_customer\")\n+\n             refund = stripe.Refund.create(**refund_data)\n-            \n-            return {\n-                'success': True,\n-                'refund_id': refund.id,\n-                'transaction_id': transaction_id,\n-                'refunded_amount': self.parse_amount(refund.amount, refund.currency),\n-                'status': PaymentStatus.REFUNDED if refund.status == 'succeeded' else PaymentStatus.FAILED,\n-                'raw_response': refund\n-            }\n-            \n+\n+            return {\n+                \"success\": True,\n+                \"refund_id\": refund.id,\n+                \"transaction_id\": transaction_id,\n+                \"refunded_amount\": self.parse_amount(refund.amount, refund.currency),\n+                \"status\": (\n+                    PaymentStatus.REFUNDED\n+                    if refund.status == \"succeeded\"\n+                    else PaymentStatus.FAILED\n+                ),\n+                \"raw_response\": refund,\n+            }\n+\n         except Exception as e:\n             self.logger.error(f\"Refund failed: {str(e)}\")\n-            return {\n-                'success': False,\n-                'error': str(e),\n-                'raw_response': None\n-            }\n-    \n-    async def get_transaction_status(\n-        self,\n-        transaction_id: str\n-    ) -> Dict[str, Any]:\n+            return {\"success\": False, \"error\": str(e), \"raw_response\": None}\n+\n+    async def get_transaction_status(self, transaction_id: str) -> Dict[str, Any]:\n         \"\"\"Get current status of a transaction\"\"\"\n         try:\n             intent = stripe.PaymentIntent.retrieve(transaction_id)\n-            \n-            return {\n-                'transaction_id': intent.id,\n-                'status': self._map_stripe_status(intent.status),\n-                'amount': self.parse_amount(intent.amount, intent.currency),\n-                'currency': intent.currency.upper(),\n-                'created_at': datetime.fromtimestamp(intent.created).isoformat(),\n-                'metadata': intent.metadata,\n-                'raw_response': intent\n-            }\n-            \n+\n+            return {\n+                \"transaction_id\": intent.id,\n+                \"status\": self._map_stripe_status(intent.status),\n+                \"amount\": self.parse_amount(intent.amount, intent.currency),\n+                \"currency\": intent.currency.upper(),\n+                \"created_at\": datetime.fromtimestamp(intent.created).isoformat(),\n+                \"metadata\": intent.metadata,\n+                \"raw_response\": intent,\n+            }\n+\n         except Exception as e:\n             self.logger.error(f\"Failed to get transaction status: {str(e)}\")\n             return {\n-                'transaction_id': transaction_id,\n-                'status': PaymentStatus.FAILED,\n-                'error': str(e),\n-                'raw_response': None\n-            }\n-    \n-    async def validate_webhook(\n-        self,\n-        payload: bytes,\n-        headers: Dict[str, str]\n-    ) -> bool:\n+                \"transaction_id\": transaction_id,\n+                \"status\": PaymentStatus.FAILED,\n+                \"error\": str(e),\n+                \"raw_response\": None,\n+            }\n+\n+    async def validate_webhook(self, payload: bytes, headers: Dict[str, str]) -> bool:\n         \"\"\"Validate a webhook from Stripe\"\"\"\n         try:\n-            sig_header = headers.get('Stripe-Signature')\n-            webhook_secret = self.config.get('webhook_secret')\n-            \n+            sig_header = headers.get(\"Stripe-Signature\")\n+            webhook_secret = self.config.get(\"webhook_secret\")\n+\n             if not sig_header or not webhook_secret:\n                 return False\n-            \n-            stripe.Webhook.construct_event(\n-                payload, sig_header, webhook_secret\n-            )\n+\n+            stripe.Webhook.construct_event(payload, sig_header, webhook_secret)\n             return True\n-            \n+\n         except ValueError:\n             # Invalid payload\n             return False\n         except stripe.error.SignatureVerificationError:\n             # Invalid signature\n             return False\n-    \n-    async def parse_webhook(\n-        self,\n-        payload: bytes\n-    ) -> Dict[str, Any]:\n+\n+    async def parse_webhook(self, payload: bytes) -> Dict[str, Any]:\n         \"\"\"Parse webhook payload\"\"\"\n         try:\n             event = stripe.Event.construct_from(\n-                stripe.util.json.loads(payload.decode('utf-8')),\n-                stripe.api_key\n+                stripe.util.json.loads(payload.decode(\"utf-8\")), stripe.api_key\n             )\n-            \n+\n             # Map Stripe events to our internal events\n             event_map = {\n-                'payment_intent.succeeded': 'payment.completed',\n-                'payment_intent.payment_failed': 'payment.failed',\n-                'charge.refunded': 'payment.refunded',\n-                'payment_intent.canceled': 'payment.cancelled'\n-            }\n-            \n-            return {\n-                'event_type': event_map.get(event.type, event.type),\n-                'transaction_id': event.data.object.get('id'),\n-                'data': event.data.object,\n-                'raw_event': event\n-            }\n-            \n+                \"payment_intent.succeeded\": \"payment.completed\",\n+                \"payment_intent.payment_failed\": \"payment.failed\",\n+                \"charge.refunded\": \"payment.refunded\",\n+                \"payment_intent.canceled\": \"payment.cancelled\",\n+            }\n+\n+            return {\n+                \"event_type\": event_map.get(event.type, event.type),\n+                \"transaction_id\": event.data.object.get(\"id\"),\n+                \"data\": event.data.object,\n+                \"raw_event\": event,\n+            }\n+\n         except Exception as e:\n             self.logger.error(f\"Failed to parse webhook: {str(e)}\")\n-            return {\n-                'event_type': 'unknown',\n-                'error': str(e),\n-                'raw_event': None\n-            }\n-    \n+            return {\"event_type\": \"unknown\", \"error\": str(e), \"raw_event\": None}\n+\n     def _map_stripe_status(self, stripe_status: str) -> PaymentStatus:\n         \"\"\"Map Stripe status to internal PaymentStatus\"\"\"\n         status_map = {\n-            'requires_payment_method': PaymentStatus.PENDING,\n-            'requires_confirmation': PaymentStatus.PENDING,\n-            'requires_action': PaymentStatus.PENDING,\n-            'processing': PaymentStatus.PROCESSING,\n-            'requires_capture': PaymentStatus.PROCESSING,\n-            'canceled': PaymentStatus.CANCELLED,\n-            'succeeded': PaymentStatus.COMPLETED,\n-            'failed': PaymentStatus.FAILED\n+            \"requires_payment_method\": PaymentStatus.PENDING,\n+            \"requires_confirmation\": PaymentStatus.PENDING,\n+            \"requires_action\": PaymentStatus.PENDING,\n+            \"processing\": PaymentStatus.PROCESSING,\n+            \"requires_capture\": PaymentStatus.PROCESSING,\n+            \"canceled\": PaymentStatus.CANCELLED,\n+            \"succeeded\": PaymentStatus.COMPLETED,\n+            \"failed\": PaymentStatus.FAILED,\n         }\n-        return status_map.get(stripe_status, PaymentStatus.FAILED)\n\\ No newline at end of file\n+        return status_map.get(stripe_status, PaymentStatus.FAILED)\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_providers/square_provider.py\t2025-08-02 20:28:26.183440+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_providers/square_provider.py\t2025-08-02 22:36:03.992826+00:00\n@@ -4,13 +4,19 @@\n \n from decimal import Decimal\n from typing import Dict, Any, Optional\n import logging\n import uuid\n+\n try:\n     from square import client as Client\n-    from square.models import CreatePaymentRequest, Money, UpdatePaymentRequest, RefundPaymentRequest\n+    from square.models import (\n+        CreatePaymentRequest,\n+        Money,\n+        UpdatePaymentRequest,\n+        RefundPaymentRequest,\n+    )\n except ImportError:\n     # For testing - mock the Square imports\n     Client = None\n     CreatePaymentRequest = None\n     Money = None\n@@ -22,345 +28,327 @@\n logger = logging.getLogger(__name__)\n \n \n class SquareProvider(PaymentProvider):\n     \"\"\"Square payment provider implementation\"\"\"\n-    \n+\n     def __init__(self, config: Dict[str, Any]):\n         super().__init__(config)\n         self.client = None\n-        self.location_id = config.get('location_id')\n-    \n+        self.location_id = config.get(\"location_id\")\n+\n     async def initialize(self) -> bool:\n         \"\"\"Initialize Square client\"\"\"\n         if Client is None:\n             # Square SDK not available (testing mode)\n             self.logger.warning(\"Square SDK not available - using mock mode\")\n             return True\n-            \n+\n         try:\n             # Initialize Square client\n             self.client = Client(\n-                access_token=self.config.get('access_token'),\n-                environment='production' if self.config.get('mode') == 'production' else 'sandbox'\n-            )\n-            \n+                access_token=self.config.get(\"access_token\"),\n+                environment=(\n+                    \"production\"\n+                    if self.config.get(\"mode\") == \"production\"\n+                    else \"sandbox\"\n+                ),\n+            )\n+\n             # Test the connection\n             result = self.client.locations.list_locations()\n-            \n+\n             if result.is_error():\n                 self.logger.error(f\"Failed to initialize Square: {result.errors}\")\n                 return False\n-            \n+\n             # If no location_id provided, use the first one\n-            if not self.location_id and result.body.get('locations'):\n-                self.location_id = result.body['locations'][0]['id']\n-                self.config['location_id'] = self.location_id\n-            \n+            if not self.location_id and result.body.get(\"locations\"):\n+                self.location_id = result.body[\"locations\"][0][\"id\"]\n+                self.config[\"location_id\"] = self.location_id\n+\n             self.logger.info(\"Square provider initialized successfully\")\n             return True\n-            \n+\n         except Exception as e:\n             self.logger.error(f\"Failed to initialize Square: {str(e)}\")\n             return False\n-    \n+\n     async def create_payment(\n-        self, \n-        amount: Decimal, \n+        self,\n+        amount: Decimal,\n         currency: str,\n         order_id: str,\n         customer_info: Dict[str, Any],\n         payment_method: Dict[str, Any],\n-        metadata: Optional[Dict[str, Any]] = None\n+        metadata: Optional[Dict[str, Any]] = None,\n     ) -> Dict[str, Any]:\n         \"\"\"Create a payment with Square\"\"\"\n         try:\n             # Create money object\n             amount_money = Money(\n-                amount=self.format_amount(amount, currency),\n-                currency=currency.upper()\n-            )\n-            \n+                amount=self.format_amount(amount, currency), currency=currency.upper()\n+            )\n+\n             # Generate idempotency key\n             idempotency_key = str(uuid.uuid4())\n-            \n+\n             # Build payment request\n             request_body = CreatePaymentRequest(\n-                source_id=payment_method.get('nonce') or payment_method.get('source_id'),\n+                source_id=payment_method.get(\"nonce\")\n+                or payment_method.get(\"source_id\"),\n                 idempotency_key=idempotency_key,\n                 amount_money=amount_money,\n                 location_id=self.location_id,\n                 reference_id=order_id,\n-                note=f\"Order {order_id}\"\n-            )\n-            \n+                note=f\"Order {order_id}\",\n+            )\n+\n             # Add customer if provided\n-            if customer_info.get('email'):\n-                request_body.buyer_email_address = customer_info['email']\n-            \n+            if customer_info.get(\"email\"):\n+                request_body.buyer_email_address = customer_info[\"email\"]\n+\n             # Create payment\n             result = self.client.payments.create_payment(request_body)\n-            \n+\n             if result.is_error():\n                 self.logger.error(f\"Payment creation failed: {result.errors}\")\n                 return {\n-                    'transaction_id': None,\n-                    'status': PaymentStatus.FAILED,\n-                    'error': str(result.errors),\n-                    'raw_response': result.errors\n-                }\n-            \n-            payment = result.body['payment']\n-            \n+                    \"transaction_id\": None,\n+                    \"status\": PaymentStatus.FAILED,\n+                    \"error\": str(result.errors),\n+                    \"raw_response\": result.errors,\n+                }\n+\n+            payment = result.body[\"payment\"]\n+\n             # Calculate fees\n             fee = self.calculate_fee(amount)\n             net_amount = amount - fee\n-            \n-            return {\n-                'transaction_id': payment['id'],\n-                'status': self._map_square_status(payment['status']),\n-                'fee': fee,\n-                'net_amount': net_amount,\n-                'receipt_url': payment.get('receipt_url'),\n-                'raw_response': payment\n-            }\n-            \n+\n+            return {\n+                \"transaction_id\": payment[\"id\"],\n+                \"status\": self._map_square_status(payment[\"status\"]),\n+                \"fee\": fee,\n+                \"net_amount\": net_amount,\n+                \"receipt_url\": payment.get(\"receipt_url\"),\n+                \"raw_response\": payment,\n+            }\n+\n         except Exception as e:\n             self.logger.error(f\"Payment creation failed: {str(e)}\")\n             return {\n-                'transaction_id': None,\n-                'status': PaymentStatus.FAILED,\n-                'error': str(e),\n-                'raw_response': None\n-            }\n-    \n+                \"transaction_id\": None,\n+                \"status\": PaymentStatus.FAILED,\n+                \"error\": str(e),\n+                \"raw_response\": None,\n+            }\n+\n     async def capture_payment(\n-        self, \n-        transaction_id: str,\n-        amount: Optional[Decimal] = None\n+        self, transaction_id: str, amount: Optional[Decimal] = None\n     ) -> Dict[str, Any]:\n         \"\"\"Square captures payments automatically\"\"\"\n         # Square doesn't support separate auth/capture flow for most payment types\n         # Payments are captured automatically\n         try:\n             result = self.client.payments.get_payment(transaction_id)\n-            \n-            if result.is_error():\n-                return {\n-                    'success': False,\n-                    'error': str(result.errors),\n-                    'raw_response': result.errors\n-                }\n-            \n-            payment = result.body['payment']\n-            \n-            return {\n-                'success': True,\n-                'transaction_id': payment['id'],\n-                'status': self._map_square_status(payment['status']),\n-                'captured_amount': self.parse_amount(\n-                    payment['amount_money']['amount'], \n-                    payment['amount_money']['currency']\n+\n+            if result.is_error():\n+                return {\n+                    \"success\": False,\n+                    \"error\": str(result.errors),\n+                    \"raw_response\": result.errors,\n+                }\n+\n+            payment = result.body[\"payment\"]\n+\n+            return {\n+                \"success\": True,\n+                \"transaction_id\": payment[\"id\"],\n+                \"status\": self._map_square_status(payment[\"status\"]),\n+                \"captured_amount\": self.parse_amount(\n+                    payment[\"amount_money\"][\"amount\"],\n+                    payment[\"amount_money\"][\"currency\"],\n                 ),\n-                'raw_response': payment\n-            }\n-            \n+                \"raw_response\": payment,\n+            }\n+\n         except Exception as e:\n             self.logger.error(f\"Payment capture failed: {str(e)}\")\n-            return {\n-                'success': False,\n-                'error': str(e),\n-                'raw_response': None\n-            }\n-    \n+            return {\"success\": False, \"error\": str(e), \"raw_response\": None}\n+\n     async def refund_payment(\n         self,\n         transaction_id: str,\n         amount: Optional[Decimal] = None,\n-        reason: Optional[str] = None\n+        reason: Optional[str] = None,\n     ) -> Dict[str, Any]:\n         \"\"\"Refund a payment\"\"\"\n         try:\n             # Get the original payment\n             payment_result = self.client.payments.get_payment(transaction_id)\n-            \n+\n             if payment_result.is_error():\n                 return {\n-                    'success': False,\n-                    'error': str(payment_result.errors),\n-                    'raw_response': payment_result.errors\n-                }\n-            \n-            payment = payment_result.body['payment']\n-            currency = payment['amount_money']['currency']\n-            \n+                    \"success\": False,\n+                    \"error\": str(payment_result.errors),\n+                    \"raw_response\": payment_result.errors,\n+                }\n+\n+            payment = payment_result.body[\"payment\"]\n+            currency = payment[\"amount_money\"][\"currency\"]\n+\n             # Prepare refund amount\n             if amount:\n                 refund_money = Money(\n-                    amount=self.format_amount(amount, currency),\n-                    currency=currency\n+                    amount=self.format_amount(amount, currency), currency=currency\n                 )\n             else:\n-                refund_money = payment['amount_money']\n-            \n+                refund_money = payment[\"amount_money\"]\n+\n             # Create refund request\n             request_body = RefundPaymentRequest(\n                 idempotency_key=str(uuid.uuid4()),\n                 amount_money=refund_money,\n                 payment_id=transaction_id,\n-                reason=reason or \"Customer requested refund\"\n-            )\n-            \n+                reason=reason or \"Customer requested refund\",\n+            )\n+\n             result = self.client.refunds.refund_payment(request_body)\n-            \n-            if result.is_error():\n-                return {\n-                    'success': False,\n-                    'error': str(result.errors),\n-                    'raw_response': result.errors\n-                }\n-            \n-            refund = result.body['refund']\n-            \n-            return {\n-                'success': True,\n-                'refund_id': refund['id'],\n-                'transaction_id': transaction_id,\n-                'refunded_amount': self.parse_amount(\n-                    refund['amount_money']['amount'],\n-                    refund['amount_money']['currency']\n+\n+            if result.is_error():\n+                return {\n+                    \"success\": False,\n+                    \"error\": str(result.errors),\n+                    \"raw_response\": result.errors,\n+                }\n+\n+            refund = result.body[\"refund\"]\n+\n+            return {\n+                \"success\": True,\n+                \"refund_id\": refund[\"id\"],\n+                \"transaction_id\": transaction_id,\n+                \"refunded_amount\": self.parse_amount(\n+                    refund[\"amount_money\"][\"amount\"], refund[\"amount_money\"][\"currency\"]\n                 ),\n-                'status': self._map_square_refund_status(refund['status']),\n-                'raw_response': refund\n-            }\n-            \n+                \"status\": self._map_square_refund_status(refund[\"status\"]),\n+                \"raw_response\": refund,\n+            }\n+\n         except Exception as e:\n             self.logger.error(f\"Refund failed: {str(e)}\")\n-            return {\n-                'success': False,\n-                'error': str(e),\n-                'raw_response': None\n-            }\n-    \n-    async def get_transaction_status(\n-        self,\n-        transaction_id: str\n-    ) -> Dict[str, Any]:\n+            return {\"success\": False, \"error\": str(e), \"raw_response\": None}\n+\n+    async def get_transaction_status(self, transaction_id: str) -> Dict[str, Any]:\n         \"\"\"Get current status of a transaction\"\"\"\n         try:\n             result = self.client.payments.get_payment(transaction_id)\n-            \n-            if result.is_error():\n-                return {\n-                    'transaction_id': transaction_id,\n-                    'status': PaymentStatus.FAILED,\n-                    'error': str(result.errors),\n-                    'raw_response': result.errors\n-                }\n-            \n-            payment = result.body['payment']\n-            \n-            return {\n-                'transaction_id': payment['id'],\n-                'status': self._map_square_status(payment['status']),\n-                'amount': self.parse_amount(\n-                    payment['amount_money']['amount'],\n-                    payment['amount_money']['currency']\n+\n+            if result.is_error():\n+                return {\n+                    \"transaction_id\": transaction_id,\n+                    \"status\": PaymentStatus.FAILED,\n+                    \"error\": str(result.errors),\n+                    \"raw_response\": result.errors,\n+                }\n+\n+            payment = result.body[\"payment\"]\n+\n+            return {\n+                \"transaction_id\": payment[\"id\"],\n+                \"status\": self._map_square_status(payment[\"status\"]),\n+                \"amount\": self.parse_amount(\n+                    payment[\"amount_money\"][\"amount\"],\n+                    payment[\"amount_money\"][\"currency\"],\n                 ),\n-                'currency': payment['amount_money']['currency'],\n-                'created_at': payment['created_at'],\n-                'receipt_url': payment.get('receipt_url'),\n-                'raw_response': payment\n-            }\n-            \n+                \"currency\": payment[\"amount_money\"][\"currency\"],\n+                \"created_at\": payment[\"created_at\"],\n+                \"receipt_url\": payment.get(\"receipt_url\"),\n+                \"raw_response\": payment,\n+            }\n+\n         except Exception as e:\n             self.logger.error(f\"Failed to get transaction status: {str(e)}\")\n             return {\n-                'transaction_id': transaction_id,\n-                'status': PaymentStatus.FAILED,\n-                'error': str(e),\n-                'raw_response': None\n-            }\n-    \n-    async def validate_webhook(\n-        self,\n-        payload: bytes,\n-        headers: Dict[str, str]\n-    ) -> bool:\n+                \"transaction_id\": transaction_id,\n+                \"status\": PaymentStatus.FAILED,\n+                \"error\": str(e),\n+                \"raw_response\": None,\n+            }\n+\n+    async def validate_webhook(self, payload: bytes, headers: Dict[str, str]) -> bool:\n         \"\"\"Validate a webhook from Square\"\"\"\n         try:\n             # Square webhook validation\n-            signature = headers.get('X-Square-Hmacsha256-Signature')\n-            webhook_signature_key = self.config.get('webhook_signature_key')\n-            \n+            signature = headers.get(\"X-Square-Hmacsha256-Signature\")\n+            webhook_signature_key = self.config.get(\"webhook_signature_key\")\n+\n             if not signature or not webhook_signature_key:\n                 return False\n-            \n+\n             # Validate the webhook signature\n             is_valid = self.client.webhooks.verify_signature(\n-                body=payload.decode('utf-8'),\n+                body=payload.decode(\"utf-8\"),\n                 signature=signature,\n                 signature_key=webhook_signature_key,\n-                notification_url=self.config.get('webhook_url', '')\n-            )\n-            \n+                notification_url=self.config.get(\"webhook_url\", \"\"),\n+            )\n+\n             return is_valid\n-            \n+\n         except Exception as e:\n             self.logger.error(f\"Webhook validation failed: {str(e)}\")\n             return False\n-    \n-    async def parse_webhook(\n-        self,\n-        payload: bytes\n-    ) -> Dict[str, Any]:\n+\n+    async def parse_webhook(self, payload: bytes) -> Dict[str, Any]:\n         \"\"\"Parse webhook payload\"\"\"\n         try:\n             import json\n-            data = json.loads(payload.decode('utf-8'))\n-            \n+\n+            data = json.loads(payload.decode(\"utf-8\"))\n+\n             # Map Square events to our internal events\n             event_map = {\n-                'payment.created': 'payment.created',\n-                'payment.updated': 'payment.updated',\n-                'refund.created': 'payment.refunded',\n-                'refund.updated': 'payment.refund_updated'\n-            }\n-            \n-            event_type = data.get('type', 'unknown')\n-            \n-            return {\n-                'event_type': event_map.get(event_type, event_type),\n-                'transaction_id': data.get('data', {}).get('object', {}).get('payment', {}).get('id'),\n-                'data': data.get('data', {}),\n-                'raw_event': data\n-            }\n-            \n+                \"payment.created\": \"payment.created\",\n+                \"payment.updated\": \"payment.updated\",\n+                \"refund.created\": \"payment.refunded\",\n+                \"refund.updated\": \"payment.refund_updated\",\n+            }\n+\n+            event_type = data.get(\"type\", \"unknown\")\n+\n+            return {\n+                \"event_type\": event_map.get(event_type, event_type),\n+                \"transaction_id\": data.get(\"data\", {})\n+                .get(\"object\", {})\n+                .get(\"payment\", {})\n+                .get(\"id\"),\n+                \"data\": data.get(\"data\", {}),\n+                \"raw_event\": data,\n+            }\n+\n         except Exception as e:\n             self.logger.error(f\"Failed to parse webhook: {str(e)}\")\n-            return {\n-                'event_type': 'unknown',\n-                'error': str(e),\n-                'raw_event': None\n-            }\n-    \n+            return {\"event_type\": \"unknown\", \"error\": str(e), \"raw_event\": None}\n+\n     def _map_square_status(self, square_status: str) -> PaymentStatus:\n         \"\"\"Map Square status to internal PaymentStatus\"\"\"\n         status_map = {\n-            'PENDING': PaymentStatus.PENDING,\n-            'APPROVED': PaymentStatus.PROCESSING,\n-            'COMPLETED': PaymentStatus.COMPLETED,\n-            'CANCELED': PaymentStatus.CANCELLED,\n-            'FAILED': PaymentStatus.FAILED\n+            \"PENDING\": PaymentStatus.PENDING,\n+            \"APPROVED\": PaymentStatus.PROCESSING,\n+            \"COMPLETED\": PaymentStatus.COMPLETED,\n+            \"CANCELED\": PaymentStatus.CANCELLED,\n+            \"FAILED\": PaymentStatus.FAILED,\n         }\n         return status_map.get(square_status, PaymentStatus.FAILED)\n-    \n+\n     def _map_square_refund_status(self, square_status: str) -> PaymentStatus:\n         \"\"\"Map Square refund status to internal PaymentStatus\"\"\"\n         status_map = {\n-            'PENDING': PaymentStatus.PROCESSING,\n-            'APPROVED': PaymentStatus.REFUNDED,\n-            'REJECTED': PaymentStatus.FAILED,\n-            'FAILED': PaymentStatus.FAILED,\n-            'COMPLETED': PaymentStatus.REFUNDED\n+            \"PENDING\": PaymentStatus.PROCESSING,\n+            \"APPROVED\": PaymentStatus.REFUNDED,\n+            \"REJECTED\": PaymentStatus.FAILED,\n+            \"FAILED\": PaymentStatus.FAILED,\n+            \"COMPLETED\": PaymentStatus.REFUNDED,\n         }\n-        return status_map.get(square_status, PaymentStatus.FAILED)\n\\ No newline at end of file\n+        return status_map.get(square_status, PaymentStatus.FAILED)\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_analytics.py\t2025-08-02 22:08:35.802973+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_analytics.py\t2025-08-02 22:36:04.003714+00:00\n@@ -14,556 +14,635 @@\n from app.core.database import Payment, Order\n from app.services.payment_providers import PaymentProvider\n \n logger = logging.getLogger(__name__)\n \n+\n class PaymentAnalyticsService:\n     \"\"\"Service for analyzing payment data and generating insights\"\"\"\n-    \n+\n     def __init__(self, db: Session):\n         self.db = db\n-    \n+\n     async def get_provider_performance_summary(\n-        self, \n+        self,\n         restaurant_id: Optional[str] = None,\n         start_date: Optional[datetime] = None,\n-        end_date: Optional[datetime] = None\n+        end_date: Optional[datetime] = None,\n     ) -> Dict:\n         \"\"\"Get comprehensive provider performance analytics\"\"\"\n-        \n+\n         # Default to last 30 days if no dates provided\n         if not end_date:\n             end_date = datetime.utcnow()\n         if not start_date:\n             start_date = end_date - timedelta(days=30)\n-        \n+\n         # Base query\n         query = self.db.query(Payment).filter(\n             Payment.processed_at.between(start_date, end_date),\n-            Payment.status == \"completed\"\n-        )\n-        \n+            Payment.status == \"completed\",\n+        )\n+\n         if restaurant_id:\n             # Join with Order to filter by restaurant\n             query = query.join(Order).filter(Order.restaurant_id == restaurant_id)\n-        \n+\n         payments = query.all()\n-        \n+\n         # Analyze by provider\n-        provider_stats = defaultdict(lambda: {\n-            'transaction_count': 0,\n-            'total_volume': Decimal('0'),\n-            'total_fees': Decimal('0'),\n-            'avg_transaction_size': Decimal('0'),\n-            'success_rate': 0.0,\n-            'avg_processing_time': 0.0,\n-            'fee_percentage': 0.0\n-        })\n-        \n-        total_volume = Decimal('0')\n-        total_fees = Decimal('0')\n-        \n+        provider_stats = defaultdict(\n+            lambda: {\n+                \"transaction_count\": 0,\n+                \"total_volume\": Decimal(\"0\"),\n+                \"total_fees\": Decimal(\"0\"),\n+                \"avg_transaction_size\": Decimal(\"0\"),\n+                \"success_rate\": 0.0,\n+                \"avg_processing_time\": 0.0,\n+                \"fee_percentage\": 0.0,\n+            }\n+        )\n+\n+        total_volume = Decimal(\"0\")\n+        total_fees = Decimal(\"0\")\n+\n         for payment in payments:\n-            provider = payment.provider or 'unknown'\n+            provider = payment.provider or \"unknown\"\n             amount = Decimal(str(payment.amount))\n             fee = Decimal(str(payment.provider_fee or payment.fee_amount or 0))\n-            \n-            provider_stats[provider]['transaction_count'] += 1\n-            provider_stats[provider]['total_volume'] += amount\n-            provider_stats[provider]['total_fees'] += fee\n-            \n+\n+            provider_stats[provider][\"transaction_count\"] += 1\n+            provider_stats[provider][\"total_volume\"] += amount\n+            provider_stats[provider][\"total_fees\"] += fee\n+\n             total_volume += amount\n             total_fees += fee\n-        \n+\n         # Calculate derived metrics\n         for provider, stats in provider_stats.items():\n-            if stats['transaction_count'] > 0:\n-                stats['avg_transaction_size'] = stats['total_volume'] / stats['transaction_count']\n-                stats['fee_percentage'] = (stats['total_fees'] / stats['total_volume'] * 100) if stats['total_volume'] > 0 else 0\n-        \n+            if stats[\"transaction_count\"] > 0:\n+                stats[\"avg_transaction_size\"] = (\n+                    stats[\"total_volume\"] / stats[\"transaction_count\"]\n+                )\n+                stats[\"fee_percentage\"] = (\n+                    (stats[\"total_fees\"] / stats[\"total_volume\"] * 100)\n+                    if stats[\"total_volume\"] > 0\n+                    else 0\n+                )\n+\n         # Calculate cost savings opportunities\n         cost_savings = await self._calculate_cost_savings(provider_stats, total_volume)\n-        \n+\n         # Get optimal provider recommendations\n-        optimal_providers = await self._get_optimal_provider_recommendations(total_volume, provider_stats)\n-        \n-        return {\n-            'period': {\n-                'start_date': start_date.isoformat(),\n-                'end_date': end_date.isoformat(),\n-                'days': (end_date - start_date).days\n+        optimal_providers = await self._get_optimal_provider_recommendations(\n+            total_volume, provider_stats\n+        )\n+\n+        return {\n+            \"period\": {\n+                \"start_date\": start_date.isoformat(),\n+                \"end_date\": end_date.isoformat(),\n+                \"days\": (end_date - start_date).days,\n             },\n-            'overall_metrics': {\n-                'total_volume': float(total_volume),\n-                'total_fees': float(total_fees),\n-                'avg_fee_percentage': float((total_fees / total_volume * 100)) if total_volume > 0 else 0,\n-                'transaction_count': sum(stats['transaction_count'] for stats in provider_stats.values())\n+            \"overall_metrics\": {\n+                \"total_volume\": float(total_volume),\n+                \"total_fees\": float(total_fees),\n+                \"avg_fee_percentage\": (\n+                    float((total_fees / total_volume * 100)) if total_volume > 0 else 0\n+                ),\n+                \"transaction_count\": sum(\n+                    stats[\"transaction_count\"] for stats in provider_stats.values()\n+                ),\n             },\n-            'provider_performance': {\n+            \"provider_performance\": {\n                 provider: {\n-                    'transaction_count': stats['transaction_count'],\n-                    'total_volume': float(stats['total_volume']),\n-                    'total_fees': float(stats['total_fees']),\n-                    'avg_transaction_size': float(stats['avg_transaction_size']),\n-                    'fee_percentage': float(stats['fee_percentage'])\n+                    \"transaction_count\": stats[\"transaction_count\"],\n+                    \"total_volume\": float(stats[\"total_volume\"]),\n+                    \"total_fees\": float(stats[\"total_fees\"]),\n+                    \"avg_transaction_size\": float(stats[\"avg_transaction_size\"]),\n+                    \"fee_percentage\": float(stats[\"fee_percentage\"]),\n                 }\n                 for provider, stats in provider_stats.items()\n             },\n-            'cost_savings': cost_savings,\n-            'recommendations': optimal_providers\n-        }\n-    \n+            \"cost_savings\": cost_savings,\n+            \"recommendations\": optimal_providers,\n+        }\n+\n     async def get_transaction_volume_trends(\n-        self, \n-        restaurant_id: Optional[str] = None,\n-        days: int = 30\n+        self, restaurant_id: Optional[str] = None, days: int = 30\n     ) -> Dict:\n         \"\"\"Get transaction volume trends over time\"\"\"\n-        \n+\n         end_date = datetime.utcnow()\n         start_date = end_date - timedelta(days=days)\n-        \n+\n         # Query daily transaction volumes\n-        query = self.db.query(\n-            func.date(Payment.processed_at).label('date'),\n-            Payment.provider,\n-            func.count(Payment.id).label('transaction_count'),\n-            func.sum(Payment.amount).label('volume'),\n-            func.sum(Payment.provider_fee).label('fees')\n-        ).filter(\n-            Payment.processed_at.between(start_date, end_date),\n-            Payment.status == \"completed\"\n-        ).group_by(\n-            func.date(Payment.processed_at),\n-            Payment.provider\n-        ).order_by(func.date(Payment.processed_at))\n-        \n+        query = (\n+            self.db.query(\n+                func.date(Payment.processed_at).label(\"date\"),\n+                Payment.provider,\n+                func.count(Payment.id).label(\"transaction_count\"),\n+                func.sum(Payment.amount).label(\"volume\"),\n+                func.sum(Payment.provider_fee).label(\"fees\"),\n+            )\n+            .filter(\n+                Payment.processed_at.between(start_date, end_date),\n+                Payment.status == \"completed\",\n+            )\n+            .group_by(func.date(Payment.processed_at), Payment.provider)\n+            .order_by(func.date(Payment.processed_at))\n+        )\n+\n         if restaurant_id:\n             query = query.join(Order).filter(Order.restaurant_id == restaurant_id)\n-        \n+\n         results = query.all()\n-        \n+\n         # Organize data by date\n-        daily_data = defaultdict(lambda: {\n-            'date': None,\n-            'total_volume': 0,\n-            'total_transactions': 0,\n-            'total_fees': 0,\n-            'providers': {}\n-        })\n-        \n+        daily_data = defaultdict(\n+            lambda: {\n+                \"date\": None,\n+                \"total_volume\": 0,\n+                \"total_transactions\": 0,\n+                \"total_fees\": 0,\n+                \"providers\": {},\n+            }\n+        )\n+\n         for result in results:\n             date_str = result.date.isoformat()\n-            if daily_data[date_str]['date'] is None:\n-                daily_data[date_str]['date'] = date_str\n-            \n-            daily_data[date_str]['total_volume'] += float(result.volume or 0)\n-            daily_data[date_str]['total_transactions'] += result.transaction_count\n-            daily_data[date_str]['total_fees'] += float(result.fees or 0)\n-            \n-            daily_data[date_str]['providers'][result.provider] = {\n-                'transaction_count': result.transaction_count,\n-                'volume': float(result.volume or 0),\n-                'fees': float(result.fees or 0)\n+            if daily_data[date_str][\"date\"] is None:\n+                daily_data[date_str][\"date\"] = date_str\n+\n+            daily_data[date_str][\"total_volume\"] += float(result.volume or 0)\n+            daily_data[date_str][\"total_transactions\"] += result.transaction_count\n+            daily_data[date_str][\"total_fees\"] += float(result.fees or 0)\n+\n+            daily_data[date_str][\"providers\"][result.provider] = {\n+                \"transaction_count\": result.transaction_count,\n+                \"volume\": float(result.volume or 0),\n+                \"fees\": float(result.fees or 0),\n             }\n-        \n+\n         # Convert to list and sort by date\n         trend_data = list(daily_data.values())\n-        trend_data.sort(key=lambda x: x['date'])\n-        \n+        trend_data.sort(key=lambda x: x[\"date\"])\n+\n         # Calculate growth rates\n         growth_metrics = self._calculate_growth_metrics(trend_data)\n-        \n-        return {\n-            'period': {\n-                'start_date': start_date.isoformat(),\n-                'end_date': end_date.isoformat(),\n-                'days': days\n+\n+        return {\n+            \"period\": {\n+                \"start_date\": start_date.isoformat(),\n+                \"end_date\": end_date.isoformat(),\n+                \"days\": days,\n             },\n-            'daily_trends': trend_data,\n-            'growth_metrics': growth_metrics\n-        }\n-    \n+            \"daily_trends\": trend_data,\n+            \"growth_metrics\": growth_metrics,\n+        }\n+\n     async def get_cost_optimization_report(\n-        self, \n+        self,\n         restaurant_id: Optional[str] = None,\n         start_date: Optional[datetime] = None,\n-        end_date: Optional[datetime] = None\n+        end_date: Optional[datetime] = None,\n     ) -> Dict:\n         \"\"\"Generate detailed cost optimization report\"\"\"\n-        \n+\n         # Get current performance\n         current_performance = await self.get_provider_performance_summary(\n             restaurant_id, start_date, end_date\n         )\n-        \n-        total_volume = Decimal(str(current_performance['overall_metrics']['total_volume']))\n-        current_fees = Decimal(str(current_performance['overall_metrics']['total_fees']))\n-        \n+\n+        total_volume = Decimal(\n+            str(current_performance[\"overall_metrics\"][\"total_volume\"])\n+        )\n+        current_fees = Decimal(\n+            str(current_performance[\"overall_metrics\"][\"total_fees\"])\n+        )\n+\n         # Calculate optimal fee structure\n         optimal_breakdown = await self._calculate_optimal_provider_mix(total_volume)\n-        \n+\n         # Calculate potential savings\n-        potential_savings = current_fees - optimal_breakdown['total_optimal_fees']\n-        savings_percentage = (potential_savings / current_fees * 100) if current_fees > 0 else 0\n-        \n+        potential_savings = current_fees - optimal_breakdown[\"total_optimal_fees\"]\n+        savings_percentage = (\n+            (potential_savings / current_fees * 100) if current_fees > 0 else 0\n+        )\n+\n         # Generate specific recommendations\n         recommendations = await self._generate_optimization_recommendations(\n             current_performance, optimal_breakdown, total_volume\n         )\n-        \n-        return {\n-            'current_state': {\n-                'total_volume': float(total_volume),\n-                'current_fees': float(current_fees),\n-                'avg_fee_rate': float(current_fees / total_volume * 100) if total_volume > 0 else 0\n+\n+        return {\n+            \"current_state\": {\n+                \"total_volume\": float(total_volume),\n+                \"current_fees\": float(current_fees),\n+                \"avg_fee_rate\": (\n+                    float(current_fees / total_volume * 100) if total_volume > 0 else 0\n+                ),\n             },\n-            'optimal_state': {\n-                'optimal_fees': float(optimal_breakdown['total_optimal_fees']),\n-                'optimal_fee_rate': float(optimal_breakdown['total_optimal_fees'] / total_volume * 100) if total_volume > 0 else 0,\n-                'provider_breakdown': {\n+            \"optimal_state\": {\n+                \"optimal_fees\": float(optimal_breakdown[\"total_optimal_fees\"]),\n+                \"optimal_fee_rate\": (\n+                    float(optimal_breakdown[\"total_optimal_fees\"] / total_volume * 100)\n+                    if total_volume > 0\n+                    else 0\n+                ),\n+                \"provider_breakdown\": {\n                     provider: {\n-                        'recommended_volume': float(data['volume']),\n-                        'expected_fees': float(data['fees']),\n-                        'volume_percentage': float(data['volume'] / total_volume * 100) if total_volume > 0 else 0\n+                        \"recommended_volume\": float(data[\"volume\"]),\n+                        \"expected_fees\": float(data[\"fees\"]),\n+                        \"volume_percentage\": (\n+                            float(data[\"volume\"] / total_volume * 100)\n+                            if total_volume > 0\n+                            else 0\n+                        ),\n                     }\n-                    for provider, data in optimal_breakdown['provider_breakdown'].items()\n-                }\n+                    for provider, data in optimal_breakdown[\n+                        \"provider_breakdown\"\n+                    ].items()\n+                },\n             },\n-            'savings_opportunity': {\n-                'potential_savings': float(potential_savings),\n-                'savings_percentage': float(savings_percentage),\n-                'annual_savings_projection': float(potential_savings * 12) if start_date and end_date and (end_date - start_date).days >= 28 else None\n+            \"savings_opportunity\": {\n+                \"potential_savings\": float(potential_savings),\n+                \"savings_percentage\": float(savings_percentage),\n+                \"annual_savings_projection\": (\n+                    float(potential_savings * 12)\n+                    if start_date and end_date and (end_date - start_date).days >= 28\n+                    else None\n+                ),\n             },\n-            'recommendations': recommendations\n-        }\n-    \n+            \"recommendations\": recommendations,\n+        }\n+\n     async def get_provider_health_scores(\n-        self, \n-        restaurant_id: Optional[str] = None\n+        self, restaurant_id: Optional[str] = None\n     ) -> Dict:\n         \"\"\"Calculate health scores for each provider based on multiple factors\"\"\"\n-        \n+\n         # Get last 7 and 30 days of data\n         end_date = datetime.utcnow()\n         start_date_7 = end_date - timedelta(days=7)\n         start_date_30 = end_date - timedelta(days=30)\n-        \n+\n         # Query recent payment data\n         query_7 = self.db.query(Payment).filter(\n             Payment.processed_at.between(start_date_7, end_date)\n         )\n         query_30 = self.db.query(Payment).filter(\n             Payment.processed_at.between(start_date_30, end_date)\n         )\n-        \n+\n         if restaurant_id:\n             query_7 = query_7.join(Order).filter(Order.restaurant_id == restaurant_id)\n             query_30 = query_30.join(Order).filter(Order.restaurant_id == restaurant_id)\n-        \n+\n         payments_7d = query_7.all()\n         payments_30d = query_30.all()\n-        \n+\n         provider_health = {}\n-        \n+\n         # Calculate health scores for each provider\n-        for provider in ['stripe', 'square', 'sumup', 'qr_code']:\n+        for provider in [\"stripe\", \"square\", \"sumup\", \"qr_code\"]:\n             # Filter payments for this provider\n             provider_payments_7d = [p for p in payments_7d if p.provider == provider]\n             provider_payments_30d = [p for p in payments_30d if p.provider == provider]\n-            \n+\n             health_score = await self._calculate_provider_health_score(\n                 provider, provider_payments_7d, provider_payments_30d\n             )\n-            \n+\n             provider_health[provider] = health_score\n-        \n-        return {\n-            'evaluation_date': end_date.isoformat(),\n-            'health_scores': provider_health,\n-            'overall_system_health': sum(score['overall_score'] for score in provider_health.values()) / len(provider_health) if provider_health else 0\n-        }\n-    \n-    async def _calculate_cost_savings(self, provider_stats: Dict, total_volume: Decimal) -> Dict:\n+\n+        return {\n+            \"evaluation_date\": end_date.isoformat(),\n+            \"health_scores\": provider_health,\n+            \"overall_system_health\": (\n+                sum(score[\"overall_score\"] for score in provider_health.values())\n+                / len(provider_health)\n+                if provider_health\n+                else 0\n+            ),\n+        }\n+\n+    async def _calculate_cost_savings(\n+        self, provider_stats: Dict, total_volume: Decimal\n+    ) -> Dict:\n         \"\"\"Calculate potential cost savings with optimal provider mix\"\"\"\n-        \n+\n         if total_volume == 0:\n-            return {'potential_savings': 0, 'optimal_mix': {}}\n-        \n-        current_total_fees = sum(Decimal(str(stats['total_fees'])) for stats in provider_stats.values())\n-        \n+            return {\"potential_savings\": 0, \"optimal_mix\": {}}\n+\n+        current_total_fees = sum(\n+            Decimal(str(stats[\"total_fees\"])) for stats in provider_stats.values()\n+        )\n+\n         # Calculate optimal fees based on volume tiers\n-        optimal_fees = Decimal('0')\n+        optimal_fees = Decimal(\"0\")\n         optimal_mix = {}\n-        \n+\n         # SumUp is best for high volume (\u00a32,714+/month)\n-        if total_volume >= Decimal('2714'):\n+        if total_volume >= Decimal(\"2714\"):\n             # Use SumUp for all transactions\n-            sumup_fee_rate = Decimal('0.0069')  # 0.69%\n-            monthly_fee = Decimal('19')  # \u00a319/month\n+            sumup_fee_rate = Decimal(\"0.0069\")  # 0.69%\n+            monthly_fee = Decimal(\"19\")  # \u00a319/month\n             optimal_fees = (total_volume * sumup_fee_rate) + monthly_fee\n-            optimal_mix['sumup'] = {\n-                'percentage': 100,\n-                'volume': float(total_volume),\n-                'fees': float(optimal_fees)\n+            optimal_mix[\"sumup\"] = {\n+                \"percentage\": 100,\n+                \"volume\": float(total_volume),\n+                \"fees\": float(optimal_fees),\n             }\n         else:\n             # Use QR code for best rates under threshold\n-            qr_fee_rate = Decimal('0.012')  # 1.2%\n+            qr_fee_rate = Decimal(\"0.012\")  # 1.2%\n             optimal_fees = total_volume * qr_fee_rate\n-            optimal_mix['qr_code'] = {\n-                'percentage': 100,\n-                'volume': float(total_volume),\n-                'fees': float(optimal_fees)\n+            optimal_mix[\"qr_code\"] = {\n+                \"percentage\": 100,\n+                \"volume\": float(total_volume),\n+                \"fees\": float(optimal_fees),\n             }\n-        \n+\n         potential_savings = current_total_fees - optimal_fees\n-        \n-        return {\n-            'potential_savings': float(potential_savings),\n-            'savings_percentage': float(potential_savings / current_total_fees * 100) if current_total_fees > 0 else 0,\n-            'optimal_mix': optimal_mix\n-        }\n-    \n+\n+        return {\n+            \"potential_savings\": float(potential_savings),\n+            \"savings_percentage\": (\n+                float(potential_savings / current_total_fees * 100)\n+                if current_total_fees > 0\n+                else 0\n+            ),\n+            \"optimal_mix\": optimal_mix,\n+        }\n+\n     async def _get_optimal_provider_recommendations(\n-        self, \n-        total_volume: Decimal, \n-        provider_stats: Dict\n+        self, total_volume: Decimal, provider_stats: Dict\n     ) -> List[Dict]:\n         \"\"\"Generate specific provider recommendations\"\"\"\n-        \n+\n         recommendations = []\n-        \n+\n         # Volume-based recommendations\n-        if total_volume >= Decimal('2714'):\n-            recommendations.append({\n-                'type': 'provider_switch',\n-                'priority': 'high',\n-                'title': 'Switch to SumUp for optimal rates',\n-                'description': f'Your monthly volume of \u00a3{total_volume:,.2f} qualifies for SumUp\\'s 0.69% + \u00a319/month plan',\n-                'estimated_savings': float((total_volume * Decimal('0.014') - (total_volume * Decimal('0.0069') + Decimal('19')))),\n-                'action': 'Configure SumUp integration'\n-            })\n-        elif total_volume >= Decimal('1000'):\n-            recommendations.append({\n-                'type': 'provider_optimization',\n-                'priority': 'medium',\n-                'title': 'Consider volume-based pricing',\n-                'description': f'At \u00a3{total_volume:,.2f}/month, you may benefit from negotiated rates',\n-                'action': 'Contact providers for volume discounts'\n-            })\n-        \n+        if total_volume >= Decimal(\"2714\"):\n+            recommendations.append(\n+                {\n+                    \"type\": \"provider_switch\",\n+                    \"priority\": \"high\",\n+                    \"title\": \"Switch to SumUp for optimal rates\",\n+                    \"description\": f\"Your monthly volume of \u00a3{total_volume:,.2f} qualifies for SumUp's 0.69% + \u00a319/month plan\",\n+                    \"estimated_savings\": float(\n+                        (\n+                            total_volume * Decimal(\"0.014\")\n+                            - (total_volume * Decimal(\"0.0069\") + Decimal(\"19\"))\n+                        )\n+                    ),\n+                    \"action\": \"Configure SumUp integration\",\n+                }\n+            )\n+        elif total_volume >= Decimal(\"1000\"):\n+            recommendations.append(\n+                {\n+                    \"type\": \"provider_optimization\",\n+                    \"priority\": \"medium\",\n+                    \"title\": \"Consider volume-based pricing\",\n+                    \"description\": f\"At \u00a3{total_volume:,.2f}/month, you may benefit from negotiated rates\",\n+                    \"action\": \"Contact providers for volume discounts\",\n+                }\n+            )\n+\n         # QR code recommendation\n-        qr_usage = provider_stats.get('qr_code', {}).get('transaction_count', 0)\n-        total_transactions = sum(stats.get('transaction_count', 0) for stats in provider_stats.values())\n-        \n+        qr_usage = provider_stats.get(\"qr_code\", {}).get(\"transaction_count\", 0)\n+        total_transactions = sum(\n+            stats.get(\"transaction_count\", 0) for stats in provider_stats.values()\n+        )\n+\n         if total_transactions > 0 and qr_usage / total_transactions < 0.3:\n-            recommendations.append({\n-                'type': 'payment_method',\n-                'priority': 'medium',\n-                'title': 'Promote QR code payments',\n-                'description': 'QR payments have lower fees (1.2%) and could reduce your costs',\n-                'action': 'Add QR payment incentives or training'\n-            })\n-        \n+            recommendations.append(\n+                {\n+                    \"type\": \"payment_method\",\n+                    \"priority\": \"medium\",\n+                    \"title\": \"Promote QR code payments\",\n+                    \"description\": \"QR payments have lower fees (1.2%) and could reduce your costs\",\n+                    \"action\": \"Add QR payment incentives or training\",\n+                }\n+            )\n+\n         return recommendations\n-    \n+\n     async def _calculate_optimal_provider_mix(self, total_volume: Decimal) -> Dict:\n         \"\"\"Calculate optimal provider distribution for given volume\"\"\"\n-        \n+\n         provider_breakdown = {}\n-        total_optimal_fees = Decimal('0')\n-        \n-        if total_volume >= Decimal('2714'):\n+        total_optimal_fees = Decimal(\"0\")\n+\n+        if total_volume >= Decimal(\"2714\"):\n             # High volume - use SumUp\n-            sumup_fees = (total_volume * Decimal('0.0069')) + Decimal('19')\n-            provider_breakdown['sumup'] = {\n-                'volume': total_volume,\n-                'fees': sumup_fees\n+            sumup_fees = (total_volume * Decimal(\"0.0069\")) + Decimal(\"19\")\n+            provider_breakdown[\"sumup\"] = {\"volume\": total_volume, \"fees\": sumup_fees}\n+            total_optimal_fees = sumup_fees\n+\n+        elif total_volume >= Decimal(\"1000\"):\n+            # Medium volume - mix of Stripe and QR\n+            qr_volume = total_volume * Decimal(\"0.7\")  # 70% QR\n+            stripe_volume = total_volume * Decimal(\"0.3\")  # 30% Stripe\n+\n+            qr_fees = qr_volume * Decimal(\"0.012\")  # 1.2%\n+            stripe_fees = (stripe_volume * Decimal(\"0.014\")) + (\n+                stripe_volume * Decimal(\"0.20\") / stripe_volume\n+            )  # 1.4% + 20p per transaction (approximated)\n+\n+            provider_breakdown[\"qr_code\"] = {\"volume\": qr_volume, \"fees\": qr_fees}\n+            provider_breakdown[\"stripe\"] = {\n+                \"volume\": stripe_volume,\n+                \"fees\": stripe_fees,\n             }\n-            total_optimal_fees = sumup_fees\n-            \n-        elif total_volume >= Decimal('1000'):\n-            # Medium volume - mix of Stripe and QR\n-            qr_volume = total_volume * Decimal('0.7')  # 70% QR\n-            stripe_volume = total_volume * Decimal('0.3')  # 30% Stripe\n-            \n-            qr_fees = qr_volume * Decimal('0.012')  # 1.2%\n-            stripe_fees = (stripe_volume * Decimal('0.014')) + (stripe_volume * Decimal('0.20') / stripe_volume)  # 1.4% + 20p per transaction (approximated)\n-            \n-            provider_breakdown['qr_code'] = {'volume': qr_volume, 'fees': qr_fees}\n-            provider_breakdown['stripe'] = {'volume': stripe_volume, 'fees': stripe_fees}\n             total_optimal_fees = qr_fees + stripe_fees\n-            \n+\n         else:\n             # Low volume - primarily QR code\n-            qr_fees = total_volume * Decimal('0.012')  # 1.2%\n-            provider_breakdown['qr_code'] = {\n-                'volume': total_volume,\n-                'fees': qr_fees\n-            }\n+            qr_fees = total_volume * Decimal(\"0.012\")  # 1.2%\n+            provider_breakdown[\"qr_code\"] = {\"volume\": total_volume, \"fees\": qr_fees}\n             total_optimal_fees = qr_fees\n-        \n-        return {\n-            'total_optimal_fees': total_optimal_fees,\n-            'provider_breakdown': provider_breakdown\n-        }\n-    \n+\n+        return {\n+            \"total_optimal_fees\": total_optimal_fees,\n+            \"provider_breakdown\": provider_breakdown,\n+        }\n+\n     async def _generate_optimization_recommendations(\n-        self, \n-        current_performance: Dict, \n-        optimal_breakdown: Dict, \n-        total_volume: Decimal\n+        self, current_performance: Dict, optimal_breakdown: Dict, total_volume: Decimal\n     ) -> List[Dict]:\n         \"\"\"Generate specific optimization recommendations\"\"\"\n-        \n+\n         recommendations = []\n-        current_fees = Decimal(str(current_performance['overall_metrics']['total_fees']))\n-        optimal_fees = optimal_breakdown['total_optimal_fees']\n-        \n+        current_fees = Decimal(\n+            str(current_performance[\"overall_metrics\"][\"total_fees\"])\n+        )\n+        optimal_fees = optimal_breakdown[\"total_optimal_fees\"]\n+\n         # High-impact recommendations\n-        if current_fees > optimal_fees * Decimal('1.2'):  # More than 20% above optimal\n-            recommendations.append({\n-                'impact': 'high',\n-                'category': 'provider_mix',\n-                'title': 'Optimize Provider Mix',\n-                'description': 'Your current provider mix is not cost-optimal for your volume',\n-                'savings': float(current_fees - optimal_fees),\n-                'action_items': [\n-                    'Review monthly transaction volume',\n-                    'Consider SumUp for high volume' if total_volume >= Decimal('2714') else 'Increase QR payment adoption',\n-                    'Renegotiate rates with current providers'\n-                ]\n-            })\n-        \n+        if current_fees > optimal_fees * Decimal(\"1.2\"):  # More than 20% above optimal\n+            recommendations.append(\n+                {\n+                    \"impact\": \"high\",\n+                    \"category\": \"provider_mix\",\n+                    \"title\": \"Optimize Provider Mix\",\n+                    \"description\": \"Your current provider mix is not cost-optimal for your volume\",\n+                    \"savings\": float(current_fees - optimal_fees),\n+                    \"action_items\": [\n+                        \"Review monthly transaction volume\",\n+                        (\n+                            \"Consider SumUp for high volume\"\n+                            if total_volume >= Decimal(\"2714\")\n+                            else \"Increase QR payment adoption\"\n+                        ),\n+                        \"Renegotiate rates with current providers\",\n+                    ],\n+                }\n+            )\n+\n         # Medium-impact recommendations\n-        if total_volume >= Decimal('1000'):\n-            recommendations.append({\n-                'impact': 'medium',\n-                'category': 'volume_discounts',\n-                'title': 'Negotiate Volume Discounts',\n-                'description': 'Your transaction volume qualifies for better rates',\n-                'action_items': [\n-                    'Contact Stripe for volume pricing',\n-                    'Explore Square\\'s volume discount tiers',\n-                    'Consider SumUp\\'s high-volume plan'\n-                ]\n-            })\n-        \n+        if total_volume >= Decimal(\"1000\"):\n+            recommendations.append(\n+                {\n+                    \"impact\": \"medium\",\n+                    \"category\": \"volume_discounts\",\n+                    \"title\": \"Negotiate Volume Discounts\",\n+                    \"description\": \"Your transaction volume qualifies for better rates\",\n+                    \"action_items\": [\n+                        \"Contact Stripe for volume pricing\",\n+                        \"Explore Square's volume discount tiers\",\n+                        \"Consider SumUp's high-volume plan\",\n+                    ],\n+                }\n+            )\n+\n         return recommendations\n-    \n+\n     async def _calculate_provider_health_score(\n-        self, \n-        provider: str, \n-        payments_7d: List[Payment], \n-        payments_30d: List[Payment]\n+        self, provider: str, payments_7d: List[Payment], payments_30d: List[Payment]\n     ) -> Dict:\n         \"\"\"Calculate comprehensive health score for a provider\"\"\"\n-        \n+\n         health_factors = {\n-            'success_rate': 0,\n-            'avg_processing_time': 0,\n-            'cost_efficiency': 0,\n-            'volume_trend': 0,\n-            'reliability': 0\n-        }\n-        \n+            \"success_rate\": 0,\n+            \"avg_processing_time\": 0,\n+            \"cost_efficiency\": 0,\n+            \"volume_trend\": 0,\n+            \"reliability\": 0,\n+        }\n+\n         if not payments_30d:\n-            return {\n-                'overall_score': 0,\n-                'factors': health_factors,\n-                'status': 'inactive'\n-            }\n-        \n+            return {\"overall_score\": 0, \"factors\": health_factors, \"status\": \"inactive\"}\n+\n         # Success rate (30%)\n-        completed_payments = [p for p in payments_30d if p.status == 'completed']\n-        success_rate = len(completed_payments) / len(payments_30d) if payments_30d else 0\n-        health_factors['success_rate'] = success_rate * 100\n-        \n+        completed_payments = [p for p in payments_30d if p.status == \"completed\"]\n+        success_rate = (\n+            len(completed_payments) / len(payments_30d) if payments_30d else 0\n+        )\n+        health_factors[\"success_rate\"] = success_rate * 100\n+\n         # Cost efficiency (25%) - lower fees = higher score\n         if completed_payments:\n-            avg_fee_rate = sum(Decimal(str(p.provider_fee or 0)) / Decimal(str(p.amount)) for p in completed_payments) / len(completed_payments)\n+            avg_fee_rate = sum(\n+                Decimal(str(p.provider_fee or 0)) / Decimal(str(p.amount))\n+                for p in completed_payments\n+            ) / len(completed_payments)\n             # Normalize to 0-100 scale (assuming max 3% fees)\n             cost_efficiency = max(0, (1 - float(avg_fee_rate)) * 100)\n-            health_factors['cost_efficiency'] = cost_efficiency\n-        \n+            health_factors[\"cost_efficiency\"] = cost_efficiency\n+\n         # Volume trend (20%) - comparing 7d vs 30d\n         volume_7d = len(payments_7d)\n         volume_30d = len(payments_30d)\n-        expected_7d = volume_30d * (7/30)  # Expected based on 30d average\n-        \n+        expected_7d = volume_30d * (7 / 30)  # Expected based on 30d average\n+\n         if expected_7d > 0:\n             trend_score = min(100, (volume_7d / expected_7d) * 100)\n-            health_factors['volume_trend'] = trend_score\n-        \n+            health_factors[\"volume_trend\"] = trend_score\n+\n         # Reliability (15%) - consistency of processing\n-        reliability_score = 100 - (len([p for p in payments_30d if p.status == 'failed']) / len(payments_30d) * 100)\n-        health_factors['reliability'] = reliability_score\n-        \n+        reliability_score = 100 - (\n+            len([p for p in payments_30d if p.status == \"failed\"])\n+            / len(payments_30d)\n+            * 100\n+        )\n+        health_factors[\"reliability\"] = reliability_score\n+\n         # Processing time (10%) - mock data for now\n-        health_factors['avg_processing_time'] = 85  # Mock score\n-        \n+        health_factors[\"avg_processing_time\"] = 85  # Mock score\n+\n         # Calculate weighted overall score\n         weights = {\n-            'success_rate': 0.30,\n-            'cost_efficiency': 0.25,\n-            'volume_trend': 0.20,\n-            'reliability': 0.15,\n-            'avg_processing_time': 0.10\n-        }\n-        \n+            \"success_rate\": 0.30,\n+            \"cost_efficiency\": 0.25,\n+            \"volume_trend\": 0.20,\n+            \"reliability\": 0.15,\n+            \"avg_processing_time\": 0.10,\n+        }\n+\n         overall_score = sum(\n-            health_factors[factor] * weight \n-            for factor, weight in weights.items()\n-        )\n-        \n+            health_factors[factor] * weight for factor, weight in weights.items()\n+        )\n+\n         # Determine status\n         if overall_score >= 80:\n-            status = 'excellent'\n+            status = \"excellent\"\n         elif overall_score >= 60:\n-            status = 'good'\n+            status = \"good\"\n         elif overall_score >= 40:\n-            status = 'needs_attention'\n+            status = \"needs_attention\"\n         else:\n-            status = 'poor'\n-        \n-        return {\n-            'overall_score': round(overall_score, 2),\n-            'factors': {k: round(v, 2) for k, v in health_factors.items()},\n-            'status': status\n-        }\n-    \n+            status = \"poor\"\n+\n+        return {\n+            \"overall_score\": round(overall_score, 2),\n+            \"factors\": {k: round(v, 2) for k, v in health_factors.items()},\n+            \"status\": status,\n+        }\n+\n     def _calculate_growth_metrics(self, trend_data: List[Dict]) -> Dict:\n         \"\"\"Calculate growth rates and trends\"\"\"\n-        \n+\n         if len(trend_data) < 2:\n-            return {'volume_growth': 0, 'transaction_growth': 0, 'trend': 'insufficient_data'}\n-        \n+            return {\n+                \"volume_growth\": 0,\n+                \"transaction_growth\": 0,\n+                \"trend\": \"insufficient_data\",\n+            }\n+\n         # Compare first and last periods\n         first_period = trend_data[0]\n         last_period = trend_data[-1]\n-        \n+\n         volume_growth = 0\n         transaction_growth = 0\n-        \n-        if first_period['total_volume'] > 0:\n-            volume_growth = ((last_period['total_volume'] - first_period['total_volume']) / first_period['total_volume']) * 100\n-        \n-        if first_period['total_transactions'] > 0:\n-            transaction_growth = ((last_period['total_transactions'] - first_period['total_transactions']) / first_period['total_transactions']) * 100\n-        \n+\n+        if first_period[\"total_volume\"] > 0:\n+            volume_growth = (\n+                (last_period[\"total_volume\"] - first_period[\"total_volume\"])\n+                / first_period[\"total_volume\"]\n+            ) * 100\n+\n+        if first_period[\"total_transactions\"] > 0:\n+            transaction_growth = (\n+                (last_period[\"total_transactions\"] - first_period[\"total_transactions\"])\n+                / first_period[\"total_transactions\"]\n+            ) * 100\n+\n         # Determine overall trend\n         if volume_growth > 10:\n-            trend = 'strong_growth'\n+            trend = \"strong_growth\"\n         elif volume_growth > 0:\n-            trend = 'growth'\n+            trend = \"growth\"\n         elif volume_growth > -10:\n-            trend = 'stable'\n+            trend = \"stable\"\n         else:\n-            trend = 'declining'\n-        \n-        return {\n-            'volume_growth': round(volume_growth, 2),\n-            'transaction_growth': round(transaction_growth, 2),\n-            'trend': trend,\n-            'period_count': len(trend_data)\n-        }\n\\ No newline at end of file\n+            trend = \"declining\"\n+\n+        return {\n+            \"volume_growth\": round(volume_growth, 2),\n+            \"transaction_growth\": round(transaction_growth, 2),\n+            \"trend\": trend,\n+            \"period_count\": len(trend_data),\n+        }\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/employee_service.py\t2025-08-02 22:07:52.524543+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/employee_service.py\t2025-08-02 22:36:04.010023+00:00\n@@ -7,214 +7,267 @@\n from datetime import datetime, date, time, timedelta\n from decimal import Decimal\n from sqlalchemy.orm import Session\n from sqlalchemy import and_, or_, func, desc\n from app.core.database import User, UserRestaurant\n-from app.models.employee import EmployeeProfile, Schedule, Shift, TimeEntry, PerformanceMetric\n+from app.models.employee import (\n+    EmployeeProfile,\n+    Schedule,\n+    Shift,\n+    TimeEntry,\n+    PerformanceMetric,\n+)\n from app.core.database import Restaurant\n from app.schemas.employee_schemas import (\n-    EmployeeCreateRequest, EmployeeUpdateRequest, EmployeeResponse,\n-    ScheduleCreateRequest, ScheduleUpdateRequest, ScheduleResponse,\n-    ShiftResponse, PerformanceMetricResponse, EmployeeSummary,\n-    WeeklyScheduleResponse, WeeklyScheduleDay\n+    EmployeeCreateRequest,\n+    EmployeeUpdateRequest,\n+    EmployeeResponse,\n+    ScheduleCreateRequest,\n+    ScheduleUpdateRequest,\n+    ScheduleResponse,\n+    ShiftResponse,\n+    PerformanceMetricResponse,\n+    EmployeeSummary,\n+    WeeklyScheduleResponse,\n+    WeeklyScheduleDay,\n )\n-from app.core.exceptions import ValidationException, AuthenticationException, FynloException, ResourceNotFoundException, ConflictException\n+from app.core.exceptions import (\n+    ValidationException,\n+    AuthenticationException,\n+    FynloException,\n+    ResourceNotFoundException,\n+    ConflictException,\n+)\n from app.core.security import get_password_hash\n from app.core.tenant_security import TenantSecurity\n import logging\n \n logger = logging.getLogger(__name__)\n+\n \n class EmployeeService:\n     \"\"\"Service class for employee management operations\"\"\"\n \n     async def get_employees(\n         self,\n         db: Session,\n         restaurant_id: Optional[int] = None,\n         role: Optional[str] = None,\n         active: Optional[bool] = True,\n-        current_user: User = None\n+        current_user: User = None,\n     ) -> List[EmployeeResponse]:\n         \"\"\"Get employees with optional filtering\"\"\"\n         try:\n             # If specific restaurant_id provided, validate access to it\n             if restaurant_id:\n                 await TenantSecurity.validate_restaurant_access(\n                     user=current_user,\n                     restaurant_id=str(restaurant_id),\n                     operation=\"access\",\n                     resource_type=\"employees\",\n-                    db=db\n+                    db=db,\n                 )\n                 # Query for specific restaurant\n                 query = db.query(EmployeeProfile).filter(\n                     EmployeeProfile.restaurant_id == restaurant_id\n                 )\n             else:\n                 # Get all accessible restaurants for the user\n-                accessible_restaurants = TenantSecurity.get_accessible_restaurant_ids(current_user, db)\n-                \n+                accessible_restaurants = TenantSecurity.get_accessible_restaurant_ids(\n+                    current_user, db\n+                )\n+\n                 if not accessible_restaurants:\n                     # No restaurant access\n-                    raise FynloException(\"User must be assigned to a restaurant\", status_code=400)\n-                \n+                    raise FynloException(\n+                        \"User must be assigned to a restaurant\", status_code=400\n+                    )\n+\n                 # Apply tenant filter for all accessible restaurants\n                 query = TenantSecurity.apply_tenant_filter(\n                     query=db.query(EmployeeProfile),\n                     user=current_user,\n                     model_class=EmployeeProfile,\n                     restaurant_field=\"restaurant_id\",\n-                    db=db\n-                )\n-            \n+                    db=db,\n+                )\n+\n             # Apply role filter\n             if role:\n                 query = query.filter(EmployeeProfile.role == role)\n-            \n+\n             # Apply active status filter\n             if active is not None:\n                 query = query.filter(EmployeeProfile.is_active == active)\n-            \n-            employees = query.order_by(EmployeeProfile.last_name, EmployeeProfile.first_name).all()\n-            \n+\n+            employees = query.order_by(\n+                EmployeeProfile.last_name, EmployeeProfile.first_name\n+            ).all()\n+\n             return [EmployeeResponse.from_orm(emp) for emp in employees]\n-            \n+\n         except FynloException:\n             raise\n         except Exception as e:\n             logger.error(f\"Error retrieving employees: {str(e)}\")\n             raise FynloException(f\"Failed to retrieve employees: {str(e)}\")\n \n     async def get_employee_by_id(\n-        self,\n-        db: Session,\n-        employee_id: int,\n-        current_user: User = None\n+        self, db: Session, employee_id: int, current_user: User = None\n     ) -> Optional[EmployeeResponse]:\n         \"\"\"Get specific employee by ID\"\"\"\n         try:\n-            employee = db.query(EmployeeProfile).filter(\n-                EmployeeProfile.id == employee_id\n-            ).first()\n-            \n+            employee = (\n+                db.query(EmployeeProfile)\n+                .filter(EmployeeProfile.id == employee_id)\n+                .first()\n+            )\n+\n             if not employee:\n                 return None\n-            \n+\n             # Validate tenant access using TenantSecurity\n             await TenantSecurity.validate_restaurant_access(\n                 user=current_user,\n                 restaurant_id=str(employee.restaurant_id),\n                 operation=\"access\",\n                 resource_type=\"employee\",\n                 resource_id=str(employee_id),\n-                db=db\n-            )\n-            \n+                db=db,\n+            )\n+\n             return EmployeeResponse.from_orm(employee)\n-            \n+\n         except FynloException:\n             raise\n         except Exception as e:\n             logger.error(f\"Error retrieving employee {employee_id}: {str(e)}\")\n             raise FynloException(f\"Failed to retrieve employee: {str(e)}\")\n \n     async def create_employee(\n         self,\n         db: Session,\n         employee_data: EmployeeCreateRequest,\n-        current_user: User = None\n+        current_user: User = None,\n     ) -> EmployeeResponse:\n         \"\"\"Create new employee\"\"\"\n         try:\n             # Determine target restaurant\n             # If restaurant_id is provided in the request, validate access to it\n             # Otherwise use the user's current restaurant\n             target_restaurant_id = employee_data.restaurant_id\n-            \n+\n             if not target_restaurant_id and current_user:\n-                target_restaurant_id = current_user.current_restaurant_id or current_user.restaurant_id\n-                \n+                target_restaurant_id = (\n+                    current_user.current_restaurant_id or current_user.restaurant_id\n+                )\n+\n             if not target_restaurant_id:\n                 raise FynloException(\"Restaurant ID must be specified\", status_code=400)\n-            \n+\n             # Validate access to the target restaurant\n             await TenantSecurity.validate_restaurant_access(\n                 user=current_user,\n                 restaurant_id=str(target_restaurant_id),\n                 operation=\"modify\",\n                 resource_type=\"employees\",\n-                db=db\n-            )\n-            \n+                db=db,\n+            )\n+\n             # Verify restaurant exists\n-            restaurant = db.query(Restaurant).filter(\n-                Restaurant.id == target_restaurant_id\n-            ).first()\n+            restaurant = (\n+                db.query(Restaurant)\n+                .filter(Restaurant.id == target_restaurant_id)\n+                .first()\n+            )\n             if not restaurant:\n                 raise ValueError(\"Restaurant not found\")\n-            \n+\n             # Check if email already exists for this restaurant\n-            existing_employee = db.query(EmployeeProfile).filter(\n-                and_(\n-                    EmployeeProfile.email == employee_data.email,\n-                    EmployeeProfile.restaurant_id == target_restaurant_id\n-                )\n-            ).first()\n+            existing_employee = (\n+                db.query(EmployeeProfile)\n+                .filter(\n+                    and_(\n+                        EmployeeProfile.email == employee_data.email,\n+                        EmployeeProfile.restaurant_id == target_restaurant_id,\n+                    )\n+                )\n+                .first()\n+            )\n             if existing_employee:\n-                raise ValueError(\"Employee with this email already exists in this restaurant\")\n-            \n+                raise ValueError(\n+                    \"Employee with this email already exists in this restaurant\"\n+                )\n+\n             # Create User record first\n             user_data = {\n-                'email': employee_data.email,\n-                'first_name': employee_data.first_name,\n-                'last_name': employee_data.last_name,\n-                'role': 'employee',\n-                'is_active': employee_data.is_active,\n-                'password_hash': get_password_hash('temp_password_123'),  # Temporary password\n-                'restaurant_id': target_restaurant_id,\n-                'current_restaurant_id': target_restaurant_id\n+                \"email\": employee_data.email,\n+                \"first_name\": employee_data.first_name,\n+                \"last_name\": employee_data.last_name,\n+                \"role\": \"employee\",\n+                \"is_active\": employee_data.is_active,\n+                \"password_hash\": get_password_hash(\n+                    \"temp_password_123\"\n+                ),  # Temporary password\n+                \"restaurant_id\": target_restaurant_id,\n+                \"current_restaurant_id\": target_restaurant_id,\n             }\n-            \n+\n             new_user = User(**user_data)\n             db.add(new_user)\n             db.flush()  # Get the user ID\n-            \n+\n             # Create UserRestaurant entry to assign employee to restaurant\n             user_restaurant = UserRestaurant(\n                 user_id=new_user.id,\n                 restaurant_id=target_restaurant_id,\n-                role='employee',\n+                role=\"employee\",\n                 is_primary=True,\n-                assigned_by=current_user.id if current_user else None\n+                assigned_by=current_user.id if current_user else None,\n             )\n             db.add(user_restaurant)\n-            \n+\n             # Create EmployeeProfile\n             employee_profile_data = {\n-                'user_id': new_user.id,\n-                'restaurant_id': target_restaurant_id,\n-                'employment_type': employee_data.employment_status,\n-                'hourly_rate': employee_data.hourly_rate,\n-                'hire_date': employee_data.hire_date or date.today(),\n-                'phone': employee_data.phone,\n-                'is_active': employee_data.is_active,\n-                'emergency_contact': {\n-                    'name': employee_data.emergency_contact_name,\n-                    'phone': employee_data.emergency_contact_phone\n-                } if employee_data.emergency_contact_name else {},\n-                'notes': [{'date': datetime.utcnow().isoformat(), 'note': employee_data.notes, 'author_id': str(current_user.id)}] if employee_data.notes else [],\n-                'max_hours_per_week': employee_data.weekly_hours if employee_data.weekly_hours else 40\n+                \"user_id\": new_user.id,\n+                \"restaurant_id\": target_restaurant_id,\n+                \"employment_type\": employee_data.employment_status,\n+                \"hourly_rate\": employee_data.hourly_rate,\n+                \"hire_date\": employee_data.hire_date or date.today(),\n+                \"phone\": employee_data.phone,\n+                \"is_active\": employee_data.is_active,\n+                \"emergency_contact\": (\n+                    {\n+                        \"name\": employee_data.emergency_contact_name,\n+                        \"phone\": employee_data.emergency_contact_phone,\n+                    }\n+                    if employee_data.emergency_contact_name\n+                    else {}\n+                ),\n+                \"notes\": (\n+                    [\n+                        {\n+                            \"date\": datetime.utcnow().isoformat(),\n+                            \"note\": employee_data.notes,\n+                            \"author_id\": str(current_user.id),\n+                        }\n+                    ]\n+                    if employee_data.notes\n+                    else []\n+                ),\n+                \"max_hours_per_week\": (\n+                    employee_data.weekly_hours if employee_data.weekly_hours else 40\n+                ),\n             }\n-            \n+\n             new_employee = EmployeeProfile(**employee_profile_data)\n             db.add(new_employee)\n             db.commit()\n-            \n+\n             logger.info(f\"Created new employee: {new_employee.email}\")\n             return EmployeeResponse.from_orm(new_employee)\n-            \n+\n         except ValueError as e:\n             db.rollback()\n             raise e\n         except FynloException:\n             db.rollback()\n@@ -227,90 +280,91 @@\n     async def update_employee(\n         self,\n         db: Session,\n         employee_id: int,\n         employee_data: EmployeeUpdateRequest,\n-        current_user: User = None\n+        current_user: User = None,\n     ) -> Optional[EmployeeResponse]:\n         \"\"\"Update employee information\"\"\"\n         try:\n-            employee = db.query(EmployeeProfile).filter(\n-                EmployeeProfile.id == employee_id\n-            ).first()\n-            \n+            employee = (\n+                db.query(EmployeeProfile)\n+                .filter(EmployeeProfile.id == employee_id)\n+                .first()\n+            )\n+\n             if not employee:\n                 return None\n-            \n+\n             # Validate tenant access using TenantSecurity\n             await TenantSecurity.validate_restaurant_access(\n                 user=current_user,\n                 restaurant_id=str(employee.restaurant_id),\n                 operation=\"modify\",\n                 resource_type=\"employee\",\n                 resource_id=str(employee_id),\n-                db=db\n-            )\n-            \n+                db=db,\n+            )\n+\n             # Update fields if provided\n             update_data = employee_data.dict(exclude_unset=True)\n             for field, value in update_data.items():\n                 if hasattr(employee, field):\n                     setattr(employee, field, value)\n-            \n+\n             employee.updated_at = datetime.utcnow()\n             db.commit()\n-            \n+\n             logger.info(f\"Updated employee: {employee.email}\")\n             return EmployeeResponse.from_orm(employee)\n-            \n+\n         except FynloException:\n             db.rollback()\n             raise\n         except Exception as e:\n             db.rollback()\n             logger.error(f\"Error updating employee {employee_id}: {str(e)}\")\n             raise FynloException(f\"Failed to update employee: {str(e)}\")\n \n     async def delete_employee(\n-        self,\n-        db: Session,\n-        employee_id: int,\n-        current_user: User = None\n+        self, db: Session, employee_id: int, current_user: User = None\n     ) -> bool:\n         \"\"\"Delete employee (soft delete - marks as inactive)\"\"\"\n         try:\n-            employee = db.query(EmployeeProfile).filter(\n-                EmployeeProfile.id == employee_id\n-            ).first()\n-            \n+            employee = (\n+                db.query(EmployeeProfile)\n+                .filter(EmployeeProfile.id == employee_id)\n+                .first()\n+            )\n+\n             if not employee:\n                 return False\n-            \n+\n             # Validate tenant access using TenantSecurity\n             await TenantSecurity.validate_restaurant_access(\n                 user=current_user,\n                 restaurant_id=str(employee.restaurant_id),\n                 operation=\"delete\",\n                 resource_type=\"employee\",\n                 resource_id=str(employee_id),\n-                db=db\n-            )\n-            \n+                db=db,\n+            )\n+\n             # Soft delete - mark as inactive\n             employee.is_active = False\n             employee.updated_at = datetime.utcnow()\n-            \n+\n             # Also deactivate the User record\n             user = db.query(User).filter(User.id == employee.user_id).first()\n             if user:\n                 user.is_active = False\n-            \n+\n             db.commit()\n-            \n+\n             logger.info(f\"Deactivated employee: {employee.email}\")\n             return True\n-            \n+\n         except FynloException:\n             db.rollback()\n             raise\n         except Exception as e:\n             db.rollback()\n@@ -323,80 +377,88 @@\n         self,\n         db: Session,\n         employee_id: int,\n         start_date: Optional[date] = None,\n         end_date: Optional[date] = None,\n-        current_user: User = None\n+        current_user: User = None,\n     ) -> List[ScheduleResponse]:\n         \"\"\"Get employee schedules with optional date filtering\"\"\"\n         try:\n             # Verify employee exists and user has access\n             employee = await self.get_employee_by_id(db, employee_id, current_user)\n             if not employee:\n                 raise FynloException(\"Employee not found\", status_code=404)\n-            \n+\n             query = db.query(Schedule).filter(Schedule.employee_id == employee_id)\n-            \n+\n             if start_date:\n                 query = query.filter(Schedule.effective_date >= start_date)\n             if end_date:\n                 query = query.filter(Schedule.effective_date <= end_date)\n-            \n+\n             schedules = query.order_by(Schedule.day_of_week, Schedule.start_time).all()\n-            \n+\n             return [ScheduleResponse.from_orm(schedule) for schedule in schedules]\n-            \n-        except FynloException:\n-            raise\n-        except Exception as e:\n-            logger.error(f\"Error retrieving schedules for employee {employee_id}: {str(e)}\")\n+\n+        except FynloException:\n+            raise\n+        except Exception as e:\n+            logger.error(\n+                f\"Error retrieving schedules for employee {employee_id}: {str(e)}\"\n+            )\n             raise FynloException(f\"Failed to retrieve schedules: {str(e)}\")\n \n     async def create_schedule(\n         self,\n         db: Session,\n         employee_id: int,\n         schedule_data: ScheduleCreateRequest,\n-        current_user: User = None\n+        current_user: User = None,\n     ) -> ScheduleResponse:\n         \"\"\"Create new schedule for employee\"\"\"\n         try:\n             # Verify employee exists and user has access\n             employee = await self.get_employee_by_id(db, employee_id, current_user)\n             if not employee:\n                 raise FynloException(\"Employee not found\", status_code=404)\n-            \n+\n             # Check for conflicts if recurring\n             if schedule_data.is_recurring:\n-                existing = db.query(Schedule).filter(\n-                    and_(\n-                        Schedule.employee_id == employee_id,\n-                        Schedule.day_of_week == schedule_data.day_of_week,\n-                        Schedule.is_recurring == True,\n-                        Schedule.effective_date <= schedule_data.effective_date\n-                    )\n-                ).first()\n-                \n+                existing = (\n+                    db.query(Schedule)\n+                    .filter(\n+                        and_(\n+                            Schedule.employee_id == employee_id,\n+                            Schedule.day_of_week == schedule_data.day_of_week,\n+                            Schedule.is_recurring == True,\n+                            Schedule.effective_date <= schedule_data.effective_date,\n+                        )\n+                    )\n+                    .first()\n+                )\n+\n                 if existing:\n-                    raise ValueError(f\"Recurring schedule already exists for this day of week\")\n-            \n+                    raise ValueError(\n+                        f\"Recurring schedule already exists for this day of week\"\n+                    )\n+\n             new_schedule = Schedule(\n                 employee_id=employee_id,\n                 day_of_week=schedule_data.day_of_week,\n                 start_time=schedule_data.start_time,\n                 end_time=schedule_data.end_time,\n                 is_recurring=schedule_data.is_recurring,\n                 effective_date=schedule_data.effective_date,\n-                notes=schedule_data.notes\n-            )\n-            \n+                notes=schedule_data.notes,\n+            )\n+\n             db.add(new_schedule)\n             db.commit()\n-            \n+\n             logger.info(f\"Created schedule for employee {employee_id}\")\n             return ScheduleResponse.from_orm(new_schedule)\n-            \n+\n         except ValueError as e:\n             db.rollback()\n             raise e\n         except FynloException:\n             db.rollback()\n@@ -405,65 +467,66 @@\n             db.rollback()\n             logger.error(f\"Error creating schedule: {str(e)}\")\n             raise FynloException(f\"Failed to create schedule: {str(e)}\")\n \n     async def clock_in(\n-        self,\n-        db: Session,\n-        employee_id: int,\n-        current_user: User = None\n+        self, db: Session, employee_id: int, current_user: User = None\n     ) -> ShiftResponse:\n         \"\"\"Clock in employee for their shift\"\"\"\n         try:\n             # Verify employee exists and user has access\n             employee = await self.get_employee_by_id(db, employee_id, current_user)\n             if not employee:\n                 raise FynloException(\"Employee not found\", status_code=404)\n-            \n+\n             # Check if already clocked in\n-            existing_shift = db.query(Shift).filter(\n-                and_(\n-                    Shift.employee_id == employee_id,\n-                    Shift.actual_start.isnot(None),\n-                    Shift.actual_end.is_(None)\n-                )\n-            ).first()\n-            \n+            existing_shift = (\n+                db.query(Shift)\n+                .filter(\n+                    and_(\n+                        Shift.employee_id == employee_id,\n+                        Shift.actual_start.isnot(None),\n+                        Shift.actual_end.is_(None),\n+                    )\n+                )\n+                .first()\n+            )\n+\n             if existing_shift:\n                 raise ValueError(\"Employee is already clocked in\")\n-            \n+\n             # Get employee to access restaurant_id\n-            employee_profile = db.query(EmployeeProfile).filter(\n-                EmployeeProfile.id == employee_id\n-            ).first()\n-            \n+            employee_profile = (\n+                db.query(EmployeeProfile)\n+                .filter(EmployeeProfile.id == employee_id)\n+                .first()\n+            )\n+\n             # Create new shift\n             now = datetime.utcnow()\n             new_shift = Shift(\n                 employee_id=employee_id,\n                 restaurant_id=employee_profile.restaurant_id,\n                 scheduled_start=now,  # Will be updated based on schedule\n                 scheduled_end=now + timedelta(hours=8),  # Default 8-hour shift\n                 actual_start=now,\n-                status='in_progress'\n-            )\n-            \n+                status=\"in_progress\",\n+            )\n+\n             db.add(new_shift)\n-            \n+\n             # Create time entry\n             time_entry = TimeEntry(\n-                employee_id=employee_id,\n-                entry_type='clock_in',\n-                timestamp=now\n+                employee_id=employee_id, entry_type=\"clock_in\", timestamp=now\n             )\n             db.add(time_entry)\n-            \n+\n             db.commit()\n-            \n+\n             logger.info(f\"Employee {employee_id} clocked in\")\n             return ShiftResponse.from_orm(new_shift)\n-            \n+\n         except ValueError as e:\n             db.rollback()\n             raise e\n         except FynloException:\n             db.rollback()\n@@ -472,374 +535,426 @@\n             db.rollback()\n             logger.error(f\"Error clocking in employee {employee_id}: {str(e)}\")\n             raise FynloException(f\"Failed to clock in: {str(e)}\")\n \n     async def clock_out(\n-        self,\n-        db: Session,\n-        employee_id: int,\n-        current_user: User = None\n+        self, db: Session, employee_id: int, current_user: User = None\n     ) -> ShiftResponse:\n         \"\"\"Clock out employee from their shift\"\"\"\n         try:\n             # Verify employee exists and user has access\n             employee = await self.get_employee_by_id(db, employee_id, current_user)\n             if not employee:\n                 raise FynloException(\"Employee not found\", status_code=404)\n-                \n+\n             # Find active shift\n-            active_shift = db.query(Shift).filter(\n-                and_(\n-                    Shift.employee_id == employee_id,\n-                    Shift.actual_start.isnot(None),\n-                    Shift.actual_end.is_(None)\n-                )\n-            ).first()\n-            \n+            active_shift = (\n+                db.query(Shift)\n+                .filter(\n+                    and_(\n+                        Shift.employee_id == employee_id,\n+                        Shift.actual_start.isnot(None),\n+                        Shift.actual_end.is_(None),\n+                    )\n+                )\n+                .first()\n+            )\n+\n             if not active_shift:\n                 raise ValueError(\"Employee is not currently clocked in\")\n-            \n+\n             # Update shift\n             now = datetime.utcnow()\n             active_shift.actual_end = now\n-            active_shift.status = 'completed'\n-            \n+            active_shift.status = \"completed\"\n+\n             # Create time entry\n             time_entry = TimeEntry(\n                 employee_id=employee_id,\n                 shift_id=active_shift.id,\n-                entry_type='clock_out',\n-                timestamp=now\n+                entry_type=\"clock_out\",\n+                timestamp=now,\n             )\n             db.add(time_entry)\n-            \n+\n             db.commit()\n-            \n+\n             logger.info(f\"Employee {employee_id} clocked out\")\n             return ShiftResponse.from_orm(active_shift)\n-            \n+\n         except ValueError as e:\n             db.rollback()\n             raise e\n         except Exception as e:\n             db.rollback()\n             logger.error(f\"Error clocking out employee {employee_id}: {str(e)}\")\n             raise FynloException(f\"Failed to clock out: {str(e)}\")\n \n     async def get_restaurant_employee_summary(\n-        self,\n-        db: Session,\n-        restaurant_id: int,\n-        current_user: User = None\n+        self, db: Session, restaurant_id: int, current_user: User = None\n     ) -> EmployeeSummary:\n         \"\"\"Get employee summary for restaurant dashboard\"\"\"\n         try:\n             # Validate tenant access using TenantSecurity\n             await TenantSecurity.validate_restaurant_access(\n                 user=current_user,\n                 restaurant_id=str(restaurant_id),\n                 operation=\"access\",\n                 resource_type=\"employee_summary\",\n-                db=db\n-            )\n-            \n+                db=db,\n+            )\n+\n             # Get accessible restaurants for the user\n-            accessible_restaurants = TenantSecurity.get_accessible_restaurant_ids(current_user, db)\n-            \n+            accessible_restaurants = TenantSecurity.get_accessible_restaurant_ids(\n+                current_user, db\n+            )\n+\n             # If specific restaurant requested, use only that one (after validation)\n             if restaurant_id in accessible_restaurants:\n                 restaurant_ids = [restaurant_id]\n             else:\n                 # Use all accessible restaurants\n                 restaurant_ids = accessible_restaurants\n-            \n+\n             # Get basic counts\n-            total_employees = db.query(EmployeeProfile).filter(\n-                EmployeeProfile.restaurant_id.in_(restaurant_ids)\n-            ).count()\n-            \n-            active_employees = db.query(EmployeeProfile).filter(\n-                and_(\n-                    EmployeeProfile.restaurant_id.in_(restaurant_ids),\n-                    EmployeeProfile.is_active == True\n-                )\n-            ).count()\n-            \n+            total_employees = (\n+                db.query(EmployeeProfile)\n+                .filter(EmployeeProfile.restaurant_id.in_(restaurant_ids))\n+                .count()\n+            )\n+\n+            active_employees = (\n+                db.query(EmployeeProfile)\n+                .filter(\n+                    and_(\n+                        EmployeeProfile.restaurant_id.in_(restaurant_ids),\n+                        EmployeeProfile.is_active == True,\n+                    )\n+                )\n+                .count()\n+            )\n+\n             # Get currently clocked in count\n-            clocked_in_now = db.query(Shift).join(EmployeeProfile).filter(\n-                and_(\n-                    EmployeeProfile.restaurant_id.in_(restaurant_ids),\n-                    Shift.actual_start.isnot(None),\n-                    Shift.actual_end.is_(None)\n-                )\n-            ).count()\n-            \n+            clocked_in_now = (\n+                db.query(Shift)\n+                .join(EmployeeProfile)\n+                .filter(\n+                    and_(\n+                        EmployeeProfile.restaurant_id.in_(restaurant_ids),\n+                        Shift.actual_start.isnot(None),\n+                        Shift.actual_end.is_(None),\n+                    )\n+                )\n+                .count()\n+            )\n+\n             # Get roles breakdown\n-            roles_query = db.query(\n-                EmployeeProfile.role,\n-                func.count(EmployeeProfile.id).label('count')\n-            ).filter(\n-                and_(\n-                    EmployeeProfile.restaurant_id.in_(restaurant_ids),\n-                    EmployeeProfile.is_active == True\n-                )\n-            ).group_by(EmployeeProfile.role).all()\n-            \n+            roles_query = (\n+                db.query(\n+                    EmployeeProfile.role, func.count(EmployeeProfile.id).label(\"count\")\n+                )\n+                .filter(\n+                    and_(\n+                        EmployeeProfile.restaurant_id.in_(restaurant_ids),\n+                        EmployeeProfile.is_active == True,\n+                    )\n+                )\n+                .group_by(EmployeeProfile.role)\n+                .all()\n+            )\n+\n             roles_breakdown = {role: count for role, count in roles_query}\n-            \n+\n             # Get employment type breakdown\n-            status_query = db.query(\n-                EmployeeProfile.employment_type,\n-                func.count(EmployeeProfile.id).label('count')\n-            ).filter(\n-                and_(\n-                    EmployeeProfile.restaurant_id.in_(restaurant_ids),\n-                    EmployeeProfile.is_active == True\n-                )\n-            ).group_by(EmployeeProfile.employment_type).all()\n-            \n-            employment_status_breakdown = {status: count for status, count in status_query}\n-            \n+            status_query = (\n+                db.query(\n+                    EmployeeProfile.employment_type,\n+                    func.count(EmployeeProfile.id).label(\"count\"),\n+                )\n+                .filter(\n+                    and_(\n+                        EmployeeProfile.restaurant_id.in_(restaurant_ids),\n+                        EmployeeProfile.is_active == True,\n+                    )\n+                )\n+                .group_by(EmployeeProfile.employment_type)\n+                .all()\n+            )\n+\n+            employment_status_breakdown = {\n+                status: count for status, count in status_query\n+            }\n+\n             return EmployeeSummary(\n                 total_employees=total_employees,\n                 active_employees=active_employees,\n                 clocked_in_now=clocked_in_now,\n-                scheduled_today=0,                  roles_breakdown=roles_breakdown,\n-                employment_status_breakdown=employment_status_breakdown\n-            )\n-            \n-        except FynloException:\n-            raise\n-        except Exception as e:\n-            logger.error(f\"Error getting employee summary for restaurant {restaurant_id}: {str(e)}\")\n+                scheduled_today=0,\n+                roles_breakdown=roles_breakdown,\n+                employment_status_breakdown=employment_status_breakdown,\n+            )\n+\n+        except FynloException:\n+            raise\n+        except Exception as e:\n+            logger.error(\n+                f\"Error getting employee summary for restaurant {restaurant_id}: {str(e)}\"\n+            )\n             raise FynloException(f\"Failed to get employee summary: {str(e)}\")\n \n     async def get_weekly_schedule(\n         self,\n         db: Session,\n         restaurant_id: int,\n         week_start: Optional[date] = None,\n-        current_user: User = None\n+        current_user: User = None,\n     ) -> WeeklyScheduleResponse:\n         \"\"\"Get weekly schedule for all restaurant employees\"\"\"\n         try:\n             # Validate tenant access using TenantSecurity\n             await TenantSecurity.validate_restaurant_access(\n                 user=current_user,\n                 restaurant_id=str(restaurant_id),\n                 operation=\"access\",\n                 resource_type=\"weekly_schedule\",\n-                db=db\n-            )\n-            \n+                db=db,\n+            )\n+\n             if not week_start:\n                 # Default to current week (Monday as start)\n                 today = date.today()\n                 week_start = today - timedelta(days=today.weekday())\n-            \n+\n             week_end = week_start + timedelta(days=6)\n-            \n+\n             # Get all employees for the restaurant\n-            employees = db.query(EmployeeProfile).filter(\n-                and_(\n-                    EmployeeProfile.restaurant_id == restaurant_id,\n-                    EmployeeProfile.is_active == True\n-                )\n-            ).all()\n-            \n+            employees = (\n+                db.query(EmployeeProfile)\n+                .filter(\n+                    and_(\n+                        EmployeeProfile.restaurant_id == restaurant_id,\n+                        EmployeeProfile.is_active == True,\n+                    )\n+                )\n+                .all()\n+            )\n+\n             # Build weekly schedule\n             days = []\n             total_week_hours = 0.0\n-            \n+\n             for i in range(7):  # 7 days of the week\n                 current_date = week_start + timedelta(days=i)\n-                day_name = current_date.strftime('%A')\n-                \n+                day_name = current_date.strftime(\"%A\")\n+\n                 # Get schedules for this day\n                 day_employees = []\n                 day_hours = 0.0\n-                \n+\n                 for employee in employees:\n-                    schedules = db.query(Schedule).filter(\n-                        and_(\n-                            Schedule.employee_id == employee.id,\n-                            Schedule.day_of_week == i,  # 0=Monday\n-                            Schedule.effective_date <= current_date\n+                    schedules = (\n+                        db.query(Schedule)\n+                        .filter(\n+                            and_(\n+                                Schedule.employee_id == employee.id,\n+                                Schedule.day_of_week == i,  # 0=Monday\n+                                Schedule.effective_date <= current_date,\n+                            )\n                         )\n-                    ).order_by(desc(Schedule.effective_date)).first()\n-                    \n+                        .order_by(desc(Schedule.effective_date))\n+                        .first()\n+                    )\n+\n                     if schedules:\n                         # Calculate hours for this shift\n-                        start_datetime = datetime.combine(current_date, schedules.start_time)\n-                        end_datetime = datetime.combine(current_date, schedules.end_time)\n+                        start_datetime = datetime.combine(\n+                            current_date, schedules.start_time\n+                        )\n+                        end_datetime = datetime.combine(\n+                            current_date, schedules.end_time\n+                        )\n                         if end_datetime <= start_datetime:\n                             end_datetime += timedelta(days=1)  # Next day\n-                        \n-                        shift_hours = (end_datetime - start_datetime).total_seconds() / 3600\n+\n+                        shift_hours = (\n+                            end_datetime - start_datetime\n+                        ).total_seconds() / 3600\n                         day_hours += shift_hours\n-                        \n-                        day_employees.append({\n-                            'employee_id': employee.id,\n-                            'employee_name': f\"{employee.first_name} {employee.last_name}\",\n-                            'role': employee.role,\n-                            'start_time': schedules.start_time.strftime('%H:%M'),\n-                            'end_time': schedules.end_time.strftime('%H:%M'),\n-                            'hours': round(shift_hours, 2)\n-                        })\n-                \n+\n+                        day_employees.append(\n+                            {\n+                                \"employee_id\": employee.id,\n+                                \"employee_name\": f\"{employee.first_name} {employee.last_name}\",\n+                                \"role\": employee.role,\n+                                \"start_time\": schedules.start_time.strftime(\"%H:%M\"),\n+                                \"end_time\": schedules.end_time.strftime(\"%H:%M\"),\n+                                \"hours\": round(shift_hours, 2),\n+                            }\n+                        )\n+\n                 total_week_hours += day_hours\n-                \n-                days.append(WeeklyScheduleDay(\n-                    date=current_date,\n-                    day_name=day_name,\n-                    employees=day_employees,\n-                    total_scheduled_hours=round(day_hours, 2),\n-                    coverage_gaps=[]                  ))\n-            \n+\n+                days.append(\n+                    WeeklyScheduleDay(\n+                        date=current_date,\n+                        day_name=day_name,\n+                        employees=day_employees,\n+                        total_scheduled_hours=round(day_hours, 2),\n+                        coverage_gaps=[],\n+                    )\n+                )\n+\n             return WeeklyScheduleResponse(\n                 week_start=week_start,\n                 week_end=week_end,\n                 restaurant_id=restaurant_id,\n                 days=days,\n-                total_week_hours=round(total_week_hours, 2)\n-            )\n-            \n-        except FynloException:\n-            raise\n-        except Exception as e:\n-            logger.error(f\"Error getting weekly schedule for restaurant {restaurant_id}: {str(e)}\")\n+                total_week_hours=round(total_week_hours, 2),\n+            )\n+\n+        except FynloException:\n+            raise\n+        except Exception as e:\n+            logger.error(\n+                f\"Error getting weekly schedule for restaurant {restaurant_id}: {str(e)}\"\n+            )\n             raise FynloException(f\"Failed to get weekly schedule: {str(e)}\")\n \n     async def get_employee_shifts(\n         self,\n         db: Session,\n         employee_id: int,\n         start_date: Optional[date] = None,\n         end_date: Optional[date] = None,\n-        current_user: User = None\n+        current_user: User = None,\n     ) -> List[ShiftResponse]:\n         \"\"\"Get employee work shifts with optional date filtering\"\"\"\n         try:\n             # Verify employee exists and user has access\n             employee = await self.get_employee_by_id(db, employee_id, current_user)\n             if not employee:\n                 raise FynloException(\"Employee not found\", status_code=404)\n-            \n+\n             query = db.query(Shift).filter(Shift.employee_id == employee_id)\n-            \n+\n             if start_date:\n                 query = query.filter(func.date(Shift.scheduled_start) >= start_date)\n             if end_date:\n                 query = query.filter(func.date(Shift.scheduled_end) <= end_date)\n-            \n+\n             shifts = query.order_by(desc(Shift.scheduled_start)).all()\n-            \n+\n             return [ShiftResponse.from_orm(shift) for shift in shifts]\n-            \n-        except FynloException:\n-            raise\n-        except Exception as e:\n-            logger.error(f\"Error retrieving shifts for employee {employee_id}: {str(e)}\")\n+\n+        except FynloException:\n+            raise\n+        except Exception as e:\n+            logger.error(\n+                f\"Error retrieving shifts for employee {employee_id}: {str(e)}\"\n+            )\n             raise FynloException(f\"Failed to retrieve shifts: {str(e)}\")\n \n     async def get_performance_metrics(\n         self,\n         db: Session,\n         employee_id: int,\n         start_date: Optional[date] = None,\n         end_date: Optional[date] = None,\n-        current_user: User = None\n+        current_user: User = None,\n     ) -> List[PerformanceMetricResponse]:\n         \"\"\"Get employee performance metrics\"\"\"\n         try:\n             # Verify employee exists and user has access\n             employee = await self.get_employee_by_id(db, employee_id, current_user)\n             if not employee:\n                 raise FynloException(\"Employee not found\", status_code=404)\n-            \n+\n             query = db.query(PerformanceMetric).filter(\n                 PerformanceMetric.employee_id == employee_id\n             )\n-            \n+\n             if start_date:\n                 query = query.filter(PerformanceMetric.metric_date >= start_date)\n             if end_date:\n                 query = query.filter(PerformanceMetric.metric_date <= end_date)\n-            \n+\n             metrics = query.order_by(desc(PerformanceMetric.metric_date)).all()\n-            \n+\n             return [PerformanceMetricResponse.from_orm(metric) for metric in metrics]\n-            \n-        except FynloException:\n-            raise\n-        except Exception as e:\n-            logger.error(f\"Error retrieving performance metrics for employee {employee_id}: {str(e)}\")\n+\n+        except FynloException:\n+            raise\n+        except Exception as e:\n+            logger.error(\n+                f\"Error retrieving performance metrics for employee {employee_id}: {str(e)}\"\n+            )\n             raise FynloException(f\"Failed to retrieve performance metrics: {str(e)}\")\n \n     # Additional helper methods\n \n     async def update_schedule(\n         self,\n         db: Session,\n         schedule_id: int,\n         schedule_data: ScheduleUpdateRequest,\n-        current_user: User = None\n+        current_user: User = None,\n     ) -> Optional[ScheduleResponse]:\n         \"\"\"Update existing schedule\"\"\"\n         try:\n             schedule = db.query(Schedule).filter(Schedule.id == schedule_id).first()\n             if not schedule:\n                 return None\n-            \n+\n             # Check access through employee\n-            employee = await self.get_employee_by_id(db, schedule.employee_id, current_user)\n+            employee = await self.get_employee_by_id(\n+                db, schedule.employee_id, current_user\n+            )\n             if not employee:\n                 raise FynloException(\"Access denied\", status_code=403)\n-            \n+\n             # Update fields if provided\n             update_data = schedule_data.dict(exclude_unset=True)\n             for field, value in update_data.items():\n                 if hasattr(schedule, field):\n                     setattr(schedule, field, value)\n-            \n+\n             schedule.updated_at = datetime.utcnow()\n             db.commit()\n-            \n+\n             return ScheduleResponse.from_orm(schedule)\n-            \n+\n         except FynloException:\n             db.rollback()\n             raise\n         except Exception as e:\n             db.rollback()\n             logger.error(f\"Error updating schedule {schedule_id}: {str(e)}\")\n             raise FynloException(f\"Failed to update schedule: {str(e)}\")\n \n     async def delete_schedule(\n-        self,\n-        db: Session,\n-        schedule_id: int,\n-        current_user: User = None\n+        self, db: Session, schedule_id: int, current_user: User = None\n     ) -> bool:\n         \"\"\"Delete schedule\"\"\"\n         try:\n             schedule = db.query(Schedule).filter(Schedule.id == schedule_id).first()\n             if not schedule:\n                 return False\n-            \n+\n             # Check access through employee\n-            employee = await self.get_employee_by_id(db, schedule.employee_id, current_user)\n+            employee = await self.get_employee_by_id(\n+                db, schedule.employee_id, current_user\n+            )\n             if not employee:\n                 raise FynloException(\"Access denied\", status_code=403)\n-            \n+\n             db.delete(schedule)\n             db.commit()\n-            \n+\n             return True\n-            \n+\n         except FynloException:\n             db.rollback()\n             raise\n         except Exception as e:\n             db.rollback()\n             logger.error(f\"Error deleting schedule {schedule_id}: {str(e)}\")\n-            raise FynloException(f\"Failed to delete schedule: {str(e)}\")\n\\ No newline at end of file\n+            raise FynloException(f\"Failed to delete schedule: {str(e)}\")\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/service_charge_calculator.py\t2025-08-02 21:56:59.005716+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/service_charge_calculator.py\t2025-08-02 22:36:04.013102+00:00\n@@ -1,14 +1,17 @@\n import logging\n from typing import Optional\n from decimal import Decimal, ROUND_HALF_UP\n \n from app.services.payment_fee_calculator import PaymentFeeCalculator\n-from app.services.platform_service import PlatformSettingsService # May not be needed directly if rate is passed\n+from app.services.platform_service import (\n+    PlatformSettingsService,\n+)  # May not be needed directly if rate is passed\n from app.schemas.fee_schemas import PaymentMethodEnum, ServiceChargeBreakdown\n \n logger = logging.getLogger(__name__)\n+\n \n class ServiceChargeCalculator:\n     \"\"\"\n     Calculates the service charge, potentially including transaction fees.\n     \"\"\"\n@@ -16,25 +19,24 @@\n     def __init__(\n         self,\n         payment_fee_calculator: PaymentFeeCalculator,\n         # platform_settings_service is kept if we need to fetch default service charge rates\n         # or other related configurations directly within this service in the future.\n-        platform_settings_service: PlatformSettingsService\n+        platform_settings_service: PlatformSettingsService,\n     ):\n         self.payment_fee_calculator = payment_fee_calculator\n         self.platform_settings_service = platform_settings_service\n-\n \n     def _round_currency(self, amount: Decimal) -> float:\n         \"\"\"Rounds a Decimal amount to 2 decimal places for currency representation.\"\"\"\n         quantizer = Decimal(\"0.01\")\n         return float(amount.quantize(quantizer, rounding=ROUND_HALF_UP))\n \n     async def calculate_service_charge_with_fees(\n         self,\n         order_subtotal: float,\n-        service_charge_config_rate: float, # e.g., 0.10 for 10%. Fetched from PlatformSettingsService by caller.\n+        service_charge_config_rate: float,  # e.g., 0.10 for 10%. Fetched from PlatformSettingsService by caller.\n         payment_method: PaymentMethodEnum,\n         customer_pays_processor_fees: bool,\n         # This flag below determines if the service charge should absorb the processor fee\n         include_processor_fee_in_service_charge: bool,\n         restaurant_id: Optional[str] = None,\n@@ -58,20 +60,24 @@\n         \"\"\"\n         dec_order_subtotal = Decimal(str(order_subtotal))\n         dec_service_charge_config_rate = Decimal(str(service_charge_config_rate))\n \n         if dec_order_subtotal < Decimal(\"0\"):\n-            logger.warning(\"Order subtotal is negative. Service charge calculation will result in zero.\")\n+            logger.warning(\n+                \"Order subtotal is negative. Service charge calculation will result in zero.\"\n+            )\n             return ServiceChargeBreakdown(\n                 original_service_charge_on_subtotal=0.0,\n                 processor_fee_added_to_service_charge=0.0,\n                 final_service_charge_amount=0.0,\n                 service_charge_rate_applied=float(dec_service_charge_config_rate),\n-                include_transaction_fees_in_service_charge=include_processor_fee_in_service_charge\n-            )\n-\n-        base_service_charge_on_subtotal = dec_order_subtotal * dec_service_charge_config_rate\n+                include_transaction_fees_in_service_charge=include_processor_fee_in_service_charge,\n+            )\n+\n+        base_service_charge_on_subtotal = (\n+            dec_order_subtotal * dec_service_charge_config_rate\n+        )\n \n         dec_processor_fee_component = Decimal(\"0.00\")\n \n         # The processor fee is calculated on the amount being paid, which includes subtotal + VAT + service charge.\n         # For an accurate processor fee calculation that might be part of the service charge,\n@@ -95,11 +101,15 @@\n         #\n         # Let's use the provided `order_subtotal` as the primary basis for calculating the service charge,\n         # and if processor fees are included, they are calculated on `order_subtotal + base_service_charge`.\n         # This implies VAT is handled separately by the caller when determining the final transaction amount for processor.\n \n-        if include_processor_fee_in_service_charge and customer_pays_processor_fees and payment_method != PaymentMethodEnum.CASH:\n+        if (\n+            include_processor_fee_in_service_charge\n+            and customer_pays_processor_fees\n+            and payment_method != PaymentMethodEnum.CASH\n+        ):\n             # Amount that would be processed if only subtotal + base SC were considered (excluding VAT for simplicity here,\n             # assuming payment_fee_calculator gets the full amount including VAT from its caller)\n             # A better approach: the caller (PlatformFeeService) should calculate processor_fee once on the correct total\n             # and pass it to this function if it's to be included.\n             #\n@@ -121,29 +131,42 @@\n             # This service only determines how the SC itself is composed.\n \n             # This is the fee that would apply to the (subtotal + base_service_charge) part.\n             # It's an *estimation* of the fee to be included in the SC.\n             # The final, definitive processor fee calculation will be in PlatformFeeService.\n-            amount_for_fee_estimation = float(dec_order_subtotal + base_service_charge_on_subtotal)\n-\n-            estimated_processor_fee_for_sc = await self.payment_fee_calculator.calculate_processor_fee(\n-                transaction_amount=amount_for_fee_estimation,\n-                payment_method=payment_method,\n-                restaurant_id=restaurant_id,\n-                monthly_volume_for_restaurant=monthly_volume_for_restaurant\n+            amount_for_fee_estimation = float(\n+                dec_order_subtotal + base_service_charge_on_subtotal\n+            )\n+\n+            estimated_processor_fee_for_sc = (\n+                await self.payment_fee_calculator.calculate_processor_fee(\n+                    transaction_amount=amount_for_fee_estimation,\n+                    payment_method=payment_method,\n+                    restaurant_id=restaurant_id,\n+                    monthly_volume_for_restaurant=monthly_volume_for_restaurant,\n+                )\n             )\n             dec_processor_fee_component = Decimal(str(estimated_processor_fee_for_sc))\n \n-        final_service_charge_amount = base_service_charge_on_subtotal + dec_processor_fee_component\n+        final_service_charge_amount = (\n+            base_service_charge_on_subtotal + dec_processor_fee_component\n+        )\n \n         return ServiceChargeBreakdown(\n-            original_service_charge_on_subtotal=self._round_currency(base_service_charge_on_subtotal),\n-            processor_fee_added_to_service_charge=self._round_currency(dec_processor_fee_component),\n-            final_service_charge_amount=self._round_currency(final_service_charge_amount),\n+            original_service_charge_on_subtotal=self._round_currency(\n+                base_service_charge_on_subtotal\n+            ),\n+            processor_fee_added_to_service_charge=self._round_currency(\n+                dec_processor_fee_component\n+            ),\n+            final_service_charge_amount=self._round_currency(\n+                final_service_charge_amount\n+            ),\n             service_charge_rate_applied=float(dec_service_charge_config_rate),\n-            include_transaction_fees_in_service_charge=include_processor_fee_in_service_charge\n+            include_transaction_fees_in_service_charge=include_processor_fee_in_service_charge,\n         )\n+\n \n # Example Usage (conceptual)\n # async def main_sc_example():\n #     from app.core.database import SessionLocal\n #     db = SessionLocal()\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_providers/sumup_provider.py\t2025-08-02 20:29:09.180368+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_providers/sumup_provider.py\t2025-08-02 22:36:04.023717+00:00\n@@ -12,380 +12,370 @@\n logger = logging.getLogger(__name__)\n \n \n class SumUpProvider(PaymentProvider):\n     \"\"\"SumUp payment provider implementation\"\"\"\n-    \n+\n     def __init__(self, config: Dict[str, Any]):\n         super().__init__(config)\n-        self.base_url = \"https://api.sumup.com/v0.1\" if config.get('mode') == 'production' else \"https://api.sumup.com/v0.1\"\n-        self.access_token = config.get('access_token')\n-        self.merchant_code = config.get('merchant_code')\n+        self.base_url = (\n+            \"https://api.sumup.com/v0.1\"\n+            if config.get(\"mode\") == \"production\"\n+            else \"https://api.sumup.com/v0.1\"\n+        )\n+        self.access_token = config.get(\"access_token\")\n+        self.merchant_code = config.get(\"merchant_code\")\n         self.client = httpx.AsyncClient(\n             base_url=self.base_url,\n             headers={\n-                'Authorization': f'Bearer {self.access_token}',\n-                'Content-Type': 'application/json'\n-            }\n+                \"Authorization\": f\"Bearer {self.access_token}\",\n+                \"Content-Type\": \"application/json\",\n+            },\n         )\n-    \n+\n     async def initialize(self) -> bool:\n         \"\"\"Initialize SumUp connection\"\"\"\n         try:\n             # Test the connection by getting merchant info\n-            response = await self.client.get('/me')\n-            \n+            response = await self.client.get(\"/me\")\n+\n             if response.status_code != 200:\n                 self.logger.error(f\"Failed to initialize SumUp: {response.text}\")\n                 return False\n-            \n+\n             merchant_info = response.json()\n-            self.merchant_code = merchant_info.get('merchant_profile', {}).get('merchant_code', self.merchant_code)\n-            \n+            self.merchant_code = merchant_info.get(\"merchant_profile\", {}).get(\n+                \"merchant_code\", self.merchant_code\n+            )\n+\n             self.logger.info(\"SumUp provider initialized successfully\")\n             return True\n-            \n+\n         except Exception as e:\n             self.logger.error(f\"Failed to initialize SumUp: {str(e)}\")\n             return False\n-    \n+\n     async def create_payment(\n-        self, \n-        amount: Decimal, \n+        self,\n+        amount: Decimal,\n         currency: str,\n         order_id: str,\n         customer_info: Dict[str, Any],\n         payment_method: Dict[str, Any],\n-        metadata: Optional[Dict[str, Any]] = None\n+        metadata: Optional[Dict[str, Any]] = None,\n     ) -> Dict[str, Any]:\n         \"\"\"Create a checkout for payment\"\"\"\n         try:\n             # SumUp uses checkout API for online payments\n             checkout_data = {\n-                'checkout_reference': order_id,\n-                'amount': float(amount),\n-                'currency': currency.upper(),\n-                'merchant_code': self.merchant_code,\n-                'description': f\"Order {order_id}\",\n-                'return_url': self.config.get('return_url', 'https://app.fynlo.com/payment/return'),\n-                'redirect_url': self.config.get('redirect_url', 'https://app.fynlo.com/payment/complete')\n-            }\n-            \n+                \"checkout_reference\": order_id,\n+                \"amount\": float(amount),\n+                \"currency\": currency.upper(),\n+                \"merchant_code\": self.merchant_code,\n+                \"description\": f\"Order {order_id}\",\n+                \"return_url\": self.config.get(\n+                    \"return_url\", \"https://app.fynlo.com/payment/return\"\n+                ),\n+                \"redirect_url\": self.config.get(\n+                    \"redirect_url\", \"https://app.fynlo.com/payment/complete\"\n+                ),\n+            }\n+\n             # Add customer email if provided\n-            if customer_info.get('email'):\n-                checkout_data['customer_email'] = customer_info['email']\n-            \n+            if customer_info.get(\"email\"):\n+                checkout_data[\"customer_email\"] = customer_info[\"email\"]\n+\n             # Create checkout\n-            response = await self.client.post('/checkouts', json=checkout_data)\n-            \n+            response = await self.client.post(\"/checkouts\", json=checkout_data)\n+\n             if response.status_code not in [200, 201]:\n                 self.logger.error(f\"Payment creation failed: {response.text}\")\n                 return {\n-                    'transaction_id': None,\n-                    'status': PaymentStatus.FAILED,\n-                    'error': response.text,\n-                    'raw_response': response.json() if response.headers.get('content-type') == 'application/json' else None\n+                    \"transaction_id\": None,\n+                    \"status\": PaymentStatus.FAILED,\n+                    \"error\": response.text,\n+                    \"raw_response\": (\n+                        response.json()\n+                        if response.headers.get(\"content-type\") == \"application/json\"\n+                        else None\n+                    ),\n                 }\n-            \n+\n             checkout = response.json()\n-            \n+\n             # Calculate fees (SumUp typically charges 1.69% for online payments)\n             fee = self.calculate_fee(amount)\n             net_amount = amount - fee\n-            \n-            return {\n-                'transaction_id': checkout['id'],\n-                'status': PaymentStatus.PENDING,  # Checkout created, awaiting payment\n-                'fee': fee,\n-                'net_amount': net_amount,\n-                'checkout_url': checkout.get('checkout_url'),\n-                'raw_response': checkout\n-            }\n-            \n+\n+            return {\n+                \"transaction_id\": checkout[\"id\"],\n+                \"status\": PaymentStatus.PENDING,  # Checkout created, awaiting payment\n+                \"fee\": fee,\n+                \"net_amount\": net_amount,\n+                \"checkout_url\": checkout.get(\"checkout_url\"),\n+                \"raw_response\": checkout,\n+            }\n+\n         except Exception as e:\n             self.logger.error(f\"Payment creation failed: {str(e)}\")\n             return {\n-                'transaction_id': None,\n-                'status': PaymentStatus.FAILED,\n-                'error': str(e),\n-                'raw_response': None\n-            }\n-    \n+                \"transaction_id\": None,\n+                \"status\": PaymentStatus.FAILED,\n+                \"error\": str(e),\n+                \"raw_response\": None,\n+            }\n+\n     async def capture_payment(\n-        self, \n-        transaction_id: str,\n-        amount: Optional[Decimal] = None\n+        self, transaction_id: str, amount: Optional[Decimal] = None\n     ) -> Dict[str, Any]:\n         \"\"\"SumUp captures payments automatically\"\"\"\n         # SumUp doesn't support separate auth/capture flow\n         # Payments are captured automatically when completed\n         try:\n             # Get checkout status\n-            response = await self.client.get(f'/checkouts/{transaction_id}')\n-            \n+            response = await self.client.get(f\"/checkouts/{transaction_id}\")\n+\n             if response.status_code != 200:\n-                return {\n-                    'success': False,\n-                    'error': response.text,\n-                    'raw_response': None\n-                }\n-            \n+                return {\"success\": False, \"error\": response.text, \"raw_response\": None}\n+\n             checkout = response.json()\n-            \n+\n             # Get transaction details if checkout is complete\n-            if checkout['status'] == 'PAID':\n-                transactions = checkout.get('transactions', [])\n+            if checkout[\"status\"] == \"PAID\":\n+                transactions = checkout.get(\"transactions\", [])\n                 if transactions:\n                     transaction = transactions[0]\n                     return {\n-                        'success': True,\n-                        'transaction_id': transaction['id'],\n-                        'status': self._map_sumup_status(transaction['status']),\n-                        'captured_amount': Decimal(str(transaction['amount'])),\n-                        'raw_response': transaction\n+                        \"success\": True,\n+                        \"transaction_id\": transaction[\"id\"],\n+                        \"status\": self._map_sumup_status(transaction[\"status\"]),\n+                        \"captured_amount\": Decimal(str(transaction[\"amount\"])),\n+                        \"raw_response\": transaction,\n                     }\n-            \n-            return {\n-                'success': False,\n-                'error': f\"Checkout not in capturable state: {checkout['status']}\",\n-                'raw_response': checkout\n-            }\n-            \n+\n+            return {\n+                \"success\": False,\n+                \"error\": f\"Checkout not in capturable state: {checkout['status']}\",\n+                \"raw_response\": checkout,\n+            }\n+\n         except Exception as e:\n             self.logger.error(f\"Payment capture failed: {str(e)}\")\n-            return {\n-                'success': False,\n-                'error': str(e),\n-                'raw_response': None\n-            }\n-    \n+            return {\"success\": False, \"error\": str(e), \"raw_response\": None}\n+\n     async def refund_payment(\n         self,\n         transaction_id: str,\n         amount: Optional[Decimal] = None,\n-        reason: Optional[str] = None\n+        reason: Optional[str] = None,\n     ) -> Dict[str, Any]:\n         \"\"\"Refund a payment\"\"\"\n         try:\n             # For SumUp, we need the transaction ID, not checkout ID\n             # First, try to get transaction details\n-            response = await self.client.get(f'/me/transactions/{transaction_id}')\n-            \n+            response = await self.client.get(f\"/me/transactions/{transaction_id}\")\n+\n             if response.status_code != 200:\n                 # Try getting from checkout\n-                checkout_response = await self.client.get(f'/checkouts/{transaction_id}')\n+                checkout_response = await self.client.get(\n+                    f\"/checkouts/{transaction_id}\"\n+                )\n                 if checkout_response.status_code == 200:\n                     checkout = checkout_response.json()\n-                    if checkout.get('transactions'):\n-                        transaction_id = checkout['transactions'][0]['id']\n+                    if checkout.get(\"transactions\"):\n+                        transaction_id = checkout[\"transactions\"][0][\"id\"]\n                     else:\n                         return {\n-                            'success': False,\n-                            'error': 'No completed transaction found for refund',\n-                            'raw_response': checkout\n+                            \"success\": False,\n+                            \"error\": \"No completed transaction found for refund\",\n+                            \"raw_response\": checkout,\n                         }\n                 else:\n                     return {\n-                        'success': False,\n-                        'error': 'Transaction not found',\n-                        'raw_response': None\n+                        \"success\": False,\n+                        \"error\": \"Transaction not found\",\n+                        \"raw_response\": None,\n                     }\n-            \n+\n             # Create refund\n             refund_data = {}\n             if amount:\n-                refund_data['amount'] = float(amount)\n-            \n+                refund_data[\"amount\"] = float(amount)\n+\n             response = await self.client.post(\n-                f'/me/refund/{transaction_id}',\n-                json=refund_data\n+                f\"/me/refund/{transaction_id}\", json=refund_data\n             )\n-            \n+\n             if response.status_code not in [200, 201]:\n                 return {\n-                    'success': False,\n-                    'error': response.text,\n-                    'raw_response': response.json() if response.headers.get('content-type') == 'application/json' else None\n+                    \"success\": False,\n+                    \"error\": response.text,\n+                    \"raw_response\": (\n+                        response.json()\n+                        if response.headers.get(\"content-type\") == \"application/json\"\n+                        else None\n+                    ),\n                 }\n-            \n+\n             refund = response.json()\n-            \n-            return {\n-                'success': True,\n-                'refund_id': refund.get('id', transaction_id),\n-                'transaction_id': transaction_id,\n-                'refunded_amount': Decimal(str(refund.get('amount', amount or 0))),\n-                'status': PaymentStatus.REFUNDED,\n-                'raw_response': refund\n-            }\n-            \n+\n+            return {\n+                \"success\": True,\n+                \"refund_id\": refund.get(\"id\", transaction_id),\n+                \"transaction_id\": transaction_id,\n+                \"refunded_amount\": Decimal(str(refund.get(\"amount\", amount or 0))),\n+                \"status\": PaymentStatus.REFUNDED,\n+                \"raw_response\": refund,\n+            }\n+\n         except Exception as e:\n             self.logger.error(f\"Refund failed: {str(e)}\")\n-            return {\n-                'success': False,\n-                'error': str(e),\n-                'raw_response': None\n-            }\n-    \n-    async def get_transaction_status(\n-        self,\n-        transaction_id: str\n-    ) -> Dict[str, Any]:\n+            return {\"success\": False, \"error\": str(e), \"raw_response\": None}\n+\n+    async def get_transaction_status(self, transaction_id: str) -> Dict[str, Any]:\n         \"\"\"Get current status of a transaction\"\"\"\n         try:\n             # Try as transaction ID first\n-            response = await self.client.get(f'/me/transactions/{transaction_id}')\n-            \n+            response = await self.client.get(f\"/me/transactions/{transaction_id}\")\n+\n             if response.status_code == 200:\n                 transaction = response.json()\n                 return {\n-                    'transaction_id': transaction['id'],\n-                    'status': self._map_sumup_status(transaction['status']),\n-                    'amount': Decimal(str(transaction['amount'])),\n-                    'currency': transaction['currency'],\n-                    'created_at': transaction.get('timestamp'),\n-                    'raw_response': transaction\n+                    \"transaction_id\": transaction[\"id\"],\n+                    \"status\": self._map_sumup_status(transaction[\"status\"]),\n+                    \"amount\": Decimal(str(transaction[\"amount\"])),\n+                    \"currency\": transaction[\"currency\"],\n+                    \"created_at\": transaction.get(\"timestamp\"),\n+                    \"raw_response\": transaction,\n                 }\n-            \n+\n             # Try as checkout ID\n-            response = await self.client.get(f'/checkouts/{transaction_id}')\n-            \n+            response = await self.client.get(f\"/checkouts/{transaction_id}\")\n+\n             if response.status_code == 200:\n                 checkout = response.json()\n-                \n+\n                 # Get transaction from checkout if available\n-                if checkout.get('transactions'):\n-                    transaction = checkout['transactions'][0]\n+                if checkout.get(\"transactions\"):\n+                    transaction = checkout[\"transactions\"][0]\n                     return {\n-                        'transaction_id': transaction['id'],\n-                        'status': self._map_sumup_status(transaction['status']),\n-                        'amount': Decimal(str(transaction['amount'])),\n-                        'currency': transaction['currency'],\n-                        'created_at': transaction.get('timestamp'),\n-                        'checkout_id': checkout['id'],\n-                        'raw_response': checkout\n+                        \"transaction_id\": transaction[\"id\"],\n+                        \"status\": self._map_sumup_status(transaction[\"status\"]),\n+                        \"amount\": Decimal(str(transaction[\"amount\"])),\n+                        \"currency\": transaction[\"currency\"],\n+                        \"created_at\": transaction.get(\"timestamp\"),\n+                        \"checkout_id\": checkout[\"id\"],\n+                        \"raw_response\": checkout,\n                     }\n                 else:\n                     return {\n-                        'transaction_id': checkout['id'],\n-                        'status': self._map_sumup_checkout_status(checkout['status']),\n-                        'amount': Decimal(str(checkout['amount'])),\n-                        'currency': checkout['currency'],\n-                        'created_at': checkout.get('date'),\n-                        'raw_response': checkout\n+                        \"transaction_id\": checkout[\"id\"],\n+                        \"status\": self._map_sumup_checkout_status(checkout[\"status\"]),\n+                        \"amount\": Decimal(str(checkout[\"amount\"])),\n+                        \"currency\": checkout[\"currency\"],\n+                        \"created_at\": checkout.get(\"date\"),\n+                        \"raw_response\": checkout,\n                     }\n-            \n-            return {\n-                'transaction_id': transaction_id,\n-                'status': PaymentStatus.FAILED,\n-                'error': 'Transaction not found',\n-                'raw_response': None\n-            }\n-            \n+\n+            return {\n+                \"transaction_id\": transaction_id,\n+                \"status\": PaymentStatus.FAILED,\n+                \"error\": \"Transaction not found\",\n+                \"raw_response\": None,\n+            }\n+\n         except Exception as e:\n             self.logger.error(f\"Failed to get transaction status: {str(e)}\")\n             return {\n-                'transaction_id': transaction_id,\n-                'status': PaymentStatus.FAILED,\n-                'error': str(e),\n-                'raw_response': None\n-            }\n-    \n-    async def validate_webhook(\n-        self,\n-        payload: bytes,\n-        headers: Dict[str, str]\n-    ) -> bool:\n+                \"transaction_id\": transaction_id,\n+                \"status\": PaymentStatus.FAILED,\n+                \"error\": str(e),\n+                \"raw_response\": None,\n+            }\n+\n+    async def validate_webhook(self, payload: bytes, headers: Dict[str, str]) -> bool:\n         \"\"\"Validate a webhook from SumUp\"\"\"\n         try:\n             # SumUp webhook validation\n-            signature = headers.get('X-Sumup-Signature')\n-            webhook_secret = self.config.get('webhook_secret')\n-            \n+            signature = headers.get(\"X-Sumup-Signature\")\n+            webhook_secret = self.config.get(\"webhook_secret\")\n+\n             if not signature or not webhook_secret:\n                 return False\n-            \n+\n             # Calculate expected signature\n             import hmac\n             import hashlib\n-            \n+\n             expected_signature = hmac.new(\n-                webhook_secret.encode(),\n-                payload,\n-                hashlib.sha256\n+                webhook_secret.encode(), payload, hashlib.sha256\n             ).hexdigest()\n-            \n+\n             return hmac.compare_digest(signature, expected_signature)\n-            \n+\n         except Exception as e:\n             self.logger.error(f\"Webhook validation failed: {str(e)}\")\n             return False\n-    \n-    async def parse_webhook(\n-        self,\n-        payload: bytes\n-    ) -> Dict[str, Any]:\n+\n+    async def parse_webhook(self, payload: bytes) -> Dict[str, Any]:\n         \"\"\"Parse webhook payload\"\"\"\n         try:\n             import json\n-            data = json.loads(payload.decode('utf-8'))\n-            \n+\n+            data = json.loads(payload.decode(\"utf-8\"))\n+\n             # Map SumUp events to our internal events\n             event_map = {\n-                'checkout.completed': 'payment.completed',\n-                'transaction.successful': 'payment.completed',\n-                'transaction.failed': 'payment.failed',\n-                'refund.successful': 'payment.refunded',\n-                'refund.failed': 'payment.refund_failed'\n-            }\n-            \n-            event_type = data.get('event_type', 'unknown')\n-            \n-            return {\n-                'event_type': event_map.get(event_type, event_type),\n-                'transaction_id': data.get('id') or data.get('transaction_id'),\n-                'data': data,\n-                'raw_event': data\n-            }\n-            \n+                \"checkout.completed\": \"payment.completed\",\n+                \"transaction.successful\": \"payment.completed\",\n+                \"transaction.failed\": \"payment.failed\",\n+                \"refund.successful\": \"payment.refunded\",\n+                \"refund.failed\": \"payment.refund_failed\",\n+            }\n+\n+            event_type = data.get(\"event_type\", \"unknown\")\n+\n+            return {\n+                \"event_type\": event_map.get(event_type, event_type),\n+                \"transaction_id\": data.get(\"id\") or data.get(\"transaction_id\"),\n+                \"data\": data,\n+                \"raw_event\": data,\n+            }\n+\n         except Exception as e:\n             self.logger.error(f\"Failed to parse webhook: {str(e)}\")\n-            return {\n-                'event_type': 'unknown',\n-                'error': str(e),\n-                'raw_event': None\n-            }\n-    \n+            return {\"event_type\": \"unknown\", \"error\": str(e), \"raw_event\": None}\n+\n     def calculate_fee(self, amount: Decimal) -> Decimal:\n         \"\"\"Calculate SumUp fee (1.69% for online payments)\"\"\"\n-        fee_rate = Decimal('0.0169')  # 1.69%\n-        return (amount * fee_rate).quantize(Decimal('0.01'))\n-    \n+        fee_rate = Decimal(\"0.0169\")  # 1.69%\n+        return (amount * fee_rate).quantize(Decimal(\"0.01\"))\n+\n     def _map_sumup_status(self, sumup_status: str) -> PaymentStatus:\n         \"\"\"Map SumUp transaction status to internal PaymentStatus\"\"\"\n         status_map = {\n-            'PENDING': PaymentStatus.PENDING,\n-            'SUCCESSFUL': PaymentStatus.COMPLETED,\n-            'FAILED': PaymentStatus.FAILED,\n-            'CANCELLED': PaymentStatus.CANCELLED,\n-            'REFUNDED': PaymentStatus.REFUNDED\n+            \"PENDING\": PaymentStatus.PENDING,\n+            \"SUCCESSFUL\": PaymentStatus.COMPLETED,\n+            \"FAILED\": PaymentStatus.FAILED,\n+            \"CANCELLED\": PaymentStatus.CANCELLED,\n+            \"REFUNDED\": PaymentStatus.REFUNDED,\n         }\n         return status_map.get(sumup_status, PaymentStatus.FAILED)\n-    \n+\n     def _map_sumup_checkout_status(self, checkout_status: str) -> PaymentStatus:\n         \"\"\"Map SumUp checkout status to internal PaymentStatus\"\"\"\n         status_map = {\n-            'PENDING': PaymentStatus.PENDING,\n-            'PAID': PaymentStatus.COMPLETED,\n-            'UNPAID': PaymentStatus.PENDING,\n-            'FAILED': PaymentStatus.FAILED,\n-            'EXPIRED': PaymentStatus.CANCELLED\n+            \"PENDING\": PaymentStatus.PENDING,\n+            \"PAID\": PaymentStatus.COMPLETED,\n+            \"UNPAID\": PaymentStatus.PENDING,\n+            \"FAILED\": PaymentStatus.FAILED,\n+            \"EXPIRED\": PaymentStatus.CANCELLED,\n         }\n         return status_map.get(checkout_status, PaymentStatus.FAILED)\n-    \n+\n     async def __aenter__(self):\n         \"\"\"Async context manager entry\"\"\"\n         return self\n-    \n+\n     async def __aexit__(self, exc_type, exc_val, exc_tb):\n         \"\"\"Async context manager exit - close HTTP client\"\"\"\n-        await self.client.aclose()\n\\ No newline at end of file\n+        await self.client.aclose()\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/report_service.py\t2025-08-02 19:23:36.832859+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/report_service.py\t2025-08-02 22:36:04.030159+00:00\n@@ -16,90 +16,128 @@\n logger = logging.getLogger(__name__)\n \n \n class ReportAggregationService:\n     \"\"\"Service for aggregating real order data into report models\"\"\"\n-    \n+\n     def __init__(self, db: Session):\n         self.db = db\n-    \n-    def generate_daily_report(self, restaurant_id: str, report_date: date) -> Optional[DailyReport]:\n+\n+    def generate_daily_report(\n+        self, restaurant_id: str, report_date: date\n+    ) -> Optional[DailyReport]:\n         \"\"\"\n         Generate comprehensive daily report from actual order data\n         \"\"\"\n         try:\n             # Check if report already exists for this date\n-            existing_report = self.db.query(DailyReport).filter(\n-                and_(\n-                    DailyReport.restaurant_id == restaurant_id,\n-                    DailyReport.report_date == report_date\n-                )\n-            ).first()\n-            \n+            existing_report = (\n+                self.db.query(DailyReport)\n+                .filter(\n+                    and_(\n+                        DailyReport.restaurant_id == restaurant_id,\n+                        DailyReport.report_date == report_date,\n+                    )\n+                )\n+                .first()\n+            )\n+\n             if existing_report:\n-                logger.info(f\"Daily report already exists for {restaurant_id} on {report_date}\")\n+                logger.info(\n+                    f\"Daily report already exists for {restaurant_id} on {report_date}\"\n+                )\n                 return existing_report\n-            \n+\n             # Get all completed orders for the date\n             date_start = datetime.combine(report_date, datetime.min.time())\n             date_end = date_start + timedelta(days=1)\n-            \n-            orders = self.db.query(Order).filter(\n-                and_(\n-                    Order.restaurant_id == restaurant_id,\n-                    Order.status == \"completed\",\n-                    Order.created_at >= date_start,\n-                    Order.created_at < date_end\n-                )\n-            ).all()\n-            \n+\n+            orders = (\n+                self.db.query(Order)\n+                .filter(\n+                    and_(\n+                        Order.restaurant_id == restaurant_id,\n+                        Order.status == \"completed\",\n+                        Order.created_at >= date_start,\n+                        Order.created_at < date_end,\n+                    )\n+                )\n+                .all()\n+            )\n+\n             if not orders:\n                 logger.info(f\"No orders found for {restaurant_id} on {report_date}\")\n                 return None\n-            \n+\n             # Calculate aggregated metrics\n             total_revenue = sum(order.total_amount for order in orders)\n             total_orders = len(orders)\n-            average_order_value = total_revenue / total_orders if total_orders > 0 else Decimal('0.00')\n-            \n+            average_order_value = (\n+                total_revenue / total_orders if total_orders > 0 else Decimal(\"0.00\")\n+            )\n+\n             # Payment method breakdown\n-            cash_sales = sum(order.total_amount for order in orders if order.payment_method == 'cash')\n-            card_sales = sum(order.total_amount for order in orders if order.payment_method == 'card')\n-            qr_sales = sum(order.total_amount for order in orders if order.payment_method == 'qr')\n-            other_sales = sum(order.total_amount for order in orders \n-                            if order.payment_method not in ['cash', 'card', 'qr'])\n-            \n+            cash_sales = sum(\n+                order.total_amount for order in orders if order.payment_method == \"cash\"\n+            )\n+            card_sales = sum(\n+                order.total_amount for order in orders if order.payment_method == \"card\"\n+            )\n+            qr_sales = sum(\n+                order.total_amount for order in orders if order.payment_method == \"qr\"\n+            )\n+            other_sales = sum(\n+                order.total_amount\n+                for order in orders\n+                if order.payment_method not in [\"cash\", \"card\", \"qr\"]\n+            )\n+\n             # Order type breakdown\n-            dine_in_orders = len([o for o in orders if o.order_type == 'dine_in'])\n-            takeaway_orders = len([o for o in orders if o.order_type == 'takeaway'])\n-            delivery_orders = len([o for o in orders if o.order_type == 'delivery'])\n-            \n+            dine_in_orders = len([o for o in orders if o.order_type == \"dine_in\"])\n+            takeaway_orders = len([o for o in orders if o.order_type == \"takeaway\"])\n+            delivery_orders = len([o for o in orders if o.order_type == \"delivery\"])\n+\n             # Tax and fee calculations\n-            total_tax = sum(order.tax_amount or Decimal('0.00') for order in orders)\n-            total_service_charge = sum(order.service_charge or Decimal('0.00') for order in orders)\n-            total_discounts = sum(order.discount_amount or Decimal('0.00') for order in orders)\n-            \n+            total_tax = sum(order.tax_amount or Decimal(\"0.00\") for order in orders)\n+            total_service_charge = sum(\n+                order.service_charge or Decimal(\"0.00\") for order in orders\n+            )\n+            total_discounts = sum(\n+                order.discount_amount or Decimal(\"0.00\") for order in orders\n+            )\n+\n             # Calculate payment processing fees (approximate)\n-            payment_processing_fees = (card_sales + qr_sales) * Decimal('0.029')  # 2.9% for cards/QR\n-            \n+            payment_processing_fees = (card_sales + qr_sales) * Decimal(\n+                \"0.029\"\n+            )  # 2.9% for cards/QR\n+\n             # Labor metrics (would be enhanced with actual labor tracking)\n-            employees_worked = self.db.query(func.count(func.distinct(User.id))).filter(\n-                and_(\n-                    User.restaurant_id == restaurant_id,\n-                    User.role.in_(['employee', 'manager']),\n-                    User.is_active == True\n-                )\n-            ).scalar() or 0\n-            \n+            employees_worked = (\n+                self.db.query(func.count(func.distinct(User.id)))\n+                .filter(\n+                    and_(\n+                        User.restaurant_id == restaurant_id,\n+                        User.role.in_([\"employee\", \"manager\"]),\n+                        User.is_active == True,\n+                    )\n+                )\n+                .scalar()\n+                or 0\n+            )\n+\n             # Estimated labor hours and cost (placeholder - would connect to actual time tracking)\n-            total_labor_hours = employees_worked * Decimal('8.0')  # Assuming 8-hour shifts\n-            total_labor_cost = total_labor_hours * Decimal('12.50')  # \u00a312.50/hour average\n-            \n+            total_labor_hours = employees_worked * Decimal(\n+                \"8.0\"\n+            )  # Assuming 8-hour shifts\n+            total_labor_cost = total_labor_hours * Decimal(\n+                \"12.50\"\n+            )  # \u00a312.50/hour average\n+\n             # COGS estimation (would connect to actual inventory tracking)\n-            cogs = total_revenue * Decimal('0.30')  # Approximate 30% food cost\n-            waste_cost = cogs * Decimal('0.05')  # Approximate 5% waste\n-            \n+            cogs = total_revenue * Decimal(\"0.30\")  # Approximate 30% food cost\n+            waste_cost = cogs * Decimal(\"0.05\")  # Approximate 5% waste\n+\n             # Create DailyReport instance\n             daily_report = DailyReport(\n                 restaurant_id=restaurant_id,\n                 report_date=report_date,\n                 total_revenue=total_revenue,\n@@ -118,132 +156,182 @@\n                 payment_processing_fees=payment_processing_fees,\n                 total_labor_hours=total_labor_hours,\n                 total_labor_cost=total_labor_cost,\n                 employees_worked=employees_worked,\n                 cogs=cogs,\n-                waste_cost=waste_cost\n-            )\n-            \n+                waste_cost=waste_cost,\n+            )\n+\n             # Save to database\n             self.db.add(daily_report)\n             self.db.commit()\n             self.db.refresh(daily_report)\n-            \n-            logger.info(f\"Generated daily report for {restaurant_id} on {report_date}: \"\n-                       f\"\u00a3{total_revenue} revenue, {total_orders} orders\")\n-            \n+\n+            logger.info(\n+                f\"Generated daily report for {restaurant_id} on {report_date}: \"\n+                f\"\u00a3{total_revenue} revenue, {total_orders} orders\"\n+            )\n+\n             return daily_report\n-            \n+\n         except Exception as e:\n-            logger.error(f\"Failed to generate daily report for {restaurant_id} on {report_date}: {str(e)}\")\n+            logger.error(\n+                f\"Failed to generate daily report for {restaurant_id} on {report_date}: {str(e)}\"\n+            )\n             self.db.rollback()\n             return None\n-    \n-    def generate_hourly_metrics(self, restaurant_id: str, report_date: date) -> List[HourlyMetric]:\n+\n+    def generate_hourly_metrics(\n+        self, restaurant_id: str, report_date: date\n+    ) -> List[HourlyMetric]:\n         \"\"\"\n         Generate hourly breakdown metrics for a specific date\n         \"\"\"\n         try:\n             hourly_metrics = []\n             date_start = datetime.combine(report_date, datetime.min.time())\n-            \n+\n             for hour in range(24):\n                 hour_start = date_start + timedelta(hours=hour)\n                 hour_end = hour_start + timedelta(hours=1)\n-                \n+\n                 # Get orders for this hour\n-                hourly_orders = self.db.query(Order).filter(\n-                    and_(\n-                        Order.restaurant_id == restaurant_id,\n-                        Order.status == \"completed\",\n-                        Order.created_at >= hour_start,\n-                        Order.created_at < hour_end\n-                    )\n-                ).all()\n-                \n+                hourly_orders = (\n+                    self.db.query(Order)\n+                    .filter(\n+                        and_(\n+                            Order.restaurant_id == restaurant_id,\n+                            Order.status == \"completed\",\n+                            Order.created_at >= hour_start,\n+                            Order.created_at < hour_end,\n+                        )\n+                    )\n+                    .all()\n+                )\n+\n                 if hourly_orders:\n                     hourly_revenue = sum(order.total_amount for order in hourly_orders)\n                     hourly_order_count = len(hourly_orders)\n-                    avg_order_value = hourly_revenue / hourly_order_count if hourly_order_count > 0 else Decimal('0.00')\n-                    \n+                    avg_order_value = (\n+                        hourly_revenue / hourly_order_count\n+                        if hourly_order_count > 0\n+                        else Decimal(\"0.00\")\n+                    )\n+\n                     # Customer count (unique customers per hour)\n-                    unique_customers = len(set(order.customer_id for order in hourly_orders if order.customer_id))\n-                    \n+                    unique_customers = len(\n+                        set(\n+                            order.customer_id\n+                            for order in hourly_orders\n+                            if order.customer_id\n+                        )\n+                    )\n+\n                     hourly_metric = HourlyMetric(\n                         restaurant_id=restaurant_id,\n                         report_date=report_date,\n                         hour=hour,\n                         revenue=hourly_revenue,\n                         order_count=hourly_order_count,\n                         customer_count=unique_customers,\n-                        avg_order_value=avg_order_value\n-                    )\n-                    \n+                        avg_order_value=avg_order_value,\n+                    )\n+\n                     hourly_metrics.append(hourly_metric)\n-            \n+\n             # Bulk save\n             if hourly_metrics:\n                 self.db.add_all(hourly_metrics)\n                 self.db.commit()\n-                logger.info(f\"Generated {len(hourly_metrics)} hourly metrics for {restaurant_id} on {report_date}\")\n-            \n+                logger.info(\n+                    f\"Generated {len(hourly_metrics)} hourly metrics for {restaurant_id} on {report_date}\"\n+                )\n+\n             return hourly_metrics\n-            \n+\n         except Exception as e:\n-            logger.error(f\"Failed to generate hourly metrics for {restaurant_id} on {report_date}: {str(e)}\")\n+            logger.error(\n+                f\"Failed to generate hourly metrics for {restaurant_id} on {report_date}: {str(e)}\"\n+            )\n             self.db.rollback()\n             return []\n-    \n-    def generate_reports_for_date_range(self, restaurant_id: str, start_date: date, end_date: date):\n+\n+    def generate_reports_for_date_range(\n+        self, restaurant_id: str, start_date: date, end_date: date\n+    ):\n         \"\"\"\n         Generate reports for a range of dates\n         \"\"\"\n         current_date = start_date\n         while current_date <= end_date:\n             self.generate_daily_report(restaurant_id, current_date)\n             self.generate_hourly_metrics(restaurant_id, current_date)\n             current_date += timedelta(days=1)\n-    \n-    def get_financial_summary(self, restaurant_id: str, start_date: date, end_date: date) -> Dict:\n+\n+    def get_financial_summary(\n+        self, restaurant_id: str, start_date: date, end_date: date\n+    ) -> Dict:\n         \"\"\"\n         Get aggregated financial summary from daily reports\n         \"\"\"\n         try:\n-            daily_reports = self.db.query(DailyReport).filter(\n-                and_(\n-                    DailyReport.restaurant_id == restaurant_id,\n-                    DailyReport.report_date >= start_date,\n-                    DailyReport.report_date <= end_date\n-                )\n-            ).all()\n-            \n+            daily_reports = (\n+                self.db.query(DailyReport)\n+                .filter(\n+                    and_(\n+                        DailyReport.restaurant_id == restaurant_id,\n+                        DailyReport.report_date >= start_date,\n+                        DailyReport.report_date <= end_date,\n+                    )\n+                )\n+                .all()\n+            )\n+\n             if not daily_reports:\n                 return {}\n-            \n+\n             total_revenue = sum(report.total_revenue for report in daily_reports)\n-            total_costs = sum(report.cogs + report.total_labor_cost for report in daily_reports)\n+            total_costs = sum(\n+                report.cogs + report.total_labor_cost for report in daily_reports\n+            )\n             gross_profit = total_revenue - total_costs\n-            \n+\n             return {\n                 \"total_revenue\": float(total_revenue),\n                 \"total_costs\": float(total_costs),\n                 \"gross_profit\": float(gross_profit),\n-                \"profit_margin\": float(gross_profit / total_revenue * 100) if total_revenue > 0 else 0,\n+                \"profit_margin\": (\n+                    float(gross_profit / total_revenue * 100)\n+                    if total_revenue > 0\n+                    else 0\n+                ),\n                 \"daily_reports\": len(daily_reports),\n-                \"food_sales\": float(sum(report.total_revenue for report in daily_reports)),\n-                \"labor_costs\": float(sum(report.total_labor_cost for report in daily_reports)),\n+                \"food_sales\": float(\n+                    sum(report.total_revenue for report in daily_reports)\n+                ),\n+                \"labor_costs\": float(\n+                    sum(report.total_labor_cost for report in daily_reports)\n+                ),\n                 \"cogs\": float(sum(report.cogs for report in daily_reports)),\n-                \"cash_payments\": float(sum(report.cash_sales for report in daily_reports)),\n-                \"card_payments\": float(sum(report.card_sales for report in daily_reports)),\n+                \"cash_payments\": float(\n+                    sum(report.cash_sales for report in daily_reports)\n+                ),\n+                \"card_payments\": float(\n+                    sum(report.card_sales for report in daily_reports)\n+                ),\n                 \"qr_payments\": float(sum(report.qr_sales for report in daily_reports)),\n-                \"vat_collected\": float(sum(report.total_tax for report in daily_reports)),\n-                \"service_charge_collected\": float(sum(report.total_service_charge for report in daily_reports))\n+                \"vat_collected\": float(\n+                    sum(report.total_tax for report in daily_reports)\n+                ),\n+                \"service_charge_collected\": float(\n+                    sum(report.total_service_charge for report in daily_reports)\n+                ),\n             }\n-            \n+\n         except Exception as e:\n             logger.error(f\"Failed to get financial summary: {str(e)}\")\n             return {}\n \n \n def get_report_service(db: Session) -> ReportAggregationService:\n     \"\"\"Factory function to get report aggregation service\"\"\"\n-    return ReportAggregationService(db)\n\\ No newline at end of file\n+    return ReportAggregationService(db)\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/staff_tip_service.py\t2025-08-02 21:56:59.005930+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/staff_tip_service.py\t2025-08-02 22:36:04.044500+00:00\n@@ -1,15 +1,21 @@\n import logging\n from typing import List, Optional\n from decimal import Decimal, ROUND_HALF_UP\n from sqlalchemy.orm import Session\n \n-from app.schemas.fee_schemas import StaffMember, StaffTipDistribution # Input/Output schema\n-from app.models.financial_records import StaffTipDistributionRecord # DB model\n-from app.core.database import SessionLocal # For example usage, service should get session via DI\n+from app.schemas.fee_schemas import (\n+    StaffMember,\n+    StaffTipDistribution,\n+)  # Input/Output schema\n+from app.models.financial_records import StaffTipDistributionRecord  # DB model\n+from app.core.database import (\n+    SessionLocal,\n+)  # For example usage, service should get session via DI\n \n logger = logging.getLogger(__name__)\n+\n \n class StaffTipService:\n     \"\"\"\n     Manages the distribution of tips to staff members,\n     accounting for service charges and transaction fees.\n@@ -39,20 +45,28 @@\n \n         Returns:\n             A list of StaffTipDistribution dictionaries detailing each staff member's allocated tip.\n         \"\"\"\n         dec_total_tips_collected = Decimal(str(total_tips_collected))\n-        dec_service_charge_amount_on_order = Decimal(str(service_charge_amount_on_order))\n-        dec_processor_fee_covered_by_service_charge = Decimal(str(processor_fee_covered_by_service_charge))\n+        dec_service_charge_amount_on_order = Decimal(\n+            str(service_charge_amount_on_order)\n+        )\n+        dec_processor_fee_covered_by_service_charge = Decimal(\n+            str(processor_fee_covered_by_service_charge)\n+        )\n \n         if not assigned_staff:\n-            logger.warning(f\"No staff assigned for order {order_reference}. Tips collected: {total_tips_collected} will not be distributed by this call.\")\n+            logger.warning(\n+                f\"No staff assigned for order {order_reference}. Tips collected: {total_tips_collected} will not be distributed by this call.\"\n+            )\n             # Depending on policy, these undistributed tips might go to a general pool or be handled differently.\n             return []\n \n         if dec_total_tips_collected <= Decimal(\"0\"):\n-            logger.info(f\"No tips collected for order {order_reference}. Nothing to distribute.\")\n+            logger.info(\n+                f\"No tips collected for order {order_reference}. Nothing to distribute.\"\n+            )\n             return []\n \n         # Business Logic: How does Service Charge affect tips?\n         # Assumption 1: Tips are entirely separate from Service Charge. SC doesn't reduce tip pool.\n         # Assumption 2: Service Charge is \"in lieu of tips\" or partially replaces tips.\n@@ -98,81 +112,123 @@\n                 # The `transaction_fee_impact` on tips. If service charge was meant for staff,\n                 # and it absorbed processor fees, then that's an impact.\n                 # This impact is on the service charge portion that would have gone to staff.\n                 # If we assume `processor_fee_covered_by_service_charge` is the total impact,\n                 # then per staff it's:\n-                impact_per_staff = dec_processor_fee_covered_by_service_charge / Decimal(num_staff) if num_staff > 0 else Decimal(\"0.00\")\n-\n+                impact_per_staff = (\n+                    dec_processor_fee_covered_by_service_charge / Decimal(num_staff)\n+                    if num_staff > 0\n+                    else Decimal(\"0.00\")\n+                )\n \n                 for staff_member_data in assigned_staff:\n-                    staff_member = StaffMember(id=staff_member_data['id'], name=staff_member_data['name'])\n+                    staff_member = StaffMember(\n+                        id=staff_member_data[\"id\"], name=staff_member_data[\"name\"]\n+                    )\n \n                     # This is the distribution of the explicit \"tips\"\n                     allocated_tip = tip_per_staff\n \n                     distribution_entry = StaffTipDistribution(\n                         staff_member=staff_member,\n                         tip_amount_allocated=self._round_currency(allocated_tip),\n                         # `notes` could indicate the transaction_fee_impact if SC was also part of their income\n-                        notes=f\"Service charge related processor fee impact per staff: {self._round_currency(impact_per_staff)}\"\n+                        notes=f\"Service charge related processor fee impact per staff: {self._round_currency(impact_per_staff)}\",\n                     )\n                     staff_tip_distributions.append(distribution_entry)\n \n                     # Persist to DB\n                     record = StaffTipDistributionRecord(\n                         order_reference=order_reference,\n                         staff_id=staff_member.id,\n-                        tip_amount_gross=self._round_currency(allocated_tip), # Gross tip share\n-                        service_charge_deduction=0.0, # Assuming SC doesn't directly reduce this tip amount here\n-                            # This field might be used if SC is pooled with tips then distributed\n-                        transaction_fee_impact_on_tip=self._round_currency(impact_per_staff), # Share of SC's fee burden\n-                        tip_amount_net=self._round_currency(allocated_tip), # Net from tips. If SC also for staff, their total income is this + SC_share\n+                        tip_amount_gross=self._round_currency(\n+                            allocated_tip\n+                        ),  # Gross tip share\n+                        service_charge_deduction=0.0,  # Assuming SC doesn't directly reduce this tip amount here\n+                        # This field might be used if SC is pooled with tips then distributed\n+                        transaction_fee_impact_on_tip=self._round_currency(\n+                            impact_per_staff\n+                        ),  # Share of SC's fee burden\n+                        tip_amount_net=self._round_currency(\n+                            allocated_tip\n+                        ),  # Net from tips. If SC also for staff, their total income is this + SC_share\n                         # distribution_timestamp is server_default\n                     )\n                     self.db.add(record)\n             else:\n-                logger.warning(f\"Tip distribution strategy is '{tip_distribution_strategy}' but no staff found for order {order_reference}.\")\n+                logger.warning(\n+                    f\"Tip distribution strategy is '{tip_distribution_strategy}' but no staff found for order {order_reference}.\"\n+                )\n \n         # elif tip_distribution_strategy == \"points_based\":\n-            # Placeholder for future strategy:\n-            # total_points = sum(staff.get('points', 1) for staff in assigned_staff)\n-            # for staff in assigned_staff:\n-            #     points = staff.get('points', 1)\n-            #     share = (Decimal(points) / Decimal(total_points)) * distributable_tip_pool\n-            #     ... create StaffTipDistribution ...\n-            # pass\n+        # Placeholder for future strategy:\n+        # total_points = sum(staff.get('points', 1) for staff in assigned_staff)\n+        # for staff in assigned_staff:\n+        #     points = staff.get('points', 1)\n+        #     share = (Decimal(points) / Decimal(total_points)) * distributable_tip_pool\n+        #     ... create StaffTipDistribution ...\n+        # pass\n         else:\n-            logger.error(f\"Unsupported tip distribution strategy: {tip_distribution_strategy}\")\n-            raise ValueError(f\"Unsupported tip distribution strategy: {tip_distribution_strategy}\")\n+            logger.error(\n+                f\"Unsupported tip distribution strategy: {tip_distribution_strategy}\"\n+            )\n+            raise ValueError(\n+                f\"Unsupported tip distribution strategy: {tip_distribution_strategy}\"\n+            )\n \n         try:\n             self.db.commit()\n-            for dist_entry_schema, db_record in zip(staff_tip_distributions, self.db.query(StaffTipDistributionRecord).filter(StaffTipDistributionRecord.order_reference == order_reference).all()): # Re-fetch to get IDs if needed, or use refreshed objects\n-                 # If you need the DB record ID in the returned schema, you'd map it here.\n-                 # For now, the schema doesn't include the DB record ID.\n-                 pass\n+            for dist_entry_schema, db_record in zip(\n+                staff_tip_distributions,\n+                self.db.query(StaffTipDistributionRecord)\n+                .filter(StaffTipDistributionRecord.order_reference == order_reference)\n+                .all(),\n+            ):  # Re-fetch to get IDs if needed, or use refreshed objects\n+                # If you need the DB record ID in the returned schema, you'd map it here.\n+                # For now, the schema doesn't include the DB record ID.\n+                pass\n         except Exception as e:\n             self.db.rollback()\n-            logger.error(f\"Error saving staff tip distributions for order {order_reference}: {e}\", exc_info=True)\n+            logger.error(\n+                f\"Error saving staff tip distributions for order {order_reference}: {e}\",\n+                exc_info=True,\n+            )\n             raise\n \n         return staff_tip_distributions\n \n-    def get_tip_distributions_for_order(self, order_reference: str) -> List[StaffTipDistributionRecord]:\n+    def get_tip_distributions_for_order(\n+        self, order_reference: str\n+    ) -> List[StaffTipDistributionRecord]:\n         \"\"\"Retrieves all tip distribution records for a given order.\"\"\"\n-        return self.db.query(StaffTipDistributionRecord).filter(\n-            StaffTipDistributionRecord.order_reference == order_reference\n+        return (\n+            self.db.query(StaffTipDistributionRecord)\n+            .filter(StaffTipDistributionRecord.order_reference == order_reference)\n+            .all()\n+        )\n+\n+    def get_tip_distributions_for_staff(\n+        self,\n+        staff_id: str,\n+        start_date: Optional[str] = None,\n+        end_date: Optional[str] = None,\n+    ) -> List[StaffTipDistributionRecord]:\n+        \"\"\"Retrieves all tip distribution records for a given staff member, optionally within a date range.\"\"\"\n+        query = self.db.query(StaffTipDistributionRecord).filter(\n+            StaffTipDistributionRecord.staff_id == staff_id\n+        )\n+        if start_date:\n+            query = query.filter(\n+                StaffTipDistributionRecord.distribution_timestamp >= start_date\n+            )\n+        if end_date:\n+            query = query.filter(\n+                StaffTipDistributionRecord.distribution_timestamp <= end_date\n+            )\n+        return query.order_by(\n+            StaffTipDistributionRecord.distribution_timestamp.desc()\n         ).all()\n-\n-    def get_tip_distributions_for_staff(self, staff_id: str, start_date: Optional[str] = None, end_date: Optional[str] = None) -> List[StaffTipDistributionRecord]:\n-        \"\"\"Retrieves all tip distribution records for a given staff member, optionally within a date range.\"\"\"\n-        query = self.db.query(StaffTipDistributionRecord).filter(StaffTipDistributionRecord.staff_id == staff_id)\n-        if start_date:\n-            query = query.filter(StaffTipDistributionRecord.distribution_timestamp >= start_date)\n-        if end_date:\n-            query = query.filter(StaffTipDistributionRecord.distribution_timestamp <= end_date)\n-        return query.order_by(StaffTipDistributionRecord.distribution_timestamp.desc()).all()\n \n \n # Example Usage (conceptual)\n # async def main_st_example():\n #     db_session = SessionLocal() # Example: get a session\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/secure_payment_config.py\t2025-08-02 22:10:21.257156+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/secure_payment_config.py\t2025-08-02 22:36:04.044069+00:00\n@@ -1,9 +1,10 @@\n \"\"\"\n Secure Payment Configuration Service\n Handles encryption/decryption of payment provider credentials\n \"\"\"\n+\n import os\n import json\n from typing import Dict, Any, Optional\n from datetime import datetime\n from cryptography.fernet import Fernet\n@@ -15,56 +16,60 @@\n from app.core.exceptions import FynloException\n \n \n class PaymentProviderConfig(Base):\n     \"\"\"Database model for encrypted payment provider configurations\"\"\"\n-    __tablename__ = 'payment_provider_configs'\n-    \n+\n+    __tablename__ = \"payment_provider_configs\"\n+\n     id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))\n     provider = Column(String, nullable=False)  # 'stripe', 'square', 'sumup', etc.\n     restaurant_id = Column(String, nullable=False)\n     encrypted_credentials = Column(Text, nullable=False)  # Encrypted JSON\n-    mode = Column(String, nullable=False, default='sandbox')  # 'sandbox' or 'production'\n+    mode = Column(\n+        String, nullable=False, default=\"sandbox\"\n+    )  # 'sandbox' or 'production'\n     enabled = Column(Boolean, default=True)\n     created_at = Column(DateTime, default=datetime.utcnow)\n     updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)\n-    \n+\n     # Composite unique constraint\n-    __table_args__ = (\n-        {'extend_existing': True},\n-    )\n+    __table_args__ = ({\"extend_existing\": True},)\n \n \n class SecurePaymentConfigService:\n     \"\"\"\n     Manages payment provider configurations with encryption\n-    \n+\n     Features:\n     - Encrypts sensitive credentials at rest\n     - Provides secure storage and retrieval\n     - Validates configuration before storage\n     - Audit trail for configuration changes\n     \"\"\"\n-    \n+\n     def __init__(self, db: Session):\n         self.db = db\n-        \n+\n         # Get encryption key from environment\n-        encryption_key = os.environ.get('PAYMENT_CONFIG_ENCRYPTION_KEY')\n+        encryption_key = os.environ.get(\"PAYMENT_CONFIG_ENCRYPTION_KEY\")\n         if not encryption_key:\n             # Use a fixed development key to prevent data loss\n-            if os.environ.get('ENVIRONMENT', 'development') == 'development':\n+            if os.environ.get(\"ENVIRONMENT\", \"development\") == \"development\":\n                 # Fixed development key - prevents losing encrypted data on restart\n                 encryption_key = \"8J5AOuMMykQkzj6EU5Z8QgPYLE1Aye4OuIjUER2b8w0=\"\n             else:\n-                raise ValueError(\"PAYMENT_CONFIG_ENCRYPTION_KEY environment variable not set\")\n-        \n+                raise ValueError(\n+                    \"PAYMENT_CONFIG_ENCRYPTION_KEY environment variable not set\"\n+                )\n+\n         # Handle both string and bytes format\n         if isinstance(encryption_key, str):\n             try:\n                 # Try to decode as base64 first (Fernet key format)\n                 import base64\n+\n                 base64.b64decode(encryption_key)\n                 encryption_key = encryption_key.encode()\n             except Exception:\n                 # If not base64, assume it's already a raw string that needs encoding\n                 encryption_key = encryption_key.encode()\n@@ -73,55 +78,56 @@\n             try:\n                 Fernet(encryption_key)\n             except Exception:\n                 # Invalid key, try to decode as string first\n                 encryption_key = encryption_key.decode().encode()\n-            \n+\n         self.cipher = Fernet(encryption_key)\n-    \n+\n     def store_provider_config(\n         self,\n         provider: str,\n         restaurant_id: str,\n         credentials: Dict[str, Any],\n-        mode: str = 'sandbox',\n-        validate: bool = True\n+        mode: str = \"sandbox\",\n+        validate: bool = True,\n     ) -> str:\n         \"\"\"\n         Store encrypted payment provider configuration\n-        \n+\n         Args:\n             provider: Provider name (stripe, square, sumup, etc.)\n             restaurant_id: Restaurant ID\n             credentials: Provider-specific credentials dict\n             mode: 'sandbox' or 'production'\n             validate: Whether to validate credentials format\n-            \n+\n         Returns:\n             Configuration ID\n-            \n+\n         Raises:\n             ValueError: If validation fails\n             FynloException: If storage fails\n         \"\"\"\n         # Validate inputs\n-        if mode not in ['sandbox', 'production']:\n+        if mode not in [\"sandbox\", \"production\"]:\n             raise ValueError(f\"Invalid mode: {mode}\")\n-        \n+\n         if validate:\n             self._validate_credentials(provider, credentials)\n-        \n+\n         # Check for existing config\n-        existing = self.db.query(PaymentProviderConfig).filter_by(\n-            provider=provider,\n-            restaurant_id=restaurant_id\n-        ).first()\n-        \n+        existing = (\n+            self.db.query(PaymentProviderConfig)\n+            .filter_by(provider=provider, restaurant_id=restaurant_id)\n+            .first()\n+        )\n+\n         # Encrypt credentials\n         credentials_json = json.dumps(credentials)\n         encrypted_creds = self.cipher.encrypt(credentials_json.encode()).decode()\n-        \n+\n         if existing:\n             # Update existing\n             existing.encrypted_credentials = encrypted_creds\n             existing.mode = mode\n             existing.updated_at = datetime.utcnow()\n@@ -131,226 +137,220 @@\n             config = PaymentProviderConfig(\n                 provider=provider,\n                 restaurant_id=restaurant_id,\n                 encrypted_credentials=encrypted_creds,\n                 mode=mode,\n-                enabled=True\n+                enabled=True,\n             )\n             self.db.add(config)\n             config_id = config.id\n-        \n+\n         try:\n             self.db.commit()\n             return config_id\n         except Exception as e:\n             self.db.rollback()\n             raise FynloException(f\"Failed to store payment config: {str(e)}\")\n-    \n+\n     def get_provider_config(\n-        self,\n-        provider: str,\n-        restaurant_id: str,\n-        mode: Optional[str] = None\n+        self, provider: str, restaurant_id: str, mode: Optional[str] = None\n     ) -> Optional[Dict[str, Any]]:\n         \"\"\"\n         Get decrypted configuration for a payment provider\n-        \n+\n         Args:\n             provider: Provider name\n             restaurant_id: Restaurant ID\n             mode: Optional mode filter\n-            \n+\n         Returns:\n             Decrypted configuration dict or None if not found\n         \"\"\"\n         query = self.db.query(PaymentProviderConfig).filter_by(\n-            provider=provider,\n-            restaurant_id=restaurant_id,\n-            enabled=True\n+            provider=provider, restaurant_id=restaurant_id, enabled=True\n         )\n-        \n+\n         if mode:\n             query = query.filter_by(mode=mode)\n-        \n+\n         config = query.first()\n-        \n+\n         if not config:\n             return None\n-        \n+\n         # Decrypt credentials\n         try:\n             decrypted_json = self.cipher.decrypt(\n                 config.encrypted_credentials.encode()\n             ).decode()\n             credentials = json.loads(decrypted_json)\n         except Exception as e:\n             raise FynloException(f\"Failed to decrypt payment config: {str(e)}\")\n-        \n+\n         return {\n-            'id': config.id,\n-            'provider': config.provider,\n-            'restaurant_id': config.restaurant_id,\n-            'credentials': credentials,\n-            'mode': config.mode,\n-            'enabled': config.enabled,\n-            'created_at': config.created_at.isoformat(),\n-            'updated_at': config.updated_at.isoformat()\n+            \"id\": config.id,\n+            \"provider\": config.provider,\n+            \"restaurant_id\": config.restaurant_id,\n+            \"credentials\": credentials,\n+            \"mode\": config.mode,\n+            \"enabled\": config.enabled,\n+            \"created_at\": config.created_at.isoformat(),\n+            \"updated_at\": config.updated_at.isoformat(),\n         }\n-    \n+\n     def list_provider_configs(\n-        self,\n-        restaurant_id: str,\n-        include_disabled: bool = False\n+        self, restaurant_id: str, include_disabled: bool = False\n     ) -> list[Dict[str, Any]]:\n         \"\"\"\n         List all provider configurations for a restaurant\n-        \n+\n         Args:\n             restaurant_id: Restaurant ID\n             include_disabled: Whether to include disabled configs\n-            \n+\n         Returns:\n             List of configuration summaries (without credentials)\n         \"\"\"\n         query = self.db.query(PaymentProviderConfig).filter_by(\n             restaurant_id=restaurant_id\n         )\n-        \n+\n         if not include_disabled:\n             query = query.filter_by(enabled=True)\n-        \n+\n         configs = query.all()\n-        \n+\n         return [\n             {\n-                'id': config.id,\n-                'provider': config.provider,\n-                'mode': config.mode,\n-                'enabled': config.enabled,\n-                'created_at': config.created_at.isoformat(),\n-                'updated_at': config.updated_at.isoformat()\n+                \"id\": config.id,\n+                \"provider\": config.provider,\n+                \"mode\": config.mode,\n+                \"enabled\": config.enabled,\n+                \"created_at\": config.created_at.isoformat(),\n+                \"updated_at\": config.updated_at.isoformat(),\n             }\n             for config in configs\n         ]\n-    \n+\n     def disable_provider_config(self, provider: str, restaurant_id: str) -> bool:\n         \"\"\"\n         Disable a provider configuration\n-        \n+\n         Args:\n             provider: Provider name\n             restaurant_id: Restaurant ID\n-            \n+\n         Returns:\n             True if disabled, False if not found\n         \"\"\"\n-        config = self.db.query(PaymentProviderConfig).filter_by(\n-            provider=provider,\n-            restaurant_id=restaurant_id\n-        ).first()\n-        \n+        config = (\n+            self.db.query(PaymentProviderConfig)\n+            .filter_by(provider=provider, restaurant_id=restaurant_id)\n+            .first()\n+        )\n+\n         if not config:\n             return False\n-        \n+\n         config.enabled = False\n         config.updated_at = datetime.utcnow()\n-        \n+\n         try:\n             self.db.commit()\n             return True\n         except Exception as e:\n             self.db.rollback()\n             raise FynloException(f\"Failed to disable payment config: {str(e)}\")\n-    \n+\n     def _validate_credentials(self, provider: str, credentials: Dict[str, Any]) -> None:\n         \"\"\"\n         Validate provider-specific credential format\n-        \n+\n         Args:\n             provider: Provider name\n             credentials: Credentials dict\n-            \n+\n         Raises:\n             ValueError: If credentials are invalid\n         \"\"\"\n         # Define required fields per provider\n         required_fields = {\n-            'stripe': ['secret_key', 'publishable_key'],\n-            'square': ['access_token', 'location_id', 'application_id'],\n-            'sumup': ['api_key', 'merchant_code'],\n-            'qr_provider': ['api_key', 'merchant_id'],\n-            'cash_provider': []  # No credentials needed\n+            \"stripe\": [\"secret_key\", \"publishable_key\"],\n+            \"square\": [\"access_token\", \"location_id\", \"application_id\"],\n+            \"sumup\": [\"api_key\", \"merchant_code\"],\n+            \"qr_provider\": [\"api_key\", \"merchant_id\"],\n+            \"cash_provider\": [],  # No credentials needed\n         }\n-        \n+\n         # Sensitive field patterns that should never be empty or exposed\n-        sensitive_patterns = ['key', 'secret', 'token', 'password']\n-        \n+        sensitive_patterns = [\"key\", \"secret\", \"token\", \"password\"]\n+\n         if provider not in required_fields:\n             raise ValueError(f\"Unknown provider: {provider}\")\n-        \n+\n         # Check required fields\n         for field in required_fields.get(provider, []):\n             if field not in credentials:\n                 raise ValueError(f\"Missing required field for {provider}: {field}\")\n-            \n+\n             value = credentials[field]\n-            \n+\n             # Validate sensitive fields\n             if any(pattern in field.lower() for pattern in sensitive_patterns):\n                 if not value or not isinstance(value, str):\n                     raise ValueError(f\"Invalid value for sensitive field: {field}\")\n-                \n+\n                 # Basic validation for API keys\n                 if len(value) < 10:\n                     raise ValueError(f\"Invalid {field}: too short\")\n-                \n+\n                 # Check for placeholder values\n-                if value.lower() in ['your-api-key', 'placeholder', 'test', '']:\n+                if value.lower() in [\"your-api-key\", \"placeholder\", \"test\", \"\"]:\n                     raise ValueError(f\"Invalid {field}: placeholder value detected\")\n-    \n+\n     def rotate_encryption_key(self, new_key: str) -> int:\n         \"\"\"\n         Rotate the encryption key for all stored configurations\n-        \n+\n         Args:\n             new_key: New encryption key\n-            \n+\n         Returns:\n             Number of configurations re-encrypted\n-            \n+\n         Note: This should be done during maintenance windows\n         \"\"\"\n         # Create new cipher\n         new_cipher = Fernet(new_key.encode())\n-        \n+\n         # Get all configurations\n         configs = self.db.query(PaymentProviderConfig).all()\n         count = 0\n-        \n+\n         for config in configs:\n             try:\n                 # Decrypt with old key\n                 decrypted = self.cipher.decrypt(\n                     config.encrypted_credentials.encode()\n                 ).decode()\n-                \n+\n                 # Re-encrypt with new key\n                 new_encrypted = new_cipher.encrypt(decrypted.encode()).decode()\n-                \n+\n                 # Update in database\n                 config.encrypted_credentials = new_encrypted\n                 config.updated_at = datetime.utcnow()\n                 count += 1\n-                \n+\n             except Exception as e:\n                 logger.error(f\"Failed to rotate key for config {config.id}: {str(e)}\")\n                 continue\n-        \n+\n         # Commit all changes\n         try:\n             self.db.commit()\n             # Update the service's cipher\n             self.cipher = new_cipher\n             return count\n         except Exception as e:\n             self.db.rollback()\n-            raise FynloException(f\"Failed to rotate encryption keys: {str(e)}\")\n\\ No newline at end of file\n+            raise FynloException(f\"Failed to rotate encryption keys: {str(e)}\")\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/websocket/__init__.py\t2025-08-01 23:08:38.319949+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/websocket/__init__.py\t2025-08-02 22:36:04.054470+00:00\n@@ -1,4 +1,4 @@\n \"\"\"\n WebSocket package\n Alternative WebSocket implementation for real-time communication\n-\"\"\"\n\\ No newline at end of file\n+\"\"\"\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/secure_payment_processor.py\t2025-08-02 22:10:38.336922+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/secure_payment_processor.py\t2025-08-02 22:36:04.064447+00:00\n@@ -1,9 +1,10 @@\n \"\"\"\n Secure Payment Processing Service\n Handles payment processing with automatic fallback and comprehensive security\n \"\"\"\n+\n from typing import Dict, Any, Optional\n from decimal import Decimal\n from datetime import datetime\n from sqlalchemy.orm import Session\n from sqlalchemy import Column, String, DateTime, DECIMAL, Text\n@@ -18,54 +19,55 @@\n from app.services.payment_factory import PaymentProviderFactory\n \n \n class PaymentProcessingError(FynloException):\n     \"\"\"Payment processing specific exception\"\"\"\n+\n     def __init__(self, message: str, payment_id: Optional[str] = None, **kwargs):\n         super().__init__(message, **kwargs)\n         self.payment_id = payment_id\n \n \n class Payment(Base):\n     \"\"\"Payment transaction record\"\"\"\n-    __tablename__ = 'payments'\n-    \n+\n+    __tablename__ = \"payments\"\n+\n     id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))\n     order_id = Column(String, nullable=False)\n     restaurant_id = Column(String, nullable=False)\n     user_id = Column(String, nullable=False)\n-    \n+\n     amount = Column(DECIMAL(10, 2), nullable=False)\n-    currency = Column(String(3), default='GBP')\n+    currency = Column(String(3), default=\"GBP\")\n     payment_method = Column(String, nullable=False)\n-    \n-    status = Column(String, default='pending')\n+\n+    status = Column(String, default=\"pending\")\n     provider = Column(String)  # Which provider processed it\n     provider_transaction_id = Column(String)  # Provider's transaction ID\n-    \n+\n     fee_amount = Column(DECIMAL(10, 2), default=0)\n     net_amount = Column(DECIMAL(10, 2))  # Amount after fees\n-    \n+\n     created_at = Column(DateTime, default=datetime.utcnow)\n     completed_at = Column(DateTime)\n-    \n+\n     # Store sanitized provider responses\n     provider_response = Column(Text)  # JSON\n     error_message = Column(Text)\n-    \n+\n     # Metadata\n     payment_metadata = Column(Text)  # JSON\n-    \n-    __table_args__ = (\n-        {'extend_existing': True},\n-    )\n+\n+    __table_args__ = ({\"extend_existing\": True},)\n \n \n class PaymentAuditLog(Base):\n     \"\"\"Audit trail for all payment actions\"\"\"\n-    __tablename__ = 'payment_audit_logs'\n-    \n+\n+    __tablename__ = \"payment_audit_logs\"\n+\n     id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))\n     payment_id = Column(String)\n     action = Column(String)  # 'attempt', 'success', 'failure', 'refund'\n     provider = Column(String)\n     user_id = Column(String)\n@@ -73,313 +75,314 @@\n     user_agent = Column(String)\n     request_data = Column(Text)  # JSON - sanitized\n     response_data = Column(Text)  # JSON - sanitized\n     error_message = Column(Text)\n     created_at = Column(DateTime, default=datetime.utcnow)\n-    \n-    __table_args__ = (\n-        {'extend_existing': True},\n-    )\n+\n+    __table_args__ = ({\"extend_existing\": True},)\n \n \n class SecurePaymentProcessor:\n     \"\"\"\n     Secure payment processing with automatic fallback\n-    \n+\n     Features:\n     - Multiple provider support with automatic fallback\n     - Comprehensive audit logging\n     - Fee calculation and transparency\n     - Security validation at every step\n     - Database transaction management\n     \"\"\"\n-    \n+\n     def __init__(self, db: Session, request_context: Optional[Dict[str, Any]] = None):\n         self.db = db\n         self.config_service = SecurePaymentConfigService(db)\n         self.provider_factory = PaymentProviderFactory()\n         self.request_context = request_context or {}\n         self.logger = logging.getLogger(__name__)\n         self._initialized = False\n-    \n+\n     async def process_payment(\n         self,\n         order_id: str,\n         amount: Decimal,\n         payment_method: str,\n         payment_details: Dict[str, Any],\n         user_id: str,\n         restaurant_id: str,\n-        metadata: Optional[Dict[str, Any]] = None\n+        metadata: Optional[Dict[str, Any]] = None,\n     ) -> Dict[str, Any]:\n         \"\"\"\n         Process payment with automatic fallback\n-        \n+\n         Args:\n             order_id: Order ID\n             amount: Payment amount\n             payment_method: Payment method (card, cash, qr_code, etc.)\n             payment_details: Method-specific payment details\n             user_id: User processing the payment\n             restaurant_id: Restaurant ID\n             metadata: Optional metadata\n-            \n+\n         Returns:\n             Payment result dict\n-            \n+\n         Raises:\n             PaymentProcessingError: If all payment attempts fail\n         \"\"\"\n         # Start database transaction\n         payment = None\n         try:\n             # Validate inputs\n             self._validate_payment_request(amount, payment_method)\n-            \n+\n             # Create payment record\n             payment = Payment(\n                 order_id=order_id,\n                 amount=amount,\n-                currency='GBP',\n+                currency=\"GBP\",\n                 payment_method=payment_method,\n-                status='pending',\n+                status=\"pending\",\n                 user_id=user_id,\n                 restaurant_id=restaurant_id,\n-                metadata=str(metadata) if metadata else None\n+                metadata=str(metadata) if metadata else None,\n             )\n             self.db.add(payment)\n             self.db.commit()\n-            \n+\n             # Log payment attempt\n             self._log_action(\n                 payment_id=payment.id,\n-                action='attempt',\n-                provider='system',\n+                action=\"attempt\",\n+                provider=\"system\",\n                 request_data={\n-                    'amount': float(amount),\n-                    'payment_method': payment_method,\n-                    'order_id': order_id\n-                }\n-            )\n-            \n+                    \"amount\": float(amount),\n+                    \"payment_method\": payment_method,\n+                    \"order_id\": order_id,\n+                },\n+            )\n+\n             # Initialize providers if not done\n             if not self._initialized:\n                 await self.provider_factory.initialize(restaurant_id)\n                 self._initialized = True\n-            \n+\n             # Get providers for fallback processing\n             providers = await self.provider_factory.get_providers_for_fallback(\n-                amount=amount,\n-                payment_method=payment_method,\n-                currency='GBP'\n-            )\n-            \n+                amount=amount, payment_method=payment_method, currency=\"GBP\"\n+            )\n+\n             if not providers:\n                 raise PaymentProcessingError(\n                     f\"No payment providers available for {payment_method}\",\n-                    payment_id=payment.id\n+                    payment_id=payment.id,\n                 )\n-            \n+\n             # Try each provider\n             last_error = None\n             for provider in providers:\n                 try:\n                     provider_name = provider.provider_name\n-                    \n+\n                     # Log provider attempt\n                     self._log_action(\n                         payment_id=payment.id,\n-                        action='provider_attempt',\n+                        action=\"provider_attempt\",\n                         provider=provider_name,\n-                        request_data={'provider': provider_name}\n+                        request_data={\"provider\": provider_name},\n                     )\n-                    \n+\n                     # Process payment\n                     result = await self._process_with_provider(\n                         provider=provider,\n                         provider_name=provider_name,\n                         payment=payment,\n                         amount=amount,\n                         payment_details=payment_details,\n-                        order_id=order_id\n+                        order_id=order_id,\n                     )\n-                    \n+\n                     # Payment successful\n                     return result\n-                    \n+\n                 except Exception as e:\n                     last_error = e\n                     self.logger.error(f\"Provider {provider_name} failed: {str(e)}\")\n-                    \n+\n                     # Log provider failure\n                     self._log_action(\n                         payment_id=payment.id,\n-                        action='provider_failure',\n+                        action=\"provider_failure\",\n                         provider=provider_name,\n-                        error_message=str(e)\n+                        error_message=str(e),\n                     )\n-                    \n+\n                     # Continue to next provider\n                     continue\n-            \n+\n             # All providers failed\n-            payment.status = 'failed'\n+            payment.status = \"failed\"\n             payment.error_message = str(last_error)\n             self.db.commit()\n-            \n+\n             # Log complete failure\n             self._log_action(\n                 payment_id=payment.id,\n-                action='failure',\n-                provider='all',\n-                error_message=f\"All providers failed. Last error: {str(last_error)}\"\n-            )\n-            \n+                action=\"failure\",\n+                provider=\"all\",\n+                error_message=f\"All providers failed. Last error: {str(last_error)}\",\n+            )\n+\n             raise PaymentProcessingError(\n-                f\"Payment processing failed: {last_error}\",\n-                payment_id=payment.id\n-            )\n-            \n+                f\"Payment processing failed: {last_error}\", payment_id=payment.id\n+            )\n+\n         except PaymentProcessingError:\n             raise\n         except Exception as e:\n             if payment:\n-                payment.status = 'failed'\n+                payment.status = \"failed\"\n                 payment.error_message = str(e)\n                 self.db.commit()\n             raise PaymentProcessingError(f\"Unexpected error: {str(e)}\")\n-    \n+\n     async def _process_with_provider(\n         self,\n-        provider: 'PaymentProvider',\n+        provider: \"PaymentProvider\",\n         provider_name: str,\n         payment: Payment,\n         amount: Decimal,\n         payment_details: Dict[str, Any],\n-        order_id: str\n+        order_id: str,\n     ) -> Dict[str, Any]:\n         \"\"\"Process payment with a specific provider\"\"\"\n         # Process payment\n         result = await provider.create_payment(\n             amount=amount,\n-            currency='GBP',\n+            currency=\"GBP\",\n             order_id=order_id,\n-            customer_info=payment_details.get('customer_info', {}),\n+            customer_info=payment_details.get(\"customer_info\", {}),\n             payment_method=payment_details,\n-            metadata={\n-                'payment_id': payment.id,\n-                'restaurant_id': payment.restaurant_id\n-            }\n+            metadata={\"payment_id\": payment.id, \"restaurant_id\": payment.restaurant_id},\n         )\n-        \n+\n         # Validate provider response\n-        if result.get('status') == PaymentStatus.FAILED:\n-            raise Exception(result.get('error', 'Payment failed'))\n-        \n+        if result.get(\"status\") == PaymentStatus.FAILED:\n+            raise Exception(result.get(\"error\", \"Payment failed\"))\n+\n         # Get fees from provider response\n-        fee_amount = result.get('fee', Decimal('0'))\n-        net_amount = result.get('net_amount', amount - fee_amount)\n-        \n+        fee_amount = result.get(\"fee\", Decimal(\"0\"))\n+        net_amount = result.get(\"net_amount\", amount - fee_amount)\n+\n         # Update payment record\n         payment.provider = provider_name\n-        payment.provider_transaction_id = result.get('transaction_id')\n-        payment.status = result.get('status', PaymentStatus.COMPLETED).value\n+        payment.provider_transaction_id = result.get(\"transaction_id\")\n+        payment.status = result.get(\"status\", PaymentStatus.COMPLETED).value\n         payment.completed_at = datetime.utcnow()\n         payment.fee_amount = fee_amount\n         payment.net_amount = net_amount\n         payment.provider_response = str(result)\n         self.db.commit()\n-        \n+\n         # Log success\n         self._log_action(\n             payment_id=payment.id,\n-            action='success',\n+            action=\"success\",\n             provider=provider_name,\n-            response_data=result\n+            response_data=result,\n         )\n-        \n+\n         return {\n-            'success': True,\n-            'payment_id': payment.id,\n-            'transaction_id': result.get('transaction_id'),\n-            'provider': provider_name,\n-            'amount': float(amount),\n-            'currency': 'GBP',\n-            'fees': {\n-                'total_fee': float(fee_amount),\n-                'rate_percentage': float(provider.calculate_fee(Decimal('100')) / 100)\n+            \"success\": True,\n+            \"payment_id\": payment.id,\n+            \"transaction_id\": result.get(\"transaction_id\"),\n+            \"provider\": provider_name,\n+            \"amount\": float(amount),\n+            \"currency\": \"GBP\",\n+            \"fees\": {\n+                \"total_fee\": float(fee_amount),\n+                \"rate_percentage\": float(provider.calculate_fee(Decimal(\"100\")) / 100),\n             },\n-            'net_amount': float(payment.net_amount),\n-            'status': payment.status,\n-            'completed_at': payment.completed_at.isoformat()\n+            \"net_amount\": float(payment.net_amount),\n+            \"status\": payment.status,\n+            \"completed_at\": payment.completed_at.isoformat(),\n         }\n-    \n+\n     def _validate_payment_request(self, amount: Decimal, payment_method: str):\n         \"\"\"Validate payment request with security checks\"\"\"\n         # Amount validation\n         if not isinstance(amount, Decimal):\n             raise ValueError(\"Amount must be a Decimal\")\n-        \n+\n         if amount <= 0:\n             raise ValueError(\"Payment amount must be positive\")\n-        \n-        if amount > Decimal('10000'):  # \u00a310,000 limit\n+\n+        if amount > Decimal(\"10000\"):  # \u00a310,000 limit\n             raise ValueError(\"Payment amount exceeds maximum limit (\u00a310,000)\")\n-        \n+\n         # Payment method validation\n-        valid_methods = ['card', 'cash', 'qr_code', 'apple_pay', 'google_pay']\n+        valid_methods = [\"card\", \"cash\", \"qr_code\", \"apple_pay\", \"google_pay\"]\n         if payment_method not in valid_methods:\n             raise ValueError(f\"Invalid payment method: {payment_method}\")\n-    \n-    \n+\n     def _log_action(\n         self,\n         payment_id: str,\n         action: str,\n         provider: str,\n         request_data: Optional[Dict[str, Any]] = None,\n         response_data: Optional[Dict[str, Any]] = None,\n-        error_message: Optional[str] = None\n+        error_message: Optional[str] = None,\n     ):\n         \"\"\"Log payment action for audit trail\"\"\"\n         try:\n             log_entry = PaymentAuditLog(\n                 payment_id=payment_id,\n                 action=action,\n                 provider=provider,\n-                user_id=self.request_context.get('user_id'),\n-                ip_address=self.request_context.get('ip_address'),\n-                user_agent=self.request_context.get('user_agent'),\n-                request_data=str(self._sanitize_data(request_data)) if request_data else None,\n-                response_data=str(self._sanitize_data(response_data)) if response_data else None,\n-                error_message=error_message\n+                user_id=self.request_context.get(\"user_id\"),\n+                ip_address=self.request_context.get(\"ip_address\"),\n+                user_agent=self.request_context.get(\"user_agent\"),\n+                request_data=(\n+                    str(self._sanitize_data(request_data)) if request_data else None\n+                ),\n+                response_data=(\n+                    str(self._sanitize_data(response_data)) if response_data else None\n+                ),\n+                error_message=error_message,\n             )\n             self.db.add(log_entry)\n             self.db.commit()\n         except Exception as e:\n             self.logger.error(f\"Failed to log payment action: {str(e)}\")\n-    \n+\n     def _sanitize_data(self, data: Any) -> Any:\n         \"\"\"Remove sensitive information from data before logging\"\"\"\n         if not data:\n             return data\n-        \n+\n         sensitive_keys = [\n-            'card_number', 'cvv', 'cvc', 'pin',\n-            'account_number', 'routing_number',\n-            'api_key', 'secret_key', 'access_token'\n+            \"card_number\",\n+            \"cvv\",\n+            \"cvc\",\n+            \"pin\",\n+            \"account_number\",\n+            \"routing_number\",\n+            \"api_key\",\n+            \"secret_key\",\n+            \"access_token\",\n         ]\n-        \n+\n         if isinstance(data, dict):\n             sanitized = {}\n             for key, value in data.items():\n                 if any(sensitive in key.lower() for sensitive in sensitive_keys):\n-                    sanitized[key] = '[REDACTED]'\n+                    sanitized[key] = \"[REDACTED]\"\n                 elif isinstance(value, dict):\n                     sanitized[key] = self._sanitize_data(value)\n                 elif isinstance(value, list):\n                     sanitized[key] = [self._sanitize_data(item) for item in value]\n                 else:\n                     sanitized[key] = value\n             return sanitized\n-        \n-        return data\n\\ No newline at end of file\n+\n+        return data\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/tests/services/test_ocr_service.py\t2025-08-02 19:52:26.974123+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/tests/services/test_ocr_service.py\t2025-08-02 22:36:04.077231+00:00\n@@ -4,19 +4,24 @@\n \n from app.services.ocr_service import OCRService\n \n # Sample base64 encoded strings for testing\n # These are not real images, just strings to simulate different inputs for the mock.\n-IMAGE_BASE64_MILK_RECEIPT = base64.b64encode(b\"This is a test receipt for milk and bread.\").decode('utf-8')\n-IMAGE_BASE64_OTHER_RECEIPT = base64.b64encode(b\"This is another generic receipt.\").decode('utf-8')\n-IMAGE_EMPTY_RECEIPT = base64.b64encode(b\"\").decode('utf-8')\n+IMAGE_BASE64_MILK_RECEIPT = base64.b64encode(\n+    b\"This is a test receipt for milk and bread.\"\n+).decode(\"utf-8\")\n+IMAGE_BASE64_OTHER_RECEIPT = base64.b64encode(\n+    b\"This is another generic receipt.\"\n+).decode(\"utf-8\")\n+IMAGE_EMPTY_RECEIPT = base64.b64encode(b\"\").decode(\"utf-8\")\n \n \n @pytest.fixture\n def ocr_service() -> OCRService:\n     \"\"\"Provides an instance of the OCRService for testing.\"\"\"\n     return OCRService(ocr_provider_config={\"provider\": \"mock\"})\n+\n \n @pytest.mark.asyncio\n async def test_parse_receipt_image_mock_milk_input(ocr_service: OCRService):\n     \"\"\"\n     Tests the mock OCR service's parse_receipt_image method with input\n@@ -24,11 +29,13 @@\n     \"\"\"\n     # The mock service checks if \"milk\" is in the decoded string.\n     # Let's create image_bytes that contain \"milk\".\n     image_bytes_with_milk = b\"simulated image data for a milk receipt\"\n \n-    result: List[Dict[str, Any]] = await ocr_service.parse_receipt_image(image_bytes_with_milk)\n+    result: List[Dict[str, Any]] = await ocr_service.parse_receipt_image(\n+        image_bytes_with_milk\n+    )\n \n     assert len(result) == 3\n     assert result[0][\"raw_text_name\"] == \"Milk 1L\"\n     assert result[0][\"parsed_quantity\"] == 2.0\n     assert result[0][\"parsed_price\"] == 1.50\n@@ -37,19 +44,22 @@\n     assert result[1][\"parsed_quantity\"] == 1.0\n     assert result[1][\"parsed_price\"] == 2.20\n \n     assert result[2][\"raw_text_name\"] == \"Organic Eggs\"\n \n+\n @pytest.mark.asyncio\n async def test_parse_receipt_image_mock_other_input(ocr_service: OCRService):\n     \"\"\"\n     Tests the mock OCR service's parse_receipt_image method with generic input.\n     \"\"\"\n     image_bytes_other = b\"simulated image data for another receipt\"\n-    result: List[Dict[str, Any]] = await ocr_service.parse_receipt_image(image_bytes_other)\n+    result: List[Dict[str, Any]] = await ocr_service.parse_receipt_image(\n+        image_bytes_other\n+    )\n \n-    assert len(result) == 3 # Mock currently returns 3 generic items\n+    assert len(result) == 3  # Mock currently returns 3 generic items\n     assert result[0][\"raw_text_name\"] == \"Generic Item A\"\n     assert result[0][\"parsed_quantity\"] == 1.0\n     assert result[0][\"parsed_price\"] == 10.00\n \n     assert result[1][\"raw_text_name\"] == \"Another Item B\"\n@@ -60,26 +70,34 @@\n async def test_parse_receipt_image_empty_input(ocr_service: OCRService):\n     \"\"\"\n     Tests the mock OCR service with empty image bytes.\n     \"\"\"\n     image_bytes_empty = b\"\"\n-    result: List[Dict[str, Any]] = await ocr_service.parse_receipt_image(image_bytes_empty)\n+    result: List[Dict[str, Any]] = await ocr_service.parse_receipt_image(\n+        image_bytes_empty\n+    )\n \n     # Current mock returns generic items even for empty, let's assert that.\n     # A real implementation might return an empty list or raise an error.\n     assert len(result) == 3\n     assert result[0][\"raw_text_name\"] == \"Generic Item A\"\n \n+\n def test_ocr_service_initialization():\n     \"\"\"Tests that OCRService can be initialized.\"\"\"\n     service = OCRService()\n     assert service is not None\n-    assert service.config == {\"provider\": \"mock\"} # As per get_ocr_service or direct init default\n+    assert service.config == {\n+        \"provider\": \"mock\"\n+    }  # As per get_ocr_service or direct init default\n \n-    service_with_config = OCRService(ocr_provider_config={\"provider\": \"aws\", \"key\": \"testkey\"})\n+    service_with_config = OCRService(\n+        ocr_provider_config={\"provider\": \"aws\", \"key\": \"testkey\"}\n+    )\n     assert service_with_config.config is not None\n     assert service_with_config.config[\"provider\"] == \"aws\"\n+\n \n # To run these tests (assuming pytest is set up and in the backend directory):\n # Ensure __init__.py files are present in app/tests and app/tests/services if needed for discovery.\n # Command: PYTHONPATH=. pytest app/tests/services/test_ocr_service.py\n \n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/platform_service.py\t2025-08-02 19:23:36.832654+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/platform_service.py\t2025-08-02 22:36:04.076256+00:00\n@@ -9,205 +9,220 @@\n from sqlalchemy.orm import Session\n from sqlalchemy import and_\n from jsonschema import validate, ValidationError\n \n from app.models.platform_config import (\n-    PlatformConfiguration, \n-    RestaurantOverride, \n+    PlatformConfiguration,\n+    RestaurantOverride,\n     ConfigurationAudit,\n     PlatformFeatureFlag,\n     DEFAULT_PLATFORM_CONFIGS,\n-    DEFAULT_FEATURE_FLAGS\n+    DEFAULT_FEATURE_FLAGS,\n )\n \n logger = logging.getLogger(__name__)\n+\n \n class PlatformSettingsService:\n     \"\"\"Service for managing platform-controlled settings\"\"\"\n-    \n+\n     def __init__(self, db: Session):\n         self.db = db\n-    \n+\n     async def get_platform_setting(self, config_key: str) -> Optional[Dict[str, Any]]:\n         \"\"\"Get a specific platform setting by key\"\"\"\n-        setting = self.db.query(PlatformConfiguration).filter(\n-            and_(\n-                PlatformConfiguration.config_key == config_key,\n-                PlatformConfiguration.is_active == True\n-            )\n-        ).first()\n-        \n+        setting = (\n+            self.db.query(PlatformConfiguration)\n+            .filter(\n+                and_(\n+                    PlatformConfiguration.config_key == config_key,\n+                    PlatformConfiguration.is_active == True,\n+                )\n+            )\n+            .first()\n+        )\n+\n         if not setting:\n             return None\n-        \n+\n         return {\n-            'key': setting.config_key,\n-            'value': setting.config_value,\n-            'category': setting.category,\n-            'description': setting.description,\n-            'is_sensitive': setting.is_sensitive,\n-            'updated_at': setting.updated_at.isoformat() if setting.updated_at else None\n+            \"key\": setting.config_key,\n+            \"value\": setting.config_value,\n+            \"category\": setting.category,\n+            \"description\": setting.description,\n+            \"is_sensitive\": setting.is_sensitive,\n+            \"updated_at\": (\n+                setting.updated_at.isoformat() if setting.updated_at else None\n+            ),\n         }\n-    \n+\n     async def get_platform_settings(\n-        self, \n-        category: Optional[str] = None,\n-        include_sensitive: bool = False\n+        self, category: Optional[str] = None, include_sensitive: bool = False\n     ) -> Dict[str, Any]:\n         \"\"\"Get all platform settings, optionally filtered by category\"\"\"\n-        \n+\n         query = self.db.query(PlatformConfiguration).filter(\n             PlatformConfiguration.is_active == True\n         )\n-        \n+\n         if category:\n             query = query.filter(PlatformConfiguration.category == category)\n-        \n+\n         if not include_sensitive:\n             query = query.filter(PlatformConfiguration.is_sensitive == False)\n-        \n+\n         settings = query.all()\n-        \n+\n         result = {}\n         for setting in settings:\n             result[setting.config_key] = {\n-                'value': setting.config_value,\n-                'category': setting.category,\n-                'description': setting.description,\n-                'is_sensitive': setting.is_sensitive,\n-                'updated_at': setting.updated_at.isoformat() if setting.updated_at else None\n+                \"value\": setting.config_value,\n+                \"category\": setting.category,\n+                \"description\": setting.description,\n+                \"is_sensitive\": setting.is_sensitive,\n+                \"updated_at\": (\n+                    setting.updated_at.isoformat() if setting.updated_at else None\n+                ),\n             }\n-        \n+\n         return result\n-    \n+\n     async def update_platform_setting(\n-        self, \n-        config_key: str, \n+        self,\n+        config_key: str,\n         config_value: Any,\n         updated_by: str,\n         change_reason: Optional[str] = None,\n-        change_source: str = \"api\"\n+        change_source: str = \"api\",\n     ) -> bool:\n         \"\"\"Update a platform setting with audit trail\"\"\"\n-        \n+\n         # Get existing setting\n-        setting = self.db.query(PlatformConfiguration).filter(\n-            PlatformConfiguration.config_key == config_key\n-        ).first()\n-        \n+        setting = (\n+            self.db.query(PlatformConfiguration)\n+            .filter(PlatformConfiguration.config_key == config_key)\n+            .first()\n+        )\n+\n         if not setting:\n             logger.error(f\"Platform setting '{config_key}' not found\")\n             return False\n-        \n+\n         # Validate against schema if defined\n         if setting.validation_schema:\n             try:\n                 validate(instance=config_value, schema=setting.validation_schema)\n             except ValidationError as e:\n                 logger.error(f\"Validation failed for {config_key}: {e}\")\n                 raise ValueError(f\"Invalid configuration value: {e.message}\")\n-        \n+\n         # Store old value for audit\n         old_value = setting.config_value\n-        \n+\n         # Update setting\n         setting.config_value = config_value\n         setting.updated_at = datetime.utcnow()\n         setting.updated_by = updated_by\n-        \n+\n         # Create audit record\n         audit = ConfigurationAudit(\n-            config_type='platform',\n+            config_type=\"platform\",\n             config_key=config_key,\n             entity_id=setting.id,\n             old_value=old_value,\n             new_value=config_value,\n             change_reason=change_reason,\n             change_source=change_source,\n-            changed_by=updated_by\n-        )\n-        \n+            changed_by=updated_by,\n+        )\n+\n         self.db.add(audit)\n         self.db.commit()\n-        \n+\n         logger.info(f\"Updated platform setting '{config_key}' by user {updated_by}\")\n         return True\n-    \n+\n     async def get_restaurant_effective_settings(\n-        self, \n-        restaurant_id: str,\n-        category: Optional[str] = None\n+        self, restaurant_id: str, category: Optional[str] = None\n     ) -> Dict[str, Any]:\n         \"\"\"Get effective settings for a restaurant (platform + overrides)\"\"\"\n-        \n+\n         # Get platform settings\n         platform_settings = await self.get_platform_settings(category=category)\n-        \n+\n         # Get restaurant overrides\n         query = self.db.query(RestaurantOverride).filter(\n             and_(\n                 RestaurantOverride.restaurant_id == restaurant_id,\n-                RestaurantOverride.is_approved == True\n-            )\n-        )\n-        \n+                RestaurantOverride.is_approved == True,\n+            )\n+        )\n+\n         overrides = query.all()\n-        \n+\n         # Merge settings\n         effective_settings = {}\n-        \n+\n         # Start with platform settings\n         for key, platform_config in platform_settings.items():\n             effective_settings[key] = {\n-                'value': platform_config['value'],\n-                'source': 'platform',\n-                'category': platform_config['category'],\n-                'description': platform_config['description'],\n-                'can_override': self._can_restaurant_override(key)\n+                \"value\": platform_config[\"value\"],\n+                \"source\": \"platform\",\n+                \"category\": platform_config[\"category\"],\n+                \"description\": platform_config[\"description\"],\n+                \"can_override\": self._can_restaurant_override(key),\n             }\n-        \n+\n         # Apply restaurant overrides\n         for override in overrides:\n             if override.config_key in effective_settings:\n-                effective_settings[override.config_key]['value'] = override.override_value\n-                effective_settings[override.config_key]['source'] = 'restaurant'\n-                effective_settings[override.config_key]['override_id'] = str(override.id)\n-        \n+                effective_settings[override.config_key][\n+                    \"value\"\n+                ] = override.override_value\n+                effective_settings[override.config_key][\"source\"] = \"restaurant\"\n+                effective_settings[override.config_key][\"override_id\"] = str(\n+                    override.id\n+                )\n+\n         return effective_settings\n-    \n+\n     async def set_restaurant_override(\n-        self, \n+        self,\n         restaurant_id: str,\n         config_key: str,\n         override_value: Any,\n         created_by: str,\n-        requires_approval: bool = False\n+        requires_approval: bool = False,\n     ) -> bool:\n         \"\"\"Set a restaurant override for a platform setting\"\"\"\n-        \n+\n         # Check if override is allowed\n         if not self._can_restaurant_override(config_key):\n             raise ValueError(f\"Restaurant overrides not allowed for '{config_key}'\")\n-        \n+\n         # Get platform setting to validate against limits\n         platform_setting = await self.get_platform_setting(config_key)\n         if not platform_setting:\n             raise ValueError(f\"Platform setting '{config_key}' not found\")\n-        \n+\n         # Validate override against platform limits\n         platform_limit = self._get_platform_limit(config_key)\n         if not self._validate_override(config_key, override_value, platform_limit):\n             raise ValueError(f\"Override value exceeds platform limits\")\n-        \n+\n         # Check for existing override\n-        existing = self.db.query(RestaurantOverride).filter(\n-            and_(\n-                RestaurantOverride.restaurant_id == restaurant_id,\n-                RestaurantOverride.config_key == config_key\n-            )\n-        ).first()\n-        \n+        existing = (\n+            self.db.query(RestaurantOverride)\n+            .filter(\n+                and_(\n+                    RestaurantOverride.restaurant_id == restaurant_id,\n+                    RestaurantOverride.config_key == config_key,\n+                )\n+            )\n+            .first()\n+        )\n+\n         if existing:\n             # Update existing override\n             old_value = existing.override_value\n             existing.override_value = override_value\n             existing.updated_at = datetime.utcnow()\n@@ -219,101 +234,130 @@\n                 restaurant_id=restaurant_id,\n                 config_key=config_key,\n                 override_value=override_value,\n                 platform_limit=platform_limit,\n                 is_approved=not requires_approval,\n-                created_by=created_by\n+                created_by=created_by,\n             )\n             self.db.add(override_record)\n             old_value = None\n-        \n+\n         # Create audit record\n         audit = ConfigurationAudit(\n-            config_type='restaurant',\n+            config_type=\"restaurant\",\n             config_key=config_key,\n             entity_id=restaurant_id,\n             old_value=old_value,\n             new_value=override_value,\n             change_reason=f\"Restaurant override for {config_key}\",\n             change_source=\"restaurant_api\",\n-            changed_by=created_by\n-        )\n-        \n+            changed_by=created_by,\n+        )\n+\n         self.db.add(audit)\n         self.db.commit()\n-        \n+\n         logger.info(f\"Set restaurant override for '{config_key}' by user {created_by}\")\n         return True\n-    \n+\n     async def get_feature_flags(\n-        self, \n-        restaurant_id: Optional[str] = None\n+        self, restaurant_id: Optional[str] = None\n     ) -> Dict[str, bool]:\n         \"\"\"Get feature flags, optionally for a specific restaurant\"\"\"\n-        \n+\n         flags = self.db.query(PlatformFeatureFlag).all()\n-        \n+\n         result = {}\n         for flag in flags:\n             is_enabled = flag.is_enabled\n-            \n+\n             # Check if restaurant is in targeted rollout\n             if restaurant_id and flag.target_restaurants:\n                 if restaurant_id in flag.target_restaurants:\n                     is_enabled = True\n                 elif flag.rollout_percentage < 100.0:\n                     # Use restaurant ID for consistent rollout\n                     import hashlib\n-                    hash_val = int(hashlib.md5(f\"{flag.feature_key}:{restaurant_id}\".encode()).hexdigest(), 16)\n+\n+                    hash_val = int(\n+                        hashlib.md5(\n+                            f\"{flag.feature_key}:{restaurant_id}\".encode()\n+                        ).hexdigest(),\n+                        16,\n+                    )\n                     percentage = (hash_val % 100) + 1\n                     is_enabled = percentage <= flag.rollout_percentage\n-            \n+\n             result[flag.feature_key] = is_enabled\n-        \n+\n         return result\n-    \n+\n     async def get_service_charge_config(self) -> Dict[str, Any]:\n         \"\"\"Get the consolidated service charge configuration.\"\"\"\n         config_keys = [\n             \"platform.service_charge.enabled\",\n             \"platform.service_charge.rate\",\n             \"platform.service_charge.description\",\n-            \"platform.service_charge.currency\"\n+            \"platform.service_charge.currency\",\n         ]\n \n         settings = await self.get_platform_settings(category=\"service_charge\")\n \n         # Fallback to default values if a key is missing, to prevent TypeErrors\n         # The default values are defined in DEFAULT_PLATFORM_CONFIGS in platform_config.py\n         # This ensures that even if DB initialization failed or a key was somehow deleted,\n         # we return a well-structured response.\n \n-        default_configs_map = {item['config_key']: item['config_value']['value'] for item in DEFAULT_PLATFORM_CONFIGS if item['config_key'] in config_keys}\n-\n-        enabled = settings.get(\"platform.service_charge.enabled\", {}).get('value', {}).get('value', default_configs_map.get('platform.service_charge.enabled'))\n-        rate = settings.get(\"platform.service_charge.rate\", {}).get('value', {}).get('value', default_configs_map.get('platform.service_charge.rate'))\n-        description = settings.get(\"platform.service_charge.description\", {}).get('value', {}).get('value', default_configs_map.get('platform.service_charge.description'))\n-        currency = settings.get(\"platform.service_charge.currency\", {}).get('value', {}).get('value', default_configs_map.get('platform.service_charge.currency'))\n+        default_configs_map = {\n+            item[\"config_key\"]: item[\"config_value\"][\"value\"]\n+            for item in DEFAULT_PLATFORM_CONFIGS\n+            if item[\"config_key\"] in config_keys\n+        }\n+\n+        enabled = (\n+            settings.get(\"platform.service_charge.enabled\", {})\n+            .get(\"value\", {})\n+            .get(\"value\", default_configs_map.get(\"platform.service_charge.enabled\"))\n+        )\n+        rate = (\n+            settings.get(\"platform.service_charge.rate\", {})\n+            .get(\"value\", {})\n+            .get(\"value\", default_configs_map.get(\"platform.service_charge.rate\"))\n+        )\n+        description = (\n+            settings.get(\"platform.service_charge.description\", {})\n+            .get(\"value\", {})\n+            .get(\n+                \"value\", default_configs_map.get(\"platform.service_charge.description\")\n+            )\n+        )\n+        currency = (\n+            settings.get(\"platform.service_charge.currency\", {})\n+            .get(\"value\", {})\n+            .get(\"value\", default_configs_map.get(\"platform.service_charge.currency\"))\n+        )\n \n         # Ensure correct types, especially for boolean, as get() can return None\n         if not isinstance(enabled, bool):\n-            enabled = default_configs_map.get('platform.service_charge.enabled', False) # Default to False if type is wrong\n+            enabled = default_configs_map.get(\n+                \"platform.service_charge.enabled\", False\n+            )  # Default to False if type is wrong\n \n         return {\n             \"service_charge\": {\n                 \"enabled\": enabled,\n                 \"rate\": rate,\n                 \"description\": description,\n-                \"currency\": currency\n+                \"currency\": currency,\n             }\n         }\n \n     async def update_service_charge_config(\n         self,\n         config_data: Dict[str, Any],\n         updated_by: str,\n-        change_reason: Optional[str] = None\n+        change_reason: Optional[str] = None,\n     ) -> bool:\n         \"\"\"Update service charge configuration settings.\"\"\"\n         # config_data is expected to be like:\n         # {\n         #   \"enabled\": true,\n@@ -327,265 +371,287 @@\n             config_key = f\"platform.service_charge.{key}\"\n             try:\n                 # Wrap the scalar value in a dictionary as per our storage convention\n                 success = await self.update_platform_setting(\n                     config_key=config_key,\n-                    config_value={'value': value}, # Ensure value is stored in the {'value': ...} structure\n+                    config_value={\n+                        \"value\": value\n+                    },  # Ensure value is stored in the {'value': ...} structure\n                     updated_by=updated_by,\n                     change_reason=change_reason or f\"Update to service charge {key}\",\n-                    change_source=\"service_charge_api\"\n+                    change_source=\"service_charge_api\",\n                 )\n                 if not success:\n                     all_success = False\n-                    logger.warning(f\"Failed to update service charge setting: {config_key}\")\n-            except ValueError as e: # Catch validation errors from update_platform_setting\n+                    logger.warning(\n+                        f\"Failed to update service charge setting: {config_key}\"\n+                    )\n+            except (\n+                ValueError\n+            ) as e:  # Catch validation errors from update_platform_setting\n                 logger.error(f\"Validation error updating {config_key}: {e}\")\n-                all_success = False # Consider it a failure for this key\n-                raise # Re-raise to inform the caller (API endpoint) of the bad request\n+                all_success = False  # Consider it a failure for this key\n+                raise  # Re-raise to inform the caller (API endpoint) of the bad request\n             except Exception as e:\n                 logger.error(f\"Error updating service charge setting {config_key}: {e}\")\n                 all_success = False\n \n         return all_success\n \n     async def update_feature_flag(\n-        self, \n+        self,\n         feature_key: str,\n         is_enabled: bool,\n         rollout_percentage: Optional[float] = None,\n         target_restaurants: Optional[List[str]] = None,\n-        updated_by: str = None\n+        updated_by: str = None,\n     ) -> bool:\n         \"\"\"Update a feature flag\"\"\"\n-        \n-        flag = self.db.query(PlatformFeatureFlag).filter(\n-            PlatformFeatureFlag.feature_key == feature_key\n-        ).first()\n-        \n+\n+        flag = (\n+            self.db.query(PlatformFeatureFlag)\n+            .filter(PlatformFeatureFlag.feature_key == feature_key)\n+            .first()\n+        )\n+\n         if not flag:\n             logger.error(f\"Feature flag '{feature_key}' not found\")\n             return False\n-        \n+\n         flag.is_enabled = is_enabled\n         if rollout_percentage is not None:\n             flag.rollout_percentage = rollout_percentage\n         if target_restaurants is not None:\n             flag.target_restaurants = target_restaurants\n         flag.updated_at = datetime.utcnow()\n-        \n+\n         self.db.commit()\n-        \n+\n         logger.info(f\"Updated feature flag '{feature_key}' to {is_enabled}\")\n         return True\n-    \n+\n     async def get_payment_fees(self) -> Dict[str, Dict[str, Any]]:\n         \"\"\"Get all payment processing fees\"\"\"\n-        \n-        fee_settings = await self.get_platform_settings(category='payment_fees')\n-        \n+\n+        fee_settings = await self.get_platform_settings(category=\"payment_fees\")\n+\n         fees = {}\n         for key, config in fee_settings.items():\n-            provider = key.replace('payment.fees.', '')\n-            fees[provider] = config['value']\n-        \n+            provider = key.replace(\"payment.fees.\", \"\")\n+            fees[provider] = config[\"value\"]\n+\n         return fees\n-    \n+\n     async def calculate_effective_fee(\n-        self, \n-        payment_method: str, \n+        self,\n+        payment_method: str,\n         amount: float,\n         restaurant_id: Optional[str] = None,\n-        monthly_volume: Optional[float] = None\n+        monthly_volume: Optional[float] = None,\n     ) -> Dict[str, Any]:\n         \"\"\"Calculate effective fee for a payment method\"\"\"\n-        \n+\n         # Get platform fee configuration\n-        fee_config = await self.get_platform_setting(f'payment.fees.{payment_method}')\n+        fee_config = await self.get_platform_setting(f\"payment.fees.{payment_method}\")\n         if not fee_config:\n-            raise ValueError(f\"No fee configuration for payment method '{payment_method}'\")\n-        \n-        fee_data = fee_config['value']\n-        \n+            raise ValueError(\n+                f\"No fee configuration for payment method '{payment_method}'\"\n+            )\n+\n+        fee_data = fee_config[\"value\"]\n+\n         # Calculate base platform fee\n-        if payment_method == 'sumup' and monthly_volume:\n+        if payment_method == \"sumup\" and monthly_volume:\n             # SumUp has volume-based pricing\n-            if monthly_volume >= fee_data.get('high_volume', {}).get('threshold', 2714):\n-                percentage = fee_data['high_volume']['percentage']\n-                monthly_fee = fee_data['high_volume']['monthly_fee']\n+            if monthly_volume >= fee_data.get(\"high_volume\", {}).get(\"threshold\", 2714):\n+                percentage = fee_data[\"high_volume\"][\"percentage\"]\n+                monthly_fee = fee_data[\"high_volume\"][\"monthly_fee\"]\n                 # Estimate monthly fee per transaction\n-                estimated_transactions = monthly_volume / (amount or 50)  # Assume avg \u00a350 transaction\n+                estimated_transactions = monthly_volume / (\n+                    amount or 50\n+                )  # Assume avg \u00a350 transaction\n                 fee_per_transaction = monthly_fee / max(estimated_transactions, 1)\n                 total_fee = (amount * percentage / 100) + fee_per_transaction\n             else:\n-                percentage = fee_data['standard']['percentage']\n+                percentage = fee_data[\"standard\"][\"percentage\"]\n                 total_fee = amount * percentage / 100\n         else:\n             # Standard percentage + fixed fee\n-            percentage = fee_data.get('percentage', 0)\n-            fixed_fee = fee_data.get('fixed_fee', 0)\n+            percentage = fee_data.get(\"percentage\", 0)\n+            fixed_fee = fee_data.get(\"fixed_fee\", 0)\n             total_fee = (amount * percentage / 100) + fixed_fee\n-        \n+\n         # Check for restaurant markup (if allowed)\n         restaurant_markup = 0.0\n         if restaurant_id:\n             effective_settings = await self.get_restaurant_effective_settings(\n-                restaurant_id, category='payment_fees'\n-            )\n-            markup_key = f'payment.markup.{payment_method}'\n+                restaurant_id, category=\"payment_fees\"\n+            )\n+            markup_key = f\"payment.markup.{payment_method}\"\n             if markup_key in effective_settings:\n-                restaurant_markup = effective_settings[markup_key]['value'].get('percentage', 0)\n-        \n+                restaurant_markup = effective_settings[markup_key][\"value\"].get(\n+                    \"percentage\", 0\n+                )\n+\n         effective_fee = total_fee + (amount * restaurant_markup / 100)\n-        \n+\n         return {\n-            'payment_method': payment_method,\n-            'amount': amount,\n-            'platform_fee': total_fee,\n-            'restaurant_markup': restaurant_markup,\n-            'effective_fee': effective_fee,\n-            'fee_percentage': (effective_fee / amount * 100) if amount > 0 else 0,\n-            'currency': fee_data.get('currency', 'GBP')\n+            \"payment_method\": payment_method,\n+            \"amount\": amount,\n+            \"platform_fee\": total_fee,\n+            \"restaurant_markup\": restaurant_markup,\n+            \"effective_fee\": effective_fee,\n+            \"fee_percentage\": (effective_fee / amount * 100) if amount > 0 else 0,\n+            \"currency\": fee_data.get(\"currency\", \"GBP\"),\n         }\n-    \n+\n     def _can_restaurant_override(self, config_key: str) -> bool:\n         \"\"\"Check if restaurants can override a specific platform setting\"\"\"\n-        \n+\n         # Settings that restaurants can override (with limits)\n         allowed_overrides = [\n-            'payment.markup.*',  # Small markup on payment fees\n-            'business.discount.maximum',  # Within platform limits\n-            'ui.theme.*',  # UI customization\n-            'receipt.customization.*',  # Receipt templates\n+            \"payment.markup.*\",  # Small markup on payment fees\n+            \"business.discount.maximum\",  # Within platform limits\n+            \"ui.theme.*\",  # UI customization\n+            \"receipt.customization.*\",  # Receipt templates\n         ]\n-        \n+\n         # Payment fees and security settings cannot be overridden\n         forbidden_overrides = [\n-            'payment.fees.*',\n-            'security.*',\n-            'compliance.*',\n-            'features.*'\n+            \"payment.fees.*\",\n+            \"security.*\",\n+            \"compliance.*\",\n+            \"features.*\",\n         ]\n-        \n+\n         # Check forbidden first\n         for pattern in forbidden_overrides:\n             if self._matches_pattern(config_key, pattern):\n                 return False\n-        \n+\n         # Check allowed\n         for pattern in allowed_overrides:\n             if self._matches_pattern(config_key, pattern):\n                 return True\n-        \n+\n         return False\n-    \n+\n     def _matches_pattern(self, config_key: str, pattern: str) -> bool:\n         \"\"\"Check if config key matches a wildcard pattern\"\"\"\n-        if pattern.endswith('*'):\n+        if pattern.endswith(\"*\"):\n             prefix = pattern[:-1]\n             return config_key.startswith(prefix)\n         return config_key == pattern\n-    \n+\n     def _get_platform_limit(self, config_key: str) -> Optional[Dict[str, Any]]:\n         \"\"\"Get platform-defined limits for restaurant overrides\"\"\"\n-        \n+\n         limits = {\n-            'payment.markup.qr_code': {'max_percentage': 0.5},\n-            'payment.markup.stripe': {'max_percentage': 0.3},\n-            'payment.markup.square': {'max_percentage': 0.3},\n-            'business.discount.maximum': {'max_percentage': 50.0},\n+            \"payment.markup.qr_code\": {\"max_percentage\": 0.5},\n+            \"payment.markup.stripe\": {\"max_percentage\": 0.3},\n+            \"payment.markup.square\": {\"max_percentage\": 0.3},\n+            \"business.discount.maximum\": {\"max_percentage\": 50.0},\n         }\n-        \n+\n         return limits.get(config_key)\n-    \n+\n     def _validate_override(\n-        self, \n-        config_key: str, \n-        override_value: Any, \n-        platform_limit: Optional[Dict[str, Any]]\n+        self,\n+        config_key: str,\n+        override_value: Any,\n+        platform_limit: Optional[Dict[str, Any]],\n     ) -> bool:\n         \"\"\"Validate restaurant override against platform limits\"\"\"\n-        \n+\n         if not platform_limit:\n             return True\n-        \n-        if config_key.startswith('payment.markup.'):\n-            max_percentage = platform_limit.get('max_percentage', 0)\n-            value_percentage = override_value.get('percentage', 0)\n+\n+        if config_key.startswith(\"payment.markup.\"):\n+            max_percentage = platform_limit.get(\"max_percentage\", 0)\n+            value_percentage = override_value.get(\"percentage\", 0)\n             return value_percentage <= max_percentage\n-        \n-        if config_key == 'business.discount.maximum':\n-            max_percentage = platform_limit.get('max_percentage', 100)\n-            return override_value.get('percentage', 0) <= max_percentage\n-        \n+\n+        if config_key == \"business.discount.maximum\":\n+            max_percentage = platform_limit.get(\"max_percentage\", 100)\n+            return override_value.get(\"percentage\", 0) <= max_percentage\n+\n         return True\n-    \n+\n     async def initialize_default_settings(self) -> bool:\n         \"\"\"Initialize platform with default configurations\"\"\"\n-        \n+\n         try:\n             # Add default platform configurations\n             for config_data in DEFAULT_PLATFORM_CONFIGS:\n-                existing = self.db.query(PlatformConfiguration).filter(\n-                    PlatformConfiguration.config_key == config_data['config_key']\n-                ).first()\n-                \n+                existing = (\n+                    self.db.query(PlatformConfiguration)\n+                    .filter(\n+                        PlatformConfiguration.config_key == config_data[\"config_key\"]\n+                    )\n+                    .first()\n+                )\n+\n                 if not existing:\n                     config = PlatformConfiguration(**config_data)\n                     self.db.add(config)\n-            \n+\n             # Add default feature flags\n             for flag_data in DEFAULT_FEATURE_FLAGS:\n-                existing = self.db.query(PlatformFeatureFlag).filter(\n-                    PlatformFeatureFlag.feature_key == flag_data['feature_key']\n-                ).first()\n-                \n+                existing = (\n+                    self.db.query(PlatformFeatureFlag)\n+                    .filter(PlatformFeatureFlag.feature_key == flag_data[\"feature_key\"])\n+                    .first()\n+                )\n+\n                 if not existing:\n                     flag = PlatformFeatureFlag(**flag_data)\n                     self.db.add(flag)\n-            \n+\n             self.db.commit()\n             logger.info(\"Default platform settings initialized successfully\")\n             return True\n-            \n+\n         except Exception as e:\n             logger.error(f\"Failed to initialize default settings: {e}\")\n             self.db.rollback()\n             return False\n-    \n+\n     async def get_audit_trail(\n-        self, \n+        self,\n         config_key: Optional[str] = None,\n         entity_id: Optional[str] = None,\n-        limit: int = 100\n+        limit: int = 100,\n     ) -> List[Dict[str, Any]]:\n         \"\"\"Get configuration audit trail\"\"\"\n-        \n+\n         query = self.db.query(ConfigurationAudit).order_by(\n             ConfigurationAudit.changed_at.desc()\n         )\n-        \n+\n         if config_key:\n             query = query.filter(ConfigurationAudit.config_key == config_key)\n-        \n+\n         if entity_id:\n             query = query.filter(ConfigurationAudit.entity_id == entity_id)\n-        \n+\n         audit_records = query.limit(limit).all()\n-        \n+\n         result = []\n         for record in audit_records:\n-            result.append({\n-                'id': str(record.id),\n-                'config_type': record.config_type,\n-                'config_key': record.config_key,\n-                'entity_id': str(record.entity_id) if record.entity_id else None,\n-                'old_value': record.old_value,\n-                'new_value': record.new_value,\n-                'change_reason': record.change_reason,\n-                'change_source': record.change_source,\n-                'changed_by': str(record.changed_by),\n-                'changed_at': record.changed_at.isoformat(),\n-                'ip_address': record.ip_address,\n-                'user_agent': record.user_agent\n-            })\n-        \n-        return result\n\\ No newline at end of file\n+            result.append(\n+                {\n+                    \"id\": str(record.id),\n+                    \"config_type\": record.config_type,\n+                    \"config_key\": record.config_key,\n+                    \"entity_id\": str(record.entity_id) if record.entity_id else None,\n+                    \"old_value\": record.old_value,\n+                    \"new_value\": record.new_value,\n+                    \"change_reason\": record.change_reason,\n+                    \"change_source\": record.change_source,\n+                    \"changed_by\": str(record.changed_by),\n+                    \"changed_at\": record.changed_at.isoformat(),\n+                    \"ip_address\": record.ip_address,\n+                    \"user_agent\": record.user_agent,\n+                }\n+            )\n+\n+        return result\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/sync_service.py\t2025-08-02 22:09:03.048838+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/sync_service.py\t2025-08-02 22:36:04.082076+00:00\n@@ -1,9 +1,10 @@\n \"\"\"\n Bidirectional Sync Service\n Handles data synchronization between platform dashboard and restaurant mobile apps\n \"\"\"\n+\n from typing import Dict, List, Optional, Any, TYPE_CHECKING\n from datetime import datetime\n import asyncio\n import json\n from sqlalchemy.orm import Session\n@@ -19,311 +20,302 @@\n logger = logging.getLogger(__name__)\n \n if TYPE_CHECKING:\n     from app.api.v1.endpoints.websocket_enhanced import EnhancedWebSocketManager\n \n+\n class SyncService:\n     \"\"\"\n     Manages bidirectional data synchronization between platform and restaurants\n     \"\"\"\n-    \n+\n     def __init__(self):\n         self.redis_client: Optional[Redis] = None\n-        self.ws_manager: Optional['EnhancedWebSocketManager'] = None\n+        self.ws_manager: Optional[\"EnhancedWebSocketManager\"] = None\n         self._sync_queue: asyncio.Queue = asyncio.Queue()\n         self._processing = False\n-        \n-    async def initialize(self, ws_manager: 'EnhancedWebSocketManager'):\n+\n+    async def initialize(self, ws_manager: \"EnhancedWebSocketManager\"):\n         \"\"\"Initialize sync service with dependencies\"\"\"\n         self.redis_client = global_redis_client\n         self.ws_manager = ws_manager\n         self._processing = True\n-        \n+\n         # Start background sync processor\n         asyncio.create_task(self._process_sync_queue())\n-        \n+\n     async def shutdown(self):\n         \"\"\"Gracefully shutdown sync service\"\"\"\n         self._processing = False\n-        \n+\n     async def sync_restaurant_update(\n-        self, \n-        restaurant_id: str, \n+        self,\n+        restaurant_id: str,\n         update_type: str,\n         data: Dict[str, Any],\n         source: str,  # 'platform' or 'mobile'\n-        db: Session\n+        db: Session,\n     ):\n         \"\"\"\n         Sync restaurant updates between platform and mobile\n         \"\"\"\n         try:\n             # Add to sync queue\n             sync_event = {\n-                'id': f\"sync_{datetime.utcnow().timestamp()}\",\n-                'restaurant_id': restaurant_id,\n-                'type': update_type,\n-                'data': data,\n-                'source': source,\n-                'timestamp': datetime.utcnow().isoformat()\n-            }\n-            \n+                \"id\": f\"sync_{datetime.utcnow().timestamp()}\",\n+                \"restaurant_id\": restaurant_id,\n+                \"type\": update_type,\n+                \"data\": data,\n+                \"source\": source,\n+                \"timestamp\": datetime.utcnow().isoformat(),\n+            }\n+\n             await self._sync_queue.put(sync_event)\n-            \n+\n             # Cache the update for conflict resolution\n             cache_key = f\"sync:restaurant:{restaurant_id}:{update_type}\"\n             await self.redis_client.set(\n-                cache_key,\n-                json.dumps(sync_event),\n-                expire=300  # 5 minute TTL\n+                cache_key, json.dumps(sync_event), expire=300  # 5 minute TTL\n             )\n-            \n-            logger.info(f\"Queued sync event: {update_type} for restaurant {restaurant_id}\")\n-            \n+\n+            logger.info(\n+                f\"Queued sync event: {update_type} for restaurant {restaurant_id}\"\n+            )\n+\n         except Exception as e:\n             logger.error(f\"Error queuing sync event: {str(e)}\")\n             raise FynloException(f\"Sync failed: {str(e)}\", status_code=500)\n-    \n+\n     async def _process_sync_queue(self):\n         \"\"\"Background task to process sync events\"\"\"\n         while self._processing:\n             try:\n                 # Get sync event from queue\n-                sync_event = await asyncio.wait_for(\n-                    self._sync_queue.get(), \n-                    timeout=1.0\n-                )\n-                \n+                sync_event = await asyncio.wait_for(self._sync_queue.get(), timeout=1.0)\n+\n                 await self._handle_sync_event(sync_event)\n-                \n+\n             except asyncio.TimeoutError:\n                 continue\n             except Exception as e:\n                 logger.error(f\"Error processing sync queue: {str(e)}\")\n-                \n+\n     async def _handle_sync_event(self, event: Dict[str, Any]):\n         \"\"\"Process individual sync event\"\"\"\n         try:\n-            restaurant_id = event['restaurant_id']\n-            event_type = event['type']\n-            source = event['source']\n-            \n+            restaurant_id = event[\"restaurant_id\"]\n+            event_type = event[\"type\"]\n+            source = event[\"source\"]\n+\n             # Determine targets based on source\n-            if source == 'platform':\n+            if source == \"platform\":\n                 # Sync to mobile apps\n                 await self._sync_to_mobile(restaurant_id, event)\n-            elif source == 'mobile':\n-                # Sync to platform dashboard  \n+            elif source == \"mobile\":\n+                # Sync to platform dashboard\n                 await self._sync_to_platform(restaurant_id, event)\n             else:\n                 # Sync to both\n                 await self._sync_to_mobile(restaurant_id, event)\n                 await self._sync_to_platform(restaurant_id, event)\n-                \n-            logger.info(f\"Processed sync event: {event_type} for restaurant {restaurant_id}\")\n-            \n+\n+            logger.info(\n+                f\"Processed sync event: {event_type} for restaurant {restaurant_id}\"\n+            )\n+\n         except Exception as e:\n             logger.error(f\"Error handling sync event: {str(e)}\")\n-            \n+\n     async def _sync_to_mobile(self, restaurant_id: str, event: Dict[str, Any]):\n         \"\"\"Send sync event to mobile apps\"\"\"\n         if not self.ws_manager:\n             return\n-            \n+\n         # Get connected mobile clients for restaurant\n         connections = self.ws_manager.get_restaurant_connections(restaurant_id)\n         mobile_connections = [\n-            conn for conn in connections \n-            if conn.client_type == 'mobile_pos'\n+            conn for conn in connections if conn.client_type == \"mobile_pos\"\n         ]\n-        \n+\n         if mobile_connections:\n             message = {\n-                'type': f\"sync.{event['type']}\",\n-                'data': event['data'],\n-                'source': 'platform',\n-                'timestamp': event['timestamp']\n-            }\n-            \n+                \"type\": f\"sync.{event['type']}\",\n+                \"data\": event[\"data\"],\n+                \"source\": \"platform\",\n+                \"timestamp\": event[\"timestamp\"],\n+            }\n+\n             # Broadcast to all mobile clients\n             for connection in mobile_connections:\n-                await self.ws_manager.send_to_connection(\n-                    connection.id,\n-                    message\n-                )\n-                \n+                await self.ws_manager.send_to_connection(connection.id, message)\n+\n     async def _sync_to_platform(self, restaurant_id: str, event: Dict[str, Any]):\n         \"\"\"Send sync event to platform dashboard\"\"\"\n         if not self.ws_manager:\n             return\n-            \n+\n         # Get platform connections\n         platform_connections = self.ws_manager.get_platform_connections()\n-        \n+\n         if platform_connections:\n             message = {\n-                'type': f\"sync.{event['type']}\",\n-                'data': event['data'],\n-                'restaurant_id': restaurant_id,\n-                'source': 'mobile',\n-                'timestamp': event['timestamp']\n-            }\n-            \n+                \"type\": f\"sync.{event['type']}\",\n+                \"data\": event[\"data\"],\n+                \"restaurant_id\": restaurant_id,\n+                \"source\": \"mobile\",\n+                \"timestamp\": event[\"timestamp\"],\n+            }\n+\n             # Broadcast to all platform dashboards\n             for connection in platform_connections:\n-                await self.ws_manager.send_to_connection(\n-                    connection.id,\n-                    message\n-                )\n-    \n+                await self.ws_manager.send_to_connection(connection.id, message)\n+\n     async def sync_menu_changes(\n         self,\n         restaurant_id: str,\n         products: List[Dict[str, Any]],\n         categories: List[Dict[str, Any]],\n         source: str,\n-        db: Session\n+        db: Session,\n     ):\n         \"\"\"Sync menu changes between platform and mobile\"\"\"\n         sync_data = {\n-            'products': products,\n-            'categories': categories,\n-            'updated_at': datetime.utcnow().isoformat()\n+            \"products\": products,\n+            \"categories\": categories,\n+            \"updated_at\": datetime.utcnow().isoformat(),\n         }\n-        \n+\n         await self.sync_restaurant_update(\n             restaurant_id=restaurant_id,\n-            update_type='menu_update',\n+            update_type=\"menu_update\",\n             data=sync_data,\n             source=source,\n-            db=db\n+            db=db,\n         )\n-        \n+\n     async def sync_order_update(\n-        self,\n-        restaurant_id: str,\n-        order: Dict[str, Any],\n-        source: str,\n-        db: Session\n+        self, restaurant_id: str, order: Dict[str, Any], source: str, db: Session\n     ):\n         \"\"\"Sync order updates in real-time\"\"\"\n         await self.sync_restaurant_update(\n             restaurant_id=restaurant_id,\n-            update_type='order_update', \n+            update_type=\"order_update\",\n             data=order,\n             source=source,\n-            db=db\n+            db=db,\n         )\n-        \n+\n     async def sync_settings_change(\n-        self,\n-        restaurant_id: str,\n-        settings: Dict[str, Any],\n-        source: str,\n-        db: Session\n+        self, restaurant_id: str, settings: Dict[str, Any], source: str, db: Session\n     ):\n         \"\"\"Sync restaurant settings changes\"\"\"\n         # Filter out platform-controlled settings\n         allowed_settings = {\n-            k: v for k, v in settings.items()\n-            if k not in ['service_charge', 'payment_methods', 'commission_rate']\n+            k: v\n+            for k, v in settings.items()\n+            if k not in [\"service_charge\", \"payment_methods\", \"commission_rate\"]\n         }\n-        \n+\n         if allowed_settings:\n             await self.sync_restaurant_update(\n                 restaurant_id=restaurant_id,\n-                update_type='settings_update',\n+                update_type=\"settings_update\",\n                 data=allowed_settings,\n                 source=source,\n-                db=db\n+                db=db,\n             )\n-    \n+\n     async def handle_sync_conflict(\n         self,\n         restaurant_id: str,\n         conflict_type: str,\n         platform_data: Dict[str, Any],\n         mobile_data: Dict[str, Any],\n-        db: Session\n+        db: Session,\n     ) -> Dict[str, Any]:\n         \"\"\"\n         Handle sync conflicts between platform and mobile\n         Default strategy: Last write wins with notification\n         \"\"\"\n-        platform_timestamp = platform_data.get('updated_at', '')\n-        mobile_timestamp = mobile_data.get('updated_at', '')\n-        \n+        platform_timestamp = platform_data.get(\"updated_at\", \"\")\n+        mobile_timestamp = mobile_data.get(\"updated_at\", \"\")\n+\n         # Compare timestamps\n         if platform_timestamp > mobile_timestamp:\n-            winner = 'platform'\n+            winner = \"platform\"\n             resolved_data = platform_data\n         else:\n-            winner = 'mobile' \n+            winner = \"mobile\"\n             resolved_data = mobile_data\n-            \n+\n         # Log conflict resolution\n         logger.warning(\n             f\"Sync conflict resolved for restaurant {restaurant_id}: \"\n             f\"{conflict_type} - {winner} data wins\"\n         )\n-        \n+\n         # Notify both sides of conflict resolution\n         conflict_message = {\n-            'type': 'sync.conflict_resolved',\n-            'data': {\n-                'conflict_type': conflict_type,\n-                'winner': winner,\n-                'resolved_data': resolved_data\n+            \"type\": \"sync.conflict_resolved\",\n+            \"data\": {\n+                \"conflict_type\": conflict_type,\n+                \"winner\": winner,\n+                \"resolved_data\": resolved_data,\n             },\n-            'restaurant_id': restaurant_id,\n-            'timestamp': datetime.utcnow().isoformat()\n+            \"restaurant_id\": restaurant_id,\n+            \"timestamp\": datetime.utcnow().isoformat(),\n         }\n-        \n+\n         # Send to both platform and mobile\n         await self._sync_to_mobile(restaurant_id, conflict_message)\n         await self._sync_to_platform(restaurant_id, conflict_message)\n-        \n+\n         return resolved_data\n-    \n-    async def get_sync_status(\n-        self, \n-        restaurant_id: str\n-    ) -> Dict[str, Any]:\n+\n+    async def get_sync_status(self, restaurant_id: str) -> Dict[str, Any]:\n         \"\"\"Get current sync status for a restaurant\"\"\"\n         try:\n             # Check pending sync events\n             pending_count = self._sync_queue.qsize()\n-            \n+\n             # Check last sync times from cache\n             menu_sync_key = f\"sync:restaurant:{restaurant_id}:menu_update\"\n-            order_sync_key = f\"sync:restaurant:{restaurant_id}:order_update\" \n+            order_sync_key = f\"sync:restaurant:{restaurant_id}:order_update\"\n             settings_sync_key = f\"sync:restaurant:{restaurant_id}:settings_update\"\n-            \n+\n             last_menu_sync = await self.redis_client.get(menu_sync_key)\n             last_order_sync = await self.redis_client.get(order_sync_key)\n             last_settings_sync = await self.redis_client.get(settings_sync_key)\n-            \n+\n             return {\n-                'restaurant_id': restaurant_id,\n-                'pending_syncs': pending_count,\n-                'last_sync_times': {\n-                    'menu': last_menu_sync.get('timestamp') if last_menu_sync else None,\n-                    'orders': last_order_sync.get('timestamp') if last_order_sync else None,\n-                    'settings': last_settings_sync.get('timestamp') if last_settings_sync else None\n+                \"restaurant_id\": restaurant_id,\n+                \"pending_syncs\": pending_count,\n+                \"last_sync_times\": {\n+                    \"menu\": last_menu_sync.get(\"timestamp\") if last_menu_sync else None,\n+                    \"orders\": (\n+                        last_order_sync.get(\"timestamp\") if last_order_sync else None\n+                    ),\n+                    \"settings\": (\n+                        last_settings_sync.get(\"timestamp\")\n+                        if last_settings_sync\n+                        else None\n+                    ),\n                 },\n-                'sync_healthy': pending_count < 100  # Threshold for healthy sync\n-            }\n-            \n+                \"sync_healthy\": pending_count < 100,  # Threshold for healthy sync\n+            }\n+\n         except Exception as e:\n             logger.error(f\"Error getting sync status: {str(e)}\")\n             return {\n-                'restaurant_id': restaurant_id,\n-                'error': str(e),\n-                'sync_healthy': False\n-            }\n+                \"restaurant_id\": restaurant_id,\n+                \"error\": str(e),\n+                \"sync_healthy\": False,\n+            }\n+\n \n # Global sync service instance\n sync_service = SyncService()\n \n+\n async def get_sync_service() -> SyncService:\n     \"\"\"Get sync service instance\"\"\"\n-    return sync_service\n\\ No newline at end of file\n+    return sync_service\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/simple_main.py\t2025-08-02 19:23:36.834338+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/simple_main.py\t2025-08-02 22:36:04.096537+00:00\n@@ -26,20 +26,25 @@\n     allow_headers=[\"*\"],\n )\n \n # Database connection - Use environment variable or fallback to localhost for development\n import os\n-DATABASE_URL = os.getenv(\"DATABASE_URL\", \"postgresql://fynlo_user:fynlo_password@localhost/fynlo_pos\")\n+\n+DATABASE_URL = os.getenv(\n+    \"DATABASE_URL\", \"postgresql://fynlo_user:fynlo_password@localhost/fynlo_pos\"\n+)\n+\n \n def get_db_connection():\n     \"\"\"Get database connection\"\"\"\n     try:\n         conn = psycopg2.connect(DATABASE_URL, cursor_factory=RealDictCursor)\n         return conn\n     except Exception as e:\n         logger.error(f\"Database connection failed: {e}\")\n         return None\n+\n \n @app.get(\"/health\")\n async def health_check():\n     \"\"\"Health check endpoint with database connectivity\"\"\"\n     try:\n@@ -47,95 +52,105 @@\n         if conn:\n             with conn.cursor() as cursor:\n                 cursor.execute(\"SELECT version();\")\n                 db_version = cursor.fetchone()\n             conn.close()\n-            \n+\n             return {\n                 \"status\": \"healthy\",\n                 \"timestamp\": datetime.now().isoformat(),\n                 \"database\": \"connected\",\n-                \"db_version\": db_version['version'] if db_version else \"unknown\"\n+                \"db_version\": db_version[\"version\"] if db_version else \"unknown\",\n             }\n         else:\n             return {\n                 \"status\": \"degraded\",\n                 \"timestamp\": datetime.now().isoformat(),\n-                \"database\": \"disconnected\"\n+                \"database\": \"disconnected\",\n             }\n     except Exception as e:\n         logger.error(f\"Health check error: {e}\")\n         return {\n             \"status\": \"unhealthy\",\n             \"timestamp\": datetime.now().isoformat(),\n-            \"error\": str(e)\n-        }\n+            \"error\": str(e),\n+        }\n+\n \n @app.get(\"/\")\n async def root():\n     \"\"\"Root endpoint\"\"\"\n-    return {\"message\": \"Fynlo POS Backend API\", \"status\": \"running\", \"timestamp\": datetime.now().isoformat()}\n+    return {\n+        \"message\": \"Fynlo POS Backend API\",\n+        \"status\": \"running\",\n+        \"timestamp\": datetime.now().isoformat(),\n+    }\n+\n \n @app.get(\"/api/v1/platform/settings/service-charge\")\n async def get_service_charge():\n     \"\"\"Get platform service charge setting\"\"\"\n     try:\n         conn = get_db_connection()\n         if not conn:\n             return {\"error\": \"Database connection failed\", \"default_rate\": 12.5}\n-        \n+\n         # For now, return a default value - later we'll read from database\n         return {\n             \"enabled\": True,\n             \"rate\": 12.5,\n             \"timestamp\": datetime.now().isoformat(),\n-            \"source\": \"platform_default\"\n+            \"source\": \"platform_default\",\n         }\n     except Exception as e:\n         logger.error(f\"Service charge get error: {e}\")\n         return {\"error\": str(e), \"default_rate\": 12.5}\n+\n \n @app.post(\"/api/v1/platform/settings/service-charge\")\n async def update_service_charge(data: dict):\n     \"\"\"Update platform service charge setting\"\"\"\n     try:\n         rate = data.get(\"rate\", 12.5)\n         enabled = data.get(\"enabled\", True)\n-        \n+\n         logger.info(f\"\ud83d\udcca Service charge update request: {rate}% enabled={enabled}\")\n-        \n+\n         # For now, just log the change - later we'll save to database\n         return {\n             \"success\": True,\n             \"rate\": rate,\n             \"enabled\": enabled,\n             \"timestamp\": datetime.now().isoformat(),\n-            \"message\": f\"Service charge updated to {rate}%\"\n+            \"message\": f\"Service charge updated to {rate}%\",\n         }\n     except Exception as e:\n         logger.error(f\"Service charge update error: {e}\")\n         return {\"error\": str(e), \"success\": False}\n+\n \n # Also add legacy endpoints without /v1 for direct testing\n @app.get(\"/api/platform/settings/service-charge\")\n async def get_service_charge_legacy():\n     \"\"\"Legacy endpoint for direct testing\"\"\"\n     return await get_service_charge()\n \n+\n @app.post(\"/api/platform/settings/service-charge\")\n async def update_service_charge_legacy(data: dict):\n     \"\"\"Legacy endpoint for direct testing\"\"\"\n     return await update_service_charge(data)\n \n+\n # Restaurant Management Endpoints\n @app.get(\"/api/v1/platform/restaurants/{platform_owner_id}\")\n async def get_platform_restaurants(platform_owner_id: str):\n     \"\"\"Get all restaurants for a platform owner\"\"\"\n     try:\n         logger.info(f\"\ud83d\udcca Returning restaurants for platform owner: {platform_owner_id}\")\n-        \n-                # For now, return mock data from backend\n+\n+        # For now, return mock data from backend\n         restaurants_data = {\n             \"restaurants\": [\n                 {\n                     \"id\": \"restaurant1\",\n                     \"name\": \"Fynlo Mexican Restaurant\",\n@@ -161,14 +176,14 @@\n                     \"theme\": \"clover\",\n                     \"primaryColor\": \"#00A651\",\n                     \"todayTransactions\": 47,\n                     \"todayRevenue\": 1280,\n                     \"activeOrders\": 3,\n-                    \"averageOrderValue\": 27.23\n+                    \"averageOrderValue\": 27.23,\n                 },\n                 {\n-                    \"id\": \"restaurant2\", \n+                    \"id\": \"restaurant2\",\n                     \"name\": \"Fynlo Pizza Palace\",\n                     \"displayName\": \"Fynlo Pizza Palace\",\n                     \"businessType\": \"restaurant\",\n                     \"address\": \"456 Main Street, Manchester, M1 2AB\",\n                     \"phone\": \"+44 161 234 5678\",\n@@ -190,22 +205,22 @@\n                     \"theme\": \"clover\",\n                     \"primaryColor\": \"#00A651\",\n                     \"todayTransactions\": 32,\n                     \"todayRevenue\": 890,\n                     \"activeOrders\": 1,\n-                    \"averageOrderValue\": 27.81\n+                    \"averageOrderValue\": 27.81,\n                 },\n                 {\n                     \"id\": \"restaurant3\",\n-                    \"name\": \"Fynlo Burger Bar\", \n+                    \"name\": \"Fynlo Burger Bar\",\n                     \"displayName\": \"Fynlo Burger Bar\",\n                     \"businessType\": \"restaurant\",\n                     \"address\": \"789 Broadway, Birmingham, B1 3CD\",\n                     \"phone\": \"+44 121 987 6543\",\n                     \"email\": \"burgers@fynlopos.com\",\n                     \"website\": \"https://fynloburgers.com\",\n-                    \"vatNumber\": \"GB456789123\", \n+                    \"vatNumber\": \"GB456789123\",\n                     \"registrationNumber\": \"45678912\",\n                     \"platformOwnerId\": platform_owner_id,\n                     \"ownerId\": \"owner_burger_1\",\n                     \"subscriptionTier\": \"enterprise\",\n                     \"currency\": \"GBP\",\n@@ -219,72 +234,79 @@\n                     \"theme\": \"clover\",\n                     \"primaryColor\": \"#00A651\",\n                     \"todayTransactions\": 28,\n                     \"todayRevenue\": 920,\n                     \"activeOrders\": 2,\n-                    \"averageOrderValue\": 32.86\n-                }\n+                    \"averageOrderValue\": 32.86,\n+                },\n             ],\n             \"total\": 3,\n-            \"source\": \"real_backend_api\"\n+            \"source\": \"real_backend_api\",\n         }\n         return restaurants_data\n-        \n+\n     except Exception as e:\n         logger.error(f\"Restaurant fetch error: {e}\")\n         return {\"error\": str(e), \"restaurants\": []}\n+\n \n @app.post(\"/api/v1/platform/restaurants\")\n async def create_restaurant(restaurant_data: dict):\n     \"\"\"Create a new restaurant for the platform\"\"\"\n     try:\n-        logger.info(f\"\ud83d\udcca Creating new restaurant: {restaurant_data.get('name', 'Unknown')}\")\n-        \n-                # For now, just return success\n+        logger.info(\n+            f\"\ud83d\udcca Creating new restaurant: {restaurant_data.get('name', 'Unknown')}\"\n+        )\n+\n+        # For now, just return success\n         return {\n             \"success\": True,\n             \"restaurant_id\": f\"restaurant_{datetime.now().timestamp()}\",\n             \"message\": \"Restaurant created successfully\",\n-            \"timestamp\": datetime.now().isoformat()\n+            \"timestamp\": datetime.now().isoformat(),\n         }\n     except Exception as e:\n         logger.error(f\"Restaurant creation error: {e}\")\n         return {\"error\": str(e), \"success\": False}\n+\n \n @app.put(\"/api/v1/platform/restaurants/{restaurant_id}\")\n async def update_restaurant(restaurant_id: str, restaurant_data: dict):\n     \"\"\"Update restaurant data\"\"\"\n     try:\n         logger.info(f\"\ud83d\udcca Updating restaurant: {restaurant_id}\")\n-        \n-                # For now, just return success\n+\n+        # For now, just return success\n         return {\n             \"success\": True,\n             \"restaurant_id\": restaurant_id,\n             \"message\": \"Restaurant updated successfully\",\n-            \"timestamp\": datetime.now().isoformat()\n+            \"timestamp\": datetime.now().isoformat(),\n         }\n     except Exception as e:\n         logger.error(f\"Restaurant update error: {e}\")\n         return {\"error\": str(e), \"success\": False}\n+\n \n @app.get(\"/api/v1/restaurants/{restaurant_id}\")\n async def get_restaurant_details(restaurant_id: str):\n     \"\"\"Get specific restaurant details\"\"\"\n     try:\n         logger.info(f\"\ud83d\udcca Getting restaurant details: {restaurant_id}\")\n-        \n-                # For now, return mock data for the requested restaurant\n+\n+        # For now, return mock data for the requested restaurant\n         return {\n             \"id\": restaurant_id,\n             \"name\": f\"Restaurant {restaurant_id}\",\n             \"isActive\": True,\n             \"lastActivity\": datetime.now().isoformat(),\n-            \"source\": \"mock_backend_data\"\n+            \"source\": \"mock_backend_data\",\n         }\n     except Exception as e:\n         logger.error(f\"Restaurant details error: {e}\")\n         return {\"error\": str(e)}\n \n+\n if __name__ == \"__main__\":\n     import uvicorn\n-    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n\\ No newline at end of file\n+\n+    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/storage_service.py\t2025-08-02 10:59:17.999749+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/storage_service.py\t2025-08-02 22:36:04.100886+00:00\n@@ -27,16 +27,16 @@\n logger = logging.getLogger(__name__)\n \n \n class StorageService:\n     \"\"\"DigitalOcean Spaces file management service\"\"\"\n-    \n+\n     def __init__(self):\n         \"\"\"Initialize the storage service\"\"\"\n         self.enabled = settings.ENABLE_SPACES_STORAGE\n         self.client = None\n-        \n+\n         # Lazy load boto3 to prevent deployment failures\n         if self.enabled:\n             global boto3, ClientError, NoCredentialsError\n             if boto3 is None:\n                 try:\n@@ -44,363 +44,358 @@\n                     from botocore.exceptions import ClientError, NoCredentialsError\n                 except ImportError:\n                     logger.warning(\"boto3 not available - storage service disabled\")\n                     self.enabled = False\n                     return\n-        \n+\n         if self.enabled and self._validate_credentials():\n             try:\n                 # Configure S3-compatible client for Spaces\n                 self.client = boto3.client(\n-                    's3',\n+                    \"s3\",\n                     endpoint_url=settings.SPACES_ENDPOINT,\n                     aws_access_key_id=settings.SPACES_ACCESS_KEY_ID,\n                     aws_secret_access_key=settings.SPACES_SECRET_ACCESS_KEY,\n-                    region_name=settings.SPACES_REGION\n-                )\n-                \n+                    region_name=settings.SPACES_REGION,\n+                )\n+\n                 self.bucket = settings.SPACES_BUCKET\n                 self.cdn_endpoint = settings.CDN_ENDPOINT\n                 self.max_file_size = settings.MAX_FILE_SIZE\n-                self.allowed_types = settings.ALLOWED_FILE_TYPES.split(',')\n-                \n+                self.allowed_types = settings.ALLOWED_FILE_TYPES.split(\",\")\n+\n                 logger.info(f\"Storage service initialized for bucket: {self.bucket}\")\n-                \n+\n             except Exception as e:\n                 logger.error(f\"Failed to initialize Spaces client: {e}\")\n                 self.enabled = False\n                 self.client = None\n         else:\n             self.client = None\n             logger.info(\"Spaces storage disabled - using local storage fallback\")\n-    \n+\n     def _validate_credentials(self) -> bool:\n         \"\"\"Validate that required credentials are present\"\"\"\n         required_settings = [\n             settings.SPACES_ACCESS_KEY_ID,\n             settings.SPACES_SECRET_ACCESS_KEY,\n-            settings.SPACES_BUCKET\n+            settings.SPACES_BUCKET,\n         ]\n-        \n+\n         if not all(required_settings):\n             logger.warning(\"Missing DigitalOcean Spaces credentials\")\n             return False\n-        \n+\n         return True\n-    \n+\n     async def upload_file(\n         self,\n         file: BinaryIO,\n         filename: str,\n         folder: str = \"uploads\",\n         user_id: Optional[int] = None,\n-        optimize_image: bool = True\n+        optimize_image: bool = True,\n     ) -> Dict[str, str]:\n         \"\"\"Upload file to Spaces with optimization\"\"\"\n-        \n+\n         if not self.enabled or not self.client:\n             raise FynloException(\n                 message=\"Storage service not available\",\n                 error_code=ErrorCodes.INTERNAL_ERROR,\n-                status_code=503\n-            )\n-        \n+                status_code=503,\n+            )\n+\n         try:\n             # Read and validate file\n             file_content = file.read()\n             file.seek(0)  # Reset file pointer\n-            \n+\n             self._validate_file(file_content, filename)\n-            \n+\n             # Generate unique filename with timestamp\n             file_hash = hashlib.md5(file_content).hexdigest()[:8]\n             timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n             file_ext = os.path.splitext(filename)[1].lower()\n             unique_filename = f\"{timestamp}_{file_hash}{file_ext}\"\n-            \n+\n             # Create organized file path\n             if user_id:\n                 file_path = f\"{folder}/user_{user_id}/{unique_filename}\"\n             else:\n                 file_path = f\"{folder}/{unique_filename}\"\n-            \n+\n             # Optimize images for web delivery\n-            if optimize_image and file_ext in ['.jpg', '.jpeg', '.png']:\n+            if optimize_image and file_ext in [\".jpg\", \".jpeg\", \".png\"]:\n                 file_content = self._optimize_image(file_content, file_ext)\n-            \n+\n             # Upload to Spaces\n             self.client.put_object(\n                 Bucket=self.bucket,\n                 Key=file_path,\n                 Body=file_content,\n                 ContentType=self._get_content_type(filename),\n-                ACL='public-read',  # Enable CDN access\n+                ACL=\"public-read\",  # Enable CDN access\n                 Metadata={\n-                    'original_filename': filename,\n-                    'user_id': str(user_id) if user_id else '',\n-                    'upload_timestamp': datetime.now().isoformat(),\n-                    'uploaded_by': 'fynlo_pos_backend'\n-                }\n-            )\n-            \n+                    \"original_filename\": filename,\n+                    \"user_id\": str(user_id) if user_id else \"\",\n+                    \"upload_timestamp\": datetime.now().isoformat(),\n+                    \"uploaded_by\": \"fynlo_pos_backend\",\n+                },\n+            )\n+\n             # Generate URLs\n             spaces_url = f\"{settings.SPACES_ENDPOINT}/{self.bucket}/{file_path}\"\n-            cdn_url = f\"{self.cdn_endpoint}/{file_path}\" if self.cdn_endpoint else spaces_url\n-            \n+            cdn_url = (\n+                f\"{self.cdn_endpoint}/{file_path}\" if self.cdn_endpoint else spaces_url\n+            )\n+\n             logger.info(f\"File uploaded successfully: {file_path}\")\n-            \n+\n             return {\n-                'filename': unique_filename,\n-                'original_filename': filename,\n-                'file_path': file_path,\n-                'spaces_url': spaces_url,\n-                'cdn_url': cdn_url,\n-                'file_size': len(file_content),\n-                'content_type': self._get_content_type(filename)\n+                \"filename\": unique_filename,\n+                \"original_filename\": filename,\n+                \"file_path\": file_path,\n+                \"spaces_url\": spaces_url,\n+                \"cdn_url\": cdn_url,\n+                \"file_size\": len(file_content),\n+                \"content_type\": self._get_content_type(filename),\n             }\n-            \n+\n         except Exception as e:\n             # Handle ClientError specifically if boto3 is available\n             if ClientError and isinstance(e, ClientError):\n-                error_code = e.response['Error']['Code']\n+                error_code = e.response[\"Error\"][\"Code\"]\n                 logger.error(f\"Spaces client error ({error_code}): {str(e)}\")\n                 raise FynloException(\n                     message=f\"Upload failed: {error_code}\",\n                     error_code=ErrorCodes.EXTERNAL_SERVICE_ERROR,\n-                    status_code=503\n+                    status_code=503,\n                 )\n             else:\n                 logger.error(f\"File upload failed: {str(e)}\")\n                 raise FynloException(\n                     message=f\"Upload failed: {str(e)}\",\n                     error_code=ErrorCodes.INTERNAL_ERROR,\n-                    status_code=500\n-                )\n-    \n+                    status_code=500,\n+                )\n+\n     def _validate_file(self, file_content: bytes, filename: str) -> None:\n         \"\"\"Validate file size and type\"\"\"\n-        \n+\n         # Check file size\n         if len(file_content) > self.max_file_size:\n             raise FynloException(\n                 message=f\"File too large. Maximum size: {self.max_file_size / (1024*1024):.1f}MB\",\n                 error_code=ErrorCodes.VALIDATION_ERROR,\n-                status_code=413\n-            )\n-        \n+                status_code=413,\n+            )\n+\n         # Check file extension\n-        file_ext = os.path.splitext(filename)[1].lower().lstrip('.')\n+        file_ext = os.path.splitext(filename)[1].lower().lstrip(\".\")\n         if file_ext not in self.allowed_types:\n             raise FynloException(\n                 message=f\"File type not allowed. Allowed types: {', '.join(self.allowed_types)}\",\n                 error_code=ErrorCodes.VALIDATION_ERROR,\n-                status_code=400\n-            )\n-        \n+                status_code=400,\n+            )\n+\n         # Basic content validation for images\n-        if file_ext in ['jpg', 'jpeg', 'png', 'gif']:\n+        if file_ext in [\"jpg\", \"jpeg\", \"png\", \"gif\"]:\n             global Image\n             if Image is None:\n                 try:\n                     from PIL import Image\n                 except ImportError:\n                     logger.warning(\"PIL not available - skipping image validation\")\n                     return\n-            \n+\n             try:\n                 Image.open(BytesIO(file_content))\n             except Exception:\n                 raise FynloException(\n                     message=\"Invalid image file\",\n                     error_code=ErrorCodes.VALIDATION_ERROR,\n-                    status_code=400\n-                )\n-    \n+                    status_code=400,\n+                )\n+\n     def _optimize_image(self, image_content: bytes, file_ext: str) -> bytes:\n         \"\"\"Optimize image for web delivery\"\"\"\n-        \n+\n         global Image\n         if Image is None:\n             try:\n                 from PIL import Image\n             except ImportError:\n                 logger.warning(\"PIL not available - returning original image\")\n                 return image_content\n-        \n+\n         try:\n             # Open image\n             image = Image.open(BytesIO(image_content))\n-            \n+\n             # Convert RGBA to RGB if saving as JPEG\n-            if file_ext.lower() in ['.jpg', '.jpeg'] and image.mode in ['RGBA', 'LA']:\n-                background = Image.new('RGB', image.size, (255, 255, 255))\n-                if image.mode == 'RGBA':\n+            if file_ext.lower() in [\".jpg\", \".jpeg\"] and image.mode in [\"RGBA\", \"LA\"]:\n+                background = Image.new(\"RGB\", image.size, (255, 255, 255))\n+                if image.mode == \"RGBA\":\n                     background.paste(image, mask=image.split()[-1])\n                 else:\n                     background.paste(image)\n                 image = background\n-            \n+\n             # Resize if too large (max 1920px width)\n             max_width = 1920\n             if image.width > max_width:\n                 ratio = max_width / image.width\n                 new_height = int(image.height * ratio)\n                 image = image.resize((max_width, new_height), Image.Resampling.LANCZOS)\n-            \n+\n             # Save optimized image\n             output = BytesIO()\n-            format_map = {'.jpg': 'JPEG', '.jpeg': 'JPEG', '.png': 'PNG'}\n-            image_format = format_map.get(file_ext.lower(), 'JPEG')\n-            \n-            if image_format == 'JPEG':\n+            format_map = {\".jpg\": \"JPEG\", \".jpeg\": \"JPEG\", \".png\": \"PNG\"}\n+            image_format = format_map.get(file_ext.lower(), \"JPEG\")\n+\n+            if image_format == \"JPEG\":\n                 image.save(output, format=image_format, quality=85, optimize=True)\n             else:\n                 image.save(output, format=image_format, optimize=True)\n-            \n+\n             optimized_content = output.getvalue()\n-            \n-            logger.info(f\"Image optimized: {len(image_content)} \u2192 {len(optimized_content)} bytes\")\n+\n+            logger.info(\n+                f\"Image optimized: {len(image_content)} \u2192 {len(optimized_content)} bytes\"\n+            )\n             return optimized_content\n-            \n+\n         except Exception as e:\n             logger.warning(f\"Image optimization failed: {e}\")\n             return image_content  # Return original if optimization fails\n-    \n+\n     def _get_content_type(self, filename: str) -> str:\n         \"\"\"Get content type for file\"\"\"\n-        \n+\n         ext_map = {\n-            '.jpg': 'image/jpeg',\n-            '.jpeg': 'image/jpeg',\n-            '.png': 'image/png',\n-            '.gif': 'image/gif',\n-            '.pdf': 'application/pdf',\n-            '.docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',\n-            '.xlsx': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'\n+            \".jpg\": \"image/jpeg\",\n+            \".jpeg\": \"image/jpeg\",\n+            \".png\": \"image/png\",\n+            \".gif\": \"image/gif\",\n+            \".pdf\": \"application/pdf\",\n+            \".docx\": \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\",\n+            \".xlsx\": \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\",\n         }\n-        \n+\n         file_ext = os.path.splitext(filename)[1].lower()\n-        return ext_map.get(file_ext, 'application/octet-stream')\n-    \n+        return ext_map.get(file_ext, \"application/octet-stream\")\n+\n     async def delete_file(self, file_path: str) -> bool:\n         \"\"\"Delete file from Spaces\"\"\"\n-        \n+\n         if not self.enabled or not self.client:\n             logger.warning(\"Spaces storage not available for deletion\")\n             return False\n-        \n+\n         try:\n             self.client.delete_object(Bucket=self.bucket, Key=file_path)\n             logger.info(f\"File deleted: {file_path}\")\n             return True\n-            \n+\n         except Exception as e:\n             # Handle ClientError specifically if boto3 is available\n             if ClientError and isinstance(e, ClientError):\n-                error_code = e.response['Error']['Code']\n-                if error_code == 'NoSuchKey':\n+                error_code = e.response[\"Error\"][\"Code\"]\n+                if error_code == \"NoSuchKey\":\n                     logger.warning(f\"File not found for deletion: {file_path}\")\n                     return False\n                 logger.error(f\"Spaces deletion error ({error_code}): {str(e)}\")\n                 return False\n             else:\n                 logger.error(f\"File deletion failed: {str(e)}\")\n                 return False\n-    \n+\n     async def get_presigned_url(\n-        self,\n-        file_path: str,\n-        expiration: int = 3600\n+        self, file_path: str, expiration: int = 3600\n     ) -> Optional[str]:\n         \"\"\"Generate presigned URL for secure file access\"\"\"\n-        \n+\n         if not self.enabled or not self.client:\n             return None\n-        \n+\n         try:\n             url = self.client.generate_presigned_url(\n-                'get_object',\n-                Params={'Bucket': self.bucket, 'Key': file_path},\n-                ExpiresIn=expiration\n-            )\n-            \n+                \"get_object\",\n+                Params={\"Bucket\": self.bucket, \"Key\": file_path},\n+                ExpiresIn=expiration,\n+            )\n+\n             return url\n-            \n+\n         except Exception as e:\n             logger.error(f\"Presigned URL generation failed: {str(e)}\")\n             return None\n-    \n+\n     async def list_files(\n-        self,\n-        prefix: str = \"\",\n-        limit: int = 100\n+        self, prefix: str = \"\", limit: int = 100\n     ) -> List[Dict[str, any]]:\n         \"\"\"List files in bucket with pagination\"\"\"\n-        \n+\n         if not self.enabled or not self.client:\n             return []\n-        \n+\n         try:\n             response = self.client.list_objects_v2(\n-                Bucket=self.bucket,\n-                Prefix=prefix,\n-                MaxKeys=limit\n-            )\n-            \n+                Bucket=self.bucket, Prefix=prefix, MaxKeys=limit\n+            )\n+\n             files = []\n-            for obj in response.get('Contents', []):\n-                cdn_url = f\"{self.cdn_endpoint}/{obj['Key']}\" if self.cdn_endpoint else f\"{settings.SPACES_ENDPOINT}/{self.bucket}/{obj['Key']}\"\n-                files.append({\n-                    'key': obj['Key'],\n-                    'size': obj['Size'],\n-                    'last_modified': obj['LastModified'],\n-                    'cdn_url': cdn_url\n-                })\n-            \n+            for obj in response.get(\"Contents\", []):\n+                cdn_url = (\n+                    f\"{self.cdn_endpoint}/{obj['Key']}\"\n+                    if self.cdn_endpoint\n+                    else f\"{settings.SPACES_ENDPOINT}/{self.bucket}/{obj['Key']}\"\n+                )\n+                files.append(\n+                    {\n+                        \"key\": obj[\"Key\"],\n+                        \"size\": obj[\"Size\"],\n+                        \"last_modified\": obj[\"LastModified\"],\n+                        \"cdn_url\": cdn_url,\n+                    }\n+                )\n+\n             return files\n-            \n+\n         except Exception as e:\n             logger.error(f\"File listing failed: {str(e)}\")\n             return []\n-    \n+\n     def get_public_url(self, file_path: str) -> str:\n         \"\"\"Get public CDN URL for a file\"\"\"\n         if self.cdn_endpoint:\n             return f\"{self.cdn_endpoint}/{file_path}\"\n         else:\n             return f\"{settings.SPACES_ENDPOINT}/{self.bucket}/{file_path}\"\n-    \n+\n     async def check_health(self) -> Dict[str, any]:\n         \"\"\"Check storage service health\"\"\"\n-        \n+\n         if not self.enabled:\n-            return {\n-                'status': 'disabled',\n-                'message': 'Spaces storage is disabled'\n-            }\n-        \n+            return {\"status\": \"disabled\", \"message\": \"Spaces storage is disabled\"}\n+\n         if not self.client:\n-            return {\n-                'status': 'error',\n-                'message': 'Spaces client not initialized'\n-            }\n-        \n+            return {\"status\": \"error\", \"message\": \"Spaces client not initialized\"}\n+\n         try:\n             # Test connection by listing bucket (with limit 1)\n             self.client.list_objects_v2(Bucket=self.bucket, MaxKeys=1)\n-            \n+\n             return {\n-                'status': 'healthy',\n-                'message': 'Spaces storage is operational',\n-                'bucket': self.bucket,\n-                'endpoint': settings.SPACES_ENDPOINT\n+                \"status\": \"healthy\",\n+                \"message\": \"Spaces storage is operational\",\n+                \"bucket\": self.bucket,\n+                \"endpoint\": settings.SPACES_ENDPOINT,\n             }\n-            \n-        except Exception as e:\n-            return {\n-                'status': 'error',\n-                'message': f'Spaces connection failed: {str(e)}'\n-            }\n+\n+        except Exception as e:\n+            return {\"status\": \"error\", \"message\": f\"Spaces connection failed: {str(e)}\"}\n \n \n # Global service instance\n-storage_service = StorageService()\n\\ No newline at end of file\n+storage_service = StorageService()\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/tasks/replica_validator.py\t2025-08-02 19:23:36.834509+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/tasks/replica_validator.py\t2025-08-02 22:36:04.110683+00:00\n@@ -18,22 +18,22 @@\n \n \n class ReplicaValidator:\n     \"\"\"\n     Validates replica counts and sends alerts for discrepancies.\n-    \n+\n     Continuously monitors:\n     - Active instance count from heartbeats\n     - Configured replica count from DigitalOcean\n     - Sends alerts when mismatches detected\n     \"\"\"\n-    \n+\n     def __init__(\n-        self, \n-        tracker: InstanceTracker, \n+        self,\n+        tracker: InstanceTracker,\n         monitor: DigitalOceanMonitor,\n-        redis_client: RedisClient\n+        redis_client: RedisClient,\n     ):\n         self.tracker = tracker\n         self.monitor = monitor\n         self.redis = redis_client\n         self.check_interval = 300  # 5 minutes\n@@ -41,76 +41,78 @@\n         self.validation_task: Optional[asyncio.Task] = None\n         self._running = False\n         self._consecutive_failures = 0\n         self._last_alert_time: Optional[datetime] = None\n         self._alert_cooldown = 900  # 15 minutes between alerts\n-        \n+\n     async def start(self):\n         \"\"\"Start the validation loop.\"\"\"\n         if self._running:\n             logger.warning(\"Replica validator already running\")\n             return\n-            \n+\n         self._running = True\n         logger.info(\"Starting replica validator\")\n-        \n+\n         # Start validation loop\n         self.validation_task = asyncio.create_task(self._validation_loop())\n-        \n+\n     async def stop(self):\n         \"\"\"Stop the validation loop.\"\"\"\n         if not self._running:\n             return\n-            \n+\n         self._running = False\n         logger.info(\"Stopping replica validator\")\n-        \n+\n         # Cancel validation task\n         if self.validation_task:\n             self.validation_task.cancel()\n             try:\n                 await self.validation_task\n             except asyncio.CancelledError:\n                 pass\n-    \n+\n     async def _validation_loop(self):\n         \"\"\"Continuously validate replica counts.\"\"\"\n         while self._running:\n             try:\n                 await self.validate_replicas()\n                 await asyncio.sleep(self.check_interval)\n             except Exception as e:\n                 logger.error(f\"Validation error: {e}\", exc_info=True)\n                 await asyncio.sleep(60)  # Shorter sleep on error\n-    \n+\n     async def validate_replicas(self) -> Dict[str, Any]:\n         \"\"\"\n         Check and report replica discrepancies.\n-        \n+\n         Returns:\n             Validation result with status and any issues found\n         \"\"\"\n         try:\n             # Get active instances from tracker\n             instances = await self.tracker.get_active_instances()\n             instance_counts = await self.tracker.get_instance_count()\n             active_count = instance_counts[\"active\"]\n-            \n+\n             # Get desired count from DO API\n             do_status = await self.monitor.get_actual_replicas()\n-            \n+\n             if \"error\" in do_status:\n                 # If DO API fails, fall back to environment variable\n                 desired_count = settings.DESIRED_REPLICAS\n                 do_api_available = False\n             else:\n-                desired_count = do_status.get(\"desired_replicas\", settings.DESIRED_REPLICAS)\n+                desired_count = do_status.get(\n+                    \"desired_replicas\", settings.DESIRED_REPLICAS\n+                )\n                 do_api_available = True\n-            \n+\n             # Check for discrepancy\n             discrepancy = active_count != desired_count\n-            \n+\n             validation_result = {\n                 \"timestamp\": datetime.now(timezone.utc).isoformat(),\n                 \"active_count\": active_count,\n                 \"desired_count\": desired_count,\n                 \"stale_count\": instance_counts[\"stale\"],\n@@ -118,109 +120,113 @@\n                 \"discrepancy\": discrepancy,\n                 \"do_api_available\": do_api_available,\n                 \"instances\": [\n                     {\n                         \"id\": inst.get(\"instance_id\"),\n-                        \"last_heartbeat\": inst.get(\"last_heartbeat\")\n+                        \"last_heartbeat\": inst.get(\"last_heartbeat\"),\n                     }\n                     for inst in instances\n-                ]\n+                ],\n             }\n-            \n+\n             # Store validation result in Redis for monitoring\n             await self.redis.set(\n-                \"replica_validation:latest\",\n-                validation_result,\n-                expire=600  # 10 minutes\n+                \"replica_validation:latest\", validation_result, expire=600  # 10 minutes\n             )\n-            \n+\n             if discrepancy:\n                 self._consecutive_failures += 1\n                 logger.warning(\n                     f\"Replica count mismatch: Active={active_count}, Desired={desired_count} \"\n                     f\"(failure {self._consecutive_failures}/{self.alert_threshold})\"\n                 )\n-                \n+\n                 # Send alert if threshold reached\n                 if self._consecutive_failures >= self.alert_threshold:\n-                    await self._send_alert({\n-                        \"type\": \"replica_mismatch\",\n-                        \"active\": active_count,\n-                        \"desired\": desired_count,\n-                        \"stale\": instance_counts[\"stale\"],\n-                        \"instances\": instances,\n-                        \"consecutive_failures\": self._consecutive_failures\n-                    })\n+                    await self._send_alert(\n+                        {\n+                            \"type\": \"replica_mismatch\",\n+                            \"active\": active_count,\n+                            \"desired\": desired_count,\n+                            \"stale\": instance_counts[\"stale\"],\n+                            \"instances\": instances,\n+                            \"consecutive_failures\": self._consecutive_failures,\n+                        }\n+                    )\n             else:\n                 # Reset failure counter on success\n                 if self._consecutive_failures > 0:\n-                    logger.info(f\"Replica count recovered after {self._consecutive_failures} failures\")\n+                    logger.info(\n+                        f\"Replica count recovered after {self._consecutive_failures} failures\"\n+                    )\n                 self._consecutive_failures = 0\n-            \n+\n             # Check for stale instances\n             if instance_counts[\"stale\"] > 0:\n                 logger.warning(f\"{instance_counts['stale']} stale instances detected\")\n-                \n+\n                 # Clean up stale instances\n                 await self.tracker.cleanup_stale_instances()\n-            \n+\n             return validation_result\n-            \n+\n         except Exception as e:\n             logger.error(f\"Validation failed: {e}\", exc_info=True)\n             return {\n                 \"timestamp\": datetime.now(timezone.utc).isoformat(),\n                 \"error\": str(e),\n                 \"active_count\": -1,\n-                \"desired_count\": -1\n+                \"desired_count\": -1,\n             }\n-    \n+\n     async def _send_alert(self, alert_data: Dict[str, Any]):\n         \"\"\"Send alert for replica discrepancy.\"\"\"\n         # Check cooldown\n         now = datetime.now(timezone.utc)\n         if self._last_alert_time:\n             time_since_last = (now - self._last_alert_time).total_seconds()\n             if time_since_last < self._alert_cooldown:\n-                logger.info(f\"Alert cooldown active, skipping (last alert {time_since_last}s ago)\")\n+                logger.info(\n+                    f\"Alert cooldown active, skipping (last alert {time_since_last}s ago)\"\n+                )\n                 return\n-        \n+\n         alert_type = alert_data.get(\"type\", \"unknown\")\n         active = alert_data.get(\"active\", 0)\n         desired = alert_data.get(\"desired\", 0)\n-        \n+\n         # Log critical alert\n         logger.critical(\n             f\"REPLICA ALERT: {alert_type} - Active: {active}, Desired: {desired}\"\n         )\n-        \n+\n         # Store alert in Redis for monitoring dashboard\n         alert_record = {\n             \"timestamp\": now.isoformat(),\n             \"type\": alert_type,\n             \"data\": alert_data,\n-            \"environment\": settings.ENVIRONMENT\n+            \"environment\": settings.ENVIRONMENT,\n         }\n-        \n+\n         await self.redis.set(\n             f\"replica_alert:{now.timestamp()}\",\n             alert_record,\n-            expire=86400  # Keep alerts for 24 hours\n+            expire=86400,  # Keep alerts for 24 hours\n         )\n-        \n+\n         # Send webhook notification if configured\n         webhook_url = os.environ.get(\"REPLICA_ALERT_WEBHOOK\")\n         if webhook_url:\n             await self._send_webhook_alert(webhook_url, alert_record)\n-        \n+\n         # Send email notification if configured\n         if settings.RESEND_API_KEY and settings.ENVIRONMENT == \"production\":\n             await self._send_email_alert(alert_record)\n-        \n+\n         # Update last alert time\n         self._last_alert_time = now\n-    \n+\n     async def _send_webhook_alert(self, webhook_url: str, alert_data: Dict[str, Any]):\n         \"\"\"Send alert via webhook (Slack, Discord, etc).\"\"\"\n         try:\n             async with httpx.AsyncClient(timeout=10.0) as client:\n                 # Format message based on webhook type\n@@ -229,32 +235,32 @@\n                 elif \"discord\" in webhook_url.lower():\n                     payload = self._format_discord_alert(alert_data)\n                 else:\n                     # Generic webhook\n                     payload = alert_data\n-                \n+\n                 response = await client.post(webhook_url, json=payload)\n-                \n+\n                 if response.status_code >= 400:\n                     logger.error(f\"Webhook alert failed: {response.status_code}\")\n                 else:\n                     logger.info(\"Webhook alert sent successfully\")\n-                    \n+\n         except Exception as e:\n             logger.error(f\"Failed to send webhook alert: {e}\")\n-    \n+\n     async def _send_email_alert(self, alert_data: Dict[str, Any]):\n         \"\"\"Send alert via email using Resend.\"\"\"\n         try:\n             # Import here to avoid circular dependency\n             from app.services.email_service import send_email\n-            \n+\n             alert_type = alert_data[\"type\"]\n             data = alert_data[\"data\"]\n-            \n+\n             subject = f\"[Fynlo Alert] Replica Count Mismatch - {settings.ENVIRONMENT}\"\n-            \n+\n             html_content = f\"\"\"\n             <h2>Replica Count Alert</h2>\n             <p>A replica count discrepancy has been detected in the {settings.ENVIRONMENT} environment.</p>\n             \n             <h3>Details:</h3>\n@@ -272,104 +278,104 @@\n                 <li>Use 'doctl apps update' to force scale reset if needed</li>\n             </ol>\n             \n             <p><small>Alert generated at: {alert_data['timestamp']}</small></p>\n             \"\"\"\n-            \n+\n             await send_email(\n-                to=settings.PLATFORM_OWNER_EMAIL,\n-                subject=subject,\n-                html=html_content\n+                to=settings.PLATFORM_OWNER_EMAIL, subject=subject, html=html_content\n             )\n-            \n+\n             logger.info(\"Email alert sent successfully\")\n-            \n+\n         except Exception as e:\n             logger.error(f\"Failed to send email alert: {e}\")\n-    \n+\n     def _format_slack_alert(self, alert_data: Dict[str, Any]) -> Dict[str, Any]:\n         \"\"\"Format alert for Slack webhook.\"\"\"\n         data = alert_data[\"data\"]\n-        \n+\n         return {\n             \"text\": f\"\ud83d\udea8 Replica Count Alert - {settings.ENVIRONMENT}\",\n-            \"attachments\": [{\n-                \"color\": \"danger\",\n-                \"fields\": [\n-                    {\n-                        \"title\": \"Active Instances\",\n-                        \"value\": str(data.get(\"active\", \"unknown\")),\n-                        \"short\": True\n-                    },\n-                    {\n-                        \"title\": \"Desired Instances\",\n-                        \"value\": str(data.get(\"desired\", \"unknown\")),\n-                        \"short\": True\n-                    },\n-                    {\n-                        \"title\": \"Environment\",\n-                        \"value\": settings.ENVIRONMENT,\n-                        \"short\": True\n-                    },\n-                    {\n-                        \"title\": \"Consecutive Failures\",\n-                        \"value\": str(data.get(\"consecutive_failures\", 0)),\n-                        \"short\": True\n-                    }\n-                ],\n-                \"footer\": \"Fynlo Monitoring\",\n-                \"ts\": int(datetime.now().timestamp())\n-            }]\n+            \"attachments\": [\n+                {\n+                    \"color\": \"danger\",\n+                    \"fields\": [\n+                        {\n+                            \"title\": \"Active Instances\",\n+                            \"value\": str(data.get(\"active\", \"unknown\")),\n+                            \"short\": True,\n+                        },\n+                        {\n+                            \"title\": \"Desired Instances\",\n+                            \"value\": str(data.get(\"desired\", \"unknown\")),\n+                            \"short\": True,\n+                        },\n+                        {\n+                            \"title\": \"Environment\",\n+                            \"value\": settings.ENVIRONMENT,\n+                            \"short\": True,\n+                        },\n+                        {\n+                            \"title\": \"Consecutive Failures\",\n+                            \"value\": str(data.get(\"consecutive_failures\", 0)),\n+                            \"short\": True,\n+                        },\n+                    ],\n+                    \"footer\": \"Fynlo Monitoring\",\n+                    \"ts\": int(datetime.now().timestamp()),\n+                }\n+            ],\n         }\n-    \n+\n     def _format_discord_alert(self, alert_data: Dict[str, Any]) -> Dict[str, Any]:\n         \"\"\"Format alert for Discord webhook.\"\"\"\n         data = alert_data[\"data\"]\n-        \n+\n         return {\n             \"content\": f\"\ud83d\udea8 **Replica Count Alert** - {settings.ENVIRONMENT}\",\n-            \"embeds\": [{\n-                \"title\": \"Instance Mismatch Detected\",\n-                \"color\": 15158332,  # Red\n-                \"fields\": [\n-                    {\n-                        \"name\": \"Active Instances\",\n-                        \"value\": str(data.get(\"active\", \"unknown\")),\n-                        \"inline\": True\n-                    },\n-                    {\n-                        \"name\": \"Desired Instances\",\n-                        \"value\": str(data.get(\"desired\", \"unknown\")),\n-                        \"inline\": True\n-                    },\n-                    {\n-                        \"name\": \"Stale Instances\",\n-                        \"value\": str(data.get(\"stale\", 0)),\n-                        \"inline\": True\n-                    }\n-                ],\n-                \"timestamp\": alert_data[\"timestamp\"]\n-            }]\n+            \"embeds\": [\n+                {\n+                    \"title\": \"Instance Mismatch Detected\",\n+                    \"color\": 15158332,  # Red\n+                    \"fields\": [\n+                        {\n+                            \"name\": \"Active Instances\",\n+                            \"value\": str(data.get(\"active\", \"unknown\")),\n+                            \"inline\": True,\n+                        },\n+                        {\n+                            \"name\": \"Desired Instances\",\n+                            \"value\": str(data.get(\"desired\", \"unknown\")),\n+                            \"inline\": True,\n+                        },\n+                        {\n+                            \"name\": \"Stale Instances\",\n+                            \"value\": str(data.get(\"stale\", 0)),\n+                            \"inline\": True,\n+                        },\n+                    ],\n+                    \"timestamp\": alert_data[\"timestamp\"],\n+                }\n+            ],\n         }\n \n \n # Global validator instance\n _replica_validator: Optional[ReplicaValidator] = None\n \n \n async def init_replica_validator(\n-    tracker: InstanceTracker,\n-    monitor: DigitalOceanMonitor,\n-    redis_client: RedisClient\n+    tracker: InstanceTracker, monitor: DigitalOceanMonitor, redis_client: RedisClient\n ):\n     \"\"\"Initialize and start the replica validator.\"\"\"\n     global _replica_validator\n-    \n+\n     if settings.ENVIRONMENT == \"development\":\n         logger.info(\"Skipping replica validator in development mode\")\n         return\n-    \n+\n     _replica_validator = ReplicaValidator(tracker, monitor, redis_client)\n     await _replica_validator.start()\n     logger.info(\"Replica validator initialized and started\")\n \n \n@@ -379,6 +385,6 @@\n     if _replica_validator:\n         await _replica_validator.stop()\n         logger.info(\"Replica validator stopped\")\n \n \n-import os  # Add this import at the top\n\\ No newline at end of file\n+import os  # Add this import at the top\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/smart_routing.py\t2025-08-02 19:23:36.833533+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/smart_routing.py\t2025-08-02 22:36:04.128033+00:00\n@@ -12,679 +12,693 @@\n \n from app.services.payment_analytics import PaymentAnalyticsService\n \n logger = logging.getLogger(__name__)\n \n+\n class RoutingStrategy(Enum):\n     \"\"\"Different routing strategies available\"\"\"\n+\n     COST_OPTIMAL = \"cost_optimal\"\n     RELIABILITY_FIRST = \"reliability_first\"\n     SPEED_OPTIMAL = \"speed_optimal\"\n     BALANCED = \"balanced\"\n     VOLUME_AWARE = \"volume_aware\"\n \n+\n @dataclass\n class ProviderScore:\n     \"\"\"Score breakdown for a provider\"\"\"\n+\n     provider: str\n     total_score: float\n     cost_score: float\n     reliability_score: float\n     speed_score: float\n     volume_score: float\n     availability_score: float\n \n+\n @dataclass\n class RoutingDecision:\n     \"\"\"Result of routing decision\"\"\"\n+\n     selected_provider: str\n     confidence: float\n     reasoning: List[str]\n     alternatives: List[Tuple[str, float]]\n     cost_analysis: Dict\n     risk_factors: List[str]\n \n+\n class SmartRoutingService:\n     \"\"\"Service for intelligent payment provider routing\"\"\"\n-    \n+\n     def __init__(self, analytics_service: PaymentAnalyticsService):\n         self.analytics = analytics_service\n         self.provider_configs = {\n-            'stripe': {\n-                'base_fee_percentage': Decimal('0.014'),  # 1.4%\n-                'fixed_fee': Decimal('0.20'),  # 20p\n-                'max_amount': Decimal('999999'),  # No practical limit\n-                'processing_time_ms': 2000,\n-                'reliability_score': 0.995,\n-                'availability_zones': ['EU', 'US', 'UK']\n+            \"stripe\": {\n+                \"base_fee_percentage\": Decimal(\"0.014\"),  # 1.4%\n+                \"fixed_fee\": Decimal(\"0.20\"),  # 20p\n+                \"max_amount\": Decimal(\"999999\"),  # No practical limit\n+                \"processing_time_ms\": 2000,\n+                \"reliability_score\": 0.995,\n+                \"availability_zones\": [\"EU\", \"US\", \"UK\"],\n             },\n-            'square': {\n-                'base_fee_percentage': Decimal('0.0175'),  # 1.75%\n-                'fixed_fee': Decimal('0'),\n-                'max_amount': Decimal('50000'),  # \u00a3500 limit for contactless\n-                'processing_time_ms': 3000,\n-                'reliability_score': 0.992,\n-                'availability_zones': ['US', 'UK', 'CA']\n+            \"square\": {\n+                \"base_fee_percentage\": Decimal(\"0.0175\"),  # 1.75%\n+                \"fixed_fee\": Decimal(\"0\"),\n+                \"max_amount\": Decimal(\"50000\"),  # \u00a3500 limit for contactless\n+                \"processing_time_ms\": 3000,\n+                \"reliability_score\": 0.992,\n+                \"availability_zones\": [\"US\", \"UK\", \"CA\"],\n             },\n-            'sumup': {\n-                'base_fee_percentage': Decimal('0.0069'),  # 0.69% for high volume\n-                'monthly_fee': Decimal('19'),  # \u00a319/month\n-                'volume_threshold': Decimal('2714'),  # \u00a32,714/month threshold\n-                'standard_fee_percentage': Decimal('0.0169'),  # 1.69% standard\n-                'max_amount': Decimal('999999'),\n-                'processing_time_ms': 2500,\n-                'reliability_score': 0.988,\n-                'availability_zones': ['EU', 'UK']\n+            \"sumup\": {\n+                \"base_fee_percentage\": Decimal(\"0.0069\"),  # 0.69% for high volume\n+                \"monthly_fee\": Decimal(\"19\"),  # \u00a319/month\n+                \"volume_threshold\": Decimal(\"2714\"),  # \u00a32,714/month threshold\n+                \"standard_fee_percentage\": Decimal(\"0.0169\"),  # 1.69% standard\n+                \"max_amount\": Decimal(\"999999\"),\n+                \"processing_time_ms\": 2500,\n+                \"reliability_score\": 0.988,\n+                \"availability_zones\": [\"EU\", \"UK\"],\n             },\n-            'qr_code': {\n-                'base_fee_percentage': Decimal('0.012'),  # 1.2%\n-                'fixed_fee': Decimal('0'),\n-                'max_amount': Decimal('999999'),\n-                'processing_time_ms': 5000,  # Longer due to customer interaction\n-                'reliability_score': 0.985,  # Depends on customer action\n-                'availability_zones': ['GLOBAL']\n-            }\n+            \"qr_code\": {\n+                \"base_fee_percentage\": Decimal(\"0.012\"),  # 1.2%\n+                \"fixed_fee\": Decimal(\"0\"),\n+                \"max_amount\": Decimal(\"999999\"),\n+                \"processing_time_ms\": 5000,  # Longer due to customer interaction\n+                \"reliability_score\": 0.985,  # Depends on customer action\n+                \"availability_zones\": [\"GLOBAL\"],\n+            },\n         }\n-    \n+\n     async def route_payment(\n         self,\n         amount: Decimal,\n         restaurant_id: str,\n         strategy: RoutingStrategy = RoutingStrategy.BALANCED,\n         customer_preferences: Optional[Dict] = None,\n-        force_provider: Optional[str] = None\n+        force_provider: Optional[str] = None,\n     ) -> RoutingDecision:\n         \"\"\"\n         Make intelligent routing decision based on multiple factors\n         \"\"\"\n-        \n+\n         if force_provider:\n             return RoutingDecision(\n                 selected_provider=force_provider,\n                 confidence=1.0,\n                 reasoning=[f\"Provider forced: {force_provider}\"],\n                 alternatives=[],\n                 cost_analysis={},\n-                risk_factors=[]\n-            )\n-        \n+                risk_factors=[],\n+            )\n+\n         # Get historical data and current state\n         analytics_data = await self._get_routing_context(restaurant_id, amount)\n-        \n+\n         # Score all providers\n         provider_scores = await self._score_providers(\n             amount, restaurant_id, analytics_data, strategy\n         )\n-        \n+\n         # Make routing decision\n         decision = await self._make_routing_decision(\n             provider_scores, analytics_data, strategy\n         )\n-        \n+\n         return decision\n-    \n+\n     async def get_routing_recommendations(\n-        self,\n-        restaurant_id: str,\n-        analysis_period_days: int = 30\n+        self, restaurant_id: str, analysis_period_days: int = 30\n     ) -> Dict:\n         \"\"\"\n         Get comprehensive routing recommendations for a restaurant\n         \"\"\"\n-        \n+\n         end_date = datetime.utcnow()\n         start_date = end_date - timedelta(days=analysis_period_days)\n-        \n+\n         # Get comprehensive analytics\n         performance_data = await self.analytics.get_provider_performance_summary(\n             restaurant_id, start_date, end_date\n         )\n-        \n+\n         cost_optimization = await self.analytics.get_cost_optimization_report(\n             restaurant_id, start_date, end_date\n         )\n-        \n+\n         health_scores = await self.analytics.get_provider_health_scores(restaurant_id)\n-        \n+\n         # Analyze transaction patterns\n         transaction_patterns = await self._analyze_transaction_patterns(\n             restaurant_id, start_date, end_date\n         )\n-        \n+\n         # Generate routing strategy recommendations\n         strategy_recommendations = await self._recommend_routing_strategies(\n             performance_data, cost_optimization, health_scores, transaction_patterns\n         )\n-        \n+\n         return {\n-            'restaurant_id': restaurant_id,\n-            'analysis_period': {\n-                'start_date': start_date.isoformat(),\n-                'end_date': end_date.isoformat(),\n-                'days': analysis_period_days\n+            \"restaurant_id\": restaurant_id,\n+            \"analysis_period\": {\n+                \"start_date\": start_date.isoformat(),\n+                \"end_date\": end_date.isoformat(),\n+                \"days\": analysis_period_days,\n             },\n-            'current_performance': performance_data,\n-            'cost_optimization': cost_optimization,\n-            'provider_health': health_scores,\n-            'transaction_patterns': transaction_patterns,\n-            'routing_recommendations': strategy_recommendations\n+            \"current_performance\": performance_data,\n+            \"cost_optimization\": cost_optimization,\n+            \"provider_health\": health_scores,\n+            \"transaction_patterns\": transaction_patterns,\n+            \"routing_recommendations\": strategy_recommendations,\n         }\n-    \n+\n     async def simulate_routing_impact(\n         self,\n         restaurant_id: str,\n         new_strategy: RoutingStrategy,\n-        simulation_days: int = 30\n+        simulation_days: int = 30,\n     ) -> Dict:\n         \"\"\"\n         Simulate the impact of changing routing strategy\n         \"\"\"\n-        \n+\n         # Get historical transactions\n         end_date = datetime.utcnow()\n         start_date = end_date - timedelta(days=simulation_days)\n-        \n+\n         # For simulation, we'll use the analytics service to get historical data\n         # and re-route each transaction with the new strategy\n-        \n+\n         analytics_data = await self.analytics.get_provider_performance_summary(\n             restaurant_id, start_date, end_date\n         )\n-        \n-        current_fees = analytics_data['overall_metrics']['total_fees']\n-        current_volume = analytics_data['overall_metrics']['total_volume']\n-        \n+\n+        current_fees = analytics_data[\"overall_metrics\"][\"total_fees\"]\n+        current_volume = analytics_data[\"overall_metrics\"][\"total_volume\"]\n+\n         # Simulate new routing\n         simulated_fees = await self._simulate_fees_with_strategy(\n             current_volume, new_strategy, restaurant_id\n         )\n-        \n+\n         savings = current_fees - simulated_fees\n         savings_percentage = (savings / current_fees * 100) if current_fees > 0 else 0\n-        \n+\n         return {\n-            'strategy': new_strategy.value,\n-            'simulation_period': simulation_days,\n-            'current_state': {\n-                'total_fees': current_fees,\n-                'total_volume': current_volume\n+            \"strategy\": new_strategy.value,\n+            \"simulation_period\": simulation_days,\n+            \"current_state\": {\n+                \"total_fees\": current_fees,\n+                \"total_volume\": current_volume,\n             },\n-            'projected_state': {\n-                'total_fees': simulated_fees,\n-                'savings': savings,\n-                'savings_percentage': savings_percentage\n+            \"projected_state\": {\n+                \"total_fees\": simulated_fees,\n+                \"savings\": savings,\n+                \"savings_percentage\": savings_percentage,\n             },\n-            'risk_assessment': await self._assess_strategy_risks(new_strategy, restaurant_id)\n+            \"risk_assessment\": await self._assess_strategy_risks(\n+                new_strategy, restaurant_id\n+            ),\n         }\n-    \n+\n     async def _get_routing_context(self, restaurant_id: str, amount: Decimal) -> Dict:\n         \"\"\"Gather context information for routing decision\"\"\"\n-        \n+\n         # Get recent performance data\n         end_date = datetime.utcnow()\n         start_date = end_date - timedelta(days=7)  # Last week\n-        \n+\n         performance = await self.analytics.get_provider_performance_summary(\n             restaurant_id, start_date, end_date\n         )\n-        \n+\n         health_scores = await self.analytics.get_provider_health_scores(restaurant_id)\n-        \n+\n         # Calculate monthly volume projection\n-        weekly_volume = performance['overall_metrics']['total_volume']\n-        monthly_volume = weekly_volume * (30/7)  # Project monthly\n-        \n+        weekly_volume = performance[\"overall_metrics\"][\"total_volume\"]\n+        monthly_volume = weekly_volume * (30 / 7)  # Project monthly\n+\n         return {\n-            'performance': performance,\n-            'health_scores': health_scores,\n-            'monthly_volume': monthly_volume,\n-            'current_transaction_amount': float(amount)\n+            \"performance\": performance,\n+            \"health_scores\": health_scores,\n+            \"monthly_volume\": monthly_volume,\n+            \"current_transaction_amount\": float(amount),\n         }\n-    \n+\n     async def _score_providers(\n         self,\n         amount: Decimal,\n         restaurant_id: str,\n         analytics_data: Dict,\n-        strategy: RoutingStrategy\n+        strategy: RoutingStrategy,\n     ) -> List[ProviderScore]:\n         \"\"\"Score all available providers based on multiple factors\"\"\"\n-        \n+\n         scores = []\n-        monthly_volume = Decimal(str(analytics_data['monthly_volume']))\n-        \n+        monthly_volume = Decimal(str(analytics_data[\"monthly_volume\"]))\n+\n         for provider, config in self.provider_configs.items():\n             # Cost score (0-100, higher is better/cheaper)\n             cost_score = await self._calculate_cost_score(\n                 provider, amount, monthly_volume, config\n             )\n-            \n+\n             # Reliability score (0-100)\n             reliability_score = await self._calculate_reliability_score(\n                 provider, analytics_data, config\n             )\n-            \n+\n             # Speed score (0-100, faster is better)\n             speed_score = await self._calculate_speed_score(provider, config)\n-            \n+\n             # Volume appropriateness score (0-100)\n             volume_score = await self._calculate_volume_score(\n                 provider, amount, monthly_volume, config\n             )\n-            \n+\n             # Availability score (0-100)\n             availability_score = await self._calculate_availability_score(\n                 provider, config\n             )\n-            \n+\n             # Calculate weighted total based on strategy\n             weights = self._get_strategy_weights(strategy)\n             total_score = (\n-                cost_score * weights['cost'] +\n-                reliability_score * weights['reliability'] +\n-                speed_score * weights['speed'] +\n-                volume_score * weights['volume'] +\n-                availability_score * weights['availability']\n-            )\n-            \n-            scores.append(ProviderScore(\n-                provider=provider,\n-                total_score=total_score,\n-                cost_score=cost_score,\n-                reliability_score=reliability_score,\n-                speed_score=speed_score,\n-                volume_score=volume_score,\n-                availability_score=availability_score\n-            ))\n-        \n+                cost_score * weights[\"cost\"]\n+                + reliability_score * weights[\"reliability\"]\n+                + speed_score * weights[\"speed\"]\n+                + volume_score * weights[\"volume\"]\n+                + availability_score * weights[\"availability\"]\n+            )\n+\n+            scores.append(\n+                ProviderScore(\n+                    provider=provider,\n+                    total_score=total_score,\n+                    cost_score=cost_score,\n+                    reliability_score=reliability_score,\n+                    speed_score=speed_score,\n+                    volume_score=volume_score,\n+                    availability_score=availability_score,\n+                )\n+            )\n+\n         # Sort by total score (highest first)\n         scores.sort(key=lambda x: x.total_score, reverse=True)\n-        \n+\n         return scores\n-    \n+\n     async def _calculate_cost_score(\n-        self,\n-        provider: str,\n-        amount: Decimal,\n-        monthly_volume: Decimal,\n-        config: Dict\n+        self, provider: str, amount: Decimal, monthly_volume: Decimal, config: Dict\n     ) -> float:\n         \"\"\"Calculate cost efficiency score (0-100, higher is cheaper)\"\"\"\n-        \n+\n         # Calculate fee for this transaction\n-        if provider == 'sumup':\n-            if monthly_volume >= config['volume_threshold']:\n-                fee = amount * config['base_fee_percentage']\n+        if provider == \"sumup\":\n+            if monthly_volume >= config[\"volume_threshold\"]:\n+                fee = amount * config[\"base_fee_percentage\"]\n                 # Add proportional monthly fee\n-                monthly_fee_per_transaction = config['monthly_fee'] / (monthly_volume / amount) if monthly_volume > 0 else Decimal('0')\n+                monthly_fee_per_transaction = (\n+                    config[\"monthly_fee\"] / (monthly_volume / amount)\n+                    if monthly_volume > 0\n+                    else Decimal(\"0\")\n+                )\n                 fee += monthly_fee_per_transaction\n             else:\n-                fee = amount * config['standard_fee_percentage']\n+                fee = amount * config[\"standard_fee_percentage\"]\n         else:\n-            fee = amount * config['base_fee_percentage']\n-            if 'fixed_fee' in config:\n-                fee += config['fixed_fee']\n-        \n+            fee = amount * config[\"base_fee_percentage\"]\n+            if \"fixed_fee\" in config:\n+                fee += config[\"fixed_fee\"]\n+\n         # Convert to percentage\n         fee_percentage = (fee / amount * 100) if amount > 0 else 0\n-        \n+\n         # Score: 100 - (fee_percentage * 50) to normalize to 0-100 range\n         # Assuming max reasonable fee is 2%\n         cost_score = max(0, 100 - (float(fee_percentage) * 50))\n-        \n+\n         return cost_score\n-    \n+\n     async def _calculate_reliability_score(\n-        self,\n-        provider: str,\n-        analytics_data: Dict,\n-        config: Dict\n+        self, provider: str, analytics_data: Dict, config: Dict\n     ) -> float:\n         \"\"\"Calculate reliability score based on historical data and config\"\"\"\n-        \n+\n         # Start with base reliability from config\n-        base_reliability = config.get('reliability_score', 0.99) * 100\n-        \n+        base_reliability = config.get(\"reliability_score\", 0.99) * 100\n+\n         # Adjust based on health scores if available\n-        health_scores = analytics_data.get('health_scores', {})\n+        health_scores = analytics_data.get(\"health_scores\", {})\n         if provider in health_scores:\n             provider_health = health_scores[provider]\n-            reliability_factor = provider_health.get('factors', {}).get('reliability', base_reliability)\n+            reliability_factor = provider_health.get(\"factors\", {}).get(\n+                \"reliability\", base_reliability\n+            )\n             # Weighted average of config and actual performance\n             reliability_score = (base_reliability * 0.3) + (reliability_factor * 0.7)\n         else:\n             reliability_score = base_reliability\n-        \n+\n         return min(100, reliability_score)\n-    \n+\n     async def _calculate_speed_score(self, provider: str, config: Dict) -> float:\n         \"\"\"Calculate processing speed score (0-100, faster is better)\"\"\"\n-        \n-        processing_time = config.get('processing_time_ms', 3000)\n-        \n+\n+        processing_time = config.get(\"processing_time_ms\", 3000)\n+\n         # Score based on processing time (2s = 100, 10s = 0)\n         max_time = 10000  # 10 seconds\n-        min_time = 2000   # 2 seconds\n-        \n+        min_time = 2000  # 2 seconds\n+\n         if processing_time <= min_time:\n             return 100\n         elif processing_time >= max_time:\n             return 0\n         else:\n             return 100 - ((processing_time - min_time) / (max_time - min_time) * 100)\n-    \n+\n     async def _calculate_volume_score(\n-        self,\n-        provider: str,\n-        amount: Decimal,\n-        monthly_volume: Decimal,\n-        config: Dict\n+        self, provider: str, amount: Decimal, monthly_volume: Decimal, config: Dict\n     ) -> float:\n         \"\"\"Calculate how well this provider suits the volume\"\"\"\n-        \n+\n         # Check if amount exceeds limits\n-        max_amount = config.get('max_amount', Decimal('999999'))\n+        max_amount = config.get(\"max_amount\", Decimal(\"999999\"))\n         if amount > max_amount:\n             return 0  # Cannot process\n-        \n+\n         # Volume appropriateness\n-        if provider == 'sumup':\n+        if provider == \"sumup\":\n             # SumUp is best for high volume\n-            if monthly_volume >= config['volume_threshold']:\n+            if monthly_volume >= config[\"volume_threshold\"]:\n                 return 100  # Perfect fit\n             else:\n                 # Score decreases as volume gets further from threshold\n-                ratio = float(monthly_volume / config['volume_threshold'])\n+                ratio = float(monthly_volume / config[\"volume_threshold\"])\n                 return min(100, ratio * 100)\n-        \n-        elif provider == 'qr_code':\n+\n+        elif provider == \"qr_code\":\n             # QR code is good for any volume but better for medium amounts\n-            if Decimal('10') <= amount <= Decimal('500'):\n+            if Decimal(\"10\") <= amount <= Decimal(\"500\"):\n                 return 100\n-            elif amount < Decimal('10'):\n+            elif amount < Decimal(\"10\"):\n                 return 70  # Small amounts are ok but not ideal\n             else:\n                 return 90  # Large amounts are fine\n-        \n-        elif provider in ['stripe', 'square']:\n+\n+        elif provider in [\"stripe\", \"square\"]:\n             # Traditional providers are good for medium volumes\n-            if Decimal('1000') <= monthly_volume <= Decimal('10000'):\n+            if Decimal(\"1000\") <= monthly_volume <= Decimal(\"10000\"):\n                 return 100\n-            elif monthly_volume < Decimal('1000'):\n+            elif monthly_volume < Decimal(\"1000\"):\n                 return 80  # Ok for small volumes\n             else:\n                 return 70  # Could be expensive for high volumes\n-        \n+\n         return 80  # Default score\n-    \n+\n     async def _calculate_availability_score(self, provider: str, config: Dict) -> float:\n         \"\"\"Calculate availability score based on geographic and time factors\"\"\"\n-        \n+\n         # For now, return 100 if available in UK\n-        availability_zones = config.get('availability_zones', [])\n-        if 'UK' in availability_zones or 'GLOBAL' in availability_zones:\n+        availability_zones = config.get(\"availability_zones\", [])\n+        if \"UK\" in availability_zones or \"GLOBAL\" in availability_zones:\n             return 100\n-        elif 'EU' in availability_zones:\n+        elif \"EU\" in availability_zones:\n             return 90\n         else:\n             return 70\n-    \n+\n     def _get_strategy_weights(self, strategy: RoutingStrategy) -> Dict[str, float]:\n         \"\"\"Get weighting factors for different strategies\"\"\"\n-        \n+\n         if strategy == RoutingStrategy.COST_OPTIMAL:\n             return {\n-                'cost': 0.5,\n-                'reliability': 0.2,\n-                'speed': 0.1,\n-                'volume': 0.15,\n-                'availability': 0.05\n+                \"cost\": 0.5,\n+                \"reliability\": 0.2,\n+                \"speed\": 0.1,\n+                \"volume\": 0.15,\n+                \"availability\": 0.05,\n             }\n         elif strategy == RoutingStrategy.RELIABILITY_FIRST:\n             return {\n-                'cost': 0.15,\n-                'reliability': 0.5,\n-                'speed': 0.15,\n-                'volume': 0.15,\n-                'availability': 0.05\n+                \"cost\": 0.15,\n+                \"reliability\": 0.5,\n+                \"speed\": 0.15,\n+                \"volume\": 0.15,\n+                \"availability\": 0.05,\n             }\n         elif strategy == RoutingStrategy.SPEED_OPTIMAL:\n             return {\n-                'cost': 0.2,\n-                'reliability': 0.25,\n-                'speed': 0.4,\n-                'volume': 0.1,\n-                'availability': 0.05\n+                \"cost\": 0.2,\n+                \"reliability\": 0.25,\n+                \"speed\": 0.4,\n+                \"volume\": 0.1,\n+                \"availability\": 0.05,\n             }\n         elif strategy == RoutingStrategy.VOLUME_AWARE:\n             return {\n-                'cost': 0.3,\n-                'reliability': 0.2,\n-                'speed': 0.1,\n-                'volume': 0.35,\n-                'availability': 0.05\n+                \"cost\": 0.3,\n+                \"reliability\": 0.2,\n+                \"speed\": 0.1,\n+                \"volume\": 0.35,\n+                \"availability\": 0.05,\n             }\n         else:  # BALANCED\n             return {\n-                'cost': 0.3,\n-                'reliability': 0.3,\n-                'speed': 0.2,\n-                'volume': 0.15,\n-                'availability': 0.05\n+                \"cost\": 0.3,\n+                \"reliability\": 0.3,\n+                \"speed\": 0.2,\n+                \"volume\": 0.15,\n+                \"availability\": 0.05,\n             }\n-    \n+\n     async def _make_routing_decision(\n         self,\n         provider_scores: List[ProviderScore],\n         analytics_data: Dict,\n-        strategy: RoutingStrategy\n+        strategy: RoutingStrategy,\n     ) -> RoutingDecision:\n         \"\"\"Make final routing decision based on scores\"\"\"\n-        \n+\n         if not provider_scores:\n             raise ValueError(\"No providers available for routing\")\n-        \n+\n         # Select top provider\n         selected = provider_scores[0]\n-        \n+\n         # Calculate confidence based on score gap\n         if len(provider_scores) > 1:\n             score_gap = selected.total_score - provider_scores[1].total_score\n             confidence = min(1.0, 0.5 + (score_gap / 100))\n         else:\n             confidence = 1.0\n-        \n+\n         # Generate reasoning\n         reasoning = []\n-        reasoning.append(f\"Selected {selected.provider} with score {selected.total_score:.1f}\")\n-        \n+        reasoning.append(\n+            f\"Selected {selected.provider} with score {selected.total_score:.1f}\"\n+        )\n+\n         if selected.cost_score >= 80:\n             reasoning.append(\"Excellent cost efficiency\")\n         elif selected.cost_score >= 60:\n             reasoning.append(\"Good cost efficiency\")\n-        \n+\n         if selected.reliability_score >= 90:\n             reasoning.append(\"High reliability\")\n-        \n+\n         if selected.volume_score >= 90:\n             reasoning.append(\"Well-suited for transaction volume\")\n-        \n+\n         # Identify alternatives\n         alternatives = [\n-            (score.provider, score.total_score) \n+            (score.provider, score.total_score)\n             for score in provider_scores[1:3]  # Top 2 alternatives\n         ]\n-        \n+\n         # Cost analysis\n         cost_analysis = {\n-            'selected_provider_cost_score': selected.cost_score,\n-            'strategy_used': strategy.value,\n-            'confidence_level': confidence\n+            \"selected_provider_cost_score\": selected.cost_score,\n+            \"strategy_used\": strategy.value,\n+            \"confidence_level\": confidence,\n         }\n-        \n+\n         # Risk factors\n         risk_factors = []\n         if selected.reliability_score < 80:\n             risk_factors.append(\"Below average reliability\")\n         if selected.availability_score < 90:\n             risk_factors.append(\"Limited availability\")\n         if confidence < 0.7:\n             risk_factors.append(\"Low confidence in selection\")\n-        \n+\n         return RoutingDecision(\n             selected_provider=selected.provider,\n             confidence=confidence,\n             reasoning=reasoning,\n             alternatives=alternatives,\n             cost_analysis=cost_analysis,\n-            risk_factors=risk_factors\n-        )\n-    \n+            risk_factors=risk_factors,\n+        )\n+\n     async def _analyze_transaction_patterns(\n-        self,\n-        restaurant_id: str,\n-        start_date: datetime,\n-        end_date: datetime\n+        self, restaurant_id: str, start_date: datetime, end_date: datetime\n     ) -> Dict:\n         \"\"\"Analyze transaction patterns for insights\"\"\"\n-        \n+\n         # Get hourly transaction data (mock for now)\n         patterns = {\n-            'peak_hours': [12, 13, 18, 19, 20],  # Lunch and dinner\n-            'avg_transaction_size': 25.50,\n-            'volume_distribution': {\n-                '0-10': 20,\n-                '10-25': 40,\n-                '25-50': 25,\n-                '50-100': 12,\n-                '100+': 3\n+            \"peak_hours\": [12, 13, 18, 19, 20],  # Lunch and dinner\n+            \"avg_transaction_size\": 25.50,\n+            \"volume_distribution\": {\n+                \"0-10\": 20,\n+                \"10-25\": 40,\n+                \"25-50\": 25,\n+                \"50-100\": 12,\n+                \"100+\": 3,\n             },\n-            'preferred_methods': {\n-                'card': 60,\n-                'qr_code': 25,\n-                'cash': 15\n-            }\n+            \"preferred_methods\": {\"card\": 60, \"qr_code\": 25, \"cash\": 15},\n         }\n-        \n+\n         return patterns\n-    \n+\n     async def _recommend_routing_strategies(\n         self,\n         performance_data: Dict,\n         cost_optimization: Dict,\n         health_scores: Dict,\n-        transaction_patterns: Dict\n+        transaction_patterns: Dict,\n     ) -> List[Dict]:\n         \"\"\"Generate routing strategy recommendations\"\"\"\n-        \n+\n         recommendations = []\n-        \n+\n         # Cost-based recommendation\n-        if cost_optimization['savings_opportunity']['savings_percentage'] > 10:\n-            recommendations.append({\n-                'strategy': RoutingStrategy.COST_OPTIMAL.value,\n-                'priority': 'high',\n-                'title': 'Switch to Cost-Optimal Routing',\n-                'description': f\"Could save {cost_optimization['savings_opportunity']['savings_percentage']:.1f}% on fees\",\n-                'estimated_impact': {\n-                    'monthly_savings': cost_optimization['savings_opportunity']['potential_savings'],\n-                    'implementation_effort': 'low'\n+        if cost_optimization[\"savings_opportunity\"][\"savings_percentage\"] > 10:\n+            recommendations.append(\n+                {\n+                    \"strategy\": RoutingStrategy.COST_OPTIMAL.value,\n+                    \"priority\": \"high\",\n+                    \"title\": \"Switch to Cost-Optimal Routing\",\n+                    \"description\": f\"Could save {cost_optimization['savings_opportunity']['savings_percentage']:.1f}% on fees\",\n+                    \"estimated_impact\": {\n+                        \"monthly_savings\": cost_optimization[\"savings_opportunity\"][\n+                            \"potential_savings\"\n+                        ],\n+                        \"implementation_effort\": \"low\",\n+                    },\n                 }\n-            })\n-        \n+            )\n+\n         # Reliability-based recommendation\n-        avg_reliability = sum(\n-            score['overall_score'] for score in health_scores['health_scores'].values()\n-        ) / len(health_scores['health_scores']) if health_scores['health_scores'] else 0\n-        \n+        avg_reliability = (\n+            sum(\n+                score[\"overall_score\"]\n+                for score in health_scores[\"health_scores\"].values()\n+            )\n+            / len(health_scores[\"health_scores\"])\n+            if health_scores[\"health_scores\"]\n+            else 0\n+        )\n+\n         if avg_reliability < 80:\n-            recommendations.append({\n-                'strategy': RoutingStrategy.RELIABILITY_FIRST.value,\n-                'priority': 'medium',\n-                'title': 'Improve Payment Reliability',\n-                'description': f\"Current reliability score is {avg_reliability:.1f}\",\n-                'estimated_impact': {\n-                    'reliability_improvement': '15-20%',\n-                    'implementation_effort': 'medium'\n+            recommendations.append(\n+                {\n+                    \"strategy\": RoutingStrategy.RELIABILITY_FIRST.value,\n+                    \"priority\": \"medium\",\n+                    \"title\": \"Improve Payment Reliability\",\n+                    \"description\": f\"Current reliability score is {avg_reliability:.1f}\",\n+                    \"estimated_impact\": {\n+                        \"reliability_improvement\": \"15-20%\",\n+                        \"implementation_effort\": \"medium\",\n+                    },\n                 }\n-            })\n-        \n+            )\n+\n         # Volume-aware recommendation\n-        total_volume = performance_data['overall_metrics']['total_volume']\n+        total_volume = performance_data[\"overall_metrics\"][\"total_volume\"]\n         if total_volume > 2714:\n-            recommendations.append({\n-                'strategy': RoutingStrategy.VOLUME_AWARE.value,\n-                'priority': 'high',\n-                'title': 'Enable Volume-Aware Routing',\n-                'description': f\"Your volume (\u00a3{total_volume:,.2f}/month) qualifies for volume discounts\",\n-                'estimated_impact': {\n-                    'potential_savings': 'Up to 30%',\n-                    'implementation_effort': 'low'\n+            recommendations.append(\n+                {\n+                    \"strategy\": RoutingStrategy.VOLUME_AWARE.value,\n+                    \"priority\": \"high\",\n+                    \"title\": \"Enable Volume-Aware Routing\",\n+                    \"description\": f\"Your volume (\u00a3{total_volume:,.2f}/month) qualifies for volume discounts\",\n+                    \"estimated_impact\": {\n+                        \"potential_savings\": \"Up to 30%\",\n+                        \"implementation_effort\": \"low\",\n+                    },\n                 }\n-            })\n-        \n+            )\n+\n         return recommendations\n-    \n+\n     async def _simulate_fees_with_strategy(\n-        self,\n-        volume: float,\n-        strategy: RoutingStrategy,\n-        restaurant_id: str\n+        self, volume: float, strategy: RoutingStrategy, restaurant_id: str\n     ) -> float:\n         \"\"\"Simulate fees with a different routing strategy\"\"\"\n-        \n+\n         # This is a simplified simulation\n         # In practice, you'd replay historical transactions\n-        \n+\n         volume_decimal = Decimal(str(volume))\n-        \n+\n         if strategy == RoutingStrategy.COST_OPTIMAL:\n-            if volume_decimal >= Decimal('2714'):\n+            if volume_decimal >= Decimal(\"2714\"):\n                 # Use SumUp for all\n-                return float((volume_decimal * Decimal('0.0069')) + Decimal('19'))\n+                return float((volume_decimal * Decimal(\"0.0069\")) + Decimal(\"19\"))\n             else:\n                 # Use QR code for all\n-                return float(volume_decimal * Decimal('0.012'))\n-        \n+                return float(volume_decimal * Decimal(\"0.012\"))\n+\n         elif strategy == RoutingStrategy.VOLUME_AWARE:\n-            if volume_decimal >= Decimal('2714'):\n+            if volume_decimal >= Decimal(\"2714\"):\n                 # Mix of SumUp (80%) and QR (20%)\n-                sumup_volume = volume_decimal * Decimal('0.8')\n-                qr_volume = volume_decimal * Decimal('0.2')\n-                sumup_fees = (sumup_volume * Decimal('0.0069')) + Decimal('19')\n-                qr_fees = qr_volume * Decimal('0.012')\n+                sumup_volume = volume_decimal * Decimal(\"0.8\")\n+                qr_volume = volume_decimal * Decimal(\"0.2\")\n+                sumup_fees = (sumup_volume * Decimal(\"0.0069\")) + Decimal(\"19\")\n+                qr_fees = qr_volume * Decimal(\"0.012\")\n                 return float(sumup_fees + qr_fees)\n-        \n+\n         # Default to current average (1.4%)\n-        return float(volume_decimal * Decimal('0.014'))\n-    \n+        return float(volume_decimal * Decimal(\"0.014\"))\n+\n     async def _assess_strategy_risks(\n-        self,\n-        strategy: RoutingStrategy,\n-        restaurant_id: str\n+        self, strategy: RoutingStrategy, restaurant_id: str\n     ) -> List[Dict]:\n         \"\"\"Assess risks of implementing a strategy\"\"\"\n-        \n+\n         risks = []\n-        \n+\n         if strategy == RoutingStrategy.COST_OPTIMAL:\n-            risks.append({\n-                'type': 'reliability',\n-                'level': 'medium',\n-                'description': 'May prioritize cost over payment success rate'\n-            })\n-        \n+            risks.append(\n+                {\n+                    \"type\": \"reliability\",\n+                    \"level\": \"medium\",\n+                    \"description\": \"May prioritize cost over payment success rate\",\n+                }\n+            )\n+\n         elif strategy == RoutingStrategy.SPEED_OPTIMAL:\n-            risks.append({\n-                'type': 'cost',\n-                'level': 'high',\n-                'description': 'May result in higher fees for faster processing'\n-            })\n-        \n+            risks.append(\n+                {\n+                    \"type\": \"cost\",\n+                    \"level\": \"high\",\n+                    \"description\": \"May result in higher fees for faster processing\",\n+                }\n+            )\n+\n         elif strategy == RoutingStrategy.VOLUME_AWARE:\n-            risks.append({\n-                'type': 'complexity',\n-                'level': 'low',\n-                'description': 'Requires accurate volume tracking and thresholds'\n-            })\n-        \n-        return risks\n\\ No newline at end of file\n+            risks.append(\n+                {\n+                    \"type\": \"complexity\",\n+                    \"level\": \"low\",\n+                    \"description\": \"Requires accurate volume tracking and thresholds\",\n+                }\n+            )\n+\n+        return risks\n--- /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/volume_tracker.py\t2025-08-02 19:23:36.834114+00:00\n+++ /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/volume_tracker.py\t2025-08-02 22:36:04.131379+00:00\n@@ -13,476 +13,508 @@\n \n from app.core.database import Payment, Order\n \n logger = logging.getLogger(__name__)\n \n+\n @dataclass\n class VolumeMetrics:\n     \"\"\"Volume metrics for a given period\"\"\"\n+\n     total_volume: Decimal\n     transaction_count: int\n     avg_transaction_size: Decimal\n     peak_hour: int\n     peak_day_volume: Decimal\n     growth_rate: float\n \n+\n @dataclass\n class VolumeThreshold:\n     \"\"\"Volume threshold configuration\"\"\"\n+\n     threshold_amount: Decimal\n     provider_recommendation: str\n     fee_benefit: str\n     description: str\n \n+\n @dataclass\n class VolumeAlert:\n     \"\"\"Volume-based alert\"\"\"\n+\n     alert_type: str\n     threshold_name: str\n     current_volume: Decimal\n     threshold_volume: Decimal\n     recommendation: str\n     priority: str\n     estimated_savings: Optional[Decimal] = None\n \n+\n class VolumeTracker:\n     \"\"\"Service for tracking transaction volumes and triggering optimizations\"\"\"\n-    \n+\n     def __init__(self, db: Session):\n         self.db = db\n-        \n+\n         # Define volume thresholds for different optimizations\n         self.volume_thresholds = {\n-            'sumup_optimal': VolumeThreshold(\n-                threshold_amount=Decimal('2714'),\n-                provider_recommendation='sumup',\n-                fee_benefit='0.69% + \u00a319/month',\n-                description='Qualifies for SumUp high-volume pricing'\n+            \"sumup_optimal\": VolumeThreshold(\n+                threshold_amount=Decimal(\"2714\"),\n+                provider_recommendation=\"sumup\",\n+                fee_benefit=\"0.69% + \u00a319/month\",\n+                description=\"Qualifies for SumUp high-volume pricing\",\n             ),\n-            'volume_discount_eligible': VolumeThreshold(\n-                threshold_amount=Decimal('10000'),\n-                provider_recommendation='negotiated',\n-                fee_benefit='Custom rates available',\n-                description='Eligible for negotiated volume discounts'\n+            \"volume_discount_eligible\": VolumeThreshold(\n+                threshold_amount=Decimal(\"10000\"),\n+                provider_recommendation=\"negotiated\",\n+                fee_benefit=\"Custom rates available\",\n+                description=\"Eligible for negotiated volume discounts\",\n             ),\n-            'enterprise_tier': VolumeThreshold(\n-                threshold_amount=Decimal('50000'),\n-                provider_recommendation='enterprise',\n-                fee_benefit='Enterprise pricing',\n-                description='Qualifies for enterprise-level services'\n-            )\n+            \"enterprise_tier\": VolumeThreshold(\n+                threshold_amount=Decimal(\"50000\"),\n+                provider_recommendation=\"enterprise\",\n+                fee_benefit=\"Enterprise pricing\",\n+                description=\"Qualifies for enterprise-level services\",\n+            ),\n         }\n-    \n+\n     async def track_restaurant_volume(\n-        self,\n-        restaurant_id: str,\n-        period_days: int = 30\n+        self, restaurant_id: str, period_days: int = 30\n     ) -> VolumeMetrics:\n         \"\"\"Track volume metrics for a restaurant over a given period\"\"\"\n-        \n+\n         end_date = datetime.utcnow()\n         start_date = end_date - timedelta(days=period_days)\n-        \n+\n         # Query payments for the period\n-        payments_query = self.db.query(Payment).join(Order).filter(\n-            Order.restaurant_id == restaurant_id,\n-            Payment.processed_at.between(start_date, end_date),\n-            Payment.status == 'completed'\n-        )\n-        \n+        payments_query = (\n+            self.db.query(Payment)\n+            .join(Order)\n+            .filter(\n+                Order.restaurant_id == restaurant_id,\n+                Payment.processed_at.between(start_date, end_date),\n+                Payment.status == \"completed\",\n+            )\n+        )\n+\n         payments = payments_query.all()\n-        \n+\n         if not payments:\n             return VolumeMetrics(\n-                total_volume=Decimal('0'),\n+                total_volume=Decimal(\"0\"),\n                 transaction_count=0,\n-                avg_transaction_size=Decimal('0'),\n+                avg_transaction_size=Decimal(\"0\"),\n                 peak_hour=12,  # Default noon\n-                peak_day_volume=Decimal('0'),\n-                growth_rate=0.0\n-            )\n-        \n+                peak_day_volume=Decimal(\"0\"),\n+                growth_rate=0.0,\n+            )\n+\n         # Calculate basic metrics\n         total_volume = sum(Decimal(str(p.amount)) for p in payments)\n         transaction_count = len(payments)\n-        avg_transaction_size = total_volume / transaction_count if transaction_count > 0 else Decimal('0')\n-        \n+        avg_transaction_size = (\n+            total_volume / transaction_count if transaction_count > 0 else Decimal(\"0\")\n+        )\n+\n         # Find peak hour\n         peak_hour = await self._calculate_peak_hour(payments)\n-        \n+\n         # Calculate peak day volume\n         peak_day_volume = await self._calculate_peak_day_volume(payments)\n-        \n+\n         # Calculate growth rate\n         growth_rate = await self._calculate_growth_rate(\n             restaurant_id, start_date, end_date, period_days\n         )\n-        \n+\n         return VolumeMetrics(\n             total_volume=total_volume,\n             transaction_count=transaction_count,\n             avg_transaction_size=avg_transaction_size,\n             peak_hour=peak_hour,\n             peak_day_volume=peak_day_volume,\n-            growth_rate=growth_rate\n-        )\n-    \n+            growth_rate=growth_rate,\n+        )\n+\n     async def check_volume_thresholds(\n-        self,\n-        restaurant_id: str,\n-        current_metrics: Optional[VolumeMetrics] = None\n+        self, restaurant_id: str, current_metrics: Optional[VolumeMetrics] = None\n     ) -> List[VolumeAlert]:\n         \"\"\"Check if restaurant volume has crossed any important thresholds\"\"\"\n-        \n+\n         if not current_metrics:\n             current_metrics = await self.track_restaurant_volume(restaurant_id)\n-        \n+\n         alerts = []\n         monthly_volume = current_metrics.total_volume  # Assuming 30-day tracking\n-        \n+\n         for threshold_name, threshold in self.volume_thresholds.items():\n             # Check if approaching threshold (within 10%)\n-            threshold_90 = threshold.threshold_amount * Decimal('0.9')\n-            \n+            threshold_90 = threshold.threshold_amount * Decimal(\"0.9\")\n+\n             if monthly_volume >= threshold.threshold_amount:\n                 # Volume exceeds threshold\n                 alert = VolumeAlert(\n-                    alert_type='threshold_exceeded',\n+                    alert_type=\"threshold_exceeded\",\n                     threshold_name=threshold_name,\n                     current_volume=monthly_volume,\n                     threshold_volume=threshold.threshold_amount,\n-                    recommendation=f'Consider switching to {threshold.provider_recommendation} for {threshold.fee_benefit}',\n-                    priority='high' if threshold_name == 'sumup_optimal' else 'medium',\n+                    recommendation=f\"Consider switching to {threshold.provider_recommendation} for {threshold.fee_benefit}\",\n+                    priority=\"high\" if threshold_name == \"sumup_optimal\" else \"medium\",\n                     estimated_savings=await self._calculate_threshold_savings(\n                         monthly_volume, threshold_name\n-                    )\n+                    ),\n                 )\n                 alerts.append(alert)\n-                \n+\n             elif monthly_volume >= threshold_90:\n                 # Approaching threshold\n                 alert = VolumeAlert(\n-                    alert_type='approaching_threshold',\n+                    alert_type=\"approaching_threshold\",\n                     threshold_name=threshold_name,\n                     current_volume=monthly_volume,\n                     threshold_volume=threshold.threshold_amount,\n-                    recommendation=f'Close to qualifying for {threshold.fee_benefit}',\n-                    priority='medium'\n+                    recommendation=f\"Close to qualifying for {threshold.fee_benefit}\",\n+                    priority=\"medium\",\n                 )\n                 alerts.append(alert)\n-        \n+\n         return alerts\n-    \n+\n     async def get_volume_forecast(\n-        self,\n-        restaurant_id: str,\n-        forecast_days: int = 30\n+        self, restaurant_id: str, forecast_days: int = 30\n     ) -> Dict:\n         \"\"\"Forecast future volume based on historical trends\"\"\"\n-        \n+\n         # Get historical data for trend analysis\n         historical_metrics = []\n-        \n+\n         for i in range(3):  # Get last 3 months\n             start_offset = (i + 1) * 30\n             end_offset = i * 30\n-            \n+\n             end_date = datetime.utcnow() - timedelta(days=end_offset)\n             start_date = end_date - timedelta(days=30)\n-            \n+\n             period_metrics = await self._get_period_metrics(\n                 restaurant_id, start_date, end_date\n             )\n             historical_metrics.append(period_metrics)\n-        \n+\n         # Calculate trend\n         if len(historical_metrics) >= 2:\n-            recent_volume = historical_metrics[0]['total_volume']\n-            previous_volume = historical_metrics[1]['total_volume']\n-            \n+            recent_volume = historical_metrics[0][\"total_volume\"]\n+            previous_volume = historical_metrics[1][\"total_volume\"]\n+\n             if previous_volume > 0:\n                 growth_rate = (recent_volume - previous_volume) / previous_volume\n             else:\n                 growth_rate = 0\n         else:\n             growth_rate = 0\n-        \n+\n         # Project future volume\n-        current_volume = historical_metrics[0]['total_volume'] if historical_metrics else 0\n+        current_volume = (\n+            historical_metrics[0][\"total_volume\"] if historical_metrics else 0\n+        )\n         projected_volume = current_volume * (1 + growth_rate) * (forecast_days / 30)\n-        \n+\n         # Check what thresholds might be crossed\n         upcoming_thresholds = []\n         for name, threshold in self.volume_thresholds.items():\n             if current_volume < threshold.threshold_amount <= projected_volume:\n-                upcoming_thresholds.append({\n-                    'threshold_name': name,\n-                    'threshold_amount': float(threshold.threshold_amount),\n-                    'description': threshold.description,\n-                    'estimated_benefit': threshold.fee_benefit\n-                })\n-        \n+                upcoming_thresholds.append(\n+                    {\n+                        \"threshold_name\": name,\n+                        \"threshold_amount\": float(threshold.threshold_amount),\n+                        \"description\": threshold.description,\n+                        \"estimated_benefit\": threshold.fee_benefit,\n+                    }\n+                )\n+\n         return {\n-            'current_monthly_volume': float(current_volume),\n-            'projected_volume': float(projected_volume),\n-            'growth_rate': float(growth_rate * 100),  # As percentage\n-            'forecast_period_days': forecast_days,\n-            'upcoming_thresholds': upcoming_thresholds,\n-            'confidence': self._calculate_forecast_confidence(historical_metrics)\n+            \"current_monthly_volume\": float(current_volume),\n+            \"projected_volume\": float(projected_volume),\n+            \"growth_rate\": float(growth_rate * 100),  # As percentage\n+            \"forecast_period_days\": forecast_days,\n+            \"upcoming_thresholds\": upcoming_thresholds,\n+            \"confidence\": self._calculate_forecast_confidence(historical_metrics),\n         }\n-    \n+\n     async def get_volume_analytics(\n-        self,\n-        restaurant_id: str,\n-        analysis_period_days: int = 90\n+        self, restaurant_id: str, analysis_period_days: int = 90\n     ) -> Dict:\n         \"\"\"Get comprehensive volume analytics\"\"\"\n-        \n+\n         current_metrics = await self.track_restaurant_volume(restaurant_id, 30)\n-        volume_alerts = await self.check_volume_thresholds(restaurant_id, current_metrics)\n+        volume_alerts = await self.check_volume_thresholds(\n+            restaurant_id, current_metrics\n+        )\n         volume_forecast = await self.get_volume_forecast(restaurant_id)\n-        \n+\n         # Get hourly distribution\n         hourly_distribution = await self._get_hourly_distribution(restaurant_id)\n-        \n+\n         # Get daily patterns\n-        daily_patterns = await self._get_daily_patterns(restaurant_id, analysis_period_days)\n-        \n+        daily_patterns = await self._get_daily_patterns(\n+            restaurant_id, analysis_period_days\n+        )\n+\n         # Calculate seasonality if enough data\n-        seasonality = await self._analyze_seasonality(restaurant_id, analysis_period_days)\n-        \n+        seasonality = await self._analyze_seasonality(\n+            restaurant_id, analysis_period_days\n+        )\n+\n         return {\n-            'current_metrics': {\n-                'total_volume': float(current_metrics.total_volume),\n-                'transaction_count': current_metrics.transaction_count,\n-                'avg_transaction_size': float(current_metrics.avg_transaction_size),\n-                'peak_hour': current_metrics.peak_hour,\n-                'peak_day_volume': float(current_metrics.peak_day_volume),\n-                'growth_rate': current_metrics.growth_rate\n+            \"current_metrics\": {\n+                \"total_volume\": float(current_metrics.total_volume),\n+                \"transaction_count\": current_metrics.transaction_count,\n+                \"avg_transaction_size\": float(current_metrics.avg_transaction_size),\n+                \"peak_hour\": current_metrics.peak_hour,\n+                \"peak_day_volume\": float(current_metrics.peak_day_volume),\n+                \"growth_rate\": current_metrics.growth_rate,\n             },\n-            'volume_alerts': [\n+            \"volume_alerts\": [\n                 {\n-                    'type': alert.alert_type,\n-                    'threshold': alert.threshold_name,\n-                    'current_volume': float(alert.current_volume),\n-                    'threshold_volume': float(alert.threshold_volume),\n-                    'recommendation': alert.recommendation,\n-                    'priority': alert.priority,\n-                    'estimated_savings': float(alert.estimated_savings) if alert.estimated_savings else None\n+                    \"type\": alert.alert_type,\n+                    \"threshold\": alert.threshold_name,\n+                    \"current_volume\": float(alert.current_volume),\n+                    \"threshold_volume\": float(alert.threshold_volume),\n+                    \"recommendation\": alert.recommendation,\n+                    \"priority\": alert.priority,\n+                    \"estimated_savings\": (\n+                        float(alert.estimated_savings)\n+                        if alert.estimated_savings\n+                        else None\n+                    ),\n                 }\n                 for alert in volume_alerts\n             ],\n-            'forecast': volume_forecast,\n-            'patterns': {\n-                'hourly_distribution': hourly_distribution,\n-                'daily_patterns': daily_patterns,\n-                'seasonality': seasonality\n-            }\n+            \"forecast\": volume_forecast,\n+            \"patterns\": {\n+                \"hourly_distribution\": hourly_distribution,\n+                \"daily_patterns\": daily_patterns,\n+                \"seasonality\": seasonality,\n+            },\n         }\n-    \n+\n     async def _calculate_peak_hour(self, payments: List[Payment]) -> int:\n         \"\"\"Calculate the peak hour of transaction activity\"\"\"\n-        \n+\n         hourly_counts = {}\n         for payment in payments:\n             if payment.processed_at:\n                 hour = payment.processed_at.hour\n                 hourly_counts[hour] = hourly_counts.get(hour, 0) + 1\n-        \n+\n         if not hourly_counts:\n             return 12  # Default to noon\n-        \n+\n         return max(hourly_counts.items(), key=lambda x: x[1])[0]\n-    \n+\n     async def _calculate_peak_day_volume(self, payments: List[Payment]) -> Decimal:\n         \"\"\"Calculate the highest single-day volume\"\"\"\n-        \n+\n         daily_volumes = {}\n         for payment in payments:\n             if payment.processed_at:\n                 date_key = payment.processed_at.date()\n                 amount = Decimal(str(payment.amount))\n-                daily_volumes[date_key] = daily_volumes.get(date_key, Decimal('0')) + amount\n-        \n+                daily_volumes[date_key] = (\n+                    daily_volumes.get(date_key, Decimal(\"0\")) + amount\n+                )\n+\n         if not daily_volumes:\n-            return Decimal('0')\n-        \n+            return Decimal(\"0\")\n+\n         return max(daily_volumes.values())\n-    \n+\n     async def _calculate_growth_rate(\n         self,\n         restaurant_id: str,\n         start_date: datetime,\n         end_date: datetime,\n-        period_days: int\n+        period_days: int,\n     ) -> float:\n         \"\"\"Calculate volume growth rate compared to previous period\"\"\"\n-        \n+\n         # Get previous period data\n         previous_start = start_date - timedelta(days=period_days)\n         previous_end = start_date\n-        \n-        previous_payments = self.db.query(Payment).join(Order).filter(\n-            Order.restaurant_id == restaurant_id,\n-            Payment.processed_at.between(previous_start, previous_end),\n-            Payment.status == 'completed'\n-        ).all()\n-        \n+\n+        previous_payments = (\n+            self.db.query(Payment)\n+            .join(Order)\n+            .filter(\n+                Order.restaurant_id == restaurant_id,\n+                Payment.processed_at.between(previous_start, previous_end),\n+                Payment.status == \"completed\",\n+            )\n+            .all()\n+        )\n+\n         current_volume = end_date  # This should be calculated from current payments\n         previous_volume = sum(Decimal(str(p.amount)) for p in previous_payments)\n-        \n+\n         if previous_volume == 0:\n             return 0.0\n-        \n+\n         # This is a simplified calculation - in practice you'd pass current volume\n         return 0.0  # Placeholder\n-    \n+\n     async def _calculate_threshold_savings(\n-        self,\n-        monthly_volume: Decimal,\n-        threshold_name: str\n+        self, monthly_volume: Decimal, threshold_name: str\n     ) -> Optional[Decimal]:\n         \"\"\"Calculate estimated monthly savings from reaching a threshold\"\"\"\n-        \n-        if threshold_name == 'sumup_optimal':\n+\n+        if threshold_name == \"sumup_optimal\":\n             # Compare SumUp pricing vs current estimated fees\n-            sumup_fees = (monthly_volume * Decimal('0.0069')) + Decimal('19')\n-            estimated_current_fees = monthly_volume * Decimal('0.014')  # Assume Stripe\n-            return max(Decimal('0'), estimated_current_fees - sumup_fees)\n-        \n+            sumup_fees = (monthly_volume * Decimal(\"0.0069\")) + Decimal(\"19\")\n+            estimated_current_fees = monthly_volume * Decimal(\"0.014\")  # Assume Stripe\n+            return max(Decimal(\"0\"), estimated_current_fees - sumup_fees)\n+\n         return None\n-    \n+\n     async def _get_period_metrics(\n-        self,\n-        restaurant_id: str,\n-        start_date: datetime,\n-        end_date: datetime\n+        self, restaurant_id: str, start_date: datetime, end_date: datetime\n     ) -> Dict:\n         \"\"\"Get metrics for a specific period\"\"\"\n-        \n-        payments = self.db.query(Payment).join(Order).filter(\n-            Order.restaurant_id == restaurant_id,\n-            Payment.processed_at.between(start_date, end_date),\n-            Payment.status == 'completed'\n-        ).all()\n-        \n+\n+        payments = (\n+            self.db.query(Payment)\n+            .join(Order)\n+            .filter(\n+                Order.restaurant_id == restaurant_id,\n+                Payment.processed_at.between(start_date, end_date),\n+                Payment.status == \"completed\",\n+            )\n+            .all()\n+        )\n+\n         total_volume = sum(Decimal(str(p.amount)) for p in payments)\n-        \n+\n         return {\n-            'total_volume': float(total_volume),\n-            'transaction_count': len(payments),\n-            'period_start': start_date.isoformat(),\n-            'period_end': end_date.isoformat()\n+            \"total_volume\": float(total_volume),\n+            \"transaction_count\": len(payments),\n+            \"period_start\": start_date.isoformat(),\n+            \"period_end\": end_date.isoformat(),\n         }\n-    \n+\n     async def _get_hourly_distribution(self, restaurant_id: str) -> Dict[int, float]:\n         \"\"\"Get transaction volume distribution by hour\"\"\"\n-        \n+\n         # Query last 30 days\n         end_date = datetime.utcnow()\n         start_date = end_date - timedelta(days=30)\n-        \n+\n         # Group by hour\n-        hourly_data = self.db.query(\n-            func.extract('hour', Payment.processed_at).label('hour'),\n-            func.sum(Payment.amount).label('volume')\n-        ).join(Order).filter(\n-            Order.restaurant_id == restaurant_id,\n-            Payment.processed_at.between(start_date, end_date),\n-            Payment.status == 'completed'\n-        ).group_by(func.extract('hour', Payment.processed_at)).all()\n-        \n+        hourly_data = (\n+            self.db.query(\n+                func.extract(\"hour\", Payment.processed_at).label(\"hour\"),\n+                func.sum(Payment.amount).label(\"volume\"),\n+            )\n+            .join(Order)\n+            .filter(\n+                Order.restaurant_id == restaurant_id,\n+                Payment.processed_at.between(start_date, end_date),\n+                Payment.status == \"completed\",\n+            )\n+            .group_by(func.extract(\"hour\", Payment.processed_at))\n+            .all()\n+        )\n+\n         # Convert to dictionary\n         distribution = {}\n         for hour_data in hourly_data:\n             hour = int(hour_data.hour) if hour_data.hour is not None else 0\n             volume = float(hour_data.volume or 0)\n             distribution[hour] = volume\n-        \n+\n         return distribution\n-    \n-    async def _get_daily_patterns(\n-        self,\n-        restaurant_id: str,\n-        analysis_days: int\n-    ) -> Dict:\n+\n+    async def _get_daily_patterns(self, restaurant_id: str, analysis_days: int) -> Dict:\n         \"\"\"Analyze daily patterns and trends\"\"\"\n-        \n+\n         end_date = datetime.utcnow()\n         start_date = end_date - timedelta(days=analysis_days)\n-        \n+\n         # Get daily volumes\n-        daily_data = self.db.query(\n-            func.date(Payment.processed_at).label('date'),\n-            func.sum(Payment.amount).label('volume'),\n-            func.count(Payment.id).label('transactions')\n-        ).join(Order).filter(\n-            Order.restaurant_id == restaurant_id,\n-            Payment.processed_at.between(start_date, end_date),\n-            Payment.status == 'completed'\n-        ).group_by(func.date(Payment.processed_at)).all()\n-        \n+        daily_data = (\n+            self.db.query(\n+                func.date(Payment.processed_at).label(\"date\"),\n+                func.sum(Payment.amount).label(\"volume\"),\n+                func.count(Payment.id).label(\"transactions\"),\n+            )\n+            .join(Order)\n+            .filter(\n+                Order.restaurant_id == restaurant_id,\n+                Payment.processed_at.between(start_date, end_date),\n+                Payment.status == \"completed\",\n+            )\n+            .group_by(func.date(Payment.processed_at))\n+            .all()\n+        )\n+\n         # Analyze patterns\n         volumes = [float(d.volume or 0) for d in daily_data]\n         avg_daily_volume = sum(volumes) / len(volumes) if volumes else 0\n-        \n+\n         # Find day-of-week patterns\n         dow_patterns = {}\n         for data in daily_data:\n             if data.date:\n                 dow = data.date.weekday()  # 0 = Monday, 6 = Sunday\n                 if dow not in dow_patterns:\n                     dow_patterns[dow] = []\n                 dow_patterns[dow].append(float(data.volume or 0))\n-        \n+\n         # Calculate average for each day of week\n         dow_averages = {}\n         for dow, volumes_list in dow_patterns.items():\n             dow_averages[dow] = sum(volumes_list) / len(volumes_list)\n-        \n+\n         return {\n-            'avg_daily_volume': avg_daily_volume,\n-            'day_of_week_patterns': dow_averages,\n-            'analysis_period_days': analysis_days\n+            \"avg_daily_volume\": avg_daily_volume,\n+            \"day_of_week_patterns\": dow_averages,\n+            \"analysis_period_days\": analysis_days,\n         }\n-    \n+\n     async def _analyze_seasonality(\n-        self,\n-        restaurant_id: str,\n-        analysis_days: int\n+        self, restaurant_id: str, analysis_days: int\n     ) -> Dict:\n         \"\"\"Analyze seasonal patterns if enough data available\"\"\"\n-        \n+\n         # For now, return basic seasonality info\n         # In practice, you'd need more sophisticated time series analysis\n-        \n+\n         return {\n-            'seasonal_factor': 1.0,  # No seasonality detected\n-            'confidence': 'low',\n-            'note': 'Insufficient data for reliable seasonality analysis'\n+            \"seasonal_factor\": 1.0,  # No seasonality detected\n+            \"confidence\": \"low\",\n+            \"note\": \"Insufficient data for reliable seasonality analysis\",\n         }\n-    \n+\n     def _calculate_forecast_confidence(self, historical_metrics: List[Dict]) -> str:\n         \"\"\"Calculate confidence level for volume forecast\"\"\"\n-        \n+\n         if len(historical_metrics) < 2:\n-            return 'low'\n+            return \"low\"\n         elif len(historical_metrics) < 3:\n-            return 'medium'\n+            return \"medium\"\n         else:\n             # Check variability in growth rates\n-            volumes = [m['total_volume'] for m in historical_metrics]\n+            volumes = [m[\"total_volume\"] for m in historical_metrics]\n             if len(volumes) >= 3:\n                 # Calculate coefficient of variation\n                 mean_vol = sum(volumes) / len(volumes)\n                 if mean_vol > 0:\n                     variance = sum((v - mean_vol) ** 2 for v in volumes) / len(volumes)\n-                    cv = (variance ** 0.5) / mean_vol\n-                    \n+                    cv = (variance**0.5) / mean_vol\n+\n                     if cv < 0.2:\n-                        return 'high'\n+                        return \"high\"\n                     elif cv < 0.5:\n-                        return 'medium'\n+                        return \"medium\"\n                     else:\n-                        return 'low'\n-            \n-            return 'medium'\n\\ No newline at end of file\n+                        return \"low\"\n+\n+            return \"medium\"\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/__init__.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/__init__.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/mobile/__init__.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/__init__.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/__init__.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/api.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/exports.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/auth_backup.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/admin.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/fees.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/mobile/endpoints.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/config.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/employees.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/dashboard.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/customers.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/menu.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/auth.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/inventory.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/monitoring.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/menu_optimized.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/files.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/analytics.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/health.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/platform_admin.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/payment_configurations.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/notifications.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/platform_settings_optimized.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/platform_settings_public.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/products_secure.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/pos.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/public_menu.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/recipes.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/platform_settings.py\nerror: cannot format /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/secure_payments.py: Cannot parse for target version Python 3.11: 61:0:         if v is not None and v.as_tuple().exponent < -2:\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/restaurant_deletion.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/platform.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/storage_health.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/rls_example.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/restaurant_switch.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/secure_payment_provider_management.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/tips.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/sumup.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/websocket_secure.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/orders.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/products.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/sync.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/platform/__init__.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/websocket_rate_limit_patch.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/websocket_portal.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/websocket_enhanced.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/platform/analytics.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/__init__.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/platform/restaurants.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/platform/financial.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/platform/subscriptions.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/platform/users.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/auth.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/cache.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/subscriptions.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/cache_warmer.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/cache_service.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/config.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/dependencies.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/feature_gate.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/database_security.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/websocket.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/logging_filters.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/restaurants.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/mobile_id_mapping.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/mobile_middleware.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/onboarding_helper.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/api/v1/endpoints/payments.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/production_guard.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/exceptions.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/analytics_engine.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/response_helper.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/file_upload.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/rate_limit_config.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/rate_limiter.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/rls_middleware.py\nerror: cannot format /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/security.py: Cannot parse for target version Python 3.11: 486:0:         return InputValidator.sanitize_string(v, context=\"general\", max_length=255)\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/rls_context.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/database.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/rls_session_context.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/security_utils.py\nerror: cannot format /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/tenant_security_current.py: Cannot parse for target version Python 3.11: 141:14:         Apply tenant filtering to a SQLAlchemy query\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/supabase.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/responses.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/platform_service.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/security_monitor.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/validators.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/redis_client.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/tenant_security.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/two_factor_auth.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/integration/__init__.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/transaction_manager.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/push_notifications.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/integration/websocket_events.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/websocket_rate_limiter.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/crud/payments.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/main_minimal.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/main_simple.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/integration/notification_events.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/middleware/rls_middleware.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/crud/inventory.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/middleware/security_headers_middleware.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/sync_manager.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/middleware/feature_gate.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/websocket.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/middleware/tenant_isolation_middleware.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models/activity_log.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/core/validation.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/middleware/version_middleware.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/middleware/sql_injection_waf.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models/audit_log.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models/financial_records.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models/payment_config.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models/refund.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/middleware/rate_limit_middleware.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models/__init__.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/schemas/auth.py\nerror: cannot format /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/schemas/employee_schemas.py: Cannot parse for target version Python 3.11: 113:0:         if info.data and 'start_time' in info.data and v <= info.data['start_time']:\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/main.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/schemas/fee_schemas.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/schemas/inventory_schemas.py\nerror: cannot format /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/schemas/search_schemas.py: Cannot parse for target version Python 3.11: 51:0:         if v:\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models/employee.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/middleware/websocket_rate_limit.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/schemas/refund_schemas.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models/platform_audit.py\nerror: cannot format /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/schemas/subscription.py: Cannot parse for target version Python 3.11: 80:0:         if v <= 0:\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/schemas/restaurant.py\nerror: cannot format /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/activity_logger.py: Cannot parse for target version Python 3.11: 99:0:         \"\"\"Log dashboard viewing activity\"\"\"\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/schemas/websocket.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/audit_logger.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models/subscription.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/cache_service.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models/platform_config.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/scripts/initialize_platform_defaults.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models/reports.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/models/stock_movement.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/financial_records_service.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/email_service.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/inventory_service.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/ocr_service.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/scripts/migrate_to_platform_settings.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/scripts/validate_migration.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/instance_tracker.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_providers/__init__.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_fee_calculator.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/digitalocean_monitor.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/config_manager.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_providers/base_provider.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_config_service.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_factory.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_providers/base.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_providers/cash_provider.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_providers.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/platform_fee_service.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/monitoring.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_providers/payment_factory.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_providers/stripe_provider.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_providers/square_provider.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_analytics.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/employee_service.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/service_charge_calculator.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/payment_providers/sumup_provider.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/report_service.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/staff_tip_service.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/secure_payment_config.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/websocket/__init__.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/secure_payment_processor.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/tests/services/test_ocr_service.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/platform_service.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/sync_service.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/simple_main.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/storage_service.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/tasks/replica_validator.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/smart_routing.py\nwould reformat /Users/arnauddecube/Documents/Fynlo/cashapp-fynlo/backend/app/services/volume_tracker.py\n\nOh no! \ud83d\udca5 \ud83d\udc94 \ud83d\udca5\n174 files would be reformatted, 3 files would be left unchanged, 7 files would fail to reformat.\n",
    "command": "black --check --diff app/"
  },
  "MyPy Type Check": {
    "success": false,
    "output": "app/api/v1/endpoints/secure_payments.py:61: error: Unexpected indent  [syntax]\nFound 1 error in 1 file (errors prevented further checking)\n",
    "command": "mypy app/ --ignore-missing-imports"
  },
  "Flake8 Style Check": {
    "success": false,
    "output": "app/__init__.py:7:29: W292 no newline at end of file\napp/api/__init__.py:4:4: W292 no newline at end of file\napp/api/mobile/__init__.py:1:21: W292 no newline at end of file\napp/api/mobile/endpoints.py:22:1: E302 expected 2 blank lines, found 1\napp/api/mobile/endpoints.py:34:1: E302 expected 2 blank lines, found 1\napp/api/mobile/endpoints.py:43:1: E302 expected 2 blank lines, found 1\napp/api/mobile/endpoints.py:50:1: E302 expected 2 blank lines, found 1\napp/api/mobile/endpoints.py:61:1: E302 expected 2 blank lines, found 1\napp/api/mobile/endpoints.py:74:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:78:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:85:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:95:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:96:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:97:5: E303 too many blank lines (2)\napp/api/mobile/endpoints.py:107:1: E302 expected 2 blank lines, found 1\napp/api/mobile/endpoints.py:122:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:131:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:135:32: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/mobile/endpoints.py:137:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:141:31: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/mobile/endpoints.py:143:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:146:70: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/mobile/endpoints.py:147:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:149:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:152:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:156:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:159:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:165:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:178:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:195:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:203:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:212:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:223:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:234:1: E302 expected 2 blank lines, found 1\napp/api/mobile/endpoints.py:247:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:251:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:257:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:261:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:271:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:276:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:283:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:291:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:293:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:304:41: W291 trailing whitespace\napp/api/mobile/endpoints.py:308:48: W291 trailing whitespace\napp/api/mobile/endpoints.py:314:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:320:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:331:1: E302 expected 2 blank lines, found 1\napp/api/mobile/endpoints.py:346:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:349:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:352:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:355:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:369:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:380:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:391:1: E302 expected 2 blank lines, found 1\napp/api/mobile/endpoints.py:399:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:403:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:417:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:423:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:432:1: E302 expected 2 blank lines, found 1\napp/api/mobile/endpoints.py:453:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:462:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:471:1: E302 expected 2 blank lines, found 1\napp/api/mobile/endpoints.py:486:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:503:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:508:1: W293 blank line contains whitespace\napp/api/mobile/endpoints.py:514:10: W292 no newline at end of file\napp/api/v1/__init__.py:4:4: W292 no newline at end of file\napp/api/v1/api.py:12:47: E261 at least two spaces before inline comment\napp/api/v1/api.py:91:88: W292 no newline at end of file\napp/api/v1/endpoints/__init__.py:12:4: W292 no newline at end of file\napp/api/v1/endpoints/admin.py:16:43: E261 at least two spaces before inline comment\napp/api/v1/endpoints/admin.py:27:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/admin.py:30:35: E261 at least two spaces before inline comment\napp/api/v1/endpoints/admin.py:66:1: W293 blank line contains whitespace\napp/api/v1/endpoints/admin.py:74:56: W504 line break after binary operator\napp/api/v1/endpoints/admin.py:74:58: W291 trailing whitespace\napp/api/v1/endpoints/admin.py:75:61: W504 line break after binary operator\napp/api/v1/endpoints/admin.py:80:1: W293 blank line contains whitespace\napp/api/v1/endpoints/admin.py:86:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/admin.py:104:121: E501 line too long (126 > 120 characters)\napp/api/v1/endpoints/admin.py:119:1: W293 blank line contains whitespace\napp/api/v1/endpoints/admin.py:128:1: W293 blank line contains whitespace\napp/api/v1/endpoints/admin.py:143:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/admin.py:162:121: E501 line too long (126 > 120 characters)\napp/api/v1/endpoints/admin.py:174:1: W293 blank line contains whitespace\napp/api/v1/endpoints/admin.py:185:5: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/admin.py:188:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/admin.py:193:35: E261 at least two spaces before inline comment\napp/api/v1/endpoints/admin.py:207:121: E501 line too long (126 > 120 characters)\napp/api/v1/endpoints/admin.py:219:1: W293 blank line contains whitespace\napp/api/v1/endpoints/admin.py:221:1: W293 blank line contains whitespace\napp/api/v1/endpoints/admin.py:225:1: W293 blank line contains whitespace\napp/api/v1/endpoints/admin.py:232:31: W291 trailing whitespace\napp/api/v1/endpoints/admin.py:233:40: W291 trailing whitespace\napp/api/v1/endpoints/admin.py:237:1: W293 blank line contains whitespace\napp/api/v1/endpoints/admin.py:240:1: W293 blank line contains whitespace\napp/api/v1/endpoints/admin.py:251:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/admin.py:271:121: E501 line too long (126 > 120 characters)\napp/api/v1/endpoints/admin.py:280:1: W293 blank line contains whitespace\napp/api/v1/endpoints/admin.py:282:1: W293 blank line contains whitespace\napp/api/v1/endpoints/admin.py:288:1: W293 blank line contains whitespace\napp/api/v1/endpoints/admin.py:294:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/admin.py:314:121: E501 line too long (126 > 120 characters)\napp/api/v1/endpoints/admin.py:323:1: W293 blank line contains whitespace\napp/api/v1/endpoints/admin.py:325:1: W293 blank line contains whitespace\napp/api/v1/endpoints/admin.py:331:1: W293 blank line contains whitespace\napp/api/v1/endpoints/admin.py:337:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/admin.py:345:1: W293 blank line contains whitespace\napp/api/v1/endpoints/admin.py:347:1: W293 blank line contains whitespace\napp/api/v1/endpoints/admin.py:352:1: W293 blank line contains whitespace\napp/api/v1/endpoints/admin.py:358:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/admin.py:365:1: W293 blank line contains whitespace\napp/api/v1/endpoints/admin.py:367:1: W293 blank line contains whitespace\napp/api/v1/endpoints/admin.py:371:1: W293 blank line contains whitespace\napp/api/v1/endpoints/admin.py:377:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/admin.py:384:1: W293 blank line contains whitespace\napp/api/v1/endpoints/admin.py:389:1: W293 blank line contains whitespace\napp/api/v1/endpoints/admin.py:395:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/admin.py:404:1: W293 blank line contains whitespace\napp/api/v1/endpoints/admin.py:410:1: W293 blank line contains whitespace\napp/api/v1/endpoints/admin.py:416:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/admin.py:425:1: W293 blank line contains whitespace\napp/api/v1/endpoints/admin.py:430:5: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/admin.py:433:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/admin.py:450:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/admin.py:451:24: W291 trailing whitespace\napp/api/v1/endpoints/admin.py:461:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/admin.py:467:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/admin.py:470:29: W292 no newline at end of file\napp/api/v1/endpoints/analytics.py:6:1: F401 'typing.Dict' imported but unused\napp/api/v1/endpoints/analytics.py:6:1: F401 'typing.Any' imported but unused\napp/api/v1/endpoints/analytics.py:7:1: F401 'fastapi.Path' imported but unused\napp/api/v1/endpoints/analytics.py:9:1: F401 'sqlalchemy.desc' imported but unused\napp/api/v1/endpoints/analytics.py:11:1: F401 'pydantic.Field' imported but unused\napp/api/v1/endpoints/analytics.py:22:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/analytics.py:29:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/analytics.py:37:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/analytics.py:45:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/analytics.py:52:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/analytics.py:60:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/analytics.py:79:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:86:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:90:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:100:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:110:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:120:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:129:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:139:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:149:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/analytics.py:169:9: F841 local variable 'week_start' is assigned to but never used\napp/api/v1/endpoints/analytics.py:261:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/analytics.py:269:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:284:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:290:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:299:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:307:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:315:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:323:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:331:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:338:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:345:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:352:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:354:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:359:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:366:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:373:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:380:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:394:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:397:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:400:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:430:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/analytics.py:449:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:456:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:460:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:470:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:480:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:490:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:499:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:509:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:519:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/analytics.py:538:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:545:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:549:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:559:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:569:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:579:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:588:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:598:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:608:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/analytics.py:627:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:634:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:638:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:648:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:658:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:668:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:677:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:687:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:697:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/analytics.py:716:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:723:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:727:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:737:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:747:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:757:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:766:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:776:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:786:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/analytics.py:802:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:809:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:815:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:825:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:835:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/analytics.py:855:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:864:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:866:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:873:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:917:1: W293 blank line contains whitespace\napp/api/v1/endpoints/analytics.py:925:10: W292 no newline at end of file\napp/api/v1/endpoints/auth.py:6:1: F401 'pydantic.BaseModel' imported but unused\napp/api/v1/endpoints/auth.py:47:5: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/auth.py:54:1: E303 too many blank lines (4)\napp/api/v1/endpoints/auth.py:55:1: E302 expected 2 blank lines, found 4\napp/api/v1/endpoints/auth.py:63:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:66:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:69:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:71:121: E501 line too long (122 > 120 characters)\napp/api/v1/endpoints/auth.py:72:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:79:121: E501 line too long (132 > 120 characters)\napp/api/v1/endpoints/auth.py:80:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:85:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:88:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:90:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:95:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:97:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:101:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:103:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:111:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:117:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:127:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:131:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:136:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:177:121: E501 line too long (121 > 120 characters)\napp/api/v1/endpoints/auth.py:195:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:206:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:213:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:220:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:223:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:230:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:237:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:244:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:260:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:266:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:268:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:274:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:282:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:284:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:293:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:296:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:300:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:308:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:363:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:368:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:394:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:398:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:411:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:422:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:435:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:438:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:440:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:447:121: E501 line too long (132 > 120 characters)\napp/api/v1/endpoints/auth.py:448:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:453:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:456:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:461:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:477:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:480:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:484:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:490:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:503:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:512:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:514:13: F401 'app.core.validation.validate_email' imported but unused\napp/api/v1/endpoints/auth.py:521:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:526:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:530:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:536:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:581:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:586:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:589:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:593:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:596:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:611:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth.py:617:87: W292 no newline at end of file\napp/api/v1/endpoints/auth_backup.py:18:1: F401 'app.core.exceptions.ValidationException' imported but unused\napp/api/v1/endpoints/auth_backup.py:35:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/auth_backup.py:39:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/auth_backup.py:48:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/auth_backup.py:56:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/auth_backup.py:66:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/auth_backup.py:70:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/auth_backup.py:74:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/auth_backup.py:76:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth_backup.py:81:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth_backup.py:84:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth_backup.py:87:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth_backup.py:90:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth_backup.py:93:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/auth_backup.py:100:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth_backup.py:105:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/auth_backup.py:106:22: E261 at least two spaces before inline comment\napp/api/v1/endpoints/auth_backup.py:119:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth_backup.py:129:70: E226 missing whitespace around arithmetic operator\napp/api/v1/endpoints/auth_backup.py:138:66: E226 missing whitespace around arithmetic operator\napp/api/v1/endpoints/auth_backup.py:142:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth_backup.py:148:50: E261 at least two spaces before inline comment\napp/api/v1/endpoints/auth_backup.py:150:66: E226 missing whitespace around arithmetic operator\napp/api/v1/endpoints/auth_backup.py:150:121: E501 line too long (121 > 120 characters)\napp/api/v1/endpoints/auth_backup.py:153:45: E261 at least two spaces before inline comment\napp/api/v1/endpoints/auth_backup.py:154:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth_backup.py:160:50: E261 at least two spaces before inline comment\napp/api/v1/endpoints/auth_backup.py:165:56: E261 at least two spaces before inline comment\napp/api/v1/endpoints/auth_backup.py:166:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth_backup.py:176:61: E261 at least two spaces before inline comment\napp/api/v1/endpoints/auth_backup.py:177:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth_backup.py:182:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/auth_backup.py:183:22: E261 at least two spaces before inline comment\napp/api/v1/endpoints/auth_backup.py:191:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth_backup.py:199:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth_backup.py:208:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth_backup.py:212:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth_backup.py:215:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/auth_backup.py:218:22: E261 at least two spaces before inline comment\napp/api/v1/endpoints/auth_backup.py:229:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth_backup.py:239:24: E261 at least two spaces before inline comment\napp/api/v1/endpoints/auth_backup.py:242:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth_backup.py:253:24: E261 at least two spaces before inline comment\napp/api/v1/endpoints/auth_backup.py:256:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth_backup.py:266:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth_backup.py:276:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth_backup.py:298:21: E261 at least two spaces before inline comment\napp/api/v1/endpoints/auth_backup.py:300:16: E261 at least two spaces before inline comment\napp/api/v1/endpoints/auth_backup.py:301:21: E261 at least two spaces before inline comment\napp/api/v1/endpoints/auth_backup.py:302:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth_backup.py:308:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/auth_backup.py:311:22: E261 at least two spaces before inline comment\napp/api/v1/endpoints/auth_backup.py:331:24: E261 at least two spaces before inline comment\napp/api/v1/endpoints/auth_backup.py:337:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth_backup.py:349:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth_backup.py:357:29: E261 at least two spaces before inline comment\napp/api/v1/endpoints/auth_backup.py:362:38: E261 at least two spaces before inline comment\napp/api/v1/endpoints/auth_backup.py:363:21: E261 at least two spaces before inline comment\napp/api/v1/endpoints/auth_backup.py:366:16: E261 at least two spaces before inline comment\napp/api/v1/endpoints/auth_backup.py:368:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth_backup.py:380:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth_backup.py:386:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/auth_backup.py:401:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth_backup.py:413:20: E261 at least two spaces before inline comment\napp/api/v1/endpoints/auth_backup.py:425:72: E261 at least two spaces before inline comment\napp/api/v1/endpoints/auth_backup.py:426:20: E261 at least two spaces before inline comment\napp/api/v1/endpoints/auth_backup.py:428:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth_backup.py:431:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/auth_backup.py:445:1: W293 blank line contains whitespace\napp/api/v1/endpoints/auth_backup.py:449:6: W292 no newline at end of file\napp/api/v1/endpoints/config.py:6:1: F401 'typing.List' imported but unused\napp/api/v1/endpoints/config.py:7:1: F401 'fastapi.status' imported but unused\napp/api/v1/endpoints/config.py:12:1: F401 'app.core.exceptions.AuthenticationException' imported but unused\napp/api/v1/endpoints/config.py:12:1: F401 'app.core.exceptions.ConflictException' imported but unused\napp/api/v1/endpoints/config.py:12:121: E501 line too long (138 > 120 characters)\napp/api/v1/endpoints/config.py:15:1: F401 'app.services.config_manager.ProviderConfig' imported but unused\napp/api/v1/endpoints/config.py:15:1: F401 'app.services.config_manager.RoutingConfig' imported but unused\napp/api/v1/endpoints/config.py:15:1: F401 'app.services.config_manager.FeatureFlags' imported but unused\napp/api/v1/endpoints/config.py:23:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/config.py:31:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/config.py:36:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/config.py:40:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/config.py:43:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/config.py:50:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:53:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:59:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:64:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:68:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/config.py:75:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:88:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:93:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:97:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/config.py:105:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:108:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:121:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:126:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:132:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/config.py:141:9: F841 local variable 'current_config' is assigned to but never used\napp/api/v1/endpoints/config.py:142:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:145:58: W291 trailing whitespace\napp/api/v1/endpoints/config.py:148:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:151:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:154:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:157:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:160:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:173:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:179:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/config.py:186:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:195:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:200:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:204:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/config.py:212:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:216:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:224:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:232:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:235:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:244:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:250:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/config.py:257:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:268:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:273:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:277:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/config.py:285:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:288:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:296:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:300:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/config.py:307:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:316:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:321:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:325:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/config.py:333:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:336:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:341:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:345:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:349:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:361:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:366:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:370:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/config.py:379:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:384:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:388:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/config.py:398:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:401:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:406:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:412:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/config.py:422:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:427:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:431:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/config.py:445:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:452:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:457:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:463:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/config.py:471:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:474:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:482:1: W293 blank line contains whitespace\napp/api/v1/endpoints/config.py:484:45: W292 no newline at end of file\napp/api/v1/endpoints/customers.py:15:1: F401 'app.core.responses.APIResponseHelper' imported but unused\napp/api/v1/endpoints/customers.py:17:1: F401 'app.core.security_utils.sanitize_sql_like_pattern' imported but unused\napp/api/v1/endpoints/customers.py:17:1: F401 'app.core.security_utils.sanitize_search_term' imported but unused\napp/api/v1/endpoints/customers.py:23:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/customers.py:30:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/customers.py:37:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/customers.py:51:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/customers.py:56:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/customers.py:62:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/customers.py:69:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/customers.py:79:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:84:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:99:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:101:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:112:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:114:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:125:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:127:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:146:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/customers.py:154:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:159:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:174:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:180:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:183:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:192:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:198:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:203:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:226:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:229:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:232:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/customers.py:241:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:246:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:261:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:271:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:279:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:282:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:291:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:295:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:298:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:314:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/customers.py:321:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:325:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:336:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:341:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:357:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/customers.py:366:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:370:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:381:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:388:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:392:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:396:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:412:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/customers.py:421:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:425:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:436:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:440:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:448:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:451:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:455:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:466:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/customers.py:475:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:479:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:490:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:494:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:507:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/customers.py:514:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:519:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:535:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:537:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:542:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:546:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:556:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:559:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:567:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:571:1: W293 blank line contains whitespace\napp/api/v1/endpoints/customers.py:583:6: W292 no newline at end of file\napp/api/v1/endpoints/dashboard.py:5:1: F401 'typing.Optional' imported but unused\napp/api/v1/endpoints/dashboard.py:5:1: F401 'typing.List' imported but unused\napp/api/v1/endpoints/dashboard.py:6:1: F401 'pydantic.Field' imported but unused\napp/api/v1/endpoints/dashboard.py:6:1: F401 'pydantic.validator' imported but unused\napp/api/v1/endpoints/dashboard.py:7:1: F401 'datetime.date' imported but unused\napp/api/v1/endpoints/dashboard.py:10:1: F401 'sqlalchemy.and_' imported but unused\napp/api/v1/endpoints/dashboard.py:10:1: F401 'sqlalchemy.case' imported but unused\napp/api/v1/endpoints/dashboard.py:11:1: F401 'collections.defaultdict' imported but unused\napp/api/v1/endpoints/dashboard.py:14:1: F401 'app.core.database.Product' imported but unused\napp/api/v1/endpoints/dashboard.py:14:1: F401 'app.core.database.Customer' imported but unused\napp/api/v1/endpoints/dashboard.py:24:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/dashboard.py:35:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:48:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:61:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:70:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:81:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:89:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:94:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:113:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:117:24: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/v1/endpoints/dashboard.py:120:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:127:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:133:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:143:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:185:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:195:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:198:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:213:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:217:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:230:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:241:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:245:34: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/v1/endpoints/dashboard.py:250:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:254:5: F841 local variable 'total_transactions' is assigned to but never used\napp/api/v1/endpoints/dashboard.py:256:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:265:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:268:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:271:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:274:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:284:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:290:30: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/v1/endpoints/dashboard.py:292:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:296:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:304:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:309:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:312:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:346:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:349:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:365:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:369:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:378:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:394:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:409:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:424:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:438:1: W293 blank line contains whitespace\napp/api/v1/endpoints/dashboard.py:442:6: W292 no newline at end of file\napp/api/v1/endpoints/employees.py:7:1: F401 'pydantic.BaseModel' imported but unused\napp/api/v1/endpoints/employees.py:15:1: F401 'app.models.employee.Employee' imported but unused\napp/api/v1/endpoints/employees.py:16:1: F401 'app.schemas.employee_schemas.TimeEntryResponse' imported but unused\napp/api/v1/endpoints/employees.py:22:1: F401 'app.middleware.rate_limit_middleware.limiter' imported but unused\napp/api/v1/endpoints/employees.py:29:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/employees.py:38:1: W293 blank line contains whitespace\napp/api/v1/endpoints/employees.py:47:1: W293 blank line contains whitespace\napp/api/v1/endpoints/employees.py:66:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/employees.py:94:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/employees.py:123:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/employees.py:158:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/employees.py:187:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/employees.py:214:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/employees.py:245:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/employees.py:280:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/employees.py:309:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/employees.py:337:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/employees.py:365:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/employees.py:394:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/employees.py:423:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/employees.py:446:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/employees.py:469:10: W292 no newline at end of file\napp/api/v1/endpoints/exports.py:6:1: F401 'typing.Optional' imported but unused\napp/api/v1/endpoints/exports.py:18:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/exports.py:33:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/exports.py:51:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/exports.py:64:6: W292 no newline at end of file\napp/api/v1/endpoints/fees.py:1:1: F401 'fastapi.Body' imported but unused\napp/api/v1/endpoints/fees.py:3:1: F401 'typing.Dict' imported but unused\napp/api/v1/endpoints/fees.py:3:1: F401 'typing.Any' imported but unused\napp/api/v1/endpoints/fees.py:10:28: E261 at least two spaces before inline comment\napp/api/v1/endpoints/fees.py:11:28: E261 at least two spaces before inline comment\napp/api/v1/endpoints/fees.py:18:75: E261 at least two spaces before inline comment\napp/api/v1/endpoints/fees.py:24:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/fees.py:30:121: E501 line too long (154 > 120 characters)\napp/api/v1/endpoints/fees.py:36:121: E501 line too long (136 > 120 characters)\napp/api/v1/endpoints/fees.py:42:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/fees.py:59:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/fees.py:63:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/fees.py:68:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/fees.py:74:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/fees.py:80:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/fees.py:88:35: E261 at least two spaces before inline comment\napp/api/v1/endpoints/fees.py:106:121: E501 line too long (202 > 120 characters)\napp/api/v1/endpoints/fees.py:115:121: E501 line too long (147 > 120 characters)\napp/api/v1/endpoints/fees.py:129:75: E261 at least two spaces before inline comment\napp/api/v1/endpoints/fees.py:135:9: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/fees.py:141:5: E303 too many blank lines (2)\napp/api/v1/endpoints/fees.py:148:71: E261 at least two spaces before inline comment\napp/api/v1/endpoints/fees.py:156:5: F841 local variable 've' is assigned to but never used\napp/api/v1/endpoints/fees.py:156:29: E261 at least two spaces before inline comment\napp/api/v1/endpoints/fees.py:158:5: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/fees.py:177:44: E261 at least two spaces before inline comment\napp/api/v1/endpoints/fees.py:210:72: E261 at least two spaces before inline comment\napp/api/v1/endpoints/fees.py:213:5: F841 local variable 've' is assigned to but never used\napp/api/v1/endpoints/fees.py:213:29: E261 at least two spaces before inline comment\napp/api/v1/endpoints/fees.py:215:5: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/files.py:22:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/files.py:28:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/files.py:34:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/files.py:43:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/files.py:52:1: W293 blank line contains whitespace\napp/api/v1/endpoints/files.py:65:1: W293 blank line contains whitespace\napp/api/v1/endpoints/files.py:74:1: W293 blank line contains whitespace\napp/api/v1/endpoints/files.py:82:1: W293 blank line contains whitespace\napp/api/v1/endpoints/files.py:86:1: W293 blank line contains whitespace\napp/api/v1/endpoints/files.py:97:1: W293 blank line contains whitespace\napp/api/v1/endpoints/files.py:107:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/files.py:126:1: W293 blank line contains whitespace\napp/api/v1/endpoints/files.py:133:1: W293 blank line contains whitespace\napp/api/v1/endpoints/files.py:141:1: W293 blank line contains whitespace\napp/api/v1/endpoints/files.py:146:1: W293 blank line contains whitespace\napp/api/v1/endpoints/files.py:156:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/files.py:174:1: W293 blank line contains whitespace\napp/api/v1/endpoints/files.py:183:1: W293 blank line contains whitespace\napp/api/v1/endpoints/files.py:190:1: W293 blank line contains whitespace\napp/api/v1/endpoints/files.py:195:1: W293 blank line contains whitespace\napp/api/v1/endpoints/files.py:199:1: W293 blank line contains whitespace\napp/api/v1/endpoints/files.py:210:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/files.py:229:1: W293 blank line contains whitespace\napp/api/v1/endpoints/files.py:247:1: W293 blank line contains whitespace\napp/api/v1/endpoints/files.py:255:1: W293 blank line contains whitespace\napp/api/v1/endpoints/files.py:259:1: W293 blank line contains whitespace\napp/api/v1/endpoints/files.py:263:1: W293 blank line contains whitespace\napp/api/v1/endpoints/files.py:274:1: W293 blank line contains whitespace\napp/api/v1/endpoints/files.py:284:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/files.py:303:1: W293 blank line contains whitespace\napp/api/v1/endpoints/files.py:311:1: W293 blank line contains whitespace\napp/api/v1/endpoints/files.py:313:1: W293 blank line contains whitespace\napp/api/v1/endpoints/files.py:320:1: W293 blank line contains whitespace\napp/api/v1/endpoints/files.py:325:1: W293 blank line contains whitespace\napp/api/v1/endpoints/files.py:336:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/files.py:348:42: W291 trailing whitespace\napp/api/v1/endpoints/files.py:352:1: W293 blank line contains whitespace\napp/api/v1/endpoints/files.py:359:1: W293 blank line contains whitespace\napp/api/v1/endpoints/files.py:362:1: W293 blank line contains whitespace\napp/api/v1/endpoints/files.py:369:1: W293 blank line contains whitespace\napp/api/v1/endpoints/files.py:378:1: W293 blank line contains whitespace\napp/api/v1/endpoints/files.py:389:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/files.py:406:1: W293 blank line contains whitespace\napp/api/v1/endpoints/files.py:416:1: W293 blank line contains whitespace\napp/api/v1/endpoints/files.py:425:1: W293 blank line contains whitespace\napp/api/v1/endpoints/files.py:432:1: W293 blank line contains whitespace\napp/api/v1/endpoints/files.py:442:1: W293 blank line contains whitespace\napp/api/v1/endpoints/files.py:450:10: W292 no newline at end of file\napp/api/v1/endpoints/health.py:19:27: W291 trailing whitespace\napp/api/v1/endpoints/health.py:20:19: W291 trailing whitespace\napp/api/v1/endpoints/health.py:47:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:50:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:58:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:65:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:81:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:105:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:107:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:117:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:124:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:127:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:144:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:150:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:161:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:166:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:200:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:206:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:228:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:244:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:249:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:253:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:257:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:267:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:278:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:284:71: W291 trailing whitespace\napp/api/v1/endpoints/health.py:285:70: W291 trailing whitespace\napp/api/v1/endpoints/health.py:288:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:298:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:300:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:312:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:315:51: W291 trailing whitespace\napp/api/v1/endpoints/health.py:318:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:321:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:325:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:336:58: W291 trailing whitespace\napp/api/v1/endpoints/health.py:341:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:349:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:353:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:356:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:372:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:375:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:386:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:394:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:416:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:419:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:440:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:450:1: W293 blank line contains whitespace\napp/api/v1/endpoints/health.py:461:28: W292 no newline at end of file\napp/api/v1/endpoints/inventory.py:5:1: F401 'pydantic.BaseModel' imported but unused\napp/api/v1/endpoints/inventory.py:9:14: E261 at least two spaces before inline comment\napp/api/v1/endpoints/inventory.py:10:1: F401 'uuid.UUID' imported but unused\napp/api/v1/endpoints/inventory.py:14:35: E261 at least two spaces before inline comment\napp/api/v1/endpoints/inventory.py:19:1: F401 'app.core.response_helper.APIResponseHelper' imported but unused\napp/api/v1/endpoints/inventory.py:25:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/inventory.py:35:1: W293 blank line contains whitespace\napp/api/v1/endpoints/inventory.py:40:1: W293 blank line contains whitespace\napp/api/v1/endpoints/inventory.py:43:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/inventory.py:53:1: W293 blank line contains whitespace\napp/api/v1/endpoints/inventory.py:57:1: W293 blank line contains whitespace\napp/api/v1/endpoints/inventory.py:67:1: W293 blank line contains whitespace\napp/api/v1/endpoints/inventory.py:70:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/inventory.py:81:1: W293 blank line contains whitespace\napp/api/v1/endpoints/inventory.py:85:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/inventory.py:96:1: W293 blank line contains whitespace\napp/api/v1/endpoints/inventory.py:101:1: W293 blank line contains whitespace\napp/api/v1/endpoints/inventory.py:111:1: W293 blank line contains whitespace\napp/api/v1/endpoints/inventory.py:112:121: E501 line too long (122 > 120 characters)\napp/api/v1/endpoints/inventory.py:115:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/inventory.py:125:1: W293 blank line contains whitespace\napp/api/v1/endpoints/inventory.py:130:1: W293 blank line contains whitespace\napp/api/v1/endpoints/inventory.py:140:1: W293 blank line contains whitespace\napp/api/v1/endpoints/inventory.py:150:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/inventory.py:161:1: W293 blank line contains whitespace\napp/api/v1/endpoints/inventory.py:164:1: W293 blank line contains whitespace\napp/api/v1/endpoints/inventory.py:169:1: W293 blank line contains whitespace\napp/api/v1/endpoints/inventory.py:199:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/inventory.py:212:1: W293 blank line contains whitespace\napp/api/v1/endpoints/inventory.py:214:12: W291 trailing whitespace\napp/api/v1/endpoints/inventory.py:216:19: W291 trailing whitespace\napp/api/v1/endpoints/inventory.py:217:21: W291 trailing whitespace\napp/api/v1/endpoints/inventory.py:218:31: W291 trailing whitespace\napp/api/v1/endpoints/inventory.py:223:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/inventory.py:237:1: W293 blank line contains whitespace\napp/api/v1/endpoints/inventory.py:242:1: W293 blank line contains whitespace\napp/api/v1/endpoints/inventory.py:254:12: W291 trailing whitespace\napp/api/v1/endpoints/inventory.py:255:17: W291 trailing whitespace\napp/api/v1/endpoints/inventory.py:257:19: W291 trailing whitespace\napp/api/v1/endpoints/inventory.py:258:21: W291 trailing whitespace\napp/api/v1/endpoints/inventory.py:259:31: W291 trailing whitespace\napp/api/v1/endpoints/inventory.py:266:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/inventory.py:275:1: W293 blank line contains whitespace\napp/api/v1/endpoints/inventory.py:279:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/inventory.py:281:121: E501 line too long (140 > 120 characters)\napp/api/v1/endpoints/inventory.py:289:1: W293 blank line contains whitespace\napp/api/v1/endpoints/inventory.py:292:16: W291 trailing whitespace\napp/api/v1/endpoints/inventory.py:297:5: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/inventory.py:314:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/inventory.py:314:45: E261 at least two spaces before inline comment\napp/api/v1/endpoints/inventory.py:317:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/inventory.py:317:46: E261 at least two spaces before inline comment\napp/api/v1/endpoints/inventory.py:322:40: E261 at least two spaces before inline comment\napp/api/v1/endpoints/inventory.py:341:1: W293 blank line contains whitespace\napp/api/v1/endpoints/inventory.py:351:1: W293 blank line contains whitespace\napp/api/v1/endpoints/inventory.py:360:5: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/inventory.py:370:121: E501 line too long (130 > 120 characters)\napp/api/v1/endpoints/inventory.py:374:68: E261 at least two spaces before inline comment\napp/api/v1/endpoints/inventory.py:377:44: E261 at least two spaces before inline comment\napp/api/v1/endpoints/inventory.py:386:121: E501 line too long (154 > 120 characters)\napp/api/v1/endpoints/menu.py:6:1: F401 'pydantic.BaseModel' imported but unused\napp/api/v1/endpoints/menu.py:15:1: F401 'app.core.redis_client.get_redis' imported but unused\napp/api/v1/endpoints/menu.py:15:1: F401 'app.core.redis_client.RedisClient' imported but unused\napp/api/v1/endpoints/menu.py:17:1: F401 'app.api.v1.endpoints.products.ProductResponse' imported but unused\napp/api/v1/endpoints/menu.py:18:1: F401 'app.core.onboarding_helper.OnboardingHelper' imported but unused\napp/api/v1/endpoints/menu.py:24:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/menu.py:32:36: W291 trailing whitespace\napp/api/v1/endpoints/menu.py:45:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu.py:65:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu.py:69:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu.py:81:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/menu.py:89:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu.py:91:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu.py:94:72: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/v1/endpoints/menu.py:96:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu.py:100:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu.py:111:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu.py:114:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu.py:118:29: W291 trailing whitespace\napp/api/v1/endpoints/menu.py:121:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu.py:128:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu.py:132:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu.py:134:121: E501 line too long (144 > 120 characters)\napp/api/v1/endpoints/menu.py:137:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu.py:165:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu.py:180:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu.py:184:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/menu.py:192:74: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/v1/endpoints/menu.py:194:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu.py:204:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu.py:208:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu.py:233:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu.py:248:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu.py:250:64: W292 no newline at end of file\napp/api/v1/endpoints/menu_optimized.py:80:121: E501 line too long (124 > 120 characters)\napp/api/v1/endpoints/menu_optimized.py:81:121: E501 line too long (124 > 120 characters)\napp/api/v1/endpoints/menu_optimized.py:121:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu_optimized.py:138:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu_optimized.py:151:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu_optimized.py:159:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu_optimized.py:162:52: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/v1/endpoints/menu_optimized.py:163:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu_optimized.py:166:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu_optimized.py:172:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu_optimized.py:176:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu_optimized.py:179:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu_optimized.py:185:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu_optimized.py:196:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu_optimized.py:206:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu_optimized.py:233:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu_optimized.py:249:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu_optimized.py:261:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu_optimized.py:270:35: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/v1/endpoints/menu_optimized.py:274:32: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/v1/endpoints/menu_optimized.py:278:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu_optimized.py:280:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu_optimized.py:285:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu_optimized.py:296:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu_optimized.py:301:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu_optimized.py:328:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu_optimized.py:343:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu_optimized.py:348:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu_optimized.py:354:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu_optimized.py:363:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu_optimized.py:368:1: W293 blank line contains whitespace\napp/api/v1/endpoints/menu_optimized.py:377:10: W292 no newline at end of file\napp/api/v1/endpoints/monitoring.py:8:1: F401 'pydantic.BaseModel' imported but unused\napp/api/v1/endpoints/monitoring.py:8:1: F401 'pydantic.Field' imported but unused\napp/api/v1/endpoints/monitoring.py:45:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:51:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:56:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:60:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:64:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:71:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:76:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:84:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:97:65: W291 trailing whitespace\napp/api/v1/endpoints/monitoring.py:98:45: W291 trailing whitespace\napp/api/v1/endpoints/monitoring.py:102:65: W291 trailing whitespace\napp/api/v1/endpoints/monitoring.py:103:45: W291 trailing whitespace\napp/api/v1/endpoints/monitoring.py:114:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:122:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:125:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:128:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:145:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:150:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:152:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:170:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:175:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:180:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:183:9: F841 local variable 'fresh_status' is assigned to but never used\napp/api/v1/endpoints/monitoring.py:184:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:188:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:191:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:212:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:218:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:220:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:232:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:253:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:256:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:261:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:264:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:267:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:273:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:283:23: W291 trailing whitespace\napp/api/v1/endpoints/monitoring.py:284:27: W291 trailing whitespace\napp/api/v1/endpoints/monitoring.py:290:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:293:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:299:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:305:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:309:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:312:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:333:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:338:5: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/monitoring.py:346:1: W293 blank line contains whitespace\napp/api/v1/endpoints/monitoring.py:353:6: W292 no newline at end of file\napp/api/v1/endpoints/notifications.py:27:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/notifications.py:33:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/notifications.py:44:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/notifications.py:51:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/notifications.py:59:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/notifications.py:78:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:86:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:93:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:106:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:116:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/notifications.py:128:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:135:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:143:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:153:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/notifications.py:171:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:183:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:194:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:204:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:212:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:222:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:232:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/notifications.py:253:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:263:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:272:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:281:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:291:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/notifications.py:312:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:322:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:329:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:336:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:349:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:359:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/notifications.py:370:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:385:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:399:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:409:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/notifications.py:424:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:437:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:447:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:457:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/notifications.py:468:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:479:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:485:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:495:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/notifications.py:512:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:515:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:521:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:531:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/notifications.py:549:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:563:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:566:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:579:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:588:1: W293 blank line contains whitespace\napp/api/v1/endpoints/notifications.py:596:10: W292 no newline at end of file\napp/api/v1/endpoints/orders.py:16:1: E402 module level import not at top of file\napp/api/v1/endpoints/orders.py:17:1: E402 module level import not at top of file\napp/api/v1/endpoints/orders.py:18:1: E402 module level import not at top of file\napp/api/v1/endpoints/orders.py:18:82: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:19:1: E402 module level import not at top of file\napp/api/v1/endpoints/orders.py:20:1: E402 module level import not at top of file\napp/api/v1/endpoints/orders.py:21:1: E402 module level import not at top of file\napp/api/v1/endpoints/orders.py:22:1: E402 module level import not at top of file\napp/api/v1/endpoints/orders.py:23:1: E402 module level import not at top of file\napp/api/v1/endpoints/orders.py:24:23: W291 trailing whitespace\napp/api/v1/endpoints/orders.py:25:26: W291 trailing whitespace\napp/api/v1/endpoints/orders.py:26:33: W291 trailing whitespace\napp/api/v1/endpoints/orders.py:31:1: E402 module level import not at top of file\napp/api/v1/endpoints/orders.py:32:1: E402 module level import not at top of file\napp/api/v1/endpoints/orders.py:33:1: E402 module level import not at top of file\napp/api/v1/endpoints/orders.py:33:61: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:34:1: E402 module level import not at top of file\napp/api/v1/endpoints/orders.py:34:62: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:39:1: E402 module level import not at top of file\napp/api/v1/endpoints/orders.py:39:51: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:40:1: E402 module level import not at top of file\napp/api/v1/endpoints/orders.py:41:1: E402 module level import not at top of file\napp/api/v1/endpoints/orders.py:41:52: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:42:1: E402 module level import not at top of file\napp/api/v1/endpoints/orders.py:42:28: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:45:31: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:48:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/orders.py:56:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/orders.py:59:40: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:65:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/orders.py:71:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/orders.py:74:31: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:92:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/orders.py:102:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/orders.py:108:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:116:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/orders.py:120:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/orders.py:129:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/orders.py:142:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:151:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:165:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:180:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:182:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:185:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:188:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:191:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:194:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:201:121: E501 line too long (126 > 120 characters)\napp/api/v1/endpoints/orders.py:203:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:208:121: E501 line too long (126 > 120 characters)\napp/api/v1/endpoints/orders.py:224:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:239:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/orders.py:247:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:256:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:268:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:283:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:289:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:292:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:301:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:306:121: E501 line too long (126 > 120 characters)\napp/api/v1/endpoints/orders.py:308:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:322:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:324:121: E501 line too long (122 > 120 characters)\napp/api/v1/endpoints/orders.py:338:70: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:339:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:350:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/orders.py:360:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:371:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:397:39: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:403:28: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:418:23: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:430:31: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/v1/endpoints/orders.py:433:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:436:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:439:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:445:121: E501 line too long (155 > 120 characters)\napp/api/v1/endpoints/orders.py:446:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:450:45: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:465:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:467:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:474:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:478:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:487:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:490:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:492:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:507:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:525:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:548:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/orders.py:556:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:562:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:567:24: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/orders.py:571:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:584:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:607:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/orders.py:616:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:621:24: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/orders.py:625:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:628:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:631:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:638:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:641:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:645:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:654:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:658:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:674:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:707:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/orders.py:717:81: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:717:121: E501 line too long (133 > 120 characters)\napp/api/v1/endpoints/orders.py:718:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:723:24: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/orders.py:727:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:730:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:734:24: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/orders.py:738:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:750:121: E501 line too long (127 > 120 characters)\napp/api/v1/endpoints/orders.py:754:20: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:756:22: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:768:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:772:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:782:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:788:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/orders.py:797:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:802:24: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/orders.py:806:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:809:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:813:24: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/orders.py:817:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:822:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:826:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:828:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:833:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:841:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:847:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/orders.py:852:51: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:862:63: E701 multiple statements on one line (colon)\napp/api/v1/endpoints/orders.py:862:64: E241 multiple spaces after ':'\napp/api/v1/endpoints/orders.py:862:64: E272 multiple spaces before keyword\napp/api/v1/endpoints/orders.py:862:121: E501 line too long (138 > 120 characters)\napp/api/v1/endpoints/orders.py:868:24: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/orders.py:872:1: W293 blank line contains whitespace\napp/api/v1/endpoints/orders.py:876:36: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:879:24: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/orders.py:892:14: E111 indentation is not a multiple of 4\napp/api/v1/endpoints/orders.py:892:14: E117 over-indented\napp/api/v1/endpoints/orders.py:893:17: E121 continuation line under-indented for hanging indent\napp/api/v1/endpoints/orders.py:894:28: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/orders.py:896:13: E122 continuation line missing indentation or outdented\napp/api/v1/endpoints/orders.py:897:10: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:901:114: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:901:121: E501 line too long (146 > 120 characters)\napp/api/v1/endpoints/orders.py:905:32: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/orders.py:914:121: E501 line too long (158 > 120 characters)\napp/api/v1/endpoints/orders.py:922:24: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/orders.py:929:74: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:940:28: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/orders.py:941:60: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:950:55: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:957:55: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:958:18: E111 indentation is not a multiple of 4\napp/api/v1/endpoints/orders.py:958:18: E117 over-indented\napp/api/v1/endpoints/orders.py:959:21: E121 continuation line under-indented for hanging indent\napp/api/v1/endpoints/orders.py:960:32: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/orders.py:962:17: E122 continuation line missing indentation or outdented\napp/api/v1/endpoints/orders.py:967:28: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/orders.py:974:49: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:976:40: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:983:23: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:987:41: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:988:27: E251 unexpected spaces around keyword / parameter equals\napp/api/v1/endpoints/orders.py:988:47: E241 multiple spaces after ','\napp/api/v1/endpoints/orders.py:995:42: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:1000:71: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:1001:57: E701 multiple statements on one line (colon)\napp/api/v1/endpoints/orders.py:1004:52: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:1010:52: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:1015:35: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:1022:24: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/orders.py:1037:46: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:1038:121: E501 line too long (123 > 120 characters)\napp/api/v1/endpoints/orders.py:1044:5: E303 too many blank lines (2)\napp/api/v1/endpoints/orders.py:1045:60: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:1048:89: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:1055:121: E501 line too long (133 > 120 characters)\napp/api/v1/endpoints/orders.py:1058:121: E501 line too long (140 > 120 characters)\napp/api/v1/endpoints/orders.py:1075:38: E261 at least two spaces before inline comment\napp/api/v1/endpoints/orders.py:1078:6: W292 no newline at end of file\napp/api/v1/endpoints/payment_configurations.py:3:1: F401 'typing.Dict' imported but unused\napp/api/v1/endpoints/payment_configurations.py:3:1: F401 'typing.Any' imported but unused\napp/api/v1/endpoints/payment_configurations.py:17:59: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payment_configurations.py:23:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/payment_configurations.py:30:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/payment_configurations.py:35:40: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payment_configurations.py:37:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/payment_configurations.py:43:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/payment_configurations.py:48:69: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payment_configurations.py:56:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/payment_configurations.py:66:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/payment_configurations.py:77:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payment_configurations.py:92:32: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payment_configurations.py:95:5: F841 local variable 've' is assigned to but never used\napp/api/v1/endpoints/payment_configurations.py:97:5: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/payment_configurations.py:97:27: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payment_configurations.py:113:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payment_configurations.py:116:121: E501 line too long (135 > 120 characters)\napp/api/v1/endpoints/payment_configurations.py:141:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payment_configurations.py:146:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payment_configurations.py:154:63: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payment_configurations.py:164:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payment_configurations.py:169:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payment_configurations.py:176:37: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payment_configurations.py:184:30: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payment_configurations.py:187:5: F841 local variable 've' is assigned to but never used\napp/api/v1/endpoints/payment_configurations.py:189:5: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/payment_configurations.py:189:27: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payment_configurations.py:206:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payment_configurations.py:211:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payment_configurations.py:215:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payment_configurations.py:218:121: E501 line too long (153 > 120 characters)\napp/api/v1/endpoints/payment_configurations.py:219:16: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:23:121: E501 line too long (156 > 120 characters)\napp/api/v1/endpoints/payments.py:38:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/payments.py:42:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/payments.py:52:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/payments.py:58:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/payments.py:66:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/payments.py:73:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/payments.py:81:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/payments.py:86:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/payments.py:94:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/payments.py:103:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/payments.py:112:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:114:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:119:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:123:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/payments.py:126:39: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:127:22: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:138:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:161:121: E501 line too long (124 > 120 characters)\napp/api/v1/endpoints/payments.py:165:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:169:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:174:46: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:177:33: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:180:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:184:47: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:190:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:195:47: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:202:50: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:207:53: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:209:21: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:214:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:217:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:219:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:231:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/payments.py:246:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:250:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:265:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:274:121: E501 line too long (141 > 120 characters)\napp/api/v1/endpoints/payments.py:278:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:281:55: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:287:121: E501 line too long (151 > 120 characters)\napp/api/v1/endpoints/payments.py:291:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:300:121: E501 line too long (191 > 120 characters)\napp/api/v1/endpoints/payments.py:304:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:319:121: E501 line too long (121 > 120 characters)\napp/api/v1/endpoints/payments.py:323:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:326:91: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:335:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:336:26: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:340:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:352:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:354:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:358:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:367:37: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:368:48: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:377:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:389:25: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:393:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:395:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:404:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/payments.py:408:48: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:409:22: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:420:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:437:121: E501 line too long (132 > 120 characters)\napp/api/v1/endpoints/payments.py:465:26: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:469:15: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:473:47: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:483:21: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:540:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:542:38: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:543:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:545:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:571:44: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:585:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/payments.py:587:46: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:599:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:613:10: E111 indentation is not a multiple of 4\napp/api/v1/endpoints/payments.py:613:10: E117 over-indented\napp/api/v1/endpoints/payments.py:614:13: E121 continuation line under-indented for hanging indent\napp/api/v1/endpoints/payments.py:621:9: E122 continuation line missing indentation or outdented\napp/api/v1/endpoints/payments.py:622:10: E111 indentation is not a multiple of 4\napp/api/v1/endpoints/payments.py:628:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:630:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:637:28: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:648:51: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:653:72: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:660:21: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:662:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:665:22: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:666:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:668:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:677:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/payments.py:690:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:698:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:700:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:714:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:720:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/payments.py:726:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:730:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:738:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:746:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/payments.py:748:38: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:750:106: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:750:121: E501 line too long (124 > 120 characters)\napp/api/v1/endpoints/payments.py:757:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:760:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:770:29: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:778:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:787:121: E501 line too long (124 > 120 characters)\napp/api/v1/endpoints/payments.py:788:121: E501 line too long (128 > 120 characters)\napp/api/v1/endpoints/payments.py:797:121: E501 line too long (124 > 120 characters)\napp/api/v1/endpoints/payments.py:811:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:815:121: E501 line too long (134 > 120 characters)\napp/api/v1/endpoints/payments.py:820:121: E501 line too long (131 > 120 characters)\napp/api/v1/endpoints/payments.py:823:25: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:836:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:838:32: E127 continuation line over-indented for visual indent\napp/api/v1/endpoints/payments.py:839:121: E501 line too long (139 > 120 characters)\napp/api/v1/endpoints/payments.py:850:41: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:862:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:865:121: E501 line too long (122 > 120 characters)\napp/api/v1/endpoints/payments.py:866:121: E501 line too long (124 > 120 characters)\napp/api/v1/endpoints/payments.py:867:80: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:877:45: E701 multiple statements on one line (colon)\napp/api/v1/endpoints/payments.py:888:14: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:892:121: E501 line too long (124 > 120 characters)\napp/api/v1/endpoints/payments.py:898:28: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:915:55: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:926:24: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:930:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/payments.py:933:36: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:945:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:967:71: E231 missing whitespace after ','\napp/api/v1/endpoints/payments.py:967:121: E501 line too long (133 > 120 characters)\napp/api/v1/endpoints/payments.py:993:21: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:995:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:998:58: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1002:27: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1009:24: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1014:5: E303 too many blank lines (2)\napp/api/v1/endpoints/payments.py:1015:46: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1018:62: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1022:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:1034:20: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1036:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:1045:10: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1064:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/payments.py:1075:5: F841 local variable 'restaurant_id' is assigned to but never used\napp/api/v1/endpoints/payments.py:1076:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:1078:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:1086:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:1089:63: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1094:33: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1096:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:1101:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:1103:36: E701 multiple statements on one line (colon)\napp/api/v1/endpoints/payments.py:1103:71: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1104:39: E701 multiple statements on one line (colon)\napp/api/v1/endpoints/payments.py:1104:79: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1105:39: E701 multiple statements on one line (colon)\napp/api/v1/endpoints/payments.py:1105:63: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1106:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:1108:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:1112:52: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1113:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:1117:64: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1125:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/payments.py:1126:18: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1128:19: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1134:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/payments.py:1135:20: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1136:35: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1138:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/payments.py:1139:37: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1141:41: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1142:16: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1148:40: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1150:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/payments.py:1164:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:1172:19: F821 undefined name 'ServiceUnavailableError'\napp/api/v1/endpoints/payments.py:1186:121: E501 line too long (128 > 120 characters)\napp/api/v1/endpoints/payments.py:1193:121: E501 line too long (128 > 120 characters)\napp/api/v1/endpoints/payments.py:1194:121: E501 line too long (135 > 120 characters)\napp/api/v1/endpoints/payments.py:1201:93: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1201:121: E501 line too long (121 > 120 characters)\napp/api/v1/endpoints/payments.py:1208:50: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1214:48: F821 undefined name 'PaymentStatus'\napp/api/v1/endpoints/payments.py:1214:77: F821 undefined name 'PaymentStatus'\napp/api/v1/endpoints/payments.py:1214:121: E501 line too long (149 > 120 characters)\napp/api/v1/endpoints/payments.py:1218:46: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1222:28: E251 unexpected spaces around keyword / parameter equals\napp/api/v1/endpoints/payments.py:1222:121: E501 line too long (202 > 120 characters)\napp/api/v1/endpoints/payments.py:1223:30: E251 unexpected spaces around keyword / parameter equals\napp/api/v1/endpoints/payments.py:1223:121: E501 line too long (204 > 120 characters)\napp/api/v1/endpoints/payments.py:1225:28: E251 unexpected spaces around keyword / parameter equals\napp/api/v1/endpoints/payments.py:1225:121: E501 line too long (260 > 120 characters)\napp/api/v1/endpoints/payments.py:1228:82: F821 undefined name 'PaymentStatus'\napp/api/v1/endpoints/payments.py:1237:57: F821 undefined name 'PaymentStatus'\napp/api/v1/endpoints/payments.py:1242:93: F821 undefined name 'PaymentStatus'\napp/api/v1/endpoints/payments.py:1242:121: E501 line too long (156 > 120 characters)\napp/api/v1/endpoints/payments.py:1243:89: F821 undefined name 'PaymentStatus'\napp/api/v1/endpoints/payments.py:1243:121: E501 line too long (146 > 120 characters)\napp/api/v1/endpoints/payments.py:1245:121: E501 line too long (124 > 120 characters)\napp/api/v1/endpoints/payments.py:1246:73: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1247:121: E501 line too long (172 > 120 characters)\napp/api/v1/endpoints/payments.py:1248:29: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1252:14: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1256:121: E501 line too long (124 > 120 characters)\napp/api/v1/endpoints/payments.py:1257:121: E501 line too long (150 > 120 characters)\napp/api/v1/endpoints/payments.py:1266:86: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1268:121: E501 line too long (129 > 120 characters)\napp/api/v1/endpoints/payments.py:1269:121: E501 line too long (150 > 120 characters)\napp/api/v1/endpoints/payments.py:1275:14: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1301:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:1309:19: F821 undefined name 'ServiceUnavailableError'\napp/api/v1/endpoints/payments.py:1322:121: E501 line too long (124 > 120 characters)\napp/api/v1/endpoints/payments.py:1324:121: E501 line too long (139 > 120 characters)\napp/api/v1/endpoints/payments.py:1326:33: F821 undefined name 'PaymentStatus'\napp/api/v1/endpoints/payments.py:1326:61: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1327:14: E111 indentation is not a multiple of 4\napp/api/v1/endpoints/payments.py:1327:14: E117 over-indented\napp/api/v1/endpoints/payments.py:1328:17: E121 continuation line under-indented for hanging indent\napp/api/v1/endpoints/payments.py:1330:121: E501 line too long (124 > 120 characters)\napp/api/v1/endpoints/payments.py:1331:121: E501 line too long (142 > 120 characters)\napp/api/v1/endpoints/payments.py:1332:14: E114 indentation is not a multiple of 4 (comment)\napp/api/v1/endpoints/payments.py:1333:14: E114 indentation is not a multiple of 4 (comment)\napp/api/v1/endpoints/payments.py:1336:97: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1340:121: E501 line too long (124 > 120 characters)\napp/api/v1/endpoints/payments.py:1341:26: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1345:50: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1350:121: E501 line too long (128 > 120 characters)\napp/api/v1/endpoints/payments.py:1352:39: F821 undefined name 'PaymentStatus'\napp/api/v1/endpoints/payments.py:1363:121: E501 line too long (124 > 120 characters)\napp/api/v1/endpoints/payments.py:1365:121: E501 line too long (126 > 120 characters)\napp/api/v1/endpoints/payments.py:1366:14: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1370:121: E501 line too long (124 > 120 characters)\napp/api/v1/endpoints/payments.py:1372:121: E501 line too long (167 > 120 characters)\napp/api/v1/endpoints/payments.py:1384:121: E501 line too long (129 > 120 characters)\napp/api/v1/endpoints/payments.py:1385:121: E501 line too long (150 > 120 characters)\napp/api/v1/endpoints/payments.py:1405:21: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1415:5: F841 local variable 'restaurant_id' is assigned to but never used\napp/api/v1/endpoints/payments.py:1416:1: W293 blank line contains whitespace\napp/api/v1/endpoints/payments.py:1424:19: F821 undefined name 'ServiceUnavailableError'\napp/api/v1/endpoints/payments.py:1435:121: E501 line too long (139 > 120 characters)\napp/api/v1/endpoints/payments.py:1443:9: E303 too many blank lines (2)\napp/api/v1/endpoints/payments.py:1443:47: F821 undefined name 'PaymentStatus'\napp/api/v1/endpoints/payments.py:1443:121: E501 line too long (150 > 120 characters)\napp/api/v1/endpoints/payments.py:1443:146: E231 missing whitespace after ','\napp/api/v1/endpoints/payments.py:1444:14: E114 indentation is not a multiple of 4 (comment)\napp/api/v1/endpoints/payments.py:1444:14: E117 over-indented (comment)\napp/api/v1/endpoints/payments.py:1446:95: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1446:121: E501 line too long (130 > 120 characters)\napp/api/v1/endpoints/payments.py:1448:121: E501 line too long (124 > 120 characters)\napp/api/v1/endpoints/payments.py:1457:62: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1459:121: E501 line too long (129 > 120 characters)\napp/api/v1/endpoints/payments.py:1460:121: E501 line too long (150 > 120 characters)\napp/api/v1/endpoints/payments.py:1477:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/payments.py:1477:58: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1479:27: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1480:34: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1485:43: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1487:67: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1507:28: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1516:57: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1525:27: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1543:20: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1547:9: E116 unexpected indentation (comment)\napp/api/v1/endpoints/payments.py:1560:121: E501 line too long (126 > 120 characters)\napp/api/v1/endpoints/payments.py:1562:38: F821 undefined name 'PaymentStatus'\napp/api/v1/endpoints/payments.py:1562:66: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1563:38: F821 undefined name 'PaymentStatus'\napp/api/v1/endpoints/payments.py:1565:121: E501 line too long (129 > 120 characters)\napp/api/v1/endpoints/payments.py:1580:121: E501 line too long (135 > 120 characters)\napp/api/v1/endpoints/payments.py:1591:121: E501 line too long (126 > 120 characters)\napp/api/v1/endpoints/payments.py:1593:38: F821 undefined name 'PaymentStatus'\napp/api/v1/endpoints/payments.py:1594:38: F821 undefined name 'PaymentStatus'\napp/api/v1/endpoints/payments.py:1613:121: E501 line too long (134 > 120 characters)\napp/api/v1/endpoints/payments.py:1622:39: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1625:121: E501 line too long (126 > 120 characters)\napp/api/v1/endpoints/payments.py:1633:38: F821 undefined name 'PaymentStatus'\napp/api/v1/endpoints/payments.py:1633:67: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1634:38: F821 undefined name 'PaymentStatus'\napp/api/v1/endpoints/payments.py:1634:66: E261 at least two spaces before inline comment\napp/api/v1/endpoints/payments.py:1651:22: E111 indentation is not a multiple of 4\napp/api/v1/endpoints/payments.py:1651:22: E117 over-indented\napp/api/v1/endpoints/payments.py:1651:121: E501 line too long (141 > 120 characters)\napp/api/v1/endpoints/payments.py:1654:121: E501 line too long (131 > 120 characters)\napp/api/v1/endpoints/payments.py:1658:121: E501 line too long (128 > 120 characters)\napp/api/v1/endpoints/payments.py:1673:121: E501 line too long (145 > 120 characters)\napp/api/v1/endpoints/payments.py:1677:121: E501 line too long (154 > 120 characters)\napp/api/v1/endpoints/payments.py:1684:121: E501 line too long (149 > 120 characters)\napp/api/v1/endpoints/payments.py:1686:64: W292 no newline at end of file\napp/api/v1/endpoints/platform.py:17:1: F401 'app.core.validation.validate_model_jsonb_fields' imported but unused\napp/api/v1/endpoints/platform.py:26:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform.py:32:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform.py:44:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform.py:57:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform.py:64:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform.py:68:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform.py:80:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform.py:96:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:98:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:107:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:112:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:114:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:118:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:123:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:132:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:140:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:143:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:148:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:161:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:164:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:170:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:183:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:188:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:202:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:215:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:222:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:232:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:242:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform.py:259:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:267:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:274:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:283:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:292:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:302:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform.py:321:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:323:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:326:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:329:59: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/v1/endpoints/platform.py:331:59: E712 comparison to False should be 'if cond is False:' or 'if not cond:'\napp/api/v1/endpoints/platform.py:332:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:335:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:338:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:346:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:353:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:367:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:379:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:389:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform.py:407:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:409:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:413:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:418:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:420:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:423:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:434:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:436:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:438:121: E501 line too long (125 > 120 characters)\napp/api/v1/endpoints/platform.py:441:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:452:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:454:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:461:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:472:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:485:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:495:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform.py:512:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:514:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:518:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:522:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:530:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:538:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:546:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:551:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:556:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:567:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:574:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:582:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:585:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:610:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:620:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform.py:628:10: W292 no newline at end of file\napp/api/v1/endpoints/platform_admin.py:43:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_admin.py:52:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_admin.py:70:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_admin.py:75:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_admin.py:80:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_admin.py:85:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_admin.py:89:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_admin.py:92:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_admin.py:94:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_admin.py:113:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_admin.py:117:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_admin.py:122:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_admin.py:127:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_admin.py:132:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_admin.py:136:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_admin.py:138:121: E501 line too long (122 > 120 characters)\napp/api/v1/endpoints/platform_admin.py:139:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_admin.py:141:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_admin.py:159:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_admin.py:161:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_admin.py:170:6: W292 no newline at end of file\napp/api/v1/endpoints/platform_settings.py:5:30: E261 at least two spaces before inline comment\napp/api/v1/endpoints/platform_settings.py:8:15: E261 at least two spaces before inline comment\napp/api/v1/endpoints/platform_settings.py:26:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform_settings.py:30:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform_settings.py:34:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform_settings.py:39:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform_settings.py:43:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform_settings.py:47:18: E261 at least two spaces before inline comment\napp/api/v1/endpoints/platform_settings.py:49:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform_settings.py:52:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform_settings.py:54:9: E116 unexpected indentation (comment)\napp/api/v1/endpoints/platform_settings.py:59:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform_settings.py:73:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:78:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:79:5: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/platform_settings.py:83:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform_settings.py:97:22: E261 at least two spaces before inline comment\napp/api/v1/endpoints/platform_settings.py:102:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform_settings.py:119:44: E261 at least two spaces before inline comment\napp/api/v1/endpoints/platform_settings.py:124:121: E501 line too long (124 > 120 characters)\napp/api/v1/endpoints/platform_settings.py:130:5: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/platform_settings.py:130:28: E261 at least two spaces before inline comment\napp/api/v1/endpoints/platform_settings.py:136:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform_settings.py:146:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:148:74: F541 f-string is missing placeholders\napp/api/v1/endpoints/platform_settings.py:149:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:154:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:157:5: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/platform_settings.py:160:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform_settings.py:171:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:179:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:181:74: F541 f-string is missing placeholders\napp/api/v1/endpoints/platform_settings.py:182:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:187:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:192:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:193:5: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/platform_settings.py:197:5: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/platform_settings.py:200:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform_settings.py:209:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:212:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:225:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:232:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:243:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:244:5: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/platform_settings.py:247:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform_settings.py:256:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:261:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:262:5: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/platform_settings.py:265:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform_settings.py:278:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:286:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:291:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:292:5: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/platform_settings.py:294:5: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/platform_settings.py:297:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform_settings.py:307:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:312:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:313:5: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/platform_settings.py:316:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform_settings.py:326:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:334:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:336:74: F541 f-string is missing placeholders\napp/api/v1/endpoints/platform_settings.py:337:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:342:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:345:5: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/platform_settings.py:348:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform_settings.py:364:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:372:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:373:5: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/platform_settings.py:376:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform_settings.py:385:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:393:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:394:5: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/platform_settings.py:398:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform_settings.py:407:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:413:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:418:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:419:5: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/platform_settings.py:422:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform_settings.py:432:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:434:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:442:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:455:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:456:5: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/platform_settings.py:458:5: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/platform_settings.py:462:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform_settings.py:471:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:474:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:477:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:484:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:487:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:492:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:503:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:504:5: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/platform_settings.py:507:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform_settings.py:516:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:520:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:525:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings.py:526:5: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/platform_settings.py:527:98: W292 no newline at end of file\napp/api/v1/endpoints/platform_settings_optimized.py:6:1: F401 'pydantic.BaseModel' imported but unused\napp/api/v1/endpoints/platform_settings_optimized.py:8:1: F401 'sqlalchemy.orm.Session' imported but unused\napp/api/v1/endpoints/platform_settings_optimized.py:13:1: F401 'app.core.database.get_db' imported but unused\napp/api/v1/endpoints/platform_settings_optimized.py:61:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform_settings_optimized.py:73:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform_settings_optimized.py:81:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform_settings_optimized.py:96:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings_optimized.py:99:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings_optimized.py:102:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings_optimized.py:105:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings_optimized.py:110:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings_optimized.py:118:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform_settings_optimized.py:132:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings_optimized.py:135:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings_optimized.py:138:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings_optimized.py:141:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings_optimized.py:146:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings_optimized.py:154:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform_settings_optimized.py:164:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings_optimized.py:168:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings_optimized.py:174:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings_optimized.py:179:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings_optimized.py:189:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings_optimized.py:197:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings_optimized.py:202:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings_optimized.py:218:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform_settings_optimized.py:226:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings_optimized.py:229:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings_optimized.py:233:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform_settings_optimized.py:239:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings_optimized.py:245:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings_optimized.py:247:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings_optimized.py:249:79: W292 no newline at end of file\napp/api/v1/endpoints/platform_settings_public.py:5:1: F401 'typing.Optional' imported but unused\napp/api/v1/endpoints/platform_settings_public.py:6:1: F401 'pydantic.BaseModel' imported but unused\napp/api/v1/endpoints/platform_settings_public.py:9:1: F401 'concurrent.futures.TimeoutError as FuturesTimeoutError' imported but unused\napp/api/v1/endpoints/platform_settings_public.py:28:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform_settings_public.py:45:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings_public.py:47:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings_public.py:50:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings_public.py:56:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings_public.py:58:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings_public.py:61:49: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/v1/endpoints/platform_settings_public.py:63:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings_public.py:74:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings_public.py:76:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings_public.py:86:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings_public.py:93:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings_public.py:98:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings_public.py:107:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/platform_settings_public.py:139:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings_public.py:144:1: W293 blank line contains whitespace\napp/api/v1/endpoints/platform_settings_public.py:147:92: W292 no newline at end of file\napp/api/v1/endpoints/pos.py:21:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/pos.py:25:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/pos.py:36:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/pos.py:43:1: W293 blank line contains whitespace\napp/api/v1/endpoints/pos.py:46:22: W291 trailing whitespace\napp/api/v1/endpoints/pos.py:47:61: W291 trailing whitespace\napp/api/v1/endpoints/pos.py:52:1: W293 blank line contains whitespace\napp/api/v1/endpoints/pos.py:59:34: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/v1/endpoints/pos.py:62:1: W293 blank line contains whitespace\napp/api/v1/endpoints/pos.py:68:1: W293 blank line contains whitespace\napp/api/v1/endpoints/pos.py:80:1: W293 blank line contains whitespace\napp/api/v1/endpoints/pos.py:86:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/pos.py:94:1: W293 blank line contains whitespace\napp/api/v1/endpoints/pos.py:97:22: W291 trailing whitespace\napp/api/v1/endpoints/pos.py:98:61: W291 trailing whitespace\napp/api/v1/endpoints/pos.py:103:1: W293 blank line contains whitespace\napp/api/v1/endpoints/pos.py:110:34: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/v1/endpoints/pos.py:113:1: W293 blank line contains whitespace\napp/api/v1/endpoints/pos.py:119:1: W293 blank line contains whitespace\napp/api/v1/endpoints/pos.py:130:1: W293 blank line contains whitespace\napp/api/v1/endpoints/pos.py:134:1: W293 blank line contains whitespace\napp/api/v1/endpoints/pos.py:146:1: W293 blank line contains whitespace\napp/api/v1/endpoints/pos.py:152:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/pos.py:161:1: W293 blank line contains whitespace\napp/api/v1/endpoints/pos.py:163:1: W293 blank line contains whitespace\napp/api/v1/endpoints/pos.py:169:1: W293 blank line contains whitespace\napp/api/v1/endpoints/pos.py:172:22: W291 trailing whitespace\napp/api/v1/endpoints/pos.py:173:36: W291 trailing whitespace\napp/api/v1/endpoints/pos.py:176:1: W293 blank line contains whitespace\napp/api/v1/endpoints/pos.py:183:1: W293 blank line contains whitespace\napp/api/v1/endpoints/pos.py:191:1: W293 blank line contains whitespace\napp/api/v1/endpoints/pos.py:194:1: W293 blank line contains whitespace\napp/api/v1/endpoints/pos.py:198:1: W293 blank line contains whitespace\napp/api/v1/endpoints/pos.py:201:1: W293 blank line contains whitespace\napp/api/v1/endpoints/pos.py:213:1: W293 blank line contains whitespace\napp/api/v1/endpoints/pos.py:219:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/pos.py:227:1: W293 blank line contains whitespace\napp/api/v1/endpoints/pos.py:230:22: W291 trailing whitespace\napp/api/v1/endpoints/pos.py:231:61: W291 trailing whitespace\napp/api/v1/endpoints/pos.py:236:1: W293 blank line contains whitespace\napp/api/v1/endpoints/pos.py:243:1: W293 blank line contains whitespace\napp/api/v1/endpoints/pos.py:257:1: W293 blank line contains whitespace\napp/api/v1/endpoints/pos.py:265:6: W292 no newline at end of file\napp/api/v1/endpoints/products.py:23:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/products.py:30:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/products.py:40:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/products.py:55:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/products.py:71:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/products.py:90:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/products.py:95:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/products.py:103:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:107:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:115:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:117:74: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/v1/endpoints/products.py:119:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:133:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:136:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:139:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:145:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/products.py:154:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:158:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:167:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:171:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:174:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:185:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:191:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/products.py:200:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:206:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:212:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:220:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:223:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:226:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:237:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:243:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/products.py:251:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:257:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:263:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:267:27: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/v1/endpoints/products.py:269:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:275:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:279:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:281:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:284:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:290:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/products.py:300:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:304:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:313:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:315:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:318:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:320:48: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/v1/endpoints/products.py:321:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:323:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:346:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:349:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:352:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:364:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/products.py:372:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:376:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:384:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:387:74: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/v1/endpoints/products.py:389:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:392:72: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/v1/endpoints/products.py:394:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:432:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:435:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:446:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/products.py:455:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:459:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:464:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:470:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:487:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:491:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:494:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:515:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/products.py:524:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:531:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:541:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:571:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:575:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:579:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:600:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/products.py:608:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:615:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:625:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:629:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:633:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:637:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/products.py:647:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/products.py:655:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:659:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:665:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:672:31: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/v1/endpoints/products.py:673:32: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/v1/endpoints/products.py:676:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:678:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:692:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:695:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:701:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/products.py:710:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:714:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:720:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:725:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:731:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:737:31: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/v1/endpoints/products.py:740:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:754:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:757:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:763:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/products.py:770:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:777:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:787:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products.py:806:6: W292 no newline at end of file\napp/api/v1/endpoints/products_secure.py:7:1: F401 'pydantic.BaseModel' imported but unused\napp/api/v1/endpoints/products_secure.py:32:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products_secure.py:35:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products_secure.py:43:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products_secure.py:46:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products_secure.py:59:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products_secure.py:74:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products_secure.py:77:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products_secure.py:85:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products_secure.py:89:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products_secure.py:106:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products_secure.py:114:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products_secure.py:124:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products_secure.py:128:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products_secure.py:131:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products_secure.py:133:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products_secure.py:144:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products_secure.py:152:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products_secure.py:154:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products_secure.py:173:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products_secure.py:179:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products_secure.py:184:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products_secure.py:193:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products_secure.py:196:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products_secure.py:197:16: F821 undefined name 'FynloException'\napp/api/v1/endpoints/products_secure.py:199:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products_secure.py:201:1: W293 blank line contains whitespace\napp/api/v1/endpoints/products_secure.py:206:6: W292 no newline at end of file\napp/api/v1/endpoints/public_menu.py:7:1: F401 'pydantic.BaseModel' imported but unused\napp/api/v1/endpoints/public_menu.py:8:46: W291 trailing whitespace\napp/api/v1/endpoints/public_menu.py:10:1: F401 'sqlalchemy.and_' imported but unused\napp/api/v1/endpoints/public_menu.py:21:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/public_menu.py:40:1: W293 blank line contains whitespace\napp/api/v1/endpoints/public_menu.py:43:1: W293 blank line contains whitespace\napp/api/v1/endpoints/public_menu.py:53:121: E501 line too long (142 > 120 characters)\napp/api/v1/endpoints/public_menu.py:56:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/public_menu.py:68:1: W293 blank line contains whitespace\napp/api/v1/endpoints/public_menu.py:72:1: W293 blank line contains whitespace\napp/api/v1/endpoints/public_menu.py:84:1: W293 blank line contains whitespace\napp/api/v1/endpoints/public_menu.py:86:60: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/v1/endpoints/public_menu.py:87:1: W293 blank line contains whitespace\napp/api/v1/endpoints/public_menu.py:92:36: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/v1/endpoints/public_menu.py:94:1: W293 blank line contains whitespace\napp/api/v1/endpoints/public_menu.py:97:1: W293 blank line contains whitespace\napp/api/v1/endpoints/public_menu.py:100:1: W293 blank line contains whitespace\napp/api/v1/endpoints/public_menu.py:109:1: W293 blank line contains whitespace\napp/api/v1/endpoints/public_menu.py:111:1: W293 blank line contains whitespace\napp/api/v1/endpoints/public_menu.py:118:1: W293 blank line contains whitespace\napp/api/v1/endpoints/public_menu.py:121:1: W293 blank line contains whitespace\napp/api/v1/endpoints/public_menu.py:126:1: W293 blank line contains whitespace\napp/api/v1/endpoints/public_menu.py:134:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/public_menu.py:145:1: W293 blank line contains whitespace\napp/api/v1/endpoints/public_menu.py:149:1: W293 blank line contains whitespace\napp/api/v1/endpoints/public_menu.py:154:33: F541 f-string is missing placeholders\napp/api/v1/endpoints/public_menu.py:161:1: W293 blank line contains whitespace\napp/api/v1/endpoints/public_menu.py:164:32: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/v1/endpoints/public_menu.py:166:1: W293 blank line contains whitespace\napp/api/v1/endpoints/public_menu.py:173:35: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/v1/endpoints/public_menu.py:175:1: W293 blank line contains whitespace\napp/api/v1/endpoints/public_menu.py:183:1: W293 blank line contains whitespace\napp/api/v1/endpoints/public_menu.py:190:1: W293 blank line contains whitespace\napp/api/v1/endpoints/public_menu.py:193:1: W293 blank line contains whitespace\napp/api/v1/endpoints/public_menu.py:198:1: W293 blank line contains whitespace\napp/api/v1/endpoints/public_menu.py:204:10: W292 no newline at end of file\napp/api/v1/endpoints/recipes.py:5:1: F401 'pydantic.BaseModel' imported but unused\napp/api/v1/endpoints/recipes.py:10:46: E261 at least two spaces before inline comment\napp/api/v1/endpoints/recipes.py:12:35: E261 at least two spaces before inline comment\napp/api/v1/endpoints/recipes.py:13:49: E261 at least two spaces before inline comment\napp/api/v1/endpoints/recipes.py:14:53: E261 at least two spaces before inline comment\napp/api/v1/endpoints/recipes.py:22:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/recipes.py:22:72: E261 at least two spaces before inline comment\napp/api/v1/endpoints/recipes.py:38:1: W293 blank line contains whitespace\napp/api/v1/endpoints/recipes.py:46:1: W293 blank line contains whitespace\napp/api/v1/endpoints/recipes.py:61:121: E501 line too long (121 > 120 characters)\napp/api/v1/endpoints/recipes.py:82:65: E261 at least two spaces before inline comment\napp/api/v1/endpoints/recipes.py:95:1: W293 blank line contains whitespace\napp/api/v1/endpoints/recipes.py:105:1: W293 blank line contains whitespace\napp/api/v1/endpoints/recipes.py:115:1: W293 blank line contains whitespace\napp/api/v1/endpoints/recipes.py:136:1: W293 blank line contains whitespace\napp/api/v1/endpoints/recipes.py:146:46: E261 at least two spaces before inline comment\napp/api/v1/endpoints/recipes.py:159:1: W293 blank line contains whitespace\napp/api/v1/endpoints/recipes.py:166:121: E501 line too long (135 > 120 characters)\napp/api/v1/endpoints/recipes.py:167:1: W293 blank line contains whitespace\napp/api/v1/endpoints/recipes.py:183:16: E261 at least two spaces before inline comment\napp/api/v1/endpoints/restaurant_deletion.py:7:1: F401 'pydantic.BaseModel' imported but unused\napp/api/v1/endpoints/restaurant_deletion.py:11:1: F401 'typing.Optional' imported but unused\napp/api/v1/endpoints/restaurant_deletion.py:11:1: F401 'typing.List' imported but unused\napp/api/v1/endpoints/restaurant_deletion.py:11:1: F401 'typing.Dict' imported but unused\napp/api/v1/endpoints/restaurant_deletion.py:41:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:47:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:55:15: F821 undefined name 'ValidationException'\napp/api/v1/endpoints/restaurant_deletion.py:56:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:59:15: F821 undefined name 'FynloException'\napp/api/v1/endpoints/restaurant_deletion.py:60:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:64:15: F821 undefined name 'NotFoundException'\napp/api/v1/endpoints/restaurant_deletion.py:65:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:68:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:83:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:95:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:107:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:115:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:128:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:138:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:150:15: F821 undefined name 'FynloException'\napp/api/v1/endpoints/restaurant_deletion.py:156:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:163:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:173:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:177:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:179:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:187:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:191:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:193:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:198:28: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/v1/endpoints/restaurant_deletion.py:202:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:205:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:207:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:215:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:218:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:220:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:230:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:233:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:235:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:241:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:244:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:247:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:253:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:262:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:265:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:283:15: F821 undefined name 'ValidationException'\napp/api/v1/endpoints/restaurant_deletion.py:284:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:294:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:297:19: F821 undefined name 'FynloException'\napp/api/v1/endpoints/restaurant_deletion.py:298:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:302:15: F821 undefined name 'NotFoundException'\napp/api/v1/endpoints/restaurant_deletion.py:303:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:309:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:316:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:324:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:326:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:337:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:346:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_deletion.py:347:5: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/restaurant_deletion.py:349:15: F821 undefined name 'FynloException'\napp/api/v1/endpoints/restaurant_deletion.py:349:69: W292 no newline at end of file\napp/api/v1/endpoints/restaurant_switch.py:7:1: F401 'pydantic.BaseModel' imported but unused\napp/api/v1/endpoints/restaurant_switch.py:9:1: F401 'sqlalchemy.and_' imported but unused\napp/api/v1/endpoints/restaurant_switch.py:9:1: F401 'sqlalchemy.or_' imported but unused\napp/api/v1/endpoints/restaurant_switch.py:10:1: F401 'typing.Optional' imported but unused\napp/api/v1/endpoints/restaurant_switch.py:10:1: F401 'typing.List' imported but unused\napp/api/v1/endpoints/restaurant_switch.py:39:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:47:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:63:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:71:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:76:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:79:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:85:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:98:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:107:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:120:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:123:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:152:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:159:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:162:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:168:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:171:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:175:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:187:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:192:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:197:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:203:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:206:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:212:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:218:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:221:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:223:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:234:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:246:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:283:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:290:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:294:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:301:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:304:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:310:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:316:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:322:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:331:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:335:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:346:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:357:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurant_switch.py:358:5: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/restaurant_switch.py:363:10: W292 no newline at end of file\napp/api/v1/endpoints/restaurants.py:32:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/restaurants.py:41:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/restaurants.py:53:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/restaurants.py:69:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/restaurants.py:79:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/restaurants.py:87:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/restaurants.py:95:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:100:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:102:55: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/v1/endpoints/restaurants.py:103:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:105:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:109:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:112:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:122:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:125:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:127:55: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/v1/endpoints/restaurants.py:128:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:130:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:150:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:161:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/restaurants.py:168:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:171:22: W291 trailing whitespace\napp/api/v1/endpoints/restaurants.py:172:61: W291 trailing whitespace\napp/api/v1/endpoints/restaurants.py:177:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:181:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:184:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:202:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/restaurants.py:210:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:213:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:216:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:221:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:225:121: E501 line too long (126 > 120 characters)\napp/api/v1/endpoints/restaurants.py:229:24: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/restaurants.py:232:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:236:24: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/restaurants.py:239:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:242:24: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/restaurants.py:245:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:250:24: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/restaurants.py:253:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:264:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:268:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:286:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/restaurants.py:293:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:297:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:306:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:310:121: E501 line too long (126 > 120 characters)\napp/api/v1/endpoints/restaurants.py:311:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:330:24: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/restaurants.py:333:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:337:24: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/restaurants.py:340:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:343:24: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/restaurants.py:346:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:351:24: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/restaurants.py:354:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:359:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:369:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:374:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:393:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:396:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:401:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:405:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:427:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:431:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:442:5: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/restaurants.py:445:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:463:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/restaurants.py:472:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:476:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:484:26: W291 trailing whitespace\napp/api/v1/endpoints/restaurants.py:488:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:490:121: E501 line too long (143 > 120 characters)\napp/api/v1/endpoints/restaurants.py:492:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:495:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:500:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:502:121: E501 line too long (134 > 120 characters)\napp/api/v1/endpoints/restaurants.py:503:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:506:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:508:121: E501 line too long (143 > 120 characters)\napp/api/v1/endpoints/restaurants.py:509:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:511:121: E501 line too long (137 > 120 characters)\napp/api/v1/endpoints/restaurants.py:512:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:515:24: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/restaurants.py:518:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:522:24: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/restaurants.py:525:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:528:24: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/restaurants.py:531:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:537:28: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/restaurants.py:541:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:545:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:549:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:567:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/restaurants.py:576:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:580:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:588:26: W291 trailing whitespace\napp/api/v1/endpoints/restaurants.py:592:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:596:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:605:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:614:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:622:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:631:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:634:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:644:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:656:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/restaurants.py:663:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:666:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:668:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:672:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:676:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:679:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:688:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:696:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:701:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:712:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:719:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:727:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:729:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:740:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:743:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:753:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/restaurants.py:761:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:765:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:773:26: W291 trailing whitespace\napp/api/v1/endpoints/restaurants.py:777:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:796:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/restaurants.py:808:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/restaurants.py:815:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/restaurants.py:820:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/restaurants.py:827:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/restaurants.py:835:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:838:22: W291 trailing whitespace\napp/api/v1/endpoints/restaurants.py:839:61: W291 trailing whitespace\napp/api/v1/endpoints/restaurants.py:844:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:849:31: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/v1/endpoints/restaurants.py:852:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:855:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:857:5: F841 local variable 'section_ids' is assigned to but never used\napp/api/v1/endpoints/restaurants.py:858:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:865:29: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/v1/endpoints/restaurants.py:868:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:871:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:873:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:884:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:894:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:907:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:916:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/restaurants.py:923:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:926:22: W291 trailing whitespace\napp/api/v1/endpoints/restaurants.py:927:61: W291 trailing whitespace\napp/api/v1/endpoints/restaurants.py:932:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:936:31: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/v1/endpoints/restaurants.py:939:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:949:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:955:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/restaurants.py:963:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:966:22: W291 trailing whitespace\napp/api/v1/endpoints/restaurants.py:967:61: W291 trailing whitespace\napp/api/v1/endpoints/restaurants.py:972:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:979:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:983:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:995:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/restaurants.py:1003:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1006:22: W291 trailing whitespace\napp/api/v1/endpoints/restaurants.py:1007:61: W291 trailing whitespace\napp/api/v1/endpoints/restaurants.py:1012:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1020:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1023:24: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/restaurants.py:1026:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1035:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1039:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1056:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/restaurants.py:1065:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1070:24: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/restaurants.py:1073:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1076:22: W291 trailing whitespace\napp/api/v1/endpoints/restaurants.py:1077:61: W291 trailing whitespace\napp/api/v1/endpoints/restaurants.py:1082:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1090:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1093:24: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/restaurants.py:1096:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1101:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1104:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1111:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1124:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1130:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/restaurants.py:1139:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1142:22: W291 trailing whitespace\napp/api/v1/endpoints/restaurants.py:1143:61: W291 trailing whitespace\napp/api/v1/endpoints/restaurants.py:1148:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1156:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1159:24: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/restaurants.py:1162:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1172:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1175:28: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/restaurants.py:1178:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1180:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1185:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1188:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1201:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1208:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/restaurants.py:1211:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/restaurants.py:1218:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1221:22: W291 trailing whitespace\napp/api/v1/endpoints/restaurants.py:1222:61: W291 trailing whitespace\napp/api/v1/endpoints/restaurants.py:1227:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1229:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1232:24: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/restaurants.py:1235:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1244:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/restaurants.py:1252:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1255:22: W291 trailing whitespace\napp/api/v1/endpoints/restaurants.py:1256:61: W291 trailing whitespace\napp/api/v1/endpoints/restaurants.py:1261:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1263:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1266:24: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/restaurants.py:1269:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1275:24: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/restaurants.py:1278:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1283:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1293:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/restaurants.py:1300:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/restaurants.py:1309:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1312:22: W291 trailing whitespace\napp/api/v1/endpoints/restaurants.py:1313:61: W291 trailing whitespace\napp/api/v1/endpoints/restaurants.py:1318:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1326:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1329:24: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/restaurants.py:1332:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1336:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1343:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1347:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1350:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1367:5: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/restaurants.py:1370:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1385:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1392:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/restaurants.py:1397:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/restaurants.py:1405:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1408:22: W291 trailing whitespace\napp/api/v1/endpoints/restaurants.py:1409:61: W291 trailing whitespace\napp/api/v1/endpoints/restaurants.py:1414:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1422:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1425:24: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/restaurants.py:1428:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1436:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1439:24: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/restaurants.py:1442:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1448:24: F821 undefined name 'ErrorCodes'\napp/api/v1/endpoints/restaurants.py:1451:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1454:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1460:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1465:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1468:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1480:5: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/restaurants.py:1482:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1497:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/restaurants.py:1506:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1509:22: W291 trailing whitespace\napp/api/v1/endpoints/restaurants.py:1510:61: W291 trailing whitespace\napp/api/v1/endpoints/restaurants.py:1515:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1521:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1526:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1538:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1540:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1545:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1548:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1560:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1570:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1577:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1582:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1589:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1593:1: W293 blank line contains whitespace\napp/api/v1/endpoints/restaurants.py:1613:1: E402 module level import not at top of file\napp/api/v1/endpoints/rls_example.py:6:1: F401 'typing.List' imported but unused\napp/api/v1/endpoints/rls_example.py:7:1: F401 'pydantic.BaseModel' imported but unused\napp/api/v1/endpoints/rls_example.py:34:1: W293 blank line contains whitespace\napp/api/v1/endpoints/rls_example.py:38:1: W293 blank line contains whitespace\napp/api/v1/endpoints/rls_example.py:42:1: W293 blank line contains whitespace\napp/api/v1/endpoints/rls_example.py:75:1: W293 blank line contains whitespace\napp/api/v1/endpoints/rls_example.py:98:19: W291 trailing whitespace\napp/api/v1/endpoints/rls_example.py:104:1: W293 blank line contains whitespace\napp/api/v1/endpoints/rls_example.py:109:1: W293 blank line contains whitespace\napp/api/v1/endpoints/rls_example.py:133:1: E402 module level import not at top of file\napp/api/v1/endpoints/rls_example.py:135:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/rls_example.py:141:10: F821 undefined name 'SessionLocal'\napp/api/v1/endpoints/rls_example.py:147:19: W292 no newline at end of file\napp/api/v1/endpoints/secure_payment_provider_management.py:34:1: W293 blank line contains whitespace\napp/api/v1/endpoints/secure_payment_provider_management.py:46:1: W293 blank line contains whitespace\napp/api/v1/endpoints/secure_payment_provider_management.py:50:1: W293 blank line contains whitespace\napp/api/v1/endpoints/secure_payment_provider_management.py:53:1: W293 blank line contains whitespace\napp/api/v1/endpoints/secure_payment_provider_management.py:61:1: W293 blank line contains whitespace\napp/api/v1/endpoints/secure_payment_provider_management.py:71:1: W293 blank line contains whitespace\napp/api/v1/endpoints/secure_payment_provider_management.py:92:1: W293 blank line contains whitespace\napp/api/v1/endpoints/secure_payment_provider_management.py:94:1: W293 blank line contains whitespace\napp/api/v1/endpoints/secure_payment_provider_management.py:97:1: W293 blank line contains whitespace\napp/api/v1/endpoints/secure_payment_provider_management.py:101:1: W293 blank line contains whitespace\napp/api/v1/endpoints/secure_payment_provider_management.py:104:1: W293 blank line contains whitespace\napp/api/v1/endpoints/secure_payment_provider_management.py:119:1: W293 blank line contains whitespace\napp/api/v1/endpoints/secure_payment_provider_management.py:124:1: W293 blank line contains whitespace\napp/api/v1/endpoints/secure_payment_provider_management.py:146:1: W293 blank line contains whitespace\napp/api/v1/endpoints/secure_payment_provider_management.py:150:1: W293 blank line contains whitespace\napp/api/v1/endpoints/secure_payment_provider_management.py:154:1: W293 blank line contains whitespace\napp/api/v1/endpoints/secure_payment_provider_management.py:157:1: W293 blank line contains whitespace\napp/api/v1/endpoints/secure_payment_provider_management.py:163:1: W293 blank line contains whitespace\napp/api/v1/endpoints/secure_payment_provider_management.py:166:1: W293 blank line contains whitespace\napp/api/v1/endpoints/secure_payment_provider_management.py:171:1: W293 blank line contains whitespace\napp/api/v1/endpoints/secure_payment_provider_management.py:194:1: W293 blank line contains whitespace\napp/api/v1/endpoints/secure_payment_provider_management.py:198:1: W293 blank line contains whitespace\napp/api/v1/endpoints/secure_payment_provider_management.py:201:1: W293 blank line contains whitespace\napp/api/v1/endpoints/secure_payment_provider_management.py:207:1: W293 blank line contains whitespace\napp/api/v1/endpoints/secure_payment_provider_management.py:211:1: W293 blank line contains whitespace\napp/api/v1/endpoints/secure_payment_provider_management.py:222:1: W293 blank line contains whitespace\napp/api/v1/endpoints/secure_payment_provider_management.py:245:1: W293 blank line contains whitespace\napp/api/v1/endpoints/secure_payment_provider_management.py:249:1: W293 blank line contains whitespace\napp/api/v1/endpoints/secure_payment_provider_management.py:255:1: W293 blank line contains whitespace\napp/api/v1/endpoints/secure_payment_provider_management.py:261:1: W293 blank line contains whitespace\napp/api/v1/endpoints/secure_payment_provider_management.py:264:1: W293 blank line contains whitespace\napp/api/v1/endpoints/secure_payment_provider_management.py:276:1: W293 blank line contains whitespace\napp/api/v1/endpoints/secure_payment_provider_management.py:306:1: W293 blank line contains whitespace\napp/api/v1/endpoints/secure_payment_provider_management.py:312:7: W292 no newline at end of file\napp/api/v1/endpoints/secure_payments.py:61:9: E999 IndentationError: unexpected indent\napp/api/v1/endpoints/storage_health.py:7:1: F401 'pydantic.BaseModel' imported but unused\napp/api/v1/endpoints/storage_health.py:16:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/storage_health.py:22:1: W293 blank line contains whitespace\napp/api/v1/endpoints/storage_health.py:29:1: W293 blank line contains whitespace\napp/api/v1/endpoints/storage_health.py:32:1: W293 blank line contains whitespace\napp/api/v1/endpoints/storage_health.py:39:59: E226 missing whitespace around arithmetic operator\napp/api/v1/endpoints/storage_health.py:42:1: W293 blank line contains whitespace\napp/api/v1/endpoints/storage_health.py:51:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/storage_health.py:59:1: W293 blank line contains whitespace\napp/api/v1/endpoints/storage_health.py:66:1: W293 blank line contains whitespace\napp/api/v1/endpoints/storage_health.py:72:1: W293 blank line contains whitespace\napp/api/v1/endpoints/storage_health.py:82:1: W293 blank line contains whitespace\napp/api/v1/endpoints/storage_health.py:85:1: W293 blank line contains whitespace\napp/api/v1/endpoints/storage_health.py:94:1: W293 blank line contains whitespace\napp/api/v1/endpoints/storage_health.py:99:10: W292 no newline at end of file\napp/api/v1/endpoints/sumup.py:8:1: F401 'fastapi.status' imported but unused\napp/api/v1/endpoints/sumup.py:9:1: F401 'typing.Any' imported but unused\napp/api/v1/endpoints/sumup.py:18:1: F401 'app.core.responses.ErrorCodes' imported but unused\napp/api/v1/endpoints/sumup.py:19:1: F401 'app.core.exceptions.FynloException' imported but unused\napp/api/v1/endpoints/sumup.py:30:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sumup.py:46:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/sumup.py:57:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sumup.py:77:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sumup.py:80:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sumup.py:86:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sumup.py:99:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sumup.py:101:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sumup.py:105:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sumup.py:124:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sumup.py:127:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sumup.py:134:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sumup.py:140:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sumup.py:146:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sumup.py:154:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sumup.py:161:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sumup.py:166:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sumup.py:185:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sumup.py:198:9: F841 local variable 'restaurant_id' is assigned to but never used\napp/api/v1/endpoints/sumup.py:199:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sumup.py:203:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sumup.py:207:38: E241 multiple spaces after ','\napp/api/v1/endpoints/sumup.py:207:76: E241 multiple spaces after ','\napp/api/v1/endpoints/sumup.py:213:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sumup.py:218:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sumup.py:238:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sumup.py:241:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sumup.py:250:9: F841 local variable 'restaurant_id' is assigned to but never used\napp/api/v1/endpoints/sumup.py:251:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sumup.py:257:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sumup.py:267:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sumup.py:268:17: E116 unexpected indentation (comment)\napp/api/v1/endpoints/sumup.py:269:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sumup.py:278:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sumup.py:284:10: W292 no newline at end of file\napp/api/v1/endpoints/sync.py:22:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/sync.py:32:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/sync.py:38:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/sync.py:44:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/sync.py:49:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/sync.py:68:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sync.py:71:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sync.py:80:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sync.py:91:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sync.py:107:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sync.py:117:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/sync.py:138:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sync.py:150:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sync.py:154:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sync.py:162:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sync.py:168:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sync.py:178:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sync.py:183:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sync.py:198:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sync.py:208:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/sync.py:228:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sync.py:236:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sync.py:245:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sync.py:255:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/sync.py:272:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sync.py:278:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sync.py:287:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sync.py:297:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/sync.py:315:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sync.py:318:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sync.py:321:46: W291 trailing whitespace\napp/api/v1/endpoints/sync.py:324:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sync.py:328:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sync.py:330:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sync.py:342:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sync.py:352:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/sync.py:369:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sync.py:371:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sync.py:379:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sync.py:386:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sync.py:394:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sync.py:404:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/sync.py:422:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sync.py:424:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sync.py:432:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sync.py:443:1: W293 blank line contains whitespace\napp/api/v1/endpoints/sync.py:451:10: W292 no newline at end of file\napp/api/v1/endpoints/tips.py:9:68: E261 at least two spaces before inline comment\napp/api/v1/endpoints/tips.py:15:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/tips.py:20:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/tips.py:24:38: E261 at least two spaces before inline comment\napp/api/v1/endpoints/tips.py:28:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/tips.py:32:41: E261 at least two spaces before inline comment\napp/api/v1/endpoints/tips.py:69:5: F841 local variable 've' is assigned to but never used\napp/api/v1/endpoints/tips.py:71:5: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/tips.py:91:38: E261 at least two spaces before inline comment\napp/api/v1/endpoints/websocket.py:11:1: F401 'pydantic.BaseModel' imported but unused\napp/api/v1/endpoints/websocket.py:49:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/websocket.py:208:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket.py:211:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket.py:472:27: W291 trailing whitespace\napp/api/v1/endpoints/websocket.py:473:27: W291 trailing whitespace\napp/api/v1/endpoints/websocket.py:488:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket.py:504:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket.py:567:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket.py:719:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket.py:871:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket.py:1024:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:51:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:63:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:66:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:68:14: W291 trailing whitespace\napp/api/v1/endpoints/websocket_enhanced.py:69:30: W291 trailing whitespace\napp/api/v1/endpoints/websocket_enhanced.py:74:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:77:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:80:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:95:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:103:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:113:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:123:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:132:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:137:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:141:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:144:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:156:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:159:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:168:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:176:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:179:49: W291 trailing whitespace\napp/api/v1/endpoints/websocket_enhanced.py:185:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:187:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:195:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:198:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:202:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:206:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:210:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:212:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:219:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:227:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:234:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:240:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:252:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:263:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:267:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:270:36: W291 trailing whitespace\napp/api/v1/endpoints/websocket_enhanced.py:271:27: W291 trailing whitespace\napp/api/v1/endpoints/websocket_enhanced.py:272:26: W291 trailing whitespace\napp/api/v1/endpoints/websocket_enhanced.py:280:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:284:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:300:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:302:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:316:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:323:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:327:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:335:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:346:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:350:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:355:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:360:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:363:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:368:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:371:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:373:121: E501 line too long (123 > 120 characters)\napp/api/v1/endpoints/websocket_enhanced.py:378:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:383:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:388:1: E305 expected 2 blank lines after class or function definition, found 1\napp/api/v1/endpoints/websocket_enhanced.py:391:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/websocket_enhanced.py:406:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:411:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:415:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:419:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:425:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:429:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:439:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:442:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:452:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:461:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:465:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:474:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:483:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:486:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:497:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:506:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:511:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:527:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:544:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:547:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:553:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:554:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_enhanced.py:555:9: E303 too many blank lines (2)\napp/api/v1/endpoints/websocket_enhanced.py:571:61: W292 no newline at end of file\napp/api/v1/endpoints/websocket_portal.py:5:1: F401 'typing.Optional' imported but unused\napp/api/v1/endpoints/websocket_portal.py:5:1: F401 'typing.Dict' imported but unused\napp/api/v1/endpoints/websocket_portal.py:5:1: F401 'typing.Any' imported but unused\napp/api/v1/endpoints/websocket_portal.py:6:1: F401 'pydantic.BaseModel' imported but unused\napp/api/v1/endpoints/websocket_portal.py:13:1: F401 'app.core.websocket.EventType' imported but unused\napp/api/v1/endpoints/websocket_portal.py:13:1: F401 'app.core.websocket.WebSocketMessage' imported but unused\napp/api/v1/endpoints/websocket_portal.py:14:23: W291 trailing whitespace\napp/api/v1/endpoints/websocket_portal.py:15:20: W291 trailing whitespace\napp/api/v1/endpoints/websocket_portal.py:22:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/websocket_portal.py:33:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_portal.py:40:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_portal.py:45:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_portal.py:54:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_portal.py:72:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_portal.py:74:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_portal.py:80:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_portal.py:82:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_portal.py:89:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_portal.py:98:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_portal.py:105:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_portal.py:116:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_portal.py:122:9: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/websocket_portal.py:139:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_portal.py:146:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_portal.py:155:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_portal.py:172:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_portal.py:174:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_portal.py:176:72: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/v1/endpoints/websocket_portal.py:186:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_portal.py:192:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_portal.py:198:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_portal.py:200:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_portal.py:206:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_portal.py:215:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_portal.py:219:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_portal.py:230:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_portal.py:236:9: F841 local variable 'e' is assigned to but never used\napp/api/v1/endpoints/websocket_portal.py:265:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_portal.py:277:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_portal.py:279:9: F821 undefined name 'logger'\napp/api/v1/endpoints/websocket_portal.py:287:79: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/v1/endpoints/websocket_portal.py:288:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_portal.py:300:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_portal.py:302:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_portal.py:304:9: F821 undefined name 'logger'\napp/api/v1/endpoints/websocket_portal.py:304:64: W292 no newline at end of file\napp/api/v1/endpoints/websocket_rate_limit_patch.py:15:47: W291 trailing whitespace\napp/api/v1/endpoints/websocket_rate_limit_patch.py:21:1: E302 expected 2 blank lines, found 1\napp/api/v1/endpoints/websocket_rate_limit_patch.py:27:10: E251 unexpected spaces around keyword / parameter equals\napp/api/v1/endpoints/websocket_rate_limit_patch.py:27:12: E251 unexpected spaces around keyword / parameter equals\napp/api/v1/endpoints/websocket_rate_limit_patch.py:35:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_rate_limit_patch.py:41:11: F821 undefined name 'get_or_create_cleanup_task'\napp/api/v1/endpoints/websocket_rate_limit_patch.py:46:16: F821 undefined name 'validate_origin'\napp/api/v1/endpoints/websocket_rate_limit_patch.py:47:13: F821 undefined name 'logger'\napp/api/v1/endpoints/websocket_rate_limit_patch.py:48:36: F821 undefined name 'sanitize_string'\napp/api/v1/endpoints/websocket_rate_limit_patch.py:58:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_rate_limit_patch.py:60:13: F821 undefined name 'logger'\napp/api/v1/endpoints/websocket_rate_limit_patch.py:71:43: F821 undefined name 'verify_websocket_access'\napp/api/v1/endpoints/websocket_rate_limit_patch.py:79:34: F821 undefined name 'check_connection_limit'\napp/api/v1/endpoints/websocket_rate_limit_patch.py:85:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_rate_limit_patch.py:87:29: F821 undefined name 'uuid'\napp/api/v1/endpoints/websocket_rate_limit_patch.py:88:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_rate_limit_patch.py:91:27: W291 trailing whitespace\napp/api/v1/endpoints/websocket_rate_limit_patch.py:97:15: F821 undefined name 'websocket_manager'\napp/api/v1/endpoints/websocket_rate_limit_patch.py:103:29: F821 undefined name 'ConnectionType'\napp/api/v1/endpoints/websocket_rate_limit_patch.py:103:85: F821 undefined name 'ConnectionType'\napp/api/v1/endpoints/websocket_rate_limit_patch.py:111:26: F821 undefined name 'datetime'\napp/api/v1/endpoints/websocket_rate_limit_patch.py:122:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_rate_limit_patch.py:128:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_rate_limit_patch.py:137:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_rate_limit_patch.py:139:21: F821 undefined name 'logger'\napp/api/v1/endpoints/websocket_rate_limit_patch.py:147:36: F821 undefined name 'json'\napp/api/v1/endpoints/websocket_rate_limit_patch.py:148:24: F821 undefined name 'json'\napp/api/v1/endpoints/websocket_rate_limit_patch.py:157:17: F841 local variable 'message_type' is assigned to but never used\napp/api/v1/endpoints/websocket_rate_limit_patch.py:158:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_rate_limit_patch.py:161:20: F821 undefined name 'WebSocketDisconnect'\napp/api/v1/endpoints/websocket_rate_limit_patch.py:164:17: F821 undefined name 'logger'\napp/api/v1/endpoints/websocket_rate_limit_patch.py:172:9: F821 undefined name 'logger'\napp/api/v1/endpoints/websocket_rate_limit_patch.py:176:19: F821 undefined name 'websocket_manager'\napp/api/v1/endpoints/websocket_rate_limit_patch.py:182:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_rate_limit_patch.py:183:9: F821 undefined name 'logger'\napp/api/v1/endpoints/websocket_rate_limit_patch.py:191:19: F821 undefined name 'asyncio'\napp/api/v1/endpoints/websocket_rate_limit_patch.py:193:13: F821 undefined name 'logger'\napp/api/v1/endpoints/websocket_rate_limit_patch.py:195:13: F821 undefined name 'logger'\napp/api/v1/endpoints/websocket_rate_limit_patch.py:202:53: W292 no newline at end of file\napp/api/v1/endpoints/websocket_secure.py:6:1: F401 'fastapi.WebSocket' imported but unused\napp/api/v1/endpoints/websocket_secure.py:6:1: F401 'fastapi.Depends' imported but unused\napp/api/v1/endpoints/websocket_secure.py:7:1: F401 'sqlalchemy.orm.Session' imported but unused\napp/api/v1/endpoints/websocket_secure.py:25:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_secure.py:30:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_secure.py:38:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_secure.py:45:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_secure.py:52:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_secure.py:59:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_secure.py:72:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_secure.py:80:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_secure.py:84:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_secure.py:96:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_secure.py:105:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_secure.py:113:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_secure.py:126:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_secure.py:136:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_secure.py:152:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_secure.py:159:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_secure.py:164:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_secure.py:170:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_secure.py:176:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_secure.py:180:1: W293 blank line contains whitespace\napp/api/v1/endpoints/websocket_secure.py:183:10: W292 no newline at end of file\napp/api/v1/platform/__init__.py:25:1: E402 module level import not at top of file\napp/api/v1/platform/__init__.py:26:1: E402 module level import not at top of file\napp/api/v1/platform/__init__.py:27:1: E402 module level import not at top of file\napp/api/v1/platform/__init__.py:28:1: E402 module level import not at top of file\napp/api/v1/platform/__init__.py:29:1: E402 module level import not at top of file\napp/api/v1/platform/__init__.py:36:49: W292 no newline at end of file\napp/api/v1/platform/analytics.py:6:1: F401 'typing.Optional' imported but unused\napp/api/v1/platform/analytics.py:35:1: W293 blank line contains whitespace\napp/api/v1/platform/analytics.py:41:1: W293 blank line contains whitespace\napp/api/v1/platform/analytics.py:46:1: W293 blank line contains whitespace\napp/api/v1/platform/analytics.py:49:1: W293 blank line contains whitespace\napp/api/v1/platform/analytics.py:62:1: W293 blank line contains whitespace\napp/api/v1/platform/analytics.py:68:1: W293 blank line contains whitespace\napp/api/v1/platform/analytics.py:73:1: W293 blank line contains whitespace\napp/api/v1/platform/analytics.py:97:1: W293 blank line contains whitespace\napp/api/v1/platform/analytics.py:100:1: W293 blank line contains whitespace\napp/api/v1/platform/analytics.py:102:1: W293 blank line contains whitespace\napp/api/v1/platform/analytics.py:122:1: W293 blank line contains whitespace\napp/api/v1/platform/analytics.py:125:1: W293 blank line contains whitespace\napp/api/v1/platform/analytics.py:136:1: W293 blank line contains whitespace\napp/api/v1/platform/analytics.py:145:1: W293 blank line contains whitespace\napp/api/v1/platform/analytics.py:148:1: W293 blank line contains whitespace\napp/api/v1/platform/analytics.py:150:1: W293 blank line contains whitespace\napp/api/v1/platform/analytics.py:171:1: W293 blank line contains whitespace\napp/api/v1/platform/analytics.py:172:9: F841 local variable 'query' is assigned to but never used\napp/api/v1/platform/analytics.py:173:1: W293 blank line contains whitespace\napp/api/v1/platform/analytics.py:188:1: W293 blank line contains whitespace\napp/api/v1/platform/analytics.py:203:1: W293 blank line contains whitespace\napp/api/v1/platform/analytics.py:216:1: W293 blank line contains whitespace\napp/api/v1/platform/analytics.py:226:1: W293 blank line contains whitespace\napp/api/v1/platform/analytics.py:229:1: W293 blank line contains whitespace\napp/api/v1/platform/analytics.py:231:1: W293 blank line contains whitespace\napp/api/v1/platform/analytics.py:236:10: W292 no newline at end of file\napp/api/v1/platform/financial.py:34:1: W293 blank line contains whitespace\napp/api/v1/platform/financial.py:39:1: W293 blank line contains whitespace\napp/api/v1/platform/financial.py:47:1: W293 blank line contains whitespace\napp/api/v1/platform/financial.py:61:1: W293 blank line contains whitespace\napp/api/v1/platform/financial.py:71:1: W293 blank line contains whitespace\napp/api/v1/platform/financial.py:78:1: W293 blank line contains whitespace\napp/api/v1/platform/financial.py:84:1: W293 blank line contains whitespace\napp/api/v1/platform/financial.py:88:1: W293 blank line contains whitespace\napp/api/v1/platform/financial.py:92:1: W293 blank line contains whitespace\napp/api/v1/platform/financial.py:100:1: W293 blank line contains whitespace\napp/api/v1/platform/financial.py:105:1: W293 blank line contains whitespace\napp/api/v1/platform/financial.py:125:1: W293 blank line contains whitespace\napp/api/v1/platform/financial.py:128:1: W293 blank line contains whitespace\napp/api/v1/platform/financial.py:130:1: W293 blank line contains whitespace\napp/api/v1/platform/financial.py:147:1: W293 blank line contains whitespace\napp/api/v1/platform/financial.py:161:1: W293 blank line contains whitespace\napp/api/v1/platform/financial.py:165:1: W293 blank line contains whitespace\napp/api/v1/platform/financial.py:178:1: W293 blank line contains whitespace\napp/api/v1/platform/financial.py:181:1: W293 blank line contains whitespace\napp/api/v1/platform/financial.py:190:1: W293 blank line contains whitespace\napp/api/v1/platform/financial.py:209:1: W293 blank line contains whitespace\napp/api/v1/platform/financial.py:220:1: W293 blank line contains whitespace\napp/api/v1/platform/financial.py:226:42: E226 missing whitespace around arithmetic operator\napp/api/v1/platform/financial.py:226:59: E226 missing whitespace around arithmetic operator\napp/api/v1/platform/financial.py:226:62: W291 trailing whitespace\napp/api/v1/platform/financial.py:227:49: W291 trailing whitespace\napp/api/v1/platform/financial.py:228:30: E226 missing whitespace around arithmetic operator\napp/api/v1/platform/financial.py:232:1: W293 blank line contains whitespace\napp/api/v1/platform/financial.py:246:1: W293 blank line contains whitespace\napp/api/v1/platform/financial.py:251:1: W293 blank line contains whitespace\napp/api/v1/platform/financial.py:256:1: W293 blank line contains whitespace\napp/api/v1/platform/financial.py:259:1: W293 blank line contains whitespace\napp/api/v1/platform/financial.py:268:1: W293 blank line contains whitespace\napp/api/v1/platform/financial.py:279:1: W293 blank line contains whitespace\napp/api/v1/platform/financial.py:284:10: W292 no newline at end of file\napp/api/v1/platform/restaurants.py:14:1: F401 'app.schemas.restaurant.RestaurantResponse' imported but unused\napp/api/v1/platform/restaurants.py:33:1: W293 blank line contains whitespace\napp/api/v1/platform/restaurants.py:44:1: W293 blank line contains whitespace\napp/api/v1/platform/restaurants.py:47:1: W293 blank line contains whitespace\napp/api/v1/platform/restaurants.py:50:1: W293 blank line contains whitespace\napp/api/v1/platform/restaurants.py:53:1: W293 blank line contains whitespace\napp/api/v1/platform/restaurants.py:56:1: W293 blank line contains whitespace\napp/api/v1/platform/restaurants.py:64:1: W293 blank line contains whitespace\napp/api/v1/platform/restaurants.py:76:1: W293 blank line contains whitespace\napp/api/v1/platform/restaurants.py:85:1: W293 blank line contains whitespace\napp/api/v1/platform/restaurants.py:104:1: W293 blank line contains whitespace\napp/api/v1/platform/restaurants.py:110:1: W293 blank line contains whitespace\napp/api/v1/platform/restaurants.py:115:1: W293 blank line contains whitespace\napp/api/v1/platform/restaurants.py:123:50: F821 undefined name 'timedelta'\napp/api/v1/platform/restaurants.py:125:1: W293 blank line contains whitespace\napp/api/v1/platform/restaurants.py:134:121: E501 line too long (134 > 120 characters)\napp/api/v1/platform/restaurants.py:135:121: E501 line too long (128 > 120 characters)\napp/api/v1/platform/restaurants.py:147:1: W293 blank line contains whitespace\napp/api/v1/platform/restaurants.py:149:1: W293 blank line contains whitespace\napp/api/v1/platform/restaurants.py:170:1: W293 blank line contains whitespace\napp/api/v1/platform/restaurants.py:176:1: W293 blank line contains whitespace\napp/api/v1/platform/restaurants.py:180:1: W293 blank line contains whitespace\napp/api/v1/platform/restaurants.py:183:1: W293 blank line contains whitespace\napp/api/v1/platform/restaurants.py:185:1: W293 blank line contains whitespace\napp/api/v1/platform/restaurants.py:199:1: W293 blank line contains whitespace\napp/api/v1/platform/restaurants.py:208:1: W293 blank line contains whitespace\napp/api/v1/platform/restaurants.py:229:1: W293 blank line contains whitespace\napp/api/v1/platform/restaurants.py:235:1: W293 blank line contains whitespace\napp/api/v1/platform/restaurants.py:238:1: W293 blank line contains whitespace\napp/api/v1/platform/restaurants.py:251:1: W293 blank line contains whitespace\napp/api/v1/platform/restaurants.py:259:1: W293 blank line contains whitespace\napp/api/v1/platform/restaurants.py:265:10: W292 no newline at end of file\napp/api/v1/platform/subscriptions.py:14:1: F401 'app.models.subscription.SubscriptionPlan' imported but unused\napp/api/v1/platform/subscriptions.py:35:1: W293 blank line contains whitespace\napp/api/v1/platform/subscriptions.py:40:1: W293 blank line contains whitespace\napp/api/v1/platform/subscriptions.py:47:1: W293 blank line contains whitespace\napp/api/v1/platform/subscriptions.py:59:1: W293 blank line contains whitespace\napp/api/v1/platform/subscriptions.py:66:1: W293 blank line contains whitespace\napp/api/v1/platform/subscriptions.py:77:1: W293 blank line contains whitespace\napp/api/v1/platform/subscriptions.py:79:1: W293 blank line contains whitespace\napp/api/v1/platform/subscriptions.py:96:1: W293 blank line contains whitespace\napp/api/v1/platform/subscriptions.py:103:1: W293 blank line contains whitespace\napp/api/v1/platform/subscriptions.py:107:1: W293 blank line contains whitespace\napp/api/v1/platform/subscriptions.py:117:1: W293 blank line contains whitespace\napp/api/v1/platform/subscriptions.py:124:1: W293 blank line contains whitespace\napp/api/v1/platform/subscriptions.py:141:1: W293 blank line contains whitespace\napp/api/v1/platform/subscriptions.py:156:1: W293 blank line contains whitespace\napp/api/v1/platform/subscriptions.py:168:1: W293 blank line contains whitespace\napp/api/v1/platform/subscriptions.py:180:1: W293 blank line contains whitespace\napp/api/v1/platform/subscriptions.py:190:1: W293 blank line contains whitespace\napp/api/v1/platform/subscriptions.py:197:1: W293 blank line contains whitespace\napp/api/v1/platform/subscriptions.py:199:1: W293 blank line contains whitespace\napp/api/v1/platform/subscriptions.py:222:1: W293 blank line contains whitespace\napp/api/v1/platform/subscriptions.py:229:1: W293 blank line contains whitespace\napp/api/v1/platform/subscriptions.py:235:1: W293 blank line contains whitespace\napp/api/v1/platform/subscriptions.py:242:1: W293 blank line contains whitespace\napp/api/v1/platform/subscriptions.py:250:1: W293 blank line contains whitespace\napp/api/v1/platform/subscriptions.py:252:1: W293 blank line contains whitespace\napp/api/v1/platform/subscriptions.py:254:1: W293 blank line contains whitespace\napp/api/v1/platform/subscriptions.py:269:1: W293 blank line contains whitespace\napp/api/v1/platform/subscriptions.py:278:1: W293 blank line contains whitespace\napp/api/v1/platform/subscriptions.py:284:10: W292 no newline at end of file\napp/api/v1/platform/users.py:33:1: W293 blank line contains whitespace\napp/api/v1/platform/users.py:44:1: W293 blank line contains whitespace\napp/api/v1/platform/users.py:47:1: W293 blank line contains whitespace\napp/api/v1/platform/users.py:50:1: W293 blank line contains whitespace\napp/api/v1/platform/users.py:53:1: W293 blank line contains whitespace\napp/api/v1/platform/users.py:56:1: W293 blank line contains whitespace\napp/api/v1/platform/users.py:59:1: W293 blank line contains whitespace\napp/api/v1/platform/users.py:66:1: W293 blank line contains whitespace\napp/api/v1/platform/users.py:81:1: W293 blank line contains whitespace\napp/api/v1/platform/users.py:90:1: W293 blank line contains whitespace\napp/api/v1/platform/users.py:107:1: W293 blank line contains whitespace\napp/api/v1/platform/users.py:110:1: W293 blank line contains whitespace\napp/api/v1/platform/users.py:115:1: W293 blank line contains whitespace\napp/api/v1/platform/users.py:120:1: W293 blank line contains whitespace\napp/api/v1/platform/users.py:126:1: W293 blank line contains whitespace\napp/api/v1/platform/users.py:136:1: W293 blank line contains whitespace\napp/api/v1/platform/users.py:146:1: W293 blank line contains whitespace\napp/api/v1/platform/users.py:159:1: W293 blank line contains whitespace\napp/api/v1/platform/users.py:161:1: W293 blank line contains whitespace\napp/api/v1/platform/users.py:179:1: W293 blank line contains whitespace\napp/api/v1/platform/users.py:185:1: W293 blank line contains whitespace\napp/api/v1/platform/users.py:192:1: W293 blank line contains whitespace\napp/api/v1/platform/users.py:195:1: W293 blank line contains whitespace\napp/api/v1/platform/users.py:208:1: W293 blank line contains whitespace\napp/api/v1/platform/users.py:216:1: W293 blank line contains whitespace\napp/api/v1/platform/users.py:234:1: W293 blank line contains whitespace\napp/api/v1/platform/users.py:240:1: W293 blank line contains whitespace\napp/api/v1/platform/users.py:247:1: W293 blank line contains whitespace\napp/api/v1/platform/users.py:254:1: W293 blank line contains whitespace\napp/api/v1/platform/users.py:258:1: W293 blank line contains whitespace\napp/api/v1/platform/users.py:262:1: W293 blank line contains whitespace\napp/api/v1/platform/users.py:276:1: W293 blank line contains whitespace\napp/api/v1/platform/users.py:280:1: W293 blank line contains whitespace\napp/api/v1/platform/users.py:286:10: W292 no newline at end of file\napp/api/v1/subscriptions.py:16:1: F401 'app.schemas.subscription.SubscriptionPlanResponse' imported but unused\napp/api/v1/subscriptions.py:16:1: F401 'app.schemas.subscription.RestaurantSubscriptionResponse' imported but unused\napp/api/v1/subscriptions.py:16:1: F401 'app.schemas.subscription.SubscriptionUsageResponse' imported but unused\napp/api/v1/subscriptions.py:36:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:41:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:43:61: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/v1/subscriptions.py:44:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:46:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:51:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:67:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:78:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:88:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:94:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:101:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:107:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:112:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:128:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:138:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:149:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:155:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:159:40: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/v1/subscriptions.py:161:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:167:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:170:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:180:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:191:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:195:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:204:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:210:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:227:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:237:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:248:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:254:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:258:40: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/api/v1/subscriptions.py:260:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:266:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:268:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:272:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:277:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:280:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:282:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:287:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:304:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:314:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:324:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:330:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:334:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:336:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:341:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:359:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:369:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:377:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:382:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:392:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:398:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:408:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:413:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:431:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:442:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:453:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:455:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:461:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:468:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:472:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:475:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:480:1: W293 blank line contains whitespace\napp/api/v1/subscriptions.py:486:10: W292 no newline at end of file\napp/core/__init__.py:4:4: W292 no newline at end of file\napp/core/analytics_engine.py:6:1: F401 'typing.Tuple' imported but unused\napp/core/analytics_engine.py:9:1: F401 'sqlalchemy.func' imported but unused\napp/core/analytics_engine.py:9:1: F401 'sqlalchemy.or_' imported but unused\napp/core/analytics_engine.py:9:1: F401 'sqlalchemy.asc' imported but unused\napp/core/analytics_engine.py:9:1: F401 'sqlalchemy.text' imported but unused\napp/core/analytics_engine.py:11:1: F401 'json' imported but unused\napp/core/analytics_engine.py:13:1: F401 'decimal.Decimal' imported but unused\napp/core/analytics_engine.py:15:1: F401 'app.core.database.get_db' imported but unused\napp/core/analytics_engine.py:15:1: F401 'app.core.database.Restaurant' imported but unused\napp/core/analytics_engine.py:18:1: E302 expected 2 blank lines, found 1\napp/core/analytics_engine.py:28:1: E302 expected 2 blank lines, found 1\napp/core/analytics_engine.py:37:1: E302 expected 2 blank lines, found 1\napp/core/analytics_engine.py:48:1: E302 expected 2 blank lines, found 1\napp/core/analytics_engine.py:55:1: E302 expected 2 blank lines, found 1\napp/core/analytics_engine.py:66:1: E302 expected 2 blank lines, found 1\napp/core/analytics_engine.py:68:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:76:24: F821 undefined name 'end_date'\napp/core/analytics_engine.py:77:20: F821 undefined name 'start_date'\napp/core/analytics_engine.py:78:66: F821 undefined name 'timeframe'\napp/core/analytics_engine.py:79:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:81:31: F821 undefined name 'restaurant_id'\napp/core/analytics_engine.py:86:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:92:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:94:70: F821 undefined name 'timeframe'\napp/core/analytics_engine.py:95:66: F821 undefined name 'timeframe'\napp/core/analytics_engine.py:96:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:100:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:102:30: F821 undefined name 'timeframe'\napp/core/analytics_engine.py:123:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:136:66: F821 undefined name 'timeframe'\napp/core/analytics_engine.py:137:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:139:31: F821 undefined name 'restaurant_id'\napp/core/analytics_engine.py:144:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:147:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:150:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:152:70: F821 undefined name 'timeframe'\napp/core/analytics_engine.py:153:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:156:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:159:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:169:34: F821 undefined name 'timeframe'\napp/core/analytics_engine.py:172:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:185:66: F821 undefined name 'timeframe'\napp/core/analytics_engine.py:186:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:189:39: F821 undefined name 'restaurant_id'\napp/core/analytics_engine.py:192:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:194:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:199:48: F821 undefined name 'restaurant_id'\napp/core/analytics_engine.py:205:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:208:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:212:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:224:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:227:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:232:121: E501 line too long (141 > 120 characters)\napp/core/analytics_engine.py:234:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:242:34: F821 undefined name 'timeframe'\napp/core/analytics_engine.py:245:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:258:66: F821 undefined name 'timeframe'\napp/core/analytics_engine.py:259:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:262:43: F821 undefined name 'restaurant_id'\napp/core/analytics_engine.py:264:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:268:47: F821 undefined name 'restaurant_id'\napp/core/analytics_engine.py:273:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:279:44: F821 undefined name 'restaurant_id'\napp/core/analytics_engine.py:284:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:296:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:299:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:300:121: E501 line too long (127 > 120 characters)\napp/core/analytics_engine.py:302:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:303:121: E501 line too long (125 > 120 characters)\napp/core/analytics_engine.py:305:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:312:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:316:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:318:121: E501 line too long (134 > 120 characters)\napp/core/analytics_engine.py:319:121: E501 line too long (132 > 120 characters)\napp/core/analytics_engine.py:320:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:338:34: F821 undefined name 'timeframe'\napp/core/analytics_engine.py:341:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:354:66: F821 undefined name 'timeframe'\napp/core/analytics_engine.py:355:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:358:42: F821 undefined name 'restaurant_id'\napp/core/analytics_engine.py:360:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:362:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:367:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:371:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:376:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:388:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:391:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:395:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:406:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:410:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:413:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:425:34: F821 undefined name 'timeframe'\napp/core/analytics_engine.py:428:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:435:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:443:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:451:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:454:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:458:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:462:40: W291 trailing whitespace\napp/core/analytics_engine.py:465:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:469:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:490:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:497:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:514:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:526:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:528:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:533:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:542:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:544:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:548:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:552:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:560:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:570:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:575:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:586:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:591:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:601:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:604:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:607:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:613:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:614:121: E501 line too long (122 > 120 characters)\napp/core/analytics_engine.py:622:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:629:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:635:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:646:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:656:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:667:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:678:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:682:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:689:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:698:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:699:121: E501 line too long (122 > 120 characters)\napp/core/analytics_engine.py:707:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:718:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:724:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:727:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:729:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:739:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:741:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:748:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:762:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:777:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:780:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:786:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:789:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:803:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:806:1: W293 blank line contains whitespace\napp/core/analytics_engine.py:807:9: F841 local variable 'e' is assigned to but never used\napp/core/analytics_engine.py:825:1: E302 expected 2 blank lines, found 1\napp/core/analytics_engine.py:827:31: W292 no newline at end of file\napp/core/auth.py:8:1: F401 'uuid' imported but unused\napp/core/auth.py:19:1: F401 'app.core.exceptions.AuthorizationException' imported but unused\napp/core/auth.py:35:1: W293 blank line contains whitespace\napp/core/auth.py:41:1: W293 blank line contains whitespace\napp/core/auth.py:56:1: W293 blank line contains whitespace\napp/core/auth.py:58:1: W293 blank line contains whitespace\napp/core/auth.py:63:1: W293 blank line contains whitespace\napp/core/auth.py:78:1: W293 blank line contains whitespace\napp/core/auth.py:83:1: W293 blank line contains whitespace\napp/core/auth.py:92:121: E501 line too long (126 > 120 characters)\napp/core/auth.py:99:1: W293 blank line contains whitespace\napp/core/auth.py:116:1: W293 blank line contains whitespace\napp/core/auth.py:129:1: W293 blank line contains whitespace\napp/core/auth.py:131:1: W293 blank line contains whitespace\napp/core/auth.py:199:1: W293 blank line contains whitespace\napp/core/auth.py:224:1: W293 blank line contains whitespace\napp/core/auth.py:227:1: W293 blank line contains whitespace\napp/core/auth.py:231:1: W293 blank line contains whitespace\napp/core/auth.py:234:1: W293 blank line contains whitespace\napp/core/auth.py:238:1: W293 blank line contains whitespace\napp/core/auth.py:243:1: W293 blank line contains whitespace\napp/core/auth.py:248:1: W293 blank line contains whitespace\napp/core/auth.py:250:1: W293 blank line contains whitespace\napp/core/auth.py:266:1: W293 blank line contains whitespace\napp/core/auth.py:269:23: W292 no newline at end of file\napp/core/cache.py:8:1: F401 'datetime.datetime' imported but unused\napp/core/cache.py:8:1: F401 'datetime.timedelta' imported but unused\napp/core/cache.py:18:1: W293 blank line contains whitespace\napp/core/cache.py:23:1: W293 blank line contains whitespace\napp/core/cache.py:40:1: W293 blank line contains whitespace\napp/core/cache.py:42:1: W293 blank line contains whitespace\napp/core/cache.py:45:1: W293 blank line contains whitespace\napp/core/cache.py:49:121: E501 line too long (126 > 120 characters)\napp/core/cache.py:58:1: W293 blank line contains whitespace\napp/core/cache.py:61:1: W293 blank line contains whitespace\napp/core/cache.py:78:1: W293 blank line contains whitespace\napp/core/cache.py:81:1: W293 blank line contains whitespace\napp/core/cache.py:98:1: W293 blank line contains whitespace\napp/core/cache.py:101:1: W293 blank line contains whitespace\napp/core/cache.py:118:17: W291 trailing whitespace\napp/core/cache.py:119:26: W291 trailing whitespace\napp/core/cache.py:124:1: W293 blank line contains whitespace\napp/core/cache.py:129:1: W293 blank line contains whitespace\napp/core/cache.py:140:1: W293 blank line contains whitespace\napp/core/cache.py:143:1: W293 blank line contains whitespace\napp/core/cache.py:159:1: W293 blank line contains whitespace\napp/core/cache.py:165:1: W293 blank line contains whitespace\napp/core/cache.py:181:1: W293 blank line contains whitespace\napp/core/cache.py:185:1: W293 blank line contains whitespace\napp/core/cache.py:197:1: W293 blank line contains whitespace\napp/core/cache.py:210:1: W293 blank line contains whitespace\napp/core/cache.py:222:1: W293 blank line contains whitespace\napp/core/cache.py:227:1: W293 blank line contains whitespace\napp/core/cache.py:238:1: W293 blank line contains whitespace\napp/core/cache.py:241:1: W293 blank line contains whitespace\napp/core/cache.py:255:1: W293 blank line contains whitespace\napp/core/cache.py:259:1: W293 blank line contains whitespace\napp/core/cache.py:270:1: W293 blank line contains whitespace\napp/core/cache.py:287:1: W293 blank line contains whitespace\napp/core/cache.py:292:1: W293 blank line contains whitespace\napp/core/cache.py:303:1: W293 blank line contains whitespace\napp/core/cache.py:306:1: W293 blank line contains whitespace\napp/core/cache.py:323:1: W293 blank line contains whitespace\napp/core/cache.py:328:1: W293 blank line contains whitespace\napp/core/cache.py:339:1: W293 blank line contains whitespace\napp/core/cache.py:342:1: W293 blank line contains whitespace\napp/core/cache.py:347:44: W292 no newline at end of file\napp/core/cache_service.py:7:1: F401 'json' imported but unused\napp/core/cache_service.py:10:1: F401 'typing.Callable' imported but unused\napp/core/cache_service.py:10:1: F401 'typing.Union' imported but unused\napp/core/cache_service.py:14:1: F401 'app.core.config.settings' imported but unused\napp/core/cache_service.py:21:1: W293 blank line contains whitespace\napp/core/cache_service.py:25:1: W293 blank line contains whitespace\napp/core/cache_service.py:30:1: W293 blank line contains whitespace\napp/core/cache_service.py:34:1: W293 blank line contains whitespace\napp/core/cache_service.py:47:1: W293 blank line contains whitespace\napp/core/cache_service.py:51:1: W293 blank line contains whitespace\napp/core/cache_service.py:54:1: W293 blank line contains whitespace\napp/core/cache_service.py:71:1: W293 blank line contains whitespace\napp/core/cache_service.py:75:1: W293 blank line contains whitespace\napp/core/cache_service.py:80:1: W293 blank line contains whitespace\napp/core/cache_service.py:93:1: W293 blank line contains whitespace\napp/core/cache_service.py:97:1: W293 blank line contains whitespace\napp/core/cache_service.py:100:1: W293 blank line contains whitespace\napp/core/cache_service.py:113:1: W293 blank line contains whitespace\napp/core/cache_service.py:117:1: W293 blank line contains whitespace\napp/core/cache_service.py:120:1: W293 blank line contains whitespace\napp/core/cache_service.py:132:1: W293 blank line contains whitespace\napp/core/cache_service.py:136:1: W293 blank line contains whitespace\napp/core/cache_service.py:139:1: W293 blank line contains whitespace\napp/core/cache_service.py:155:1: W293 blank line contains whitespace\napp/core/cache_service.py:160:1: W293 blank line contains whitespace\napp/core/cache_service.py:163:1: W293 blank line contains whitespace\napp/core/cache_service.py:167:1: W293 blank line contains whitespace\napp/core/cache_service.py:170:1: W293 blank line contains whitespace\napp/core/cache_service.py:179:1: W293 blank line contains whitespace\napp/core/cache_service.py:184:1: W293 blank line contains whitespace\napp/core/cache_service.py:187:1: W293 blank line contains whitespace\napp/core/cache_service.py:195:1: W293 blank line contains whitespace\napp/core/cache_service.py:200:1: W293 blank line contains whitespace\napp/core/cache_service.py:206:1: W293 blank line contains whitespace\napp/core/cache_service.py:210:1: W293 blank line contains whitespace\napp/core/cache_service.py:214:1: W293 blank line contains whitespace\napp/core/cache_service.py:218:1: W293 blank line contains whitespace\napp/core/cache_service.py:242:1: W293 blank line contains whitespace\napp/core/cache_service.py:248:1: W293 blank line contains whitespace\napp/core/cache_service.py:261:1: W293 blank line contains whitespace\napp/core/cache_service.py:264:1: W293 blank line contains whitespace\napp/core/cache_service.py:283:1: W293 blank line contains whitespace\napp/core/cache_service.py:286:1: W293 blank line contains whitespace\napp/core/cache_service.py:294:1: W293 blank line contains whitespace\napp/core/cache_service.py:299:1: W293 blank line contains whitespace\napp/core/cache_service.py:302:1: W293 blank line contains whitespace\napp/core/cache_service.py:305:1: W293 blank line contains whitespace\napp/core/cache_service.py:307:1: W293 blank line contains whitespace\napp/core/cache_service.py:312:1: W293 blank line contains whitespace\napp/core/cache_service.py:324:1: W293 blank line contains whitespace\napp/core/cache_service.py:328:34: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/core/cache_service.py:330:1: W293 blank line contains whitespace\napp/core/cache_service.py:339:1: W293 blank line contains whitespace\napp/core/cache_service.py:343:35: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/core/cache_service.py:345:1: W293 blank line contains whitespace\napp/core/cache_service.py:359:1: W293 blank line contains whitespace\napp/core/cache_service.py:363:1: W293 blank line contains whitespace\napp/core/cache_service.py:372:70: W292 no newline at end of file\napp/core/cache_warmer.py:9:1: F401 'typing.List' imported but unused\napp/core/cache_warmer.py:9:1: F401 'typing.Optional' imported but unused\napp/core/cache_warmer.py:9:1: F401 'typing.Dict' imported but unused\napp/core/cache_warmer.py:14:1: F401 'app.core.database.get_db' imported but unused\napp/core/cache_warmer.py:16:1: F401 'app.core.config.settings' imported but unused\napp/core/cache_warmer.py:23:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:28:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:32:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:39:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:50:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:54:38: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/core/cache_warmer.py:56:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:58:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:65:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:70:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:75:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:77:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:82:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:88:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:91:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:93:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:96:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:104:39: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/core/cache_warmer.py:107:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:110:33: W291 trailing whitespace\napp/core/cache_warmer.py:113:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:120:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:133:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:137:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:140:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:142:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:146:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:154:40: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/core/cache_warmer.py:157:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:167:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:173:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:177:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:188:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:192:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:194:121: E501 line too long (121 > 120 characters)\napp/core/cache_warmer.py:195:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:197:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:201:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:206:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:210:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:214:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:221:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:224:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:233:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:235:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:240:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:255:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:266:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:269:1: W293 blank line contains whitespace\napp/core/cache_warmer.py:288:13: W292 no newline at end of file\napp/core/config.py:23:1: E302 expected 2 blank lines, found 1\napp/core/config.py:25:1: W293 blank line contains whitespace\napp/core/config.py:32:1: W293 blank line contains whitespace\napp/core/config.py:35:1: W293 blank line contains whitespace\napp/core/config.py:38:1: W293 blank line contains whitespace\napp/core/config.py:44:1: W293 blank line contains whitespace\napp/core/config.py:54:1: W293 blank line contains whitespace\napp/core/config.py:65:40: E261 at least two spaces before inline comment\napp/core/config.py:66:1: W293 blank line contains whitespace\napp/core/config.py:69:46: W291 trailing whitespace\napp/core/config.py:72:1: W293 blank line contains whitespace\napp/core/config.py:76:1: W293 blank line contains whitespace\napp/core/config.py:80:1: W293 blank line contains whitespace\napp/core/config.py:85:1: W293 blank line contains whitespace\napp/core/config.py:108:1: W293 blank line contains whitespace\napp/core/config.py:119:1: W293 blank line contains whitespace\napp/core/config.py:122:1: W293 blank line contains whitespace\napp/core/config.py:139:1: W293 blank line contains whitespace\napp/core/config.py:145:1: W293 blank line contains whitespace\napp/core/config.py:151:1: W293 blank line contains whitespace\napp/core/config.py:154:1: W293 blank line contains whitespace\napp/core/config.py:157:1: W293 blank line contains whitespace\napp/core/config.py:164:9: F841 local variable 'e' is assigned to but never used\napp/core/config.py:166:1: W293 blank line contains whitespace\napp/core/config.py:170:1: W293 blank line contains whitespace\napp/core/config.py:173:1: W293 blank line contains whitespace\napp/core/config.py:179:1: W293 blank line contains whitespace\napp/core/config.py:183:1: W293 blank line contains whitespace\napp/core/config.py:195:1: E305 expected 2 blank lines after class or function definition, found 1\napp/core/config.py:213:7: E111 indentation is not a multiple of 4\napp/core/config.py:214:33: E261 at least two spaces before inline comment\napp/core/config.py:215:7: E111 indentation is not a multiple of 4\napp/core/config.py:216:10: E261 at least two spaces before inline comment\napp/core/config.py:217:7: E111 indentation is not a multiple of 4\napp/core/config.py:227:1: E302 expected 2 blank lines, found 1\napp/core/config.py:255:80: E261 at least two spaces before inline comment\napp/core/config.py:259:35: E261 at least two spaces before inline comment\napp/core/config.py:260:14: E111 indentation is not a multiple of 4\napp/core/config.py:260:14: E117 over-indented\napp/core/config.py:269:14: E111 indentation is not a multiple of 4\napp/core/config.py:269:14: E117 over-indented\napp/core/config.py:269:121: E501 line too long (137 > 120 characters)\napp/core/config.py:272:13: F841 local variable 'error_message' is assigned to but never used\napp/core/config.py:277:121: E501 line too long (122 > 120 characters)\napp/core/config.py:280:1: E305 expected 2 blank lines after class or function definition, found 1\napp/core/config.py:281:1: W391 blank line at end of file\napp/core/database.py:6:121: E501 line too long (132 > 120 characters)\napp/core/database.py:11:1: F401 'sqlalchemy.sql.elements.TextClause' imported but unused\napp/core/database.py:44:1: W293 blank line contains whitespace\napp/core/database.py:51:1: W293 blank line contains whitespace\napp/core/database.py:65:1: E402 module level import not at top of file\napp/core/database.py:95:1: E302 expected 2 blank lines, found 1\napp/core/database.py:98:1: W293 blank line contains whitespace\napp/core/database.py:106:1: E302 expected 2 blank lines, found 1\napp/core/database.py:109:1: W293 blank line contains whitespace\napp/core/database.py:141:1: W293 blank line contains whitespace\napp/core/database.py:145:1: E302 expected 2 blank lines, found 1\napp/core/database.py:148:1: W293 blank line contains whitespace\napp/core/database.py:168:1: W293 blank line contains whitespace\napp/core/database.py:173:1: E302 expected 2 blank lines, found 1\napp/core/database.py:176:1: W293 blank line contains whitespace\napp/core/database.py:186:1: W293 blank line contains whitespace\napp/core/database.py:191:1: W293 blank line contains whitespace\napp/core/database.py:196:1: E302 expected 2 blank lines, found 1\napp/core/database.py:199:1: W293 blank line contains whitespace\napp/core/database.py:213:1: E302 expected 2 blank lines, found 1\napp/core/database.py:216:1: W293 blank line contains whitespace\napp/core/database.py:227:1: E302 expected 2 blank lines, found 1\napp/core/database.py:230:1: W293 blank line contains whitespace\napp/core/database.py:249:1: W293 blank line contains whitespace\napp/core/database.py:253:1: E302 expected 2 blank lines, found 1\napp/core/database.py:256:1: W293 blank line contains whitespace\napp/core/database.py:276:1: W293 blank line contains whitespace\napp/core/database.py:280:1: E302 expected 2 blank lines, found 1\napp/core/database.py:283:1: W293 blank line contains whitespace\napp/core/database.py:296:1: E302 expected 2 blank lines, found 1\napp/core/database.py:299:1: W293 blank line contains whitespace\napp/core/database.py:310:1: E302 expected 2 blank lines, found 1\napp/core/database.py:313:1: W293 blank line contains whitespace\napp/core/database.py:323:1: E302 expected 2 blank lines, found 1\napp/core/database.py:331:55: E261 at least two spaces before inline comment\napp/core/database.py:332:60: E261 at least two spaces before inline comment\napp/core/database.py:333:47: E261 at least two spaces before inline comment\napp/core/database.py:334:58: E261 at least two spaces before inline comment\napp/core/database.py:351:84: E261 at least two spaces before inline comment\napp/core/database.py:352:86: E261 at least two spaces before inline comment\napp/core/database.py:353:44: E261 at least two spaces before inline comment\napp/core/database.py:360:121: E501 line too long (131 > 120 characters)\napp/core/database.py:370:46: E261 at least two spaces before inline comment\napp/core/database.py:371:48: E261 at least two spaces before inline comment\napp/core/database.py:371:121: E501 line too long (125 > 120 characters)\napp/core/database.py:372:51: E261 at least two spaces before inline comment\napp/core/database.py:383:1: W293 blank line contains whitespace\napp/core/database.py:400:1: W293 blank line contains whitespace\napp/core/database.py:405:1: E302 expected 2 blank lines, found 1\napp/core/database.py:408:1: W293 blank line contains whitespace\napp/core/database.py:424:1: E305 expected 2 blank lines after class or function definition, found 1\napp/core/database.py:424:1: E402 module level import not at top of file\napp/core/database.py:425:1: F811 redefinition of unused 'Optional' from line 13\napp/core/database.py:425:1: E402 module level import not at top of file\napp/core/database.py:433:1: E302 expected 2 blank lines, found 1\napp/core/database.py:435:1: W293 blank line contains whitespace\napp/core/database.py:445:1: W293 blank line contains whitespace\napp/core/database.py:451:1: W293 blank line contains whitespace\napp/core/database.py:471:1: W293 blank line contains whitespace\napp/core/database.py:481:1: W293 blank line contains whitespace\napp/core/database.py:486:1: W293 blank line contains whitespace\napp/core/database.py:490:1: W293 blank line contains whitespace\napp/core/database.py:494:1: W293 blank line contains whitespace\napp/core/database.py:498:1: W293 blank line contains whitespace\napp/core/database.py:502:1: W293 blank line contains whitespace\napp/core/database.py:548:1: W293 blank line contains whitespace\napp/core/database.py:557:1: E302 expected 2 blank lines, found 1\napp/core/database.py:561:1: W293 blank line contains whitespace\napp/core/database.py:569:43: W292 no newline at end of file\napp/core/database_security.py:16:1: W293 blank line contains whitespace\napp/core/database_security.py:21:1: W293 blank line contains whitespace\napp/core/database_security.py:31:1: W293 blank line contains whitespace\napp/core/database_security.py:39:1: W293 blank line contains whitespace\napp/core/database_security.py:44:1: W293 blank line contains whitespace\napp/core/database_security.py:49:1: W293 blank line contains whitespace\napp/core/database_security.py:53:1: W293 blank line contains whitespace\napp/core/database_security.py:60:1: W293 blank line contains whitespace\napp/core/database_security.py:63:1: W293 blank line contains whitespace\napp/core/database_security.py:66:1: W293 blank line contains whitespace\napp/core/database_security.py:69:1: W293 blank line contains whitespace\napp/core/database_security.py:72:1: W293 blank line contains whitespace\napp/core/database_security.py:75:1: W293 blank line contains whitespace\napp/core/database_security.py:78:1: W293 blank line contains whitespace\napp/core/database_security.py:84:1: W293 blank line contains whitespace\napp/core/database_security.py:89:1: W293 blank line contains whitespace\napp/core/database_security.py:108:1: W293 blank line contains whitespace\napp/core/database_security.py:111:62: W291 trailing whitespace\napp/core/database_security.py:114:1: W293 blank line contains whitespace\napp/core/database_security.py:121:36: W291 trailing whitespace\napp/core/database_security.py:122:33: W291 trailing whitespace\napp/core/database_security.py:123:36: W291 trailing whitespace\napp/core/database_security.py:124:35: W291 trailing whitespace\napp/core/database_security.py:140:1: W293 blank line contains whitespace\napp/core/database_security.py:153:1: W293 blank line contains whitespace\napp/core/database_security.py:161:1: W293 blank line contains whitespace\napp/core/database_security.py:166:1: W293 blank line contains whitespace\napp/core/database_security.py:171:1: W293 blank line contains whitespace\napp/core/database_security.py:173:1: W293 blank line contains whitespace\napp/core/database_security.py:178:1: W293 blank line contains whitespace\napp/core/database_security.py:185:63: W291 trailing whitespace\napp/core/database_security.py:188:1: W293 blank line contains whitespace\napp/core/database_security.py:193:1: W293 blank line contains whitespace\napp/core/database_security.py:203:1: W293 blank line contains whitespace\napp/core/database_security.py:207:1: W293 blank line contains whitespace\napp/core/database_security.py:209:1: W293 blank line contains whitespace\napp/core/database_security.py:214:1: W293 blank line contains whitespace\napp/core/database_security.py:218:1: W293 blank line contains whitespace\napp/core/database_security.py:222:1: W293 blank line contains whitespace\napp/core/database_security.py:226:1: W293 blank line contains whitespace\napp/core/database_security.py:235:1: W293 blank line contains whitespace\napp/core/database_security.py:240:1: W293 blank line contains whitespace\napp/core/database_security.py:245:1: W293 blank line contains whitespace\napp/core/database_security.py:249:1: W293 blank line contains whitespace\napp/core/database_security.py:254:1: W293 blank line contains whitespace\napp/core/database_security.py:259:1: W293 blank line contains whitespace\napp/core/database_security.py:265:1: W293 blank line contains whitespace\napp/core/database_security.py:270:1: W293 blank line contains whitespace\napp/core/database_security.py:278:23: W291 trailing whitespace\napp/core/database_security.py:291:1: W293 blank line contains whitespace\napp/core/database_security.py:295:23: W291 trailing whitespace\napp/core/database_security.py:308:1: W293 blank line contains whitespace\napp/core/database_security.py:312:1: E402 module level import not at top of file\napp/core/database_security.py:318:1: W293 blank line contains whitespace\napp/core/database_security.py:323:1: W293 blank line contains whitespace\napp/core/database_security.py:327:1: W293 blank line contains whitespace\napp/core/database_security.py:330:1: W293 blank line contains whitespace\napp/core/database_security.py:333:1: W293 blank line contains whitespace\napp/core/database_security.py:336:1: W293 blank line contains whitespace\napp/core/database_security.py:339:1: W293 blank line contains whitespace\napp/core/database_security.py:342:1: W293 blank line contains whitespace\napp/core/database_security.py:344:1: W293 blank line contains whitespace\napp/core/database_security.py:347:48: W292 no newline at end of file\napp/core/dependencies.py:9:1: F401 'app.core.exceptions.FynloException' imported but unused\napp/core/dependencies.py:25:1: W293 blank line contains whitespace\napp/core/dependencies.py:44:1: W293 blank line contains whitespace\napp/core/dependencies.py:47:1: W293 blank line contains whitespace\napp/core/dependencies.py:59:1: W293 blank line contains whitespace\napp/core/dependencies.py:73:1: W293 blank line contains whitespace\napp/core/dependencies.py:76:1: W293 blank line contains whitespace\napp/core/dependencies.py:77:1: W293 blank line contains whitespace\napp/core/dependencies.py:78:5: E303 too many blank lines (2)\napp/core/dependencies.py:86:1: W293 blank line contains whitespace\napp/core/dependencies.py:93:1: W293 blank line contains whitespace\napp/core/dependencies.py:101:1: W293 blank line contains whitespace\napp/core/dependencies.py:104:1: W293 blank line contains whitespace\napp/core/dependencies.py:114:1: W293 blank line contains whitespace\napp/core/dependencies.py:125:1: W293 blank line contains whitespace\napp/core/dependencies.py:132:1: W293 blank line contains whitespace\napp/core/dependencies.py:140:1: W293 blank line contains whitespace\napp/core/dependencies.py:143:1: W293 blank line contains whitespace\napp/core/dependencies.py:153:1: W293 blank line contains whitespace\napp/core/dependencies.py:161:1: W293 blank line contains whitespace\napp/core/dependencies.py:170:1: W293 blank line contains whitespace\napp/core/dependencies.py:180:1: W293 blank line contains whitespace\napp/core/dependencies.py:190:1: W293 blank line contains whitespace\napp/core/dependencies.py:198:60: W292 no newline at end of file\napp/core/exceptions.py:10:1: F401 'pydantic.BaseModel' imported but unused\napp/core/exceptions.py:15:37: E261 at least two spaces before inline comment\napp/core/exceptions.py:24:1: W293 blank line contains whitespace\napp/core/exceptions.py:41:1: W293 blank line contains whitespace\napp/core/exceptions.py:53:1: W293 blank line contains whitespace\napp/core/exceptions.py:65:1: W293 blank line contains whitespace\napp/core/exceptions.py:75:1: W293 blank line contains whitespace\napp/core/exceptions.py:86:1: W293 blank line contains whitespace\napp/core/exceptions.py:96:1: W293 blank line contains whitespace\napp/core/exceptions.py:101:1: W293 blank line contains whitespace\napp/core/exceptions.py:112:1: W293 blank line contains whitespace\napp/core/exceptions.py:122:1: W293 blank line contains whitespace\napp/core/exceptions.py:133:1: W293 blank line contains whitespace\napp/core/exceptions.py:150:1: W293 blank line contains whitespace\napp/core/exceptions.py:160:1: W293 blank line contains whitespace\napp/core/exceptions.py:171:1: W293 blank line contains whitespace\napp/core/exceptions.py:184:1: W293 blank line contains whitespace\napp/core/exceptions.py:195:1: W293 blank line contains whitespace\napp/core/exceptions.py:211:1: W293 blank line contains whitespace\napp/core/exceptions.py:222:1: W293 blank line contains whitespace\napp/core/exceptions.py:235:1: W293 blank line contains whitespace\napp/core/exceptions.py:240:1: W293 blank line contains whitespace\napp/core/exceptions.py:251:1: W293 blank line contains whitespace\napp/core/exceptions.py:262:1: W293 blank line contains whitespace\napp/core/exceptions.py:273:1: W293 blank line contains whitespace\napp/core/exceptions.py:275:1: W293 blank line contains whitespace\napp/core/exceptions.py:295:14: E111 indentation is not a multiple of 4\napp/core/exceptions.py:295:14: E117 over-indented\napp/core/exceptions.py:296:39: E261 at least two spaces before inline comment\napp/core/exceptions.py:300:5: E303 too many blank lines (2)\napp/core/exceptions.py:310:1: W293 blank line contains whitespace\napp/core/exceptions.py:312:1: W293 blank line contains whitespace\napp/core/exceptions.py:323:1: W293 blank line contains whitespace\napp/core/exceptions.py:333:1: W293 blank line contains whitespace\napp/core/exceptions.py:337:37: E261 at least two spaces before inline comment\napp/core/exceptions.py:345:44: E261 at least two spaces before inline comment\napp/core/exceptions.py:352:1: W293 blank line contains whitespace\napp/core/exceptions.py:354:1: W293 blank line contains whitespace\napp/core/exceptions.py:366:1: W293 blank line contains whitespace\napp/core/exceptions.py:383:1: W293 blank line contains whitespace\napp/core/exceptions.py:393:1: W293 blank line contains whitespace\napp/core/exceptions.py:401:1: W293 blank line contains whitespace\napp/core/exceptions.py:412:1: W293 blank line contains whitespace\napp/core/exceptions.py:420:1: W293 blank line contains whitespace\napp/core/exceptions.py:432:1: W293 blank line contains whitespace\napp/core/exceptions.py:442:10: W292 no newline at end of file\napp/core/feature_gate.py:2:1: F401 'typing.Callable' imported but unused\napp/core/feature_gate.py:4:1: F401 'app.core.database.get_db' imported but unused\napp/core/feature_gate.py:4:1: F401 'app.core.database.User' imported but unused\napp/core/feature_gate.py:5:1: F401 'app.core.exceptions.AuthenticationException' imported but unused\napp/core/feature_gate.py:13:1: W293 blank line contains whitespace\napp/core/feature_gate.py:20:1: W293 blank line contains whitespace\napp/core/feature_gate.py:30:1: E302 expected 2 blank lines, found 1\napp/core/feature_gate.py:35:17: E128 continuation line under-indented for visual indent\napp/core/feature_gate.py:36:17: E128 continuation line under-indented for visual indent\napp/core/feature_gate.py:41:1: E302 expected 2 blank lines, found 1\napp/core/feature_gate.py:46:1: W293 blank line contains whitespace\napp/core/feature_gate.py:53:1: E302 expected 2 blank lines, found 1\napp/core/feature_gate.py:61:1: W293 blank line contains whitespace\napp/core/feature_gate.py:74:1: W293 blank line contains whitespace\napp/core/feature_gate.py:78:98: W292 no newline at end of file\napp/core/file_upload.py:24:1: F401 'app.core.responses.APIResponseHelper' imported but unused\napp/core/file_upload.py:29:1: E302 expected 2 blank lines, found 1\napp/core/file_upload.py:31:1: W293 blank line contains whitespace\napp/core/file_upload.py:38:1: W293 blank line contains whitespace\napp/core/file_upload.py:43:21: W291 trailing whitespace\napp/core/file_upload.py:48:1: W293 blank line contains whitespace\napp/core/file_upload.py:53:1: W293 blank line contains whitespace\napp/core/file_upload.py:62:1: E302 expected 2 blank lines, found 1\napp/core/file_upload.py:69:1: E302 expected 2 blank lines, found 1\napp/core/file_upload.py:78:1: E302 expected 2 blank lines, found 1\napp/core/file_upload.py:80:1: W293 blank line contains whitespace\napp/core/file_upload.py:84:1: W293 blank line contains whitespace\napp/core/file_upload.py:97:1: W293 blank line contains whitespace\napp/core/file_upload.py:107:1: W293 blank line contains whitespace\napp/core/file_upload.py:111:1: W293 blank line contains whitespace\napp/core/file_upload.py:124:1: W293 blank line contains whitespace\napp/core/file_upload.py:127:1: W293 blank line contains whitespace\napp/core/file_upload.py:131:98: E226 missing whitespace around arithmetic operator\napp/core/file_upload.py:135:1: W293 blank line contains whitespace\napp/core/file_upload.py:139:1: W293 blank line contains whitespace\napp/core/file_upload.py:146:1: W293 blank line contains whitespace\napp/core/file_upload.py:152:1: W293 blank line contains whitespace\napp/core/file_upload.py:154:1: W293 blank line contains whitespace\napp/core/file_upload.py:167:1: W293 blank line contains whitespace\napp/core/file_upload.py:175:1: W293 blank line contains whitespace\napp/core/file_upload.py:183:1: W293 blank line contains whitespace\napp/core/file_upload.py:186:1: W293 blank line contains whitespace\napp/core/file_upload.py:195:1: W293 blank line contains whitespace\napp/core/file_upload.py:200:1: W293 blank line contains whitespace\napp/core/file_upload.py:202:1: W293 blank line contains whitespace\napp/core/file_upload.py:209:1: W293 blank line contains whitespace\napp/core/file_upload.py:215:1: W293 blank line contains whitespace\napp/core/file_upload.py:221:1: W293 blank line contains whitespace\napp/core/file_upload.py:225:1: W293 blank line contains whitespace\napp/core/file_upload.py:227:34: W291 trailing whitespace\napp/core/file_upload.py:228:28: W291 trailing whitespace\napp/core/file_upload.py:232:1: W293 blank line contains whitespace\napp/core/file_upload.py:238:1: W293 blank line contains whitespace\napp/core/file_upload.py:240:1: W293 blank line contains whitespace\napp/core/file_upload.py:247:1: W293 blank line contains whitespace\napp/core/file_upload.py:256:1: W293 blank line contains whitespace\napp/core/file_upload.py:262:1: W293 blank line contains whitespace\napp/core/file_upload.py:264:1: W293 blank line contains whitespace\napp/core/file_upload.py:272:1: W293 blank line contains whitespace\napp/core/file_upload.py:276:1: W293 blank line contains whitespace\napp/core/file_upload.py:284:1: W293 blank line contains whitespace\napp/core/file_upload.py:286:1: W293 blank line contains whitespace\napp/core/file_upload.py:293:1: W293 blank line contains whitespace\napp/core/file_upload.py:294:50: W291 trailing whitespace\napp/core/file_upload.py:295:40: E128 continuation line under-indented for visual indent\napp/core/file_upload.py:295:57: W291 trailing whitespace\napp/core/file_upload.py:296:40: E128 continuation line under-indented for visual indent\napp/core/file_upload.py:297:40: E128 continuation line under-indented for visual indent\napp/core/file_upload.py:298:40: E128 continuation line under-indented for visual indent\napp/core/file_upload.py:305:1: W293 blank line contains whitespace\napp/core/file_upload.py:308:1: W293 blank line contains whitespace\napp/core/file_upload.py:316:1: W293 blank line contains whitespace\napp/core/file_upload.py:318:1: W293 blank line contains whitespace\napp/core/file_upload.py:327:1: W293 blank line contains whitespace\napp/core/file_upload.py:346:1: W293 blank line contains whitespace\napp/core/file_upload.py:355:40: W291 trailing whitespace\napp/core/file_upload.py:356:34: E128 continuation line under-indented for visual indent\napp/core/file_upload.py:356:51: W291 trailing whitespace\napp/core/file_upload.py:357:34: E128 continuation line under-indented for visual indent\napp/core/file_upload.py:358:34: E128 continuation line under-indented for visual indent\napp/core/file_upload.py:359:34: E128 continuation line under-indented for visual indent\napp/core/file_upload.py:360:34: E128 continuation line under-indented for visual indent\napp/core/file_upload.py:374:1: W293 blank line contains whitespace\napp/core/file_upload.py:379:1: W293 blank line contains whitespace\napp/core/file_upload.py:382:1: W293 blank line contains whitespace\napp/core/file_upload.py:385:1: W293 blank line contains whitespace\napp/core/file_upload.py:393:1: W293 blank line contains whitespace\napp/core/file_upload.py:396:1: W293 blank line contains whitespace\napp/core/file_upload.py:402:1: W293 blank line contains whitespace\napp/core/file_upload.py:406:1: W293 blank line contains whitespace\napp/core/file_upload.py:422:1: W293 blank line contains whitespace\napp/core/file_upload.py:431:1: W293 blank line contains whitespace\napp/core/file_upload.py:443:1: W293 blank line contains whitespace\napp/core/file_upload.py:446:1: W293 blank line contains whitespace\napp/core/file_upload.py:454:1: W293 blank line contains whitespace\napp/core/file_upload.py:456:1: W293 blank line contains whitespace\napp/core/file_upload.py:465:1: E305 expected 2 blank lines after class or function definition, found 1\napp/core/file_upload.py:465:42: W292 no newline at end of file\napp/core/logging_filters.py:54:1: E302 expected 2 blank lines, found 1\napp/core/logging_filters.py:72:1: W293 blank line contains whitespace\napp/core/logging_filters.py:80:121: E501 line too long (122 > 120 characters)\napp/core/logging_filters.py:84:5: E303 too many blank lines (2)\napp/core/logging_filters.py:100:20: F821 undefined name 'record'\napp/core/logging_filters.py:100:52: F821 undefined name 'record'\napp/core/logging_filters.py:101:13: F821 undefined name 'record'\napp/core/logging_filters.py:101:46: F821 undefined name 'record'\napp/core/logging_filters.py:104:12: F821 undefined name 'record'\napp/core/logging_filters.py:104:47: F821 undefined name 'record'\napp/core/logging_filters.py:108:23: F821 undefined name 'record'\napp/core/logging_filters.py:116:1: W293 blank line contains whitespace\napp/core/logging_filters.py:125:1: W293 blank line contains whitespace\napp/core/logging_filters.py:128:121: E501 line too long (160 > 120 characters)\napp/core/logging_filters.py:139:27: F821 undefined name 'record'\napp/core/logging_filters.py:140:18: F821 undefined name 'record'\napp/core/logging_filters.py:140:18: E111 indentation is not a multiple of 4\napp/core/logging_filters.py:140:18: E117 over-indented\napp/core/logging_filters.py:140:38: E261 at least two spaces before inline comment\napp/core/logging_filters.py:141:18: F821 undefined name 'record'\napp/core/logging_filters.py:141:18: E111 indentation is not a multiple of 4\napp/core/logging_filters.py:141:34: E261 at least two spaces before inline comment\napp/core/logging_filters.py:144:9: E303 too many blank lines (2)\napp/core/logging_filters.py:145:23: F821 undefined name 'record'\napp/core/logging_filters.py:146:13: F821 undefined name 'record'\napp/core/logging_filters.py:146:45: F821 undefined name 'record'\napp/core/logging_filters.py:147:25: F821 undefined name 'record'\napp/core/logging_filters.py:149:24: F821 undefined name 'record'\napp/core/logging_filters.py:154:13: F821 undefined name 'record'\napp/core/logging_filters.py:158:1: E302 expected 2 blank lines, found 1\napp/core/mobile_id_mapping.py:10:1: F401 'sqlalchemy.ext.declarative.declarative_base' imported but unused\napp/core/mobile_id_mapping.py:17:1: E302 expected 2 blank lines, found 1\napp/core/mobile_id_mapping.py:23:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:28:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:34:1: E302 expected 2 blank lines, found 1\napp/core/mobile_id_mapping.py:39:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:43:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:48:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:52:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:56:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:59:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:68:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:76:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:82:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:89:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:92:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:101:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:106:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:109:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:113:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:117:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:121:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:130:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:137:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:143:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:150:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:152:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:156:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:160:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:164:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:167:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:172:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:176:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:179:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:183:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:186:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:192:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:195:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:197:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:201:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:205:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:212:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:220:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:223:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:229:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:237:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:240:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:246:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:252:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:255:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:261:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:263:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:267:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:272:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:277:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:283:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:286:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:296:1: W293 blank line contains whitespace\napp/core/mobile_id_mapping.py:302:1: E302 expected 2 blank lines, found 1\napp/core/mobile_id_mapping.py:312:1: E305 expected 2 blank lines after class or function definition, found 1\napp/core/mobile_id_mapping.py:314:1: E302 expected 2 blank lines, found 1\napp/core/mobile_id_mapping.py:316:38: W292 no newline at end of file\napp/core/mobile_middleware.py:14:1: E302 expected 2 blank lines, found 1\napp/core/mobile_middleware.py:18:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:23:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:32:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:35:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:39:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:42:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:44:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:58:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:60:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:71:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:80:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:85:1: E302 expected 2 blank lines, found 1\napp/core/mobile_middleware.py:89:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:98:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:100:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:104:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:106:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:113:48: W504 line break after binary operator\napp/core/mobile_middleware.py:116:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:124:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:133:1: E302 expected 2 blank lines, found 1\napp/core/mobile_middleware.py:137:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:143:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:147:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:151:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:153:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:160:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:167:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:175:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:178:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:181:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:184:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:187:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:191:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:193:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:197:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:212:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:219:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:223:1: E302 expected 2 blank lines, found 1\napp/core/mobile_middleware.py:228:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:238:1: E302 expected 2 blank lines, found 1\napp/core/mobile_middleware.py:243:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:252:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:255:1: W293 blank line contains whitespace\napp/core/mobile_middleware.py:256:56: W292 no newline at end of file\napp/core/onboarding_helper.py:13:1: W293 blank line contains whitespace\napp/core/onboarding_helper.py:20:1: W293 blank line contains whitespace\napp/core/onboarding_helper.py:24:1: W293 blank line contains whitespace\napp/core/onboarding_helper.py:70:1: W293 blank line contains whitespace\napp/core/onboarding_helper.py:76:1: W293 blank line contains whitespace\napp/core/onboarding_helper.py:78:77: W291 trailing whitespace\napp/core/onboarding_helper.py:82:1: W293 blank line contains whitespace\napp/core/onboarding_helper.py:87:1: W293 blank line contains whitespace\napp/core/onboarding_helper.py:96:1: W293 blank line contains whitespace\napp/core/onboarding_helper.py:100:1: W293 blank line contains whitespace\napp/core/onboarding_helper.py:109:1: W293 blank line contains whitespace\napp/core/onboarding_helper.py:112:1: W293 blank line contains whitespace\napp/core/onboarding_helper.py:116:1: W293 blank line contains whitespace\napp/core/onboarding_helper.py:191:1: W293 blank line contains whitespace\napp/core/onboarding_helper.py:195:11: W292 no newline at end of file\napp/core/platform_service.py:10:1: F401 'decimal.Decimal' imported but unused\napp/core/platform_service.py:15:1: E302 expected 2 blank lines, found 1\napp/core/platform_service.py:17:1: W293 blank line contains whitespace\napp/core/platform_service.py:20:1: W293 blank line contains whitespace\napp/core/platform_service.py:34:1: W293 blank line contains whitespace\napp/core/platform_service.py:39:1: W293 blank line contains whitespace\napp/core/platform_service.py:41:1: W293 blank line contains whitespace\napp/core/platform_service.py:45:1: W293 blank line contains whitespace\napp/core/platform_service.py:49:1: W293 blank line contains whitespace\napp/core/platform_service.py:57:1: W293 blank line contains whitespace\napp/core/platform_service.py:64:1: W293 blank line contains whitespace\napp/core/platform_service.py:69:1: W293 blank line contains whitespace\napp/core/platform_service.py:78:121: E501 line too long (123 > 120 characters)\napp/core/platform_service.py:89:1: W293 blank line contains whitespace\napp/core/platform_service.py:96:1: W293 blank line contains whitespace\napp/core/platform_service.py:105:1: W293 blank line contains whitespace\napp/core/platform_service.py:108:1: W293 blank line contains whitespace\napp/core/platform_service.py:110:1: W293 blank line contains whitespace\napp/core/platform_service.py:119:1: W293 blank line contains whitespace\napp/core/platform_service.py:122:1: W293 blank line contains whitespace\napp/core/platform_service.py:127:1: W293 blank line contains whitespace\napp/core/platform_service.py:131:1: W293 blank line contains whitespace\napp/core/platform_service.py:146:1: W293 blank line contains whitespace\napp/core/platform_service.py:149:1: W293 blank line contains whitespace\napp/core/platform_service.py:151:1: W293 blank line contains whitespace\napp/core/platform_service.py:158:1: W293 blank line contains whitespace\napp/core/platform_service.py:167:1: W293 blank line contains whitespace\napp/core/platform_service.py:170:1: W293 blank line contains whitespace\napp/core/platform_service.py:174:1: W293 blank line contains whitespace\napp/core/platform_service.py:184:1: W293 blank line contains whitespace\napp/core/platform_service.py:186:1: W293 blank line contains whitespace\napp/core/platform_service.py:191:1: W293 blank line contains whitespace\napp/core/platform_service.py:201:1: W293 blank line contains whitespace\napp/core/platform_service.py:204:1: W293 blank line contains whitespace\napp/core/platform_service.py:211:121: E501 line too long (139 > 120 characters)\napp/core/platform_service.py:214:1: W293 blank line contains whitespace\napp/core/platform_service.py:221:1: W293 blank line contains whitespace\napp/core/platform_service.py:233:1: W293 blank line contains whitespace\napp/core/platform_service.py:235:1: W293 blank line contains whitespace\napp/core/platform_service.py:238:1: W293 blank line contains whitespace\napp/core/platform_service.py:247:1: W293 blank line contains whitespace\napp/core/platform_service.py:250:1: W293 blank line contains whitespace\napp/core/platform_service.py:255:1: W293 blank line contains whitespace\napp/core/platform_service.py:257:1: W293 blank line contains whitespace\napp/core/platform_service.py:275:1: W293 blank line contains whitespace\napp/core/platform_service.py:277:1: W293 blank line contains whitespace\napp/core/platform_service.py:284:1: W293 blank line contains whitespace\napp/core/platform_service.py:293:1: W293 blank line contains whitespace\napp/core/platform_service.py:295:1: W293 blank line contains whitespace\napp/core/platform_service.py:299:1: W293 blank line contains whitespace\napp/core/platform_service.py:306:1: W293 blank line contains whitespace\napp/core/platform_service.py:316:1: W293 blank line contains whitespace\napp/core/platform_service.py:323:121: E501 line too long (134 > 120 characters)\napp/core/platform_service.py:326:1: W293 blank line contains whitespace\napp/core/platform_service.py:331:1: W293 blank line contains whitespace\napp/core/platform_service.py:337:121: E501 line too long (124 > 120 characters)\napp/core/platform_service.py:341:1: W293 blank line contains whitespace\napp/core/platform_service.py:348:1: W293 blank line contains whitespace\napp/core/platform_service.py:354:1: W293 blank line contains whitespace\napp/core/platform_service.py:363:1: W293 blank line contains whitespace\napp/core/platform_service.py:367:1: E302 expected 2 blank lines, found 1\napp/core/platform_service.py:369:31: W292 no newline at end of file\napp/core/production_guard.py:8:1: F401 'fastapi.HTTPException' imported but unused\napp/core/production_guard.py:22:23: F821 undefined name 'FynloException'\napp/core/production_guard.py:30:23: F821 undefined name 'FynloException'\napp/core/production_guard.py:48:81: W292 no newline at end of file\napp/core/push_notifications.py:9:1: F401 'json' imported but unused\napp/core/push_notifications.py:16:1: F401 'app.core.responses.APIResponseHelper' imported but unused\napp/core/push_notifications.py:23:1: E302 expected 2 blank lines, found 1\napp/core/push_notifications.py:36:1: E302 expected 2 blank lines, found 1\napp/core/push_notifications.py:43:1: E302 expected 2 blank lines, found 1\napp/core/push_notifications.py:53:1: W293 blank line contains whitespace\napp/core/push_notifications.py:60:1: E302 expected 2 blank lines, found 1\napp/core/push_notifications.py:71:1: W293 blank line contains whitespace\napp/core/push_notifications.py:78:1: E302 expected 2 blank lines, found 1\napp/core/push_notifications.py:87:1: W293 blank line contains whitespace\napp/core/push_notifications.py:92:1: E302 expected 2 blank lines, found 1\napp/core/push_notifications.py:101:1: W293 blank line contains whitespace\napp/core/push_notifications.py:106:1: E302 expected 2 blank lines, found 1\napp/core/push_notifications.py:125:1: E302 expected 2 blank lines, found 1\napp/core/push_notifications.py:127:1: W293 blank line contains whitespace\napp/core/push_notifications.py:134:1: W293 blank line contains whitespace\napp/core/push_notifications.py:142:1: W293 blank line contains whitespace\napp/core/push_notifications.py:145:1: W293 blank line contains whitespace\napp/core/push_notifications.py:153:1: W293 blank line contains whitespace\napp/core/push_notifications.py:276:1: W293 blank line contains whitespace\napp/core/push_notifications.py:293:1: W293 blank line contains whitespace\napp/core/push_notifications.py:304:1: W293 blank line contains whitespace\napp/core/push_notifications.py:307:1: W293 blank line contains whitespace\napp/core/push_notifications.py:310:1: W293 blank line contains whitespace\napp/core/push_notifications.py:314:1: W293 blank line contains whitespace\napp/core/push_notifications.py:323:1: W293 blank line contains whitespace\napp/core/push_notifications.py:327:1: W293 blank line contains whitespace\napp/core/push_notifications.py:338:1: W293 blank line contains whitespace\napp/core/push_notifications.py:341:1: W293 blank line contains whitespace\napp/core/push_notifications.py:344:1: W293 blank line contains whitespace\napp/core/push_notifications.py:352:1: W293 blank line contains whitespace\napp/core/push_notifications.py:360:1: W293 blank line contains whitespace\napp/core/push_notifications.py:366:1: W293 blank line contains whitespace\napp/core/push_notifications.py:370:1: W293 blank line contains whitespace\napp/core/push_notifications.py:374:1: W293 blank line contains whitespace\napp/core/push_notifications.py:380:1: W293 blank line contains whitespace\napp/core/push_notifications.py:383:1: W293 blank line contains whitespace\napp/core/push_notifications.py:390:1: W293 blank line contains whitespace\napp/core/push_notifications.py:397:1: W293 blank line contains whitespace\napp/core/push_notifications.py:415:1: W293 blank line contains whitespace\napp/core/push_notifications.py:419:1: W293 blank line contains whitespace\napp/core/push_notifications.py:427:1: W293 blank line contains whitespace\napp/core/push_notifications.py:437:1: W293 blank line contains whitespace\napp/core/push_notifications.py:444:1: W293 blank line contains whitespace\napp/core/push_notifications.py:453:13: F821 undefined name 'preferences'\napp/core/push_notifications.py:453:35: F821 undefined name 'user_id'\napp/core/push_notifications.py:454:13: F821 undefined name 'preferences'\napp/core/push_notifications.py:455:35: F821 undefined name 'user_id'\napp/core/push_notifications.py:455:46: F821 undefined name 'preferences'\napp/core/push_notifications.py:456:1: W293 blank line contains whitespace\napp/core/push_notifications.py:457:70: F821 undefined name 'user_id'\napp/core/push_notifications.py:459:1: W293 blank line contains whitespace\napp/core/push_notifications.py:463:1: W293 blank line contains whitespace\napp/core/push_notifications.py:469:1: W293 blank line contains whitespace\napp/core/push_notifications.py:480:1: W293 blank line contains whitespace\napp/core/push_notifications.py:481:25: F821 undefined name 'limit'\napp/core/push_notifications.py:482:1: W293 blank line contains whitespace\napp/core/push_notifications.py:495:1: W293 blank line contains whitespace\napp/core/push_notifications.py:505:1: W293 blank line contains whitespace\napp/core/push_notifications.py:508:1: W293 blank line contains whitespace\napp/core/push_notifications.py:512:1: W293 blank line contains whitespace\napp/core/push_notifications.py:529:1: W293 blank line contains whitespace\napp/core/push_notifications.py:538:1: W293 blank line contains whitespace\napp/core/push_notifications.py:544:1: W293 blank line contains whitespace\napp/core/push_notifications.py:550:1: W293 blank line contains whitespace\napp/core/push_notifications.py:560:1: W293 blank line contains whitespace\napp/core/push_notifications.py:564:1: W293 blank line contains whitespace\napp/core/push_notifications.py:570:1: W293 blank line contains whitespace\napp/core/push_notifications.py:579:1: W293 blank line contains whitespace\napp/core/push_notifications.py:583:1: E305 expected 2 blank lines after class or function definition, found 1\napp/core/push_notifications.py:586:1: E302 expected 2 blank lines, found 1\napp/core/push_notifications.py:594:1: E302 expected 2 blank lines, found 1\napp/core/push_notifications.py:597:43: W291 trailing whitespace\napp/core/push_notifications.py:598:53: W291 trailing whitespace\napp/core/push_notifications.py:601:1: W293 blank line contains whitespace\napp/core/push_notifications.py:608:1: E302 expected 2 blank lines, found 1\napp/core/push_notifications.py:616:1: E302 expected 2 blank lines, found 1\napp/core/push_notifications.py:624:1: E302 expected 2 blank lines, found 1\napp/core/push_notifications.py:626:37: W292 no newline at end of file\napp/core/rate_limit_config.py:6:1: F401 'typing.Dict' imported but unused\napp/core/rate_limit_config.py:72:1: E302 expected 2 blank lines, found 1\napp/core/rate_limit_config.py:75:1: W293 blank line contains whitespace\napp/core/rate_limit_config.py:79:1: W293 blank line contains whitespace\napp/core/rate_limit_config.py:91:1: W293 blank line contains whitespace\napp/core/rate_limit_config.py:96:1: E302 expected 2 blank lines, found 1\napp/core/rate_limit_config.py:110:1: E302 expected 2 blank lines, found 1\napp/core/rate_limit_config.py:113:1: W293 blank line contains whitespace\napp/core/rate_limit_config.py:116:1: W293 blank line contains whitespace\napp/core/rate_limit_config.py:122:1: W293 blank line contains whitespace\napp/core/rate_limit_config.py:127:1: W293 blank line contains whitespace\napp/core/rate_limit_config.py:131:1: W293 blank line contains whitespace\napp/core/rate_limit_config.py:135:1: W293 blank line contains whitespace\napp/core/rate_limit_config.py:141:1: E305 expected 2 blank lines after class or function definition, found 1\napp/core/rate_limit_config.py:190:1: E302 expected 2 blank lines, found 1\napp/core/rate_limit_config.py:193:1: W293 blank line contains whitespace\napp/core/rate_limit_config.py:197:1: W293 blank line contains whitespace\napp/core/rate_limit_config.py:202:1: W293 blank line contains whitespace\napp/core/rate_limit_config.py:207:1: W293 blank line contains whitespace\napp/core/rate_limit_config.py:214:25: W292 no newline at end of file\napp/core/rate_limiter.py:8:1: F401 'datetime.datetime' imported but unused\napp/core/rate_limiter.py:8:1: F401 'datetime.timedelta' imported but unused\napp/core/rate_limiter.py:16:1: W293 blank line contains whitespace\napp/core/rate_limiter.py:18:14: W291 trailing whitespace\napp/core/rate_limiter.py:25:1: W293 blank line contains whitespace\napp/core/rate_limiter.py:34:1: W293 blank line contains whitespace\napp/core/rate_limiter.py:37:1: W293 blank line contains whitespace\napp/core/rate_limiter.py:40:1: W293 blank line contains whitespace\napp/core/rate_limiter.py:44:1: W293 blank line contains whitespace\napp/core/rate_limiter.py:49:1: W293 blank line contains whitespace\napp/core/rate_limiter.py:54:1: W293 blank line contains whitespace\napp/core/rate_limiter.py:56:1: W293 blank line contains whitespace\napp/core/rate_limiter.py:61:1: W293 blank line contains whitespace\napp/core/rate_limiter.py:64:1: W293 blank line contains whitespace\napp/core/rate_limiter.py:68:1: W293 blank line contains whitespace\napp/core/rate_limiter.py:72:1: W293 blank line contains whitespace\napp/core/rate_limiter.py:77:1: W293 blank line contains whitespace\napp/core/rate_limiter.py:80:1: W293 blank line contains whitespace\napp/core/rate_limiter.py:82:1: W293 blank line contains whitespace\napp/core/rate_limiter.py:87:1: W293 blank line contains whitespace\napp/core/rate_limiter.py:91:1: W293 blank line contains whitespace\napp/core/rate_limiter.py:96:1: W293 blank line contains whitespace\napp/core/rate_limiter.py:99:1: W293 blank line contains whitespace\napp/core/rate_limiter.py:104:1: W293 blank line contains whitespace\napp/core/rate_limiter.py:106:1: W293 blank line contains whitespace\napp/core/rate_limiter.py:109:1: W293 blank line contains whitespace\napp/core/rate_limiter.py:114:1: W293 blank line contains whitespace\napp/core/rate_limiter.py:120:1: W293 blank line contains whitespace\napp/core/rate_limiter.py:130:1: W293 blank line contains whitespace\napp/core/rate_limiter.py:133:1: W293 blank line contains whitespace\napp/core/rate_limiter.py:138:1: W293 blank line contains whitespace\napp/core/rate_limiter.py:143:1: W293 blank line contains whitespace\napp/core/rate_limiter.py:145:12: F821 undefined name 'ip_address'\napp/core/rate_limiter.py:147:33: F821 undefined name 'ip_address'\napp/core/rate_limiter.py:148:62: F821 undefined name 'ip_address'\napp/core/rate_limiter.py:151:1: W293 blank line contains whitespace\napp/core/rate_limiter.py:152:40: F821 undefined name 'ip_address'\napp/core/rate_limiter.py:153:63: F821 undefined name 'ip_address'\napp/core/rate_limiter.py:154:1: W293 blank line contains whitespace\napp/core/rate_limiter.py:156:12: F821 undefined name 'user_id'\napp/core/rate_limiter.py:157:42: F821 undefined name 'user_id'\napp/core/rate_limiter.py:158:39: F821 undefined name 'user_id'\napp/core/rate_limiter.py:159:1: W293 blank line contains whitespace\napp/core/rate_limiter.py:161:12: F821 undefined name 'ip_address'\napp/core/rate_limiter.py:162:33: F821 undefined name 'ip_address'\napp/core/rate_limiter.py:163:29: F821 undefined name 'ip_address'\napp/core/rate_limiter.py:163:63: F821 undefined name 'user_id'\napp/core/rate_limiter.py:164:1: W293 blank line contains whitespace\napp/core/rate_limiter.py:165:12: F821 undefined name 'user_id'\napp/core/rate_limiter.py:166:35: F821 undefined name 'user_id'\napp/core/rate_limiter.py:167:31: F821 undefined name 'user_id'\napp/core/rate_limiter.py:167:44: F821 undefined name 'connection_id'\napp/core/rate_limiter.py:168:1: W293 blank line contains whitespace\napp/core/rate_limiter.py:170:1: W293 blank line contains whitespace\napp/core/rate_limiter.py:176:51: W292 no newline at end of file\napp/core/redis_client.py:19:1: E302 expected 2 blank lines, found 1\napp/core/redis_client.py:25:32: E261 at least two spaces before inline comment\napp/core/redis_client.py:30:1: W293 blank line contains whitespace\napp/core/redis_client.py:57:1: W293 blank line contains whitespace\napp/core/redis_client.py:64:27: F821 undefined name 'ServiceUnavailableError'\napp/core/redis_client.py:72:5: E303 too many blank lines (2)\napp/core/redis_client.py:92:27: E261 at least two spaces before inline comment\napp/core/redis_client.py:93:55: E261 at least two spaces before inline comment\napp/core/redis_client.py:95:49: E261 at least two spaces before inline comment\napp/core/redis_client.py:104:38: E261 at least two spaces before inline comment\napp/core/redis_client.py:117:27: E261 at least two spaces before inline comment\napp/core/redis_client.py:122:41: E261 at least two spaces before inline comment\napp/core/redis_client.py:124:29: E261 at least two spaces before inline comment\napp/core/redis_client.py:143:27: E261 at least two spaces before inline comment\napp/core/redis_client.py:157:27: E261 at least two spaces before inline comment\napp/core/redis_client.py:167:79: E261 at least two spaces before inline comment\napp/core/redis_client.py:168:26: E261 at least two spaces before inline comment\napp/core/redis_client.py:169:18: E114 indentation is not a multiple of 4 (comment)\napp/core/redis_client.py:169:18: E117 over-indented (comment)\napp/core/redis_client.py:177:27: E261 at least two spaces before inline comment\napp/core/redis_client.py:178:14: E111 indentation is not a multiple of 4\napp/core/redis_client.py:178:14: E117 over-indented\napp/core/redis_client.py:180:54: E261 at least two spaces before inline comment\napp/core/redis_client.py:191:19: F821 undefined name 'ServiceUnavailableError'\napp/core/redis_client.py:240:27: E261 at least two spaces before inline comment\napp/core/redis_client.py:248:30: F541 f-string is missing placeholders\napp/core/redis_client.py:271:27: E261 at least two spaces before inline comment\napp/core/redis_client.py:283:1: W293 blank line contains whitespace\napp/core/redis_client.py:291:1: W293 blank line contains whitespace\napp/core/redis_client.py:296:1: W293 blank line contains whitespace\napp/core/redis_client.py:309:1: W293 blank line contains whitespace\napp/core/redis_client.py:321:1: W293 blank line contains whitespace\napp/core/redis_client.py:326:1: W293 blank line contains whitespace\napp/core/redis_client.py:341:19: F821 undefined name 'ServiceUnavailableError'\napp/core/redis_client.py:342:25: F541 f-string is missing placeholders\napp/core/redis_client.py:347:1: W293 blank line contains whitespace\napp/core/redis_client.py:349:19: F821 undefined name 'ServiceUnavailableError'\napp/core/redis_client.py:365:24: E261 at least two spaces before inline comment\napp/core/redis_client.py:372:1: E302 expected 2 blank lines, found 1\napp/core/redis_client.py:377:1: E302 expected 2 blank lines, found 1\napp/core/redis_client.py:381:1: E302 expected 2 blank lines, found 1\napp/core/redis_client.py:389:1: E302 expected 2 blank lines, found 1\napp/core/redis_client.py:409:10: W292 no newline at end of file\napp/core/response_helper.py:6:1: F401 'typing.Union' imported but unused\napp/core/response_helper.py:19:1: W293 blank line contains whitespace\napp/core/response_helper.py:25:1: W293 blank line contains whitespace\napp/core/response_helper.py:34:1: W293 blank line contains whitespace\napp/core/response_helper.py:37:1: W293 blank line contains whitespace\napp/core/response_helper.py:38:12: F821 undefined name 'meta'\napp/core/response_helper.py:39:32: F821 undefined name 'meta'\napp/core/response_helper.py:40:1: W293 blank line contains whitespace\napp/core/response_helper.py:55:1: W293 blank line contains whitespace\napp/core/response_helper.py:61:1: W293 blank line contains whitespace\napp/core/response_helper.py:70:1: W293 blank line contains whitespace\napp/core/response_helper.py:73:1: W293 blank line contains whitespace\napp/core/response_helper.py:76:1: W293 blank line contains whitespace\napp/core/response_helper.py:83:121: E501 line too long (181 > 120 characters)\napp/core/response_helper.py:86:1: W293 blank line contains whitespace\napp/core/response_helper.py:93:1: W293 blank line contains whitespace\napp/core/response_helper.py:98:1: W293 blank line contains whitespace\napp/core/response_helper.py:115:121: E501 line too long (125 > 120 characters)\napp/core/response_helper.py:118:1: W293 blank line contains whitespace\napp/core/response_helper.py:122:1: W293 blank line contains whitespace\napp/core/response_helper.py:135:10: W292 no newline at end of file\napp/core/responses.py:48:1: W293 blank line contains whitespace\napp/core/responses.py:64:1: W293 blank line contains whitespace\napp/core/responses.py:69:1: W293 blank line contains whitespace\napp/core/responses.py:83:1: W293 blank line contains whitespace\napp/core/responses.py:99:1: W293 blank line contains whitespace\napp/core/responses.py:106:1: W293 blank line contains whitespace\napp/core/responses.py:111:1: W293 blank line contains whitespace\napp/core/responses.py:124:1: W293 blank line contains whitespace\napp/core/responses.py:134:1: W293 blank line contains whitespace\napp/core/responses.py:140:1: W293 blank line contains whitespace\napp/core/responses.py:149:1: W293 blank line contains whitespace\napp/core/responses.py:158:1: W293 blank line contains whitespace\napp/core/responses.py:171:1: W293 blank line contains whitespace\napp/core/responses.py:179:1: W293 blank line contains whitespace\napp/core/responses.py:186:1: W293 blank line contains whitespace\napp/core/responses.py:197:1: W293 blank line contains whitespace\napp/core/responses.py:206:1: W293 blank line contains whitespace\napp/core/responses.py:217:1: W293 blank line contains whitespace\napp/core/responses.py:230:1: W293 blank line contains whitespace\napp/core/responses.py:233:1: W293 blank line contains whitespace\napp/core/responses.py:238:1: W293 blank line contains whitespace\napp/core/responses.py:245:1: W293 blank line contains whitespace\napp/core/responses.py:253:1: W293 blank line contains whitespace\napp/core/responses.py:261:1: W293 blank line contains whitespace\napp/core/responses.py:278:1: W293 blank line contains whitespace\napp/core/responses.py:285:1: W293 blank line contains whitespace\napp/core/responses.py:290:1: W293 blank line contains whitespace\napp/core/responses.py:295:1: W293 blank line contains whitespace\napp/core/responses.py:300:1: W293 blank line contains whitespace\napp/core/responses.py:306:1: W293 blank line contains whitespace\napp/core/responses.py:316:1: W293 blank line contains whitespace\napp/core/responses.py:322:1: W293 blank line contains whitespace\napp/core/responses.py:332:1: W293 blank line contains whitespace\napp/core/responses.py:337:26: W292 no newline at end of file\napp/core/rls_context.py:18:1: W293 blank line contains whitespace\napp/core/rls_context.py:24:1: W293 blank line contains whitespace\napp/core/rls_context.py:36:1: W293 blank line contains whitespace\napp/core/rls_context.py:39:93: W291 trailing whitespace\napp/core/rls_context.py:40:30: E128 continuation line under-indented for visual indent\napp/core/rls_context.py:44:1: W293 blank line contains whitespace\napp/core/rls_context.py:47:80: W291 trailing whitespace\napp/core/rls_context.py:48:27: E128 continuation line under-indented for visual indent\napp/core/rls_context.py:49:1: W293 blank line contains whitespace\napp/core/rls_context.py:61:1: W293 blank line contains whitespace\napp/core/rls_context.py:63:1: W293 blank line contains whitespace\napp/core/rls_context.py:70:1: W293 blank line contains whitespace\napp/core/rls_context.py:76:1: W293 blank line contains whitespace\napp/core/rls_context.py:80:1: W293 blank line contains whitespace\napp/core/rls_context.py:87:1: W293 blank line contains whitespace\napp/core/rls_context.py:92:1: W293 blank line contains whitespace\napp/core/rls_context.py:94:1: W293 blank line contains whitespace\napp/core/rls_context.py:99:1: W293 blank line contains whitespace\napp/core/rls_context.py:103:1: W293 blank line contains whitespace\napp/core/rls_context.py:111:1: W293 blank line contains whitespace\napp/core/rls_context.py:113:89: W291 trailing whitespace\napp/core/rls_context.py:114:26: E128 continuation line under-indented for visual indent\napp/core/rls_context.py:117:1: W293 blank line contains whitespace\napp/core/rls_context.py:120:76: W291 trailing whitespace\napp/core/rls_context.py:121:23: E128 continuation line under-indented for visual indent\napp/core/rls_context.py:122:1: W293 blank line contains whitespace\napp/core/rls_context.py:123:18: W292 no newline at end of file\napp/core/rls_middleware.py:21:1: W293 blank line contains whitespace\napp/core/rls_middleware.py:28:1: W293 blank line contains whitespace\napp/core/rls_middleware.py:33:1: W293 blank line contains whitespace\napp/core/rls_middleware.py:44:1: W293 blank line contains whitespace\napp/core/rls_middleware.py:47:1: W293 blank line contains whitespace\napp/core/rls_middleware.py:53:1: W293 blank line contains whitespace\napp/core/rls_middleware.py:56:1: W293 blank line contains whitespace\napp/core/rls_middleware.py:60:1: W293 blank line contains whitespace\napp/core/rls_middleware.py:66:1: W293 blank line contains whitespace\napp/core/rls_middleware.py:71:1: W293 blank line contains whitespace\napp/core/rls_middleware.py:85:1: W293 blank line contains whitespace\napp/core/rls_middleware.py:86:13: F841 local variable 'e' is assigned to but never used\napp/core/rls_middleware.py:90:1: W293 blank line contains whitespace\napp/core/rls_middleware.py:93:1: W293 blank line contains whitespace\napp/core/rls_middleware.py:95:1: W293 blank line contains whitespace\napp/core/rls_middleware.py:100:1: W293 blank line contains whitespace\napp/core/rls_middleware.py:103:1: W293 blank line contains whitespace\napp/core/rls_middleware.py:109:17: F841 local variable 'e' is assigned to but never used\napp/core/rls_middleware.py:111:1: W293 blank line contains whitespace\napp/core/rls_middleware.py:116:17: F841 local variable 'e' is assigned to but never used\napp/core/rls_middleware.py:124:38: W292 no newline at end of file\napp/core/rls_session_context.py:18:30: W291 trailing whitespace\napp/core/rls_session_context.py:28:1: W293 blank line contains whitespace\napp/core/rls_session_context.py:37:1: W293 blank line contains whitespace\napp/core/rls_session_context.py:76:1: W293 blank line contains whitespace\napp/core/rls_session_context.py:86:1: W293 blank line contains whitespace\napp/core/rls_session_context.py:98:1: W293 blank line contains whitespace\napp/core/rls_session_context.py:107:1: W293 blank line contains whitespace\napp/core/rls_session_context.py:109:89: W291 trailing whitespace\napp/core/rls_session_context.py:110:27: E128 continuation line under-indented for visual indent\napp/core/rls_session_context.py:114:1: W293 blank line contains whitespace\napp/core/rls_session_context.py:115:76: W291 trailing whitespace\napp/core/rls_session_context.py:116:23: E128 continuation line under-indented for visual indent\napp/core/rls_session_context.py:117:1: W293 blank line contains whitespace\napp/core/rls_session_context.py:120:1: W293 blank line contains whitespace\napp/core/rls_session_context.py:124:1: W293 blank line contains whitespace\napp/core/rls_session_context.py:137:1: W293 blank line contains whitespace\napp/core/rls_session_context.py:139:1: W293 blank line contains whitespace\napp/core/rls_session_context.py:142:1: W293 blank line contains whitespace\napp/core/rls_session_context.py:148:1: W293 blank line contains whitespace\napp/core/rls_session_context.py:155:1: W293 blank line contains whitespace\napp/core/rls_session_context.py:164:1: W293 blank line contains whitespace\napp/core/rls_session_context.py:168:1: W293 blank line contains whitespace\napp/core/rls_session_context.py:172:1: W293 blank line contains whitespace\napp/core/rls_session_context.py:179:1: W293 blank line contains whitespace\napp/core/rls_session_context.py:190:1: W293 blank line contains whitespace\napp/core/rls_session_context.py:195:1: W293 blank line contains whitespace\napp/core/rls_session_context.py:198:1: W293 blank line contains whitespace\napp/core/rls_session_context.py:200:1: W293 blank line contains whitespace\napp/core/rls_session_context.py:204:1: W293 blank line contains whitespace\napp/core/rls_session_context.py:211:53: W292 no newline at end of file\napp/core/security.py:486:9: E999 IndentationError: unexpected indent\napp/core/security_monitor.py:11:1: F401 'sqlalchemy.orm.Session' imported but unused\napp/core/security_monitor.py:27:1: W293 blank line contains whitespace\napp/core/security_monitor.py:33:1: W293 blank line contains whitespace\napp/core/security_monitor.py:38:1: W293 blank line contains whitespace\napp/core/security_monitor.py:43:1: W293 blank line contains whitespace\napp/core/security_monitor.py:47:1: W293 blank line contains whitespace\napp/core/security_monitor.py:58:1: W293 blank line contains whitespace\napp/core/security_monitor.py:61:1: W293 blank line contains whitespace\napp/core/security_monitor.py:72:1: W293 blank line contains whitespace\napp/core/security_monitor.py:77:1: W293 blank line contains whitespace\napp/core/security_monitor.py:105:1: W293 blank line contains whitespace\napp/core/security_monitor.py:111:1: W293 blank line contains whitespace\napp/core/security_monitor.py:118:1: W293 blank line contains whitespace\napp/core/security_monitor.py:121:1: W293 blank line contains whitespace\napp/core/security_monitor.py:124:1: W293 blank line contains whitespace\napp/core/security_monitor.py:127:1: W293 blank line contains whitespace\napp/core/security_monitor.py:135:1: W293 blank line contains whitespace\napp/core/security_monitor.py:151:1: W293 blank line contains whitespace\napp/core/security_monitor.py:156:1: W293 blank line contains whitespace\napp/core/security_monitor.py:173:1: W293 blank line contains whitespace\napp/core/security_monitor.py:198:1: W293 blank line contains whitespace\napp/core/security_monitor.py:219:1: W293 blank line contains whitespace\napp/core/security_monitor.py:231:1: W293 blank line contains whitespace\napp/core/security_monitor.py:238:1: W293 blank line contains whitespace\napp/core/security_monitor.py:244:1: W293 blank line contains whitespace\napp/core/security_monitor.py:250:1: W293 blank line contains whitespace\napp/core/security_monitor.py:253:1: W293 blank line contains whitespace\napp/core/security_monitor.py:265:1: W293 blank line contains whitespace\napp/core/security_monitor.py:276:1: W293 blank line contains whitespace\napp/core/security_monitor.py:285:1: W293 blank line contains whitespace\napp/core/security_monitor.py:300:1: W293 blank line contains whitespace\napp/core/security_monitor.py:303:1: W293 blank line contains whitespace\napp/core/security_monitor.py:313:1: W293 blank line contains whitespace\napp/core/security_monitor.py:332:37: W292 no newline at end of file\napp/core/security_utils.py:9:1: W293 blank line contains whitespace\napp/core/security_utils.py:13:7: W605 invalid escape sequence '\\ '\napp/core/security_utils.py:14:1: W293 blank line contains whitespace\napp/core/security_utils.py:17:1: W293 blank line contains whitespace\napp/core/security_utils.py:23:1: W293 blank line contains whitespace\napp/core/security_utils.py:30:1: W293 blank line contains whitespace\napp/core/security_utils.py:37:1: W293 blank line contains whitespace\napp/core/security_utils.py:41:1: W293 blank line contains whitespace\napp/core/security_utils.py:44:1: W293 blank line contains whitespace\napp/core/security_utils.py:56:1: W293 blank line contains whitespace\napp/core/security_utils.py:59:1: W293 blank line contains whitespace\napp/core/security_utils.py:73:1: W293 blank line contains whitespace\napp/core/security_utils.py:77:1: W293 blank line contains whitespace\napp/core/security_utils.py:83:1: W293 blank line contains whitespace\napp/core/security_utils.py:86:1: W293 blank line contains whitespace\napp/core/security_utils.py:89:1: W293 blank line contains whitespace\napp/core/security_utils.py:92:1: W293 blank line contains whitespace\napp/core/security_utils.py:93:16: W292 no newline at end of file\napp/core/supabase.py:23:1: W293 blank line contains whitespace\napp/core/supabase.py:26:1: W293 blank line contains whitespace\napp/core/supabase.py:32:1: W293 blank line contains whitespace\napp/core/supabase.py:40:1: W293 blank line contains whitespace\napp/core/supabase.py:44:1: W293 blank line contains whitespace\napp/core/supabase.py:52:1: W293 blank line contains whitespace\napp/core/supabase.py:55:1: W293 blank line contains whitespace\napp/core/supabase.py:60:1: W293 blank line contains whitespace\napp/core/supabase.py:62:1: W293 blank line contains whitespace\napp/core/supabase.py:64:1: W293 blank line contains whitespace\napp/core/supabase.py:74:1: W293 blank line contains whitespace\napp/core/supabase.py:82:1: W293 blank line contains whitespace\napp/core/supabase.py:94:26: W292 no newline at end of file\napp/core/sync_manager.py:6:1: F401 'typing.Tuple' imported but unused\napp/core/sync_manager.py:9:1: F401 'sqlalchemy.or_' imported but unused\napp/core/sync_manager.py:11:1: F401 'json' imported but unused\napp/core/sync_manager.py:14:1: F401 'app.core.database.get_db' imported but unused\napp/core/sync_manager.py:14:1: F401 'app.core.database.User' imported but unused\napp/core/sync_manager.py:16:1: F401 'app.core.responses.APIResponseHelper' imported but unused\napp/core/sync_manager.py:18:1: E302 expected 2 blank lines, found 1\napp/core/sync_manager.py:24:1: E302 expected 2 blank lines, found 1\napp/core/sync_manager.py:32:1: E302 expected 2 blank lines, found 1\napp/core/sync_manager.py:39:1: E302 expected 2 blank lines, found 1\napp/core/sync_manager.py:85:1: E302 expected 2 blank lines, found 1\napp/core/sync_manager.py:109:1: E302 expected 2 blank lines, found 1\napp/core/sync_manager.py:111:1: W293 blank line contains whitespace\napp/core/sync_manager.py:121:38: F821 undefined name 'sync_actions'\napp/core/sync_manager.py:129:1: W293 blank line contains whitespace\napp/core/sync_manager.py:132:32: F821 undefined name 'sync_actions'\napp/core/sync_manager.py:135:38: F821 undefined name 'restaurant_id'\napp/core/sync_manager.py:135:53: F821 undefined name 'user_id'\napp/core/sync_manager.py:135:62: F821 undefined name 'device_id'\napp/core/sync_manager.py:144:1: W293 blank line contains whitespace\napp/core/sync_manager.py:150:1: W293 blank line contains whitespace\napp/core/sync_manager.py:158:1: W293 blank line contains whitespace\napp/core/sync_manager.py:165:1: W293 blank line contains whitespace\napp/core/sync_manager.py:169:1: W293 blank line contains whitespace\napp/core/sync_manager.py:171:1: W293 blank line contains whitespace\napp/core/sync_manager.py:183:20: F821 undefined name 'last_sync_timestamp'\napp/core/sync_manager.py:185:1: W293 blank line contains whitespace\napp/core/sync_manager.py:192:1: W293 blank line contains whitespace\napp/core/sync_manager.py:200:1: W293 blank line contains whitespace\napp/core/sync_manager.py:202:31: F821 undefined name 'entity_types'\napp/core/sync_manager.py:203:1: W293 blank line contains whitespace\napp/core/sync_manager.py:207:25: F821 undefined name 'restaurant_id'\napp/core/sync_manager.py:211:1: W293 blank line contains whitespace\napp/core/sync_manager.py:213:1: W293 blank line contains whitespace\napp/core/sync_manager.py:225:79: F821 undefined name 'conflict_id'\napp/core/sync_manager.py:232:1: W293 blank line contains whitespace\napp/core/sync_manager.py:234:1: W293 blank line contains whitespace\napp/core/sync_manager.py:235:16: F821 undefined name 'resolution_strategy'\napp/core/sync_manager.py:239:1: W293 blank line contains whitespace\napp/core/sync_manager.py:240:18: F821 undefined name 'resolution_strategy'\napp/core/sync_manager.py:244:1: W293 blank line contains whitespace\napp/core/sync_manager.py:245:18: F821 undefined name 'resolution_strategy'\napp/core/sync_manager.py:247:24: F821 undefined name 'merged_data'\napp/core/sync_manager.py:253:67: F821 undefined name 'merged_data'\napp/core/sync_manager.py:255:1: W293 blank line contains whitespace\napp/core/sync_manager.py:260:1: W293 blank line contains whitespace\napp/core/sync_manager.py:263:84: F821 undefined name 'conflict_id'\napp/core/sync_manager.py:265:1: W293 blank line contains whitespace\napp/core/sync_manager.py:267:32: F821 undefined name 'conflict_id'\napp/core/sync_manager.py:268:40: F821 undefined name 'resolution_strategy'\napp/core/sync_manager.py:272:1: W293 blank line contains whitespace\napp/core/sync_manager.py:286:1: W293 blank line contains whitespace\napp/core/sync_manager.py:287:83: F821 undefined name 'restaurant_id'\napp/core/sync_manager.py:288:96: F821 undefined name 'restaurant_id'\napp/core/sync_manager.py:289:1: W293 blank line contains whitespace\napp/core/sync_manager.py:291:34: F821 undefined name 'restaurant_id'\napp/core/sync_manager.py:292:30: F821 undefined name 'device_id'\napp/core/sync_manager.py:298:1: W293 blank line contains whitespace\napp/core/sync_manager.py:305:1: W293 blank line contains whitespace\napp/core/sync_manager.py:315:1: W293 blank line contains whitespace\napp/core/sync_manager.py:319:1: W293 blank line contains whitespace\napp/core/sync_manager.py:324:1: W293 blank line contains whitespace\napp/core/sync_manager.py:337:1: W293 blank line contains whitespace\napp/core/sync_manager.py:347:1: W293 blank line contains whitespace\napp/core/sync_manager.py:353:1: W293 blank line contains whitespace\napp/core/sync_manager.py:357:1: W293 blank line contains whitespace\napp/core/sync_manager.py:366:1: W293 blank line contains whitespace\napp/core/sync_manager.py:370:1: W293 blank line contains whitespace\napp/core/sync_manager.py:376:1: W293 blank line contains whitespace\napp/core/sync_manager.py:382:1: W293 blank line contains whitespace\napp/core/sync_manager.py:405:1: W293 blank line contains whitespace\napp/core/sync_manager.py:410:1: W293 blank line contains whitespace\napp/core/sync_manager.py:415:1: W293 blank line contains whitespace\napp/core/sync_manager.py:422:1: W293 blank line contains whitespace\napp/core/sync_manager.py:430:1: W293 blank line contains whitespace\napp/core/sync_manager.py:439:1: W293 blank line contains whitespace\napp/core/sync_manager.py:448:1: W293 blank line contains whitespace\napp/core/sync_manager.py:450:1: W293 blank line contains whitespace\napp/core/sync_manager.py:451:9: F841 local variable 'e' is assigned to but never used\napp/core/sync_manager.py:454:1: W293 blank line contains whitespace\napp/core/sync_manager.py:460:1: W293 blank line contains whitespace\napp/core/sync_manager.py:471:1: W293 blank line contains whitespace\napp/core/sync_manager.py:491:1: W293 blank line contains whitespace\napp/core/sync_manager.py:493:1: W293 blank line contains whitespace\napp/core/sync_manager.py:503:1: W293 blank line contains whitespace\napp/core/sync_manager.py:505:1: W293 blank line contains whitespace\napp/core/sync_manager.py:510:1: W293 blank line contains whitespace\napp/core/sync_manager.py:515:1: W293 blank line contains whitespace\napp/core/sync_manager.py:519:1: W293 blank line contains whitespace\napp/core/sync_manager.py:525:1: W293 blank line contains whitespace\napp/core/sync_manager.py:534:1: W293 blank line contains whitespace\napp/core/sync_manager.py:545:1: W293 blank line contains whitespace\napp/core/sync_manager.py:554:1: W293 blank line contains whitespace\napp/core/sync_manager.py:566:1: W293 blank line contains whitespace\napp/core/sync_manager.py:575:1: W293 blank line contains whitespace\napp/core/sync_manager.py:587:1: W293 blank line contains whitespace\napp/core/sync_manager.py:596:1: W293 blank line contains whitespace\napp/core/sync_manager.py:610:1: E302 expected 2 blank lines, found 1\napp/core/sync_manager.py:612:34: W292 no newline at end of file\napp/core/tenant_security.py:9:1: F401 'typing.Union' imported but unused\napp/core/tenant_security.py:10:1: F401 'fastapi.status' imported but unused\napp/core/tenant_security.py:12:1: F401 'sqlalchemy.select' imported but unused\napp/core/tenant_security.py:13:1: F401 'app.models.Restaurant' imported but unused\napp/core/tenant_security.py:17:1: F401 'app.core.exceptions.FynloException' imported but unused\napp/core/tenant_security.py:22:1: W293 blank line contains whitespace\napp/core/tenant_security.py:31:1: W293 blank line contains whitespace\napp/core/tenant_security.py:35:1: W293 blank line contains whitespace\napp/core/tenant_security.py:38:1: W293 blank line contains whitespace\napp/core/tenant_security.py:51:1: W293 blank line contains whitespace\napp/core/tenant_security.py:57:1: W293 blank line contains whitespace\napp/core/tenant_security.py:70:1: W293 blank line contains whitespace\napp/core/tenant_security.py:82:1: W293 blank line contains whitespace\napp/core/tenant_security.py:85:1: W293 blank line contains whitespace\napp/core/tenant_security.py:89:1: W293 blank line contains whitespace\napp/core/tenant_security.py:97:1: W293 blank line contains whitespace\napp/core/tenant_security.py:118:1: W293 blank line contains whitespace\napp/core/tenant_security.py:124:1: W293 blank line contains whitespace\napp/core/tenant_security.py:134:121: E501 line too long (134 > 120 characters)\napp/core/tenant_security.py:135:1: W293 blank line contains whitespace\napp/core/tenant_security.py:136:1: W293 blank line contains whitespace\napp/core/tenant_security.py:137:5: E303 too many blank lines (2)\napp/core/tenant_security.py:148:1: W293 blank line contains whitespace\napp/core/tenant_security.py:155:1: W293 blank line contains whitespace\napp/core/tenant_security.py:162:1: W293 blank line contains whitespace\napp/core/tenant_security.py:165:1: W293 blank line contains whitespace\napp/core/tenant_security.py:169:1: W293 blank line contains whitespace\napp/core/tenant_security.py:172:1: W293 blank line contains whitespace\napp/core/tenant_security.py:176:1: W293 blank line contains whitespace\napp/core/tenant_security.py:179:1: W293 blank line contains whitespace\napp/core/tenant_security.py:184:1: W293 blank line contains whitespace\napp/core/tenant_security.py:191:1: W293 blank line contains whitespace\napp/core/tenant_security.py:194:1: W293 blank line contains whitespace\napp/core/tenant_security.py:201:1: W293 blank line contains whitespace\napp/core/tenant_security.py:204:1: W293 blank line contains whitespace\napp/core/tenant_security.py:210:1: W293 blank line contains whitespace\napp/core/tenant_security.py:212:1: W293 blank line contains whitespace\napp/core/tenant_security.py:223:1: W293 blank line contains whitespace\napp/core/tenant_security.py:229:1: W293 blank line contains whitespace\napp/core/tenant_security.py:235:121: E501 line too long (129 > 120 characters)\napp/core/tenant_security.py:236:1: W293 blank line contains whitespace\napp/core/tenant_security.py:237:1: W293 blank line contains whitespace\napp/core/tenant_security.py:238:5: E303 too many blank lines (2)\napp/core/tenant_security.py:242:1: W293 blank line contains whitespace\napp/core/tenant_security.py:246:1: W293 blank line contains whitespace\napp/core/tenant_security.py:253:1: W293 blank line contains whitespace\napp/core/tenant_security.py:261:1: W293 blank line contains whitespace\napp/core/tenant_security.py:264:1: W293 blank line contains whitespace\napp/core/tenant_security.py:265:20: W292 no newline at end of file\napp/core/tenant_security_current.py:237:10: E999 SyntaxError: unterminated triple-quoted string literal (detected at line 255)\napp/core/transaction_manager.py:17:1: E302 expected 2 blank lines, found 1\napp/core/transaction_manager.py:21:1: E302 expected 2 blank lines, found 1\napp/core/transaction_manager.py:25:1: E302 expected 2 blank lines, found 1\napp/core/transaction_manager.py:35:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:41:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:46:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:56:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:66:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:69:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:72:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:79:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:86:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:94:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:101:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:105:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:110:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:113:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:119:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:124:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:127:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:129:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:133:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:138:121: E501 line too long (126 > 120 characters)\napp/core/transaction_manager.py:142:34: F541 f-string is missing placeholders\napp/core/transaction_manager.py:144:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:149:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:157:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:159:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:163:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:174:22: F821 undefined name 'func'\napp/core/transaction_manager.py:184:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:186:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:189:30: F821 undefined name 'func'\napp/core/transaction_manager.py:190:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:192:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:194:12: F821 undefined name 'decorator'\napp/core/transaction_manager.py:200:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:204:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:226:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:228:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:237:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:243:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:247:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:252:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:262:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:267:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:272:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:274:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:281:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:283:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:296:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:303:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:310:1: W293 blank line contains whitespace\napp/core/transaction_manager.py:316:54: W292 no newline at end of file\napp/core/two_factor_auth.py:10:1: F401 'datetime.timedelta' imported but unused\napp/core/two_factor_auth.py:16:1: F401 'app.core.exceptions.ResourceNotFoundException' imported but unused\napp/core/two_factor_auth.py:16:1: F401 'app.core.exceptions.ConflictException' imported but unused\napp/core/two_factor_auth.py:16:121: E501 line too long (138 > 120 characters)\napp/core/two_factor_auth.py:29:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:32:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:36:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:40:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:49:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:54:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:57:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:62:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:64:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:73:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:77:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:87:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:92:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:102:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:109:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:111:14: W291 trailing whitespace\napp/core/two_factor_auth.py:112:20: W291 trailing whitespace\napp/core/two_factor_auth.py:121:51: W291 trailing whitespace\napp/core/two_factor_auth.py:124:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:131:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:136:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:146:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:149:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:151:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:156:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:158:14: W291 trailing whitespace\napp/core/two_factor_auth.py:159:20: W291 trailing whitespace\napp/core/two_factor_auth.py:164:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:172:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:176:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:179:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:181:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:185:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:189:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:195:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:197:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:199:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:202:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:207:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:210:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:212:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:223:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:227:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:229:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:231:14: W291 trailing whitespace\napp/core/two_factor_auth.py:232:20: W291 trailing whitespace\napp/core/two_factor_auth.py:244:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:247:51: W291 trailing whitespace\napp/core/two_factor_auth.py:250:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:253:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:257:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:261:1: W293 blank line contains whitespace\napp/core/two_factor_auth.py:266:34: W292 no newline at end of file\napp/core/validation.py:8:1: F401 'decimal.Decimal' imported but unused\napp/core/validation.py:14:1: E302 expected 2 blank lines, found 1\napp/core/validation.py:21:1: E302 expected 2 blank lines, found 1\napp/core/validation.py:25:1: W293 blank line contains whitespace\napp/core/validation.py:36:1: E302 expected 2 blank lines, found 1\napp/core/validation.py:38:1: W293 blank line contains whitespace\napp/core/validation.py:43:1: W293 blank line contains whitespace\napp/core/validation.py:51:1: W293 blank line contains whitespace\napp/core/validation.py:54:1: W293 blank line contains whitespace\napp/core/validation.py:57:1: W293 blank line contains whitespace\napp/core/validation.py:68:1: W293 blank line contains whitespace\napp/core/validation.py:70:1: W293 blank line contains whitespace\napp/core/validation.py:80:1: W293 blank line contains whitespace\napp/core/validation.py:91:1: W293 blank line contains whitespace\napp/core/validation.py:102:1: W293 blank line contains whitespace\napp/core/validation.py:113:1: W293 blank line contains whitespace\napp/core/validation.py:123:1: W293 blank line contains whitespace\napp/core/validation.py:125:1: W293 blank line contains whitespace\napp/core/validation.py:130:1: W293 blank line contains whitespace\napp/core/validation.py:140:1: W293 blank line contains whitespace\napp/core/validation.py:142:1: W293 blank line contains whitespace\napp/core/validation.py:151:1: W293 blank line contains whitespace\napp/core/validation.py:159:1: W293 blank line contains whitespace\napp/core/validation.py:164:121: E501 line too long (178 > 120 characters)\napp/core/validation.py:168:1: W293 blank line contains whitespace\napp/core/validation.py:170:1: W293 blank line contains whitespace\napp/core/validation.py:175:1: W293 blank line contains whitespace\napp/core/validation.py:184:1: W293 blank line contains whitespace\napp/core/validation.py:194:1: W293 blank line contains whitespace\napp/core/validation.py:204:1: W293 blank line contains whitespace\napp/core/validation.py:206:1: W293 blank line contains whitespace\napp/core/validation.py:211:1: W293 blank line contains whitespace\napp/core/validation.py:215:1: W293 blank line contains whitespace\napp/core/validation.py:218:1: W293 blank line contains whitespace\napp/core/validation.py:227:1: W293 blank line contains whitespace\napp/core/validation.py:232:1: W293 blank line contains whitespace\napp/core/validation.py:236:121: E501 line too long (129 > 120 characters)\napp/core/validation.py:244:1: W293 blank line contains whitespace\napp/core/validation.py:246:1: W293 blank line contains whitespace\napp/core/validation.py:251:1: W293 blank line contains whitespace\napp/core/validation.py:259:1: W293 blank line contains whitespace\napp/core/validation.py:266:1: W293 blank line contains whitespace\napp/core/validation.py:278:1: W293 blank line contains whitespace\napp/core/validation.py:292:1: W293 blank line contains whitespace\napp/core/validation.py:300:1: W293 blank line contains whitespace\napp/core/validation.py:302:1: W293 blank line contains whitespace\napp/core/validation.py:307:1: W293 blank line contains whitespace\napp/core/validation.py:311:1: W293 blank line contains whitespace\napp/core/validation.py:315:75: E226 missing whitespace around arithmetic operator\napp/core/validation.py:319:1: W293 blank line contains whitespace\napp/core/validation.py:323:1: W293 blank line contains whitespace\napp/core/validation.py:331:1: W293 blank line contains whitespace\napp/core/validation.py:334:1: E302 expected 2 blank lines, found 1\napp/core/validation.py:341:1: W293 blank line contains whitespace\napp/core/validation.py:347:1: W293 blank line contains whitespace\napp/core/validation.py:356:1: E302 expected 2 blank lines, found 1\napp/core/validation.py:362:1: E302 expected 2 blank lines, found 1\napp/core/validation.py:368:1: E302 expected 2 blank lines, found 1\napp/core/validation.py:374:1: E302 expected 2 blank lines, found 1\napp/core/validation.py:380:1: E305 expected 2 blank lines after class or function definition, found 1\napp/core/validation.py:385:1: F811 redefinition of unused 're' from line 9\napp/core/validation.py:385:1: E402 module level import not at top of file\napp/core/validation.py:386:1: F811 redefinition of unused 'Dict' from line 6\napp/core/validation.py:386:1: F811 redefinition of unused 'Optional' from line 6\napp/core/validation.py:386:1: F811 redefinition of unused 'Union' from line 6\napp/core/validation.py:386:1: E402 module level import not at top of file\napp/core/validation.py:387:1: E402 module level import not at top of file\napp/core/validation.py:388:1: F401 'jsonschema.validate' imported but unused\napp/core/validation.py:388:1: F401 'jsonschema.ValidationError as JSONSchemaError' imported but unused\napp/core/validation.py:388:1: E402 module level import not at top of file\napp/core/validation.py:398:1: W293 blank line contains whitespace\napp/core/validation.py:416:1: W293 blank line contains whitespace\napp/core/validation.py:426:1: W293 blank line contains whitespace\napp/core/validation.py:431:1: W293 blank line contains whitespace\napp/core/validation.py:441:1: W293 blank line contains whitespace\napp/core/validation.py:455:1: W293 blank line contains whitespace\napp/core/validation.py:481:1: W293 blank line contains whitespace\napp/core/validation.py:489:1: W293 blank line contains whitespace\napp/core/validation.py:515:1: W293 blank line contains whitespace\napp/core/validation.py:520:64: W291 trailing whitespace\napp/core/validation.py:536:1: W293 blank line contains whitespace\napp/core/validation.py:544:1: W293 blank line contains whitespace\napp/core/validation.py:564:1: W293 blank line contains whitespace\napp/core/validation.py:571:1: W293 blank line contains whitespace\napp/core/validation.py:587:1: W293 blank line contains whitespace\napp/core/validation.py:600:1: W293 blank line contains whitespace\napp/core/validation.py:604:1: W293 blank line contains whitespace\napp/core/validation.py:607:1: W293 blank line contains whitespace\napp/core/validation.py:650:1: W293 blank line contains whitespace\napp/core/validation.py:652:76: W291 trailing whitespace\napp/core/validation.py:655:1: W293 blank line contains whitespace\napp/core/validation.py:657:78: W291 trailing whitespace\napp/core/validation.py:662:1: W293 blank line contains whitespace\napp/core/validation.py:665:1: W293 blank line contains whitespace\napp/core/validation.py:688:1: W293 blank line contains whitespace\napp/core/validation.py:693:1: W293 blank line contains whitespace\napp/core/validation.py:698:1: W293 blank line contains whitespace\napp/core/validation.py:701:1: W293 blank line contains whitespace\napp/core/validation.py:708:1: W293 blank line contains whitespace\napp/core/validation.py:710:16: W292 no newline at end of file\napp/core/validators.py:25:1: W293 blank line contains whitespace\napp/core/validators.py:30:1: W293 blank line contains whitespace\napp/core/validators.py:38:1: W293 blank line contains whitespace\napp/core/validators.py:42:1: W293 blank line contains whitespace\napp/core/validators.py:45:1: W293 blank line contains whitespace\napp/core/validators.py:61:1: W293 blank line contains whitespace\napp/core/validators.py:64:1: W293 blank line contains whitespace\napp/core/validators.py:72:1: W293 blank line contains whitespace\napp/core/validators.py:77:1: W293 blank line contains whitespace\napp/core/validators.py:80:1: W293 blank line contains whitespace\napp/core/validators.py:83:1: W293 blank line contains whitespace\napp/core/validators.py:91:1: W293 blank line contains whitespace\napp/core/validators.py:94:1: W293 blank line contains whitespace\napp/core/validators.py:98:1: W293 blank line contains whitespace\napp/core/validators.py:102:1: W293 blank line contains whitespace\napp/core/validators.py:110:1: W293 blank line contains whitespace\napp/core/validators.py:114:1: W293 blank line contains whitespace\napp/core/validators.py:119:1: W293 blank line contains whitespace\napp/core/validators.py:122:1: W293 blank line contains whitespace\napp/core/validators.py:130:1: W293 blank line contains whitespace\napp/core/validators.py:135:1: W293 blank line contains whitespace\napp/core/validators.py:138:1: W293 blank line contains whitespace\napp/core/validators.py:202:1: W293 blank line contains whitespace\napp/core/validators.py:207:17: W292 no newline at end of file\napp/core/websocket.py:14:1: F401 'app.core.responses.APIResponseHelper' imported but unused\napp/core/websocket.py:16:1: E302 expected 2 blank lines, found 1\napp/core/websocket.py:31:1: E302 expected 2 blank lines, found 1\napp/core/websocket.py:39:1: E302 expected 2 blank lines, found 1\napp/core/websocket.py:65:1: E302 expected 2 blank lines, found 1\napp/core/websocket.py:86:1: E302 expected 2 blank lines, found 1\napp/core/websocket.py:88:1: W293 blank line contains whitespace\napp/core/websocket.py:92:1: W293 blank line contains whitespace\napp/core/websocket.py:95:1: W293 blank line contains whitespace\napp/core/websocket.py:98:1: W293 blank line contains whitespace\napp/core/websocket.py:101:1: W293 blank line contains whitespace\napp/core/websocket.py:104:1: W293 blank line contains whitespace\napp/core/websocket.py:112:1: W293 blank line contains whitespace\napp/core/websocket.py:124:1: W293 blank line contains whitespace\napp/core/websocket.py:134:1: W293 blank line contains whitespace\napp/core/websocket.py:137:1: W293 blank line contains whitespace\napp/core/websocket.py:142:1: W293 blank line contains whitespace\napp/core/websocket.py:148:1: W293 blank line contains whitespace\napp/core/websocket.py:154:1: W293 blank line contains whitespace\napp/core/websocket.py:158:1: W293 blank line contains whitespace\napp/core/websocket.py:173:1: W293 blank line contains whitespace\napp/core/websocket.py:176:1: W293 blank line contains whitespace\napp/core/websocket.py:178:1: W293 blank line contains whitespace\napp/core/websocket.py:185:1: W293 blank line contains whitespace\napp/core/websocket.py:191:1: W293 blank line contains whitespace\napp/core/websocket.py:193:1: W293 blank line contains whitespace\napp/core/websocket.py:200:1: W293 blank line contains whitespace\napp/core/websocket.py:207:1: W293 blank line contains whitespace\napp/core/websocket.py:215:1: W293 blank line contains whitespace\napp/core/websocket.py:218:1: W293 blank line contains whitespace\napp/core/websocket.py:221:1: W293 blank line contains whitespace\napp/core/websocket.py:224:13: F821 undefined name 'logger'\napp/core/websocket.py:225:1: W293 blank line contains whitespace\napp/core/websocket.py:231:1: W293 blank line contains whitespace\napp/core/websocket.py:233:1: W293 blank line contains whitespace\napp/core/websocket.py:236:1: W293 blank line contains whitespace\napp/core/websocket.py:239:1: W293 blank line contains whitespace\napp/core/websocket.py:242:1: W293 blank line contains whitespace\napp/core/websocket.py:248:13: F821 undefined name 'logger'\napp/core/websocket.py:250:1: W293 blank line contains whitespace\napp/core/websocket.py:255:1: W293 blank line contains whitespace\napp/core/websocket.py:257:1: W293 blank line contains whitespace\napp/core/websocket.py:260:1: W293 blank line contains whitespace\napp/core/websocket.py:267:1: W293 blank line contains whitespace\napp/core/websocket.py:269:1: W293 blank line contains whitespace\napp/core/websocket.py:272:1: W293 blank line contains whitespace\napp/core/websocket.py:276:1: W293 blank line contains whitespace\napp/core/websocket.py:279:1: W293 blank line contains whitespace\napp/core/websocket.py:281:1: W293 blank line contains whitespace\napp/core/websocket.py:286:1: W293 blank line contains whitespace\napp/core/websocket.py:297:1: W293 blank line contains whitespace\napp/core/websocket.py:299:1: W293 blank line contains whitespace\napp/core/websocket.py:304:1: W293 blank line contains whitespace\napp/core/websocket.py:308:1: W293 blank line contains whitespace\napp/core/websocket.py:312:1: W293 blank line contains whitespace\napp/core/websocket.py:314:1: W293 blank line contains whitespace\napp/core/websocket.py:319:1: W293 blank line contains whitespace\napp/core/websocket.py:321:1: W293 blank line contains whitespace\napp/core/websocket.py:325:1: W293 blank line contains whitespace\napp/core/websocket.py:330:1: W293 blank line contains whitespace\napp/core/websocket.py:333:1: W293 blank line contains whitespace\napp/core/websocket.py:338:1: W293 blank line contains whitespace\napp/core/websocket.py:343:1: W293 blank line contains whitespace\napp/core/websocket.py:353:1: W293 blank line contains whitespace\napp/core/websocket.py:358:1: W293 blank line contains whitespace\napp/core/websocket.py:362:1: W293 blank line contains whitespace\napp/core/websocket.py:379:1: E305 expected 2 blank lines after class or function definition, found 1\napp/core/websocket.py:382:1: E302 expected 2 blank lines, found 1\napp/core/websocket.py:398:1: W293 blank line contains whitespace\napp/core/websocket.py:405:1: E302 expected 2 blank lines, found 1\napp/core/websocket.py:405:121: E501 line too long (135 > 120 characters)\napp/core/websocket.py:421:1: W293 blank line contains whitespace\napp/core/websocket.py:424:1: E302 expected 2 blank lines, found 1\napp/core/websocket.py:440:1: W293 blank line contains whitespace\napp/core/websocket.py:447:1: E302 expected 2 blank lines, found 1\napp/core/websocket.py:447:121: E501 line too long (123 > 120 characters)\napp/core/websocket.py:462:1: W293 blank line contains whitespace\napp/core/websocket.py:469:1: E302 expected 2 blank lines, found 1\napp/core/websocket.py:486:1: W293 blank line contains whitespace\napp/core/websocket.py:493:1: E302 expected 2 blank lines, found 1\napp/core/websocket.py:496:1: W293 blank line contains whitespace\napp/core/websocket.py:510:1: W293 blank line contains whitespace\napp/core/websocket.py:521:1: W293 blank line contains whitespace\napp/core/websocket.py:545:1: W293 blank line contains whitespace\napp/core/websocket.py:551:1: W293 blank line contains whitespace\napp/core/websocket.py:569:1: W293 blank line contains whitespace\napp/core/websocket.py:579:20: W291 trailing whitespace\napp/core/websocket.py:580:1: E302 expected 2 blank lines, found 1\napp/core/websocket.py:582:29: W292 no newline at end of file\napp/core/websocket_rate_limiter.py:8:1: F401 'datetime.datetime' imported but unused\napp/core/websocket_rate_limiter.py:8:1: F401 'datetime.timedelta' imported but unused\napp/core/websocket_rate_limiter.py:22:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:25:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:31:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:35:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:40:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:50:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:52:14: W291 trailing whitespace\napp/core/websocket_rate_limiter.py:53:25: W291 trailing whitespace\napp/core/websocket_rate_limiter.py:58:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:69:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:76:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:80:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:93:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:96:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:101:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:105:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:107:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:113:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:115:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:117:14: W291 trailing whitespace\napp/core/websocket_rate_limiter.py:123:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:130:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:137:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:140:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:153:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:156:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:161:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:164:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:166:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:168:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:173:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:179:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:186:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:190:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:192:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:198:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:202:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:209:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:216:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:223:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:230:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:234:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:240:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:243:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:248:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:251:1: W293 blank line contains whitespace\napp/core/websocket_rate_limiter.py:260:48: W292 no newline at end of file\napp/crud/inventory.py:9:1: F401 'datetime.datetime' imported but unused\napp/crud/inventory.py:16:1: E302 expected 2 blank lines, found 1\napp/crud/inventory.py:38:15: F821 undefined name 'get_inventory_item'\napp/crud/inventory.py:38:38: F821 undefined name 'sku'\napp/crud/inventory.py:40:23: F821 undefined name 'item_update'\napp/crud/inventory.py:47:15: F821 undefined name 'get_inventory_item'\napp/crud/inventory.py:47:38: F821 undefined name 'sku'\napp/crud/inventory.py:55:1: E302 expected 2 blank lines, found 1\napp/crud/inventory.py:55:121: E501 line too long (210 > 120 characters)\napp/crud/inventory.py:61:15: F821 undefined name 'get_inventory_item'\napp/crud/inventory.py:65:5: F841 local variable 'original_qty' is assigned to but never used\napp/crud/inventory.py:69:45: E261 at least two spaces before inline comment\napp/crud/inventory.py:81:37: E261 at least two spaces before inline comment\napp/crud/inventory.py:95:1: E302 expected 2 blank lines, found 1\napp/crud/inventory.py:103:34: F821 undefined name 'ingredient_sku'\napp/crud/inventory.py:107:1: E302 expected 2 blank lines, found 1\napp/crud/inventory.py:107:121: E501 line too long (143 > 120 characters)\napp/crud/inventory.py:121:20: F821 undefined name 'get_inventory_item'\napp/crud/inventory.py:136:27: E261 at least two spaces before inline comment\napp/crud/inventory.py:141:121: E501 line too long (161 > 120 characters)\napp/crud/inventory.py:187:26: E261 at least two spaces before inline comment\napp/crud/inventory.py:194:121: E501 line too long (131 > 120 characters)\napp/crud/inventory.py:218:1: E302 expected 2 blank lines, found 1\napp/crud/inventory.py:218:121: E501 line too long (133 > 120 characters)\napp/crud/inventory.py:220:21: F821 undefined name 'get_recipe_ingredient'\napp/crud/inventory.py:224:29: E261 at least two spaces before inline comment\napp/crud/inventory.py:228:39: F821 undefined name 'entry'\napp/crud/inventory.py:234:37: F821 undefined name 'sku'\napp/crud/inventory.py:237:8: F821 undefined name 'start_date'\napp/crud/inventory.py:238:57: F821 undefined name 'start_date'\napp/crud/inventory.py:239:8: F821 undefined name 'end_date'\napp/crud/inventory.py:240:57: F821 undefined name 'end_date'\napp/crud/inventory.py:241:66: F821 undefined name 'skip'\napp/crud/inventory.py:241:78: F821 undefined name 'limit'\napp/crud/inventory.py:245:8: F821 undefined name 'start_date'\napp/crud/inventory.py:246:57: F821 undefined name 'start_date'\napp/crud/inventory.py:247:8: F821 undefined name 'end_date'\napp/crud/inventory.py:248:57: F821 undefined name 'end_date'\napp/crud/inventory.py:249:66: F821 undefined name 'skip'\napp/crud/inventory.py:249:78: F821 undefined name 'limit'\napp/crud/inventory.py:268:121: E501 line too long (145 > 120 characters)\napp/crud/inventory.py:296:1: E302 expected 2 blank lines, found 1\napp/crud/inventory.py:296:121: E501 line too long (123 > 120 characters)\napp/crud/inventory.py:306:49: W504 line break after binary operator\napp/crud/inventory.py:307:41: W504 line break after binary operator\napp/crud/inventory.py:335:1: E302 expected 2 blank lines, found 1\napp/crud/inventory.py:356:6: E121 continuation line under-indented for hanging indent\napp/crud/inventory.py:371:1: E302 expected 2 blank lines, found 1\napp/crud/inventory.py:386:85: E261 at least two spaces before inline comment\napp/crud/inventory.py:387:24: E261 at least two spaces before inline comment\napp/crud/inventory.py:388:14: E111 indentation is not a multiple of 4\napp/crud/inventory.py:388:14: E117 over-indented\napp/crud/payments.py:12:1: E302 expected 2 blank lines, found 1\napp/crud/payments.py:20:1: W293 blank line contains whitespace\napp/crud/payments.py:23:1: W293 blank line contains whitespace\napp/crud/payments.py:36:1: W293 blank line contains whitespace\napp/crud/payments.py:41:1: E302 expected 2 blank lines, found 1\napp/crud/payments.py:50:1: W293 blank line contains whitespace\napp/crud/payments.py:65:1: W293 blank line contains whitespace\napp/crud/payments.py:69:1: W293 blank line contains whitespace\napp/crud/payments.py:79:53: W291 trailing whitespace\napp/crud/payments.py:83:1: W293 blank line contains whitespace\napp/crud/payments.py:87:1: W293 blank line contains whitespace\napp/crud/payments.py:90:1: W293 blank line contains whitespace\napp/crud/payments.py:99:1: E302 expected 2 blank lines, found 1\napp/crud/payments.py:102:1: W293 blank line contains whitespace\napp/crud/payments.py:105:1: W293 blank line contains whitespace\napp/crud/payments.py:113:1: W293 blank line contains whitespace\napp/crud/payments.py:115:1: W293 blank line contains whitespace\napp/crud/payments.py:118:1: E302 expected 2 blank lines, found 1\napp/crud/payments.py:124:1: W293 blank line contains whitespace\napp/crud/payments.py:126:1: W293 blank line contains whitespace\napp/crud/payments.py:134:1: W293 blank line contains whitespace\napp/crud/payments.py:142:1: W293 blank line contains whitespace\napp/crud/payments.py:145:1: E302 expected 2 blank lines, found 1\napp/crud/payments.py:153:1: W293 blank line contains whitespace\napp/crud/payments.py:168:1: W293 blank line contains whitespace\napp/crud/payments.py:184:1: W293 blank line contains whitespace\napp/crud/payments.py:195:1: W293 blank line contains whitespace\napp/crud/payments.py:203:1: W293 blank line contains whitespace\napp/crud/payments.py:207:1: W293 blank line contains whitespace\napp/crud/payments.py:210:26: W291 trailing whitespace\napp/crud/payments.py:214:24: W291 trailing whitespace\napp/crud/payments.py:217:1: W293 blank line contains whitespace\napp/crud/payments.py:224:1: W293 blank line contains whitespace\napp/crud/payments.py:228:11: W291 trailing whitespace\napp/crud/payments.py:231:1: W293 blank line contains whitespace\napp/crud/payments.py:232:18: W292 no newline at end of file\napp/integration/__init__.py:1:36: W292 no newline at end of file\napp/integration/notification_events.py:10:1: F401 'app.core.push_notifications.send_order_notification' imported but unused\napp/integration/notification_events.py:10:1: F401 'app.core.push_notifications.send_payment_notification' imported but unused\napp/integration/notification_events.py:10:1: F401 'app.core.push_notifications.send_kitchen_alert' imported but unused\napp/integration/notification_events.py:10:1: F401 'app.core.push_notifications.send_inventory_alert' imported but unused\napp/integration/notification_events.py:19:1: E302 expected 2 blank lines, found 1\napp/integration/notification_events.py:21:1: W293 blank line contains whitespace\napp/integration/notification_events.py:34:1: W293 blank line contains whitespace\napp/integration/notification_events.py:42:1: W293 blank line contains whitespace\napp/integration/notification_events.py:44:13: F821 undefined name 'logger'\napp/integration/notification_events.py:45:1: W293 blank line contains whitespace\napp/integration/notification_events.py:47:121: E501 line too long (135 > 120 characters)\napp/integration/notification_events.py:57:1: W293 blank line contains whitespace\napp/integration/notification_events.py:60:1: W293 blank line contains whitespace\napp/integration/notification_events.py:66:1: W293 blank line contains whitespace\napp/integration/notification_events.py:72:1: W293 blank line contains whitespace\napp/integration/notification_events.py:79:1: W293 blank line contains whitespace\napp/integration/notification_events.py:81:13: F821 undefined name 'logger'\napp/integration/notification_events.py:82:1: W293 blank line contains whitespace\napp/integration/notification_events.py:95:1: W293 blank line contains whitespace\napp/integration/notification_events.py:103:1: W293 blank line contains whitespace\napp/integration/notification_events.py:105:13: F821 undefined name 'logger'\napp/integration/notification_events.py:106:1: W293 blank line contains whitespace\napp/integration/notification_events.py:120:1: W293 blank line contains whitespace\napp/integration/notification_events.py:128:1: W293 blank line contains whitespace\napp/integration/notification_events.py:130:13: F821 undefined name 'logger'\napp/integration/notification_events.py:131:1: W293 blank line contains whitespace\napp/integration/notification_events.py:133:121: E501 line too long (123 > 120 characters)\napp/integration/notification_events.py:144:1: W293 blank line contains whitespace\napp/integration/notification_events.py:152:1: W293 blank line contains whitespace\napp/integration/notification_events.py:154:13: F821 undefined name 'logger'\napp/integration/notification_events.py:155:1: W293 blank line contains whitespace\napp/integration/notification_events.py:167:1: W293 blank line contains whitespace\napp/integration/notification_events.py:175:1: W293 blank line contains whitespace\napp/integration/notification_events.py:177:13: F821 undefined name 'logger'\napp/integration/notification_events.py:178:1: W293 blank line contains whitespace\napp/integration/notification_events.py:186:1: W293 blank line contains whitespace\napp/integration/notification_events.py:194:1: W293 blank line contains whitespace\napp/integration/notification_events.py:202:1: W293 blank line contains whitespace\napp/integration/notification_events.py:204:13: F821 undefined name 'logger'\napp/integration/notification_events.py:205:1: W293 blank line contains whitespace\napp/integration/notification_events.py:216:1: W293 blank line contains whitespace\napp/integration/notification_events.py:224:1: W293 blank line contains whitespace\napp/integration/notification_events.py:226:13: F821 undefined name 'logger'\napp/integration/notification_events.py:227:1: W293 blank line contains whitespace\napp/integration/notification_events.py:229:121: E501 line too long (129 > 120 characters)\napp/integration/notification_events.py:238:1: W293 blank line contains whitespace\napp/integration/notification_events.py:246:1: W293 blank line contains whitespace\napp/integration/notification_events.py:248:13: F821 undefined name 'logger'\napp/integration/notification_events.py:249:1: W293 blank line contains whitespace\napp/integration/notification_events.py:257:47: F821 undefined name 'timedelta'\napp/integration/notification_events.py:258:1: W293 blank line contains whitespace\napp/integration/notification_events.py:262:1: W293 blank line contains whitespace\napp/integration/notification_events.py:270:1: W293 blank line contains whitespace\napp/integration/notification_events.py:272:13: F821 undefined name 'logger'\napp/integration/notification_events.py:273:1: W293 blank line contains whitespace\napp/integration/notification_events.py:281:13: F821 undefined name 'logger'\napp/integration/notification_events.py:284:1: E305 expected 2 blank lines after class or function definition, found 1\napp/integration/notification_events.py:287:1: E302 expected 2 blank lines, found 1\napp/integration/notification_events.py:291:1: E302 expected 2 blank lines, found 1\napp/integration/notification_events.py:291:121: E501 line too long (138 > 120 characters)\napp/integration/notification_events.py:295:1: E302 expected 2 blank lines, found 1\napp/integration/notification_events.py:302:1: E302 expected 2 blank lines, found 1\napp/integration/notification_events.py:302:121: E501 line too long (130 > 120 characters)\napp/integration/notification_events.py:306:1: E302 expected 2 blank lines, found 1\napp/integration/notification_events.py:310:1: E302 expected 2 blank lines, found 1\napp/integration/notification_events.py:314:1: E302 expected 2 blank lines, found 1\napp/integration/notification_events.py:316:78: W292 no newline at end of file\napp/integration/websocket_events.py:7:1: F401 'datetime.datetime' imported but unused\napp/integration/websocket_events.py:9:1: F401 'app.core.websocket.websocket_manager' imported but unused\napp/integration/websocket_events.py:19:1: E302 expected 2 blank lines, found 1\napp/integration/websocket_events.py:21:1: W293 blank line contains whitespace\napp/integration/websocket_events.py:32:13: F821 undefined name 'logger'\napp/integration/websocket_events.py:33:1: W293 blank line contains whitespace\napp/integration/websocket_events.py:35:121: E501 line too long (135 > 120 characters)\napp/integration/websocket_events.py:46:13: F821 undefined name 'logger'\napp/integration/websocket_events.py:47:1: W293 blank line contains whitespace\napp/integration/websocket_events.py:59:13: F821 undefined name 'logger'\napp/integration/websocket_events.py:60:1: W293 blank line contains whitespace\napp/integration/websocket_events.py:62:121: E501 line too long (123 > 120 characters)\napp/integration/websocket_events.py:73:13: F821 undefined name 'logger'\napp/integration/websocket_events.py:74:1: W293 blank line contains whitespace\napp/integration/websocket_events.py:86:13: F821 undefined name 'logger'\napp/integration/websocket_events.py:87:1: W293 blank line contains whitespace\napp/integration/websocket_events.py:99:13: F821 undefined name 'logger'\napp/integration/websocket_events.py:100:1: W293 blank line contains whitespace\napp/integration/websocket_events.py:112:13: F821 undefined name 'logger'\napp/integration/websocket_events.py:115:1: E305 expected 2 blank lines after class or function definition, found 1\napp/integration/websocket_events.py:118:1: E302 expected 2 blank lines, found 1\napp/integration/websocket_events.py:122:1: E302 expected 2 blank lines, found 1\napp/integration/websocket_events.py:122:121: E501 line too long (133 > 120 characters)\napp/integration/websocket_events.py:126:1: E302 expected 2 blank lines, found 1\napp/integration/websocket_events.py:130:1: E302 expected 2 blank lines, found 1\napp/integration/websocket_events.py:130:121: E501 line too long (121 > 120 characters)\napp/integration/websocket_events.py:134:1: E302 expected 2 blank lines, found 1\napp/integration/websocket_events.py:138:1: E302 expected 2 blank lines, found 1\napp/integration/websocket_events.py:142:1: E302 expected 2 blank lines, found 1\napp/integration/websocket_events.py:144:77: W292 no newline at end of file\napp/main.py:20:1: F401 'app.core.websocket.websocket_manager' imported but unused\napp/main.py:21:1: F401 'app.core.exceptions.FynloException' imported but unused\napp/main.py:21:1: F401 'app.core.exceptions.ErrorCodes' imported but unused\napp/main.py:27:1: F401 'app.core.mobile_middleware.MobileCompatibilityMiddleware' imported but unused\napp/main.py:27:1: F401 'app.core.mobile_middleware.MobileDataOptimizationMiddleware' imported but unused\napp/main.py:31:1: F401 'app.middleware.version_middleware.APIVersionMiddleware' imported but unused\napp/main.py:32:1: F401 'app.middleware.security_headers_middleware.SecurityHeadersMiddleware' imported but unused\napp/main.py:47:1: E402 module level import not at top of file\napp/main.py:57:1: E302 expected 2 blank lines, found 1\napp/main.py:61:1: W293 blank line contains whitespace\napp/main.py:66:1: W293 blank line contains whitespace\napp/main.py:69:1: W293 blank line contains whitespace\napp/main.py:72:1: W293 blank line contains whitespace\napp/main.py:75:1: W293 blank line contains whitespace\napp/main.py:80:1: W293 blank line contains whitespace\napp/main.py:85:1: W293 blank line contains whitespace\napp/main.py:90:1: W293 blank line contains whitespace\napp/main.py:96:1: W293 blank line contains whitespace\napp/main.py:103:1: W293 blank line contains whitespace\napp/main.py:107:1: W293 blank line contains whitespace\napp/main.py:112:1: W293 blank line contains whitespace\napp/main.py:114:1: W293 blank line contains whitespace\napp/main.py:119:1: W293 blank line contains whitespace\napp/main.py:122:1: W293 blank line contains whitespace\napp/main.py:188:1: E402 module level import not at top of file\napp/main.py:217:1: E302 expected 2 blank lines, found 1\napp/main.py:231:1: E302 expected 2 blank lines, found 1\napp/main.py:234:1: W293 blank line contains whitespace\napp/main.py:244:1: E302 expected 2 blank lines, found 1\napp/main.py:273:1: W293 blank line contains whitespace\napp/main.py:283:121: E501 line too long (140 > 120 characters)\napp/main.py:284:121: E501 line too long (144 > 120 characters)\napp/main.py:291:1: E302 expected 2 blank lines, found 1\napp/main.py:298:1: W293 blank line contains whitespace\napp/main.py:303:28: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/main.py:305:1: W293 blank line contains whitespace\napp/main.py:313:1: W293 blank line contains whitespace\napp/main.py:316:1: W293 blank line contains whitespace\napp/main.py:337:41: W291 trailing whitespace\napp/main.py:371:1: E302 expected 2 blank lines, found 1\napp/main.py:384:1: E302 expected 2 blank lines, found 1\napp/main.py:389:1: W293 blank line contains whitespace\napp/main.py:393:1: W293 blank line contains whitespace\napp/main.py:407:121: E501 line too long (127 > 120 characters)\napp/main.py:409:1: W293 blank line contains whitespace\napp/main.py:415:1: E302 expected 2 blank lines, found 1\napp/main.py:438:1: W293 blank line contains whitespace\napp/main.py:444:1: E302 expected 2 blank lines, found 1\napp/main.py:467:1: W293 blank line contains whitespace\napp/main.py:473:1: E302 expected 2 blank lines, found 1\napp/main.py:477:1: W293 blank line contains whitespace\napp/main.py:486:1: W293 blank line contains whitespace\napp/main.py:489:121: E501 line too long (128 > 120 characters)\napp/main.py:490:1: W293 blank line contains whitespace\napp/main.py:494:1: W293 blank line contains whitespace\napp/main.py:517:1: E302 expected 2 blank lines, found 1\napp/main.py:556:1: E302 expected 2 blank lines, found 1\napp/main.py:560:1: W293 blank line contains whitespace\napp/main.py:564:1: W293 blank line contains whitespace\napp/main.py:567:1: W293 blank line contains whitespace\napp/main.py:590:1: W293 blank line contains whitespace\napp/main.py:605:6: W292 no newline at end of file\napp/main_minimal.py:13:1: E122 continuation line missing indentation or outdented\napp/main_minimal.py:14:1: E122 continuation line missing indentation or outdented\napp/main_minimal.py:15:1: E122 continuation line missing indentation or outdented\napp/main_minimal.py:20:1: E122 continuation line missing indentation or outdented\napp/main_minimal.py:21:1: E122 continuation line missing indentation or outdented\napp/main_minimal.py:22:1: E122 continuation line missing indentation or outdented\napp/main_minimal.py:23:1: E122 continuation line missing indentation or outdented\napp/main_minimal.py:24:1: E122 continuation line missing indentation or outdented\napp/main_minimal.py:27:1: E302 expected 2 blank lines, found 1\napp/main_minimal.py:31:5: E122 continuation line missing indentation or outdented\napp/main_minimal.py:32:5: E122 continuation line missing indentation or outdented\napp/main_minimal.py:33:5: E122 continuation line missing indentation or outdented\napp/main_minimal.py:34:5: E122 continuation line missing indentation or outdented\napp/main_minimal.py:35:5: E122 continuation line missing indentation or outdented\napp/main_minimal.py:38:1: E302 expected 2 blank lines, found 1\napp/main_minimal.py:50:1: E302 expected 2 blank lines, found 1\napp/main_minimal.py:64:1: E302 expected 2 blank lines, found 1\napp/main_minimal.py:78:1: E302 expected 2 blank lines, found 1\napp/main_minimal.py:93:1: E302 expected 2 blank lines, found 1\napp/main_minimal.py:127:48: W292 no newline at end of file\napp/main_simple.py:33:1: E302 expected 2 blank lines, found 1\napp/main_simple.py:43:1: E302 expected 2 blank lines, found 1\napp/main_simple.py:53:1: E302 expected 2 blank lines, found 1\napp/main_simple.py:63:1: E302 expected 2 blank lines, found 1\napp/main_simple.py:73:48: W292 no newline at end of file\napp/middleware/feature_gate.py:8:1: F401 'functools.wraps' imported but unused\napp/middleware/feature_gate.py:9:1: F401 'fastapi.Request' imported but unused\napp/middleware/feature_gate.py:11:1: F401 'typing.Callable' imported but unused\napp/middleware/feature_gate.py:15:1: F401 'app.core.auth.get_current_user' imported but unused\napp/middleware/feature_gate.py:21:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:26:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:35:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:41:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:47:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:57:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:72:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:75:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:82:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:87:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:90:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:97:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:107:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:109:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:112:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:119:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:121:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:132:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:141:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:148:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:155:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:157:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:168:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:176:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:180:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:187:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:192:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:199:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:201:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:220:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:223:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:227:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:231:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:234:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:236:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:241:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:245:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:248:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:254:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:263:1: W293 blank line contains whitespace\napp/middleware/feature_gate.py:274:10: W292 no newline at end of file\napp/middleware/rate_limit_middleware.py:11:1: F401 'slowapi.errors.RateLimitExceeded' imported but unused\napp/middleware/rate_limit_middleware.py:12:1: F401 'slowapi.middleware.SlowAPIMiddleware' imported but unused\napp/middleware/rate_limit_middleware.py:16:47: E261 at least two spaces before inline comment\napp/middleware/rate_limit_middleware.py:23:1: E302 expected 2 blank lines, found 1\napp/middleware/rate_limit_middleware.py:35:52: E261 at least two spaces before inline comment\napp/middleware/rate_limit_middleware.py:38:28: E261 at least two spaces before inline comment\napp/middleware/rate_limit_middleware.py:40:20: E261 at least two spaces before inline comment\napp/middleware/rate_limit_middleware.py:46:1: E302 expected 2 blank lines, found 1\napp/middleware/rate_limit_middleware.py:49:1: W293 blank line contains whitespace\napp/middleware/rate_limit_middleware.py:55:1: E302 expected 2 blank lines, found 1\napp/middleware/rate_limit_middleware.py:61:1: E302 expected 2 blank lines, found 1\napp/middleware/rate_limit_middleware.py:161:27: E261 at least two spaces before inline comment\napp/middleware/rls_middleware.py:8:1: F401 'starlette.responses.Response' imported but unused\napp/middleware/rls_middleware.py:24:1: W293 blank line contains whitespace\napp/middleware/rls_middleware.py:29:1: W293 blank line contains whitespace\napp/middleware/rls_middleware.py:34:1: W293 blank line contains whitespace\napp/middleware/rls_middleware.py:40:1: W293 blank line contains whitespace\napp/middleware/rls_middleware.py:42:1: W293 blank line contains whitespace\napp/middleware/rls_middleware.py:45:1: W293 blank line contains whitespace\napp/middleware/rls_middleware.py:47:1: W293 blank line contains whitespace\napp/middleware/rls_middleware.py:53:1: W293 blank line contains whitespace\napp/middleware/rls_middleware.py:67:1: W293 blank line contains whitespace\napp/middleware/rls_middleware.py:75:1: W293 blank line contains whitespace\napp/middleware/rls_middleware.py:93:1: W293 blank line contains whitespace\napp/middleware/rls_middleware.py:98:1: W293 blank line contains whitespace\napp/middleware/rls_middleware.py:114:52: W291 trailing whitespace\napp/middleware/rls_middleware.py:115:21: E128 continuation line under-indented for visual indent\napp/middleware/rls_middleware.py:115:57: W291 trailing whitespace\napp/middleware/rls_middleware.py:116:21: E128 continuation line under-indented for visual indent\napp/middleware/rls_middleware.py:120:1: W293 blank line contains whitespace\napp/middleware/rls_middleware.py:130:1: W293 blank line contains whitespace\napp/middleware/rls_middleware.py:137:1: W293 blank line contains whitespace\napp/middleware/rls_middleware.py:139:21: W292 no newline at end of file\napp/middleware/security_headers_middleware.py:6:1: E302 expected 2 blank lines, found 1\napp/middleware/security_headers_middleware.py:13:63: E261 at least two spaces before inline comment\napp/middleware/security_headers_middleware.py:24:98: E261 at least two spaces before inline comment\napp/middleware/security_headers_middleware.py:24:121: E501 line too long (136 > 120 characters)\napp/middleware/security_headers_middleware.py:25:79: E261 at least two spaces before inline comment\napp/middleware/security_headers_middleware.py:27:96: E261 at least two spaces before inline comment\napp/middleware/security_headers_middleware.py:27:121: E501 line too long (123 > 120 characters)\napp/middleware/security_headers_middleware.py:39:94: E261 at least two spaces before inline comment\napp/middleware/security_headers_middleware.py:40:88: E261 at least two spaces before inline comment\napp/middleware/security_headers_middleware.py:40:121: E501 line too long (135 > 120 characters)\napp/middleware/security_headers_middleware.py:41:68: E261 at least two spaces before inline comment\napp/middleware/security_headers_middleware.py:42:65: E261 at least two spaces before inline comment\napp/middleware/security_headers_middleware.py:45:121: E501 line too long (151 > 120 characters)\napp/middleware/security_headers_middleware.py:48:15: E261 at least two spaces before inline comment\napp/middleware/security_headers_middleware.py:49:93: E261 at least two spaces before inline comment\napp/middleware/security_headers_middleware.py:50:38: E261 at least two spaces before inline comment\napp/middleware/security_headers_middleware.py:52:39: E261 at least two spaces before inline comment\napp/middleware/security_headers_middleware.py:53:43: E261 at least two spaces before inline comment\napp/middleware/security_headers_middleware.py:66:121: E501 line too long (169 > 120 characters)\napp/middleware/security_headers_middleware.py:66:130: E261 at least two spaces before inline comment\napp/middleware/security_headers_middleware.py:72:39: E261 at least two spaces before inline comment\napp/middleware/security_headers_middleware.py:73:40: E261 at least two spaces before inline comment\napp/middleware/security_headers_middleware.py:74:41: E261 at least two spaces before inline comment\napp/middleware/security_headers_middleware.py:82:43: E261 at least two spaces before inline comment\napp/middleware/security_headers_middleware.py:92:25: E261 at least two spaces before inline comment\napp/middleware/security_headers_middleware.py:94:33: E261 at least two spaces before inline comment\napp/middleware/security_headers_middleware.py:95:30: E261 at least two spaces before inline comment\napp/middleware/security_headers_middleware.py:100:26: E261 at least two spaces before inline comment\napp/middleware/sql_injection_waf.py:27:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:34:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:37:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:41:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:45:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:48:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:51:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:54:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:57:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:60:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:63:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:67:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:69:72: W291 trailing whitespace\napp/middleware/sql_injection_waf.py:70:25: E128 continuation line under-indented for visual indent\napp/middleware/sql_injection_waf.py:71:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:87:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:96:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:102:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:107:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:111:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:115:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:121:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:131:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:137:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:142:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:149:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:160:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:164:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:166:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:172:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:177:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:181:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:189:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:198:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:203:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:209:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:211:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:216:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:219:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:224:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:230:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:234:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:236:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:240:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:245:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:252:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:255:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:259:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:261:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:268:1: W293 blank line contains whitespace\napp/middleware/sql_injection_waf.py:271:32: W292 no newline at end of file\napp/middleware/tenant_isolation_middleware.py:23:1: W293 blank line contains whitespace\napp/middleware/tenant_isolation_middleware.py:26:1: W293 blank line contains whitespace\napp/middleware/tenant_isolation_middleware.py:34:1: W293 blank line contains whitespace\napp/middleware/tenant_isolation_middleware.py:44:1: W293 blank line contains whitespace\napp/middleware/tenant_isolation_middleware.py:47:1: W293 blank line contains whitespace\napp/middleware/tenant_isolation_middleware.py:53:1: W293 blank line contains whitespace\napp/middleware/tenant_isolation_middleware.py:61:1: W293 blank line contains whitespace\napp/middleware/tenant_isolation_middleware.py:66:1: W293 blank line contains whitespace\napp/middleware/tenant_isolation_middleware.py:71:1: W293 blank line contains whitespace\napp/middleware/tenant_isolation_middleware.py:82:1: W293 blank line contains whitespace\napp/middleware/tenant_isolation_middleware.py:91:1: W293 blank line contains whitespace\napp/middleware/tenant_isolation_middleware.py:96:1: W293 blank line contains whitespace\napp/middleware/tenant_isolation_middleware.py:99:1: W293 blank line contains whitespace\napp/middleware/tenant_isolation_middleware.py:103:1: W293 blank line contains whitespace\napp/middleware/tenant_isolation_middleware.py:107:1: W293 blank line contains whitespace\napp/middleware/tenant_isolation_middleware.py:116:1: W293 blank line contains whitespace\napp/middleware/tenant_isolation_middleware.py:121:69: W292 no newline at end of file\napp/middleware/version_middleware.py:7:1: F401 'fastapi.responses.JSONResponse' imported but unused\napp/middleware/version_middleware.py:14:1: E302 expected 2 blank lines, found 1\napp/middleware/version_middleware.py:17:1: W293 blank line contains whitespace\napp/middleware/version_middleware.py:24:1: W293 blank line contains whitespace\napp/middleware/version_middleware.py:27:1: W293 blank line contains whitespace\napp/middleware/version_middleware.py:33:1: W293 blank line contains whitespace\napp/middleware/version_middleware.py:36:1: W293 blank line contains whitespace\napp/middleware/version_middleware.py:40:1: W293 blank line contains whitespace\napp/middleware/version_middleware.py:44:1: W293 blank line contains whitespace\napp/middleware/version_middleware.py:49:1: W293 blank line contains whitespace\napp/middleware/version_middleware.py:54:1: W293 blank line contains whitespace\napp/middleware/version_middleware.py:57:1: W293 blank line contains whitespace\napp/middleware/version_middleware.py:61:1: W293 blank line contains whitespace\napp/middleware/version_middleware.py:67:1: W293 blank line contains whitespace\napp/middleware/version_middleware.py:71:1: W293 blank line contains whitespace\napp/middleware/version_middleware.py:77:1: W293 blank line contains whitespace\napp/middleware/version_middleware.py:79:1: W293 blank line contains whitespace\napp/middleware/version_middleware.py:83:1: W293 blank line contains whitespace\napp/middleware/version_middleware.py:88:1: W293 blank line contains whitespace\napp/middleware/version_middleware.py:94:1: W293 blank line contains whitespace\napp/middleware/version_middleware.py:98:1: W293 blank line contains whitespace\napp/middleware/version_middleware.py:100:1: W293 blank line contains whitespace\napp/middleware/version_middleware.py:104:1: W293 blank line contains whitespace\napp/middleware/version_middleware.py:109:1: W293 blank line contains whitespace\napp/middleware/version_middleware.py:114:1: W293 blank line contains whitespace\napp/middleware/version_middleware.py:120:1: W293 blank line contains whitespace\napp/middleware/version_middleware.py:128:1: W293 blank line contains whitespace\napp/middleware/version_middleware.py:132:1: W293 blank line contains whitespace\napp/middleware/version_middleware.py:135:1: W293 blank line contains whitespace\napp/middleware/version_middleware.py:143:1: W293 blank line contains whitespace\napp/middleware/version_middleware.py:148:1: W293 blank line contains whitespace\napp/middleware/version_middleware.py:153:1: W293 blank line contains whitespace\napp/middleware/version_middleware.py:157:1: W293 blank line contains whitespace\napp/middleware/version_middleware.py:158:21: F541 f-string is missing placeholders\napp/middleware/version_middleware.py:159:1: W293 blank line contains whitespace\napp/middleware/version_middleware.py:164:1: W293 blank line contains whitespace\napp/middleware/version_middleware.py:170:1: W293 blank line contains whitespace\napp/middleware/version_middleware.py:176:1: W293 blank line contains whitespace\napp/middleware/version_middleware.py:181:1: W293 blank line contains whitespace\napp/middleware/version_middleware.py:193:2: W291 trailing whitespace\napp/middleware/version_middleware.py:193:3: W292 no newline at end of file\napp/middleware/websocket_rate_limit.py:32:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:38:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:42:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:46:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:50:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:60:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:62:14: W291 trailing whitespace\napp/middleware/websocket_rate_limit.py:63:25: W291 trailing whitespace\napp/middleware/websocket_rate_limit.py:68:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:80:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:84:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:89:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:94:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:99:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:103:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:106:31: F541 f-string is missing placeholders\napp/middleware/websocket_rate_limit.py:107:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:110:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:116:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:118:14: W291 trailing whitespace\napp/middleware/websocket_rate_limit.py:125:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:134:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:138:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:143:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:145:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:150:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:156:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:159:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:164:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:172:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:180:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:193:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:197:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:203:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:205:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:212:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:214:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:223:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:227:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:237:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:243:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:252:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:257:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:262:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:265:31: W291 trailing whitespace\napp/middleware/websocket_rate_limit.py:268:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:276:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:280:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:283:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:288:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:292:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:299:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:301:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:308:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:311:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:317:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:324:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:327:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:329:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:333:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:342:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:355:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:362:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:366:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:371:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:380:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:383:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:386:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:389:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:394:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:400:28: W291 trailing whitespace\napp/middleware/websocket_rate_limit.py:401:35: W291 trailing whitespace\napp/middleware/websocket_rate_limit.py:404:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:410:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:413:1: W293 blank line contains whitespace\napp/middleware/websocket_rate_limit.py:464:72: W292 no newline at end of file\napp/models.py:42:2: W292 no newline at end of file\napp/models/activity_log.py:13:1: E302 expected 2 blank lines, found 1\napp/models/activity_log.py:15:1: W293 blank line contains whitespace\napp/models/activity_log.py:17:1: W293 blank line contains whitespace\napp/models/activity_log.py:26:1: W293 blank line contains whitespace\napp/models/activity_log.py:30:1: W293 blank line contains whitespace\napp/models/activity_log.py:39:1: W293 blank line contains whitespace\napp/models/activity_log.py:42:1: W293 blank line contains whitespace\napp/models/activity_log.py:54:10: W292 no newline at end of file\napp/models/audit_log.py:5:1: F401 'sqlalchemy.orm.relationship' imported but unused\napp/models/audit_log.py:61:1: E302 expected 2 blank lines, found 1\napp/models/audit_log.py:67:1: E302 expected 2 blank lines, found 1\napp/models/audit_log.py:73:121: E501 line too long (125 > 120 characters)\napp/models/employee.py:16:1: W293 blank line contains whitespace\napp/models/employee.py:20:1: W293 blank line contains whitespace\napp/models/employee.py:26:1: W293 blank line contains whitespace\napp/models/employee.py:30:1: W293 blank line contains whitespace\napp/models/employee.py:35:1: W293 blank line contains whitespace\napp/models/employee.py:41:1: W293 blank line contains whitespace\napp/models/employee.py:46:1: W293 blank line contains whitespace\napp/models/employee.py:49:1: W293 blank line contains whitespace\napp/models/employee.py:53:121: E501 line too long (134 > 120 characters)\napp/models/employee.py:61:1: W293 blank line contains whitespace\napp/models/employee.py:65:1: W293 blank line contains whitespace\napp/models/employee.py:71:1: W293 blank line contains whitespace\napp/models/employee.py:75:1: W293 blank line contains whitespace\napp/models/employee.py:79:1: W293 blank line contains whitespace\napp/models/employee.py:83:1: W293 blank line contains whitespace\napp/models/employee.py:88:1: W293 blank line contains whitespace\napp/models/employee.py:95:1: W293 blank line contains whitespace\napp/models/employee.py:105:1: W293 blank line contains whitespace\napp/models/employee.py:110:1: W293 blank line contains whitespace\napp/models/employee.py:114:1: W293 blank line contains whitespace\napp/models/employee.py:119:1: W293 blank line contains whitespace\napp/models/employee.py:123:1: W293 blank line contains whitespace\napp/models/employee.py:128:1: W293 blank line contains whitespace\napp/models/employee.py:134:1: W293 blank line contains whitespace\napp/models/employee.py:140:1: W293 blank line contains whitespace\napp/models/employee.py:144:1: W293 blank line contains whitespace\napp/models/employee.py:155:1: W293 blank line contains whitespace\napp/models/employee.py:159:1: W293 blank line contains whitespace\napp/models/employee.py:163:1: W293 blank line contains whitespace\napp/models/employee.py:168:1: W293 blank line contains whitespace\napp/models/employee.py:175:1: W293 blank line contains whitespace\napp/models/employee.py:177:1: W293 blank line contains whitespace\napp/models/employee.py:187:1: W293 blank line contains whitespace\napp/models/employee.py:191:1: W293 blank line contains whitespace\napp/models/employee.py:195:1: W293 blank line contains whitespace\napp/models/employee.py:200:1: W293 blank line contains whitespace\napp/models/employee.py:204:1: W293 blank line contains whitespace\napp/models/employee.py:209:1: W293 blank line contains whitespace\napp/models/employee.py:213:1: W293 blank line contains whitespace\napp/models/employee.py:219:1: W293 blank line contains whitespace\napp/models/employee.py:222:1: W293 blank line contains whitespace\napp/models/employee.py:226:1: W293 blank line contains whitespace\napp/models/employee.py:230:6: W292 no newline at end of file\napp/models/financial_records.py:2:1: F401 'sqlalchemy.dialects.postgresql.UUID' imported but unused\napp/models/financial_records.py:3:32: E261 at least two spaces before inline comment\napp/models/financial_records.py:5:35: E261 at least two spaces before inline comment\napp/models/financial_records.py:8:1: E302 expected 2 blank lines, found 1\napp/models/financial_records.py:11:55: E261 at least two spaces before inline comment\napp/models/financial_records.py:13:121: E501 line too long (124 > 120 characters)\napp/models/financial_records.py:17:65: E261 at least two spaces before inline comment\napp/models/financial_records.py:19:66: E261 at least two spaces before inline comment\napp/models/financial_records.py:21:52: E261 at least two spaces before inline comment\napp/models/financial_records.py:37:1: E302 expected 2 blank lines, found 1\napp/models/financial_records.py:42:65: E261 at least two spaces before inline comment\napp/models/financial_records.py:50:88: E261 at least two spaces before inline comment\napp/models/financial_records.py:50:121: E501 line too long (121 > 120 characters)\napp/models/financial_records.py:51:60: E261 at least two spaces before inline comment\napp/models/payment_config.py:2:1: F401 'sqlalchemy.orm.relationship' imported but unused\napp/models/payment_config.py:3:1: F401 'sqlalchemy.dialects.postgresql.UUID' imported but unused\napp/models/payment_config.py:5:35: E261 at least two spaces before inline comment\napp/models/payment_config.py:6:1: F401 'app.schemas.fee_schemas.PaymentMethodEnum' imported but unused\napp/models/payment_config.py:8:1: E302 expected 2 blank lines, found 1\napp/models/payment_config.py:22:62: E261 at least two spaces before inline comment\napp/models/payment_config.py:26:64: E261 at least two spaces before inline comment\napp/models/payment_config.py:42:70: W291 trailing whitespace\napp/models/payment_config.py:59:121: E501 line too long (127 > 120 characters)\napp/models/platform_audit.py:7:1: F401 'typing.Dict' imported but unused\napp/models/platform_audit.py:7:1: F401 'typing.Any' imported but unused\napp/models/platform_audit.py:18:1: W293 blank line contains whitespace\napp/models/platform_audit.py:20:1: W293 blank line contains whitespace\napp/models/platform_audit.py:24:1: W293 blank line contains whitespace\napp/models/platform_audit.py:29:1: W293 blank line contains whitespace\napp/models/platform_audit.py:34:1: W293 blank line contains whitespace\napp/models/platform_audit.py:39:1: W293 blank line contains whitespace\napp/models/platform_audit.py:42:1: W293 blank line contains whitespace\napp/models/platform_audit.py:62:1: W293 blank line contains whitespace\napp/models/platform_audit.py:75:1: W293 blank line contains whitespace\napp/models/platform_audit.py:80:1: W293 blank line contains whitespace\napp/models/platform_audit.py:84:1: W293 blank line contains whitespace\napp/models/platform_audit.py:98:1: W293 blank line contains whitespace\napp/models/platform_audit.py:102:1: W293 blank line contains whitespace\napp/models/platform_audit.py:114:1: W293 blank line contains whitespace\napp/models/platform_audit.py:121:1: W293 blank line contains whitespace\napp/models/platform_audit.py:126:1: W293 blank line contains whitespace\napp/models/platform_audit.py:132:1: W293 blank line contains whitespace\napp/models/platform_audit.py:153:1: W293 blank line contains whitespace\napp/models/platform_audit.py:164:1: W293 blank line contains whitespace\napp/models/platform_audit.py:169:1: W293 blank line contains whitespace\napp/models/platform_audit.py:172:1: W293 blank line contains whitespace\napp/models/platform_audit.py:175:1: W293 blank line contains whitespace\napp/models/platform_audit.py:178:1: W293 blank line contains whitespace\napp/models/platform_audit.py:181:1: W293 blank line contains whitespace\napp/models/platform_audit.py:184:1: W293 blank line contains whitespace\napp/models/platform_audit.py:187:1: W293 blank line contains whitespace\napp/models/platform_audit.py:191:1: W293 blank line contains whitespace\napp/models/platform_audit.py:195:1: W293 blank line contains whitespace\napp/models/platform_audit.py:201:1: W293 blank line contains whitespace\napp/models/platform_audit.py:202:51: F821 undefined name 'days'\napp/models/platform_audit.py:203:1: W293 blank line contains whitespace\napp/models/platform_audit.py:213:1: W293 blank line contains whitespace\napp/models/platform_audit.py:225:1: W293 blank line contains whitespace\napp/models/platform_audit.py:235:1: W293 blank line contains whitespace\napp/models/platform_audit.py:237:24: F821 undefined name 'days'\napp/models/platform_audit.py:247:6: W292 no newline at end of file\napp/models/platform_config.py:12:1: E302 expected 2 blank lines, found 1\napp/models/platform_config.py:40:1: E302 expected 2 blank lines, found 1\napp/models/platform_config.py:68:1: E302 expected 2 blank lines, found 1\napp/models/platform_config.py:98:1: E302 expected 2 blank lines, found 1\napp/models/platform_config.py:120:1: E305 expected 2 blank lines after class or function definition, found 1\napp/models/platform_config.py:179:1: W293 blank line contains whitespace\napp/models/platform_config.py:257:41: E261 at least two spaces before inline comment\napp/models/platform_config.py:265:41: E261 at least two spaces before inline comment\napp/models/platform_config.py:269:121: E501 line too long (122 > 120 characters)\napp/models/platform_config.py:273:62: E261 at least two spaces before inline comment\napp/models/platform_config.py:281:42: E261 at least two spaces before inline comment\napp/models/platform_config.py:285:121: E501 line too long (123 > 120 characters)\napp/models/platform_config.py:326:2: W292 no newline at end of file\napp/models/refund.py:7:1: E302 expected 2 blank lines, found 1\napp/models/refund.py:23:1: E302 expected 2 blank lines, found 1\napp/models/refund.py:36:42: E261 at least two spaces before inline comment\napp/models/refund.py:44:32: E261 at least two spaces before inline comment\napp/models/reports.py:16:1: W293 blank line contains whitespace\napp/models/reports.py:20:1: W293 blank line contains whitespace\napp/models/reports.py:25:1: W293 blank line contains whitespace\napp/models/reports.py:31:1: W293 blank line contains whitespace\napp/models/reports.py:36:1: W293 blank line contains whitespace\napp/models/reports.py:42:1: W293 blank line contains whitespace\napp/models/reports.py:47:1: W293 blank line contains whitespace\napp/models/reports.py:51:1: W293 blank line contains whitespace\napp/models/reports.py:56:1: W293 blank line contains whitespace\napp/models/reports.py:60:1: W293 blank line contains whitespace\napp/models/reports.py:64:1: W293 blank line contains whitespace\napp/models/reports.py:69:1: W293 blank line contains whitespace\napp/models/reports.py:72:1: W293 blank line contains whitespace\napp/models/reports.py:82:1: W293 blank line contains whitespace\napp/models/reports.py:87:1: W293 blank line contains whitespace\napp/models/reports.py:93:1: W293 blank line contains whitespace\napp/models/reports.py:98:1: W293 blank line contains whitespace\napp/models/reports.py:103:1: W293 blank line contains whitespace\napp/models/reports.py:105:1: W293 blank line contains whitespace\napp/models/reports.py:108:1: W293 blank line contains whitespace\napp/models/reports.py:118:1: W293 blank line contains whitespace\napp/models/reports.py:123:1: W293 blank line contains whitespace\napp/models/reports.py:130:1: W293 blank line contains whitespace\napp/models/reports.py:135:1: W293 blank line contains whitespace\napp/models/reports.py:139:1: W293 blank line contains whitespace\napp/models/reports.py:144:1: W293 blank line contains whitespace\napp/models/reports.py:146:1: W293 blank line contains whitespace\napp/models/reports.py:150:1: W293 blank line contains whitespace\napp/models/reports.py:160:1: W293 blank line contains whitespace\napp/models/reports.py:165:1: W293 blank line contains whitespace\napp/models/reports.py:169:1: W293 blank line contains whitespace\napp/models/reports.py:175:1: W293 blank line contains whitespace\napp/models/reports.py:180:1: W293 blank line contains whitespace\napp/models/reports.py:184:1: W293 blank line contains whitespace\napp/models/reports.py:188:1: W293 blank line contains whitespace\napp/models/reports.py:192:1: W293 blank line contains whitespace\napp/models/reports.py:194:1: W293 blank line contains whitespace\napp/models/reports.py:198:1: W293 blank line contains whitespace\napp/models/reports.py:208:1: W293 blank line contains whitespace\napp/models/reports.py:212:1: W293 blank line contains whitespace\napp/models/reports.py:217:1: W293 blank line contains whitespace\napp/models/reports.py:221:1: W293 blank line contains whitespace\napp/models/reports.py:226:1: W293 blank line contains whitespace\napp/models/reports.py:231:1: W293 blank line contains whitespace\napp/models/reports.py:236:1: W293 blank line contains whitespace\napp/models/reports.py:241:1: W293 blank line contains whitespace\napp/models/reports.py:245:1: W293 blank line contains whitespace\napp/models/reports.py:248:1: W293 blank line contains whitespace\napp/models/reports.py:253:1: W293 blank line contains whitespace\napp/models/reports.py:257:1: W293 blank line contains whitespace\napp/models/reports.py:261:6: W292 no newline at end of file\napp/models/stock_movement.py:29:1: W293 blank line contains whitespace\napp/models/stock_movement.py:32:1: W293 blank line contains whitespace\napp/models/stock_movement.py:40:1: W293 blank line contains whitespace\napp/models/stock_movement.py:43:1: W293 blank line contains whitespace\napp/models/stock_movement.py:50:1: W293 blank line contains whitespace\napp/models/stock_movement.py:53:1: W293 blank line contains whitespace\napp/models/stock_movement.py:58:1: W293 blank line contains whitespace\napp/models/stock_movement.py:63:1: W293 blank line contains whitespace\napp/models/stock_movement.py:66:1: W293 blank line contains whitespace\napp/models/stock_movement.py:76:1: W293 blank line contains whitespace\napp/models/stock_movement.py:80:1: W293 blank line contains whitespace\napp/models/stock_movement.py:86:1: W293 blank line contains whitespace\napp/models/stock_movement.py:92:1: W293 blank line contains whitespace\napp/models/stock_movement.py:96:1: W293 blank line contains whitespace\napp/models/stock_movement.py:100:1: W293 blank line contains whitespace\napp/models/stock_movement.py:105:1: W293 blank line contains whitespace\napp/models/stock_movement.py:108:1: W293 blank line contains whitespace\napp/models/stock_movement.py:121:1: W293 blank line contains whitespace\napp/models/stock_movement.py:125:1: W293 blank line contains whitespace\napp/models/stock_movement.py:131:1: W293 blank line contains whitespace\napp/models/stock_movement.py:136:1: W293 blank line contains whitespace\napp/models/stock_movement.py:138:1: W293 blank line contains whitespace\napp/models/stock_movement.py:147:1: W293 blank line contains whitespace\napp/models/stock_movement.py:151:1: W293 blank line contains whitespace\napp/models/stock_movement.py:156:1: W293 blank line contains whitespace\napp/models/stock_movement.py:160:1: W293 blank line contains whitespace\napp/models/stock_movement.py:164:1: W293 blank line contains whitespace\napp/models/stock_movement.py:168:1: W293 blank line contains whitespace\napp/models/stock_movement.py:172:1: W293 blank line contains whitespace\napp/models/stock_movement.py:176:1: W293 blank line contains whitespace\napp/models/stock_movement.py:180:1: W293 blank line contains whitespace\napp/models/stock_movement.py:184:1: W293 blank line contains whitespace\napp/models/stock_movement.py:197:1: W293 blank line contains whitespace\napp/models/stock_movement.py:201:1: W293 blank line contains whitespace\napp/models/stock_movement.py:206:1: W293 blank line contains whitespace\napp/models/stock_movement.py:212:1: W293 blank line contains whitespace\napp/models/stock_movement.py:217:1: W293 blank line contains whitespace\napp/models/stock_movement.py:221:1: W293 blank line contains whitespace\napp/models/stock_movement.py:224:1: W293 blank line contains whitespace\napp/models/stock_movement.py:234:1: W293 blank line contains whitespace\napp/models/stock_movement.py:237:1: W293 blank line contains whitespace\napp/models/stock_movement.py:241:1: W293 blank line contains whitespace\napp/models/stock_movement.py:244:1: W293 blank line contains whitespace\napp/models/stock_movement.py:249:1: W293 blank line contains whitespace\napp/models/stock_movement.py:254:1: W293 blank line contains whitespace\napp/models/stock_movement.py:259:1: W293 blank line contains whitespace\napp/models/stock_movement.py:262:1: W293 blank line contains whitespace\napp/models/stock_movement.py:274:1: W293 blank line contains whitespace\napp/models/stock_movement.py:278:1: W293 blank line contains whitespace\napp/models/stock_movement.py:283:1: W293 blank line contains whitespace\napp/models/stock_movement.py:287:1: W293 blank line contains whitespace\napp/models/stock_movement.py:291:1: W293 blank line contains whitespace\napp/models/stock_movement.py:294:1: W293 blank line contains whitespace\napp/models/stock_movement.py:298:36: W292 no newline at end of file\napp/models/subscription.py:20:1: W293 blank line contains whitespace\napp/models/subscription.py:76:1: W293 blank line contains whitespace\napp/models/subscription.py:98:121: E501 line too long (127 > 120 characters)\napp/models/subscription.py:131:1: W293 blank line contains whitespace\napp/models/subscription.py:150:1: W293 blank line contains whitespace\napp/models/subscription.py:169:121: E501 line too long (128 > 120 characters)\napp/models/subscription.py:180:1: W293 blank line contains whitespace\napp/models/subscription.py:186:1: W293 blank line contains whitespace\napp/models/subscription.py:196:1: W293 blank line contains whitespace\napp/models/subscription.py:202:1: W293 blank line contains whitespace\napp/models/subscription.py:213:44: W292 no newline at end of file\napp/schemas/auth.py:32:19: W292 no newline at end of file\napp/schemas/employee_schemas.py:113:9: E999 IndentationError: unexpected indent\napp/schemas/fee_schemas.py:5:1: E302 expected 2 blank lines, found 1\napp/schemas/fee_schemas.py:9:32: E261 at least two spaces before inline comment\napp/schemas/fee_schemas.py:12:1: E302 expected 2 blank lines, found 1\napp/schemas/fee_schemas.py:14:22: E261 at least two spaces before inline comment\napp/schemas/fee_schemas.py:22:1: E302 expected 2 blank lines, found 1\napp/schemas/fee_schemas.py:24:49: E261 at least two spaces before inline comment\napp/schemas/fee_schemas.py:26:39: E261 at least two spaces before inline comment\napp/schemas/fee_schemas.py:30:1: E302 expected 2 blank lines, found 1\napp/schemas/fee_schemas.py:31:12: E261 at least two spaces before inline comment\napp/schemas/fee_schemas.py:34:1: E302 expected 2 blank lines, found 1\napp/schemas/fee_schemas.py:40:1: E302 expected 2 blank lines, found 1\napp/schemas/fee_schemas.py:41:22: E261 at least two spaces before inline comment\napp/schemas/fee_schemas.py:42:33: E261 at least two spaces before inline comment\napp/schemas/fee_schemas.py:45:35: E261 at least two spaces before inline comment\napp/schemas/fee_schemas.py:46:50: E261 at least two spaces before inline comment\napp/schemas/fee_schemas.py:49:31: E261 at least two spaces before inline comment\napp/schemas/fee_schemas.py:52:1: E302 expected 2 blank lines, found 1\napp/schemas/fee_schemas.py:54:18: E261 at least two spaces before inline comment\napp/schemas/fee_schemas.py:59:31: E261 at least two spaces before inline comment\napp/schemas/fee_schemas.py:65:1: E302 expected 2 blank lines, found 1\napp/schemas/fee_schemas.py:67:18: E261 at least two spaces before inline comment\napp/schemas/fee_schemas.py:68:18: E261 at least two spaces before inline comment\napp/schemas/fee_schemas.py:69:28: E261 at least two spaces before inline comment\napp/schemas/fee_schemas.py:70:36: E261 at least two spaces before inline comment\napp/schemas/fee_schemas.py:71:41: E261 at least two spaces before inline comment\napp/schemas/fee_schemas.py:72:26: E261 at least two spaces before inline comment\napp/schemas/fee_schemas.py:73:32: E261 at least two spaces before inline comment\napp/schemas/inventory_schemas.py:10:1: E302 expected 2 blank lines, found 1\napp/schemas/inventory_schemas.py:12:121: E501 line too long (122 > 120 characters)\napp/schemas/inventory_schemas.py:21:1: E302 expected 2 blank lines, found 1\napp/schemas/inventory_schemas.py:24:1: E302 expected 2 blank lines, found 1\napp/schemas/inventory_schemas.py:33:1: E302 expected 2 blank lines, found 1\napp/schemas/inventory_schemas.py:39:1: E302 expected 2 blank lines, found 1\napp/schemas/inventory_schemas.py:46:121: E501 line too long (163 > 120 characters)\napp/schemas/inventory_schemas.py:48:1: E302 expected 2 blank lines, found 1\napp/schemas/inventory_schemas.py:51:1: E302 expected 2 blank lines, found 1\napp/schemas/inventory_schemas.py:62:1: E302 expected 2 blank lines, found 1\napp/schemas/inventory_schemas.py:65:1: E302 expected 2 blank lines, found 1\napp/schemas/inventory_schemas.py:81:1: E302 expected 2 blank lines, found 1\napp/schemas/inventory_schemas.py:93:29: E261 at least two spaces before inline comment\napp/schemas/inventory_schemas.py:101:121: E501 line too long (122 > 120 characters)\napp/schemas/inventory_schemas.py:104:1: E302 expected 2 blank lines, found 1\napp/schemas/inventory_schemas.py:107:1: E302 expected 2 blank lines, found 1\napp/schemas/inventory_schemas.py:114:1: E302 expected 2 blank lines, found 1\napp/schemas/inventory_schemas.py:118:1: E302 expected 2 blank lines, found 1\napp/schemas/inventory_schemas.py:120:22: E261 at least two spaces before inline comment\napp/schemas/inventory_schemas.py:121:48: E261 at least two spaces before inline comment\napp/schemas/inventory_schemas.py:123:1: E302 expected 2 blank lines, found 1\napp/schemas/inventory_schemas.py:128:1: E302 expected 2 blank lines, found 1\napp/schemas/inventory_schemas.py:133:16: E261 at least two spaces before inline comment\napp/schemas/inventory_schemas.py:136:1: E302 expected 2 blank lines, found 1\napp/schemas/refund_schemas.py:5:1: E302 expected 2 blank lines, found 1\napp/schemas/refund_schemas.py:6:17: E261 at least two spaces before inline comment\napp/schemas/refund_schemas.py:9:1: E302 expected 2 blank lines, found 1\napp/schemas/refund_schemas.py:10:51: E261 at least two spaces before inline comment\napp/schemas/refund_schemas.py:13:37: E261 at least two spaces before inline comment\napp/schemas/refund_schemas.py:15:1: E302 expected 2 blank lines, found 1\napp/schemas/refund_schemas.py:17:18: E261 at least two spaces before inline comment\napp/schemas/refund_schemas.py:20:16: E261 at least two spaces before inline comment\napp/schemas/refund_schemas.py:22:20: E261 at least two spaces before inline comment\napp/schemas/refund_schemas.py:25:31: E261 at least two spaces before inline comment\napp/schemas/refund_schemas.py:30:1: E302 expected 2 blank lines, found 1\napp/schemas/refund_schemas.py:33:34: E261 at least two spaces before inline comment\napp/schemas/refund_schemas.py:36:19: E261 at least two spaces before inline comment\napp/schemas/restaurant.py:89:54: W292 no newline at end of file\napp/schemas/search_schemas.py:51:9: E999 IndentationError: unexpected indent\napp/schemas/subscription.py:80:9: E999 IndentationError: unexpected indent\napp/schemas/websocket.py:19:1: W293 blank line contains whitespace\napp/schemas/websocket.py:26:1: W293 blank line contains whitespace\napp/schemas/websocket.py:34:1: W293 blank line contains whitespace\napp/schemas/websocket.py:41:1: W293 blank line contains whitespace\napp/schemas/websocket.py:47:1: W293 blank line contains whitespace\napp/schemas/websocket.py:52:1: W293 blank line contains whitespace\napp/schemas/websocket.py:58:1: W293 blank line contains whitespace\napp/schemas/websocket.py:64:1: W293 blank line contains whitespace\napp/schemas/websocket.py:83:31: W292 no newline at end of file\napp/scripts/initialize_platform_defaults.py:12:1: F401 'typing.Dict' imported but unused\napp/scripts/initialize_platform_defaults.py:12:1: F401 'typing.Any' imported but unused\napp/scripts/initialize_platform_defaults.py:12:1: F401 'typing.List' imported but unused\napp/scripts/initialize_platform_defaults.py:17:1: E402 module level import not at top of file\napp/scripts/initialize_platform_defaults.py:18:1: E402 module level import not at top of file\napp/scripts/initialize_platform_defaults.py:19:27: W291 trailing whitespace\napp/scripts/initialize_platform_defaults.py:33:1: E302 expected 2 blank lines, found 1\napp/scripts/initialize_platform_defaults.py:35:1: W293 blank line contains whitespace\napp/scripts/initialize_platform_defaults.py:48:1: W293 blank line contains whitespace\napp/scripts/initialize_platform_defaults.py:51:1: W293 blank line contains whitespace\napp/scripts/initialize_platform_defaults.py:60:1: W293 blank line contains whitespace\napp/scripts/initialize_platform_defaults.py:63:1: W293 blank line contains whitespace\napp/scripts/initialize_platform_defaults.py:65:1: W293 blank line contains whitespace\napp/scripts/initialize_platform_defaults.py:70:1: W293 blank line contains whitespace\napp/scripts/initialize_platform_defaults.py:74:1: W293 blank line contains whitespace\napp/scripts/initialize_platform_defaults.py:77:1: W293 blank line contains whitespace\napp/scripts/initialize_platform_defaults.py:84:1: W293 blank line contains whitespace\napp/scripts/initialize_platform_defaults.py:89:1: W293 blank line contains whitespace\napp/scripts/initialize_platform_defaults.py:92:1: W293 blank line contains whitespace\napp/scripts/initialize_platform_defaults.py:98:1: W293 blank line contains whitespace\napp/scripts/initialize_platform_defaults.py:107:1: W293 blank line contains whitespace\napp/scripts/initialize_platform_defaults.py:117:1: W293 blank line contains whitespace\napp/scripts/initialize_platform_defaults.py:120:1: W293 blank line contains whitespace\napp/scripts/initialize_platform_defaults.py:124:1: W293 blank line contains whitespace\napp/scripts/initialize_platform_defaults.py:127:1: W293 blank line contains whitespace\napp/scripts/initialize_platform_defaults.py:133:1: W293 blank line contains whitespace\napp/scripts/initialize_platform_defaults.py:141:1: W293 blank line contains whitespace\napp/scripts/initialize_platform_defaults.py:151:1: W293 blank line contains whitespace\napp/scripts/initialize_platform_defaults.py:154:1: W293 blank line contains whitespace\napp/scripts/initialize_platform_defaults.py:158:1: W293 blank line contains whitespace\napp/scripts/initialize_platform_defaults.py:161:1: W293 blank line contains whitespace\napp/scripts/initialize_platform_defaults.py:162:9: F841 local variable 'report' is assigned to but never used\napp/scripts/initialize_platform_defaults.py:186:1: W293 blank line contains whitespace\napp/scripts/initialize_platform_defaults.py:192:1: W293 blank line contains whitespace\napp/scripts/initialize_platform_defaults.py:194:1: W293 blank line contains whitespace\napp/scripts/initialize_platform_defaults.py:197:24: E128 continuation line under-indented for visual indent\napp/scripts/initialize_platform_defaults.py:198:1: W293 blank line contains whitespace\napp/scripts/initialize_platform_defaults.py:200:1: W293 blank line contains whitespace\napp/scripts/initialize_platform_defaults.py:205:1: W293 blank line contains whitespace\napp/scripts/initialize_platform_defaults.py:208:1: W293 blank line contains whitespace\napp/scripts/initialize_platform_defaults.py:217:11: W292 no newline at end of file\napp/scripts/migrate_to_platform_settings.py:13:1: F401 'typing.Tuple' imported but unused\napp/scripts/migrate_to_platform_settings.py:13:1: F401 'typing.Optional' imported but unused\napp/scripts/migrate_to_platform_settings.py:15:1: F401 'sqlalchemy.text' imported but unused\napp/scripts/migrate_to_platform_settings.py:20:1: F401 'app.core.database.Platform' imported but unused\napp/scripts/migrate_to_platform_settings.py:20:1: E402 module level import not at top of file\napp/scripts/migrate_to_platform_settings.py:21:1: E402 module level import not at top of file\napp/scripts/migrate_to_platform_settings.py:22:27: W291 trailing whitespace\napp/scripts/migrate_to_platform_settings.py:23:24: W291 trailing whitespace\napp/scripts/migrate_to_platform_settings.py:42:1: E302 expected 2 blank lines, found 1\napp/scripts/migrate_to_platform_settings.py:44:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:55:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:58:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:70:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:72:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:76:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:81:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:86:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:90:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:95:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:99:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:103:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:110:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:115:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:118:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:124:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:129:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:135:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:140:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:143:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:146:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:148:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:151:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:155:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:157:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:160:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:163:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:167:27: W291 trailing whitespace\napp/scripts/migrate_to_platform_settings.py:174:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:180:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:182:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:185:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:187:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:195:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:205:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:208:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:210:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:214:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:217:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:220:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:224:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:227:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:232:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:237:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:243:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:246:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:251:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:254:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:257:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:261:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:264:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:269:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:272:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:275:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:278:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:282:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:284:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:287:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:292:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:295:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:297:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:302:49: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/scripts/migrate_to_platform_settings.py:305:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:308:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:310:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:313:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:320:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:323:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:326:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:328:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:329:79: W291 trailing whitespace\napp/scripts/migrate_to_platform_settings.py:330:27: E128 continuation line under-indented for visual indent\napp/scripts/migrate_to_platform_settings.py:332:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:335:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:340:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:347:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:356:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:359:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:361:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:365:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:368:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:379:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:381:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:384:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:386:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:391:121: E501 line too long (137 > 120 characters)\napp/scripts/migrate_to_platform_settings.py:393:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:397:121: E501 line too long (121 > 120 characters)\napp/scripts/migrate_to_platform_settings.py:399:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:403:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:407:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:413:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:416:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:418:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:422:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:424:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:427:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:429:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:460:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:463:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:469:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:471:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:473:72: W291 trailing whitespace\napp/scripts/migrate_to_platform_settings.py:474:24: E128 continuation line under-indented for visual indent\napp/scripts/migrate_to_platform_settings.py:475:58: W291 trailing whitespace\napp/scripts/migrate_to_platform_settings.py:476:24: E128 continuation line under-indented for visual indent\napp/scripts/migrate_to_platform_settings.py:477:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:479:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:482:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:487:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:489:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:492:1: W293 blank line contains whitespace\napp/scripts/migrate_to_platform_settings.py:504:11: W292 no newline at end of file\napp/scripts/validate_migration.py:11:1: F401 'json' imported but unused\napp/scripts/validate_migration.py:14:1: F401 'typing.Dict' imported but unused\napp/scripts/validate_migration.py:14:1: F401 'typing.Any' imported but unused\napp/scripts/validate_migration.py:14:1: F401 'typing.List' imported but unused\napp/scripts/validate_migration.py:14:1: F401 'typing.Tuple' imported but unused\napp/scripts/validate_migration.py:14:1: F401 'typing.Optional' imported but unused\napp/scripts/validate_migration.py:16:1: F401 'sqlalchemy.func' imported but unused\napp/scripts/validate_migration.py:21:1: F401 'app.core.database.Platform' imported but unused\napp/scripts/validate_migration.py:21:1: E402 module level import not at top of file\napp/scripts/validate_migration.py:22:1: E402 module level import not at top of file\napp/scripts/validate_migration.py:23:27: W291 trailing whitespace\napp/scripts/validate_migration.py:24:24: W291 trailing whitespace\napp/scripts/validate_migration.py:28:1: E402 module level import not at top of file\napp/scripts/validate_migration.py:38:1: E302 expected 2 blank lines, found 1\napp/scripts/validate_migration.py:40:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:51:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:54:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:57:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:60:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:62:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:67:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:71:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:75:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:79:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:83:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:87:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:91:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:95:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:98:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:100:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:105:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:107:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:112:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:115:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:118:36: W291 trailing whitespace\napp/scripts/validate_migration.py:122:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:129:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:136:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:138:49: W291 trailing whitespace\napp/scripts/validate_migration.py:142:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:145:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:149:35: W291 trailing whitespace\napp/scripts/validate_migration.py:155:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:162:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:169:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:175:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:178:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:180:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:186:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:194:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:197:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:199:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:208:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:216:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:219:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:226:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:233:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:240:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:247:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:250:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:254:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:261:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:268:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:271:61: W291 trailing whitespace\napp/scripts/validate_migration.py:275:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:278:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:281:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:285:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:289:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:292:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:302:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:305:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:310:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:316:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:321:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:324:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:326:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:329:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:331:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:349:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:356:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:363:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:368:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:373:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:382:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:389:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:391:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:397:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:401:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:403:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:410:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:417:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:426:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:428:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:432:40: W291 trailing whitespace\napp/scripts/validate_migration.py:433:41: W291 trailing whitespace\napp/scripts/validate_migration.py:434:32: W291 trailing whitespace\napp/scripts/validate_migration.py:437:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:439:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:444:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:448:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:450:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:456:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:458:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:466:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:474:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:482:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:486:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:492:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:495:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:497:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:506:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:528:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:533:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:538:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:541:121: E501 line too long (185 > 120 characters)\napp/scripts/validate_migration.py:552:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:555:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:561:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:564:1: W293 blank line contains whitespace\napp/scripts/validate_migration.py:572:11: W292 no newline at end of file\napp/services/activity_logger.py:99:9: E999 IndentationError: unexpected indent\napp/services/audit_logger.py:9:1: F401 'app.core.database.get_db' imported but unused\napp/services/audit_logger.py:14:1: E302 expected 2 blank lines, found 1\napp/services/audit_logger.py:61:39: E261 at least two spaces before inline comment\napp/services/audit_logger.py:86:35: E261 at least two spaces before inline comment\napp/services/cache_service.py:8:1: F401 'datetime.datetime' imported but unused\napp/services/cache_service.py:8:1: F401 'datetime.timedelta' imported but unused\napp/services/cache_service.py:11:1: F401 'app.core.config.settings' imported but unused\napp/services/cache_service.py:15:1: E302 expected 2 blank lines, found 1\napp/services/cache_service.py:17:1: W293 blank line contains whitespace\napp/services/cache_service.py:20:1: W293 blank line contains whitespace\napp/services/cache_service.py:25:1: W293 blank line contains whitespace\napp/services/cache_service.py:33:1: W293 blank line contains whitespace\napp/services/cache_service.py:36:1: W293 blank line contains whitespace\napp/services/cache_service.py:39:1: W293 blank line contains whitespace\napp/services/cache_service.py:41:1: W293 blank line contains whitespace\napp/services/cache_service.py:45:1: W293 blank line contains whitespace\napp/services/cache_service.py:53:1: W293 blank line contains whitespace\napp/services/cache_service.py:61:1: W293 blank line contains whitespace\napp/services/cache_service.py:65:1: W293 blank line contains whitespace\napp/services/cache_service.py:73:1: W293 blank line contains whitespace\napp/services/cache_service.py:77:1: W293 blank line contains whitespace\napp/services/cache_service.py:80:25: W292 no newline at end of file\napp/services/config_manager.py:17:1: E302 expected 2 blank lines, found 1\napp/services/config_manager.py:24:1: E302 expected 2 blank lines, found 1\napp/services/config_manager.py:37:1: E302 expected 2 blank lines, found 1\napp/services/config_manager.py:50:1: E302 expected 2 blank lines, found 1\napp/services/config_manager.py:62:1: E302 expected 2 blank lines, found 1\napp/services/config_manager.py:72:1: E302 expected 2 blank lines, found 1\napp/services/config_manager.py:74:1: W293 blank line contains whitespace\napp/services/config_manager.py:79:1: W293 blank line contains whitespace\napp/services/config_manager.py:85:1: W293 blank line contains whitespace\napp/services/config_manager.py:88:1: W293 blank line contains whitespace\napp/services/config_manager.py:97:1: W293 blank line contains whitespace\napp/services/config_manager.py:102:1: W293 blank line contains whitespace\napp/services/config_manager.py:105:1: W293 blank line contains whitespace\napp/services/config_manager.py:108:1: W293 blank line contains whitespace\napp/services/config_manager.py:112:1: W293 blank line contains whitespace\napp/services/config_manager.py:117:1: W293 blank line contains whitespace\napp/services/config_manager.py:125:1: W293 blank line contains whitespace\napp/services/config_manager.py:133:47: W291 trailing whitespace\napp/services/config_manager.py:139:1: W293 blank line contains whitespace\napp/services/config_manager.py:144:1: W293 blank line contains whitespace\napp/services/config_manager.py:149:1: W293 blank line contains whitespace\napp/services/config_manager.py:151:1: W293 blank line contains whitespace\napp/services/config_manager.py:156:1: W293 blank line contains whitespace\napp/services/config_manager.py:159:1: W293 blank line contains whitespace\napp/services/config_manager.py:163:1: W293 blank line contains whitespace\napp/services/config_manager.py:169:1: W293 blank line contains whitespace\napp/services/config_manager.py:175:1: W293 blank line contains whitespace\napp/services/config_manager.py:181:1: W293 blank line contains whitespace\napp/services/config_manager.py:185:1: W293 blank line contains whitespace\napp/services/config_manager.py:188:1: W293 blank line contains whitespace\napp/services/config_manager.py:191:1: W293 blank line contains whitespace\napp/services/config_manager.py:203:1: W293 blank line contains whitespace\napp/services/config_manager.py:208:1: W293 blank line contains whitespace\napp/services/config_manager.py:216:1: W293 blank line contains whitespace\napp/services/config_manager.py:221:1: W293 blank line contains whitespace\napp/services/config_manager.py:224:1: W293 blank line contains whitespace\napp/services/config_manager.py:227:1: W293 blank line contains whitespace\napp/services/config_manager.py:231:1: W293 blank line contains whitespace\napp/services/config_manager.py:239:1: W293 blank line contains whitespace\napp/services/config_manager.py:241:35: F541 f-string is missing placeholders\napp/services/config_manager.py:242:1: W293 blank line contains whitespace\napp/services/config_manager.py:244:35: F541 f-string is missing placeholders\napp/services/config_manager.py:245:1: W293 blank line contains whitespace\napp/services/config_manager.py:249:1: W293 blank line contains whitespace\napp/services/config_manager.py:253:1: W293 blank line contains whitespace\napp/services/config_manager.py:256:1: W293 blank line contains whitespace\napp/services/config_manager.py:263:1: W293 blank line contains whitespace\napp/services/config_manager.py:267:1: W293 blank line contains whitespace\napp/services/config_manager.py:271:1: W293 blank line contains whitespace\napp/services/config_manager.py:275:1: W293 blank line contains whitespace\napp/services/config_manager.py:279:1: W293 blank line contains whitespace\napp/services/config_manager.py:283:1: W293 blank line contains whitespace\napp/services/config_manager.py:287:1: W293 blank line contains whitespace\napp/services/config_manager.py:289:1: W293 blank line contains whitespace\napp/services/config_manager.py:302:1: W293 blank line contains whitespace\napp/services/config_manager.py:311:1: W293 blank line contains whitespace\napp/services/config_manager.py:323:1: W293 blank line contains whitespace\napp/services/config_manager.py:333:1: W293 blank line contains whitespace\napp/services/config_manager.py:341:1: W293 blank line contains whitespace\napp/services/config_manager.py:346:1: W293 blank line contains whitespace\napp/services/config_manager.py:353:1: W293 blank line contains whitespace\napp/services/config_manager.py:355:1: W293 blank line contains whitespace\napp/services/config_manager.py:363:1: W293 blank line contains whitespace\napp/services/config_manager.py:395:1: E305 expected 2 blank lines after class or function definition, found 1\napp/services/config_manager.py:395:40: W292 no newline at end of file\napp/services/digitalocean_monitor.py:12:1: F401 'functools.lru_cache' imported but unused\napp/services/digitalocean_monitor.py:49:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:54:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:61:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:67:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:71:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:75:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:78:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:89:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:93:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:106:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:110:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:115:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:121:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:135:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:145:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:149:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:153:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:158:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:161:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:164:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:171:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:178:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:182:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:188:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:196:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:206:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:211:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:214:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:217:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:224:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:227:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:232:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:239:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:248:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:252:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:256:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:259:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:271:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:273:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:280:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:283:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:287:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:308:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:312:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:314:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:319:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:322:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:325:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:331:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:340:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:343:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:347:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:356:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:362:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:368:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:372:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:375:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:378:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:381:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:388:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:391:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:394:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:403:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:412:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:416:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:420:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:430:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:434:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:438:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:441:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:444:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:470:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:472:1: W293 blank line contains whitespace\napp/services/digitalocean_monitor.py:497:27: W292 no newline at end of file\napp/services/email_service.py:6:1: F401 'os' imported but unused\napp/services/email_service.py:8:1: F401 'typing.Optional' imported but unused\napp/services/email_service.py:8:1: F401 'typing.Dict' imported but unused\napp/services/email_service.py:19:1: E302 expected 2 blank lines, found 1\napp/services/email_service.py:21:1: W293 blank line contains whitespace\napp/services/email_service.py:29:1: W293 blank line contains whitespace\napp/services/email_service.py:35:1: W293 blank line contains whitespace\napp/services/email_service.py:38:1: W293 blank line contains whitespace\napp/services/email_service.py:49:1: W293 blank line contains whitespace\napp/services/email_service.py:52:1: W293 blank line contains whitespace\napp/services/email_service.py:54:1: W293 blank line contains whitespace\napp/services/email_service.py:59:1: W293 blank line contains whitespace\napp/services/email_service.py:63:1: W293 blank line contains whitespace\napp/services/email_service.py:68:1: W293 blank line contains whitespace\napp/services/email_service.py:73:121: E501 line too long (122 > 120 characters)\napp/services/email_service.py:77:121: E501 line too long (149 > 120 characters)\napp/services/email_service.py:85:1: W293 blank line contains whitespace\napp/services/email_service.py:88:51: E225 missing whitespace around operator\napp/services/email_service.py:89:1: W293 blank line contains whitespace\napp/services/email_service.py:102:1: W293 blank line contains whitespace\napp/services/email_service.py:104:1: W293 blank line contains whitespace\napp/services/email_service.py:107:121: E501 line too long (146 > 120 characters)\napp/services/email_service.py:112:1: W293 blank line contains whitespace\napp/services/email_service.py:118:1: W293 blank line contains whitespace\napp/services/email_service.py:124:1: W293 blank line contains whitespace\napp/services/email_service.py:131:1: W293 blank line contains whitespace\napp/services/email_service.py:135:24: F821 undefined name 'to_email'\napp/services/email_service.py:139:1: W293 blank line contains whitespace\napp/services/email_service.py:141:16: F821 undefined name 'tags'\napp/services/email_service.py:142:71: F821 undefined name 'tags'\napp/services/email_service.py:143:1: W293 blank line contains whitespace\napp/services/email_service.py:145:1: W293 blank line contains whitespace\napp/services/email_service.py:147:66: F821 undefined name 'to_email'\napp/services/email_service.py:152:1: W293 blank line contains whitespace\napp/services/email_service.py:156:1: W293 blank line contains whitespace\napp/services/email_service.py:163:1: W293 blank line contains whitespace\napp/services/email_service.py:171:1: W293 blank line contains whitespace\napp/services/email_service.py:178:1: W293 blank line contains whitespace\napp/services/email_service.py:184:1: E305 expected 2 blank lines after class or function definition, found 1\napp/services/email_service.py:185:85: W292 no newline at end of file\napp/services/employee_service.py:6:1: F401 'typing.Dict' imported but unused\napp/services/employee_service.py:6:1: F401 'typing.Any' imported but unused\napp/services/employee_service.py:7:1: F401 'datetime.time' imported but unused\napp/services/employee_service.py:8:1: F401 'decimal.Decimal' imported but unused\napp/services/employee_service.py:10:1: F401 'sqlalchemy.or_' imported but unused\napp/services/employee_service.py:20:1: F401 'app.core.exceptions.ValidationException' imported but unused\napp/services/employee_service.py:20:1: F401 'app.core.exceptions.AuthenticationException' imported but unused\napp/services/employee_service.py:20:1: F401 'app.core.exceptions.ResourceNotFoundException' imported but unused\napp/services/employee_service.py:20:1: F401 'app.core.exceptions.ConflictException' imported but unused\napp/services/employee_service.py:20:121: E501 line too long (138 > 120 characters)\napp/services/employee_service.py:27:1: E302 expected 2 blank lines, found 1\napp/services/employee_service.py:56:1: W293 blank line contains whitespace\napp/services/employee_service.py:60:1: W293 blank line contains whitespace\napp/services/employee_service.py:69:1: W293 blank line contains whitespace\napp/services/employee_service.py:73:1: W293 blank line contains whitespace\napp/services/employee_service.py:77:1: W293 blank line contains whitespace\napp/services/employee_service.py:79:1: W293 blank line contains whitespace\napp/services/employee_service.py:81:1: W293 blank line contains whitespace\napp/services/employee_service.py:99:1: W293 blank line contains whitespace\napp/services/employee_service.py:102:1: W293 blank line contains whitespace\napp/services/employee_service.py:112:1: W293 blank line contains whitespace\napp/services/employee_service.py:114:1: W293 blank line contains whitespace\napp/services/employee_service.py:133:1: W293 blank line contains whitespace\napp/services/employee_service.py:136:1: W293 blank line contains whitespace\napp/services/employee_service.py:139:1: W293 blank line contains whitespace\napp/services/employee_service.py:148:1: W293 blank line contains whitespace\napp/services/employee_service.py:155:1: W293 blank line contains whitespace\napp/services/employee_service.py:165:1: W293 blank line contains whitespace\napp/services/employee_service.py:177:1: W293 blank line contains whitespace\napp/services/employee_service.py:181:1: W293 blank line contains whitespace\napp/services/employee_service.py:191:1: W293 blank line contains whitespace\napp/services/employee_service.py:205:121: E501 line too long (162 > 120 characters)\napp/services/employee_service.py:208:1: W293 blank line contains whitespace\napp/services/employee_service.py:212:1: W293 blank line contains whitespace\napp/services/employee_service.py:215:1: W293 blank line contains whitespace\napp/services/employee_service.py:239:1: W293 blank line contains whitespace\napp/services/employee_service.py:242:1: W293 blank line contains whitespace\napp/services/employee_service.py:252:1: W293 blank line contains whitespace\napp/services/employee_service.py:258:1: W293 blank line contains whitespace\napp/services/employee_service.py:261:1: W293 blank line contains whitespace\napp/services/employee_service.py:264:1: W293 blank line contains whitespace\napp/services/employee_service.py:284:1: W293 blank line contains whitespace\napp/services/employee_service.py:287:1: W293 blank line contains whitespace\napp/services/employee_service.py:297:1: W293 blank line contains whitespace\napp/services/employee_service.py:301:1: W293 blank line contains whitespace\napp/services/employee_service.py:306:1: W293 blank line contains whitespace\napp/services/employee_service.py:308:1: W293 blank line contains whitespace\napp/services/employee_service.py:311:1: W293 blank line contains whitespace\napp/services/employee_service.py:336:1: W293 blank line contains whitespace\napp/services/employee_service.py:338:1: W293 blank line contains whitespace\napp/services/employee_service.py:343:1: W293 blank line contains whitespace\napp/services/employee_service.py:345:1: W293 blank line contains whitespace\napp/services/employee_service.py:347:1: W293 blank line contains whitespace\napp/services/employee_service.py:367:1: W293 blank line contains whitespace\napp/services/employee_service.py:374:47: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/services/employee_service.py:378:1: W293 blank line contains whitespace\napp/services/employee_service.py:380:38: F541 f-string is missing placeholders\napp/services/employee_service.py:381:1: W293 blank line contains whitespace\napp/services/employee_service.py:391:1: W293 blank line contains whitespace\napp/services/employee_service.py:394:1: W293 blank line contains whitespace\napp/services/employee_service.py:397:1: W293 blank line contains whitespace\napp/services/employee_service.py:421:1: W293 blank line contains whitespace\napp/services/employee_service.py:430:1: W293 blank line contains whitespace\napp/services/employee_service.py:433:1: W293 blank line contains whitespace\napp/services/employee_service.py:438:1: W293 blank line contains whitespace\napp/services/employee_service.py:449:1: W293 blank line contains whitespace\napp/services/employee_service.py:451:1: W293 blank line contains whitespace\napp/services/employee_service.py:459:1: W293 blank line contains whitespace\napp/services/employee_service.py:461:1: W293 blank line contains whitespace\napp/services/employee_service.py:464:1: W293 blank line contains whitespace\napp/services/employee_service.py:488:1: W293 blank line contains whitespace\napp/services/employee_service.py:497:1: W293 blank line contains whitespace\napp/services/employee_service.py:500:1: W293 blank line contains whitespace\napp/services/employee_service.py:505:1: W293 blank line contains whitespace\napp/services/employee_service.py:514:1: W293 blank line contains whitespace\napp/services/employee_service.py:516:1: W293 blank line contains whitespace\napp/services/employee_service.py:519:1: W293 blank line contains whitespace\napp/services/employee_service.py:544:1: W293 blank line contains whitespace\napp/services/employee_service.py:547:1: W293 blank line contains whitespace\napp/services/employee_service.py:554:1: W293 blank line contains whitespace\napp/services/employee_service.py:559:1: W293 blank line contains whitespace\napp/services/employee_service.py:563:47: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/services/employee_service.py:566:1: W293 blank line contains whitespace\napp/services/employee_service.py:575:1: W293 blank line contains whitespace\napp/services/employee_service.py:583:47: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/services/employee_service.py:586:1: W293 blank line contains whitespace\napp/services/employee_service.py:588:1: W293 blank line contains whitespace\napp/services/employee_service.py:596:47: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/services/employee_service.py:599:1: W293 blank line contains whitespace\napp/services/employee_service.py:601:1: W293 blank line contains whitespace\napp/services/employee_service.py:606:35: E241 multiple spaces after ','\napp/services/employee_service.py:609:1: W293 blank line contains whitespace\napp/services/employee_service.py:633:1: W293 blank line contains whitespace\napp/services/employee_service.py:638:1: W293 blank line contains whitespace\napp/services/employee_service.py:640:1: W293 blank line contains whitespace\napp/services/employee_service.py:645:47: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/services/employee_service.py:648:1: W293 blank line contains whitespace\napp/services/employee_service.py:652:1: W293 blank line contains whitespace\napp/services/employee_service.py:656:1: W293 blank line contains whitespace\napp/services/employee_service.py:660:1: W293 blank line contains whitespace\napp/services/employee_service.py:669:1: W293 blank line contains whitespace\napp/services/employee_service.py:676:1: W293 blank line contains whitespace\napp/services/employee_service.py:679:1: W293 blank line contains whitespace\napp/services/employee_service.py:688:1: W293 blank line contains whitespace\napp/services/employee_service.py:690:1: W293 blank line contains whitespace\napp/services/employee_service.py:696:54: E202 whitespace before ')'\napp/services/employee_service.py:697:1: W293 blank line contains whitespace\napp/services/employee_service.py:705:1: W293 blank line contains whitespace\napp/services/employee_service.py:726:1: W293 blank line contains whitespace\napp/services/employee_service.py:728:1: W293 blank line contains whitespace\napp/services/employee_service.py:733:1: W293 blank line contains whitespace\napp/services/employee_service.py:735:1: W293 blank line contains whitespace\napp/services/employee_service.py:737:1: W293 blank line contains whitespace\napp/services/employee_service.py:758:1: W293 blank line contains whitespace\napp/services/employee_service.py:762:1: W293 blank line contains whitespace\napp/services/employee_service.py:767:1: W293 blank line contains whitespace\napp/services/employee_service.py:769:1: W293 blank line contains whitespace\napp/services/employee_service.py:771:1: W293 blank line contains whitespace\napp/services/employee_service.py:792:1: W293 blank line contains whitespace\napp/services/employee_service.py:797:1: W293 blank line contains whitespace\napp/services/employee_service.py:803:1: W293 blank line contains whitespace\napp/services/employee_service.py:806:1: W293 blank line contains whitespace\napp/services/employee_service.py:808:1: W293 blank line contains whitespace\napp/services/employee_service.py:828:1: W293 blank line contains whitespace\napp/services/employee_service.py:833:1: W293 blank line contains whitespace\napp/services/employee_service.py:836:1: W293 blank line contains whitespace\napp/services/employee_service.py:838:1: W293 blank line contains whitespace\napp/services/employee_service.py:845:73: W292 no newline at end of file\napp/services/financial_records_service.py:2:1: F401 'typing.Optional' imported but unused\napp/services/financial_records_service.py:7:1: F401 'app.schemas.fee_schemas.StaffTipDistributionRecordSchema' imported but unused\napp/services/financial_records_service.py:7:1: F401 'app.schemas.fee_schemas.PaymentMethodEnum' imported but unused\napp/services/financial_records_service.py:11:1: E302 expected 2 blank lines, found 1\napp/services/financial_records_service.py:26:50: E261 at least two spaces before inline comment\napp/services/financial_records_service.py:30:61: E261 at least two spaces before inline comment\napp/services/financial_records_service.py:41:17: E261 at least two spaces before inline comment\napp/services/financial_records_service.py:78:105: F821 undefined name 'staff_id'\napp/services/financial_records_service.py:79:12: F821 undefined name 'start_date'\napp/services/financial_records_service.py:80:87: F821 undefined name 'start_date'\napp/services/financial_records_service.py:81:12: F821 undefined name 'end_date'\napp/services/financial_records_service.py:82:87: F821 undefined name 'end_date'\napp/services/instance_tracker.py:24:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:28:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:38:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:44:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:47:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:57:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:63:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:66:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:69:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:72:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:77:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:80:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:88:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:91:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:112:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:120:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:122:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:125:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:133:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:143:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:153:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:155:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:158:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:161:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:166:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:178:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:187:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:192:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:195:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:197:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:201:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:207:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:213:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:219:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:222:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:227:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:230:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:236:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:241:1: W293 blank line contains whitespace\napp/services/instance_tracker.py:263:5: F824 `global instance_tracker` is unused: name is never assigned in scope\napp/services/instance_tracker.py:266:48: W292 no newline at end of file\napp/services/inventory_service.py:8:1: F401 'app.core.exceptions.InventoryException' imported but unused\napp/services/inventory_service.py:9:15: E261 at least two spaces before inline comment\napp/services/inventory_service.py:11:121: E501 line too long (148 > 120 characters)\napp/services/inventory_service.py:19:1: E302 expected 2 blank lines, found 1\napp/services/inventory_service.py:46:68: E261 at least two spaces before inline comment\napp/services/inventory_service.py:46:121: E501 line too long (123 > 120 characters)\napp/services/inventory_service.py:47:121: E501 line too long (121 > 120 characters)\napp/services/inventory_service.py:61:47: E261 at least two spaces before inline comment\napp/services/inventory_service.py:64:121: E501 line too long (125 > 120 characters)\napp/services/inventory_service.py:98:37: E261 at least two spaces before inline comment\napp/services/inventory_service.py:103:121: E501 line too long (142 > 120 characters)\napp/services/inventory_service.py:110:58: E261 at least two spaces before inline comment\napp/services/inventory_service.py:113:121: E501 line too long (192 > 120 characters)\napp/services/inventory_service.py:156:74: E261 at least two spaces before inline comment\napp/services/inventory_service.py:158:26: E111 indentation is not a multiple of 4\napp/services/inventory_service.py:158:26: E117 over-indented\napp/services/inventory_service.py:159:29: E121 continuation line under-indented for hanging indent\napp/services/inventory_service.py:165:25: E122 continuation line missing indentation or outdented\napp/services/inventory_service.py:172:121: E501 line too long (133 > 120 characters)\napp/services/monitoring.py:7:1: F401 'asyncio' imported but unused\napp/services/monitoring.py:10:1: F401 'decimal.Decimal' imported but unused\napp/services/monitoring.py:14:1: F401 'json' imported but unused\napp/services/monitoring.py:25:1: E302 expected 2 blank lines, found 1\napp/services/monitoring.py:32:1: E302 expected 2 blank lines, found 1\napp/services/monitoring.py:41:1: E302 expected 2 blank lines, found 1\napp/services/monitoring.py:56:1: E302 expected 2 blank lines, found 1\napp/services/monitoring.py:67:1: E302 expected 2 blank lines, found 1\napp/services/monitoring.py:69:1: W293 blank line contains whitespace\napp/services/monitoring.py:74:1: W293 blank line contains whitespace\napp/services/monitoring.py:84:1: W293 blank line contains whitespace\napp/services/monitoring.py:90:1: W293 blank line contains whitespace\napp/services/monitoring.py:94:1: W293 blank line contains whitespace\napp/services/monitoring.py:103:1: W293 blank line contains whitespace\napp/services/monitoring.py:108:1: W293 blank line contains whitespace\napp/services/monitoring.py:112:1: W293 blank line contains whitespace\napp/services/monitoring.py:116:1: W293 blank line contains whitespace\napp/services/monitoring.py:120:1: W293 blank line contains whitespace\napp/services/monitoring.py:124:1: W293 blank line contains whitespace\napp/services/monitoring.py:127:61: W291 trailing whitespace\napp/services/monitoring.py:130:1: W293 blank line contains whitespace\napp/services/monitoring.py:135:1: W293 blank line contains whitespace\napp/services/monitoring.py:140:1: W293 blank line contains whitespace\napp/services/monitoring.py:145:1: W293 blank line contains whitespace\napp/services/monitoring.py:147:1: W293 blank line contains whitespace\napp/services/monitoring.py:152:1: W293 blank line contains whitespace\napp/services/monitoring.py:158:1: W293 blank line contains whitespace\napp/services/monitoring.py:164:1: W293 blank line contains whitespace\napp/services/monitoring.py:171:1: W293 blank line contains whitespace\napp/services/monitoring.py:173:1: W293 blank line contains whitespace\napp/services/monitoring.py:180:121: E501 line too long (161 > 120 characters)\napp/services/monitoring.py:186:1: W293 blank line contains whitespace\napp/services/monitoring.py:189:1: W293 blank line contains whitespace\napp/services/monitoring.py:191:1: W293 blank line contains whitespace\napp/services/monitoring.py:193:1: W293 blank line contains whitespace\napp/services/monitoring.py:200:1: W293 blank line contains whitespace\napp/services/monitoring.py:205:1: W293 blank line contains whitespace\napp/services/monitoring.py:211:1: W293 blank line contains whitespace\napp/services/monitoring.py:215:1: W293 blank line contains whitespace\napp/services/monitoring.py:218:1: W293 blank line contains whitespace\napp/services/monitoring.py:224:121: E501 line too long (151 > 120 characters)\napp/services/monitoring.py:231:1: W293 blank line contains whitespace\napp/services/monitoring.py:234:1: W293 blank line contains whitespace\napp/services/monitoring.py:236:1: W293 blank line contains whitespace\napp/services/monitoring.py:238:1: W293 blank line contains whitespace\napp/services/monitoring.py:245:1: W293 blank line contains whitespace\napp/services/monitoring.py:251:1: W293 blank line contains whitespace\napp/services/monitoring.py:257:1: W293 blank line contains whitespace\napp/services/monitoring.py:260:1: W293 blank line contains whitespace\napp/services/monitoring.py:265:1: W293 blank line contains whitespace\napp/services/monitoring.py:269:1: W293 blank line contains whitespace\napp/services/monitoring.py:276:31: F541 f-string is missing placeholders\napp/services/monitoring.py:277:121: E501 line too long (124 > 120 characters)\napp/services/monitoring.py:283:1: W293 blank line contains whitespace\napp/services/monitoring.py:286:1: W293 blank line contains whitespace\napp/services/monitoring.py:288:1: W293 blank line contains whitespace\napp/services/monitoring.py:304:1: W293 blank line contains whitespace\napp/services/monitoring.py:307:1: W293 blank line contains whitespace\napp/services/monitoring.py:309:1: W293 blank line contains whitespace\napp/services/monitoring.py:316:1: W293 blank line contains whitespace\napp/services/monitoring.py:322:1: W293 blank line contains whitespace\napp/services/monitoring.py:327:1: W293 blank line contains whitespace\napp/services/monitoring.py:336:1: W293 blank line contains whitespace\napp/services/monitoring.py:344:121: E501 line too long (195 > 120 characters)\napp/services/monitoring.py:352:1: W293 blank line contains whitespace\napp/services/monitoring.py:355:1: W293 blank line contains whitespace\napp/services/monitoring.py:357:1: W293 blank line contains whitespace\napp/services/monitoring.py:364:1: W293 blank line contains whitespace\napp/services/monitoring.py:370:1: W293 blank line contains whitespace\napp/services/monitoring.py:380:1: W293 blank line contains whitespace\napp/services/monitoring.py:389:121: E501 line too long (151 > 120 characters)\napp/services/monitoring.py:394:1: W293 blank line contains whitespace\napp/services/monitoring.py:397:1: W293 blank line contains whitespace\napp/services/monitoring.py:399:1: W293 blank line contains whitespace\napp/services/monitoring.py:401:1: W293 blank line contains whitespace\napp/services/monitoring.py:408:1: W293 blank line contains whitespace\napp/services/monitoring.py:412:1: W293 blank line contains whitespace\napp/services/monitoring.py:418:1: W293 blank line contains whitespace\napp/services/monitoring.py:420:1: W293 blank line contains whitespace\napp/services/monitoring.py:435:1: W293 blank line contains whitespace\napp/services/monitoring.py:449:1: W293 blank line contains whitespace\napp/services/monitoring.py:452:1: W293 blank line contains whitespace\napp/services/monitoring.py:455:1: W293 blank line contains whitespace\napp/services/monitoring.py:459:1: W293 blank line contains whitespace\napp/services/monitoring.py:462:1: W293 blank line contains whitespace\napp/services/monitoring.py:466:1: W293 blank line contains whitespace\napp/services/monitoring.py:471:1: W293 blank line contains whitespace\napp/services/monitoring.py:475:1: W293 blank line contains whitespace\napp/services/monitoring.py:481:1: W293 blank line contains whitespace\napp/services/monitoring.py:487:1: W293 blank line contains whitespace\napp/services/monitoring.py:489:90: E226 missing whitespace around arithmetic operator\napp/services/monitoring.py:490:1: W293 blank line contains whitespace\napp/services/monitoring.py:493:1: W293 blank line contains whitespace\napp/services/monitoring.py:505:1: W293 blank line contains whitespace\napp/services/monitoring.py:512:1: W293 blank line contains whitespace\napp/services/monitoring.py:520:1: W293 blank line contains whitespace\napp/services/monitoring.py:527:1: E305 expected 2 blank lines after class or function definition, found 1\napp/services/monitoring.py:529:1: E302 expected 2 blank lines, found 1\napp/services/monitoring.py:534:31: W292 no newline at end of file\napp/services/ocr_service.py:7:1: E302 expected 2 blank lines, found 1\napp/services/ocr_service.py:28:9: F821 undefined name 'logger'\napp/services/ocr_service.py:42:9: F821 undefined name 'logger'\napp/services/ocr_service.py:54:18: E111 indentation is not a multiple of 4\napp/services/ocr_service.py:54:18: E117 over-indented\napp/services/ocr_service.py:55:21: E121 continuation line under-indented for hanging indent\napp/services/ocr_service.py:55:121: E501 line too long (147 > 120 characters)\napp/services/ocr_service.py:56:121: E501 line too long (150 > 120 characters)\napp/services/ocr_service.py:57:121: E501 line too long (155 > 120 characters)\napp/services/ocr_service.py:58:17: E122 continuation line missing indentation or outdented\napp/services/ocr_service.py:60:17: E261 at least two spaces before inline comment\napp/services/ocr_service.py:63:121: E501 line too long (148 > 120 characters)\napp/services/ocr_service.py:64:121: E501 line too long (152 > 120 characters)\napp/services/ocr_service.py:65:121: E501 line too long (168 > 120 characters)\napp/services/ocr_service.py:65:147: E261 at least two spaces before inline comment\napp/services/ocr_service.py:104:121: E501 line too long (127 > 120 characters)\napp/services/ocr_service.py:111:1: E302 expected 2 blank lines, found 1\napp/services/payment_analytics.py:15:1: F401 'app.services.payment_providers.PaymentProvider' imported but unused\napp/services/payment_analytics.py:19:1: E302 expected 2 blank lines, found 1\napp/services/payment_analytics.py:21:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:24:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:26:14: W291 trailing whitespace\napp/services/payment_analytics.py:32:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:38:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:44:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:48:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:50:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:61:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:64:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:69:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:73:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:76:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:81:121: E501 line too long (129 > 120 characters)\napp/services/payment_analytics.py:82:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:85:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:88:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:114:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:116:14: W291 trailing whitespace\napp/services/payment_analytics.py:121:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:124:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:139:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:142:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:144:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:153:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:158:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:162:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:168:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:172:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:175:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:185:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:187:14: W291 trailing whitespace\napp/services/payment_analytics.py:193:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:198:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:201:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:204:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:208:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:213:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:222:121: E501 line too long (131 > 120 characters)\napp/services/payment_analytics.py:235:121: E501 line too long (150 > 120 characters)\napp/services/payment_analytics.py:239:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:241:14: W291 trailing whitespace\napp/services/payment_analytics.py:245:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:250:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:258:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:262:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:265:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:267:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:273:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:277:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:279:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:283:121: E501 line too long (151 > 120 characters)\napp/services/payment_analytics.py:285:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:288:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:291:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:293:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:297:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:318:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:320:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:326:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:328:14: W291 trailing whitespace\napp/services/payment_analytics.py:329:31: W291 trailing whitespace\napp/services/payment_analytics.py:333:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:335:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:342:121: E501 line too long (124 > 120 characters)\napp/services/payment_analytics.py:343:121: E501 line too long (131 > 120 characters)\napp/services/payment_analytics.py:354:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:358:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:367:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:369:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:372:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:375:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:384:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:389:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:391:121: E501 line too long (157 > 120 characters)\napp/services/payment_analytics.py:392:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:396:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:405:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:410:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:412:14: W291 trailing whitespace\napp/services/payment_analytics.py:413:35: W291 trailing whitespace\napp/services/payment_analytics.py:414:33: W291 trailing whitespace\napp/services/payment_analytics.py:418:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:422:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:433:121: E501 line too long (124 > 120 characters)\napp/services/payment_analytics.py:437:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:451:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:453:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:455:14: W291 trailing whitespace\napp/services/payment_analytics.py:456:23: W291 trailing whitespace\napp/services/payment_analytics.py:457:36: W291 trailing whitespace\napp/services/payment_analytics.py:461:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:469:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:476:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:481:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:484:121: E501 line too long (144 > 120 characters)\napp/services/payment_analytics.py:488:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:492:38: E226 missing whitespace around arithmetic operator\napp/services/payment_analytics.py:493:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:497:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:501:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:504:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:513:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:515:44: W291 trailing whitespace\napp/services/payment_analytics.py:518:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:528:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:534:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:537:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:540:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:544:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:547:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:549:121: E501 line too long (127 > 120 characters)\napp/services/payment_analytics.py:550:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:552:121: E501 line too long (150 > 120 characters)\napp/services/payment_analytics.py:553:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:563:1: W293 blank line contains whitespace\napp/services/payment_analytics.py:569:10: W292 no newline at end of file\napp/services/payment_config_service.py:7:85: E261 at least two spaces before inline comment\napp/services/payment_config_service.py:7:121: E501 line too long (122 > 120 characters)\napp/services/payment_config_service.py:11:1: E302 expected 2 blank lines, found 1\napp/services/payment_config_service.py:23:32: F821 undefined name 'payment_method'\napp/services/payment_config_service.py:26:12: F821 undefined name 'restaurant_id'\napp/services/payment_config_service.py:28:55: F821 undefined name 'restaurant_id'\napp/services/payment_config_service.py:32:97: F821 undefined name 'restaurant_id'\napp/services/payment_config_service.py:37:58: E261 at least two spaces before inline comment\napp/services/payment_config_service.py:59:121: E501 line too long (125 > 120 characters)\napp/services/payment_config_service.py:76:121: E501 line too long (134 > 120 characters)\napp/services/payment_config_service.py:93:121: E501 line too long (126 > 120 characters)\napp/services/payment_config_service.py:100:121: E501 line too long (140 > 120 characters)\napp/services/payment_config_service.py:126:121: E501 line too long (149 > 120 characters)\napp/services/payment_config_service.py:130:121: E501 line too long (137 > 120 characters)\napp/services/payment_config_service.py:141:23: E261 at least two spaces before inline comment\napp/services/payment_config_service.py:148:121: E501 line too long (124 > 120 characters)\napp/services/payment_config_service.py:149:14: E261 at least two spaces before inline comment\napp/services/payment_config_service.py:156:121: E501 line too long (121 > 120 characters)\napp/services/payment_config_service.py:163:121: E501 line too long (124 > 120 characters)\napp/services/payment_config_service.py:171:121: E501 line too long (127 > 120 characters)\napp/services/payment_config_service.py:179:25: E261 at least two spaces before inline comment\napp/services/payment_factory.py:1:1: F401 'typing.Any' imported but unused\napp/services/payment_factory.py:5:1: F401 '.payment_providers.square_provider.SquareProvider' imported but unused\napp/services/payment_factory.py:11:1: F401 '..core.database.get_db' imported but unused\napp/services/payment_factory.py:16:1: E302 expected 2 blank lines, found 1\napp/services/payment_factory.py:18:1: W293 blank line contains whitespace\napp/services/payment_factory.py:20:60: E261 at least two spaces before inline comment\napp/services/payment_factory.py:31:1: W293 blank line contains whitespace\napp/services/payment_factory.py:39:1: W293 blank line contains whitespace\napp/services/payment_factory.py:48:1: W293 blank line contains whitespace\napp/services/payment_factory.py:50:75: W504 line break after binary operator\napp/services/payment_factory.py:51:13: E129 visually indented line with same indent as next logical line\napp/services/payment_factory.py:61:81: E261 at least two spaces before inline comment\napp/services/payment_factory.py:83:19: E251 unexpected spaces around keyword / parameter equals\napp/services/payment_factory.py:83:21: E251 unexpected spaces around keyword / parameter equals\napp/services/payment_factory.py:84:30: E261 at least two spaces before inline comment\napp/services/payment_factory.py:98:1: W293 blank line contains whitespace\napp/services/payment_factory.py:102:1: W293 blank line contains whitespace\napp/services/payment_factory.py:112:1: W293 blank line contains whitespace\napp/services/payment_factory.py:123:1: W293 blank line contains whitespace\napp/services/payment_factory.py:126:1: W293 blank line contains whitespace\napp/services/payment_factory.py:134:1: W293 blank line contains whitespace\napp/services/payment_factory.py:138:1: W293 blank line contains whitespace\napp/services/payment_factory.py:141:1: W293 blank line contains whitespace\napp/services/payment_factory.py:144:1: W293 blank line contains whitespace\napp/services/payment_factory.py:152:1: W293 blank line contains whitespace\napp/services/payment_factory.py:156:1: W293 blank line contains whitespace\napp/services/payment_factory.py:158:1: W293 blank line contains whitespace\napp/services/payment_factory.py:166:1: W293 blank line contains whitespace\napp/services/payment_factory.py:170:1: W293 blank line contains whitespace\napp/services/payment_factory.py:174:1: W293 blank line contains whitespace\napp/services/payment_factory.py:184:1: W293 blank line contains whitespace\napp/services/payment_factory.py:186:1: W293 blank line contains whitespace\napp/services/payment_factory.py:194:9: F841 local variable 'e' is assigned to but never used\napp/services/payment_factory.py:197:1: W293 blank line contains whitespace\napp/services/payment_factory.py:201:1: W293 blank line contains whitespace\napp/services/payment_factory.py:205:19: E251 unexpected spaces around keyword / parameter equals\napp/services/payment_factory.py:205:21: E251 unexpected spaces around keyword / parameter equals\napp/services/payment_factory.py:210:1: W293 blank line contains whitespace\napp/services/payment_factory.py:215:1: W293 blank line contains whitespace\napp/services/payment_factory.py:220:19: E251 unexpected spaces around keyword / parameter equals\napp/services/payment_factory.py:220:21: E251 unexpected spaces around keyword / parameter equals\napp/services/payment_factory.py:225:1: W293 blank line contains whitespace\napp/services/payment_factory.py:232:1: W293 blank line contains whitespace\napp/services/payment_factory.py:236:19: E251 unexpected spaces around keyword / parameter equals\napp/services/payment_factory.py:236:21: E251 unexpected spaces around keyword / parameter equals\napp/services/payment_factory.py:241:1: W293 blank line contains whitespace\napp/services/payment_factory.py:246:1: W293 blank line contains whitespace\napp/services/payment_factory.py:261:1: E305 expected 2 blank lines after class or function definition, found 1\napp/services/payment_factory.py:264:1: E302 expected 2 blank lines, found 1\napp/services/payment_factory.py:266:55: W292 no newline at end of file\napp/services/payment_fee_calculator.py:10:1: E302 expected 2 blank lines, found 1\napp/services/payment_fee_calculator.py:33:121: E501 line too long (128 > 120 characters)\napp/services/payment_fee_calculator.py:34:121: E501 line too long (122 > 120 characters)\napp/services/payment_fee_calculator.py:65:121: E501 line too long (125 > 120 characters)\napp/services/payment_fee_calculator.py:83:21: E261 at least two spaces before inline comment\napp/services/payment_fee_calculator.py:116:43: E261 at least two spaces before inline comment\napp/services/payment_fee_calculator.py:116:121: E501 line too long (131 > 120 characters)\napp/services/payment_fee_calculator.py:118:121: E501 line too long (133 > 120 characters)\napp/services/payment_fee_calculator.py:137:121: E501 line too long (123 > 120 characters)\napp/services/payment_providers.py:13:1: E302 expected 2 blank lines, found 1\napp/services/payment_providers.py:20:1: E302 expected 2 blank lines, found 1\napp/services/payment_providers.py:22:1: W293 blank line contains whitespace\napp/services/payment_providers.py:26:1: W293 blank line contains whitespace\napp/services/payment_providers.py:38:1: W293 blank line contains whitespace\napp/services/payment_providers.py:53:1: W293 blank line contains whitespace\napp/services/payment_providers.py:63:1: W293 blank line contains whitespace\napp/services/payment_providers.py:75:1: W293 blank line contains whitespace\napp/services/payment_providers.py:84:31: F821 undefined name 'transaction_id'\napp/services/payment_providers.py:85:23: F821 undefined name 'status'\napp/services/payment_providers.py:91:29: F821 undefined name 'provider_response'\napp/services/payment_providers.py:92:25: F821 undefined name 'provider_response'\napp/services/payment_providers.py:96:1: E305 expected 2 blank lines after class or function definition, found 1\napp/services/payment_providers.py:102:2: W292 no newline at end of file\napp/services/payment_providers/__init__.py:18:2: W292 no newline at end of file\napp/services/payment_providers/base.py:28:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:32:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:39:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:44:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:49:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:52:14: W291 trailing whitespace\napp/services/payment_providers/base.py:53:25: W291 trailing whitespace\napp/services/payment_providers/base.py:62:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:70:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:80:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:83:14: W291 trailing whitespace\napp/services/payment_providers/base.py:89:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:93:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:98:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:108:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:113:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:118:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:126:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:129:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:134:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:143:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:147:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:152:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:160:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:163:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:168:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:172:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:175:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:182:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:186:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:190:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:194:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:198:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:202:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:206:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:210:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:214:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:218:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:224:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:228:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:232:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:237:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:241:1: W293 blank line contains whitespace\napp/services/payment_providers/base.py:260:14: W292 no newline at end of file\napp/services/payment_providers/base_provider.py:6:1: E302 expected 2 blank lines, found 1\napp/services/payment_providers/base_provider.py:13:1: E302 expected 2 blank lines, found 1\napp/services/payment_providers/base_provider.py:16:30: E261 at least two spaces before inline comment\napp/services/payment_providers/base_provider.py:18:1: E302 expected 2 blank lines, found 1\napp/services/payment_providers/base_provider.py:22:29: E261 at least two spaces before inline comment\napp/services/payment_providers/base_provider.py:26:40: E261 at least two spaces before inline comment\napp/services/payment_providers/base_provider.py:47:1: E302 expected 2 blank lines, found 1\napp/services/payment_providers/base_provider.py:47:48: E261 at least two spaces before inline comment\napp/services/payment_providers/base_provider.py:80:20: E261 at least two spaces before inline comment\napp/services/payment_providers/cash_provider.py:7:65: E261 at least two spaces before inline comment\napp/services/payment_providers/cash_provider.py:13:1: E302 expected 2 blank lines, found 1\napp/services/payment_providers/cash_provider.py:13:21: E261 at least two spaces before inline comment\napp/services/payment_providers/cash_provider.py:20:1: E302 expected 2 blank lines, found 1\napp/services/payment_providers/cash_provider.py:52:121: E501 line too long (145 > 120 characters)\napp/services/payment_providers/cash_provider.py:64:121: E501 line too long (130 > 120 characters)\napp/services/payment_providers/cash_provider.py:68:54: E261 at least two spaces before inline comment\napp/services/payment_providers/cash_provider.py:69:45: E261 at least two spaces before inline comment\napp/services/payment_providers/cash_provider.py:80:29: E261 at least two spaces before inline comment\napp/services/payment_providers/cash_provider.py:84:40: E261 at least two spaces before inline comment\napp/services/payment_providers/cash_provider.py:91:121: E501 line too long (129 > 120 characters)\napp/services/payment_providers/cash_provider.py:107:54: E261 at least two spaces before inline comment\napp/services/payment_providers/cash_provider.py:108:46: E261 at least two spaces before inline comment\napp/services/payment_providers/cash_provider.py:121:121: E501 line too long (123 > 120 characters)\napp/services/payment_providers/cash_provider.py:125:29: E261 at least two spaces before inline comment\napp/services/payment_providers/cash_provider.py:126:55: E261 at least two spaces before inline comment\napp/services/payment_providers/cash_provider.py:129:26: E261 at least two spaces before inline comment\napp/services/payment_providers/payment_factory.py:22:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:25:31: F821 undefined name 'SecurePaymentConfig'\napp/services/payment_providers/payment_factory.py:27:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:32:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:36:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:46:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:49:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:53:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:57:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:66:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:73:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:75:41: W504 line break after binary operator\napp/services/payment_providers/payment_factory.py:75:44: W291 trailing whitespace\napp/services/payment_providers/payment_factory.py:76:76: W504 line break after binary operator\napp/services/payment_providers/payment_factory.py:77:5: E129 visually indented line with same indent as next logical line\napp/services/payment_providers/payment_factory.py:78:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:81:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:84:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:92:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:96:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:101:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:104:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:106:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:115:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:119:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:121:41: W504 line break after binary operator\napp/services/payment_providers/payment_factory.py:121:44: W291 trailing whitespace\napp/services/payment_providers/payment_factory.py:122:76: W504 line break after binary operator\napp/services/payment_providers/payment_factory.py:123:5: E129 visually indented line with same indent as next logical line\napp/services/payment_providers/payment_factory.py:124:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:127:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:135:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:140:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:142:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:156:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:160:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:167:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:171:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:173:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:181:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:185:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:189:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:195:53: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/services/payment_providers/payment_factory.py:199:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:203:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:206:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:211:32: F821 undefined name 'PaymentTransaction'\napp/services/payment_providers/payment_factory.py:214:30: F821 undefined name 'PaymentTransaction'\napp/services/payment_providers/payment_factory.py:220:21: F821 undefined name 'PaymentTransaction'\napp/services/payment_providers/payment_factory.py:221:21: F821 undefined name 'PaymentTransaction'\napp/services/payment_providers/payment_factory.py:224:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:226:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:231:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:239:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:243:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:254:1: W293 blank line contains whitespace\napp/services/payment_providers/payment_factory.py:255:20: W292 no newline at end of file\napp/services/payment_providers/square_provider.py:27:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:32:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:39:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:46:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:49:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:53:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:58:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:61:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:65:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:67:14: W291 trailing whitespace\napp/services/payment_providers/square_provider.py:68:25: W291 trailing whitespace\napp/services/payment_providers/square_provider.py:82:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:85:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:95:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:99:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:102:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:111:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:113:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:117:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:126:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:135:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:137:14: W291 trailing whitespace\napp/services/payment_providers/square_provider.py:146:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:153:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:155:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:161:55: W291 trailing whitespace\napp/services/payment_providers/square_provider.py:166:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:174:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:185:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:192:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:195:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:204:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:212:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:214:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:221:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:223:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:235:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:243:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:251:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:259:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:261:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:274:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:283:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:294:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:297:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:305:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:307:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:311:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:320:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:328:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:330:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:337:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:345:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:356:1: W293 blank line contains whitespace\napp/services/payment_providers/square_provider.py:366:67: W292 no newline at end of file\napp/services/payment_providers/stripe_provider.py:18:1: W293 blank line contains whitespace\napp/services/payment_providers/stripe_provider.py:24:1: W293 blank line contains whitespace\napp/services/payment_providers/stripe_provider.py:27:1: W293 blank line contains whitespace\napp/services/payment_providers/stripe_provider.py:33:1: W293 blank line contains whitespace\napp/services/payment_providers/stripe_provider.py:35:14: W291 trailing whitespace\napp/services/payment_providers/stripe_provider.py:36:25: W291 trailing whitespace\napp/services/payment_providers/stripe_provider.py:47:1: W293 blank line contains whitespace\napp/services/payment_providers/stripe_provider.py:60:1: W293 blank line contains whitespace\napp/services/payment_providers/stripe_provider.py:64:1: W293 blank line contains whitespace\napp/services/payment_providers/stripe_provider.py:72:1: W293 blank line contains whitespace\napp/services/payment_providers/stripe_provider.py:75:1: W293 blank line contains whitespace\napp/services/payment_providers/stripe_provider.py:79:1: W293 blank line contains whitespace\napp/services/payment_providers/stripe_provider.py:88:1: W293 blank line contains whitespace\napp/services/payment_providers/stripe_provider.py:106:1: W293 blank line contains whitespace\napp/services/payment_providers/stripe_provider.py:108:14: W291 trailing whitespace\napp/services/payment_providers/stripe_provider.py:117:1: W293 blank line contains whitespace\napp/services/payment_providers/stripe_provider.py:119:1: W293 blank line contains whitespace\napp/services/payment_providers/stripe_provider.py:127:1: W293 blank line contains whitespace\napp/services/payment_providers/stripe_provider.py:135:1: W293 blank line contains whitespace\napp/services/payment_providers/stripe_provider.py:151:1: W293 blank line contains whitespace\napp/services/payment_providers/stripe_provider.py:156:1: W293 blank line contains whitespace\napp/services/payment_providers/stripe_provider.py:165:1: W293 blank line contains whitespace\napp/services/payment_providers/stripe_provider.py:167:1: W293 blank line contains whitespace\napp/services/payment_providers/stripe_provider.py:176:1: W293 blank line contains whitespace\napp/services/payment_providers/stripe_provider.py:184:1: W293 blank line contains whitespace\napp/services/payment_providers/stripe_provider.py:192:1: W293 blank line contains whitespace\napp/services/payment_providers/stripe_provider.py:202:1: W293 blank line contains whitespace\napp/services/payment_providers/stripe_provider.py:211:1: W293 blank line contains whitespace\napp/services/payment_providers/stripe_provider.py:221:1: W293 blank line contains whitespace\napp/services/payment_providers/stripe_provider.py:224:1: W293 blank line contains whitespace\napp/services/payment_providers/stripe_provider.py:229:1: W293 blank line contains whitespace\napp/services/payment_providers/stripe_provider.py:236:1: W293 blank line contains whitespace\napp/services/payment_providers/stripe_provider.py:247:1: W293 blank line contains whitespace\napp/services/payment_providers/stripe_provider.py:255:1: W293 blank line contains whitespace\napp/services/payment_providers/stripe_provider.py:262:1: W293 blank line contains whitespace\napp/services/payment_providers/stripe_provider.py:270:1: W293 blank line contains whitespace\napp/services/payment_providers/stripe_provider.py:283:67: W292 no newline at end of file\napp/services/payment_providers/sumup_provider.py:17:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:20:121: E501 line too long (124 > 120 characters)\napp/services/payment_providers/sumup_provider.py:30:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:36:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:40:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:43:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:46:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:50:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:52:14: W291 trailing whitespace\napp/services/payment_providers/sumup_provider.py:53:25: W291 trailing whitespace\napp/services/payment_providers/sumup_provider.py:72:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:76:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:79:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:86:121: E501 line too long (123 > 120 characters)\napp/services/payment_providers/sumup_provider.py:88:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:90:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:94:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:103:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:112:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:114:14: W291 trailing whitespace\napp/services/payment_providers/sumup_provider.py:124:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:131:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:133:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:146:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:152:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:160:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:172:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:192:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:197:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:202:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:207:121: E501 line too long (123 > 120 characters)\napp/services/payment_providers/sumup_provider.py:209:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:211:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:220:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:228:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:237:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:248:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:251:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:254:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:276:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:283:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:292:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:303:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:306:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:310:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:316:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:318:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:322:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:331:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:340:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:342:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:349:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:357:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:362:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:373:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:384:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:388:1: W293 blank line contains whitespace\napp/services/payment_providers/sumup_provider.py:391:35: W292 no newline at end of file\napp/services/platform_fee_service.py:11:1: E302 expected 2 blank lines, found 1\napp/services/platform_fee_service.py:23:60: E261 at least two spaces before inline comment\napp/services/platform_fee_service.py:45:121: E501 line too long (125 > 120 characters)\napp/services/platform_fee_service.py:49:121: E501 line too long (121 > 120 characters)\napp/services/platform_fee_service.py:59:27: E261 at least two spaces before inline comment\napp/services/platform_fee_service.py:60:44: E261 at least two spaces before inline comment\napp/services/platform_fee_service.py:97:53: E261 at least two spaces before inline comment\napp/services/platform_fee_service.py:99:85: E261 at least two spaces before inline comment\napp/services/platform_fee_service.py:112:121: E501 line too long (144 > 120 characters)\napp/services/platform_fee_service.py:124:74: E261 at least two spaces before inline comment\napp/services/platform_service.py:14:27: W291 trailing whitespace\napp/services/platform_service.py:15:24: W291 trailing whitespace\napp/services/platform_service.py:24:1: E302 expected 2 blank lines, found 1\napp/services/platform_service.py:26:1: W293 blank line contains whitespace\napp/services/platform_service.py:29:1: W293 blank line contains whitespace\napp/services/platform_service.py:35:49: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/services/platform_service.py:38:1: W293 blank line contains whitespace\napp/services/platform_service.py:41:1: W293 blank line contains whitespace\napp/services/platform_service.py:50:1: W293 blank line contains whitespace\napp/services/platform_service.py:52:14: W291 trailing whitespace\napp/services/platform_service.py:57:1: W293 blank line contains whitespace\napp/services/platform_service.py:59:45: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/services/platform_service.py:61:1: W293 blank line contains whitespace\napp/services/platform_service.py:64:1: W293 blank line contains whitespace\napp/services/platform_service.py:66:69: E712 comparison to False should be 'if cond is False:' or 'if not cond:'\napp/services/platform_service.py:67:1: W293 blank line contains whitespace\napp/services/platform_service.py:69:1: W293 blank line contains whitespace\napp/services/platform_service.py:79:1: W293 blank line contains whitespace\napp/services/platform_service.py:81:1: W293 blank line contains whitespace\napp/services/platform_service.py:83:14: W291 trailing whitespace\napp/services/platform_service.py:84:25: W291 trailing whitespace\napp/services/platform_service.py:91:1: W293 blank line contains whitespace\napp/services/platform_service.py:96:1: W293 blank line contains whitespace\napp/services/platform_service.py:100:1: W293 blank line contains whitespace\napp/services/platform_service.py:108:1: W293 blank line contains whitespace\napp/services/platform_service.py:111:1: W293 blank line contains whitespace\napp/services/platform_service.py:116:1: W293 blank line contains whitespace\napp/services/platform_service.py:128:1: W293 blank line contains whitespace\napp/services/platform_service.py:131:1: W293 blank line contains whitespace\napp/services/platform_service.py:134:1: W293 blank line contains whitespace\napp/services/platform_service.py:136:14: W291 trailing whitespace\napp/services/platform_service.py:141:1: W293 blank line contains whitespace\napp/services/platform_service.py:144:1: W293 blank line contains whitespace\napp/services/platform_service.py:149:48: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/services/platform_service.py:152:1: W293 blank line contains whitespace\napp/services/platform_service.py:154:1: W293 blank line contains whitespace\napp/services/platform_service.py:157:1: W293 blank line contains whitespace\napp/services/platform_service.py:167:1: W293 blank line contains whitespace\napp/services/platform_service.py:174:1: W293 blank line contains whitespace\napp/services/platform_service.py:176:1: W293 blank line contains whitespace\napp/services/platform_service.py:178:14: W291 trailing whitespace\napp/services/platform_service.py:186:1: W293 blank line contains whitespace\napp/services/platform_service.py:190:1: W293 blank line contains whitespace\napp/services/platform_service.py:195:1: W293 blank line contains whitespace\napp/services/platform_service.py:199:30: F541 f-string is missing placeholders\napp/services/platform_service.py:200:1: W293 blank line contains whitespace\napp/services/platform_service.py:208:1: W293 blank line contains whitespace\napp/services/platform_service.py:228:1: W293 blank line contains whitespace\napp/services/platform_service.py:240:1: W293 blank line contains whitespace\napp/services/platform_service.py:243:1: W293 blank line contains whitespace\napp/services/platform_service.py:246:1: W293 blank line contains whitespace\napp/services/platform_service.py:248:14: W291 trailing whitespace\napp/services/platform_service.py:252:1: W293 blank line contains whitespace\napp/services/platform_service.py:254:1: W293 blank line contains whitespace\napp/services/platform_service.py:258:1: W293 blank line contains whitespace\napp/services/platform_service.py:269:1: W293 blank line contains whitespace\napp/services/platform_service.py:271:1: W293 blank line contains whitespace\napp/services/platform_service.py:273:1: W293 blank line contains whitespace\napp/services/platform_service.py:290:121: E501 line too long (155 > 120 characters)\napp/services/platform_service.py:292:121: E501 line too long (159 > 120 characters)\napp/services/platform_service.py:293:121: E501 line too long (150 > 120 characters)\napp/services/platform_service.py:294:121: E501 line too long (171 > 120 characters)\napp/services/platform_service.py:295:121: E501 line too long (162 > 120 characters)\napp/services/platform_service.py:299:88: E261 at least two spaces before inline comment\napp/services/platform_service.py:299:121: E501 line too long (123 > 120 characters)\napp/services/platform_service.py:332:51: E261 at least two spaces before inline comment\napp/services/platform_service.py:340:36: E261 at least two spaces before inline comment\napp/services/platform_service.py:342:36: E261 at least two spaces before inline comment\napp/services/platform_service.py:343:22: E261 at least two spaces before inline comment\napp/services/platform_service.py:351:14: W291 trailing whitespace\napp/services/platform_service.py:359:1: W293 blank line contains whitespace\napp/services/platform_service.py:363:1: W293 blank line contains whitespace\napp/services/platform_service.py:367:1: W293 blank line contains whitespace\napp/services/platform_service.py:374:1: W293 blank line contains whitespace\napp/services/platform_service.py:376:1: W293 blank line contains whitespace\napp/services/platform_service.py:379:1: W293 blank line contains whitespace\napp/services/platform_service.py:382:1: W293 blank line contains whitespace\napp/services/platform_service.py:384:1: W293 blank line contains whitespace\napp/services/platform_service.py:389:1: W293 blank line contains whitespace\napp/services/platform_service.py:391:1: W293 blank line contains whitespace\napp/services/platform_service.py:393:14: W291 trailing whitespace\napp/services/platform_service.py:394:29: W291 trailing whitespace\napp/services/platform_service.py:400:1: W293 blank line contains whitespace\napp/services/platform_service.py:405:1: W293 blank line contains whitespace\napp/services/platform_service.py:407:1: W293 blank line contains whitespace\napp/services/platform_service.py:426:1: W293 blank line contains whitespace\napp/services/platform_service.py:436:1: W293 blank line contains whitespace\napp/services/platform_service.py:438:1: W293 blank line contains whitespace\napp/services/platform_service.py:448:1: W293 blank line contains whitespace\napp/services/platform_service.py:451:1: W293 blank line contains whitespace\napp/services/platform_service.py:459:1: W293 blank line contains whitespace\napp/services/platform_service.py:467:1: W293 blank line contains whitespace\napp/services/platform_service.py:472:1: W293 blank line contains whitespace\napp/services/platform_service.py:477:1: W293 blank line contains whitespace\napp/services/platform_service.py:479:1: W293 blank line contains whitespace\napp/services/platform_service.py:486:1: W293 blank line contains whitespace\napp/services/platform_service.py:489:1: W293 blank line contains whitespace\napp/services/platform_service.py:496:1: W293 blank line contains whitespace\napp/services/platform_service.py:498:1: W293 blank line contains whitespace\napp/services/platform_service.py:500:14: W291 trailing whitespace\napp/services/platform_service.py:501:25: W291 trailing whitespace\napp/services/platform_service.py:502:29: W291 trailing whitespace\napp/services/platform_service.py:506:1: W293 blank line contains whitespace\napp/services/platform_service.py:509:1: W293 blank line contains whitespace\napp/services/platform_service.py:514:1: W293 blank line contains whitespace\napp/services/platform_service.py:518:1: W293 blank line contains whitespace\napp/services/platform_service.py:520:1: W293 blank line contains whitespace\napp/services/platform_service.py:523:1: W293 blank line contains whitespace\napp/services/platform_service.py:530:1: W293 blank line contains whitespace\napp/services/platform_service.py:534:1: W293 blank line contains whitespace\napp/services/platform_service.py:540:1: W293 blank line contains whitespace\napp/services/platform_service.py:544:1: W293 blank line contains whitespace\napp/services/platform_service.py:548:1: W293 blank line contains whitespace\napp/services/platform_service.py:553:1: W293 blank line contains whitespace\napp/services/platform_service.py:555:14: W291 trailing whitespace\napp/services/platform_service.py:561:1: W293 blank line contains whitespace\napp/services/platform_service.py:565:1: W293 blank line contains whitespace\napp/services/platform_service.py:568:1: W293 blank line contains whitespace\napp/services/platform_service.py:571:1: W293 blank line contains whitespace\napp/services/platform_service.py:573:1: W293 blank line contains whitespace\napp/services/platform_service.py:590:1: W293 blank line contains whitespace\napp/services/platform_service.py:591:22: W292 no newline at end of file\napp/services/report_service.py:14:1: F811 redefinition of unused 'DailyReport' from line 13\napp/services/report_service.py:14:1: F811 redefinition of unused 'HourlyMetric' from line 13\napp/services/report_service.py:21:1: W293 blank line contains whitespace\napp/services/report_service.py:24:1: W293 blank line contains whitespace\napp/services/report_service.py:37:1: W293 blank line contains whitespace\napp/services/report_service.py:41:1: W293 blank line contains whitespace\napp/services/report_service.py:45:1: W293 blank line contains whitespace\napp/services/report_service.py:54:1: W293 blank line contains whitespace\napp/services/report_service.py:58:1: W293 blank line contains whitespace\napp/services/report_service.py:63:1: W293 blank line contains whitespace\napp/services/report_service.py:68:69: W291 trailing whitespace\napp/services/report_service.py:69:29: E128 continuation line under-indented for visual indent\napp/services/report_service.py:70:1: W293 blank line contains whitespace\napp/services/report_service.py:75:1: W293 blank line contains whitespace\napp/services/report_service.py:80:1: W293 blank line contains whitespace\napp/services/report_service.py:83:1: W293 blank line contains whitespace\napp/services/report_service.py:89:36: E712 comparison to True should be 'if cond is True:' or 'if cond:'\napp/services/report_service.py:92:1: W293 blank line contains whitespace\napp/services/report_service.py:96:1: W293 blank line contains whitespace\napp/services/report_service.py:100:1: W293 blank line contains whitespace\napp/services/report_service.py:125:1: W293 blank line contains whitespace\napp/services/report_service.py:130:1: W293 blank line contains whitespace\napp/services/report_service.py:132:24: E128 continuation line under-indented for visual indent\napp/services/report_service.py:133:1: W293 blank line contains whitespace\napp/services/report_service.py:135:1: W293 blank line contains whitespace\napp/services/report_service.py:140:1: W293 blank line contains whitespace\napp/services/report_service.py:148:1: W293 blank line contains whitespace\napp/services/report_service.py:152:1: W293 blank line contains whitespace\napp/services/report_service.py:162:1: W293 blank line contains whitespace\napp/services/report_service.py:167:1: W293 blank line contains whitespace\napp/services/report_service.py:170:1: W293 blank line contains whitespace\napp/services/report_service.py:180:1: W293 blank line contains whitespace\napp/services/report_service.py:182:1: W293 blank line contains whitespace\napp/services/report_service.py:188:1: W293 blank line contains whitespace\napp/services/report_service.py:190:1: W293 blank line contains whitespace\napp/services/report_service.py:195:1: W293 blank line contains whitespace\napp/services/report_service.py:205:1: W293 blank line contains whitespace\napp/services/report_service.py:218:1: W293 blank line contains whitespace\napp/services/report_service.py:221:1: W293 blank line contains whitespace\napp/services/report_service.py:225:1: W293 blank line contains whitespace\napp/services/report_service.py:241:1: W293 blank line contains whitespace\napp/services/report_service.py:249:40: W292 no newline at end of file\napp/services/secure_payment_config.py:21:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:30:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:40:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:47:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:50:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:60:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:78:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:80:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:91:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:98:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:101:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:109:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:112:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:118:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:122:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:140:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:147:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:156:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:161:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:170:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:173:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:175:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:178:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:187:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:198:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:206:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:210:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:217:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:220:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:222:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:234:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:238:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:242:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:250:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:253:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:256:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:263:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:267:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:271:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:283:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:286:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:289:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:294:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:296:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:301:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:305:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:309:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:313:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:316:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:319:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:324:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:328:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:335:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:338:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:343:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:345:17: F821 undefined name 'logger'\napp/services/secure_payment_config.py:347:1: W293 blank line contains whitespace\napp/services/secure_payment_config.py:356:80: W292 no newline at end of file\napp/services/secure_payment_processor.py:12:1: F401 'enum.Enum' imported but unused\napp/services/secure_payment_processor.py:31:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:36:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:40:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:44:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:47:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:50:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:54:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:57:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:66:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:78:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:87:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:95:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:103:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:116:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:125:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:128:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:137:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:151:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:163:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:168:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:175:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:181:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:187:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:195:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:205:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:208:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:212:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:220:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:223:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:228:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:236:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:241:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:250:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:253:19: F821 undefined name 'PaymentProvider'\napp/services/secure_payment_processor.py:273:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:277:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:281:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:291:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:299:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:315:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:321:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:324:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:327:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:332:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:333:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:334:5: E303 too many blank lines (2)\napp/services/secure_payment_processor.py:360:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:365:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:371:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:384:1: W293 blank line contains whitespace\napp/services/secure_payment_processor.py:385:20: W292 no newline at end of file\napp/services/service_charge_calculator.py:6:66: E261 at least two spaces before inline comment\napp/services/service_charge_calculator.py:11:1: E302 expected 2 blank lines, found 1\napp/services/service_charge_calculator.py:27:5: E303 too many blank lines (2)\napp/services/service_charge_calculator.py:35:43: E261 at least two spaces before inline comment\napp/services/service_charge_calculator.py:81:121: E501 line too long (136 > 120 characters)\napp/services/service_charge_calculator.py:85:121: E501 line too long (125 > 120 characters)\napp/services/service_charge_calculator.py:89:121: E501 line too long (121 > 120 characters)\napp/services/service_charge_calculator.py:98:121: E501 line too long (123 > 120 characters)\napp/services/service_charge_calculator.py:100:121: E501 line too long (129 > 120 characters)\napp/services/service_charge_calculator.py:101:121: E501 line too long (123 > 120 characters)\napp/services/service_charge_calculator.py:103:121: E501 line too long (121 > 120 characters)\napp/services/smart_routing.py:17:1: E302 expected 2 blank lines, found 1\napp/services/smart_routing.py:25:1: E302 expected 2 blank lines, found 1\napp/services/smart_routing.py:36:1: E302 expected 2 blank lines, found 1\napp/services/smart_routing.py:46:1: E302 expected 2 blank lines, found 1\napp/services/smart_routing.py:48:1: W293 blank line contains whitespace\napp/services/smart_routing.py:87:1: W293 blank line contains whitespace\napp/services/smart_routing.py:99:1: W293 blank line contains whitespace\napp/services/smart_routing.py:109:1: W293 blank line contains whitespace\napp/services/smart_routing.py:112:1: W293 blank line contains whitespace\napp/services/smart_routing.py:117:1: W293 blank line contains whitespace\napp/services/smart_routing.py:122:1: W293 blank line contains whitespace\napp/services/smart_routing.py:124:1: W293 blank line contains whitespace\napp/services/smart_routing.py:133:1: W293 blank line contains whitespace\napp/services/smart_routing.py:136:1: W293 blank line contains whitespace\napp/services/smart_routing.py:141:1: W293 blank line contains whitespace\napp/services/smart_routing.py:145:1: W293 blank line contains whitespace\napp/services/smart_routing.py:147:1: W293 blank line contains whitespace\napp/services/smart_routing.py:152:1: W293 blank line contains whitespace\napp/services/smart_routing.py:157:1: W293 blank line contains whitespace\napp/services/smart_routing.py:171:1: W293 blank line contains whitespace\napp/services/smart_routing.py:181:1: W293 blank line contains whitespace\napp/services/smart_routing.py:185:1: W293 blank line contains whitespace\napp/services/smart_routing.py:188:1: W293 blank line contains whitespace\napp/services/smart_routing.py:192:1: W293 blank line contains whitespace\napp/services/smart_routing.py:195:1: W293 blank line contains whitespace\napp/services/smart_routing.py:200:1: W293 blank line contains whitespace\napp/services/smart_routing.py:203:1: W293 blank line contains whitespace\napp/services/smart_routing.py:218:1: W293 blank line contains whitespace\napp/services/smart_routing.py:221:1: W293 blank line contains whitespace\napp/services/smart_routing.py:225:1: W293 blank line contains whitespace\napp/services/smart_routing.py:229:1: W293 blank line contains whitespace\napp/services/smart_routing.py:231:1: W293 blank line contains whitespace\napp/services/smart_routing.py:234:45: E226 missing whitespace around arithmetic operator\napp/services/smart_routing.py:235:1: W293 blank line contains whitespace\napp/services/smart_routing.py:242:1: W293 blank line contains whitespace\napp/services/smart_routing.py:251:1: W293 blank line contains whitespace\napp/services/smart_routing.py:254:1: W293 blank line contains whitespace\napp/services/smart_routing.py:260:1: W293 blank line contains whitespace\napp/services/smart_routing.py:265:1: W293 blank line contains whitespace\napp/services/smart_routing.py:268:1: W293 blank line contains whitespace\napp/services/smart_routing.py:273:1: W293 blank line contains whitespace\napp/services/smart_routing.py:278:1: W293 blank line contains whitespace\napp/services/smart_routing.py:282:46: W504 line break after binary operator\napp/services/smart_routing.py:283:60: W504 line break after binary operator\napp/services/smart_routing.py:284:48: W504 line break after binary operator\napp/services/smart_routing.py:285:50: W504 line break after binary operator\napp/services/smart_routing.py:288:1: W293 blank line contains whitespace\napp/services/smart_routing.py:298:1: W293 blank line contains whitespace\napp/services/smart_routing.py:301:1: W293 blank line contains whitespace\napp/services/smart_routing.py:303:1: W293 blank line contains whitespace\napp/services/smart_routing.py:312:1: W293 blank line contains whitespace\napp/services/smart_routing.py:318:121: E501 line too long (135 > 120 characters)\napp/services/smart_routing.py:326:1: W293 blank line contains whitespace\napp/services/smart_routing.py:329:1: W293 blank line contains whitespace\napp/services/smart_routing.py:333:1: W293 blank line contains whitespace\napp/services/smart_routing.py:335:1: W293 blank line contains whitespace\napp/services/smart_routing.py:343:1: W293 blank line contains whitespace\napp/services/smart_routing.py:346:1: W293 blank line contains whitespace\napp/services/smart_routing.py:356:1: W293 blank line contains whitespace\napp/services/smart_routing.py:358:1: W293 blank line contains whitespace\napp/services/smart_routing.py:361:1: W293 blank line contains whitespace\napp/services/smart_routing.py:363:1: W293 blank line contains whitespace\napp/services/smart_routing.py:367:1: W293 blank line contains whitespace\napp/services/smart_routing.py:374:1: W293 blank line contains whitespace\napp/services/smart_routing.py:383:1: W293 blank line contains whitespace\napp/services/smart_routing.py:388:1: W293 blank line contains whitespace\napp/services/smart_routing.py:398:1: W293 blank line contains whitespace\napp/services/smart_routing.py:407:1: W293 blank line contains whitespace\napp/services/smart_routing.py:416:1: W293 blank line contains whitespace\napp/services/smart_routing.py:418:1: W293 blank line contains whitespace\napp/services/smart_routing.py:421:1: W293 blank line contains whitespace\napp/services/smart_routing.py:430:1: W293 blank line contains whitespace\napp/services/smart_routing.py:433:1: W293 blank line contains whitespace\napp/services/smart_routing.py:474:1: W293 blank line contains whitespace\napp/services/smart_routing.py:482:1: W293 blank line contains whitespace\napp/services/smart_routing.py:485:1: W293 blank line contains whitespace\napp/services/smart_routing.py:488:1: W293 blank line contains whitespace\napp/services/smart_routing.py:495:1: W293 blank line contains whitespace\napp/services/smart_routing.py:499:1: W293 blank line contains whitespace\napp/services/smart_routing.py:504:1: W293 blank line contains whitespace\napp/services/smart_routing.py:507:1: W293 blank line contains whitespace\napp/services/smart_routing.py:510:1: W293 blank line contains whitespace\napp/services/smart_routing.py:513:48: W291 trailing whitespace\napp/services/smart_routing.py:516:1: W293 blank line contains whitespace\napp/services/smart_routing.py:523:1: W293 blank line contains whitespace\napp/services/smart_routing.py:532:1: W293 blank line contains whitespace\napp/services/smart_routing.py:541:1: W293 blank line contains whitespace\napp/services/smart_routing.py:549:1: W293 blank line contains whitespace\napp/services/smart_routing.py:567:1: W293 blank line contains whitespace\napp/services/smart_routing.py:569:1: W293 blank line contains whitespace\napp/services/smart_routing.py:578:1: W293 blank line contains whitespace\napp/services/smart_routing.py:580:1: W293 blank line contains whitespace\napp/services/smart_routing.py:587:121: E501 line too long (123 > 120 characters)\napp/services/smart_routing.py:593:1: W293 blank line contains whitespace\napp/services/smart_routing.py:598:1: W293 blank line contains whitespace\napp/services/smart_routing.py:610:1: W293 blank line contains whitespace\napp/services/smart_routing.py:624:1: W293 blank line contains whitespace\napp/services/smart_routing.py:626:1: W293 blank line contains whitespace\napp/services/smart_routing.py:634:1: W293 blank line contains whitespace\napp/services/smart_routing.py:637:1: W293 blank line contains whitespace\napp/services/smart_routing.py:639:1: W293 blank line contains whitespace\napp/services/smart_routing.py:647:1: W293 blank line contains whitespace\napp/services/smart_routing.py:656:1: W293 blank line contains whitespace\napp/services/smart_routing.py:659:1: W293 blank line contains whitespace\napp/services/smart_routing.py:666:1: W293 blank line contains whitespace\napp/services/smart_routing.py:668:1: W293 blank line contains whitespace\napp/services/smart_routing.py:675:1: W293 blank line contains whitespace\napp/services/smart_routing.py:682:1: W293 blank line contains whitespace\napp/services/smart_routing.py:689:1: W293 blank line contains whitespace\napp/services/smart_routing.py:690:21: W292 no newline at end of file\napp/services/staff_tip_service.py:6:70: E261 at least two spaces before inline comment\napp/services/staff_tip_service.py:7:68: E261 at least two spaces before inline comment\napp/services/staff_tip_service.py:8:1: F401 'app.core.database.SessionLocal' imported but unused\napp/services/staff_tip_service.py:8:43: E261 at least two spaces before inline comment\napp/services/staff_tip_service.py:12:1: E302 expected 2 blank lines, found 1\napp/services/staff_tip_service.py:43:48: F821 undefined name 'total_tips_collected'\napp/services/staff_tip_service.py:44:9: F841 local variable 'dec_service_charge_amount_on_order' is assigned to but never used\napp/services/staff_tip_service.py:44:58: F821 undefined name 'service_charge_amount_on_order'\napp/services/staff_tip_service.py:45:67: F821 undefined name 'processor_fee_covered_by_service_charge'\napp/services/staff_tip_service.py:47:16: F821 undefined name 'assigned_staff'\napp/services/staff_tip_service.py:48:59: F821 undefined name 'order_reference'\napp/services/staff_tip_service.py:48:94: F821 undefined name 'total_tips_collected'\napp/services/staff_tip_service.py:48:121: E501 line too long (154 > 120 characters)\napp/services/staff_tip_service.py:53:56: F821 undefined name 'order_reference'\napp/services/staff_tip_service.py:84:121: E501 line too long (207 > 120 characters)\napp/services/staff_tip_service.py:93:25: F821 undefined name 'assigned_staff'\napp/services/staff_tip_service.py:95:12: F821 undefined name 'tip_distribution_strategy'\napp/services/staff_tip_service.py:103:121: E501 line too long (137 > 120 characters)\napp/services/staff_tip_service.py:106:17: E303 too many blank lines (2)\napp/services/staff_tip_service.py:106:42: F821 undefined name 'assigned_staff'\napp/services/staff_tip_service.py:116:121: E501 line too long (128 > 120 characters)\napp/services/staff_tip_service.py:122:41: F821 undefined name 'order_reference'\napp/services/staff_tip_service.py:124:78: E261 at least two spaces before inline comment\napp/services/staff_tip_service.py:125:54: E261 at least two spaces before inline comment\napp/services/staff_tip_service.py:126:29: E131 continuation line unaligned for hanging indent\napp/services/staff_tip_service.py:127:94: E261 at least two spaces before inline comment\napp/services/staff_tip_service.py:128:76: E261 at least two spaces before inline comment\napp/services/staff_tip_service.py:128:121: E501 line too long (152 > 120 characters)\napp/services/staff_tip_service.py:133:65: F821 undefined name 'tip_distribution_strategy'\napp/services/staff_tip_service.py:133:121: E501 line too long (141 > 120 characters)\napp/services/staff_tip_service.py:133:123: F821 undefined name 'order_reference'\napp/services/staff_tip_service.py:144:68: F821 undefined name 'tip_distribution_strategy'\napp/services/staff_tip_service.py:145:72: F821 undefined name 'tip_distribution_strategy'\napp/services/staff_tip_service.py:149:121: E501 line too long (254 > 120 characters)\napp/services/staff_tip_service.py:149:173: F821 undefined name 'order_reference'\napp/services/staff_tip_service.py:149:197: E261 at least two spaces before inline comment\napp/services/staff_tip_service.py:150:18: E114 indentation is not a multiple of 4 (comment)\napp/services/staff_tip_service.py:150:18: E117 over-indented (comment)\napp/services/staff_tip_service.py:151:18: E114 indentation is not a multiple of 4 (comment)\napp/services/staff_tip_service.py:151:18: E117 over-indented (comment)\napp/services/staff_tip_service.py:152:18: E111 indentation is not a multiple of 4\napp/services/staff_tip_service.py:152:18: E117 over-indented\napp/services/staff_tip_service.py:155:76: F821 undefined name 'order_reference'\napp/services/staff_tip_service.py:166:121: E501 line too long (163 > 120 characters)\napp/services/storage_service.py:32:1: W293 blank line contains whitespace\napp/services/storage_service.py:37:1: W293 blank line contains whitespace\napp/services/storage_service.py:49:1: W293 blank line contains whitespace\napp/services/storage_service.py:60:1: W293 blank line contains whitespace\napp/services/storage_service.py:65:1: W293 blank line contains whitespace\napp/services/storage_service.py:67:1: W293 blank line contains whitespace\napp/services/storage_service.py:75:1: W293 blank line contains whitespace\napp/services/storage_service.py:83:1: W293 blank line contains whitespace\napp/services/storage_service.py:87:1: W293 blank line contains whitespace\napp/services/storage_service.py:89:1: W293 blank line contains whitespace\napp/services/storage_service.py:99:1: W293 blank line contains whitespace\napp/services/storage_service.py:106:1: W293 blank line contains whitespace\napp/services/storage_service.py:111:1: W293 blank line contains whitespace\napp/services/storage_service.py:113:1: W293 blank line contains whitespace\napp/services/storage_service.py:119:1: W293 blank line contains whitespace\napp/services/storage_service.py:125:1: W293 blank line contains whitespace\napp/services/storage_service.py:129:1: W293 blank line contains whitespace\napp/services/storage_service.py:144:1: W293 blank line contains whitespace\napp/services/storage_service.py:148:1: W293 blank line contains whitespace\napp/services/storage_service.py:150:1: W293 blank line contains whitespace\napp/services/storage_service.py:160:1: W293 blank line contains whitespace\napp/services/storage_service.py:178:1: W293 blank line contains whitespace\napp/services/storage_service.py:181:1: W293 blank line contains whitespace\napp/services/storage_service.py:185:84: E226 missing whitespace around arithmetic operator\napp/services/storage_service.py:189:1: W293 blank line contains whitespace\napp/services/storage_service.py:198:1: W293 blank line contains whitespace\napp/services/storage_service.py:208:1: W293 blank line contains whitespace\napp/services/storage_service.py:217:1: W293 blank line contains whitespace\napp/services/storage_service.py:220:1: W293 blank line contains whitespace\napp/services/storage_service.py:228:1: W293 blank line contains whitespace\napp/services/storage_service.py:232:1: W293 blank line contains whitespace\napp/services/storage_service.py:241:1: W293 blank line contains whitespace\napp/services/storage_service.py:248:1: W293 blank line contains whitespace\napp/services/storage_service.py:253:1: W293 blank line contains whitespace\napp/services/storage_service.py:258:1: W293 blank line contains whitespace\napp/services/storage_service.py:260:1: W293 blank line contains whitespace\napp/services/storage_service.py:263:1: W293 blank line contains whitespace\napp/services/storage_service.py:267:1: W293 blank line contains whitespace\napp/services/storage_service.py:270:1: W293 blank line contains whitespace\napp/services/storage_service.py:280:1: W293 blank line contains whitespace\napp/services/storage_service.py:283:1: W293 blank line contains whitespace\napp/services/storage_service.py:286:1: W293 blank line contains whitespace\napp/services/storage_service.py:290:1: W293 blank line contains whitespace\napp/services/storage_service.py:295:1: W293 blank line contains whitespace\napp/services/storage_service.py:308:1: W293 blank line contains whitespace\napp/services/storage_service.py:315:1: W293 blank line contains whitespace\napp/services/storage_service.py:318:1: W293 blank line contains whitespace\napp/services/storage_service.py:325:1: W293 blank line contains whitespace\napp/services/storage_service.py:327:1: W293 blank line contains whitespace\napp/services/storage_service.py:331:1: W293 blank line contains whitespace\napp/services/storage_service.py:338:1: W293 blank line contains whitespace\napp/services/storage_service.py:341:1: W293 blank line contains whitespace\napp/services/storage_service.py:348:1: W293 blank line contains whitespace\napp/services/storage_service.py:351:121: E501 line too long (144 > 120 characters)\napp/services/storage_service.py:358:1: W293 blank line contains whitespace\napp/services/storage_service.py:360:1: W293 blank line contains whitespace\napp/services/storage_service.py:364:1: W293 blank line contains whitespace\napp/services/storage_service.py:371:1: W293 blank line contains whitespace\napp/services/storage_service.py:374:1: W293 blank line contains whitespace\napp/services/storage_service.py:380:1: W293 blank line contains whitespace\napp/services/storage_service.py:386:1: W293 blank line contains whitespace\napp/services/storage_service.py:390:1: W293 blank line contains whitespace\napp/services/storage_service.py:397:1: W293 blank line contains whitespace\napp/services/storage_service.py:406:35: W292 no newline at end of file\napp/services/sync_service.py:10:1: F401 'sqlalchemy.and_' imported but unused\napp/services/sync_service.py:10:1: F401 'sqlalchemy.or_' imported but unused\napp/services/sync_service.py:13:1: F401 'app.core.database.get_db' imported but unused\napp/services/sync_service.py:15:1: F401 'app.models.Restaurant' imported but unused\napp/services/sync_service.py:15:1: F401 'app.models.Product' imported but unused\napp/services/sync_service.py:15:1: F401 'app.models.Category' imported but unused\napp/services/sync_service.py:15:1: F401 'app.models.Order' imported but unused\napp/services/sync_service.py:15:1: F401 'app.models.User' imported but unused\napp/services/sync_service.py:24:1: E302 expected 2 blank lines, found 1\napp/services/sync_service.py:28:1: W293 blank line contains whitespace\napp/services/sync_service.py:34:1: W293 blank line contains whitespace\napp/services/sync_service.py:40:1: W293 blank line contains whitespace\napp/services/sync_service.py:43:1: W293 blank line contains whitespace\napp/services/sync_service.py:47:1: W293 blank line contains whitespace\napp/services/sync_service.py:49:14: W291 trailing whitespace\napp/services/sync_service.py:50:28: W291 trailing whitespace\napp/services/sync_service.py:69:1: W293 blank line contains whitespace\napp/services/sync_service.py:71:1: W293 blank line contains whitespace\napp/services/sync_service.py:79:1: W293 blank line contains whitespace\napp/services/sync_service.py:81:1: W293 blank line contains whitespace\napp/services/sync_service.py:85:1: W293 blank line contains whitespace\napp/services/sync_service.py:92:44: W291 trailing whitespace\napp/services/sync_service.py:95:1: W293 blank line contains whitespace\napp/services/sync_service.py:97:1: W293 blank line contains whitespace\napp/services/sync_service.py:102:1: W293 blank line contains whitespace\napp/services/sync_service.py:109:1: W293 blank line contains whitespace\napp/services/sync_service.py:115:45: W291 trailing whitespace\napp/services/sync_service.py:121:1: W293 blank line contains whitespace\napp/services/sync_service.py:123:1: W293 blank line contains whitespace\napp/services/sync_service.py:126:1: W293 blank line contains whitespace\napp/services/sync_service.py:131:1: W293 blank line contains whitespace\napp/services/sync_service.py:135:41: W291 trailing whitespace\napp/services/sync_service.py:138:1: W293 blank line contains whitespace\napp/services/sync_service.py:146:1: W293 blank line contains whitespace\napp/services/sync_service.py:153:1: W293 blank line contains whitespace\napp/services/sync_service.py:158:1: W293 blank line contains whitespace\napp/services/sync_service.py:161:1: W293 blank line contains whitespace\napp/services/sync_service.py:170:1: W293 blank line contains whitespace\napp/services/sync_service.py:177:1: W293 blank line contains whitespace\napp/services/sync_service.py:192:1: W293 blank line contains whitespace\napp/services/sync_service.py:200:1: W293 blank line contains whitespace\napp/services/sync_service.py:211:40: W291 trailing whitespace\napp/services/sync_service.py:216:1: W293 blank line contains whitespace\napp/services/sync_service.py:230:1: W293 blank line contains whitespace\napp/services/sync_service.py:239:1: W293 blank line contains whitespace\napp/services/sync_service.py:254:1: W293 blank line contains whitespace\napp/services/sync_service.py:260:30: W291 trailing whitespace\napp/services/sync_service.py:262:1: W293 blank line contains whitespace\napp/services/sync_service.py:268:1: W293 blank line contains whitespace\napp/services/sync_service.py:280:1: W293 blank line contains whitespace\napp/services/sync_service.py:284:1: W293 blank line contains whitespace\napp/services/sync_service.py:286:1: W293 blank line contains whitespace\napp/services/sync_service.py:288:14: W291 trailing whitespace\napp/services/sync_service.py:295:1: W293 blank line contains whitespace\napp/services/sync_service.py:298:77: W291 trailing whitespace\napp/services/sync_service.py:300:1: W293 blank line contains whitespace\napp/services/sync_service.py:304:1: W293 blank line contains whitespace\napp/services/sync_service.py:315:1: W293 blank line contains whitespace\napp/services/sync_service.py:325:1: E305 expected 2 blank lines after class or function definition, found 1\napp/services/sync_service.py:327:1: E302 expected 2 blank lines, found 1\napp/services/sync_service.py:329:24: W292 no newline at end of file\napp/services/volume_tracker.py:18:1: E302 expected 2 blank lines, found 1\napp/services/volume_tracker.py:28:1: E302 expected 2 blank lines, found 1\napp/services/volume_tracker.py:36:1: E302 expected 2 blank lines, found 1\napp/services/volume_tracker.py:47:1: E302 expected 2 blank lines, found 1\napp/services/volume_tracker.py:49:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:52:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:74:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:81:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:84:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:91:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:93:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:103:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:108:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:111:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:114:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:119:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:128:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:135:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:138:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:141:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:145:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:153:121: E501 line too long (124 > 120 characters)\napp/services/volume_tracker.py:160:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:172:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:174:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:181:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:184:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:186:13: F841 local variable 'start_offset' is assigned to but never used\napp/services/volume_tracker.py:188:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:191:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:196:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:201:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:208:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:212:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:223:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:232:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:239:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:243:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:246:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:249:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:252:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:281:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:284:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:290:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:293:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:295:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:298:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:305:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:308:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:310:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:319:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:323:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:329:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:330:9: F841 local variable 'current_volume' is assigned to but never used\napp/services/volume_tracker.py:332:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:335:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:338:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:345:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:351:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:353:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:361:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:367:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:369:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:376:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:379:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:383:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:393:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:400:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:402:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:409:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:412:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:423:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:427:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:436:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:441:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:447:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:454:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:457:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:463:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:466:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:480:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:487:1: W293 blank line contains whitespace\napp/services/volume_tracker.py:488:28: W292 no newline at end of file\napp/simple_main.py:30:1: E402 module level import not at top of file\napp/simple_main.py:33:1: E302 expected 2 blank lines, found 1\napp/simple_main.py:42:1: E302 expected 2 blank lines, found 1\napp/simple_main.py:52:1: W293 blank line contains whitespace\napp/simple_main.py:73:1: E302 expected 2 blank lines, found 1\napp/simple_main.py:78:1: E302 expected 2 blank lines, found 1\napp/simple_main.py:85:1: W293 blank line contains whitespace\napp/simple_main.py:97:1: E302 expected 2 blank lines, found 1\napp/simple_main.py:103:1: W293 blank line contains whitespace\napp/simple_main.py:105:1: W293 blank line contains whitespace\napp/simple_main.py:119:1: E302 expected 2 blank lines, found 1\napp/simple_main.py:124:1: E302 expected 2 blank lines, found 1\napp/simple_main.py:130:1: E302 expected 2 blank lines, found 1\napp/simple_main.py:135:1: W293 blank line contains whitespace\napp/simple_main.py:136:17: E116 unexpected indentation (comment)\napp/simple_main.py:169:41: W291 trailing whitespace\napp/simple_main.py:199:48: W291 trailing whitespace\napp/simple_main.py:206:48: W291 trailing whitespace\napp/simple_main.py:231:1: W293 blank line contains whitespace\napp/simple_main.py:236:1: E302 expected 2 blank lines, found 1\napp/simple_main.py:241:1: W293 blank line contains whitespace\napp/simple_main.py:242:17: E116 unexpected indentation (comment)\napp/simple_main.py:253:1: E302 expected 2 blank lines, found 1\napp/simple_main.py:258:1: W293 blank line contains whitespace\napp/simple_main.py:259:17: E116 unexpected indentation (comment)\napp/simple_main.py:270:1: E302 expected 2 blank lines, found 1\napp/simple_main.py:275:1: W293 blank line contains whitespace\napp/simple_main.py:276:17: E116 unexpected indentation (comment)\napp/simple_main.py:290:48: W292 no newline at end of file\napp/tasks/replica_validator.py:23:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:29:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:31:14: W291 trailing whitespace\napp/tasks/replica_validator.py:32:34: W291 trailing whitespace\napp/tasks/replica_validator.py:46:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:52:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:55:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:58:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:63:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:66:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:74:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:84:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:88:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:97:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:100:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:108:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:111:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:128:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:135:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:142:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:158:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:162:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:165:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:167:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:176:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:186:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:190:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:195:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:203:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:209:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:214:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:218:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:221:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:234:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:236:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:241:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:244:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:250:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:251:13: F841 local variable 'alert_type' is assigned to but never used\napp/tasks/replica_validator.py:253:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:255:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:259:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:267:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:270:121: E501 line too long (129 > 120 characters)\napp/tasks/replica_validator.py:274:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:277:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:283:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:285:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:288:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:292:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:323:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:327:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:366:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:370:1: W293 blank line contains whitespace\napp/tasks/replica_validator.py:378:5: F824 `global _replica_validator` is unused: name is never assigned in scope\napp/tasks/replica_validator.py:384:1: E402 module level import not at top of file\napp/tasks/replica_validator.py:384:40: W292 no newline at end of file\napp/tests/services/test_ocr_service.py:19:1: E302 expected 2 blank lines, found 1\napp/tests/services/test_ocr_service.py:42:1: E302 expected 2 blank lines, found 1\napp/tests/services/test_ocr_service.py:50:28: E261 at least two spaces before inline comment\napp/tests/services/test_ocr_service.py:72:1: E302 expected 2 blank lines, found 1\napp/tests/services/test_ocr_service.py:76:50: E261 at least two spaces before inline comment\napp/websocket/__init__.py:4:4: W292 no newline at end of file\n19    E111 indentation is not a multiple of 4\n6     E114 indentation is not a multiple of 4 (comment)\n7     E116 unexpected indentation (comment)\n18    E117 over-indented\n7     E121 continuation line under-indented for hanging indent\n18    E122 continuation line missing indentation or outdented\n1     E127 continuation line over-indented for visual indent\n26    E128 continuation line under-indented for visual indent\n3     E129 visually indented line with same indent as next logical line\n1     E131 continuation line unaligned for hanging indent\n1     E202 whitespace before ')'\n1     E225 missing whitespace around operator\n13    E226 missing whitespace around arithmetic operator\n2     E231 missing whitespace after ','\n5     E241 multiple spaces after ':'\n14    E251 unexpected spaces around keyword / parameter equals\n385   E261 at least two spaces before inline comment\n1     E272 multiple spaces before keyword\n582   E302 expected 2 blank lines, found 1\n17    E303 too many blank lines (2)\n19    E305 expected 2 blank lines after class or function definition, found 1\n42    E402 module level import not at top of file\n275   E501 line too long (126 > 120 characters)\n6     E701 multiple statements on one line (colon)\n58    E712 comparison to True should be 'if cond is True:' or 'if cond:'\n7     E999 IndentationError: unexpected indent\n233   F401 'typing.Dict' imported but unused\n14    F541 f-string is missing placeholders\n7     F811 redefinition of unused 'Optional' from line 13\n276   F821 undefined name 'ErrorCodes'\n2     F824 `global instance_tracker` is unused: name is never assigned in scope\n67    F841 local variable 'e' is assigned to but never used\n226   W291 trailing whitespace\n142   W292 no newline at end of file\n5173  W293 blank line contains whitespace\n1     W391 blank line at end of file\n14    W504 line break after binary operator\n1     W605 invalid escape sequence '\\ '\n7690\n<unknown>:7: SyntaxWarning: invalid escape sequence '\\ '\n",
    "command": "flake8 app/ --statistics --count"
  },
  "Bandit Security Check": {
    "success": false,
    "output": "Working... \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 100% 0:00:01\n[main]\tINFO\tprofile include tests: None\n[main]\tINFO\tprofile exclude tests: None\n[main]\tINFO\tcli include tests: None\n[main]\tINFO\tcli exclude tests: None\n[warnings]\tWARNING\tinvalid escape sequence '\\ '\n\n[json]\tINFO\tJSON output written to file: bandit-report.json\n",
    "command": "bandit -r app/ -f json -o bandit-report.json"
  }
}